    PID TTY          TIME CMD
3225959 pts/91   00:00:00 bash
    PID TTY          TIME CMD
3225959 pts/91   00:00:00 bash
    PID TTY          TIME CMD
3225959 pts/91   00:00:00 bash
    PID TTY          TIME CMD
3225959 pts/91   00:00:00 bash
    PID TTY          TIME CMD
3225959 pts/91   00:00:00 bash
    PID TTY          TIME CMD
3225959 pts/91   00:00:00 bash
    PID TTY          TIME CMD
3225959 pts/91   00:00:00 bash
    PID TTY          TIME CMD
3225959 pts/91   00:00:00 bash
    PID TTY          TIME CMD
3225959 pts/91   00:00:00 bash
    PID TTY          TIME CMD
3225959 pts/91   00:00:00 bash
    PID TTY          TIME CMD
3225959 pts/91   00:00:00 bash
    PID TTY          TIME CMD
3225959 pts/91   00:00:00 bash
    PID TTY          TIME CMD
3225959 pts/91   00:00:00 bash
    PID TTY          TIME CMD
3225959 pts/91   00:00:00 bash
    PID TTY          TIME CMD
3225959 pts/91   00:00:00 bash
    PID TTY          TIME CMD
3225959 pts/91   00:00:00 bash
    PID TTY          TIME CMD
3225959 pts/91   00:00:00 bash
    PID TTY          TIME CMD
3225959 pts/91   00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
3225959 ?        00:00:00 bash
    PID TTY          TIME CMD
2024-07-10 17:08:44 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt22.sep.tokenized.fr-de', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=1000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=100, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-10 17:08:44 | INFO | fairseq.tasks.translation | [fr] dictionary: 8 types
2024-07-10 17:08:44 | INFO | fairseq.tasks.translation | [de] dictionary: 9960 types
2024-07-10 17:08:44 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.fr
2024-07-10 17:08:44 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.de
2024-07-10 17:08:44 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de valid fr-de 3238 examples
2024-07-10 17:08:45 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9960, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=9960, bias=False)
  )
)
2024-07-10 17:08:45 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-10 17:08:45 | INFO | fairseq_cli.train | model: transformer_iwslt_de_en (TransformerModel)
2024-07-10 17:08:45 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-10 17:08:45 | INFO | fairseq_cli.train | num. model params: 36646912 (num. trained: 36646912)
2024-07-10 17:08:54 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-10 17:08:54 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-10 17:08:54 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-10 17:08:54 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-10 17:08:54 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-10 17:08:54 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-10 17:08:54 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/checkpoint_last.pt
2024-07-10 17:08:54 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-10 17:08:55 | INFO | fairseq.data.data_utils | loaded 1732407 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.fr
2024-07-10 17:08:55 | INFO | fairseq.data.data_utils | loaded 1732407 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.de
2024-07-10 17:08:55 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de train fr-de 1732407 examples
2024-07-10 17:08:57 | INFO | fairseq.trainer | begin training epoch 1
2024-07-10 17:09:16 | INFO | train_inner | epoch 001:    100 / 13004 loss=13.277, nll_loss=13.193, ppl=9364.63, wps=24299.7, ups=6.21, wpb=3914.1, bsz=125.7, num_updates=100, lr=1.25e-05, gnorm=2.29, train_wall=19, wall=22
2024-07-10 17:09:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-10 17:09:17 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.347 | nll_loss 12.136 | ppl 4502.1 | wps 96968.3 | wpb 3703.5 | bsz 124.5 | num_updates 100
2024-07-10 17:09:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:09:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_100.pt (epoch 1 @ 100 updates, score 12.347) (writing took 1.887698165141046 seconds)
2024-07-10 17:09:34 | INFO | train_inner | epoch 001:    200 / 13004 loss=12.059, nll_loss=11.836, ppl=3655.95, wps=21700.1, ups=5.54, wpb=3918.8, bsz=133.2, num_updates=200, lr=2.5e-05, gnorm=1.259, train_wall=15, wall=40
2024-07-10 17:09:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:09:35 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.565 | nll_loss 11.269 | ppl 2468.44 | wps 94224.8 | wpb 3703.5 | bsz 124.5 | num_updates 200 | best_loss 11.565
2024-07-10 17:09:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:09:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_200.pt (epoch 1 @ 200 updates, score 11.565) (writing took 4.909762936644256 seconds)
2024-07-10 17:09:55 | INFO | train_inner | epoch 001:    300 / 13004 loss=11.361, nll_loss=11.042, ppl=2108.85, wps=18636.2, ups=4.73, wpb=3938.8, bsz=150.6, num_updates=300, lr=3.75e-05, gnorm=1.143, train_wall=15, wall=61
2024-07-10 17:09:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:09:56 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.038 | nll_loss 10.648 | ppl 1604.56 | wps 97886.6 | wpb 3703.5 | bsz 124.5 | num_updates 300 | best_loss 11.038
2024-07-10 17:09:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:10:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_300.pt (epoch 1 @ 300 updates, score 11.038) (writing took 4.577756346203387 seconds)
2024-07-10 17:10:16 | INFO | train_inner | epoch 001:    400 / 13004 loss=11.036, nll_loss=10.641, ppl=1597.14, wps=18681.5, ups=4.78, wpb=3904.3, bsz=133.6, num_updates=400, lr=5e-05, gnorm=1.122, train_wall=15, wall=82
2024-07-10 17:10:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:10:17 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.806 | nll_loss 10.342 | ppl 1297.5 | wps 97555.1 | wpb 3703.5 | bsz 124.5 | num_updates 400 | best_loss 10.806
2024-07-10 17:10:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:10:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_400.pt (epoch 1 @ 400 updates, score 10.806) (writing took 4.695798910222948 seconds)
2024-07-10 17:10:37 | INFO | train_inner | epoch 001:    500 / 13004 loss=10.921, nll_loss=10.487, ppl=1435.54, wps=18779.4, ups=4.78, wpb=3924.8, bsz=133.7, num_updates=500, lr=6.25e-05, gnorm=1.077, train_wall=15, wall=102
2024-07-10 17:10:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:10:38 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.787 | nll_loss 10.307 | ppl 1267.15 | wps 96219.3 | wpb 3703.5 | bsz 124.5 | num_updates 500 | best_loss 10.787
2024-07-10 17:10:38 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:10:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_500.pt (epoch 1 @ 500 updates, score 10.787) (writing took 4.43922474142164 seconds)
2024-07-10 17:10:58 | INFO | train_inner | epoch 001:    600 / 13004 loss=10.854, nll_loss=10.409, ppl=1359.92, wps=18846.9, ups=4.78, wpb=3943.5, bsz=134.6, num_updates=600, lr=7.5e-05, gnorm=1.001, train_wall=15, wall=123
2024-07-10 17:10:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:10:59 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.805 | nll_loss 10.319 | ppl 1277.73 | wps 96601.9 | wpb 3703.5 | bsz 124.5 | num_updates 600 | best_loss 10.787
2024-07-10 17:10:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:11:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_600.pt (epoch 1 @ 600 updates, score 10.805) (writing took 2.6880914233624935 seconds)
2024-07-10 17:11:17 | INFO | train_inner | epoch 001:    700 / 13004 loss=10.748, nll_loss=10.289, ppl=1250.7, wps=20850.3, ups=5.29, wpb=3942.2, bsz=144.2, num_updates=700, lr=8.75e-05, gnorm=1.136, train_wall=15, wall=142
2024-07-10 17:11:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:11:18 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.639 | nll_loss 10.129 | ppl 1119.79 | wps 96084.2 | wpb 3703.5 | bsz 124.5 | num_updates 700 | best_loss 10.639
2024-07-10 17:11:18 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:11:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_700.pt (epoch 1 @ 700 updates, score 10.639) (writing took 5.311430060304701 seconds)
2024-07-10 17:11:39 | INFO | train_inner | epoch 001:    800 / 13004 loss=10.584, nll_loss=10.102, ppl=1098.67, wps=17771.4, ups=4.52, wpb=3935.6, bsz=140.9, num_updates=800, lr=0.0001, gnorm=1.126, train_wall=16, wall=164
2024-07-10 17:11:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:11:40 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.505 | nll_loss 9.98 | ppl 1010.23 | wps 98311.7 | wpb 3703.5 | bsz 124.5 | num_updates 800 | best_loss 10.505
2024-07-10 17:11:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:11:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_800.pt (epoch 1 @ 800 updates, score 10.505) (writing took 4.436386258341372 seconds)
2024-07-10 17:12:00 | INFO | train_inner | epoch 001:    900 / 13004 loss=10.467, nll_loss=9.966, ppl=999.92, wps=18696, ups=4.76, wpb=3923.6, bsz=127, num_updates=900, lr=0.0001125, gnorm=1.114, train_wall=15, wall=185
2024-07-10 17:12:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:12:01 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.372 | nll_loss 9.825 | ppl 906.96 | wps 93784.5 | wpb 3703.5 | bsz 124.5 | num_updates 900 | best_loss 10.372
2024-07-10 17:12:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:12:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_900.pt (epoch 1 @ 900 updates, score 10.372) (writing took 4.709857682697475 seconds)
2024-07-10 17:12:21 | INFO | train_inner | epoch 001:   1000 / 13004 loss=10.277, nll_loss=9.745, ppl=858.24, wps=18568.6, ups=4.7, wpb=3947.3, bsz=136.8, num_updates=1000, lr=0.000125, gnorm=1.19, train_wall=15, wall=207
2024-07-10 17:12:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:12:22 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.234 | nll_loss 9.66 | ppl 808.92 | wps 97386.7 | wpb 3703.5 | bsz 124.5 | num_updates 1000 | best_loss 10.234
2024-07-10 17:12:22 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:12:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 10.234) (writing took 4.381798745132983 seconds)
2024-07-10 17:12:27 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-10 17:12:27 | INFO | train | epoch 001 | loss 11.157 | nll_loss 10.769 | ppl 1745.26 | wps 18994.5 | ups 4.83 | wpb 3929.3 | bsz 136 | num_updates 1000 | lr 0.000125 | gnorm 1.246 | train_wall 155 | wall 212
2024-07-10 17:12:27 | INFO | fairseq_cli.train | done training in 209.8 seconds
2024-07-10 17:12:32 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt22.sep.tokenized.fr-de', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=10000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=500, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-10 17:12:32 | INFO | fairseq.tasks.translation | [fr] dictionary: 8 types
2024-07-10 17:12:32 | INFO | fairseq.tasks.translation | [de] dictionary: 9960 types
2024-07-10 17:12:32 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.fr
2024-07-10 17:12:32 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.de
2024-07-10 17:12:32 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de valid fr-de 3238 examples
2024-07-10 17:12:33 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9960, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=9960, bias=False)
  )
)
2024-07-10 17:12:33 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-10 17:12:33 | INFO | fairseq_cli.train | model: transformer_iwslt_de_en (TransformerModel)
2024-07-10 17:12:33 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-10 17:12:33 | INFO | fairseq_cli.train | num. model params: 36646912 (num. trained: 36646912)
2024-07-10 17:12:44 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-10 17:12:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-10 17:12:44 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-10 17:12:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-10 17:12:44 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-10 17:12:44 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-10 17:12:45 | INFO | fairseq.trainer | loaded checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 1000 updates)
2024-07-10 17:12:45 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-10 17:12:45 | INFO | fairseq.data.data_utils | loaded 1732407 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.fr
2024-07-10 17:12:45 | INFO | fairseq.data.data_utils | loaded 1732407 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.de
2024-07-10 17:12:45 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de train fr-de 1732407 examples
2024-07-10 17:12:47 | INFO | fairseq.trainer | begin training epoch 1
2024-07-10 17:13:04 | INFO | train_inner | epoch 001:   1100 / 13004 loss=10.19, nll_loss=9.64, ppl=797.73, wps=19698.1, ups=5.02, wpb=3920.7, bsz=135.5, num_updates=1100, lr=0.0001375, gnorm=1.168, train_wall=17, wall=0
2024-07-10 17:13:19 | INFO | train_inner | epoch 001:   1200 / 13004 loss=10.08, nll_loss=9.51, ppl=728.97, wps=25556.8, ups=6.51, wpb=3927.8, bsz=139.8, num_updates=1200, lr=0.00015, gnorm=1.232, train_wall=15, wall=0
2024-07-10 17:13:35 | INFO | train_inner | epoch 001:   1300 / 13004 loss=9.967, nll_loss=9.376, ppl=664.32, wps=25699.9, ups=6.56, wpb=3916.3, bsz=138.2, num_updates=1300, lr=0.0001625, gnorm=1.198, train_wall=15, wall=0
2024-07-10 17:13:50 | INFO | train_inner | epoch 001:   1400 / 13004 loss=9.872, nll_loss=9.264, ppl=614.69, wps=25793.2, ups=6.56, wpb=3931.3, bsz=141.9, num_updates=1400, lr=0.000175, gnorm=1.145, train_wall=15, wall=0
2024-07-10 17:14:05 | INFO | train_inner | epoch 001:   1500 / 13004 loss=9.75, nll_loss=9.122, ppl=557.09, wps=25867, ups=6.61, wpb=3912.5, bsz=118.2, num_updates=1500, lr=0.0001875, gnorm=1.03, train_wall=15, wall=0
2024-07-10 17:14:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-10 17:14:06 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.727 | nll_loss 9.056 | ppl 532.33 | wps 95636.8 | wpb 3703.5 | bsz 124.5 | num_updates 1500 | best_loss 9.727
2024-07-10 17:14:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:14:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_1500.pt (epoch 1 @ 1500 updates, score 9.727) (writing took 5.267683499492705 seconds)
2024-07-10 17:14:27 | INFO | train_inner | epoch 001:   1600 / 13004 loss=9.659, nll_loss=9.014, ppl=517.02, wps=18131, ups=4.62, wpb=3923.7, bsz=133.8, num_updates=1600, lr=0.0002, gnorm=1.132, train_wall=15, wall=0
2024-07-10 17:14:42 | INFO | train_inner | epoch 001:   1700 / 13004 loss=9.55, nll_loss=8.887, ppl=473.32, wps=25607.5, ups=6.55, wpb=3911.7, bsz=137.4, num_updates=1700, lr=0.0002125, gnorm=1.062, train_wall=15, wall=0
2024-07-10 17:14:57 | INFO | train_inner | epoch 001:   1800 / 13004 loss=9.479, nll_loss=8.805, ppl=447.12, wps=25825.3, ups=6.6, wpb=3912, bsz=140.2, num_updates=1800, lr=0.000225, gnorm=1.072, train_wall=15, wall=0
2024-07-10 17:15:12 | INFO | train_inner | epoch 001:   1900 / 13004 loss=9.416, nll_loss=8.73, ppl=424.72, wps=25571.7, ups=6.53, wpb=3914.8, bsz=125.5, num_updates=1900, lr=0.0002375, gnorm=1.016, train_wall=15, wall=0
2024-07-10 17:15:27 | INFO | train_inner | epoch 001:   2000 / 13004 loss=9.305, nll_loss=8.603, ppl=388.89, wps=25899.6, ups=6.59, wpb=3927.5, bsz=129.7, num_updates=2000, lr=0.00025, gnorm=1.001, train_wall=15, wall=0
2024-07-10 17:15:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:15:29 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.367 | nll_loss 8.64 | ppl 399 | wps 97047.7 | wpb 3703.5 | bsz 124.5 | num_updates 2000 | best_loss 9.367
2024-07-10 17:15:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:15:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 9.367) (writing took 9.27162798307836 seconds)
2024-07-10 17:15:53 | INFO | train_inner | epoch 001:   2100 / 13004 loss=9.291, nll_loss=8.585, ppl=384.12, wps=15199.8, ups=3.9, wpb=3893.4, bsz=133.5, num_updates=2100, lr=0.0002625, gnorm=1.11, train_wall=15, wall=0
2024-07-10 17:16:08 | INFO | train_inner | epoch 001:   2200 / 13004 loss=9.162, nll_loss=8.438, ppl=346.7, wps=25811.9, ups=6.62, wpb=3901.3, bsz=117.8, num_updates=2200, lr=0.000275, gnorm=0.969, train_wall=15, wall=0
2024-07-10 17:16:23 | INFO | train_inner | epoch 001:   2300 / 13004 loss=9.053, nll_loss=8.313, ppl=318, wps=26353.9, ups=6.72, wpb=3919.1, bsz=129.4, num_updates=2300, lr=0.0002875, gnorm=0.968, train_wall=15, wall=0
2024-07-10 17:16:38 | INFO | train_inner | epoch 001:   2400 / 13004 loss=8.996, nll_loss=8.246, ppl=303.62, wps=25961, ups=6.61, wpb=3926.8, bsz=134.1, num_updates=2400, lr=0.0003, gnorm=0.973, train_wall=15, wall=0
2024-07-10 17:16:53 | INFO | train_inner | epoch 001:   2500 / 13004 loss=8.923, nll_loss=8.162, ppl=286.39, wps=25665, ups=6.54, wpb=3922.6, bsz=147.8, num_updates=2500, lr=0.0003125, gnorm=1.05, train_wall=15, wall=0
2024-07-10 17:16:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:16:55 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.038 | nll_loss 8.25 | ppl 304.43 | wps 97010.5 | wpb 3703.5 | bsz 124.5 | num_updates 2500 | best_loss 9.038
2024-07-10 17:16:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:16:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_2500.pt (epoch 1 @ 2500 updates, score 9.038) (writing took 4.591807051561773 seconds)
2024-07-10 17:17:14 | INFO | train_inner | epoch 001:   2600 / 13004 loss=8.831, nll_loss=8.056, ppl=266.16, wps=18991.3, ups=4.82, wpb=3941.6, bsz=151.7, num_updates=2600, lr=0.000325, gnorm=0.997, train_wall=15, wall=0
2024-07-10 17:17:29 | INFO | train_inner | epoch 001:   2700 / 13004 loss=8.772, nll_loss=7.988, ppl=253.92, wps=25778.8, ups=6.57, wpb=3923.6, bsz=127.9, num_updates=2700, lr=0.0003375, gnorm=0.94, train_wall=15, wall=0
2024-07-10 17:17:44 | INFO | train_inner | epoch 001:   2800 / 13004 loss=8.665, nll_loss=7.866, ppl=233.34, wps=26182.1, ups=6.7, wpb=3905.7, bsz=127.1, num_updates=2800, lr=0.00035, gnorm=0.947, train_wall=15, wall=0
2024-07-10 17:17:59 | INFO | train_inner | epoch 001:   2900 / 13004 loss=8.612, nll_loss=7.805, ppl=223.62, wps=25938.5, ups=6.66, wpb=3893.9, bsz=124.6, num_updates=2900, lr=0.0003625, gnorm=0.916, train_wall=15, wall=0
2024-07-10 17:18:14 | INFO | train_inner | epoch 001:   3000 / 13004 loss=8.536, nll_loss=7.717, ppl=210.45, wps=25818.8, ups=6.62, wpb=3899.8, bsz=128.8, num_updates=3000, lr=0.000375, gnorm=0.932, train_wall=15, wall=0
2024-07-10 17:18:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:18:16 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.728 | nll_loss 7.886 | ppl 236.62 | wps 97198.1 | wpb 3703.5 | bsz 124.5 | num_updates 3000 | best_loss 8.728
2024-07-10 17:18:16 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:18:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_3000.pt (epoch 1 @ 3000 updates, score 8.728) (writing took 4.389882704243064 seconds)
2024-07-10 17:18:35 | INFO | train_inner | epoch 001:   3100 / 13004 loss=8.486, nll_loss=7.659, ppl=202.11, wps=18950.9, ups=4.84, wpb=3915.3, bsz=128.2, num_updates=3100, lr=0.0003875, gnorm=0.945, train_wall=15, wall=0
2024-07-10 17:18:50 | INFO | train_inner | epoch 001:   3200 / 13004 loss=8.509, nll_loss=7.685, ppl=205.85, wps=25814, ups=6.58, wpb=3922, bsz=135.8, num_updates=3200, lr=0.0004, gnorm=0.995, train_wall=15, wall=0
2024-07-10 17:19:05 | INFO | train_inner | epoch 001:   3300 / 13004 loss=8.437, nll_loss=7.603, ppl=194.36, wps=26107.3, ups=6.67, wpb=3915.5, bsz=135.3, num_updates=3300, lr=0.0004125, gnorm=0.951, train_wall=15, wall=0
2024-07-10 17:19:21 | INFO | train_inner | epoch 001:   3400 / 13004 loss=8.304, nll_loss=7.451, ppl=174.93, wps=25363.5, ups=6.5, wpb=3900.1, bsz=116.6, num_updates=3400, lr=0.000425, gnorm=0.86, train_wall=15, wall=0
2024-07-10 17:19:36 | INFO | train_inner | epoch 001:   3500 / 13004 loss=8.306, nll_loss=7.452, ppl=175.06, wps=25313.3, ups=6.45, wpb=3926.9, bsz=139.1, num_updates=3500, lr=0.0004375, gnorm=0.904, train_wall=15, wall=0
2024-07-10 17:19:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:19:37 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.421 | nll_loss 7.521 | ppl 183.64 | wps 97106.1 | wpb 3703.5 | bsz 124.5 | num_updates 3500 | best_loss 8.421
2024-07-10 17:19:37 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:19:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_3500.pt (epoch 1 @ 3500 updates, score 8.421) (writing took 4.575020755641162 seconds)
2024-07-10 17:19:57 | INFO | train_inner | epoch 001:   3600 / 13004 loss=8.216, nll_loss=7.349, ppl=162.99, wps=18896.9, ups=4.83, wpb=3914.3, bsz=128.2, num_updates=3600, lr=0.00045, gnorm=0.851, train_wall=15, wall=0
2024-07-10 17:20:12 | INFO | train_inner | epoch 001:   3700 / 13004 loss=8.237, nll_loss=7.373, ppl=165.73, wps=26001.3, ups=6.63, wpb=3922.5, bsz=140.4, num_updates=3700, lr=0.0004625, gnorm=0.906, train_wall=15, wall=0
2024-07-10 17:20:27 | INFO | train_inner | epoch 001:   3800 / 13004 loss=8.127, nll_loss=7.246, ppl=151.84, wps=25982.6, ups=6.57, wpb=3952.1, bsz=162.6, num_updates=3800, lr=0.000475, gnorm=0.86, train_wall=15, wall=0
2024-07-10 17:20:42 | INFO | train_inner | epoch 001:   3900 / 13004 loss=8.129, nll_loss=7.248, ppl=152, wps=26095.9, ups=6.63, wpb=3933.4, bsz=153.6, num_updates=3900, lr=0.0004875, gnorm=0.889, train_wall=15, wall=0
2024-07-10 17:20:58 | INFO | train_inner | epoch 001:   4000 / 13004 loss=8.1, nll_loss=7.216, ppl=148.64, wps=25597.1, ups=6.5, wpb=3940.3, bsz=161.5, num_updates=4000, lr=0.0005, gnorm=0.851, train_wall=15, wall=0
2024-07-10 17:20:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:20:59 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.291 | nll_loss 7.364 | ppl 164.72 | wps 96185.2 | wpb 3703.5 | bsz 124.5 | num_updates 4000 | best_loss 8.291
2024-07-10 17:20:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:21:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 8.291) (writing took 4.8107844879850745 seconds)
2024-07-10 17:21:19 | INFO | train_inner | epoch 001:   4100 / 13004 loss=8.122, nll_loss=7.24, ppl=151.17, wps=18596.1, ups=4.75, wpb=3916.2, bsz=165.3, num_updates=4100, lr=0.000493865, gnorm=0.944, train_wall=15, wall=0
2024-07-10 17:21:34 | INFO | train_inner | epoch 001:   4200 / 13004 loss=8.089, nll_loss=7.202, ppl=147.27, wps=26120.2, ups=6.76, wpb=3865.7, bsz=106.3, num_updates=4200, lr=0.00048795, gnorm=0.812, train_wall=15, wall=0
2024-07-10 17:21:49 | INFO | train_inner | epoch 001:   4300 / 13004 loss=7.956, nll_loss=7.051, ppl=132.63, wps=25243.3, ups=6.41, wpb=3938.3, bsz=133.8, num_updates=4300, lr=0.000482243, gnorm=0.77, train_wall=15, wall=0
2024-07-10 17:22:04 | INFO | train_inner | epoch 001:   4400 / 13004 loss=7.946, nll_loss=7.039, ppl=131.54, wps=25614, ups=6.54, wpb=3915.6, bsz=123.3, num_updates=4400, lr=0.000476731, gnorm=0.789, train_wall=15, wall=0
2024-07-10 17:22:20 | INFO | train_inner | epoch 001:   4500 / 13004 loss=7.935, nll_loss=7.027, ppl=130.38, wps=25930.4, ups=6.6, wpb=3927.6, bsz=149.2, num_updates=4500, lr=0.000471405, gnorm=0.801, train_wall=15, wall=0
2024-07-10 17:22:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:22:21 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.158 | nll_loss 7.218 | ppl 148.92 | wps 94891.6 | wpb 3703.5 | bsz 124.5 | num_updates 4500 | best_loss 8.158
2024-07-10 17:22:21 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:22:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_4500.pt (epoch 1 @ 4500 updates, score 8.158) (writing took 4.723729588091373 seconds)
2024-07-10 17:22:40 | INFO | train_inner | epoch 001:   4600 / 13004 loss=7.891, nll_loss=6.976, ppl=125.89, wps=18716.9, ups=4.82, wpb=3880.8, bsz=125.1, num_updates=4600, lr=0.000466252, gnorm=0.777, train_wall=15, wall=0
2024-07-10 17:22:56 | INFO | train_inner | epoch 001:   4700 / 13004 loss=7.865, nll_loss=6.947, ppl=123.37, wps=25896.8, ups=6.59, wpb=3927.7, bsz=135, num_updates=4700, lr=0.000461266, gnorm=0.776, train_wall=15, wall=0
2024-07-10 17:23:10 | INFO | train_inner | epoch 001:   4800 / 13004 loss=7.844, nll_loss=6.922, ppl=121.28, wps=26203.4, ups=6.71, wpb=3903.9, bsz=129.8, num_updates=4800, lr=0.000456435, gnorm=0.782, train_wall=15, wall=0
2024-07-10 17:23:26 | INFO | train_inner | epoch 001:   4900 / 13004 loss=7.863, nll_loss=6.944, ppl=123.09, wps=25116, ups=6.44, wpb=3901.2, bsz=136.9, num_updates=4900, lr=0.000451754, gnorm=0.791, train_wall=15, wall=0
2024-07-10 17:23:41 | INFO | train_inner | epoch 001:   5000 / 13004 loss=7.822, nll_loss=6.897, ppl=119.19, wps=26082.4, ups=6.75, wpb=3865.3, bsz=121.9, num_updates=5000, lr=0.000447214, gnorm=0.788, train_wall=15, wall=0
2024-07-10 17:23:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:23:42 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.019 | nll_loss 7.06 | ppl 133.45 | wps 98006.2 | wpb 3703.5 | bsz 124.5 | num_updates 5000 | best_loss 8.019
2024-07-10 17:23:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:23:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_5000.pt (epoch 1 @ 5000 updates, score 8.019) (writing took 4.367122363299131 seconds)
2024-07-10 17:24:01 | INFO | train_inner | epoch 001:   5100 / 13004 loss=7.786, nll_loss=6.856, ppl=115.81, wps=19089.3, ups=4.88, wpb=3913.4, bsz=121.4, num_updates=5100, lr=0.000442807, gnorm=0.766, train_wall=15, wall=0
2024-07-10 17:24:17 | INFO | train_inner | epoch 001:   5200 / 13004 loss=7.738, nll_loss=6.801, ppl=111.49, wps=24844.8, ups=6.31, wpb=3938.5, bsz=142.2, num_updates=5200, lr=0.000438529, gnorm=0.783, train_wall=16, wall=0
2024-07-10 17:24:32 | INFO | train_inner | epoch 001:   5300 / 13004 loss=7.715, nll_loss=6.774, ppl=109.47, wps=26318, ups=6.66, wpb=3951.3, bsz=131, num_updates=5300, lr=0.000434372, gnorm=0.755, train_wall=15, wall=0
2024-07-10 17:24:48 | INFO | train_inner | epoch 001:   5400 / 13004 loss=7.709, nll_loss=6.768, ppl=108.97, wps=25326.6, ups=6.47, wpb=3911.6, bsz=135.2, num_updates=5400, lr=0.000430331, gnorm=0.755, train_wall=15, wall=0
2024-07-10 17:25:03 | INFO | train_inner | epoch 001:   5500 / 13004 loss=7.707, nll_loss=6.765, ppl=108.76, wps=25892.6, ups=6.61, wpb=3916.8, bsz=143.7, num_updates=5500, lr=0.000426401, gnorm=0.815, train_wall=15, wall=0
2024-07-10 17:25:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:25:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.891 | nll_loss 6.914 | ppl 120.6 | wps 93861.1 | wpb 3703.5 | bsz 124.5 | num_updates 5500 | best_loss 7.891
2024-07-10 17:25:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:25:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_5500.pt (epoch 1 @ 5500 updates, score 7.891) (writing took 5.585708797909319 seconds)
2024-07-10 17:25:25 | INFO | train_inner | epoch 001:   5600 / 13004 loss=7.627, nll_loss=6.674, ppl=102.13, wps=17876.9, ups=4.52, wpb=3955.9, bsz=135.8, num_updates=5600, lr=0.000422577, gnorm=0.75, train_wall=15, wall=0
2024-07-10 17:25:40 | INFO | train_inner | epoch 001:   5700 / 13004 loss=7.705, nll_loss=6.763, ppl=108.63, wps=25664.4, ups=6.5, wpb=3946.7, bsz=148.3, num_updates=5700, lr=0.000418854, gnorm=0.804, train_wall=15, wall=0
2024-07-10 17:25:56 | INFO | train_inner | epoch 001:   5800 / 13004 loss=7.639, nll_loss=6.687, ppl=103.02, wps=25390.8, ups=6.47, wpb=3924.6, bsz=133.7, num_updates=5800, lr=0.000415227, gnorm=0.768, train_wall=15, wall=0
2024-07-10 17:26:11 | INFO | train_inner | epoch 001:   5900 / 13004 loss=7.609, nll_loss=6.653, ppl=100.65, wps=25952.8, ups=6.61, wpb=3926.7, bsz=132.4, num_updates=5900, lr=0.000411693, gnorm=0.766, train_wall=15, wall=0
2024-07-10 17:26:26 | INFO | train_inner | epoch 001:   6000 / 13004 loss=7.639, nll_loss=6.687, ppl=103.02, wps=26003.5, ups=6.62, wpb=3929.1, bsz=146.7, num_updates=6000, lr=0.000408248, gnorm=0.79, train_wall=15, wall=0
2024-07-10 17:26:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:26:27 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.814 | nll_loss 6.818 | ppl 112.81 | wps 97203.9 | wpb 3703.5 | bsz 124.5 | num_updates 6000 | best_loss 7.814
2024-07-10 17:26:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:26:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 7.814) (writing took 4.4207593677565455 seconds)
2024-07-10 17:26:46 | INFO | train_inner | epoch 001:   6100 / 13004 loss=7.618, nll_loss=6.663, ppl=101.35, wps=19041.7, ups=4.91, wpb=3881, bsz=126.6, num_updates=6100, lr=0.000404888, gnorm=0.78, train_wall=15, wall=0
2024-07-10 17:27:01 | INFO | train_inner | epoch 001:   6200 / 13004 loss=7.556, nll_loss=6.593, ppl=96.53, wps=26027.8, ups=6.64, wpb=3921.2, bsz=137.4, num_updates=6200, lr=0.00040161, gnorm=0.764, train_wall=15, wall=0
2024-07-10 17:27:16 | INFO | train_inner | epoch 001:   6300 / 13004 loss=7.584, nll_loss=6.624, ppl=98.66, wps=26225.8, ups=6.72, wpb=3900.2, bsz=131.8, num_updates=6300, lr=0.00039841, gnorm=0.776, train_wall=15, wall=0
2024-07-10 17:27:31 | INFO | train_inner | epoch 001:   6400 / 13004 loss=7.551, nll_loss=6.587, ppl=96.17, wps=26169, ups=6.67, wpb=3922.8, bsz=125.4, num_updates=6400, lr=0.000395285, gnorm=0.752, train_wall=15, wall=0
2024-07-10 17:27:47 | INFO | train_inner | epoch 001:   6500 / 13004 loss=7.533, nll_loss=6.566, ppl=94.74, wps=24938.8, ups=6.35, wpb=3929.3, bsz=135.4, num_updates=6500, lr=0.000392232, gnorm=0.774, train_wall=16, wall=0
2024-07-10 17:27:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:27:48 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.793 | nll_loss 6.8 | ppl 111.44 | wps 96207.3 | wpb 3703.5 | bsz 124.5 | num_updates 6500 | best_loss 7.793
2024-07-10 17:27:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:27:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_6500.pt (epoch 1 @ 6500 updates, score 7.793) (writing took 4.439279501326382 seconds)
2024-07-10 17:28:08 | INFO | train_inner | epoch 001:   6600 / 13004 loss=7.5, nll_loss=6.529, ppl=92.33, wps=19041.1, ups=4.85, wpb=3929.4, bsz=126.2, num_updates=6600, lr=0.000389249, gnorm=0.731, train_wall=15, wall=0
2024-07-10 17:28:23 | INFO | train_inner | epoch 001:   6700 / 13004 loss=7.485, nll_loss=6.512, ppl=91.27, wps=26279.6, ups=6.7, wpb=3923, bsz=149.4, num_updates=6700, lr=0.000386334, gnorm=0.773, train_wall=15, wall=0
2024-07-10 17:28:38 | INFO | train_inner | epoch 001:   6800 / 13004 loss=7.515, nll_loss=6.546, ppl=93.43, wps=25887.1, ups=6.65, wpb=3892.3, bsz=107.2, num_updates=6800, lr=0.000383482, gnorm=0.75, train_wall=15, wall=0
2024-07-10 17:28:53 | INFO | train_inner | epoch 001:   6900 / 13004 loss=7.476, nll_loss=6.502, ppl=90.61, wps=25764.8, ups=6.57, wpb=3923.6, bsz=123.9, num_updates=6900, lr=0.000380693, gnorm=0.749, train_wall=15, wall=0
2024-07-10 17:29:08 | INFO | train_inner | epoch 001:   7000 / 13004 loss=7.505, nll_loss=6.533, ppl=92.62, wps=25795.7, ups=6.61, wpb=3901.5, bsz=118.6, num_updates=7000, lr=0.000377964, gnorm=0.77, train_wall=15, wall=0
2024-07-10 17:29:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:29:09 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.73 | nll_loss 6.722 | ppl 105.55 | wps 90576.8 | wpb 3703.5 | bsz 124.5 | num_updates 7000 | best_loss 7.73
2024-07-10 17:29:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:29:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_7000.pt (epoch 1 @ 7000 updates, score 7.73) (writing took 4.4950754744932055 seconds)
2024-07-10 17:29:29 | INFO | train_inner | epoch 001:   7100 / 13004 loss=7.477, nll_loss=6.503, ppl=90.67, wps=18965, ups=4.85, wpb=3910.3, bsz=153.9, num_updates=7100, lr=0.000375293, gnorm=0.792, train_wall=15, wall=0
2024-07-10 17:29:44 | INFO | train_inner | epoch 001:   7200 / 13004 loss=7.471, nll_loss=6.496, ppl=90.24, wps=24958.2, ups=6.43, wpb=3881.5, bsz=119.3, num_updates=7200, lr=0.000372678, gnorm=0.763, train_wall=15, wall=0
2024-07-10 17:29:59 | INFO | train_inner | epoch 001:   7300 / 13004 loss=7.424, nll_loss=6.442, ppl=86.95, wps=26142.9, ups=6.64, wpb=3937.1, bsz=151.8, num_updates=7300, lr=0.000370117, gnorm=0.777, train_wall=15, wall=0
2024-07-10 17:30:15 | INFO | train_inner | epoch 001:   7400 / 13004 loss=7.473, nll_loss=6.497, ppl=90.31, wps=24923.1, ups=6.39, wpb=3899, bsz=116.2, num_updates=7400, lr=0.000367607, gnorm=0.76, train_wall=15, wall=0
2024-07-10 17:30:30 | INFO | train_inner | epoch 001:   7500 / 13004 loss=7.474, nll_loss=6.498, ppl=90.4, wps=26045.1, ups=6.71, wpb=3879.3, bsz=115, num_updates=7500, lr=0.000365148, gnorm=0.768, train_wall=15, wall=0
2024-07-10 17:30:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:30:31 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.666 | nll_loss 6.653 | ppl 100.62 | wps 96091.8 | wpb 3703.5 | bsz 124.5 | num_updates 7500 | best_loss 7.666
2024-07-10 17:30:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:30:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_7500.pt (epoch 1 @ 7500 updates, score 7.666) (writing took 5.964466784149408 seconds)
2024-07-10 17:30:52 | INFO | train_inner | epoch 001:   7600 / 13004 loss=7.505, nll_loss=6.535, ppl=92.74, wps=17265.1, ups=4.4, wpb=3926.7, bsz=165.5, num_updates=7600, lr=0.000362738, gnorm=0.865, train_wall=15, wall=0
2024-07-10 17:31:08 | INFO | train_inner | epoch 001:   7700 / 13004 loss=7.385, nll_loss=6.398, ppl=84.31, wps=25953.9, ups=6.62, wpb=3922.4, bsz=125.2, num_updates=7700, lr=0.000360375, gnorm=0.735, train_wall=15, wall=0
2024-07-10 17:31:23 | INFO | train_inner | epoch 001:   7800 / 13004 loss=7.37, nll_loss=6.38, ppl=83.27, wps=26050.7, ups=6.6, wpb=3946.5, bsz=140.2, num_updates=7800, lr=0.000358057, gnorm=0.757, train_wall=15, wall=0
2024-07-10 17:31:38 | INFO | train_inner | epoch 001:   7900 / 13004 loss=7.397, nll_loss=6.41, ppl=85.05, wps=25907.7, ups=6.6, wpb=3925.8, bsz=123.6, num_updates=7900, lr=0.000355784, gnorm=0.747, train_wall=15, wall=0
2024-07-10 17:31:53 | INFO | train_inner | epoch 001:   8000 / 13004 loss=7.403, nll_loss=6.417, ppl=85.48, wps=25636.7, ups=6.53, wpb=3926, bsz=141, num_updates=8000, lr=0.000353553, gnorm=0.798, train_wall=15, wall=0
2024-07-10 17:31:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:31:54 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.631 | nll_loss 6.61 | ppl 97.7 | wps 97058.3 | wpb 3703.5 | bsz 124.5 | num_updates 8000 | best_loss 7.631
2024-07-10 17:31:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:32:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 7.631) (writing took 5.611957464367151 seconds)
2024-07-10 17:32:15 | INFO | train_inner | epoch 001:   8100 / 13004 loss=7.324, nll_loss=6.327, ppl=80.3, wps=17991, ups=4.55, wpb=3950, bsz=150.6, num_updates=8100, lr=0.000351364, gnorm=0.745, train_wall=15, wall=0
2024-07-10 17:32:30 | INFO | train_inner | epoch 001:   8200 / 13004 loss=7.371, nll_loss=6.381, ppl=83.33, wps=25867.8, ups=6.6, wpb=3920.9, bsz=125.8, num_updates=8200, lr=0.000349215, gnorm=0.752, train_wall=15, wall=0
2024-07-10 17:32:45 | INFO | train_inner | epoch 001:   8300 / 13004 loss=7.376, nll_loss=6.385, ppl=83.6, wps=26146.3, ups=6.68, wpb=3913.1, bsz=126.5, num_updates=8300, lr=0.000347105, gnorm=0.775, train_wall=15, wall=0
2024-07-10 17:33:01 | INFO | train_inner | epoch 001:   8400 / 13004 loss=7.314, nll_loss=6.315, ppl=79.63, wps=25616.8, ups=6.53, wpb=3920.1, bsz=132.6, num_updates=8400, lr=0.000345033, gnorm=0.749, train_wall=15, wall=0
2024-07-10 17:33:16 | INFO | train_inner | epoch 001:   8500 / 13004 loss=7.354, nll_loss=6.361, ppl=82.18, wps=25804.2, ups=6.64, wpb=3886.2, bsz=116.3, num_updates=8500, lr=0.000342997, gnorm=0.763, train_wall=15, wall=0
2024-07-10 17:33:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:33:17 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.594 | nll_loss 6.568 | ppl 94.9 | wps 98174.6 | wpb 3703.5 | bsz 124.5 | num_updates 8500 | best_loss 7.594
2024-07-10 17:33:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:33:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_8500.pt (epoch 1 @ 8500 updates, score 7.594) (writing took 4.490456108003855 seconds)
2024-07-10 17:33:36 | INFO | train_inner | epoch 001:   8600 / 13004 loss=7.325, nll_loss=6.327, ppl=80.3, wps=18829, ups=4.82, wpb=3902.4, bsz=115.8, num_updates=8600, lr=0.000340997, gnorm=0.756, train_wall=15, wall=0
2024-07-10 17:33:51 | INFO | train_inner | epoch 001:   8700 / 13004 loss=7.28, nll_loss=6.276, ppl=77.52, wps=26198.1, ups=6.64, wpb=3944.6, bsz=142.4, num_updates=8700, lr=0.000339032, gnorm=0.759, train_wall=15, wall=0
2024-07-10 17:34:06 | INFO | train_inner | epoch 001:   8800 / 13004 loss=7.322, nll_loss=6.324, ppl=80.09, wps=26335.1, ups=6.73, wpb=3913.9, bsz=130.9, num_updates=8800, lr=0.0003371, gnorm=0.78, train_wall=15, wall=0
2024-07-10 17:34:21 | INFO | train_inner | epoch 001:   8900 / 13004 loss=7.298, nll_loss=6.296, ppl=78.6, wps=26202.6, ups=6.62, wpb=3955.7, bsz=128.6, num_updates=8900, lr=0.000335201, gnorm=0.748, train_wall=15, wall=0
2024-07-10 17:34:36 | INFO | train_inner | epoch 001:   9000 / 13004 loss=7.272, nll_loss=6.267, ppl=77.03, wps=25933.1, ups=6.62, wpb=3919.6, bsz=144.9, num_updates=9000, lr=0.000333333, gnorm=0.785, train_wall=15, wall=0
2024-07-10 17:34:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:34:38 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.564 | nll_loss 6.53 | ppl 92.4 | wps 97467.6 | wpb 3703.5 | bsz 124.5 | num_updates 9000 | best_loss 7.564
2024-07-10 17:34:38 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:34:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_9000.pt (epoch 1 @ 9000 updates, score 7.564) (writing took 4.745312439277768 seconds)
2024-07-10 17:34:57 | INFO | train_inner | epoch 001:   9100 / 13004 loss=7.327, nll_loss=6.329, ppl=80.41, wps=18687, ups=4.79, wpb=3897.4, bsz=115.3, num_updates=9100, lr=0.000331497, gnorm=0.761, train_wall=15, wall=0
2024-07-10 17:35:12 | INFO | train_inner | epoch 001:   9200 / 13004 loss=7.317, nll_loss=6.319, ppl=79.84, wps=26280.4, ups=6.7, wpb=3919.9, bsz=136.8, num_updates=9200, lr=0.00032969, gnorm=0.788, train_wall=15, wall=0
2024-07-10 17:35:27 | INFO | train_inner | epoch 001:   9300 / 13004 loss=7.354, nll_loss=6.361, ppl=82.21, wps=26186.8, ups=6.66, wpb=3929.8, bsz=146.8, num_updates=9300, lr=0.000327913, gnorm=0.816, train_wall=15, wall=0
2024-07-10 17:35:42 | INFO | train_inner | epoch 001:   9400 / 13004 loss=7.267, nll_loss=6.262, ppl=76.74, wps=26208.6, ups=6.66, wpb=3935.4, bsz=138.5, num_updates=9400, lr=0.000326164, gnorm=0.772, train_wall=15, wall=0
2024-07-10 17:35:58 | INFO | train_inner | epoch 001:   9500 / 13004 loss=7.268, nll_loss=6.262, ppl=76.75, wps=25542.2, ups=6.55, wpb=3896.8, bsz=121.7, num_updates=9500, lr=0.000324443, gnorm=0.759, train_wall=15, wall=0
2024-07-10 17:35:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:35:59 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.537 | nll_loss 6.501 | ppl 90.55 | wps 96431.4 | wpb 3703.5 | bsz 124.5 | num_updates 9500 | best_loss 7.537
2024-07-10 17:35:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:36:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_9500.pt (epoch 1 @ 9500 updates, score 7.537) (writing took 4.420793001540005 seconds)
2024-07-10 17:36:18 | INFO | train_inner | epoch 001:   9600 / 13004 loss=7.245, nll_loss=6.236, ppl=75.4, wps=18775.2, ups=4.79, wpb=3920.2, bsz=122.2, num_updates=9600, lr=0.000322749, gnorm=0.763, train_wall=15, wall=0
2024-07-10 17:36:33 | INFO | train_inner | epoch 001:   9700 / 13004 loss=7.227, nll_loss=6.217, ppl=74.38, wps=26139, ups=6.64, wpb=3936.1, bsz=147, num_updates=9700, lr=0.000321081, gnorm=0.771, train_wall=15, wall=0
2024-07-10 17:36:48 | INFO | train_inner | epoch 001:   9800 / 13004 loss=7.205, nll_loss=6.189, ppl=72.98, wps=26358.6, ups=6.7, wpb=3933.1, bsz=121, num_updates=9800, lr=0.000319438, gnorm=0.754, train_wall=15, wall=0
2024-07-10 17:37:04 | INFO | train_inner | epoch 001:   9900 / 13004 loss=7.227, nll_loss=6.216, ppl=74.35, wps=25882, ups=6.56, wpb=3947.5, bsz=134.9, num_updates=9900, lr=0.000317821, gnorm=0.755, train_wall=15, wall=0
2024-07-10 17:37:19 | INFO | train_inner | epoch 001:  10000 / 13004 loss=7.23, nll_loss=6.218, ppl=74.43, wps=26004, ups=6.64, wpb=3914.1, bsz=119, num_updates=10000, lr=0.000316228, gnorm=0.767, train_wall=15, wall=0
2024-07-10 17:37:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:37:20 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.517 | nll_loss 6.482 | ppl 89.37 | wps 95278.5 | wpb 3703.5 | bsz 124.5 | num_updates 10000 | best_loss 7.517
2024-07-10 17:37:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:37:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score 7.517) (writing took 4.390318447723985 seconds)
2024-07-10 17:37:24 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-10 17:37:24 | INFO | train | epoch 001 | loss 8.324 | nll_loss 7.479 | ppl 178.46 | wps 23309.5 | ups 5.95 | wpb 3919.5 | bsz 133.7 | num_updates 10000 | lr 0.000316228 | gnorm 0.888 | train_wall 1506 | wall 0
2024-07-10 17:37:24 | INFO | fairseq_cli.train | done training in 1477.1 seconds
2024-07-10 17:37:29 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt22.sep.tokenized.fr-de', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=100000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=1000, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-10 17:37:29 | INFO | fairseq.tasks.translation | [fr] dictionary: 8 types
2024-07-10 17:37:29 | INFO | fairseq.tasks.translation | [de] dictionary: 9960 types
2024-07-10 17:37:29 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.fr
2024-07-10 17:37:29 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.de
2024-07-10 17:37:29 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de valid fr-de 3238 examples
2024-07-10 17:37:30 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9960, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=9960, bias=False)
  )
)
2024-07-10 17:37:30 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-10 17:37:30 | INFO | fairseq_cli.train | model: transformer_iwslt_de_en (TransformerModel)
2024-07-10 17:37:30 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-10 17:37:30 | INFO | fairseq_cli.train | num. model params: 36646912 (num. trained: 36646912)
2024-07-10 17:37:40 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-10 17:37:40 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-10 17:37:40 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-10 17:37:40 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-10 17:37:40 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-10 17:37:40 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-10 17:37:42 | INFO | fairseq.trainer | loaded checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 10000 updates)
2024-07-10 17:37:42 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-10 17:37:42 | INFO | fairseq.data.data_utils | loaded 1732407 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.fr
2024-07-10 17:37:42 | INFO | fairseq.data.data_utils | loaded 1732407 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.de
2024-07-10 17:37:42 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de train fr-de 1732407 examples
2024-07-10 17:37:44 | INFO | fairseq.trainer | begin training epoch 1
2024-07-10 17:38:00 | INFO | train_inner | epoch 001:  10100 / 13004 loss=7.238, nll_loss=6.228, ppl=74.97, wps=20031.4, ups=5.07, wpb=3948.8, bsz=143.4, num_updates=10100, lr=0.000314658, gnorm=0.785, train_wall=16, wall=0
2024-07-10 17:38:15 | INFO | train_inner | epoch 001:  10200 / 13004 loss=7.233, nll_loss=6.222, ppl=74.66, wps=25877.9, ups=6.64, wpb=3894.7, bsz=115, num_updates=10200, lr=0.000313112, gnorm=0.761, train_wall=15, wall=0
2024-07-10 17:38:31 | INFO | train_inner | epoch 001:  10300 / 13004 loss=7.202, nll_loss=6.187, ppl=72.87, wps=25564.1, ups=6.51, wpb=3929.8, bsz=138.2, num_updates=10300, lr=0.000311588, gnorm=0.769, train_wall=15, wall=0
2024-07-10 17:38:46 | INFO | train_inner | epoch 001:  10400 / 13004 loss=7.213, nll_loss=6.2, ppl=73.53, wps=25637.4, ups=6.55, wpb=3912.5, bsz=124.9, num_updates=10400, lr=0.000310087, gnorm=0.768, train_wall=15, wall=0
2024-07-10 17:39:01 | INFO | train_inner | epoch 001:  10500 / 13004 loss=7.268, nll_loss=6.262, ppl=76.74, wps=25732.3, ups=6.64, wpb=3872.5, bsz=136.8, num_updates=10500, lr=0.000308607, gnorm=0.816, train_wall=15, wall=0
2024-07-10 17:39:16 | INFO | train_inner | epoch 001:  10600 / 13004 loss=7.216, nll_loss=6.203, ppl=73.67, wps=25747.7, ups=6.58, wpb=3911.8, bsz=125.2, num_updates=10600, lr=0.000307148, gnorm=0.763, train_wall=15, wall=0
2024-07-10 17:39:32 | INFO | train_inner | epoch 001:  10700 / 13004 loss=7.166, nll_loss=6.146, ppl=70.79, wps=25784.9, ups=6.55, wpb=3937.4, bsz=125.3, num_updates=10700, lr=0.000305709, gnorm=0.76, train_wall=15, wall=0
2024-07-10 17:39:47 | INFO | train_inner | epoch 001:  10800 / 13004 loss=7.215, nll_loss=6.202, ppl=73.61, wps=25775.7, ups=6.59, wpb=3910.5, bsz=121.4, num_updates=10800, lr=0.00030429, gnorm=0.771, train_wall=15, wall=0
2024-07-10 17:40:02 | INFO | train_inner | epoch 001:  10900 / 13004 loss=7.179, nll_loss=6.16, ppl=71.51, wps=25687.4, ups=6.57, wpb=3911, bsz=121.4, num_updates=10900, lr=0.000302891, gnorm=0.771, train_wall=15, wall=0
2024-07-10 17:40:17 | INFO | train_inner | epoch 001:  11000 / 13004 loss=7.26, nll_loss=6.253, ppl=76.28, wps=25778.1, ups=6.61, wpb=3897.7, bsz=128.2, num_updates=11000, lr=0.000301511, gnorm=0.816, train_wall=15, wall=0
2024-07-10 17:40:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-10 17:40:18 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.486 | nll_loss 6.441 | ppl 86.9 | wps 94690.4 | wpb 3703.5 | bsz 124.5 | num_updates 11000 | best_loss 7.486
2024-07-10 17:40:18 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:40:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_11000.pt (epoch 1 @ 11000 updates, score 7.486) (writing took 5.111269968561828 seconds)
2024-07-10 17:40:39 | INFO | train_inner | epoch 001:  11100 / 13004 loss=7.149, nll_loss=6.126, ppl=69.86, wps=17858.7, ups=4.55, wpb=3922.6, bsz=126.9, num_updates=11100, lr=0.00030015, gnorm=0.766, train_wall=16, wall=0
2024-07-10 17:40:55 | INFO | train_inner | epoch 001:  11200 / 13004 loss=7.16, nll_loss=6.139, ppl=70.45, wps=25565.8, ups=6.49, wpb=3939.5, bsz=121.2, num_updates=11200, lr=0.000298807, gnorm=0.761, train_wall=15, wall=0
2024-07-10 17:41:10 | INFO | train_inner | epoch 001:  11300 / 13004 loss=7.162, nll_loss=6.142, ppl=70.62, wps=25328.4, ups=6.42, wpb=3944.5, bsz=142.7, num_updates=11300, lr=0.000297482, gnorm=0.769, train_wall=15, wall=0
2024-07-10 17:41:25 | INFO | train_inner | epoch 001:  11400 / 13004 loss=7.114, nll_loss=6.088, ppl=68.01, wps=25654.4, ups=6.49, wpb=3955.2, bsz=149.3, num_updates=11400, lr=0.000296174, gnorm=0.766, train_wall=15, wall=0
2024-07-10 17:41:41 | INFO | train_inner | epoch 001:  11500 / 13004 loss=7.11, nll_loss=6.083, ppl=67.77, wps=25709.2, ups=6.52, wpb=3945.6, bsz=131.4, num_updates=11500, lr=0.000294884, gnorm=0.75, train_wall=15, wall=0
2024-07-10 17:41:56 | INFO | train_inner | epoch 001:  11600 / 13004 loss=7.206, nll_loss=6.192, ppl=73.11, wps=25979.6, ups=6.62, wpb=3923.8, bsz=146.7, num_updates=11600, lr=0.00029361, gnorm=0.827, train_wall=15, wall=0
2024-07-10 17:42:12 | INFO | train_inner | epoch 001:  11700 / 13004 loss=7.153, nll_loss=6.132, ppl=70.11, wps=24856.8, ups=6.31, wpb=3937.8, bsz=133.8, num_updates=11700, lr=0.000292353, gnorm=0.758, train_wall=16, wall=0
2024-07-10 17:42:27 | INFO | train_inner | epoch 001:  11800 / 13004 loss=7.137, nll_loss=6.113, ppl=69.22, wps=25684.5, ups=6.61, wpb=3885.5, bsz=119.4, num_updates=11800, lr=0.000291111, gnorm=0.775, train_wall=15, wall=0
2024-07-10 17:42:43 | INFO | train_inner | epoch 001:  11900 / 13004 loss=7.126, nll_loss=6.099, ppl=68.57, wps=25054.6, ups=6.39, wpb=3921.4, bsz=131, num_updates=11900, lr=0.000289886, gnorm=0.773, train_wall=15, wall=0
2024-07-10 17:42:58 | INFO | train_inner | epoch 001:  12000 / 13004 loss=7.171, nll_loss=6.152, ppl=71.11, wps=25629.6, ups=6.53, wpb=3924.7, bsz=142.2, num_updates=12000, lr=0.000288675, gnorm=0.822, train_wall=15, wall=0
2024-07-10 17:42:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:42:59 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.424 | nll_loss 6.374 | ppl 82.93 | wps 97755.6 | wpb 3703.5 | bsz 124.5 | num_updates 12000 | best_loss 7.424
2024-07-10 17:42:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:43:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_12000.pt (epoch 1 @ 12000 updates, score 7.424) (writing took 4.6278386591002345 seconds)
2024-07-10 17:43:19 | INFO | train_inner | epoch 001:  12100 / 13004 loss=7.126, nll_loss=6.101, ppl=68.63, wps=18584.9, ups=4.73, wpb=3926.5, bsz=125.2, num_updates=12100, lr=0.00028748, gnorm=0.771, train_wall=15, wall=0
2024-07-10 17:43:34 | INFO | train_inner | epoch 001:  12200 / 13004 loss=7.154, nll_loss=6.132, ppl=70.11, wps=25901.7, ups=6.68, wpb=3878.4, bsz=120.6, num_updates=12200, lr=0.000286299, gnorm=0.778, train_wall=15, wall=0
2024-07-10 17:43:49 | INFO | train_inner | epoch 001:  12300 / 13004 loss=7.108, nll_loss=6.079, ppl=67.58, wps=25632.1, ups=6.55, wpb=3914.9, bsz=128.2, num_updates=12300, lr=0.000285133, gnorm=0.78, train_wall=15, wall=0
2024-07-10 17:44:05 | INFO | train_inner | epoch 001:  12400 / 13004 loss=7.161, nll_loss=6.14, ppl=70.53, wps=25108.6, ups=6.43, wpb=3907.3, bsz=121.8, num_updates=12400, lr=0.000283981, gnorm=0.793, train_wall=15, wall=0
2024-07-10 17:44:20 | INFO | train_inner | epoch 001:  12500 / 13004 loss=7.126, nll_loss=6.101, ppl=68.65, wps=25350.8, ups=6.44, wpb=3935.7, bsz=146.3, num_updates=12500, lr=0.000282843, gnorm=0.796, train_wall=15, wall=0
2024-07-10 17:44:36 | INFO | train_inner | epoch 001:  12600 / 13004 loss=7.095, nll_loss=6.066, ppl=66.97, wps=25713.4, ups=6.51, wpb=3948.5, bsz=136.6, num_updates=12600, lr=0.000281718, gnorm=0.766, train_wall=15, wall=0
2024-07-10 17:44:51 | INFO | train_inner | epoch 001:  12700 / 13004 loss=7.121, nll_loss=6.095, ppl=68.35, wps=25705.1, ups=6.54, wpb=3930.9, bsz=141, num_updates=12700, lr=0.000280607, gnorm=0.781, train_wall=15, wall=0
2024-07-10 17:45:06 | INFO | train_inner | epoch 001:  12800 / 13004 loss=7.108, nll_loss=6.08, ppl=67.63, wps=25673.2, ups=6.55, wpb=3917.6, bsz=135.8, num_updates=12800, lr=0.000279508, gnorm=0.777, train_wall=15, wall=0
2024-07-10 17:45:22 | INFO | train_inner | epoch 001:  12900 / 13004 loss=7.127, nll_loss=6.101, ppl=68.64, wps=25050, ups=6.4, wpb=3916.9, bsz=134.6, num_updates=12900, lr=0.000278423, gnorm=0.798, train_wall=15, wall=0
2024-07-10 17:45:37 | INFO | train_inner | epoch 001:  13000 / 13004 loss=7.122, nll_loss=6.095, ppl=68.37, wps=25429.7, ups=6.5, wpb=3910.5, bsz=133.1, num_updates=13000, lr=0.00027735, gnorm=0.803, train_wall=15, wall=0
2024-07-10 17:45:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:45:38 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.373 | nll_loss 6.31 | ppl 79.31 | wps 95112.5 | wpb 3703.5 | bsz 124.5 | num_updates 13000 | best_loss 7.373
2024-07-10 17:45:38 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:45:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_13000.pt (epoch 1 @ 13000 updates, score 7.373) (writing took 4.848970658145845 seconds)
2024-07-10 17:45:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:45:45 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.365 | nll_loss 6.303 | ppl 78.96 | wps 96830.4 | wpb 3703.5 | bsz 124.5 | num_updates 13004 | best_loss 7.365
2024-07-10 17:45:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:45:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_best.pt (epoch 1 @ 13004 updates, score 7.365) (writing took 4.054802116937935 seconds)
2024-07-10 17:45:49 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-10 17:45:49 | INFO | train | epoch 001 | loss 8.056 | nll_loss 7.171 | ppl 144.08 | wps 23550.7 | ups 6.01 | wpb 3919.8 | bsz 133.2 | num_updates 13004 | lr 0.000277307 | gnorm 0.863 | train_wall 1963 | wall 0
2024-07-10 17:45:49 | INFO | fairseq.trainer | begin training epoch 2
2024-07-10 17:46:04 | INFO | train_inner | epoch 002:     96 / 13004 loss=7.051, nll_loss=6.015, ppl=64.67, wps=14753.7, ups=3.74, wpb=3941.8, bsz=143, num_updates=13100, lr=0.000276289, gnorm=0.788, train_wall=15, wall=0
2024-07-10 17:46:19 | INFO | train_inner | epoch 002:    196 / 13004 loss=7.069, nll_loss=6.035, ppl=65.57, wps=25568.7, ups=6.51, wpb=3930.2, bsz=129.6, num_updates=13200, lr=0.000275241, gnorm=0.787, train_wall=15, wall=0
2024-07-10 17:46:35 | INFO | train_inner | epoch 002:    296 / 13004 loss=7.09, nll_loss=6.058, ppl=66.62, wps=25579.9, ups=6.55, wpb=3902.8, bsz=129.3, num_updates=13300, lr=0.000274204, gnorm=0.819, train_wall=15, wall=0
2024-07-10 17:46:50 | INFO | train_inner | epoch 002:    396 / 13004 loss=7.039, nll_loss=6, ppl=63.99, wps=25345.5, ups=6.43, wpb=3942.2, bsz=131.4, num_updates=13400, lr=0.000273179, gnorm=0.76, train_wall=15, wall=0
2024-07-10 17:47:05 | INFO | train_inner | epoch 002:    496 / 13004 loss=7.069, nll_loss=6.034, ppl=65.51, wps=25527.9, ups=6.54, wpb=3904.6, bsz=128.3, num_updates=13500, lr=0.000272166, gnorm=0.802, train_wall=15, wall=0
2024-07-10 17:47:21 | INFO | train_inner | epoch 002:    596 / 13004 loss=7.08, nll_loss=6.047, ppl=66.12, wps=25315.4, ups=6.46, wpb=3919.9, bsz=126.4, num_updates=13600, lr=0.000271163, gnorm=0.791, train_wall=15, wall=0
2024-07-10 17:47:36 | INFO | train_inner | epoch 002:    696 / 13004 loss=7.082, nll_loss=6.05, ppl=66.24, wps=25344.5, ups=6.48, wpb=3912.4, bsz=136.4, num_updates=13700, lr=0.000270172, gnorm=0.803, train_wall=15, wall=0
2024-07-10 17:47:52 | INFO | train_inner | epoch 002:    796 / 13004 loss=7.059, nll_loss=6.024, ppl=65.06, wps=25578.3, ups=6.55, wpb=3903, bsz=128.3, num_updates=13800, lr=0.000269191, gnorm=0.792, train_wall=15, wall=0
2024-07-10 17:48:07 | INFO | train_inner | epoch 002:    896 / 13004 loss=7.046, nll_loss=6.008, ppl=64.37, wps=25173.6, ups=6.44, wpb=3908.8, bsz=131.6, num_updates=13900, lr=0.000268221, gnorm=0.78, train_wall=15, wall=0
2024-07-10 17:48:22 | INFO | train_inner | epoch 002:    996 / 13004 loss=7.051, nll_loss=6.014, ppl=64.61, wps=25971.5, ups=6.59, wpb=3943.8, bsz=147, num_updates=14000, lr=0.000267261, gnorm=0.785, train_wall=15, wall=0
2024-07-10 17:48:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:48:24 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.353 | nll_loss 6.289 | ppl 78.17 | wps 96005.9 | wpb 3703.5 | bsz 124.5 | num_updates 14000 | best_loss 7.353
2024-07-10 17:48:24 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:48:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_14000.pt (epoch 2 @ 14000 updates, score 7.353) (writing took 4.769849237054586 seconds)
2024-07-10 17:48:44 | INFO | train_inner | epoch 002:   1096 / 13004 loss=7.069, nll_loss=6.034, ppl=65.51, wps=18059.9, ups=4.65, wpb=3885.5, bsz=127.3, num_updates=14100, lr=0.000266312, gnorm=0.809, train_wall=15, wall=0
2024-07-10 17:49:00 | INFO | train_inner | epoch 002:   1196 / 13004 loss=7.048, nll_loss=6.01, ppl=64.46, wps=24665.6, ups=6.28, wpb=3929.2, bsz=129.8, num_updates=14200, lr=0.000265372, gnorm=0.786, train_wall=16, wall=0
2024-07-10 17:49:15 | INFO | train_inner | epoch 002:   1296 / 13004 loss=7.118, nll_loss=6.091, ppl=68.18, wps=25469.9, ups=6.53, wpb=3899, bsz=147.1, num_updates=14300, lr=0.000264443, gnorm=0.876, train_wall=15, wall=0
2024-07-10 17:49:30 | INFO | train_inner | epoch 002:   1396 / 13004 loss=7.041, nll_loss=6.002, ppl=64.1, wps=25681.5, ups=6.55, wpb=3920.8, bsz=125.5, num_updates=14400, lr=0.000263523, gnorm=0.776, train_wall=15, wall=0
2024-07-10 17:49:46 | INFO | train_inner | epoch 002:   1496 / 13004 loss=7.045, nll_loss=6.007, ppl=64.32, wps=25766.5, ups=6.59, wpb=3907.9, bsz=116.7, num_updates=14500, lr=0.000262613, gnorm=0.782, train_wall=15, wall=0
2024-07-10 17:50:01 | INFO | train_inner | epoch 002:   1596 / 13004 loss=7.022, nll_loss=5.981, ppl=63.16, wps=25628.6, ups=6.53, wpb=3926.6, bsz=143.5, num_updates=14600, lr=0.000261712, gnorm=0.783, train_wall=15, wall=0
2024-07-10 17:50:16 | INFO | train_inner | epoch 002:   1696 / 13004 loss=7.024, nll_loss=5.982, ppl=63.21, wps=24967.3, ups=6.42, wpb=3887.1, bsz=116.6, num_updates=14700, lr=0.00026082, gnorm=0.787, train_wall=15, wall=0
2024-07-10 17:50:32 | INFO | train_inner | epoch 002:   1796 / 13004 loss=7.019, nll_loss=5.977, ppl=62.98, wps=25414.5, ups=6.45, wpb=3937.7, bsz=136.4, num_updates=14800, lr=0.000259938, gnorm=0.783, train_wall=15, wall=0
2024-07-10 17:50:47 | INFO | train_inner | epoch 002:   1896 / 13004 loss=7.022, nll_loss=5.98, ppl=63.13, wps=25818.7, ups=6.56, wpb=3935.3, bsz=119.6, num_updates=14900, lr=0.000259064, gnorm=0.78, train_wall=15, wall=0
2024-07-10 17:51:03 | INFO | train_inner | epoch 002:   1996 / 13004 loss=7.007, nll_loss=5.963, ppl=62.38, wps=24614.5, ups=6.25, wpb=3941.4, bsz=133.3, num_updates=15000, lr=0.000258199, gnorm=0.785, train_wall=16, wall=0
2024-07-10 17:51:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:51:04 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.337 | nll_loss 6.273 | ppl 77.31 | wps 96744 | wpb 3703.5 | bsz 124.5 | num_updates 15000 | best_loss 7.337
2024-07-10 17:51:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:51:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_15000.pt (epoch 2 @ 15000 updates, score 7.337) (writing took 4.548878451809287 seconds)
2024-07-10 17:51:24 | INFO | train_inner | epoch 002:   2096 / 13004 loss=7.028, nll_loss=5.988, ppl=63.47, wps=18582.7, ups=4.75, wpb=3912.2, bsz=130.5, num_updates=15100, lr=0.000257343, gnorm=0.797, train_wall=15, wall=0
2024-07-10 17:51:40 | INFO | train_inner | epoch 002:   2196 / 13004 loss=7.071, nll_loss=6.037, ppl=65.64, wps=25430.7, ups=6.44, wpb=3947.8, bsz=156.2, num_updates=15200, lr=0.000256495, gnorm=0.835, train_wall=15, wall=0
2024-07-10 17:51:55 | INFO | train_inner | epoch 002:   2296 / 13004 loss=6.959, nll_loss=5.909, ppl=60.07, wps=25692.5, ups=6.58, wpb=3902.8, bsz=125.7, num_updates=15300, lr=0.000255655, gnorm=0.78, train_wall=15, wall=0
2024-07-10 17:52:11 | INFO | train_inner | epoch 002:   2396 / 13004 loss=7, nll_loss=5.956, ppl=62.09, wps=24877.3, ups=6.39, wpb=3890.2, bsz=137.3, num_updates=15400, lr=0.000254824, gnorm=0.796, train_wall=15, wall=0
2024-07-10 17:52:26 | INFO | train_inner | epoch 002:   2496 / 13004 loss=7.054, nll_loss=6.018, ppl=64.8, wps=25116, ups=6.37, wpb=3941.3, bsz=164.6, num_updates=15500, lr=0.000254, gnorm=0.851, train_wall=16, wall=0
2024-07-10 17:52:41 | INFO | train_inner | epoch 002:   2596 / 13004 loss=7.018, nll_loss=5.976, ppl=62.93, wps=25801.5, ups=6.59, wpb=3915.7, bsz=121.7, num_updates=15600, lr=0.000253185, gnorm=0.787, train_wall=15, wall=0
2024-07-10 17:52:57 | INFO | train_inner | epoch 002:   2696 / 13004 loss=7.025, nll_loss=5.985, ppl=63.33, wps=25053.7, ups=6.39, wpb=3921.5, bsz=120.5, num_updates=15700, lr=0.000252377, gnorm=0.793, train_wall=15, wall=0
2024-07-10 17:53:13 | INFO | train_inner | epoch 002:   2796 / 13004 loss=6.998, nll_loss=5.954, ppl=61.98, wps=25492.7, ups=6.48, wpb=3936.7, bsz=157.7, num_updates=15800, lr=0.000251577, gnorm=0.809, train_wall=15, wall=0
2024-07-10 17:53:28 | INFO | train_inner | epoch 002:   2896 / 13004 loss=6.977, nll_loss=5.93, ppl=60.98, wps=25378.5, ups=6.47, wpb=3925.4, bsz=148.2, num_updates=15900, lr=0.000250785, gnorm=0.805, train_wall=15, wall=0
2024-07-10 17:53:44 | INFO | train_inner | epoch 002:   2996 / 13004 loss=7.039, nll_loss=5.999, ppl=63.97, wps=25104.2, ups=6.44, wpb=3897.8, bsz=113, num_updates=16000, lr=0.00025, gnorm=0.794, train_wall=15, wall=0
2024-07-10 17:53:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:53:45 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.298 | nll_loss 6.227 | ppl 74.92 | wps 97632.8 | wpb 3703.5 | bsz 124.5 | num_updates 16000 | best_loss 7.298
2024-07-10 17:53:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:53:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_16000.pt (epoch 2 @ 16000 updates, score 7.298) (writing took 5.892832745797932 seconds)
2024-07-10 17:54:06 | INFO | train_inner | epoch 002:   3096 / 13004 loss=7.01, nll_loss=5.967, ppl=62.54, wps=17475.9, ups=4.45, wpb=3924.9, bsz=129.8, num_updates=16100, lr=0.000249222, gnorm=0.799, train_wall=15, wall=0
2024-07-10 17:54:21 | INFO | train_inner | epoch 002:   3196 / 13004 loss=7.002, nll_loss=5.957, ppl=62.13, wps=25695.4, ups=6.54, wpb=3929, bsz=136.6, num_updates=16200, lr=0.000248452, gnorm=0.798, train_wall=15, wall=0
2024-07-10 17:54:37 | INFO | train_inner | epoch 002:   3296 / 13004 loss=7.019, nll_loss=5.977, ppl=63, wps=25494, ups=6.54, wpb=3899.4, bsz=140.2, num_updates=16300, lr=0.000247689, gnorm=0.829, train_wall=15, wall=0
2024-07-10 17:54:52 | INFO | train_inner | epoch 002:   3396 / 13004 loss=7.02, nll_loss=5.979, ppl=63.09, wps=25214.7, ups=6.4, wpb=3939.8, bsz=143.6, num_updates=16400, lr=0.000246932, gnorm=0.796, train_wall=15, wall=0
2024-07-10 17:55:08 | INFO | train_inner | epoch 002:   3496 / 13004 loss=6.975, nll_loss=5.927, ppl=60.82, wps=25671.2, ups=6.54, wpb=3926.6, bsz=114.8, num_updates=16500, lr=0.000246183, gnorm=0.782, train_wall=15, wall=0
2024-07-10 17:55:24 | INFO | train_inner | epoch 002:   3596 / 13004 loss=7.001, nll_loss=5.956, ppl=62.08, wps=24094.1, ups=6.18, wpb=3897.3, bsz=124.4, num_updates=16600, lr=0.00024544, gnorm=0.818, train_wall=16, wall=0
2024-07-10 17:55:39 | INFO | train_inner | epoch 002:   3696 / 13004 loss=6.964, nll_loss=5.915, ppl=60.34, wps=25341.6, ups=6.43, wpb=3941.8, bsz=145.4, num_updates=16700, lr=0.000244704, gnorm=0.801, train_wall=15, wall=0
2024-07-10 17:55:54 | INFO | train_inner | epoch 002:   3796 / 13004 loss=6.967, nll_loss=5.918, ppl=60.45, wps=25786.2, ups=6.59, wpb=3912, bsz=137.7, num_updates=16800, lr=0.000243975, gnorm=0.792, train_wall=15, wall=0
2024-07-10 17:56:10 | INFO | train_inner | epoch 002:   3896 / 13004 loss=6.991, nll_loss=5.945, ppl=61.61, wps=25196.5, ups=6.37, wpb=3953.4, bsz=137.8, num_updates=16900, lr=0.000243252, gnorm=0.801, train_wall=16, wall=0
2024-07-10 17:56:25 | INFO | train_inner | epoch 002:   3996 / 13004 loss=6.975, nll_loss=5.927, ppl=60.85, wps=25679.7, ups=6.58, wpb=3904.8, bsz=135, num_updates=17000, lr=0.000242536, gnorm=0.821, train_wall=15, wall=0
2024-07-10 17:56:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:56:26 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.297 | nll_loss 6.222 | ppl 74.64 | wps 97807.3 | wpb 3703.5 | bsz 124.5 | num_updates 17000 | best_loss 7.297
2024-07-10 17:56:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:56:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_17000.pt (epoch 2 @ 17000 updates, score 7.297) (writing took 5.149986055679619 seconds)
2024-07-10 17:56:47 | INFO | train_inner | epoch 002:   4096 / 13004 loss=7.006, nll_loss=5.961, ppl=62.31, wps=18103.8, ups=4.64, wpb=3903.5, bsz=115.2, num_updates=17100, lr=0.000241825, gnorm=0.811, train_wall=15, wall=0
2024-07-10 17:57:02 | INFO | train_inner | epoch 002:   4196 / 13004 loss=6.966, nll_loss=5.917, ppl=60.43, wps=25529.3, ups=6.51, wpb=3923.7, bsz=135.4, num_updates=17200, lr=0.000241121, gnorm=0.795, train_wall=15, wall=0
2024-07-10 17:57:18 | INFO | train_inner | epoch 002:   4296 / 13004 loss=6.944, nll_loss=5.892, ppl=59.37, wps=25310.9, ups=6.46, wpb=3916.9, bsz=131.1, num_updates=17300, lr=0.000240424, gnorm=0.796, train_wall=15, wall=0
2024-07-10 17:57:33 | INFO | train_inner | epoch 002:   4396 / 13004 loss=6.98, nll_loss=5.932, ppl=61.04, wps=25278.8, ups=6.48, wpb=3899.3, bsz=113.5, num_updates=17400, lr=0.000239732, gnorm=0.798, train_wall=15, wall=0
2024-07-10 17:57:48 | INFO | train_inner | epoch 002:   4496 / 13004 loss=6.946, nll_loss=5.893, ppl=59.44, wps=25828.7, ups=6.58, wpb=3924.6, bsz=120.1, num_updates=17500, lr=0.000239046, gnorm=0.791, train_wall=15, wall=0
2024-07-10 17:58:04 | INFO | train_inner | epoch 002:   4596 / 13004 loss=6.975, nll_loss=5.927, ppl=60.84, wps=25341.3, ups=6.48, wpb=3911.4, bsz=125.8, num_updates=17600, lr=0.000238366, gnorm=0.803, train_wall=15, wall=0
2024-07-10 17:58:19 | INFO | train_inner | epoch 002:   4696 / 13004 loss=6.947, nll_loss=5.895, ppl=59.51, wps=25361.2, ups=6.46, wpb=3923.8, bsz=145, num_updates=17700, lr=0.000237691, gnorm=0.803, train_wall=15, wall=0
2024-07-10 17:58:34 | INFO | train_inner | epoch 002:   4796 / 13004 loss=7.014, nll_loss=5.971, ppl=62.73, wps=25907.7, ups=6.62, wpb=3912.3, bsz=127, num_updates=17800, lr=0.000237023, gnorm=0.82, train_wall=15, wall=0
2024-07-10 17:58:50 | INFO | train_inner | epoch 002:   4896 / 13004 loss=7.01, nll_loss=5.968, ppl=62.58, wps=25281.8, ups=6.45, wpb=3918.1, bsz=141.2, num_updates=17900, lr=0.00023636, gnorm=0.82, train_wall=15, wall=0
2024-07-10 17:59:05 | INFO | train_inner | epoch 002:   4996 / 13004 loss=6.952, nll_loss=5.901, ppl=59.74, wps=25483.8, ups=6.46, wpb=3944.2, bsz=140.8, num_updates=18000, lr=0.000235702, gnorm=0.799, train_wall=15, wall=0
2024-07-10 17:59:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 17:59:07 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.268 | nll_loss 6.189 | ppl 72.96 | wps 93519.9 | wpb 3703.5 | bsz 124.5 | num_updates 18000 | best_loss 7.268
2024-07-10 17:59:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 17:59:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_18000.pt (epoch 2 @ 18000 updates, score 7.268) (writing took 4.755223462358117 seconds)
2024-07-10 17:59:27 | INFO | train_inner | epoch 002:   5096 / 13004 loss=6.949, nll_loss=5.897, ppl=59.58, wps=18092.7, ups=4.63, wpb=3909.5, bsz=120.3, num_updates=18100, lr=0.00023505, gnorm=0.797, train_wall=15, wall=0
2024-07-10 17:59:42 | INFO | train_inner | epoch 002:   5196 / 13004 loss=6.982, nll_loss=5.936, ppl=61.2, wps=25662.2, ups=6.56, wpb=3910.4, bsz=127.4, num_updates=18200, lr=0.000234404, gnorm=0.803, train_wall=15, wall=0
2024-07-10 17:59:58 | INFO | train_inner | epoch 002:   5296 / 13004 loss=6.931, nll_loss=5.877, ppl=58.79, wps=25182.1, ups=6.44, wpb=3908.3, bsz=151, num_updates=18300, lr=0.000233762, gnorm=0.824, train_wall=15, wall=0
2024-07-10 18:00:13 | INFO | train_inner | epoch 002:   5396 / 13004 loss=6.929, nll_loss=5.874, ppl=58.66, wps=25787.9, ups=6.56, wpb=3929.1, bsz=127.7, num_updates=18400, lr=0.000233126, gnorm=0.792, train_wall=15, wall=0
2024-07-10 18:00:29 | INFO | train_inner | epoch 002:   5496 / 13004 loss=6.931, nll_loss=5.877, ppl=58.77, wps=24951.1, ups=6.36, wpb=3922.5, bsz=142.6, num_updates=18500, lr=0.000232495, gnorm=0.81, train_wall=16, wall=0
2024-07-10 18:00:44 | INFO | train_inner | epoch 002:   5596 / 13004 loss=6.951, nll_loss=5.899, ppl=59.67, wps=25461, ups=6.55, wpb=3888.3, bsz=127.3, num_updates=18600, lr=0.000231869, gnorm=0.819, train_wall=15, wall=0
2024-07-10 18:00:59 | INFO | train_inner | epoch 002:   5696 / 13004 loss=6.941, nll_loss=5.889, ppl=59.26, wps=25573.2, ups=6.49, wpb=3939.4, bsz=148.8, num_updates=18700, lr=0.000231249, gnorm=0.82, train_wall=15, wall=0
2024-07-10 18:01:15 | INFO | train_inner | epoch 002:   5796 / 13004 loss=6.959, nll_loss=5.908, ppl=60.06, wps=25651.7, ups=6.57, wpb=3902.3, bsz=118.1, num_updates=18800, lr=0.000230633, gnorm=0.801, train_wall=15, wall=0
2024-07-10 18:01:30 | INFO | train_inner | epoch 002:   5896 / 13004 loss=6.875, nll_loss=5.812, ppl=56.19, wps=24935.8, ups=6.31, wpb=3949.5, bsz=139.9, num_updates=18900, lr=0.000230022, gnorm=0.779, train_wall=16, wall=0
2024-07-10 18:01:46 | INFO | train_inner | epoch 002:   5996 / 13004 loss=6.903, nll_loss=5.845, ppl=57.47, wps=25892.4, ups=6.58, wpb=3937.5, bsz=133.9, num_updates=19000, lr=0.000229416, gnorm=0.795, train_wall=15, wall=0
2024-07-10 18:01:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:01:47 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.255 | nll_loss 6.172 | ppl 72.11 | wps 95341.4 | wpb 3703.5 | bsz 124.5 | num_updates 19000 | best_loss 7.255
2024-07-10 18:01:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:01:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_19000.pt (epoch 2 @ 19000 updates, score 7.255) (writing took 5.648071945644915 seconds)
2024-07-10 18:02:08 | INFO | train_inner | epoch 002:   6096 / 13004 loss=6.953, nll_loss=5.902, ppl=59.78, wps=17425.5, ups=4.43, wpb=3932.3, bsz=126.7, num_updates=19100, lr=0.000228814, gnorm=0.806, train_wall=16, wall=0
2024-07-10 18:02:23 | INFO | train_inner | epoch 002:   6196 / 13004 loss=6.993, nll_loss=5.948, ppl=61.72, wps=25578.5, ups=6.59, wpb=3879.3, bsz=137, num_updates=19200, lr=0.000228218, gnorm=0.852, train_wall=15, wall=0
2024-07-10 18:02:39 | INFO | train_inner | epoch 002:   6296 / 13004 loss=6.947, nll_loss=5.895, ppl=59.51, wps=25545.5, ups=6.56, wpb=3895.5, bsz=128.9, num_updates=19300, lr=0.000227626, gnorm=0.807, train_wall=15, wall=0
2024-07-10 18:02:54 | INFO | train_inner | epoch 002:   6396 / 13004 loss=6.937, nll_loss=5.884, ppl=59.05, wps=24723, ups=6.3, wpb=3927.2, bsz=147.6, num_updates=19400, lr=0.000227038, gnorm=0.82, train_wall=16, wall=0
2024-07-10 18:03:10 | INFO | train_inner | epoch 002:   6496 / 13004 loss=6.928, nll_loss=5.874, ppl=58.64, wps=25716.6, ups=6.58, wpb=3908.5, bsz=132.4, num_updates=19500, lr=0.000226455, gnorm=0.817, train_wall=15, wall=0
2024-07-10 18:03:25 | INFO | train_inner | epoch 002:   6596 / 13004 loss=6.952, nll_loss=5.9, ppl=59.73, wps=25033, ups=6.4, wpb=3913.2, bsz=129.1, num_updates=19600, lr=0.000225877, gnorm=0.816, train_wall=15, wall=0
2024-07-10 18:03:41 | INFO | train_inner | epoch 002:   6696 / 13004 loss=6.951, nll_loss=5.901, ppl=59.74, wps=25907.6, ups=6.57, wpb=3945.8, bsz=151.7, num_updates=19700, lr=0.000225303, gnorm=0.816, train_wall=15, wall=0
2024-07-10 18:03:56 | INFO | train_inner | epoch 002:   6796 / 13004 loss=6.908, nll_loss=5.851, ppl=57.73, wps=25278.1, ups=6.46, wpb=3911.2, bsz=127.4, num_updates=19800, lr=0.000224733, gnorm=0.797, train_wall=15, wall=0
2024-07-10 18:04:11 | INFO | train_inner | epoch 002:   6896 / 13004 loss=6.907, nll_loss=5.849, ppl=57.63, wps=25544.1, ups=6.48, wpb=3943.1, bsz=123.1, num_updates=19900, lr=0.000224168, gnorm=0.788, train_wall=15, wall=0
2024-07-10 18:04:27 | INFO | train_inner | epoch 002:   6996 / 13004 loss=6.932, nll_loss=5.877, ppl=58.78, wps=25565.2, ups=6.49, wpb=3940.6, bsz=121.6, num_updates=20000, lr=0.000223607, gnorm=0.805, train_wall=15, wall=0
2024-07-10 18:04:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:04:28 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.236 | nll_loss 6.153 | ppl 71.16 | wps 96389.8 | wpb 3703.5 | bsz 124.5 | num_updates 20000 | best_loss 7.236
2024-07-10 18:04:28 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:04:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_20000.pt (epoch 2 @ 20000 updates, score 7.236) (writing took 9.842803915962577 seconds)
2024-07-10 18:04:53 | INFO | train_inner | epoch 002:   7096 / 13004 loss=6.883, nll_loss=5.822, ppl=56.58, wps=14813, ups=3.77, wpb=3930.6, bsz=137.5, num_updates=20100, lr=0.00022305, gnorm=0.794, train_wall=15, wall=0
2024-07-10 18:05:09 | INFO | train_inner | epoch 002:   7196 / 13004 loss=6.953, nll_loss=5.902, ppl=59.81, wps=25668.9, ups=6.56, wpb=3915.3, bsz=157.8, num_updates=20200, lr=0.000222497, gnorm=0.856, train_wall=15, wall=0
2024-07-10 18:05:24 | INFO | train_inner | epoch 002:   7296 / 13004 loss=6.92, nll_loss=5.865, ppl=58.28, wps=25342.3, ups=6.45, wpb=3931.7, bsz=144.8, num_updates=20300, lr=0.000221948, gnorm=0.818, train_wall=15, wall=0
2024-07-10 18:05:40 | INFO | train_inner | epoch 002:   7396 / 13004 loss=6.936, nll_loss=5.883, ppl=59, wps=25605.4, ups=6.5, wpb=3941.1, bsz=141.3, num_updates=20400, lr=0.000221404, gnorm=0.839, train_wall=15, wall=0
2024-07-10 18:05:55 | INFO | train_inner | epoch 002:   7496 / 13004 loss=6.901, nll_loss=5.843, ppl=57.4, wps=25702.6, ups=6.58, wpb=3907.8, bsz=130.6, num_updates=20500, lr=0.000220863, gnorm=0.821, train_wall=15, wall=0
2024-07-10 18:06:10 | INFO | train_inner | epoch 002:   7596 / 13004 loss=6.914, nll_loss=5.857, ppl=57.96, wps=25651.9, ups=6.53, wpb=3927.3, bsz=132.2, num_updates=20600, lr=0.000220326, gnorm=0.81, train_wall=15, wall=0
2024-07-10 18:06:26 | INFO | train_inner | epoch 002:   7696 / 13004 loss=6.886, nll_loss=5.826, ppl=56.71, wps=25111.8, ups=6.38, wpb=3934.3, bsz=126.4, num_updates=20700, lr=0.000219793, gnorm=0.793, train_wall=15, wall=0
2024-07-10 18:06:41 | INFO | train_inner | epoch 002:   7796 / 13004 loss=6.9, nll_loss=5.841, ppl=57.31, wps=25703.8, ups=6.54, wpb=3927.8, bsz=137.4, num_updates=20800, lr=0.000219265, gnorm=0.807, train_wall=15, wall=0
2024-07-10 18:06:56 | INFO | train_inner | epoch 002:   7896 / 13004 loss=6.925, nll_loss=5.871, ppl=58.51, wps=25698.8, ups=6.59, wpb=3897.6, bsz=124.7, num_updates=20900, lr=0.000218739, gnorm=0.839, train_wall=15, wall=0
2024-07-10 18:07:11 | INFO | train_inner | epoch 002:   7996 / 13004 loss=6.906, nll_loss=5.848, ppl=57.6, wps=25963.1, ups=6.62, wpb=3922.7, bsz=118.8, num_updates=21000, lr=0.000218218, gnorm=0.802, train_wall=15, wall=0
2024-07-10 18:07:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:07:12 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.195 | nll_loss 6.106 | ppl 68.9 | wps 95436.5 | wpb 3703.5 | bsz 124.5 | num_updates 21000 | best_loss 7.195
2024-07-10 18:07:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:07:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_21000.pt (epoch 2 @ 21000 updates, score 7.195) (writing took 7.155621513724327 seconds)
2024-07-10 18:07:35 | INFO | train_inner | epoch 002:   8096 / 13004 loss=6.92, nll_loss=5.864, ppl=58.24, wps=16699.8, ups=4.25, wpb=3927.2, bsz=123.4, num_updates=21100, lr=0.0002177, gnorm=0.804, train_wall=15, wall=0
2024-07-10 18:07:50 | INFO | train_inner | epoch 002:   8196 / 13004 loss=6.895, nll_loss=5.836, ppl=57.14, wps=25633.4, ups=6.54, wpb=3917.1, bsz=126.9, num_updates=21200, lr=0.000217186, gnorm=0.813, train_wall=15, wall=0
2024-07-10 18:08:06 | INFO | train_inner | epoch 002:   8296 / 13004 loss=6.867, nll_loss=5.803, ppl=55.85, wps=25622.5, ups=6.49, wpb=3946.3, bsz=123.4, num_updates=21300, lr=0.000216676, gnorm=0.788, train_wall=15, wall=0
2024-07-10 18:08:21 | INFO | train_inner | epoch 002:   8396 / 13004 loss=6.88, nll_loss=5.819, ppl=56.44, wps=25447, ups=6.49, wpb=3919.7, bsz=126.9, num_updates=21400, lr=0.000216169, gnorm=0.823, train_wall=15, wall=0
2024-07-10 18:08:36 | INFO | train_inner | epoch 002:   8496 / 13004 loss=6.864, nll_loss=5.8, ppl=55.72, wps=25659.3, ups=6.54, wpb=3922.7, bsz=124, num_updates=21500, lr=0.000215666, gnorm=0.798, train_wall=15, wall=0
2024-07-10 18:08:51 | INFO | train_inner | epoch 002:   8596 / 13004 loss=6.914, nll_loss=5.857, ppl=57.95, wps=25639.2, ups=6.55, wpb=3915.3, bsz=126.2, num_updates=21600, lr=0.000215166, gnorm=0.831, train_wall=15, wall=0
2024-07-10 18:09:07 | INFO | train_inner | epoch 002:   8696 / 13004 loss=6.89, nll_loss=5.831, ppl=56.92, wps=25573.5, ups=6.52, wpb=3924.2, bsz=139.8, num_updates=21700, lr=0.000214669, gnorm=0.841, train_wall=15, wall=0
2024-07-10 18:09:23 | INFO | train_inner | epoch 002:   8796 / 13004 loss=6.888, nll_loss=5.828, ppl=56.82, wps=24973.8, ups=6.36, wpb=3927.8, bsz=137.5, num_updates=21800, lr=0.000214176, gnorm=0.81, train_wall=16, wall=0
2024-07-10 18:09:38 | INFO | train_inner | epoch 002:   8896 / 13004 loss=6.86, nll_loss=5.796, ppl=55.56, wps=25872.3, ups=6.59, wpb=3927.2, bsz=124.1, num_updates=21900, lr=0.000213687, gnorm=0.801, train_wall=15, wall=0
2024-07-10 18:09:53 | INFO | train_inner | epoch 002:   8996 / 13004 loss=6.851, nll_loss=5.786, ppl=55.16, wps=25547.2, ups=6.49, wpb=3935.6, bsz=129.4, num_updates=22000, lr=0.000213201, gnorm=0.8, train_wall=15, wall=0
2024-07-10 18:09:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:09:54 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.198 | nll_loss 6.109 | ppl 69.04 | wps 97353.2 | wpb 3703.5 | bsz 124.5 | num_updates 22000 | best_loss 7.195
2024-07-10 18:09:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:09:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_22000.pt (epoch 2 @ 22000 updates, score 7.198) (writing took 2.8373790504410863 seconds)
2024-07-10 18:10:12 | INFO | train_inner | epoch 002:   9096 / 13004 loss=6.9, nll_loss=5.841, ppl=57.32, wps=20139.3, ups=5.17, wpb=3898.2, bsz=120.7, num_updates=22100, lr=0.000212718, gnorm=0.814, train_wall=15, wall=0
2024-07-10 18:10:28 | INFO | train_inner | epoch 002:   9196 / 13004 loss=6.89, nll_loss=5.83, ppl=56.88, wps=25742.7, ups=6.56, wpb=3923.9, bsz=141.4, num_updates=22200, lr=0.000212238, gnorm=0.829, train_wall=15, wall=0
2024-07-10 18:10:43 | INFO | train_inner | epoch 002:   9296 / 13004 loss=6.928, nll_loss=5.874, ppl=58.64, wps=24954.4, ups=6.35, wpb=3928.2, bsz=154.7, num_updates=22300, lr=0.000211762, gnorm=0.874, train_wall=16, wall=0
2024-07-10 18:10:59 | INFO | train_inner | epoch 002:   9396 / 13004 loss=6.905, nll_loss=5.847, ppl=57.57, wps=25179, ups=6.46, wpb=3894.9, bsz=134.5, num_updates=22400, lr=0.000211289, gnorm=0.822, train_wall=15, wall=0
2024-07-10 18:11:14 | INFO | train_inner | epoch 002:   9496 / 13004 loss=6.879, nll_loss=5.818, ppl=56.43, wps=25828.1, ups=6.58, wpb=3922.8, bsz=158, num_updates=22500, lr=0.000210819, gnorm=0.847, train_wall=15, wall=0
2024-07-10 18:11:29 | INFO | train_inner | epoch 002:   9596 / 13004 loss=6.896, nll_loss=5.837, ppl=57.18, wps=25357.7, ups=6.53, wpb=3885.6, bsz=127.8, num_updates=22600, lr=0.000210352, gnorm=0.904, train_wall=15, wall=0
2024-07-10 18:11:45 | INFO | train_inner | epoch 002:   9696 / 13004 loss=6.885, nll_loss=5.825, ppl=56.69, wps=25780.9, ups=6.54, wpb=3942.2, bsz=138.7, num_updates=22700, lr=0.000209888, gnorm=0.8, train_wall=15, wall=0
2024-07-10 18:12:00 | INFO | train_inner | epoch 002:   9796 / 13004 loss=6.892, nll_loss=5.831, ppl=56.94, wps=25911.9, ups=6.59, wpb=3930.8, bsz=127, num_updates=22800, lr=0.000209427, gnorm=0.827, train_wall=15, wall=0
2024-07-10 18:12:15 | INFO | train_inner | epoch 002:   9896 / 13004 loss=6.871, nll_loss=5.808, ppl=56.02, wps=26064.3, ups=6.61, wpb=3942.2, bsz=134.2, num_updates=22900, lr=0.000208969, gnorm=0.802, train_wall=15, wall=0
2024-07-10 18:12:30 | INFO | train_inner | epoch 002:   9996 / 13004 loss=6.893, nll_loss=5.832, ppl=56.98, wps=25435.4, ups=6.53, wpb=3896.2, bsz=137.9, num_updates=23000, lr=0.000208514, gnorm=0.864, train_wall=15, wall=0
2024-07-10 18:12:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:12:32 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.183 | nll_loss 6.097 | ppl 68.45 | wps 93015.1 | wpb 3703.5 | bsz 124.5 | num_updates 23000 | best_loss 7.183
2024-07-10 18:12:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:12:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_23000.pt (epoch 2 @ 23000 updates, score 7.183) (writing took 4.520269469358027 seconds)
2024-07-10 18:12:51 | INFO | train_inner | epoch 002:  10096 / 13004 loss=6.9, nll_loss=5.842, ppl=57.35, wps=18628.8, ups=4.75, wpb=3925.8, bsz=125.6, num_updates=23100, lr=0.000208063, gnorm=0.806, train_wall=15, wall=0
2024-07-10 18:13:07 | INFO | train_inner | epoch 002:  10196 / 13004 loss=6.899, nll_loss=5.84, ppl=57.29, wps=25755, ups=6.53, wpb=3941.1, bsz=146, num_updates=23200, lr=0.000207614, gnorm=0.865, train_wall=15, wall=0
2024-07-10 18:13:22 | INFO | train_inner | epoch 002:  10296 / 13004 loss=6.85, nll_loss=5.784, ppl=55.11, wps=25476.3, ups=6.47, wpb=3939.9, bsz=138.6, num_updates=23300, lr=0.000207168, gnorm=0.807, train_wall=15, wall=0
2024-07-10 18:13:38 | INFO | train_inner | epoch 002:  10396 / 13004 loss=6.921, nll_loss=5.866, ppl=58.32, wps=25664.4, ups=6.5, wpb=3946, bsz=153.1, num_updates=23400, lr=0.000206725, gnorm=0.856, train_wall=15, wall=0
2024-07-10 18:13:53 | INFO | train_inner | epoch 002:  10496 / 13004 loss=6.868, nll_loss=5.804, ppl=55.86, wps=25523.1, ups=6.54, wpb=3905, bsz=121.9, num_updates=23500, lr=0.000206284, gnorm=0.808, train_wall=15, wall=0
2024-07-10 18:14:08 | INFO | train_inner | epoch 002:  10596 / 13004 loss=6.868, nll_loss=5.805, ppl=55.91, wps=25153.1, ups=6.42, wpb=3920.6, bsz=151.4, num_updates=23600, lr=0.000205847, gnorm=0.861, train_wall=15, wall=0
2024-07-10 18:14:24 | INFO | train_inner | epoch 002:  10696 / 13004 loss=6.883, nll_loss=5.822, ppl=56.59, wps=25400.2, ups=6.55, wpb=3876.3, bsz=125.5, num_updates=23700, lr=0.000205412, gnorm=0.835, train_wall=15, wall=0
2024-07-10 18:14:39 | INFO | train_inner | epoch 002:  10796 / 13004 loss=6.851, nll_loss=5.785, ppl=55.14, wps=25455.5, ups=6.5, wpb=3914, bsz=150.8, num_updates=23800, lr=0.00020498, gnorm=0.852, train_wall=15, wall=0
2024-07-10 18:14:55 | INFO | train_inner | epoch 002:  10896 / 13004 loss=6.894, nll_loss=5.835, ppl=57.09, wps=25226.6, ups=6.47, wpb=3898.6, bsz=137, num_updates=23900, lr=0.000204551, gnorm=0.84, train_wall=15, wall=0
2024-07-10 18:15:10 | INFO | train_inner | epoch 002:  10996 / 13004 loss=6.882, nll_loss=5.822, ppl=56.58, wps=25547.4, ups=6.55, wpb=3898.9, bsz=135, num_updates=24000, lr=0.000204124, gnorm=0.824, train_wall=15, wall=0
2024-07-10 18:15:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:15:11 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.199 | nll_loss 6.109 | ppl 69.04 | wps 96913.9 | wpb 3703.5 | bsz 124.5 | num_updates 24000 | best_loss 7.183
2024-07-10 18:15:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:15:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_24000.pt (epoch 2 @ 24000 updates, score 7.199) (writing took 2.715254354290664 seconds)
2024-07-10 18:15:29 | INFO | train_inner | epoch 002:  11096 / 13004 loss=6.873, nll_loss=5.81, ppl=56.09, wps=20450.7, ups=5.22, wpb=3917.7, bsz=126.9, num_updates=24100, lr=0.0002037, gnorm=0.814, train_wall=15, wall=0
2024-07-10 18:15:45 | INFO | train_inner | epoch 002:  11196 / 13004 loss=6.874, nll_loss=5.812, ppl=56.19, wps=24656.9, ups=6.32, wpb=3902.7, bsz=133.2, num_updates=24200, lr=0.000203279, gnorm=0.841, train_wall=16, wall=0
2024-07-10 18:16:00 | INFO | train_inner | epoch 002:  11296 / 13004 loss=6.888, nll_loss=5.828, ppl=56.81, wps=25135.6, ups=6.4, wpb=3925.8, bsz=133, num_updates=24300, lr=0.00020286, gnorm=0.821, train_wall=15, wall=0
2024-07-10 18:16:16 | INFO | train_inner | epoch 002:  11396 / 13004 loss=6.846, nll_loss=5.78, ppl=54.94, wps=25777, ups=6.58, wpb=3919.2, bsz=130.6, num_updates=24400, lr=0.000202444, gnorm=0.81, train_wall=15, wall=0
2024-07-10 18:16:31 | INFO | train_inner | epoch 002:  11496 / 13004 loss=6.826, nll_loss=5.757, ppl=54.08, wps=25770, ups=6.51, wpb=3957.8, bsz=131, num_updates=24500, lr=0.000202031, gnorm=0.797, train_wall=15, wall=0
2024-07-10 18:16:46 | INFO | train_inner | epoch 002:  11596 / 13004 loss=6.832, nll_loss=5.764, ppl=54.32, wps=25544.3, ups=6.46, wpb=3953, bsz=147.8, num_updates=24600, lr=0.000201619, gnorm=0.814, train_wall=15, wall=0
2024-07-10 18:17:02 | INFO | train_inner | epoch 002:  11696 / 13004 loss=6.852, nll_loss=5.788, ppl=55.25, wps=25803.9, ups=6.57, wpb=3929.5, bsz=137.6, num_updates=24700, lr=0.000201211, gnorm=0.818, train_wall=15, wall=0
2024-07-10 18:17:17 | INFO | train_inner | epoch 002:  11796 / 13004 loss=6.836, nll_loss=5.768, ppl=54.5, wps=25790.2, ups=6.61, wpb=3899.2, bsz=113, num_updates=24800, lr=0.000200805, gnorm=0.807, train_wall=15, wall=0
2024-07-10 18:17:32 | INFO | train_inner | epoch 002:  11896 / 13004 loss=6.914, nll_loss=5.858, ppl=57.99, wps=25699, ups=6.54, wpb=3930.6, bsz=154.3, num_updates=24900, lr=0.000200401, gnorm=0.866, train_wall=15, wall=0
2024-07-10 18:17:48 | INFO | train_inner | epoch 002:  11996 / 13004 loss=6.849, nll_loss=5.782, ppl=55.04, wps=25324.5, ups=6.46, wpb=3919.3, bsz=119.8, num_updates=25000, lr=0.0002, gnorm=0.822, train_wall=15, wall=0
2024-07-10 18:17:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:17:49 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.179 | nll_loss 6.087 | ppl 67.96 | wps 97357.9 | wpb 3703.5 | bsz 124.5 | num_updates 25000 | best_loss 7.179
2024-07-10 18:17:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:17:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_25000.pt (epoch 2 @ 25000 updates, score 7.179) (writing took 4.549100757576525 seconds)
2024-07-10 18:18:09 | INFO | train_inner | epoch 002:  12096 / 13004 loss=6.857, nll_loss=5.792, ppl=55.41, wps=18422.9, ups=4.74, wpb=3884.9, bsz=123.8, num_updates=25100, lr=0.000199601, gnorm=0.821, train_wall=15, wall=0
2024-07-10 18:18:24 | INFO | train_inner | epoch 002:  12196 / 13004 loss=6.841, nll_loss=5.774, ppl=54.73, wps=25578.1, ups=6.55, wpb=3906.5, bsz=120.9, num_updates=25200, lr=0.000199205, gnorm=0.817, train_wall=15, wall=0
2024-07-10 18:18:39 | INFO | train_inner | epoch 002:  12296 / 13004 loss=6.871, nll_loss=5.809, ppl=56.05, wps=25225.7, ups=6.49, wpb=3885.2, bsz=131.3, num_updates=25300, lr=0.000198811, gnorm=0.843, train_wall=15, wall=0
2024-07-10 18:18:55 | INFO | train_inner | epoch 002:  12396 / 13004 loss=6.853, nll_loss=5.789, ppl=55.28, wps=25735.3, ups=6.56, wpb=3920.2, bsz=138.4, num_updates=25400, lr=0.000198419, gnorm=0.838, train_wall=15, wall=0
2024-07-10 18:19:10 | INFO | train_inner | epoch 002:  12496 / 13004 loss=6.861, nll_loss=5.796, ppl=55.57, wps=25640, ups=6.56, wpb=3910.1, bsz=127.3, num_updates=25500, lr=0.00019803, gnorm=0.83, train_wall=15, wall=0
2024-07-10 18:19:25 | INFO | train_inner | epoch 002:  12596 / 13004 loss=6.897, nll_loss=5.838, ppl=57.21, wps=25587.9, ups=6.52, wpb=3923.2, bsz=135.8, num_updates=25600, lr=0.000197642, gnorm=0.843, train_wall=15, wall=0
2024-07-10 18:19:40 | INFO | train_inner | epoch 002:  12696 / 13004 loss=6.812, nll_loss=5.74, ppl=53.46, wps=25886.2, ups=6.59, wpb=3925.7, bsz=129.4, num_updates=25700, lr=0.000197257, gnorm=0.803, train_wall=15, wall=0
2024-07-10 18:19:56 | INFO | train_inner | epoch 002:  12796 / 13004 loss=6.839, nll_loss=5.773, ppl=54.67, wps=25493.2, ups=6.51, wpb=3918.3, bsz=124.7, num_updates=25800, lr=0.000196875, gnorm=0.813, train_wall=15, wall=0
2024-07-10 18:20:11 | INFO | train_inner | epoch 002:  12896 / 13004 loss=6.837, nll_loss=5.769, ppl=54.53, wps=25640, ups=6.52, wpb=3932.1, bsz=135.5, num_updates=25900, lr=0.000196494, gnorm=0.833, train_wall=15, wall=0
2024-07-10 18:20:26 | INFO | train_inner | epoch 002:  12996 / 13004 loss=6.808, nll_loss=5.737, ppl=53.32, wps=25961.8, ups=6.64, wpb=3911.4, bsz=128.6, num_updates=26000, lr=0.000196116, gnorm=0.811, train_wall=15, wall=0
2024-07-10 18:20:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:20:27 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.152 | nll_loss 6.06 | ppl 66.7 | wps 96924.7 | wpb 3703.5 | bsz 124.5 | num_updates 26000 | best_loss 7.152
2024-07-10 18:20:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:20:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_26000.pt (epoch 2 @ 26000 updates, score 7.152) (writing took 5.9690010556951165 seconds)
2024-07-10 18:20:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:20:36 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.159 | nll_loss 6.063 | ppl 66.87 | wps 97427.6 | wpb 3703.5 | bsz 124.5 | num_updates 26008 | best_loss 7.152
2024-07-10 18:20:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:20:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 2 @ 26008 updates, score 7.159) (writing took 2.3429639413952827 seconds)
2024-07-10 18:20:38 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2024-07-10 18:20:38 | INFO | train | epoch 002 | loss 6.942 | nll_loss 5.889 | ppl 59.26 | wps 24402.7 | ups 6.23 | wpb 3919.8 | bsz 133.2 | num_updates 26008 | lr 0.000196086 | gnorm 0.813 | train_wall 1980 | wall 0
2024-07-10 18:20:38 | INFO | fairseq.trainer | begin training epoch 3
2024-07-10 18:20:52 | INFO | train_inner | epoch 003:     92 / 13004 loss=6.77, nll_loss=5.692, ppl=51.7, wps=15049, ups=3.82, wpb=3940.4, bsz=133.8, num_updates=26100, lr=0.00019574, gnorm=0.806, train_wall=15, wall=0
2024-07-10 18:21:08 | INFO | train_inner | epoch 003:    192 / 13004 loss=6.844, nll_loss=5.778, ppl=54.86, wps=25413.1, ups=6.51, wpb=3903.6, bsz=137.1, num_updates=26200, lr=0.000195366, gnorm=0.886, train_wall=15, wall=0
2024-07-10 18:21:23 | INFO | train_inner | epoch 003:    292 / 13004 loss=6.776, nll_loss=5.7, ppl=51.97, wps=25668.8, ups=6.59, wpb=3893.8, bsz=125.4, num_updates=26300, lr=0.000194994, gnorm=0.825, train_wall=15, wall=0
2024-07-10 18:21:38 | INFO | train_inner | epoch 003:    392 / 13004 loss=6.8, nll_loss=5.727, ppl=52.97, wps=25293.9, ups=6.43, wpb=3931.6, bsz=133.1, num_updates=26400, lr=0.000194625, gnorm=0.819, train_wall=15, wall=0
2024-07-10 18:21:54 | INFO | train_inner | epoch 003:    492 / 13004 loss=6.796, nll_loss=5.723, ppl=52.81, wps=25763.2, ups=6.58, wpb=3914.1, bsz=135, num_updates=26500, lr=0.000194257, gnorm=0.83, train_wall=15, wall=0
2024-07-10 18:22:09 | INFO | train_inner | epoch 003:    592 / 13004 loss=6.789, nll_loss=5.715, ppl=52.51, wps=24920.3, ups=6.31, wpb=3950.9, bsz=146.3, num_updates=26600, lr=0.000193892, gnorm=0.829, train_wall=16, wall=0
2024-07-10 18:22:24 | INFO | train_inner | epoch 003:    692 / 13004 loss=6.776, nll_loss=5.699, ppl=51.96, wps=26019.2, ups=6.65, wpb=3912.4, bsz=131.2, num_updates=26700, lr=0.000193528, gnorm=0.827, train_wall=15, wall=0
2024-07-10 18:22:40 | INFO | train_inner | epoch 003:    792 / 13004 loss=6.807, nll_loss=5.734, ppl=53.23, wps=25388.4, ups=6.52, wpb=3896.8, bsz=126.8, num_updates=26800, lr=0.000193167, gnorm=0.85, train_wall=15, wall=0
2024-07-10 18:22:55 | INFO | train_inner | epoch 003:    892 / 13004 loss=6.775, nll_loss=5.699, ppl=51.95, wps=25710.3, ups=6.54, wpb=3928.8, bsz=134, num_updates=26900, lr=0.000192807, gnorm=0.822, train_wall=15, wall=0
2024-07-10 18:23:11 | INFO | train_inner | epoch 003:    992 / 13004 loss=6.859, nll_loss=5.794, ppl=55.5, wps=25474.9, ups=6.46, wpb=3941.1, bsz=153.4, num_updates=27000, lr=0.00019245, gnorm=0.887, train_wall=15, wall=0
2024-07-10 18:23:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:23:12 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.145 | nll_loss 6.045 | ppl 66.02 | wps 96676 | wpb 3703.5 | bsz 124.5 | num_updates 27000 | best_loss 7.145
2024-07-10 18:23:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:23:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_27000.pt (epoch 3 @ 27000 updates, score 7.145) (writing took 4.974409835413098 seconds)
2024-07-10 18:23:32 | INFO | train_inner | epoch 003:   1092 / 13004 loss=6.791, nll_loss=5.716, ppl=52.55, wps=18272.9, ups=4.62, wpb=3951.4, bsz=123.9, num_updates=27100, lr=0.000192095, gnorm=0.81, train_wall=15, wall=0
2024-07-10 18:23:48 | INFO | train_inner | epoch 003:   1192 / 13004 loss=6.814, nll_loss=5.743, ppl=53.55, wps=24799.6, ups=6.34, wpb=3913.2, bsz=137.8, num_updates=27200, lr=0.000191741, gnorm=0.845, train_wall=16, wall=0
2024-07-10 18:24:03 | INFO | train_inner | epoch 003:   1292 / 13004 loss=6.795, nll_loss=5.721, ppl=52.74, wps=25563.1, ups=6.5, wpb=3934.5, bsz=144.5, num_updates=27300, lr=0.00019139, gnorm=0.832, train_wall=15, wall=0
2024-07-10 18:24:19 | INFO | train_inner | epoch 003:   1392 / 13004 loss=6.837, nll_loss=5.769, ppl=54.52, wps=24883.9, ups=6.35, wpb=3921.6, bsz=134.8, num_updates=27400, lr=0.00019104, gnorm=0.837, train_wall=16, wall=0
2024-07-10 18:24:34 | INFO | train_inner | epoch 003:   1492 / 13004 loss=6.834, nll_loss=5.766, ppl=54.41, wps=25433.5, ups=6.55, wpb=3883.2, bsz=141, num_updates=27500, lr=0.000190693, gnorm=0.879, train_wall=15, wall=0
2024-07-10 18:24:50 | INFO | train_inner | epoch 003:   1592 / 13004 loss=6.825, nll_loss=5.756, ppl=54.04, wps=24986.1, ups=6.42, wpb=3891.5, bsz=131.9, num_updates=27600, lr=0.000190347, gnorm=0.838, train_wall=15, wall=0
2024-07-10 18:25:05 | INFO | train_inner | epoch 003:   1692 / 13004 loss=6.817, nll_loss=5.746, ppl=53.66, wps=25351.1, ups=6.49, wpb=3908, bsz=133.2, num_updates=27700, lr=0.000190003, gnorm=0.853, train_wall=15, wall=0
2024-07-10 18:25:21 | INFO | train_inner | epoch 003:   1792 / 13004 loss=6.799, nll_loss=5.726, ppl=52.92, wps=25726, ups=6.59, wpb=3905.4, bsz=123.8, num_updates=27800, lr=0.000189661, gnorm=0.825, train_wall=15, wall=0
2024-07-10 18:25:36 | INFO | train_inner | epoch 003:   1892 / 13004 loss=6.812, nll_loss=5.74, ppl=53.44, wps=24771.7, ups=6.35, wpb=3899.6, bsz=122.6, num_updates=27900, lr=0.000189321, gnorm=0.828, train_wall=16, wall=0
2024-07-10 18:25:52 | INFO | train_inner | epoch 003:   1992 / 13004 loss=6.804, nll_loss=5.731, ppl=53.13, wps=25572.5, ups=6.49, wpb=3938.3, bsz=145.4, num_updates=28000, lr=0.000188982, gnorm=0.836, train_wall=15, wall=0
2024-07-10 18:25:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:25:53 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.143 | nll_loss 6.045 | ppl 66.02 | wps 96952 | wpb 3703.5 | bsz 124.5 | num_updates 28000 | best_loss 7.143
2024-07-10 18:25:53 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:25:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_28000.pt (epoch 3 @ 28000 updates, score 7.143) (writing took 4.730856781825423 seconds)
2024-07-10 18:26:13 | INFO | train_inner | epoch 003:   2092 / 13004 loss=6.805, nll_loss=5.733, ppl=53.19, wps=18384.3, ups=4.69, wpb=3920.9, bsz=138, num_updates=28100, lr=0.000188646, gnorm=0.831, train_wall=15, wall=0
2024-07-10 18:26:29 | INFO | train_inner | epoch 003:   2192 / 13004 loss=6.783, nll_loss=5.707, ppl=52.25, wps=25346.1, ups=6.44, wpb=3937.8, bsz=127.4, num_updates=28200, lr=0.000188311, gnorm=0.819, train_wall=15, wall=0
2024-07-10 18:26:44 | INFO | train_inner | epoch 003:   2292 / 13004 loss=6.817, nll_loss=5.746, ppl=53.68, wps=25008.3, ups=6.35, wpb=3939.3, bsz=148.6, num_updates=28300, lr=0.000187978, gnorm=0.868, train_wall=16, wall=0
2024-07-10 18:27:00 | INFO | train_inner | epoch 003:   2392 / 13004 loss=6.821, nll_loss=5.752, ppl=53.88, wps=25223.9, ups=6.42, wpb=3929.8, bsz=155.5, num_updates=28400, lr=0.000187647, gnorm=0.851, train_wall=15, wall=0
2024-07-10 18:27:15 | INFO | train_inner | epoch 003:   2492 / 13004 loss=6.823, nll_loss=5.753, ppl=53.91, wps=25294.8, ups=6.44, wpb=3927.9, bsz=146.6, num_updates=28500, lr=0.000187317, gnorm=0.872, train_wall=15, wall=0
2024-07-10 18:27:31 | INFO | train_inner | epoch 003:   2592 / 13004 loss=6.797, nll_loss=5.723, ppl=52.82, wps=25499, ups=6.49, wpb=3930.1, bsz=128.5, num_updates=28600, lr=0.000186989, gnorm=0.851, train_wall=15, wall=0
2024-07-10 18:27:46 | INFO | train_inner | epoch 003:   2692 / 13004 loss=6.829, nll_loss=5.76, ppl=54.18, wps=25534.9, ups=6.55, wpb=3899.7, bsz=134.3, num_updates=28700, lr=0.000186663, gnorm=0.852, train_wall=15, wall=0
2024-07-10 18:28:02 | INFO | train_inner | epoch 003:   2792 / 13004 loss=6.826, nll_loss=5.757, ppl=54.08, wps=25520, ups=6.48, wpb=3939.5, bsz=150.2, num_updates=28800, lr=0.000186339, gnorm=0.86, train_wall=15, wall=0
2024-07-10 18:28:17 | INFO | train_inner | epoch 003:   2892 / 13004 loss=6.781, nll_loss=5.705, ppl=52.15, wps=25545.9, ups=6.57, wpb=3889.9, bsz=118.1, num_updates=28900, lr=0.000186016, gnorm=0.818, train_wall=15, wall=0
2024-07-10 18:28:32 | INFO | train_inner | epoch 003:   2992 / 13004 loss=6.81, nll_loss=5.738, ppl=53.39, wps=25708.1, ups=6.59, wpb=3902.2, bsz=132.3, num_updates=29000, lr=0.000185695, gnorm=0.846, train_wall=15, wall=0
2024-07-10 18:28:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:28:33 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.113 | nll_loss 6.015 | ppl 64.65 | wps 95513 | wpb 3703.5 | bsz 124.5 | num_updates 29000 | best_loss 7.113
2024-07-10 18:28:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:28:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_29000.pt (epoch 3 @ 29000 updates, score 7.113) (writing took 4.928505519405007 seconds)
2024-07-10 18:28:53 | INFO | train_inner | epoch 003:   3092 / 13004 loss=6.818, nll_loss=5.747, ppl=53.72, wps=18284.2, ups=4.66, wpb=3922.3, bsz=146.6, num_updates=29100, lr=0.000185376, gnorm=0.855, train_wall=15, wall=0
2024-07-10 18:29:09 | INFO | train_inner | epoch 003:   3192 / 13004 loss=6.816, nll_loss=5.745, ppl=53.64, wps=25442.6, ups=6.51, wpb=3910.8, bsz=144.4, num_updates=29200, lr=0.000185058, gnorm=0.878, train_wall=15, wall=0
2024-07-10 18:29:24 | INFO | train_inner | epoch 003:   3292 / 13004 loss=6.752, nll_loss=5.672, ppl=50.99, wps=25744.8, ups=6.57, wpb=3916.9, bsz=131.1, num_updates=29300, lr=0.000184742, gnorm=0.815, train_wall=15, wall=0
2024-07-10 18:29:39 | INFO | train_inner | epoch 003:   3392 / 13004 loss=6.781, nll_loss=5.705, ppl=52.16, wps=25891.3, ups=6.61, wpb=3917.4, bsz=133.8, num_updates=29400, lr=0.000184428, gnorm=0.848, train_wall=15, wall=0
2024-07-10 18:29:54 | INFO | train_inner | epoch 003:   3492 / 13004 loss=6.757, nll_loss=5.677, ppl=51.16, wps=25708.2, ups=6.61, wpb=3888.1, bsz=121, num_updates=29500, lr=0.000184115, gnorm=0.84, train_wall=15, wall=0
2024-07-10 18:30:10 | INFO | train_inner | epoch 003:   3592 / 13004 loss=6.79, nll_loss=5.715, ppl=52.54, wps=25652.5, ups=6.56, wpb=3912.2, bsz=127.4, num_updates=29600, lr=0.000183804, gnorm=0.836, train_wall=15, wall=0
2024-07-10 18:30:25 | INFO | train_inner | epoch 003:   3692 / 13004 loss=6.78, nll_loss=5.704, ppl=52.14, wps=25586.9, ups=6.55, wpb=3907.7, bsz=121.7, num_updates=29700, lr=0.000183494, gnorm=0.818, train_wall=15, wall=0
2024-07-10 18:30:40 | INFO | train_inner | epoch 003:   3792 / 13004 loss=6.767, nll_loss=5.689, ppl=51.61, wps=25691.4, ups=6.54, wpb=3929.4, bsz=135, num_updates=29800, lr=0.000183186, gnorm=0.83, train_wall=15, wall=0
2024-07-10 18:30:55 | INFO | train_inner | epoch 003:   3892 / 13004 loss=6.805, nll_loss=5.732, ppl=53.16, wps=25913.1, ups=6.57, wpb=3943.7, bsz=126, num_updates=29900, lr=0.000182879, gnorm=0.842, train_wall=15, wall=0
2024-07-10 18:31:11 | INFO | train_inner | epoch 003:   3992 / 13004 loss=6.802, nll_loss=5.729, ppl=53.05, wps=25385.6, ups=6.5, wpb=3906.1, bsz=122, num_updates=30000, lr=0.000182574, gnorm=0.839, train_wall=15, wall=0
2024-07-10 18:31:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:31:12 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.124 | nll_loss 6.024 | ppl 65.06 | wps 94980.1 | wpb 3703.5 | bsz 124.5 | num_updates 30000 | best_loss 7.113
2024-07-10 18:31:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:31:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_30000.pt (epoch 3 @ 30000 updates, score 7.124) (writing took 3.0017395364120603 seconds)
2024-07-10 18:31:30 | INFO | train_inner | epoch 003:   4092 / 13004 loss=6.837, nll_loss=5.768, ppl=54.5, wps=20143, ups=5.17, wpb=3899.8, bsz=132.6, num_updates=30100, lr=0.000182271, gnorm=0.885, train_wall=15, wall=0
2024-07-10 18:31:45 | INFO | train_inner | epoch 003:   4192 / 13004 loss=6.759, nll_loss=5.681, ppl=51.3, wps=25611.4, ups=6.49, wpb=3943.8, bsz=148.6, num_updates=30200, lr=0.000181969, gnorm=0.822, train_wall=15, wall=0
2024-07-10 18:32:01 | INFO | train_inner | epoch 003:   4292 / 13004 loss=6.767, nll_loss=5.689, ppl=51.6, wps=25617.4, ups=6.56, wpb=3903.7, bsz=124.6, num_updates=30300, lr=0.000181668, gnorm=0.843, train_wall=15, wall=0
2024-07-10 18:32:16 | INFO | train_inner | epoch 003:   4392 / 13004 loss=6.781, nll_loss=5.705, ppl=52.17, wps=25617.1, ups=6.56, wpb=3908, bsz=127.8, num_updates=30400, lr=0.000181369, gnorm=0.856, train_wall=15, wall=0
2024-07-10 18:32:31 | INFO | train_inner | epoch 003:   4492 / 13004 loss=6.746, nll_loss=5.666, ppl=50.76, wps=25583.8, ups=6.5, wpb=3937.8, bsz=129.5, num_updates=30500, lr=0.000181071, gnorm=0.831, train_wall=15, wall=0
2024-07-10 18:32:47 | INFO | train_inner | epoch 003:   4592 / 13004 loss=6.767, nll_loss=5.689, ppl=51.58, wps=25259.2, ups=6.44, wpb=3923.8, bsz=127.9, num_updates=30600, lr=0.000180775, gnorm=0.843, train_wall=15, wall=0
2024-07-10 18:33:02 | INFO | train_inner | epoch 003:   4692 / 13004 loss=6.762, nll_loss=5.683, ppl=51.36, wps=25669.8, ups=6.53, wpb=3933, bsz=123.9, num_updates=30700, lr=0.000180481, gnorm=0.83, train_wall=15, wall=0
2024-07-10 18:33:18 | INFO | train_inner | epoch 003:   4792 / 13004 loss=6.779, nll_loss=5.703, ppl=52.11, wps=25697.6, ups=6.52, wpb=3940.2, bsz=149.1, num_updates=30800, lr=0.000180187, gnorm=0.832, train_wall=15, wall=0
2024-07-10 18:33:33 | INFO | train_inner | epoch 003:   4892 / 13004 loss=6.731, nll_loss=5.648, ppl=50.15, wps=25471.1, ups=6.48, wpb=3932, bsz=130, num_updates=30900, lr=0.000179896, gnorm=0.829, train_wall=15, wall=0
2024-07-10 18:33:48 | INFO | train_inner | epoch 003:   4992 / 13004 loss=6.808, nll_loss=5.736, ppl=53.28, wps=25859.9, ups=6.62, wpb=3905.4, bsz=131, num_updates=31000, lr=0.000179605, gnorm=0.849, train_wall=15, wall=0
2024-07-10 18:33:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:33:49 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.115 | nll_loss 6.011 | ppl 64.49 | wps 97344.7 | wpb 3703.5 | bsz 124.5 | num_updates 31000 | best_loss 7.113
2024-07-10 18:33:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:33:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_31000.pt (epoch 3 @ 31000 updates, score 7.115) (writing took 3.1192560754716396 seconds)
2024-07-10 18:34:08 | INFO | train_inner | epoch 003:   5092 / 13004 loss=6.729, nll_loss=5.646, ppl=50.08, wps=20076.7, ups=5.13, wpb=3913.3, bsz=122.7, num_updates=31100, lr=0.000179316, gnorm=0.822, train_wall=15, wall=0
2024-07-10 18:34:23 | INFO | train_inner | epoch 003:   5192 / 13004 loss=6.776, nll_loss=5.699, ppl=51.95, wps=25477.4, ups=6.53, wpb=3903.3, bsz=128.2, num_updates=31200, lr=0.000179029, gnorm=0.869, train_wall=15, wall=0
2024-07-10 18:34:38 | INFO | train_inner | epoch 003:   5292 / 13004 loss=6.76, nll_loss=5.681, ppl=51.29, wps=25616.7, ups=6.51, wpb=3933, bsz=121.7, num_updates=31300, lr=0.000178743, gnorm=0.836, train_wall=15, wall=0
2024-07-10 18:34:53 | INFO | train_inner | epoch 003:   5392 / 13004 loss=6.788, nll_loss=5.714, ppl=52.48, wps=25827.2, ups=6.58, wpb=3924.5, bsz=133.5, num_updates=31400, lr=0.000178458, gnorm=0.87, train_wall=15, wall=0
2024-07-10 18:35:09 | INFO | train_inner | epoch 003:   5492 / 13004 loss=6.806, nll_loss=5.733, ppl=53.19, wps=25569.9, ups=6.57, wpb=3889.3, bsz=125.9, num_updates=31500, lr=0.000178174, gnorm=0.855, train_wall=15, wall=0
2024-07-10 18:35:24 | INFO | train_inner | epoch 003:   5592 / 13004 loss=6.768, nll_loss=5.69, ppl=51.64, wps=25811.4, ups=6.56, wpb=3931.7, bsz=136.3, num_updates=31600, lr=0.000177892, gnorm=0.83, train_wall=15, wall=0
2024-07-10 18:35:39 | INFO | train_inner | epoch 003:   5692 / 13004 loss=6.723, nll_loss=5.639, ppl=49.83, wps=25730.8, ups=6.55, wpb=3929.1, bsz=138.4, num_updates=31700, lr=0.000177611, gnorm=0.829, train_wall=15, wall=0
2024-07-10 18:35:54 | INFO | train_inner | epoch 003:   5792 / 13004 loss=6.762, nll_loss=5.683, ppl=51.37, wps=25526.6, ups=6.53, wpb=3906.2, bsz=117.5, num_updates=31800, lr=0.000177332, gnorm=0.837, train_wall=15, wall=0
2024-07-10 18:36:10 | INFO | train_inner | epoch 003:   5892 / 13004 loss=6.791, nll_loss=5.717, ppl=52.59, wps=25601.1, ups=6.56, wpb=3900.4, bsz=135.9, num_updates=31900, lr=0.000177054, gnorm=0.873, train_wall=15, wall=0
2024-07-10 18:36:25 | INFO | train_inner | epoch 003:   5992 / 13004 loss=6.762, nll_loss=5.684, ppl=51.41, wps=25655.7, ups=6.53, wpb=3929.9, bsz=130.3, num_updates=32000, lr=0.000176777, gnorm=0.832, train_wall=15, wall=0
2024-07-10 18:36:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:36:26 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.107 | nll_loss 6.002 | ppl 64.1 | wps 95379 | wpb 3703.5 | bsz 124.5 | num_updates 32000 | best_loss 7.107
2024-07-10 18:36:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:36:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_32000.pt (epoch 3 @ 32000 updates, score 7.107) (writing took 8.654725149273872 seconds)
2024-07-10 18:36:50 | INFO | train_inner | epoch 003:   6092 / 13004 loss=6.769, nll_loss=5.691, ppl=51.65, wps=15694.3, ups=3.97, wpb=3953.8, bsz=143.4, num_updates=32100, lr=0.000176501, gnorm=0.879, train_wall=15, wall=0
2024-07-10 18:37:06 | INFO | train_inner | epoch 003:   6192 / 13004 loss=6.822, nll_loss=5.752, ppl=53.89, wps=25567.5, ups=6.51, wpb=3924.9, bsz=138.4, num_updates=32200, lr=0.000176227, gnorm=0.872, train_wall=15, wall=0
2024-07-10 18:37:21 | INFO | train_inner | epoch 003:   6292 / 13004 loss=6.759, nll_loss=5.681, ppl=51.32, wps=25546.1, ups=6.47, wpb=3948.8, bsz=154.8, num_updates=32300, lr=0.000175954, gnorm=0.838, train_wall=15, wall=0
2024-07-10 18:37:36 | INFO | train_inner | epoch 003:   6392 / 13004 loss=6.761, nll_loss=5.682, ppl=51.36, wps=25723.3, ups=6.56, wpb=3924.2, bsz=140.7, num_updates=32400, lr=0.000175682, gnorm=0.861, train_wall=15, wall=0
2024-07-10 18:37:51 | INFO | train_inner | epoch 003:   6492 / 13004 loss=6.788, nll_loss=5.713, ppl=52.46, wps=25679.6, ups=6.58, wpb=3905.4, bsz=134.2, num_updates=32500, lr=0.000175412, gnorm=0.864, train_wall=15, wall=0
2024-07-10 18:38:07 | INFO | train_inner | epoch 003:   6592 / 13004 loss=6.769, nll_loss=5.691, ppl=51.67, wps=25637, ups=6.55, wpb=3915.1, bsz=120.7, num_updates=32600, lr=0.000175142, gnorm=0.834, train_wall=15, wall=0
2024-07-10 18:38:22 | INFO | train_inner | epoch 003:   6692 / 13004 loss=6.768, nll_loss=5.69, ppl=51.64, wps=25707.3, ups=6.54, wpb=3932, bsz=145, num_updates=32700, lr=0.000174874, gnorm=0.841, train_wall=15, wall=0
2024-07-10 18:38:37 | INFO | train_inner | epoch 003:   6792 / 13004 loss=6.778, nll_loss=5.702, ppl=52.05, wps=25729.8, ups=6.49, wpb=3961.8, bsz=159, num_updates=32800, lr=0.000174608, gnorm=0.862, train_wall=15, wall=0
2024-07-10 18:38:53 | INFO | train_inner | epoch 003:   6892 / 13004 loss=6.775, nll_loss=5.698, ppl=51.92, wps=25580.2, ups=6.52, wpb=3921.4, bsz=131.7, num_updates=32900, lr=0.000174342, gnorm=0.841, train_wall=15, wall=0
2024-07-10 18:39:08 | INFO | train_inner | epoch 003:   6992 / 13004 loss=6.746, nll_loss=5.665, ppl=50.75, wps=25807.4, ups=6.61, wpb=3904.7, bsz=134.6, num_updates=33000, lr=0.000174078, gnorm=0.838, train_wall=15, wall=0
2024-07-10 18:39:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:39:09 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.101 | nll_loss 5.995 | ppl 63.79 | wps 96348.8 | wpb 3703.5 | bsz 124.5 | num_updates 33000 | best_loss 7.101
2024-07-10 18:39:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:39:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_33000.pt (epoch 3 @ 33000 updates, score 7.101) (writing took 4.760920944623649 seconds)
2024-07-10 18:39:29 | INFO | train_inner | epoch 003:   7092 / 13004 loss=6.739, nll_loss=5.657, ppl=50.45, wps=18430.7, ups=4.7, wpb=3918.6, bsz=127.3, num_updates=33100, lr=0.000173814, gnorm=0.83, train_wall=15, wall=0
2024-07-10 18:39:44 | INFO | train_inner | epoch 003:   7192 / 13004 loss=6.726, nll_loss=5.642, ppl=49.95, wps=25548.9, ups=6.53, wpb=3910.5, bsz=122.6, num_updates=33200, lr=0.000173553, gnorm=0.836, train_wall=15, wall=0
2024-07-10 18:40:00 | INFO | train_inner | epoch 003:   7292 / 13004 loss=6.787, nll_loss=5.712, ppl=52.41, wps=25564.4, ups=6.51, wpb=3928.2, bsz=146.2, num_updates=33300, lr=0.000173292, gnorm=0.872, train_wall=15, wall=0
2024-07-10 18:40:15 | INFO | train_inner | epoch 003:   7392 / 13004 loss=6.756, nll_loss=5.677, ppl=51.18, wps=25793, ups=6.56, wpb=3931.8, bsz=146.8, num_updates=33400, lr=0.000173032, gnorm=0.842, train_wall=15, wall=0
2024-07-10 18:40:30 | INFO | train_inner | epoch 003:   7492 / 13004 loss=6.759, nll_loss=5.68, ppl=51.28, wps=25952.3, ups=6.58, wpb=3943, bsz=136.7, num_updates=33500, lr=0.000172774, gnorm=0.829, train_wall=15, wall=0
2024-07-10 18:40:46 | INFO | train_inner | epoch 003:   7592 / 13004 loss=6.764, nll_loss=5.686, ppl=51.47, wps=25683.2, ups=6.54, wpb=3927.4, bsz=135.8, num_updates=33600, lr=0.000172516, gnorm=0.855, train_wall=15, wall=0
2024-07-10 18:41:01 | INFO | train_inner | epoch 003:   7692 / 13004 loss=6.756, nll_loss=5.677, ppl=51.17, wps=25650.3, ups=6.55, wpb=3913.3, bsz=122.2, num_updates=33700, lr=0.00017226, gnorm=0.848, train_wall=15, wall=0
2024-07-10 18:41:16 | INFO | train_inner | epoch 003:   7792 / 13004 loss=6.741, nll_loss=5.659, ppl=50.54, wps=25841.9, ups=6.57, wpb=3936.2, bsz=120.4, num_updates=33800, lr=0.000172005, gnorm=0.833, train_wall=15, wall=0
2024-07-10 18:41:31 | INFO | train_inner | epoch 003:   7892 / 13004 loss=6.684, nll_loss=5.595, ppl=48.33, wps=25781.9, ups=6.56, wpb=3928, bsz=138.9, num_updates=33900, lr=0.000171751, gnorm=0.825, train_wall=15, wall=0
2024-07-10 18:41:47 | INFO | train_inner | epoch 003:   7992 / 13004 loss=6.732, nll_loss=5.65, ppl=50.2, wps=25673.9, ups=6.53, wpb=3929.2, bsz=138.2, num_updates=34000, lr=0.000171499, gnorm=0.842, train_wall=15, wall=0
2024-07-10 18:41:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:41:48 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.094 | nll_loss 5.988 | ppl 63.46 | wps 96317.2 | wpb 3703.5 | bsz 124.5 | num_updates 34000 | best_loss 7.094
2024-07-10 18:41:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:41:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_34000.pt (epoch 3 @ 34000 updates, score 7.094) (writing took 4.912961741909385 seconds)
2024-07-10 18:42:08 | INFO | train_inner | epoch 003:   8092 / 13004 loss=6.763, nll_loss=5.684, ppl=51.43, wps=18217, ups=4.68, wpb=3889.4, bsz=133.4, num_updates=34100, lr=0.000171247, gnorm=0.875, train_wall=15, wall=0
2024-07-10 18:42:23 | INFO | train_inner | epoch 003:   8192 / 13004 loss=6.741, nll_loss=5.66, ppl=50.55, wps=25558.2, ups=6.53, wpb=3914.4, bsz=123.8, num_updates=34200, lr=0.000170996, gnorm=0.839, train_wall=15, wall=0
2024-07-10 18:42:39 | INFO | train_inner | epoch 003:   8292 / 13004 loss=6.704, nll_loss=5.616, ppl=49.06, wps=25633.2, ups=6.56, wpb=3909, bsz=112.8, num_updates=34300, lr=0.000170747, gnorm=0.828, train_wall=15, wall=0
2024-07-10 18:42:54 | INFO | train_inner | epoch 003:   8392 / 13004 loss=6.738, nll_loss=5.656, ppl=50.42, wps=25667.3, ups=6.54, wpb=3924.1, bsz=136.1, num_updates=34400, lr=0.000170499, gnorm=0.86, train_wall=15, wall=0
2024-07-10 18:43:09 | INFO | train_inner | epoch 003:   8492 / 13004 loss=6.814, nll_loss=5.743, ppl=53.55, wps=25794.3, ups=6.58, wpb=3922.2, bsz=147.1, num_updates=34500, lr=0.000170251, gnorm=0.894, train_wall=15, wall=0
2024-07-10 18:43:24 | INFO | train_inner | epoch 003:   8592 / 13004 loss=6.753, nll_loss=5.674, ppl=51.05, wps=25624.7, ups=6.51, wpb=3934.3, bsz=133.1, num_updates=34600, lr=0.000170005, gnorm=0.846, train_wall=15, wall=0
2024-07-10 18:43:40 | INFO | train_inner | epoch 003:   8692 / 13004 loss=6.762, nll_loss=5.683, ppl=51.37, wps=25649.4, ups=6.58, wpb=3900.1, bsz=133.9, num_updates=34700, lr=0.00016976, gnorm=0.863, train_wall=15, wall=0
2024-07-10 18:43:55 | INFO | train_inner | epoch 003:   8792 / 13004 loss=6.724, nll_loss=5.641, ppl=49.88, wps=25575, ups=6.54, wpb=3908.5, bsz=130.3, num_updates=34800, lr=0.000169516, gnorm=0.854, train_wall=15, wall=0
2024-07-10 18:44:10 | INFO | train_inner | epoch 003:   8892 / 13004 loss=6.787, nll_loss=5.711, ppl=52.4, wps=25425.2, ups=6.51, wpb=3903, bsz=133.8, num_updates=34900, lr=0.000169273, gnorm=0.882, train_wall=15, wall=0
2024-07-10 18:44:25 | INFO | train_inner | epoch 003:   8992 / 13004 loss=6.729, nll_loss=5.646, ppl=50.07, wps=25624.6, ups=6.57, wpb=3902.8, bsz=119.4, num_updates=35000, lr=0.000169031, gnorm=0.843, train_wall=15, wall=0
2024-07-10 18:44:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:44:27 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.09 | nll_loss 5.979 | ppl 63.09 | wps 96200.9 | wpb 3703.5 | bsz 124.5 | num_updates 35000 | best_loss 7.09
2024-07-10 18:44:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:44:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_35000.pt (epoch 3 @ 35000 updates, score 7.09) (writing took 4.5084372675046325 seconds)
2024-07-10 18:44:46 | INFO | train_inner | epoch 003:   9092 / 13004 loss=6.759, nll_loss=5.68, ppl=51.27, wps=18752.6, ups=4.8, wpb=3910, bsz=127, num_updates=35100, lr=0.00016879, gnorm=0.85, train_wall=15, wall=0
2024-07-10 18:45:02 | INFO | train_inner | epoch 003:   9192 / 13004 loss=6.718, nll_loss=5.633, ppl=49.62, wps=25866.4, ups=6.55, wpb=3948.3, bsz=130.6, num_updates=35200, lr=0.00016855, gnorm=0.832, train_wall=15, wall=0
2024-07-10 18:45:17 | INFO | train_inner | epoch 003:   9292 / 13004 loss=6.801, nll_loss=5.728, ppl=53, wps=25695.4, ups=6.58, wpb=3906.4, bsz=127.1, num_updates=35300, lr=0.000168311, gnorm=0.879, train_wall=15, wall=0
2024-07-10 18:45:32 | INFO | train_inner | epoch 003:   9392 / 13004 loss=6.771, nll_loss=5.694, ppl=51.76, wps=25500.9, ups=6.54, wpb=3898.5, bsz=142.7, num_updates=35400, lr=0.000168073, gnorm=0.883, train_wall=15, wall=0
2024-07-10 18:45:47 | INFO | train_inner | epoch 003:   9492 / 13004 loss=6.738, nll_loss=5.656, ppl=50.44, wps=25679.9, ups=6.54, wpb=3927.2, bsz=125.7, num_updates=35500, lr=0.000167836, gnorm=0.832, train_wall=15, wall=0
2024-07-10 18:46:02 | INFO | train_inner | epoch 003:   9592 / 13004 loss=6.725, nll_loss=5.64, ppl=49.87, wps=25729.7, ups=6.6, wpb=3901.1, bsz=107.8, num_updates=35600, lr=0.0001676, gnorm=0.841, train_wall=15, wall=0
2024-07-10 18:46:18 | INFO | train_inner | epoch 003:   9692 / 13004 loss=6.738, nll_loss=5.655, ppl=50.4, wps=25733.1, ups=6.57, wpb=3916, bsz=130.1, num_updates=35700, lr=0.000167365, gnorm=0.859, train_wall=15, wall=0
2024-07-10 18:46:33 | INFO | train_inner | epoch 003:   9792 / 13004 loss=6.722, nll_loss=5.637, ppl=49.77, wps=25619, ups=6.51, wpb=3934.6, bsz=131.1, num_updates=35800, lr=0.000167132, gnorm=0.838, train_wall=15, wall=0
2024-07-10 18:46:48 | INFO | train_inner | epoch 003:   9892 / 13004 loss=6.769, nll_loss=5.69, ppl=51.64, wps=25635.6, ups=6.56, wpb=3909.3, bsz=113.5, num_updates=35900, lr=0.000166899, gnorm=0.852, train_wall=15, wall=0
2024-07-10 18:47:04 | INFO | train_inner | epoch 003:   9992 / 13004 loss=6.772, nll_loss=5.695, ppl=51.81, wps=25771, ups=6.58, wpb=3916.7, bsz=134.5, num_updates=36000, lr=0.000166667, gnorm=0.886, train_wall=15, wall=0
2024-07-10 18:47:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:47:05 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.081 | nll_loss 5.974 | ppl 62.86 | wps 95165.5 | wpb 3703.5 | bsz 124.5 | num_updates 36000 | best_loss 7.081
2024-07-10 18:47:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:47:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_36000.pt (epoch 3 @ 36000 updates, score 7.081) (writing took 4.700836033560336 seconds)
2024-07-10 18:47:25 | INFO | train_inner | epoch 003:  10092 / 13004 loss=6.778, nll_loss=5.701, ppl=52.03, wps=18596.2, ups=4.71, wpb=3947.8, bsz=141.3, num_updates=36100, lr=0.000166436, gnorm=0.859, train_wall=15, wall=0
2024-07-10 18:47:40 | INFO | train_inner | epoch 003:  10192 / 13004 loss=6.73, nll_loss=5.647, ppl=50.12, wps=25742, ups=6.58, wpb=3910.3, bsz=125.4, num_updates=36200, lr=0.000166206, gnorm=0.839, train_wall=15, wall=0
2024-07-10 18:47:55 | INFO | train_inner | epoch 003:  10292 / 13004 loss=6.707, nll_loss=5.622, ppl=49.25, wps=25822.3, ups=6.55, wpb=3945.1, bsz=158.1, num_updates=36300, lr=0.000165977, gnorm=0.838, train_wall=15, wall=0
2024-07-10 18:48:11 | INFO | train_inner | epoch 003:  10392 / 13004 loss=6.726, nll_loss=5.643, ppl=49.96, wps=25630.3, ups=6.54, wpb=3920.4, bsz=126.6, num_updates=36400, lr=0.000165748, gnorm=0.842, train_wall=15, wall=0
2024-07-10 18:48:26 | INFO | train_inner | epoch 003:  10492 / 13004 loss=6.73, nll_loss=5.647, ppl=50.12, wps=25912.5, ups=6.6, wpb=3924.1, bsz=129, num_updates=36500, lr=0.000165521, gnorm=0.842, train_wall=15, wall=0
2024-07-10 18:48:41 | INFO | train_inner | epoch 003:  10592 / 13004 loss=6.71, nll_loss=5.623, ppl=49.3, wps=25902.5, ups=6.6, wpb=3924, bsz=123.9, num_updates=36600, lr=0.000165295, gnorm=0.844, train_wall=15, wall=0
2024-07-10 18:48:56 | INFO | train_inner | epoch 003:  10692 / 13004 loss=6.742, nll_loss=5.66, ppl=50.58, wps=25710.7, ups=6.57, wpb=3916.2, bsz=133, num_updates=36700, lr=0.00016507, gnorm=0.872, train_wall=15, wall=0
2024-07-10 18:49:11 | INFO | train_inner | epoch 003:  10792 / 13004 loss=6.726, nll_loss=5.642, ppl=49.95, wps=25764.2, ups=6.56, wpb=3925.7, bsz=136.5, num_updates=36800, lr=0.000164845, gnorm=0.851, train_wall=15, wall=0
2024-07-10 18:49:27 | INFO | train_inner | epoch 003:  10892 / 13004 loss=6.691, nll_loss=5.603, ppl=48.6, wps=25658.1, ups=6.56, wpb=3911.8, bsz=125.4, num_updates=36900, lr=0.000164622, gnorm=0.838, train_wall=15, wall=0
2024-07-10 18:49:42 | INFO | train_inner | epoch 003:  10992 / 13004 loss=6.748, nll_loss=5.668, ppl=50.83, wps=25501.9, ups=6.54, wpb=3898.9, bsz=129.4, num_updates=37000, lr=0.000164399, gnorm=0.877, train_wall=15, wall=0
2024-07-10 18:49:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:49:43 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.074 | nll_loss 5.968 | ppl 62.57 | wps 95244.8 | wpb 3703.5 | bsz 124.5 | num_updates 37000 | best_loss 7.074
2024-07-10 18:49:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:49:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_37000.pt (epoch 3 @ 37000 updates, score 7.074) (writing took 6.7599283484742045 seconds)
2024-07-10 18:50:05 | INFO | train_inner | epoch 003:  11092 / 13004 loss=6.731, nll_loss=5.648, ppl=50.14, wps=16788.5, ups=4.27, wpb=3936.2, bsz=126.2, num_updates=37100, lr=0.000164177, gnorm=0.845, train_wall=15, wall=0
2024-07-10 18:50:21 | INFO | train_inner | epoch 003:  11192 / 13004 loss=6.713, nll_loss=5.628, ppl=49.46, wps=25689, ups=6.53, wpb=3934.2, bsz=137.5, num_updates=37200, lr=0.000163956, gnorm=0.837, train_wall=15, wall=0
2024-07-10 18:50:36 | INFO | train_inner | epoch 003:  11292 / 13004 loss=6.787, nll_loss=5.712, ppl=52.42, wps=25761.8, ups=6.54, wpb=3936.6, bsz=151.8, num_updates=37300, lr=0.000163737, gnorm=0.895, train_wall=15, wall=0
2024-07-10 18:50:51 | INFO | train_inner | epoch 003:  11392 / 13004 loss=6.736, nll_loss=5.654, ppl=50.36, wps=25825.7, ups=6.61, wpb=3906.2, bsz=120.5, num_updates=37400, lr=0.000163517, gnorm=0.851, train_wall=15, wall=0
2024-07-10 18:51:06 | INFO | train_inner | epoch 003:  11492 / 13004 loss=6.757, nll_loss=5.678, ppl=51.21, wps=25685, ups=6.56, wpb=3914, bsz=145.8, num_updates=37500, lr=0.000163299, gnorm=0.883, train_wall=15, wall=0
2024-07-10 18:51:21 | INFO | train_inner | epoch 003:  11592 / 13004 loss=6.737, nll_loss=5.655, ppl=50.4, wps=25752.7, ups=6.58, wpb=3911.8, bsz=122.9, num_updates=37600, lr=0.000163082, gnorm=0.848, train_wall=15, wall=0
2024-07-10 18:51:37 | INFO | train_inner | epoch 003:  11692 / 13004 loss=6.725, nll_loss=5.641, ppl=49.89, wps=25774.7, ups=6.61, wpb=3896.7, bsz=118.5, num_updates=37700, lr=0.000162866, gnorm=0.857, train_wall=15, wall=0
2024-07-10 18:51:52 | INFO | train_inner | epoch 003:  11792 / 13004 loss=6.728, nll_loss=5.645, ppl=50.04, wps=25443.7, ups=6.5, wpb=3913.8, bsz=151.9, num_updates=37800, lr=0.00016265, gnorm=0.879, train_wall=15, wall=0
2024-07-10 18:52:07 | INFO | train_inner | epoch 003:  11892 / 13004 loss=6.738, nll_loss=5.657, ppl=50.44, wps=25534.9, ups=6.54, wpb=3907.3, bsz=132.9, num_updates=37900, lr=0.000162435, gnorm=0.86, train_wall=15, wall=0
2024-07-10 18:52:23 | INFO | train_inner | epoch 003:  11992 / 13004 loss=6.71, nll_loss=5.624, ppl=49.33, wps=25552.5, ups=6.54, wpb=3906.5, bsz=117.1, num_updates=38000, lr=0.000162221, gnorm=0.842, train_wall=15, wall=0
2024-07-10 18:52:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:52:24 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.063 | nll_loss 5.954 | ppl 61.97 | wps 93076.6 | wpb 3703.5 | bsz 124.5 | num_updates 38000 | best_loss 7.063
2024-07-10 18:52:24 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:52:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_38000.pt (epoch 3 @ 38000 updates, score 7.063) (writing took 7.5661819614470005 seconds)
2024-07-10 18:52:47 | INFO | train_inner | epoch 003:  12092 / 13004 loss=6.71, nll_loss=5.625, ppl=49.34, wps=16368.6, ups=4.14, wpb=3955.7, bsz=145.8, num_updates=38100, lr=0.000162008, gnorm=0.85, train_wall=15, wall=0
2024-07-10 18:53:02 | INFO | train_inner | epoch 003:  12192 / 13004 loss=6.718, nll_loss=5.633, ppl=49.62, wps=25722.9, ups=6.52, wpb=3942.4, bsz=133.9, num_updates=38200, lr=0.000161796, gnorm=0.929, train_wall=15, wall=0
2024-07-10 18:53:17 | INFO | train_inner | epoch 003:  12292 / 13004 loss=6.729, nll_loss=5.646, ppl=50.09, wps=25662.1, ups=6.55, wpb=3916.2, bsz=157, num_updates=38300, lr=0.000161585, gnorm=0.875, train_wall=15, wall=0
2024-07-10 18:53:32 | INFO | train_inner | epoch 003:  12392 / 13004 loss=6.718, nll_loss=5.633, ppl=49.61, wps=25711.6, ups=6.6, wpb=3893.6, bsz=121.3, num_updates=38400, lr=0.000161374, gnorm=0.865, train_wall=15, wall=0
2024-07-10 18:53:48 | INFO | train_inner | epoch 003:  12492 / 13004 loss=6.757, nll_loss=5.678, ppl=51.2, wps=25271.6, ups=6.43, wpb=3929.7, bsz=140.2, num_updates=38500, lr=0.000161165, gnorm=0.913, train_wall=15, wall=0
2024-07-10 18:54:03 | INFO | train_inner | epoch 003:  12592 / 13004 loss=6.701, nll_loss=5.614, ppl=48.97, wps=25593.9, ups=6.53, wpb=3917.6, bsz=133.5, num_updates=38600, lr=0.000160956, gnorm=0.843, train_wall=15, wall=0
2024-07-10 18:54:19 | INFO | train_inner | epoch 003:  12692 / 13004 loss=6.764, nll_loss=5.686, ppl=51.47, wps=25534, ups=6.54, wpb=3904.3, bsz=139.4, num_updates=38700, lr=0.000160748, gnorm=0.895, train_wall=15, wall=0
2024-07-10 18:54:34 | INFO | train_inner | epoch 003:  12792 / 13004 loss=6.679, nll_loss=5.589, ppl=48.13, wps=25767.6, ups=6.55, wpb=3934.7, bsz=126.3, num_updates=38800, lr=0.00016054, gnorm=0.831, train_wall=15, wall=0
2024-07-10 18:54:49 | INFO | train_inner | epoch 003:  12892 / 13004 loss=6.675, nll_loss=5.585, ppl=47.99, wps=25689.3, ups=6.56, wpb=3917.2, bsz=124.2, num_updates=38900, lr=0.000160334, gnorm=0.834, train_wall=15, wall=0
2024-07-10 18:55:04 | INFO | train_inner | epoch 003:  12992 / 13004 loss=6.711, nll_loss=5.624, ppl=49.33, wps=25762.5, ups=6.59, wpb=3910.3, bsz=129.2, num_updates=39000, lr=0.000160128, gnorm=0.851, train_wall=15, wall=0
2024-07-10 18:55:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:55:05 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.064 | nll_loss 5.951 | ppl 61.87 | wps 91549.7 | wpb 3703.5 | bsz 124.5 | num_updates 39000 | best_loss 7.063
2024-07-10 18:55:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:55:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_39000.pt (epoch 3 @ 39000 updates, score 7.064) (writing took 4.021186248399317 seconds)
2024-07-10 18:55:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:55:12 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.057 | nll_loss 5.947 | ppl 61.68 | wps 95842.6 | wpb 3703.5 | bsz 124.5 | num_updates 39012 | best_loss 7.057
2024-07-10 18:55:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:55:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_best.pt (epoch 3 @ 39012 updates, score 7.057) (writing took 6.239217785187066 seconds)
2024-07-10 18:55:19 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2024-07-10 18:55:19 | INFO | train | epoch 003 | loss 6.765 | nll_loss 5.687 | ppl 51.52 | wps 24496.4 | ups 6.25 | wpb 3919.8 | bsz 133.2 | num_updates 39012 | lr 0.000160104 | gnorm 0.849 | train_wall 1969 | wall 0
2024-07-10 18:55:19 | INFO | fairseq.trainer | begin training epoch 4
2024-07-10 18:55:32 | INFO | train_inner | epoch 004:     88 / 13004 loss=6.679, nll_loss=5.589, ppl=48.14, wps=13874.2, ups=3.55, wpb=3906.6, bsz=131, num_updates=39100, lr=0.000159923, gnorm=0.855, train_wall=15, wall=0
2024-07-10 18:55:48 | INFO | train_inner | epoch 004:    188 / 13004 loss=6.724, nll_loss=5.64, ppl=49.86, wps=25538.2, ups=6.54, wpb=3905.4, bsz=137.1, num_updates=39200, lr=0.000159719, gnorm=0.889, train_wall=15, wall=0
2024-07-10 18:56:03 | INFO | train_inner | epoch 004:    288 / 13004 loss=6.761, nll_loss=5.683, ppl=51.37, wps=25487.9, ups=6.56, wpb=3887.9, bsz=146.2, num_updates=39300, lr=0.000159516, gnorm=0.905, train_wall=15, wall=0
2024-07-10 18:56:18 | INFO | train_inner | epoch 004:    388 / 13004 loss=6.672, nll_loss=5.58, ppl=47.84, wps=25698, ups=6.51, wpb=3950.1, bsz=144.1, num_updates=39400, lr=0.000159313, gnorm=0.841, train_wall=15, wall=0
2024-07-10 18:56:33 | INFO | train_inner | epoch 004:    488 / 13004 loss=6.714, nll_loss=5.628, ppl=49.44, wps=25838, ups=6.63, wpb=3899.7, bsz=122.3, num_updates=39500, lr=0.000159111, gnorm=0.913, train_wall=15, wall=0
2024-07-10 18:56:49 | INFO | train_inner | epoch 004:    588 / 13004 loss=6.722, nll_loss=5.638, ppl=49.81, wps=25587.3, ups=6.55, wpb=3909.1, bsz=151.9, num_updates=39600, lr=0.00015891, gnorm=0.892, train_wall=15, wall=0
2024-07-10 18:57:04 | INFO | train_inner | epoch 004:    688 / 13004 loss=6.665, nll_loss=5.573, ppl=47.6, wps=25592.3, ups=6.46, wpb=3962, bsz=147.8, num_updates=39700, lr=0.00015871, gnorm=0.851, train_wall=15, wall=0
2024-07-10 18:57:20 | INFO | train_inner | epoch 004:    788 / 13004 loss=6.651, nll_loss=5.557, ppl=47.09, wps=25551, ups=6.51, wpb=3921.9, bsz=129.8, num_updates=39800, lr=0.000158511, gnorm=0.833, train_wall=15, wall=0
2024-07-10 18:57:35 | INFO | train_inner | epoch 004:    888 / 13004 loss=6.687, nll_loss=5.596, ppl=48.38, wps=25707.9, ups=6.61, wpb=3891.6, bsz=119, num_updates=39900, lr=0.000158312, gnorm=0.864, train_wall=15, wall=0
2024-07-10 18:57:50 | INFO | train_inner | epoch 004:    988 / 13004 loss=6.668, nll_loss=5.576, ppl=47.69, wps=25757.5, ups=6.56, wpb=3928.9, bsz=130.2, num_updates=40000, lr=0.000158114, gnorm=0.849, train_wall=15, wall=0
2024-07-10 18:57:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 18:57:51 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.049 | nll_loss 5.937 | ppl 61.28 | wps 94334.6 | wpb 3703.5 | bsz 124.5 | num_updates 40000 | best_loss 7.049
2024-07-10 18:57:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 18:57:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_40000.pt (epoch 4 @ 40000 updates, score 7.049) (writing took 8.180282349698246 seconds)
2024-07-10 18:58:15 | INFO | train_inner | epoch 004:   1088 / 13004 loss=6.731, nll_loss=5.648, ppl=50.16, wps=15769.3, ups=4.06, wpb=3883.9, bsz=133.3, num_updates=40100, lr=0.000157917, gnorm=0.926, train_wall=15, wall=0
2024-07-10 18:58:30 | INFO | train_inner | epoch 004:   1188 / 13004 loss=6.754, nll_loss=5.674, ppl=51.05, wps=26009.3, ups=6.65, wpb=3913.7, bsz=134, num_updates=40200, lr=0.00015772, gnorm=0.899, train_wall=15, wall=0
2024-07-10 18:58:45 | INFO | train_inner | epoch 004:   1288 / 13004 loss=6.69, nll_loss=5.601, ppl=48.54, wps=25560.8, ups=6.51, wpb=3927.7, bsz=132.9, num_updates=40300, lr=0.000157524, gnorm=0.868, train_wall=15, wall=0
2024-07-10 18:59:00 | INFO | train_inner | epoch 004:   1388 / 13004 loss=6.69, nll_loss=5.601, ppl=48.53, wps=25855.7, ups=6.58, wpb=3932.3, bsz=134.5, num_updates=40400, lr=0.000157329, gnorm=0.845, train_wall=15, wall=0
2024-07-10 18:59:16 | INFO | train_inner | epoch 004:   1488 / 13004 loss=6.663, nll_loss=5.572, ppl=47.56, wps=25586, ups=6.5, wpb=3938.5, bsz=148.6, num_updates=40500, lr=0.000157135, gnorm=0.862, train_wall=15, wall=0
2024-07-10 18:59:31 | INFO | train_inner | epoch 004:   1588 / 13004 loss=6.707, nll_loss=5.62, ppl=49.18, wps=25636.6, ups=6.57, wpb=3904.2, bsz=128.3, num_updates=40600, lr=0.000156941, gnorm=0.885, train_wall=15, wall=0
2024-07-10 18:59:46 | INFO | train_inner | epoch 004:   1688 / 13004 loss=6.685, nll_loss=5.595, ppl=48.34, wps=25516.2, ups=6.55, wpb=3896.4, bsz=125.9, num_updates=40700, lr=0.000156748, gnorm=0.867, train_wall=15, wall=0
2024-07-10 19:00:01 | INFO | train_inner | epoch 004:   1788 / 13004 loss=6.673, nll_loss=5.582, ppl=47.89, wps=25590.4, ups=6.53, wpb=3918.4, bsz=136.5, num_updates=40800, lr=0.000156556, gnorm=0.873, train_wall=15, wall=0
2024-07-10 19:00:17 | INFO | train_inner | epoch 004:   1888 / 13004 loss=6.711, nll_loss=5.624, ppl=49.33, wps=25784.1, ups=6.55, wpb=3933.6, bsz=137.8, num_updates=40900, lr=0.000156365, gnorm=0.886, train_wall=15, wall=0
2024-07-10 19:00:32 | INFO | train_inner | epoch 004:   1988 / 13004 loss=6.729, nll_loss=5.646, ppl=50.06, wps=25715.6, ups=6.59, wpb=3902.8, bsz=145.4, num_updates=41000, lr=0.000156174, gnorm=0.88, train_wall=15, wall=0
2024-07-10 19:00:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:00:33 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.05 | nll_loss 5.945 | ppl 61.59 | wps 95496.7 | wpb 3703.5 | bsz 124.5 | num_updates 41000 | best_loss 7.049
2024-07-10 19:00:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:00:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_41000.pt (epoch 4 @ 41000 updates, score 7.05) (writing took 4.262948255054653 seconds)
2024-07-10 19:00:52 | INFO | train_inner | epoch 004:   2088 / 13004 loss=6.683, nll_loss=5.594, ppl=48.29, wps=18807.9, ups=4.85, wpb=3879.1, bsz=135, num_updates=41100, lr=0.000155984, gnorm=0.873, train_wall=15, wall=0
2024-07-10 19:01:08 | INFO | train_inner | epoch 004:   2188 / 13004 loss=6.694, nll_loss=5.604, ppl=48.65, wps=25707.9, ups=6.55, wpb=3923.7, bsz=135, num_updates=41200, lr=0.000155794, gnorm=0.858, train_wall=15, wall=0
2024-07-10 19:01:23 | INFO | train_inner | epoch 004:   2288 / 13004 loss=6.657, nll_loss=5.563, ppl=47.29, wps=26082.5, ups=6.65, wpb=3923.1, bsz=122.2, num_updates=41300, lr=0.000155606, gnorm=0.856, train_wall=15, wall=0
2024-07-10 19:01:38 | INFO | train_inner | epoch 004:   2388 / 13004 loss=6.685, nll_loss=5.595, ppl=48.35, wps=25681.9, ups=6.55, wpb=3918.9, bsz=130.2, num_updates=41400, lr=0.000155417, gnorm=0.864, train_wall=15, wall=0
2024-07-10 19:01:53 | INFO | train_inner | epoch 004:   2488 / 13004 loss=6.709, nll_loss=5.622, ppl=49.26, wps=25790.9, ups=6.59, wpb=3913.7, bsz=140.7, num_updates=41500, lr=0.00015523, gnorm=0.893, train_wall=15, wall=0
2024-07-10 19:02:08 | INFO | train_inner | epoch 004:   2588 / 13004 loss=6.674, nll_loss=5.583, ppl=47.92, wps=25657.3, ups=6.57, wpb=3902.8, bsz=123.2, num_updates=41600, lr=0.000155043, gnorm=0.859, train_wall=15, wall=0
2024-07-10 19:02:24 | INFO | train_inner | epoch 004:   2688 / 13004 loss=6.654, nll_loss=5.56, ppl=47.16, wps=25412.4, ups=6.46, wpb=3933.7, bsz=145.5, num_updates=41700, lr=0.000154857, gnorm=0.857, train_wall=15, wall=0
2024-07-10 19:02:39 | INFO | train_inner | epoch 004:   2788 / 13004 loss=6.697, nll_loss=5.609, ppl=48.82, wps=25445.7, ups=6.49, wpb=3923.3, bsz=145.2, num_updates=41800, lr=0.000154672, gnorm=0.925, train_wall=15, wall=0
2024-07-10 19:02:55 | INFO | train_inner | epoch 004:   2888 / 13004 loss=6.686, nll_loss=5.596, ppl=48.36, wps=25611.4, ups=6.52, wpb=3929.4, bsz=140, num_updates=41900, lr=0.000154487, gnorm=0.875, train_wall=15, wall=0
2024-07-10 19:03:10 | INFO | train_inner | epoch 004:   2988 / 13004 loss=6.733, nll_loss=5.65, ppl=50.2, wps=25557.9, ups=6.51, wpb=3928.7, bsz=142.2, num_updates=42000, lr=0.000154303, gnorm=0.906, train_wall=15, wall=0
2024-07-10 19:03:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:03:11 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.062 | nll_loss 5.948 | ppl 61.73 | wps 95398.7 | wpb 3703.5 | bsz 124.5 | num_updates 42000 | best_loss 7.049
2024-07-10 19:03:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:03:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_42000.pt (epoch 4 @ 42000 updates, score 7.062) (writing took 4.447442336007953 seconds)
2024-07-10 19:03:31 | INFO | train_inner | epoch 004:   3088 / 13004 loss=6.71, nll_loss=5.624, ppl=49.33, wps=18777.5, ups=4.75, wpb=3953.5, bsz=143.2, num_updates=42100, lr=0.00015412, gnorm=0.873, train_wall=15, wall=0
2024-07-10 19:03:46 | INFO | train_inner | epoch 004:   3188 / 13004 loss=6.735, nll_loss=5.651, ppl=50.26, wps=25446.3, ups=6.5, wpb=3914, bsz=129.5, num_updates=42200, lr=0.000153937, gnorm=0.882, train_wall=15, wall=0
2024-07-10 19:04:02 | INFO | train_inner | epoch 004:   3288 / 13004 loss=6.667, nll_loss=5.574, ppl=47.65, wps=25674.1, ups=6.54, wpb=3924.6, bsz=129.4, num_updates=42300, lr=0.000153755, gnorm=0.844, train_wall=15, wall=0
2024-07-10 19:04:17 | INFO | train_inner | epoch 004:   3388 / 13004 loss=6.736, nll_loss=5.654, ppl=50.35, wps=25430.5, ups=6.45, wpb=3940.8, bsz=145.3, num_updates=42400, lr=0.000153574, gnorm=0.922, train_wall=15, wall=0
2024-07-10 19:04:33 | INFO | train_inner | epoch 004:   3488 / 13004 loss=6.648, nll_loss=5.552, ppl=46.91, wps=25305.4, ups=6.48, wpb=3903.4, bsz=119.5, num_updates=42500, lr=0.000153393, gnorm=0.858, train_wall=15, wall=0
2024-07-10 19:04:48 | INFO | train_inner | epoch 004:   3588 / 13004 loss=6.68, nll_loss=5.589, ppl=48.15, wps=25580.1, ups=6.54, wpb=3911.1, bsz=118.3, num_updates=42600, lr=0.000153213, gnorm=0.863, train_wall=15, wall=0
2024-07-10 19:05:03 | INFO | train_inner | epoch 004:   3688 / 13004 loss=6.691, nll_loss=5.603, ppl=48.61, wps=25549.5, ups=6.56, wpb=3891.9, bsz=136.9, num_updates=42700, lr=0.000153033, gnorm=0.888, train_wall=15, wall=0
2024-07-10 19:05:19 | INFO | train_inner | epoch 004:   3788 / 13004 loss=6.661, nll_loss=5.567, ppl=47.42, wps=25532.8, ups=6.47, wpb=3945.5, bsz=136.4, num_updates=42800, lr=0.000152854, gnorm=0.858, train_wall=15, wall=0
2024-07-10 19:05:34 | INFO | train_inner | epoch 004:   3888 / 13004 loss=6.678, nll_loss=5.587, ppl=48.06, wps=25511.8, ups=6.47, wpb=3943.5, bsz=129.8, num_updates=42900, lr=0.000152676, gnorm=0.851, train_wall=15, wall=0
2024-07-10 19:05:49 | INFO | train_inner | epoch 004:   3988 / 13004 loss=6.681, nll_loss=5.591, ppl=48.2, wps=25427.4, ups=6.52, wpb=3901.8, bsz=123.4, num_updates=43000, lr=0.000152499, gnorm=0.872, train_wall=15, wall=0
2024-07-10 19:05:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:05:51 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.039 | nll_loss 5.931 | ppl 61.01 | wps 94818.6 | wpb 3703.5 | bsz 124.5 | num_updates 43000 | best_loss 7.039
2024-07-10 19:05:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:05:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_43000.pt (epoch 4 @ 43000 updates, score 7.039) (writing took 4.539116473868489 seconds)
2024-07-10 19:06:11 | INFO | train_inner | epoch 004:   4088 / 13004 loss=6.667, nll_loss=5.576, ppl=47.71, wps=18670.1, ups=4.72, wpb=3955.5, bsz=149.7, num_updates=43100, lr=0.000152322, gnorm=0.88, train_wall=15, wall=0
2024-07-10 19:06:26 | INFO | train_inner | epoch 004:   4188 / 13004 loss=6.658, nll_loss=5.564, ppl=47.32, wps=25688.8, ups=6.59, wpb=3896.8, bsz=113.2, num_updates=43200, lr=0.000152145, gnorm=0.86, train_wall=15, wall=0
2024-07-10 19:06:41 | INFO | train_inner | epoch 004:   4288 / 13004 loss=6.673, nll_loss=5.581, ppl=47.87, wps=25565.7, ups=6.49, wpb=3938.6, bsz=135.5, num_updates=43300, lr=0.000151969, gnorm=0.869, train_wall=15, wall=0
2024-07-10 19:06:56 | INFO | train_inner | epoch 004:   4388 / 13004 loss=6.673, nll_loss=5.582, ppl=47.91, wps=25711.3, ups=6.55, wpb=3924.9, bsz=134.2, num_updates=43400, lr=0.000151794, gnorm=0.862, train_wall=15, wall=0
2024-07-10 19:07:12 | INFO | train_inner | epoch 004:   4488 / 13004 loss=6.686, nll_loss=5.596, ppl=48.38, wps=25458.6, ups=6.49, wpb=3922.3, bsz=143.4, num_updates=43500, lr=0.00015162, gnorm=0.879, train_wall=15, wall=0
2024-07-10 19:07:27 | INFO | train_inner | epoch 004:   4588 / 13004 loss=6.69, nll_loss=5.601, ppl=48.52, wps=25679.7, ups=6.6, wpb=3889.2, bsz=113.6, num_updates=43600, lr=0.000151446, gnorm=0.864, train_wall=15, wall=0
2024-07-10 19:07:42 | INFO | train_inner | epoch 004:   4688 / 13004 loss=6.694, nll_loss=5.605, ppl=48.67, wps=25703.6, ups=6.57, wpb=3914.2, bsz=137, num_updates=43700, lr=0.000151272, gnorm=0.905, train_wall=15, wall=0
2024-07-10 19:07:57 | INFO | train_inner | epoch 004:   4788 / 13004 loss=6.635, nll_loss=5.537, ppl=46.44, wps=25791.6, ups=6.59, wpb=3913.6, bsz=121.8, num_updates=43800, lr=0.000151099, gnorm=0.858, train_wall=15, wall=0
2024-07-10 19:08:13 | INFO | train_inner | epoch 004:   4888 / 13004 loss=6.684, nll_loss=5.595, ppl=48.35, wps=25805.6, ups=6.56, wpb=3932.2, bsz=137.3, num_updates=43900, lr=0.000150927, gnorm=0.879, train_wall=15, wall=0
2024-07-10 19:08:28 | INFO | train_inner | epoch 004:   4988 / 13004 loss=6.731, nll_loss=5.649, ppl=50.19, wps=25555.9, ups=6.53, wpb=3911.8, bsz=162.2, num_updates=44000, lr=0.000150756, gnorm=0.918, train_wall=15, wall=0
2024-07-10 19:08:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:08:29 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.042 | nll_loss 5.928 | ppl 60.89 | wps 96369.7 | wpb 3703.5 | bsz 124.5 | num_updates 44000 | best_loss 7.039
2024-07-10 19:08:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:08:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_44000.pt (epoch 4 @ 44000 updates, score 7.042) (writing took 2.8828637674450874 seconds)
2024-07-10 19:08:47 | INFO | train_inner | epoch 004:   5088 / 13004 loss=6.668, nll_loss=5.576, ppl=47.72, wps=20452.8, ups=5.18, wpb=3949.5, bsz=143, num_updates=44100, lr=0.000150585, gnorm=0.857, train_wall=15, wall=0
2024-07-10 19:09:03 | INFO | train_inner | epoch 004:   5188 / 13004 loss=6.645, nll_loss=5.55, ppl=46.84, wps=25582.1, ups=6.49, wpb=3939.5, bsz=141, num_updates=44200, lr=0.000150414, gnorm=0.856, train_wall=15, wall=0
2024-07-10 19:09:18 | INFO | train_inner | epoch 004:   5288 / 13004 loss=6.705, nll_loss=5.618, ppl=49.11, wps=25325.3, ups=6.54, wpb=3872.6, bsz=138.3, num_updates=44300, lr=0.000150244, gnorm=0.911, train_wall=15, wall=0
2024-07-10 19:09:33 | INFO | train_inner | epoch 004:   5388 / 13004 loss=6.7, nll_loss=5.614, ppl=48.97, wps=25716.6, ups=6.61, wpb=3891.4, bsz=134.4, num_updates=44400, lr=0.000150075, gnorm=0.88, train_wall=15, wall=0
2024-07-10 19:09:48 | INFO | train_inner | epoch 004:   5488 / 13004 loss=6.693, nll_loss=5.604, ppl=48.65, wps=25684.5, ups=6.59, wpb=3900.4, bsz=131.8, num_updates=44500, lr=0.000149906, gnorm=0.876, train_wall=15, wall=0
2024-07-10 19:10:04 | INFO | train_inner | epoch 004:   5588 / 13004 loss=6.696, nll_loss=5.608, ppl=48.77, wps=25772.1, ups=6.53, wpb=3946.3, bsz=142.8, num_updates=44600, lr=0.000149738, gnorm=0.889, train_wall=15, wall=0
2024-07-10 19:10:19 | INFO | train_inner | epoch 004:   5688 / 13004 loss=6.695, nll_loss=5.608, ppl=48.76, wps=25753.7, ups=6.57, wpb=3922, bsz=140.9, num_updates=44700, lr=0.000149571, gnorm=0.918, train_wall=15, wall=0
2024-07-10 19:10:34 | INFO | train_inner | epoch 004:   5788 / 13004 loss=6.662, nll_loss=5.569, ppl=47.47, wps=25480.6, ups=6.49, wpb=3925.7, bsz=131, num_updates=44800, lr=0.000149404, gnorm=0.863, train_wall=15, wall=0
2024-07-10 19:10:50 | INFO | train_inner | epoch 004:   5888 / 13004 loss=6.684, nll_loss=5.594, ppl=48.29, wps=25544.9, ups=6.54, wpb=3905.5, bsz=123, num_updates=44900, lr=0.000149237, gnorm=0.891, train_wall=15, wall=0
2024-07-10 19:11:05 | INFO | train_inner | epoch 004:   5988 / 13004 loss=6.693, nll_loss=5.605, ppl=48.69, wps=25656.8, ups=6.53, wpb=3930.3, bsz=137.7, num_updates=45000, lr=0.000149071, gnorm=0.867, train_wall=15, wall=0
2024-07-10 19:11:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:11:06 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.035 | nll_loss 5.925 | ppl 60.74 | wps 95940.8 | wpb 3703.5 | bsz 124.5 | num_updates 45000 | best_loss 7.035
2024-07-10 19:11:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:11:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_45000.pt (epoch 4 @ 45000 updates, score 7.035) (writing took 5.099102476611733 seconds)
2024-07-10 19:11:26 | INFO | train_inner | epoch 004:   6088 / 13004 loss=6.666, nll_loss=5.574, ppl=47.63, wps=18179.3, ups=4.64, wpb=3920.3, bsz=135.3, num_updates=45100, lr=0.000148906, gnorm=0.867, train_wall=15, wall=0
2024-07-10 19:11:42 | INFO | train_inner | epoch 004:   6188 / 13004 loss=6.688, nll_loss=5.598, ppl=48.45, wps=25420.8, ups=6.53, wpb=3895.9, bsz=111.6, num_updates=45200, lr=0.000148741, gnorm=0.871, train_wall=15, wall=0
2024-07-10 19:11:57 | INFO | train_inner | epoch 004:   6288 / 13004 loss=6.663, nll_loss=5.569, ppl=47.47, wps=25701.6, ups=6.53, wpb=3936.9, bsz=121.5, num_updates=45300, lr=0.000148577, gnorm=0.852, train_wall=15, wall=0
2024-07-10 19:12:12 | INFO | train_inner | epoch 004:   6388 / 13004 loss=6.696, nll_loss=5.609, ppl=48.81, wps=25619.7, ups=6.55, wpb=3913.9, bsz=127, num_updates=45400, lr=0.000148413, gnorm=0.891, train_wall=15, wall=0
2024-07-10 19:12:28 | INFO | train_inner | epoch 004:   6488 / 13004 loss=6.704, nll_loss=5.617, ppl=49.08, wps=25625.5, ups=6.5, wpb=3942.9, bsz=143.2, num_updates=45500, lr=0.00014825, gnorm=0.914, train_wall=15, wall=0
2024-07-10 19:12:43 | INFO | train_inner | epoch 004:   6588 / 13004 loss=6.7, nll_loss=5.613, ppl=48.94, wps=25553.9, ups=6.52, wpb=3919, bsz=136.5, num_updates=45600, lr=0.000148087, gnorm=0.875, train_wall=15, wall=0
2024-07-10 19:12:58 | INFO | train_inner | epoch 004:   6688 / 13004 loss=6.666, nll_loss=5.574, ppl=47.65, wps=25748.6, ups=6.54, wpb=3936, bsz=150.2, num_updates=45700, lr=0.000147925, gnorm=0.863, train_wall=15, wall=0
2024-07-10 19:13:14 | INFO | train_inner | epoch 004:   6788 / 13004 loss=6.661, nll_loss=5.567, ppl=47.42, wps=25537.8, ups=6.51, wpb=3924.1, bsz=109.8, num_updates=45800, lr=0.000147764, gnorm=0.856, train_wall=15, wall=0
2024-07-10 19:13:29 | INFO | train_inner | epoch 004:   6888 / 13004 loss=6.701, nll_loss=5.614, ppl=48.98, wps=25373.9, ups=6.51, wpb=3897.2, bsz=129.5, num_updates=45900, lr=0.000147602, gnorm=0.923, train_wall=15, wall=0
2024-07-10 19:13:44 | INFO | train_inner | epoch 004:   6988 / 13004 loss=6.663, nll_loss=5.57, ppl=47.51, wps=25726, ups=6.59, wpb=3903.7, bsz=127.7, num_updates=46000, lr=0.000147442, gnorm=0.855, train_wall=15, wall=0
2024-07-10 19:13:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:13:45 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.03 | nll_loss 5.916 | ppl 60.37 | wps 95496.4 | wpb 3703.5 | bsz 124.5 | num_updates 46000 | best_loss 7.03
2024-07-10 19:13:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:13:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_46000.pt (epoch 4 @ 46000 updates, score 7.03) (writing took 5.164474376477301 seconds)
2024-07-10 19:14:06 | INFO | train_inner | epoch 004:   7088 / 13004 loss=6.646, nll_loss=5.55, ppl=46.87, wps=18161.5, ups=4.6, wpb=3950.2, bsz=137.5, num_updates=46100, lr=0.000147282, gnorm=0.85, train_wall=15, wall=0
2024-07-10 19:14:21 | INFO | train_inner | epoch 004:   7188 / 13004 loss=6.706, nll_loss=5.619, ppl=49.16, wps=25528.5, ups=6.56, wpb=3890.3, bsz=124.5, num_updates=46200, lr=0.000147122, gnorm=0.905, train_wall=15, wall=0
2024-07-10 19:14:36 | INFO | train_inner | epoch 004:   7288 / 13004 loss=6.647, nll_loss=5.551, ppl=46.88, wps=25616.8, ups=6.58, wpb=3891.3, bsz=113, num_updates=46300, lr=0.000146964, gnorm=0.865, train_wall=15, wall=0
2024-07-10 19:14:52 | INFO | train_inner | epoch 004:   7388 / 13004 loss=6.679, nll_loss=5.589, ppl=48.15, wps=25685, ups=6.54, wpb=3926.6, bsz=131.4, num_updates=46400, lr=0.000146805, gnorm=0.87, train_wall=15, wall=0
2024-07-10 19:15:07 | INFO | train_inner | epoch 004:   7488 / 13004 loss=6.646, nll_loss=5.551, ppl=46.87, wps=25756.3, ups=6.6, wpb=3904.6, bsz=114.2, num_updates=46500, lr=0.000146647, gnorm=0.865, train_wall=15, wall=0
2024-07-10 19:15:22 | INFO | train_inner | epoch 004:   7588 / 13004 loss=6.692, nll_loss=5.603, ppl=48.62, wps=25815.5, ups=6.6, wpb=3911.4, bsz=128.3, num_updates=46600, lr=0.00014649, gnorm=0.894, train_wall=15, wall=0
2024-07-10 19:15:37 | INFO | train_inner | epoch 004:   7688 / 13004 loss=6.645, nll_loss=5.55, ppl=46.85, wps=25611.8, ups=6.56, wpb=3906.8, bsz=131.8, num_updates=46700, lr=0.000146333, gnorm=0.873, train_wall=15, wall=0
2024-07-10 19:15:53 | INFO | train_inner | epoch 004:   7788 / 13004 loss=6.676, nll_loss=5.585, ppl=48.01, wps=25584.8, ups=6.47, wpb=3954.8, bsz=134.9, num_updates=46800, lr=0.000146176, gnorm=0.892, train_wall=15, wall=0
2024-07-10 19:16:08 | INFO | train_inner | epoch 004:   7888 / 13004 loss=6.653, nll_loss=5.559, ppl=47.15, wps=25773.9, ups=6.55, wpb=3936.2, bsz=138.6, num_updates=46900, lr=0.00014602, gnorm=0.859, train_wall=15, wall=0
2024-07-10 19:16:23 | INFO | train_inner | epoch 004:   7988 / 13004 loss=6.669, nll_loss=5.578, ppl=47.76, wps=25585.4, ups=6.52, wpb=3926.6, bsz=125.8, num_updates=47000, lr=0.000145865, gnorm=0.865, train_wall=15, wall=0
2024-07-10 19:16:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:16:25 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.031 | nll_loss 5.92 | ppl 60.53 | wps 93661.9 | wpb 3703.5 | bsz 124.5 | num_updates 47000 | best_loss 7.03
2024-07-10 19:16:25 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:16:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_47000.pt (epoch 4 @ 47000 updates, score 7.031) (writing took 2.7694331873208284 seconds)
2024-07-10 19:16:43 | INFO | train_inner | epoch 004:   8088 / 13004 loss=6.676, nll_loss=5.585, ppl=48.01, wps=20263.1, ups=5.22, wpb=3883, bsz=121.4, num_updates=47100, lr=0.00014571, gnorm=0.89, train_wall=15, wall=0
2024-07-10 19:16:58 | INFO | train_inner | epoch 004:   8188 / 13004 loss=6.667, nll_loss=5.575, ppl=47.68, wps=25661, ups=6.54, wpb=3924.5, bsz=132.1, num_updates=47200, lr=0.000145556, gnorm=0.874, train_wall=15, wall=0
2024-07-10 19:17:13 | INFO | train_inner | epoch 004:   8288 / 13004 loss=6.68, nll_loss=5.59, ppl=48.17, wps=25773.8, ups=6.58, wpb=3919.3, bsz=122.2, num_updates=47300, lr=0.000145402, gnorm=0.88, train_wall=15, wall=0
2024-07-10 19:17:28 | INFO | train_inner | epoch 004:   8388 / 13004 loss=6.667, nll_loss=5.575, ppl=47.66, wps=25715.2, ups=6.51, wpb=3948.9, bsz=154.2, num_updates=47400, lr=0.000145248, gnorm=0.898, train_wall=15, wall=0
2024-07-10 19:17:44 | INFO | train_inner | epoch 004:   8488 / 13004 loss=6.637, nll_loss=5.54, ppl=46.51, wps=25657.3, ups=6.56, wpb=3909, bsz=115, num_updates=47500, lr=0.000145095, gnorm=0.857, train_wall=15, wall=0
2024-07-10 19:17:59 | INFO | train_inner | epoch 004:   8588 / 13004 loss=6.67, nll_loss=5.578, ppl=47.78, wps=25707.8, ups=6.56, wpb=3920.9, bsz=131.6, num_updates=47600, lr=0.000144943, gnorm=0.883, train_wall=15, wall=0
2024-07-10 19:18:14 | INFO | train_inner | epoch 004:   8688 / 13004 loss=6.713, nll_loss=5.628, ppl=49.45, wps=25600.8, ups=6.52, wpb=3923.6, bsz=145.8, num_updates=47700, lr=0.000144791, gnorm=0.909, train_wall=15, wall=0
2024-07-10 19:18:29 | INFO | train_inner | epoch 004:   8788 / 13004 loss=6.677, nll_loss=5.586, ppl=48.03, wps=25635.3, ups=6.57, wpb=3900.7, bsz=127.6, num_updates=47800, lr=0.000144639, gnorm=0.89, train_wall=15, wall=0
2024-07-10 19:18:45 | INFO | train_inner | epoch 004:   8888 / 13004 loss=6.62, nll_loss=5.521, ppl=45.92, wps=25689.4, ups=6.54, wpb=3925.5, bsz=116.4, num_updates=47900, lr=0.000144488, gnorm=0.851, train_wall=15, wall=0
2024-07-10 19:19:00 | INFO | train_inner | epoch 004:   8988 / 13004 loss=6.655, nll_loss=5.562, ppl=47.23, wps=25569.8, ups=6.55, wpb=3901.6, bsz=127.7, num_updates=48000, lr=0.000144338, gnorm=0.878, train_wall=15, wall=0
2024-07-10 19:19:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:19:01 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.017 | nll_loss 5.9 | ppl 59.72 | wps 96132.9 | wpb 3703.5 | bsz 124.5 | num_updates 48000 | best_loss 7.017
2024-07-10 19:19:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:19:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_48000.pt (epoch 4 @ 48000 updates, score 7.017) (writing took 4.804871981032193 seconds)
2024-07-10 19:19:21 | INFO | train_inner | epoch 004:   9088 / 13004 loss=6.648, nll_loss=5.554, ppl=46.97, wps=18455.8, ups=4.69, wpb=3933.6, bsz=131.8, num_updates=48100, lr=0.000144187, gnorm=0.875, train_wall=15, wall=0
2024-07-10 19:19:37 | INFO | train_inner | epoch 004:   9188 / 13004 loss=6.645, nll_loss=5.551, ppl=46.87, wps=25531.8, ups=6.5, wpb=3930.6, bsz=128.2, num_updates=48200, lr=0.000144038, gnorm=0.866, train_wall=15, wall=0
2024-07-10 19:19:52 | INFO | train_inner | epoch 004:   9288 / 13004 loss=6.681, nll_loss=5.591, ppl=48.19, wps=25716.2, ups=6.58, wpb=3905.6, bsz=117, num_updates=48300, lr=0.000143889, gnorm=0.898, train_wall=15, wall=0
2024-07-10 19:20:07 | INFO | train_inner | epoch 004:   9388 / 13004 loss=6.672, nll_loss=5.581, ppl=47.86, wps=25684.2, ups=6.53, wpb=3930.6, bsz=123.7, num_updates=48400, lr=0.00014374, gnorm=0.899, train_wall=15, wall=0
2024-07-10 19:20:23 | INFO | train_inner | epoch 004:   9488 / 13004 loss=6.671, nll_loss=5.581, ppl=47.85, wps=25666.6, ups=6.51, wpb=3941.6, bsz=136.2, num_updates=48500, lr=0.000143592, gnorm=0.871, train_wall=15, wall=0
2024-07-10 19:20:38 | INFO | train_inner | epoch 004:   9588 / 13004 loss=6.701, nll_loss=5.615, ppl=49, wps=25496.9, ups=6.54, wpb=3897.6, bsz=131.8, num_updates=48600, lr=0.000143444, gnorm=0.924, train_wall=15, wall=0
2024-07-10 19:20:53 | INFO | train_inner | epoch 004:   9688 / 13004 loss=6.686, nll_loss=5.597, ppl=48.41, wps=25647, ups=6.55, wpb=3916.4, bsz=139.7, num_updates=48700, lr=0.000143296, gnorm=0.898, train_wall=15, wall=0
2024-07-10 19:21:08 | INFO | train_inner | epoch 004:   9788 / 13004 loss=6.734, nll_loss=5.651, ppl=50.25, wps=25579.5, ups=6.49, wpb=3939.2, bsz=145.4, num_updates=48800, lr=0.00014315, gnorm=0.924, train_wall=15, wall=0
2024-07-10 19:21:24 | INFO | train_inner | epoch 004:   9888 / 13004 loss=6.674, nll_loss=5.583, ppl=47.93, wps=25659.5, ups=6.52, wpb=3935.2, bsz=144.6, num_updates=48900, lr=0.000143003, gnorm=0.901, train_wall=15, wall=0
2024-07-10 19:21:39 | INFO | train_inner | epoch 004:   9988 / 13004 loss=6.671, nll_loss=5.58, ppl=47.84, wps=25741, ups=6.51, wpb=3951.3, bsz=145.4, num_updates=49000, lr=0.000142857, gnorm=0.867, train_wall=15, wall=0
2024-07-10 19:21:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:21:40 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.002 | nll_loss 5.885 | ppl 59.1 | wps 95399.4 | wpb 3703.5 | bsz 124.5 | num_updates 49000 | best_loss 7.002
2024-07-10 19:21:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:21:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_49000.pt (epoch 4 @ 49000 updates, score 7.002) (writing took 4.533931842073798 seconds)
2024-07-10 19:22:00 | INFO | train_inner | epoch 004:  10088 / 13004 loss=6.648, nll_loss=5.553, ppl=46.96, wps=18611.5, ups=4.78, wpb=3896.6, bsz=121.1, num_updates=49100, lr=0.000142712, gnorm=0.874, train_wall=15, wall=0
2024-07-10 19:22:16 | INFO | train_inner | epoch 004:  10188 / 13004 loss=6.642, nll_loss=5.547, ppl=46.76, wps=25441.3, ups=6.47, wpb=3930.6, bsz=157.6, num_updates=49200, lr=0.000142566, gnorm=0.884, train_wall=15, wall=0
2024-07-10 19:22:31 | INFO | train_inner | epoch 004:  10288 / 13004 loss=6.649, nll_loss=5.555, ppl=47.01, wps=25502.4, ups=6.52, wpb=3913.3, bsz=133.8, num_updates=49300, lr=0.000142422, gnorm=0.893, train_wall=15, wall=0
2024-07-10 19:22:46 | INFO | train_inner | epoch 004:  10388 / 13004 loss=6.702, nll_loss=5.615, ppl=49, wps=25602.5, ups=6.56, wpb=3901.9, bsz=125.1, num_updates=49400, lr=0.000142278, gnorm=0.915, train_wall=15, wall=0
2024-07-10 19:23:01 | INFO | train_inner | epoch 004:  10488 / 13004 loss=6.659, nll_loss=5.567, ppl=47.41, wps=25856.6, ups=6.59, wpb=3924.7, bsz=149.3, num_updates=49500, lr=0.000142134, gnorm=0.881, train_wall=15, wall=0
2024-07-10 19:23:17 | INFO | train_inner | epoch 004:  10588 / 13004 loss=6.643, nll_loss=5.548, ppl=46.79, wps=25813.7, ups=6.56, wpb=3937, bsz=141.6, num_updates=49600, lr=0.00014199, gnorm=0.873, train_wall=15, wall=0
2024-07-10 19:23:32 | INFO | train_inner | epoch 004:  10688 / 13004 loss=6.69, nll_loss=5.602, ppl=48.56, wps=25789.5, ups=6.55, wpb=3935.5, bsz=138.6, num_updates=49700, lr=0.000141848, gnorm=0.91, train_wall=15, wall=0
2024-07-10 19:23:47 | INFO | train_inner | epoch 004:  10788 / 13004 loss=6.714, nll_loss=5.629, ppl=49.47, wps=25484, ups=6.5, wpb=3923.4, bsz=144.7, num_updates=49800, lr=0.000141705, gnorm=0.908, train_wall=15, wall=0
2024-07-10 19:24:03 | INFO | train_inner | epoch 004:  10888 / 13004 loss=6.715, nll_loss=5.631, ppl=49.56, wps=25532.5, ups=6.48, wpb=3937.9, bsz=148.6, num_updates=49900, lr=0.000141563, gnorm=0.931, train_wall=15, wall=0
2024-07-10 19:24:18 | INFO | train_inner | epoch 004:  10988 / 13004 loss=6.657, nll_loss=5.564, ppl=47.3, wps=25630.5, ups=6.54, wpb=3919.1, bsz=121.6, num_updates=50000, lr=0.000141421, gnorm=0.88, train_wall=15, wall=0
2024-07-10 19:24:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:24:19 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.019 | nll_loss 5.901 | ppl 59.77 | wps 96163.7 | wpb 3703.5 | bsz 124.5 | num_updates 50000 | best_loss 7.002
2024-07-10 19:24:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:24:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_50000.pt (epoch 4 @ 50000 updates, score 7.019) (writing took 2.968211389146745 seconds)
2024-07-10 19:24:37 | INFO | train_inner | epoch 004:  11088 / 13004 loss=6.628, nll_loss=5.531, ppl=46.24, wps=20202.7, ups=5.15, wpb=3919.1, bsz=138.1, num_updates=50100, lr=0.00014128, gnorm=0.877, train_wall=15, wall=0
2024-07-10 19:24:53 | INFO | train_inner | epoch 004:  11188 / 13004 loss=6.645, nll_loss=5.55, ppl=46.87, wps=25770.6, ups=6.56, wpb=3926.2, bsz=139.2, num_updates=50200, lr=0.000141139, gnorm=0.869, train_wall=15, wall=0
2024-07-10 19:25:08 | INFO | train_inner | epoch 004:  11288 / 13004 loss=6.684, nll_loss=5.595, ppl=48.35, wps=25661, ups=6.56, wpb=3909.7, bsz=134, num_updates=50300, lr=0.000140999, gnorm=0.907, train_wall=15, wall=0
2024-07-10 19:25:23 | INFO | train_inner | epoch 004:  11388 / 13004 loss=6.621, nll_loss=5.524, ppl=46, wps=25592.1, ups=6.52, wpb=3924.3, bsz=140.5, num_updates=50400, lr=0.000140859, gnorm=0.863, train_wall=15, wall=0
2024-07-10 19:25:38 | INFO | train_inner | epoch 004:  11488 / 13004 loss=6.624, nll_loss=5.525, ppl=46.05, wps=25746.4, ups=6.52, wpb=3948.5, bsz=120.6, num_updates=50500, lr=0.00014072, gnorm=0.859, train_wall=15, wall=0
2024-07-10 19:25:54 | INFO | train_inner | epoch 004:  11588 / 13004 loss=6.654, nll_loss=5.561, ppl=47.2, wps=25758.6, ups=6.55, wpb=3933.8, bsz=149.2, num_updates=50600, lr=0.00014058, gnorm=0.905, train_wall=15, wall=0
2024-07-10 19:26:09 | INFO | train_inner | epoch 004:  11688 / 13004 loss=6.635, nll_loss=5.539, ppl=46.48, wps=25875.4, ups=6.61, wpb=3913, bsz=122.2, num_updates=50700, lr=0.000140442, gnorm=0.866, train_wall=15, wall=0
2024-07-10 19:26:24 | INFO | train_inner | epoch 004:  11788 / 13004 loss=6.625, nll_loss=5.527, ppl=46.1, wps=25593.7, ups=6.55, wpb=3907.2, bsz=123.8, num_updates=50800, lr=0.000140303, gnorm=0.872, train_wall=15, wall=0
2024-07-10 19:26:40 | INFO | train_inner | epoch 004:  11888 / 13004 loss=6.655, nll_loss=5.562, ppl=47.24, wps=25600.1, ups=6.51, wpb=3930.3, bsz=128.8, num_updates=50900, lr=0.000140165, gnorm=0.875, train_wall=15, wall=0
2024-07-10 19:26:55 | INFO | train_inner | epoch 004:  11988 / 13004 loss=6.668, nll_loss=5.577, ppl=47.73, wps=25884.8, ups=6.59, wpb=3929.2, bsz=141.6, num_updates=51000, lr=0.000140028, gnorm=0.903, train_wall=15, wall=0
2024-07-10 19:26:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:26:56 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.008 | nll_loss 5.889 | ppl 59.26 | wps 95037.5 | wpb 3703.5 | bsz 124.5 | num_updates 51000 | best_loss 7.002
2024-07-10 19:26:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:26:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_51000.pt (epoch 4 @ 51000 updates, score 7.008) (writing took 2.6757383588701487 seconds)
2024-07-10 19:27:14 | INFO | train_inner | epoch 004:  12088 / 13004 loss=6.65, nll_loss=5.556, ppl=47.04, wps=20630.1, ups=5.25, wpb=3931.5, bsz=127.9, num_updates=51100, lr=0.000139891, gnorm=0.876, train_wall=15, wall=0
2024-07-10 19:27:29 | INFO | train_inner | epoch 004:  12188 / 13004 loss=6.602, nll_loss=5.501, ppl=45.28, wps=25727.2, ups=6.54, wpb=3932.6, bsz=123.5, num_updates=51200, lr=0.000139754, gnorm=0.856, train_wall=15, wall=0
2024-07-10 19:27:44 | INFO | train_inner | epoch 004:  12288 / 13004 loss=6.703, nll_loss=5.615, ppl=49, wps=25389.6, ups=6.56, wpb=3868.5, bsz=113.9, num_updates=51300, lr=0.000139618, gnorm=1.005, train_wall=15, wall=0
2024-07-10 19:28:00 | INFO | train_inner | epoch 004:  12388 / 13004 loss=6.635, nll_loss=5.539, ppl=46.5, wps=25510.5, ups=6.52, wpb=3912.1, bsz=126.6, num_updates=51400, lr=0.000139482, gnorm=1.659, train_wall=15, wall=0
2024-07-10 19:28:15 | INFO | train_inner | epoch 004:  12488 / 13004 loss=6.638, nll_loss=5.542, ppl=46.59, wps=25715, ups=6.58, wpb=3909.4, bsz=122.2, num_updates=51500, lr=0.000139347, gnorm=0.931, train_wall=15, wall=0
2024-07-10 19:28:30 | INFO | train_inner | epoch 004:  12588 / 13004 loss=6.625, nll_loss=5.526, ppl=46.09, wps=25566.4, ups=6.53, wpb=3916.1, bsz=123.6, num_updates=51600, lr=0.000139212, gnorm=0.871, train_wall=15, wall=0
2024-07-10 19:28:45 | INFO | train_inner | epoch 004:  12688 / 13004 loss=6.651, nll_loss=5.556, ppl=47.06, wps=25764.6, ups=6.56, wpb=3929.9, bsz=145.4, num_updates=51700, lr=0.000139077, gnorm=0.891, train_wall=15, wall=0
2024-07-10 19:29:01 | INFO | train_inner | epoch 004:  12788 / 13004 loss=6.656, nll_loss=5.562, ppl=47.25, wps=25688, ups=6.54, wpb=3929.9, bsz=138, num_updates=51800, lr=0.000138943, gnorm=0.892, train_wall=15, wall=0
2024-07-10 19:29:16 | INFO | train_inner | epoch 004:  12888 / 13004 loss=6.64, nll_loss=5.545, ppl=46.68, wps=25775.7, ups=6.57, wpb=3923.8, bsz=135.3, num_updates=51900, lr=0.000138809, gnorm=0.883, train_wall=15, wall=0
2024-07-10 19:29:31 | INFO | train_inner | epoch 004:  12988 / 13004 loss=6.699, nll_loss=5.612, ppl=48.91, wps=25546.9, ups=6.53, wpb=3911.2, bsz=128.6, num_updates=52000, lr=0.000138675, gnorm=0.922, train_wall=15, wall=0
2024-07-10 19:29:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:29:32 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.004 | nll_loss 5.887 | ppl 59.19 | wps 94706.9 | wpb 3703.5 | bsz 124.5 | num_updates 52000 | best_loss 7.002
2024-07-10 19:29:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:29:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_52000.pt (epoch 4 @ 52000 updates, score 7.004) (writing took 2.988976244814694 seconds)
2024-07-10 19:29:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:29:39 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.005 | nll_loss 5.887 | ppl 59.16 | wps 95878.7 | wpb 3703.5 | bsz 124.5 | num_updates 52016 | best_loss 7.002
2024-07-10 19:29:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:29:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 4 @ 52016 updates, score 7.005) (writing took 2.416465599089861 seconds)
2024-07-10 19:29:41 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2024-07-10 19:29:41 | INFO | train | epoch 004 | loss 6.676 | nll_loss 5.586 | ppl 48.02 | wps 24711.6 | ups 6.3 | wpb 3919.8 | bsz 133.2 | num_updates 52016 | lr 0.000138654 | gnorm 0.887 | train_wall 1965 | wall 0
2024-07-10 19:29:41 | INFO | fairseq.trainer | begin training epoch 5
2024-07-10 19:29:54 | INFO | train_inner | epoch 005:     84 / 13004 loss=6.592, nll_loss=5.49, ppl=44.94, wps=16956.1, ups=4.32, wpb=3924.5, bsz=138.6, num_updates=52100, lr=0.000138542, gnorm=0.879, train_wall=15, wall=0
2024-07-10 19:30:10 | INFO | train_inner | epoch 005:    184 / 13004 loss=6.645, nll_loss=5.549, ppl=46.83, wps=25792.2, ups=6.55, wpb=3938, bsz=149.8, num_updates=52200, lr=0.000138409, gnorm=0.916, train_wall=15, wall=0
2024-07-10 19:30:25 | INFO | train_inner | epoch 005:    284 / 13004 loss=6.647, nll_loss=5.552, ppl=46.92, wps=25737.2, ups=6.55, wpb=3930.6, bsz=141.7, num_updates=52300, lr=0.000138277, gnorm=0.906, train_wall=15, wall=0
2024-07-10 19:30:40 | INFO | train_inner | epoch 005:    384 / 13004 loss=6.631, nll_loss=5.533, ppl=46.31, wps=25575.7, ups=6.52, wpb=3924, bsz=126.6, num_updates=52400, lr=0.000138145, gnorm=0.897, train_wall=15, wall=0
2024-07-10 19:30:55 | INFO | train_inner | epoch 005:    484 / 13004 loss=6.59, nll_loss=5.487, ppl=44.86, wps=25669.8, ups=6.57, wpb=3905, bsz=127.6, num_updates=52500, lr=0.000138013, gnorm=0.874, train_wall=15, wall=0
2024-07-10 19:31:11 | INFO | train_inner | epoch 005:    584 / 13004 loss=6.659, nll_loss=5.567, ppl=47.42, wps=25839.1, ups=6.53, wpb=3958.5, bsz=181.6, num_updates=52600, lr=0.000137882, gnorm=0.955, train_wall=15, wall=0
2024-07-10 19:31:26 | INFO | train_inner | epoch 005:    684 / 13004 loss=6.621, nll_loss=5.522, ppl=45.95, wps=25602.4, ups=6.51, wpb=3933.7, bsz=136.7, num_updates=52700, lr=0.000137751, gnorm=0.88, train_wall=15, wall=0
2024-07-10 19:31:41 | INFO | train_inner | epoch 005:    784 / 13004 loss=6.618, nll_loss=5.519, ppl=45.86, wps=25557.4, ups=6.56, wpb=3896.9, bsz=123.7, num_updates=52800, lr=0.00013762, gnorm=0.89, train_wall=15, wall=0
2024-07-10 19:31:57 | INFO | train_inner | epoch 005:    884 / 13004 loss=6.612, nll_loss=5.511, ppl=45.61, wps=25634.9, ups=6.61, wpb=3879, bsz=124.1, num_updates=52900, lr=0.00013749, gnorm=0.888, train_wall=15, wall=0
2024-07-10 19:32:12 | INFO | train_inner | epoch 005:    984 / 13004 loss=6.612, nll_loss=5.512, ppl=45.64, wps=25533.7, ups=6.47, wpb=3943.8, bsz=140.2, num_updates=53000, lr=0.000137361, gnorm=0.883, train_wall=15, wall=0
2024-07-10 19:32:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:32:13 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.999 | nll_loss 5.878 | ppl 58.8 | wps 96689.1 | wpb 3703.5 | bsz 124.5 | num_updates 53000 | best_loss 6.999
2024-07-10 19:32:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:32:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_53000.pt (epoch 5 @ 53000 updates, score 6.999) (writing took 5.1171751245856285 seconds)
2024-07-10 19:32:33 | INFO | train_inner | epoch 005:   1084 / 13004 loss=6.624, nll_loss=5.526, ppl=46.07, wps=18088, ups=4.65, wpb=3887.4, bsz=124.6, num_updates=53100, lr=0.000137231, gnorm=0.893, train_wall=15, wall=0
2024-07-10 19:32:49 | INFO | train_inner | epoch 005:   1184 / 13004 loss=6.624, nll_loss=5.524, ppl=46.02, wps=25694.7, ups=6.56, wpb=3919.5, bsz=128.6, num_updates=53200, lr=0.000137102, gnorm=0.917, train_wall=15, wall=0
2024-07-10 19:33:04 | INFO | train_inner | epoch 005:   1284 / 13004 loss=6.682, nll_loss=5.592, ppl=48.24, wps=25687.2, ups=6.58, wpb=3902.4, bsz=139.1, num_updates=53300, lr=0.000136973, gnorm=0.921, train_wall=15, wall=0
2024-07-10 19:33:19 | INFO | train_inner | epoch 005:   1384 / 13004 loss=6.633, nll_loss=5.536, ppl=46.39, wps=25632.7, ups=6.51, wpb=3938.5, bsz=132.9, num_updates=53400, lr=0.000136845, gnorm=0.904, train_wall=15, wall=0
2024-07-10 19:33:34 | INFO | train_inner | epoch 005:   1484 / 13004 loss=6.612, nll_loss=5.512, ppl=45.62, wps=25559.3, ups=6.57, wpb=3887.8, bsz=113.8, num_updates=53500, lr=0.000136717, gnorm=0.879, train_wall=15, wall=0
2024-07-10 19:33:50 | INFO | train_inner | epoch 005:   1584 / 13004 loss=6.629, nll_loss=5.531, ppl=46.25, wps=25642.7, ups=6.57, wpb=3905.3, bsz=133.5, num_updates=53600, lr=0.00013659, gnorm=0.903, train_wall=15, wall=0
2024-07-10 19:34:05 | INFO | train_inner | epoch 005:   1684 / 13004 loss=6.64, nll_loss=5.543, ppl=46.64, wps=25677.1, ups=6.51, wpb=3945.9, bsz=137.6, num_updates=53700, lr=0.000136462, gnorm=0.896, train_wall=15, wall=0
2024-07-10 19:34:20 | INFO | train_inner | epoch 005:   1784 / 13004 loss=6.622, nll_loss=5.523, ppl=45.98, wps=25577.8, ups=6.5, wpb=3937.6, bsz=135.6, num_updates=53800, lr=0.000136335, gnorm=0.879, train_wall=15, wall=0
2024-07-10 19:34:36 | INFO | train_inner | epoch 005:   1884 / 13004 loss=6.64, nll_loss=5.544, ppl=46.67, wps=25628.6, ups=6.51, wpb=3937.2, bsz=150.2, num_updates=53900, lr=0.000136209, gnorm=0.906, train_wall=15, wall=0
2024-07-10 19:34:51 | INFO | train_inner | epoch 005:   1984 / 13004 loss=6.629, nll_loss=5.532, ppl=46.26, wps=25410.7, ups=6.53, wpb=3892.2, bsz=118.9, num_updates=54000, lr=0.000136083, gnorm=0.892, train_wall=15, wall=0
2024-07-10 19:34:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:34:52 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.004 | nll_loss 5.889 | ppl 59.24 | wps 95579.4 | wpb 3703.5 | bsz 124.5 | num_updates 54000 | best_loss 6.999
2024-07-10 19:34:52 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:34:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_54000.pt (epoch 5 @ 54000 updates, score 7.004) (writing took 2.943758104927838 seconds)
2024-07-10 19:35:11 | INFO | train_inner | epoch 005:   2084 / 13004 loss=6.659, nll_loss=5.566, ppl=47.38, wps=20125.5, ups=5.13, wpb=3925.7, bsz=150.6, num_updates=54100, lr=0.000135957, gnorm=0.932, train_wall=15, wall=0
2024-07-10 19:35:26 | INFO | train_inner | epoch 005:   2184 / 13004 loss=6.62, nll_loss=5.521, ppl=45.91, wps=25564.6, ups=6.55, wpb=3903.3, bsz=110.3, num_updates=54200, lr=0.000135831, gnorm=0.877, train_wall=15, wall=0
2024-07-10 19:35:41 | INFO | train_inner | epoch 005:   2284 / 13004 loss=6.654, nll_loss=5.56, ppl=47.19, wps=25779.1, ups=6.55, wpb=3936.3, bsz=146.8, num_updates=54300, lr=0.000135706, gnorm=0.911, train_wall=15, wall=0
2024-07-10 19:35:57 | INFO | train_inner | epoch 005:   2384 / 13004 loss=6.644, nll_loss=5.549, ppl=46.81, wps=25611.6, ups=6.5, wpb=3938, bsz=139.2, num_updates=54400, lr=0.000135582, gnorm=0.892, train_wall=15, wall=0
2024-07-10 19:36:12 | INFO | train_inner | epoch 005:   2484 / 13004 loss=6.615, nll_loss=5.515, ppl=45.73, wps=25542, ups=6.49, wpb=3937.8, bsz=127.8, num_updates=54500, lr=0.000135457, gnorm=0.875, train_wall=15, wall=0
2024-07-10 19:36:27 | INFO | train_inner | epoch 005:   2584 / 13004 loss=6.616, nll_loss=5.516, ppl=45.78, wps=25395.3, ups=6.48, wpb=3921.9, bsz=143.6, num_updates=54600, lr=0.000135333, gnorm=0.885, train_wall=15, wall=0
2024-07-10 19:36:43 | INFO | train_inner | epoch 005:   2684 / 13004 loss=6.625, nll_loss=5.527, ppl=46.1, wps=25778.2, ups=6.58, wpb=3919.1, bsz=123.6, num_updates=54700, lr=0.000135209, gnorm=0.891, train_wall=15, wall=0
2024-07-10 19:36:58 | INFO | train_inner | epoch 005:   2784 / 13004 loss=6.613, nll_loss=5.513, ppl=45.66, wps=25753.4, ups=6.55, wpb=3929.8, bsz=136.4, num_updates=54800, lr=0.000135086, gnorm=0.908, train_wall=15, wall=0
2024-07-10 19:37:13 | INFO | train_inner | epoch 005:   2884 / 13004 loss=6.612, nll_loss=5.512, ppl=45.65, wps=25523, ups=6.52, wpb=3913.6, bsz=147.5, num_updates=54900, lr=0.000134963, gnorm=0.898, train_wall=15, wall=0
2024-07-10 19:37:28 | INFO | train_inner | epoch 005:   2984 / 13004 loss=6.626, nll_loss=5.527, ppl=46.11, wps=25677.4, ups=6.58, wpb=3904, bsz=123.1, num_updates=55000, lr=0.00013484, gnorm=0.893, train_wall=15, wall=0
2024-07-10 19:37:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:37:30 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.994 | nll_loss 5.872 | ppl 58.56 | wps 94892.1 | wpb 3703.5 | bsz 124.5 | num_updates 55000 | best_loss 6.994
2024-07-10 19:37:30 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:37:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_55000.pt (epoch 5 @ 55000 updates, score 6.994) (writing took 4.679678180254996 seconds)
2024-07-10 19:37:50 | INFO | train_inner | epoch 005:   3084 / 13004 loss=6.579, nll_loss=5.474, ppl=44.45, wps=18604.3, ups=4.75, wpb=3916.6, bsz=125.2, num_updates=55100, lr=0.000134718, gnorm=0.886, train_wall=15, wall=0
2024-07-10 19:38:05 | INFO | train_inner | epoch 005:   3184 / 13004 loss=6.618, nll_loss=5.519, ppl=45.86, wps=25355.5, ups=6.48, wpb=3910.8, bsz=111.3, num_updates=55200, lr=0.000134595, gnorm=0.88, train_wall=15, wall=0
2024-07-10 19:38:20 | INFO | train_inner | epoch 005:   3284 / 13004 loss=6.626, nll_loss=5.529, ppl=46.16, wps=25528.2, ups=6.49, wpb=3935.4, bsz=135.3, num_updates=55300, lr=0.000134474, gnorm=0.901, train_wall=15, wall=0
2024-07-10 19:38:36 | INFO | train_inner | epoch 005:   3384 / 13004 loss=6.632, nll_loss=5.534, ppl=46.32, wps=25640.1, ups=6.56, wpb=3906.6, bsz=124.5, num_updates=55400, lr=0.000134352, gnorm=0.931, train_wall=15, wall=0
2024-07-10 19:38:51 | INFO | train_inner | epoch 005:   3484 / 13004 loss=6.578, nll_loss=5.475, ppl=44.47, wps=25561.9, ups=6.52, wpb=3918.3, bsz=133.9, num_updates=55500, lr=0.000134231, gnorm=0.876, train_wall=15, wall=0
2024-07-10 19:39:06 | INFO | train_inner | epoch 005:   3584 / 13004 loss=6.59, nll_loss=5.486, ppl=44.83, wps=25822.6, ups=6.55, wpb=3941.4, bsz=135, num_updates=55600, lr=0.00013411, gnorm=0.896, train_wall=15, wall=0
2024-07-10 19:39:21 | INFO | train_inner | epoch 005:   3684 / 13004 loss=6.653, nll_loss=5.558, ppl=47.12, wps=25755.2, ups=6.59, wpb=3906.1, bsz=126, num_updates=55700, lr=0.00013399, gnorm=0.925, train_wall=15, wall=0
2024-07-10 19:39:37 | INFO | train_inner | epoch 005:   3784 / 13004 loss=6.623, nll_loss=5.525, ppl=46.04, wps=25728.1, ups=6.57, wpb=3915.4, bsz=130.2, num_updates=55800, lr=0.00013387, gnorm=0.888, train_wall=15, wall=0
2024-07-10 19:39:52 | INFO | train_inner | epoch 005:   3884 / 13004 loss=6.603, nll_loss=5.503, ppl=45.34, wps=25840.2, ups=6.55, wpb=3943.8, bsz=147.4, num_updates=55900, lr=0.00013375, gnorm=0.891, train_wall=15, wall=0
2024-07-10 19:40:07 | INFO | train_inner | epoch 005:   3984 / 13004 loss=6.631, nll_loss=5.534, ppl=46.33, wps=25905.2, ups=6.57, wpb=3944.9, bsz=141.8, num_updates=56000, lr=0.000133631, gnorm=0.889, train_wall=15, wall=0
2024-07-10 19:40:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:40:08 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.996 | nll_loss 5.874 | ppl 58.64 | wps 94611.1 | wpb 3703.5 | bsz 124.5 | num_updates 56000 | best_loss 6.994
2024-07-10 19:40:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:40:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_56000.pt (epoch 5 @ 56000 updates, score 6.996) (writing took 3.5183560391888022 seconds)
2024-07-10 19:40:27 | INFO | train_inner | epoch 005:   4084 / 13004 loss=6.668, nll_loss=5.576, ppl=47.69, wps=19434.7, ups=4.98, wpb=3902.4, bsz=139.7, num_updates=56100, lr=0.000133511, gnorm=0.939, train_wall=15, wall=0
2024-07-10 19:40:43 | INFO | train_inner | epoch 005:   4184 / 13004 loss=6.651, nll_loss=5.556, ppl=47.05, wps=25557.4, ups=6.51, wpb=3928.3, bsz=134.5, num_updates=56200, lr=0.000133393, gnorm=0.928, train_wall=15, wall=0
2024-07-10 19:40:58 | INFO | train_inner | epoch 005:   4284 / 13004 loss=6.602, nll_loss=5.5, ppl=45.25, wps=25482.5, ups=6.53, wpb=3899.8, bsz=118.2, num_updates=56300, lr=0.000133274, gnorm=0.886, train_wall=15, wall=0
2024-07-10 19:41:13 | INFO | train_inner | epoch 005:   4384 / 13004 loss=6.588, nll_loss=5.484, ppl=44.75, wps=25507.1, ups=6.59, wpb=3868.4, bsz=118.1, num_updates=56400, lr=0.000133156, gnorm=0.897, train_wall=15, wall=0
2024-07-10 19:41:28 | INFO | train_inner | epoch 005:   4484 / 13004 loss=6.614, nll_loss=5.514, ppl=45.69, wps=25338, ups=6.49, wpb=3905, bsz=127.3, num_updates=56500, lr=0.000133038, gnorm=0.883, train_wall=15, wall=0
2024-07-10 19:41:44 | INFO | train_inner | epoch 005:   4584 / 13004 loss=6.625, nll_loss=5.526, ppl=46.09, wps=25489.5, ups=6.5, wpb=3922.7, bsz=119.8, num_updates=56600, lr=0.00013292, gnorm=0.882, train_wall=15, wall=0
2024-07-10 19:41:59 | INFO | train_inner | epoch 005:   4684 / 13004 loss=6.635, nll_loss=5.538, ppl=46.45, wps=25391.3, ups=6.46, wpb=3931.4, bsz=135.4, num_updates=56700, lr=0.000132803, gnorm=0.915, train_wall=15, wall=0
2024-07-10 19:42:15 | INFO | train_inner | epoch 005:   4784 / 13004 loss=6.612, nll_loss=5.513, ppl=45.66, wps=25589.5, ups=6.52, wpb=3927.1, bsz=128.7, num_updates=56800, lr=0.000132686, gnorm=0.885, train_wall=15, wall=0
2024-07-10 19:42:30 | INFO | train_inner | epoch 005:   4884 / 13004 loss=6.603, nll_loss=5.501, ppl=45.3, wps=25602.9, ups=6.55, wpb=3911.7, bsz=121.3, num_updates=56900, lr=0.00013257, gnorm=0.884, train_wall=15, wall=0
2024-07-10 19:42:45 | INFO | train_inner | epoch 005:   4984 / 13004 loss=6.602, nll_loss=5.5, ppl=45.27, wps=25690.9, ups=6.54, wpb=3926.1, bsz=118.3, num_updates=57000, lr=0.000132453, gnorm=0.883, train_wall=15, wall=0
2024-07-10 19:42:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:42:46 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.986 | nll_loss 5.866 | ppl 58.33 | wps 94298.2 | wpb 3703.5 | bsz 124.5 | num_updates 57000 | best_loss 6.986
2024-07-10 19:42:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:43:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_57000.pt (epoch 5 @ 57000 updates, score 6.986) (writing took 16.628629425540566 seconds)
2024-07-10 19:43:18 | INFO | train_inner | epoch 005:   5084 / 13004 loss=6.692, nll_loss=5.604, ppl=48.62, wps=11753.4, ups=3.02, wpb=3895.5, bsz=155.3, num_updates=57100, lr=0.000132337, gnorm=1.003, train_wall=15, wall=0
2024-07-10 19:43:34 | INFO | train_inner | epoch 005:   5184 / 13004 loss=6.65, nll_loss=5.556, ppl=47.04, wps=25521.7, ups=6.54, wpb=3903.8, bsz=139.1, num_updates=57200, lr=0.000132221, gnorm=0.929, train_wall=15, wall=0
2024-07-10 19:43:49 | INFO | train_inner | epoch 005:   5284 / 13004 loss=6.652, nll_loss=5.559, ppl=47.13, wps=25570, ups=6.56, wpb=3900.8, bsz=136.7, num_updates=57300, lr=0.000132106, gnorm=0.918, train_wall=15, wall=0
2024-07-10 19:44:04 | INFO | train_inner | epoch 005:   5384 / 13004 loss=6.655, nll_loss=5.562, ppl=47.25, wps=25640.4, ups=6.54, wpb=3918, bsz=150, num_updates=57400, lr=0.000131991, gnorm=0.937, train_wall=15, wall=0
2024-07-10 19:44:20 | INFO | train_inner | epoch 005:   5484 / 13004 loss=6.582, nll_loss=5.477, ppl=44.54, wps=25586.4, ups=6.53, wpb=3919.8, bsz=126.4, num_updates=57500, lr=0.000131876, gnorm=0.877, train_wall=15, wall=0
2024-07-10 19:44:35 | INFO | train_inner | epoch 005:   5584 / 13004 loss=6.627, nll_loss=5.529, ppl=46.19, wps=25526.2, ups=6.51, wpb=3922.3, bsz=123.8, num_updates=57600, lr=0.000131762, gnorm=0.898, train_wall=15, wall=0
2024-07-10 19:44:50 | INFO | train_inner | epoch 005:   5684 / 13004 loss=6.69, nll_loss=5.602, ppl=48.57, wps=25682, ups=6.53, wpb=3934.8, bsz=149.8, num_updates=57700, lr=0.000131647, gnorm=0.943, train_wall=15, wall=0
2024-07-10 19:45:06 | INFO | train_inner | epoch 005:   5784 / 13004 loss=6.625, nll_loss=5.527, ppl=46.12, wps=25583, ups=6.53, wpb=3917.4, bsz=118.6, num_updates=57800, lr=0.000131533, gnorm=0.875, train_wall=15, wall=0
2024-07-10 19:45:21 | INFO | train_inner | epoch 005:   5884 / 13004 loss=6.639, nll_loss=5.542, ppl=46.6, wps=25753.6, ups=6.59, wpb=3905.8, bsz=115, num_updates=57900, lr=0.00013142, gnorm=0.904, train_wall=15, wall=0
2024-07-10 19:45:36 | INFO | train_inner | epoch 005:   5984 / 13004 loss=6.598, nll_loss=5.495, ppl=45.09, wps=25646.9, ups=6.55, wpb=3917.7, bsz=122.6, num_updates=58000, lr=0.000131306, gnorm=0.89, train_wall=15, wall=0
2024-07-10 19:45:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:45:37 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.978 | nll_loss 5.856 | ppl 57.91 | wps 95892.1 | wpb 3703.5 | bsz 124.5 | num_updates 58000 | best_loss 6.978
2024-07-10 19:45:37 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:45:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_58000.pt (epoch 5 @ 58000 updates, score 6.978) (writing took 6.149121740832925 seconds)
2024-07-10 19:45:59 | INFO | train_inner | epoch 005:   6084 / 13004 loss=6.621, nll_loss=5.522, ppl=45.96, wps=17306.2, ups=4.43, wpb=3910.7, bsz=142.7, num_updates=58100, lr=0.000131193, gnorm=0.91, train_wall=15, wall=0
2024-07-10 19:46:14 | INFO | train_inner | epoch 005:   6184 / 13004 loss=6.622, nll_loss=5.523, ppl=45.99, wps=25629.4, ups=6.57, wpb=3901.7, bsz=121.5, num_updates=58200, lr=0.000131081, gnorm=0.887, train_wall=15, wall=0
2024-07-10 19:46:29 | INFO | train_inner | epoch 005:   6284 / 13004 loss=6.646, nll_loss=5.551, ppl=46.89, wps=25598.6, ups=6.54, wpb=3915.7, bsz=137.8, num_updates=58300, lr=0.000130968, gnorm=0.934, train_wall=15, wall=0
2024-07-10 19:46:44 | INFO | train_inner | epoch 005:   6384 / 13004 loss=6.609, nll_loss=5.509, ppl=45.53, wps=25765.1, ups=6.58, wpb=3916.8, bsz=130.9, num_updates=58400, lr=0.000130856, gnorm=0.889, train_wall=15, wall=0
2024-07-10 19:47:00 | INFO | train_inner | epoch 005:   6484 / 13004 loss=6.692, nll_loss=5.604, ppl=48.62, wps=25404.8, ups=6.47, wpb=3926.1, bsz=161.6, num_updates=58500, lr=0.000130744, gnorm=0.977, train_wall=15, wall=0
2024-07-10 19:47:15 | INFO | train_inner | epoch 005:   6584 / 13004 loss=6.633, nll_loss=5.536, ppl=46.4, wps=25622.6, ups=6.57, wpb=3897.8, bsz=134.6, num_updates=58600, lr=0.000130632, gnorm=0.904, train_wall=15, wall=0
2024-07-10 19:47:30 | INFO | train_inner | epoch 005:   6684 / 13004 loss=6.654, nll_loss=5.56, ppl=47.16, wps=25645.6, ups=6.58, wpb=3899.7, bsz=140.6, num_updates=58700, lr=0.000130521, gnorm=0.951, train_wall=15, wall=0
2024-07-10 19:47:45 | INFO | train_inner | epoch 005:   6784 / 13004 loss=6.625, nll_loss=5.527, ppl=46.09, wps=25701.2, ups=6.59, wpb=3901.4, bsz=126.9, num_updates=58800, lr=0.00013041, gnorm=0.918, train_wall=15, wall=0
2024-07-10 19:48:00 | INFO | train_inner | epoch 005:   6884 / 13004 loss=6.628, nll_loss=5.531, ppl=46.23, wps=25794.5, ups=6.62, wpb=3899.3, bsz=142.1, num_updates=58900, lr=0.000130299, gnorm=0.906, train_wall=15, wall=0
2024-07-10 19:48:16 | INFO | train_inner | epoch 005:   6984 / 13004 loss=6.605, nll_loss=5.504, ppl=45.38, wps=25613.6, ups=6.53, wpb=3921.3, bsz=140.3, num_updates=59000, lr=0.000130189, gnorm=0.894, train_wall=15, wall=0
2024-07-10 19:48:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:48:17 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.985 | nll_loss 5.867 | ppl 58.36 | wps 94695.4 | wpb 3703.5 | bsz 124.5 | num_updates 59000 | best_loss 6.978
2024-07-10 19:48:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:48:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_59000.pt (epoch 5 @ 59000 updates, score 6.985) (writing took 3.987750118598342 seconds)
2024-07-10 19:48:36 | INFO | train_inner | epoch 005:   7084 / 13004 loss=6.614, nll_loss=5.514, ppl=45.7, wps=19171.4, ups=4.88, wpb=3930.5, bsz=124.3, num_updates=59100, lr=0.000130079, gnorm=0.899, train_wall=15, wall=0
2024-07-10 19:48:51 | INFO | train_inner | epoch 005:   7184 / 13004 loss=6.595, nll_loss=5.492, ppl=45, wps=25588, ups=6.56, wpb=3900.9, bsz=126.6, num_updates=59200, lr=0.000129969, gnorm=0.905, train_wall=15, wall=0
2024-07-10 19:49:07 | INFO | train_inner | epoch 005:   7284 / 13004 loss=6.637, nll_loss=5.541, ppl=46.57, wps=25810.3, ups=6.58, wpb=3919.7, bsz=134.6, num_updates=59300, lr=0.000129859, gnorm=0.895, train_wall=15, wall=0
2024-07-10 19:49:22 | INFO | train_inner | epoch 005:   7384 / 13004 loss=6.604, nll_loss=5.503, ppl=45.36, wps=25762.3, ups=6.57, wpb=3919.9, bsz=125.4, num_updates=59400, lr=0.00012975, gnorm=0.891, train_wall=15, wall=0
2024-07-10 19:49:37 | INFO | train_inner | epoch 005:   7484 / 13004 loss=6.627, nll_loss=5.529, ppl=46.17, wps=25631.6, ups=6.51, wpb=3935.7, bsz=150, num_updates=59500, lr=0.000129641, gnorm=0.918, train_wall=15, wall=0
2024-07-10 19:49:53 | INFO | train_inner | epoch 005:   7584 / 13004 loss=6.618, nll_loss=5.52, ppl=45.89, wps=25564.1, ups=6.53, wpb=3915.9, bsz=127, num_updates=59600, lr=0.000129532, gnorm=0.889, train_wall=15, wall=0
2024-07-10 19:50:08 | INFO | train_inner | epoch 005:   7684 / 13004 loss=6.633, nll_loss=5.535, ppl=46.37, wps=25840.7, ups=6.62, wpb=3906.2, bsz=122.7, num_updates=59700, lr=0.000129423, gnorm=0.909, train_wall=15, wall=0
2024-07-10 19:50:23 | INFO | train_inner | epoch 005:   7784 / 13004 loss=6.649, nll_loss=5.555, ppl=47.01, wps=25770.6, ups=6.57, wpb=3921.7, bsz=142.8, num_updates=59800, lr=0.000129315, gnorm=0.945, train_wall=15, wall=0
2024-07-10 19:50:38 | INFO | train_inner | epoch 005:   7884 / 13004 loss=6.618, nll_loss=5.519, ppl=45.85, wps=25573.7, ups=6.53, wpb=3913.8, bsz=117.8, num_updates=59900, lr=0.000129207, gnorm=0.895, train_wall=15, wall=0
2024-07-10 19:50:54 | INFO | train_inner | epoch 005:   7984 / 13004 loss=6.625, nll_loss=5.528, ppl=46.14, wps=25647.4, ups=6.53, wpb=3928.4, bsz=142.2, num_updates=60000, lr=0.000129099, gnorm=0.915, train_wall=15, wall=0
2024-07-10 19:50:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:50:55 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.977 | nll_loss 5.85 | ppl 57.7 | wps 94276.9 | wpb 3703.5 | bsz 124.5 | num_updates 60000 | best_loss 6.977
2024-07-10 19:50:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:51:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_60000.pt (epoch 5 @ 60000 updates, score 6.977) (writing took 5.7455718126147985 seconds)
2024-07-10 19:51:16 | INFO | train_inner | epoch 005:   8084 / 13004 loss=6.616, nll_loss=5.517, ppl=45.8, wps=17692.1, ups=4.48, wpb=3950.2, bsz=134.3, num_updates=60100, lr=0.000128992, gnorm=0.898, train_wall=15, wall=0
2024-07-10 19:51:31 | INFO | train_inner | epoch 005:   8184 / 13004 loss=6.616, nll_loss=5.517, ppl=45.8, wps=25584.2, ups=6.51, wpb=3933, bsz=140.3, num_updates=60200, lr=0.000128885, gnorm=0.913, train_wall=15, wall=0
2024-07-10 19:51:47 | INFO | train_inner | epoch 005:   8284 / 13004 loss=6.596, nll_loss=5.495, ppl=45.08, wps=25581.2, ups=6.55, wpb=3907.5, bsz=127.8, num_updates=60300, lr=0.000128778, gnorm=0.896, train_wall=15, wall=0
2024-07-10 19:52:02 | INFO | train_inner | epoch 005:   8384 / 13004 loss=6.641, nll_loss=5.545, ppl=46.7, wps=25584.8, ups=6.5, wpb=3938.8, bsz=136.5, num_updates=60400, lr=0.000128671, gnorm=0.914, train_wall=15, wall=0
2024-07-10 19:52:17 | INFO | train_inner | epoch 005:   8484 / 13004 loss=6.605, nll_loss=5.505, ppl=45.4, wps=25431.4, ups=6.49, wpb=3917, bsz=126.2, num_updates=60500, lr=0.000128565, gnorm=0.89, train_wall=15, wall=0
2024-07-10 19:52:33 | INFO | train_inner | epoch 005:   8584 / 13004 loss=6.612, nll_loss=5.512, ppl=45.64, wps=25842.1, ups=6.57, wpb=3935.4, bsz=148.2, num_updates=60600, lr=0.000128459, gnorm=0.903, train_wall=15, wall=0
2024-07-10 19:52:48 | INFO | train_inner | epoch 005:   8684 / 13004 loss=6.645, nll_loss=5.551, ppl=46.87, wps=25600.3, ups=6.57, wpb=3894.6, bsz=136.2, num_updates=60700, lr=0.000128353, gnorm=0.976, train_wall=15, wall=0
2024-07-10 19:53:03 | INFO | train_inner | epoch 005:   8784 / 13004 loss=6.626, nll_loss=5.53, ppl=46.2, wps=25459.1, ups=6.51, wpb=3910.3, bsz=143.1, num_updates=60800, lr=0.000128247, gnorm=0.908, train_wall=15, wall=0
2024-07-10 19:53:18 | INFO | train_inner | epoch 005:   8884 / 13004 loss=6.582, nll_loss=5.478, ppl=44.57, wps=25503.9, ups=6.55, wpb=3893.4, bsz=123.5, num_updates=60900, lr=0.000128142, gnorm=0.898, train_wall=15, wall=0
2024-07-10 19:53:34 | INFO | train_inner | epoch 005:   8984 / 13004 loss=6.585, nll_loss=5.483, ppl=44.71, wps=25598.5, ups=6.51, wpb=3929.8, bsz=135.4, num_updates=61000, lr=0.000128037, gnorm=0.884, train_wall=15, wall=0
2024-07-10 19:53:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:53:35 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.978 | nll_loss 5.859 | ppl 58.06 | wps 94388.2 | wpb 3703.5 | bsz 124.5 | num_updates 61000 | best_loss 6.977
2024-07-10 19:53:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:53:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_61000.pt (epoch 5 @ 61000 updates, score 6.978) (writing took 2.846766031347215 seconds)
2024-07-10 19:53:53 | INFO | train_inner | epoch 005:   9084 / 13004 loss=6.639, nll_loss=5.543, ppl=46.61, wps=20124.3, ups=5.13, wpb=3924.5, bsz=126.6, num_updates=61100, lr=0.000127932, gnorm=0.918, train_wall=15, wall=0
2024-07-10 19:54:09 | INFO | train_inner | epoch 005:   9184 / 13004 loss=6.626, nll_loss=5.529, ppl=46.16, wps=25278.4, ups=6.5, wpb=3887.3, bsz=128, num_updates=61200, lr=0.000127827, gnorm=0.915, train_wall=15, wall=0
2024-07-10 19:54:24 | INFO | train_inner | epoch 005:   9284 / 13004 loss=6.568, nll_loss=5.463, ppl=44.1, wps=25471.8, ups=6.45, wpb=3948.4, bsz=136.1, num_updates=61300, lr=0.000127723, gnorm=0.881, train_wall=15, wall=0
2024-07-10 19:54:40 | INFO | train_inner | epoch 005:   9384 / 13004 loss=6.643, nll_loss=5.548, ppl=46.79, wps=25455.8, ups=6.45, wpb=3949.7, bsz=154.8, num_updates=61400, lr=0.000127619, gnorm=0.947, train_wall=15, wall=0
2024-07-10 19:54:55 | INFO | train_inner | epoch 005:   9484 / 13004 loss=6.612, nll_loss=5.512, ppl=45.63, wps=25408, ups=6.47, wpb=3924.4, bsz=125.6, num_updates=61500, lr=0.000127515, gnorm=0.906, train_wall=15, wall=0
2024-07-10 19:55:10 | INFO | train_inner | epoch 005:   9584 / 13004 loss=6.581, nll_loss=5.477, ppl=44.53, wps=25584.6, ups=6.52, wpb=3924.7, bsz=127.6, num_updates=61600, lr=0.000127412, gnorm=0.895, train_wall=15, wall=0
2024-07-10 19:55:26 | INFO | train_inner | epoch 005:   9684 / 13004 loss=6.596, nll_loss=5.494, ppl=45.08, wps=25693.5, ups=6.55, wpb=3921.8, bsz=133.7, num_updates=61700, lr=0.000127309, gnorm=0.897, train_wall=15, wall=0
2024-07-10 19:55:41 | INFO | train_inner | epoch 005:   9784 / 13004 loss=6.588, nll_loss=5.485, ppl=44.79, wps=25939.4, ups=6.6, wpb=3930.2, bsz=131.4, num_updates=61800, lr=0.000127205, gnorm=0.889, train_wall=15, wall=0
2024-07-10 19:55:56 | INFO | train_inner | epoch 005:   9884 / 13004 loss=6.6, nll_loss=5.499, ppl=45.21, wps=25607.5, ups=6.53, wpb=3919.7, bsz=130.4, num_updates=61900, lr=0.000127103, gnorm=0.912, train_wall=15, wall=0
2024-07-10 19:56:11 | INFO | train_inner | epoch 005:   9984 / 13004 loss=6.616, nll_loss=5.517, ppl=45.79, wps=25809.4, ups=6.56, wpb=3934.6, bsz=144.6, num_updates=62000, lr=0.000127, gnorm=0.917, train_wall=15, wall=0
2024-07-10 19:56:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:56:13 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.985 | nll_loss 5.869 | ppl 58.45 | wps 95717.3 | wpb 3703.5 | bsz 124.5 | num_updates 62000 | best_loss 6.977
2024-07-10 19:56:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:56:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_62000.pt (epoch 5 @ 62000 updates, score 6.985) (writing took 2.753152186051011 seconds)
2024-07-10 19:56:31 | INFO | train_inner | epoch 005:  10084 / 13004 loss=6.57, nll_loss=5.464, ppl=44.14, wps=20522.9, ups=5.22, wpb=3929.9, bsz=127.7, num_updates=62100, lr=0.000126898, gnorm=0.892, train_wall=15, wall=0
2024-07-10 19:56:46 | INFO | train_inner | epoch 005:  10184 / 13004 loss=6.67, nll_loss=5.578, ppl=47.79, wps=25763.9, ups=6.52, wpb=3951.4, bsz=133.7, num_updates=62200, lr=0.000126796, gnorm=0.926, train_wall=15, wall=0
2024-07-10 19:57:01 | INFO | train_inner | epoch 005:  10284 / 13004 loss=6.606, nll_loss=5.506, ppl=45.45, wps=25607.2, ups=6.52, wpb=3927.4, bsz=129.8, num_updates=62300, lr=0.000126694, gnorm=0.897, train_wall=15, wall=0
2024-07-10 19:57:16 | INFO | train_inner | epoch 005:  10384 / 13004 loss=6.607, nll_loss=5.507, ppl=45.47, wps=25716.9, ups=6.59, wpb=3905.1, bsz=119.3, num_updates=62400, lr=0.000126592, gnorm=0.9, train_wall=15, wall=0
2024-07-10 19:57:32 | INFO | train_inner | epoch 005:  10484 / 13004 loss=6.636, nll_loss=5.54, ppl=46.52, wps=25634.2, ups=6.57, wpb=3903.2, bsz=139.8, num_updates=62500, lr=0.000126491, gnorm=0.951, train_wall=15, wall=0
2024-07-10 19:57:47 | INFO | train_inner | epoch 005:  10584 / 13004 loss=6.571, nll_loss=5.464, ppl=44.15, wps=25589.1, ups=6.58, wpb=3888.9, bsz=115.1, num_updates=62600, lr=0.00012639, gnorm=0.904, train_wall=15, wall=0
2024-07-10 19:58:02 | INFO | train_inner | epoch 005:  10684 / 13004 loss=6.592, nll_loss=5.489, ppl=44.92, wps=25659.6, ups=6.53, wpb=3928.3, bsz=140.2, num_updates=62700, lr=0.000126289, gnorm=0.919, train_wall=15, wall=0
2024-07-10 19:58:17 | INFO | train_inner | epoch 005:  10784 / 13004 loss=6.595, nll_loss=5.493, ppl=45.05, wps=25994.2, ups=6.63, wpb=3920.4, bsz=137.8, num_updates=62800, lr=0.000126189, gnorm=0.881, train_wall=15, wall=0
2024-07-10 19:58:33 | INFO | train_inner | epoch 005:  10884 / 13004 loss=6.573, nll_loss=5.467, ppl=44.23, wps=25439.8, ups=6.5, wpb=3915, bsz=123, num_updates=62900, lr=0.000126088, gnorm=0.89, train_wall=15, wall=0
2024-07-10 19:58:48 | INFO | train_inner | epoch 005:  10984 / 13004 loss=6.596, nll_loss=5.494, ppl=45.07, wps=25629.9, ups=6.52, wpb=3932.3, bsz=131.1, num_updates=63000, lr=0.000125988, gnorm=0.903, train_wall=15, wall=0
2024-07-10 19:58:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 19:58:49 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.97 | nll_loss 5.848 | ppl 57.59 | wps 96380.8 | wpb 3703.5 | bsz 124.5 | num_updates 63000 | best_loss 6.97
2024-07-10 19:58:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 19:58:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_63000.pt (epoch 5 @ 63000 updates, score 6.97) (writing took 4.948494992218912 seconds)
2024-07-10 19:59:09 | INFO | train_inner | epoch 005:  11084 / 13004 loss=6.592, nll_loss=5.49, ppl=44.94, wps=18261.5, ups=4.68, wpb=3900.8, bsz=122.4, num_updates=63100, lr=0.000125888, gnorm=0.911, train_wall=15, wall=0
2024-07-10 19:59:25 | INFO | train_inner | epoch 005:  11184 / 13004 loss=6.602, nll_loss=5.501, ppl=45.29, wps=25838.9, ups=6.55, wpb=3942.9, bsz=140.3, num_updates=63200, lr=0.000125789, gnorm=0.898, train_wall=15, wall=0
2024-07-10 19:59:40 | INFO | train_inner | epoch 005:  11284 / 13004 loss=6.592, nll_loss=5.489, ppl=44.91, wps=25650.9, ups=6.55, wpb=3917.3, bsz=125.3, num_updates=63300, lr=0.000125689, gnorm=0.894, train_wall=15, wall=0
2024-07-10 19:59:55 | INFO | train_inner | epoch 005:  11384 / 13004 loss=6.616, nll_loss=5.517, ppl=45.8, wps=25629.1, ups=6.56, wpb=3908.9, bsz=136.2, num_updates=63400, lr=0.00012559, gnorm=0.905, train_wall=15, wall=0
2024-07-10 20:00:10 | INFO | train_inner | epoch 005:  11484 / 13004 loss=6.623, nll_loss=5.526, ppl=46.07, wps=25489.3, ups=6.5, wpb=3921.7, bsz=153, num_updates=63500, lr=0.000125491, gnorm=0.95, train_wall=15, wall=0
2024-07-10 20:00:26 | INFO | train_inner | epoch 005:  11584 / 13004 loss=6.575, nll_loss=5.47, ppl=44.32, wps=25916.8, ups=6.59, wpb=3930.8, bsz=127.1, num_updates=63600, lr=0.000125392, gnorm=0.88, train_wall=15, wall=0
2024-07-10 20:00:41 | INFO | train_inner | epoch 005:  11684 / 13004 loss=6.647, nll_loss=5.553, ppl=46.94, wps=25861.5, ups=6.58, wpb=3929.4, bsz=156.9, num_updates=63700, lr=0.000125294, gnorm=0.948, train_wall=15, wall=0
2024-07-10 20:00:56 | INFO | train_inner | epoch 005:  11784 / 13004 loss=6.598, nll_loss=5.497, ppl=45.16, wps=25641.8, ups=6.54, wpb=3921.2, bsz=126.8, num_updates=63800, lr=0.000125196, gnorm=0.884, train_wall=15, wall=0
2024-07-10 20:01:12 | INFO | train_inner | epoch 005:  11884 / 13004 loss=6.653, nll_loss=5.559, ppl=47.13, wps=25119.4, ups=6.42, wpb=3915.4, bsz=141, num_updates=63900, lr=0.000125098, gnorm=0.961, train_wall=15, wall=0
2024-07-10 20:01:27 | INFO | train_inner | epoch 005:  11984 / 13004 loss=6.622, nll_loss=5.524, ppl=46, wps=25644.9, ups=6.58, wpb=3898.6, bsz=120.7, num_updates=64000, lr=0.000125, gnorm=0.91, train_wall=15, wall=0
2024-07-10 20:01:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:01:28 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.973 | nll_loss 5.849 | ppl 57.62 | wps 95156.5 | wpb 3703.5 | bsz 124.5 | num_updates 64000 | best_loss 6.97
2024-07-10 20:01:28 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:01:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_64000.pt (epoch 5 @ 64000 updates, score 6.973) (writing took 2.7386651430279016 seconds)
2024-07-10 20:01:46 | INFO | train_inner | epoch 005:  12084 / 13004 loss=6.578, nll_loss=5.474, ppl=44.46, wps=20670.6, ups=5.26, wpb=3931, bsz=128.8, num_updates=64100, lr=0.000124902, gnorm=0.889, train_wall=15, wall=0
2024-07-10 20:02:01 | INFO | train_inner | epoch 005:  12184 / 13004 loss=6.636, nll_loss=5.54, ppl=46.51, wps=25632.6, ups=6.53, wpb=3922.9, bsz=144.6, num_updates=64200, lr=0.000124805, gnorm=0.964, train_wall=15, wall=0
2024-07-10 20:02:17 | INFO | train_inner | epoch 005:  12284 / 13004 loss=6.588, nll_loss=5.485, ppl=44.79, wps=25766.6, ups=6.55, wpb=3932.8, bsz=133.6, num_updates=64300, lr=0.000124708, gnorm=0.903, train_wall=15, wall=0
2024-07-10 20:02:32 | INFO | train_inner | epoch 005:  12384 / 13004 loss=6.61, nll_loss=5.511, ppl=45.59, wps=25652.7, ups=6.51, wpb=3940.1, bsz=125.9, num_updates=64400, lr=0.000124611, gnorm=0.909, train_wall=15, wall=0
2024-07-10 20:02:47 | INFO | train_inner | epoch 005:  12484 / 13004 loss=6.593, nll_loss=5.491, ppl=44.96, wps=25594.8, ups=6.5, wpb=3936.9, bsz=134.8, num_updates=64500, lr=0.000124515, gnorm=0.9, train_wall=15, wall=0
2024-07-10 20:03:03 | INFO | train_inner | epoch 005:  12584 / 13004 loss=6.63, nll_loss=5.533, ppl=46.3, wps=25631.5, ups=6.53, wpb=3924.2, bsz=133.3, num_updates=64600, lr=0.000124418, gnorm=0.916, train_wall=15, wall=0
2024-07-10 20:03:18 | INFO | train_inner | epoch 005:  12684 / 13004 loss=6.627, nll_loss=5.53, ppl=46.21, wps=25683.4, ups=6.52, wpb=3936.5, bsz=146.1, num_updates=64700, lr=0.000124322, gnorm=0.947, train_wall=15, wall=0
2024-07-10 20:03:33 | INFO | train_inner | epoch 005:  12784 / 13004 loss=6.604, nll_loss=5.503, ppl=45.35, wps=25657, ups=6.55, wpb=3918.8, bsz=146.6, num_updates=64800, lr=0.000124226, gnorm=0.943, train_wall=15, wall=0
2024-07-10 20:03:49 | INFO | train_inner | epoch 005:  12884 / 13004 loss=6.569, nll_loss=5.464, ppl=44.13, wps=25521.5, ups=6.47, wpb=3942.3, bsz=126.4, num_updates=64900, lr=0.00012413, gnorm=0.884, train_wall=15, wall=0
2024-07-10 20:04:04 | INFO | train_inner | epoch 005:  12984 / 13004 loss=6.603, nll_loss=5.502, ppl=45.32, wps=25530.5, ups=6.5, wpb=3926.2, bsz=113.5, num_updates=65000, lr=0.000124035, gnorm=0.895, train_wall=15, wall=0
2024-07-10 20:04:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:04:05 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.955 | nll_loss 5.831 | ppl 56.93 | wps 95588.8 | wpb 3703.5 | bsz 124.5 | num_updates 65000 | best_loss 6.955
2024-07-10 20:04:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:04:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_65000.pt (epoch 5 @ 65000 updates, score 6.955) (writing took 5.250300246290863 seconds)
2024-07-10 20:04:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:04:15 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.97 | nll_loss 5.846 | ppl 57.54 | wps 95088.8 | wpb 3703.5 | bsz 124.5 | num_updates 65020 | best_loss 6.955
2024-07-10 20:04:15 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:04:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 5 @ 65020 updates, score 6.97) (writing took 2.5332655711099505 seconds)
2024-07-10 20:04:17 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2024-07-10 20:04:17 | INFO | train | epoch 005 | loss 6.619 | nll_loss 5.521 | ppl 45.9 | wps 24555.1 | ups 6.26 | wpb 3919.8 | bsz 133.2 | num_updates 65020 | lr 0.000124016 | gnorm 0.906 | train_wall 1966 | wall 0
2024-07-10 20:04:17 | INFO | fairseq.trainer | begin training epoch 6
2024-07-10 20:04:30 | INFO | train_inner | epoch 006:     80 / 13004 loss=6.589, nll_loss=5.486, ppl=44.8, wps=15260.7, ups=3.9, wpb=3915, bsz=134.8, num_updates=65100, lr=0.000123939, gnorm=0.943, train_wall=15, wall=0
2024-07-10 20:04:45 | INFO | train_inner | epoch 006:    180 / 13004 loss=6.543, nll_loss=5.433, ppl=43.21, wps=25549, ups=6.51, wpb=3925.4, bsz=105.7, num_updates=65200, lr=0.000123844, gnorm=0.883, train_wall=15, wall=0
2024-07-10 20:05:00 | INFO | train_inner | epoch 006:    280 / 13004 loss=6.609, nll_loss=5.509, ppl=45.53, wps=25390, ups=6.49, wpb=3914.2, bsz=142.6, num_updates=65300, lr=0.000123749, gnorm=0.974, train_wall=15, wall=0
2024-07-10 20:05:16 | INFO | train_inner | epoch 006:    380 / 13004 loss=6.566, nll_loss=5.46, ppl=44.01, wps=25595.8, ups=6.52, wpb=3928.5, bsz=128.6, num_updates=65400, lr=0.000123655, gnorm=0.9, train_wall=15, wall=0
2024-07-10 20:05:31 | INFO | train_inner | epoch 006:    480 / 13004 loss=6.615, nll_loss=5.515, ppl=45.73, wps=25707.8, ups=6.56, wpb=3917.6, bsz=124.2, num_updates=65500, lr=0.00012356, gnorm=0.924, train_wall=15, wall=0
2024-07-10 20:05:46 | INFO | train_inner | epoch 006:    580 / 13004 loss=6.597, nll_loss=5.495, ppl=45.09, wps=25579.1, ups=6.53, wpb=3916.1, bsz=134.6, num_updates=65600, lr=0.000123466, gnorm=0.927, train_wall=15, wall=0
2024-07-10 20:06:02 | INFO | train_inner | epoch 006:    680 / 13004 loss=6.559, nll_loss=5.451, ppl=43.76, wps=25757.1, ups=6.58, wpb=3913.6, bsz=124.6, num_updates=65700, lr=0.000123372, gnorm=0.901, train_wall=15, wall=0
2024-07-10 20:06:17 | INFO | train_inner | epoch 006:    780 / 13004 loss=6.587, nll_loss=5.484, ppl=44.74, wps=25582.9, ups=6.52, wpb=3921.7, bsz=150.6, num_updates=65800, lr=0.000123278, gnorm=0.952, train_wall=15, wall=0
2024-07-10 20:06:32 | INFO | train_inner | epoch 006:    880 / 13004 loss=6.555, nll_loss=5.446, ppl=43.59, wps=25777.9, ups=6.55, wpb=3935.5, bsz=115.8, num_updates=65900, lr=0.000123185, gnorm=0.885, train_wall=15, wall=0
2024-07-10 20:06:47 | INFO | train_inner | epoch 006:    980 / 13004 loss=6.586, nll_loss=5.482, ppl=44.71, wps=25468.9, ups=6.52, wpb=3909.2, bsz=134.3, num_updates=66000, lr=0.000123091, gnorm=0.92, train_wall=15, wall=0
2024-07-10 20:06:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:06:49 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.974 | nll_loss 5.853 | ppl 57.82 | wps 93074.1 | wpb 3703.5 | bsz 124.5 | num_updates 66000 | best_loss 6.955
2024-07-10 20:06:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:06:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_66000.pt (epoch 6 @ 66000 updates, score 6.974) (writing took 2.8749810894951224 seconds)
2024-07-10 20:07:07 | INFO | train_inner | epoch 006:   1080 / 13004 loss=6.622, nll_loss=5.523, ppl=45.99, wps=20188.1, ups=5.14, wpb=3929.8, bsz=137.2, num_updates=66100, lr=0.000122998, gnorm=0.946, train_wall=15, wall=0
2024-07-10 20:07:22 | INFO | train_inner | epoch 006:   1180 / 13004 loss=6.55, nll_loss=5.441, ppl=43.44, wps=25699.5, ups=6.58, wpb=3906.4, bsz=140.6, num_updates=66200, lr=0.000122905, gnorm=0.902, train_wall=15, wall=0
2024-07-10 20:07:37 | INFO | train_inner | epoch 006:   1280 / 13004 loss=6.565, nll_loss=5.458, ppl=43.95, wps=25560.9, ups=6.52, wpb=3920.6, bsz=121.9, num_updates=66300, lr=0.000122813, gnorm=0.904, train_wall=15, wall=0
2024-07-10 20:07:53 | INFO | train_inner | epoch 006:   1380 / 13004 loss=6.559, nll_loss=5.451, ppl=43.75, wps=25899.7, ups=6.61, wpb=3916.9, bsz=125.4, num_updates=66400, lr=0.00012272, gnorm=0.909, train_wall=15, wall=0
2024-07-10 20:08:08 | INFO | train_inner | epoch 006:   1480 / 13004 loss=6.582, nll_loss=5.476, ppl=44.52, wps=25777.9, ups=6.61, wpb=3902.8, bsz=110.7, num_updates=66500, lr=0.000122628, gnorm=0.923, train_wall=15, wall=0
2024-07-10 20:08:23 | INFO | train_inner | epoch 006:   1580 / 13004 loss=6.637, nll_loss=5.541, ppl=46.56, wps=25901.9, ups=6.61, wpb=3918.9, bsz=155.8, num_updates=66600, lr=0.000122536, gnorm=1.004, train_wall=15, wall=0
2024-07-10 20:08:38 | INFO | train_inner | epoch 006:   1680 / 13004 loss=6.622, nll_loss=5.524, ppl=46.01, wps=25905.5, ups=6.63, wpb=3907.3, bsz=148.6, num_updates=66700, lr=0.000122444, gnorm=0.959, train_wall=15, wall=0
2024-07-10 20:08:53 | INFO | train_inner | epoch 006:   1780 / 13004 loss=6.581, nll_loss=5.477, ppl=44.54, wps=25823.4, ups=6.59, wpb=3921.4, bsz=138.1, num_updates=66800, lr=0.000122352, gnorm=0.91, train_wall=15, wall=0
2024-07-10 20:09:08 | INFO | train_inner | epoch 006:   1880 / 13004 loss=6.596, nll_loss=5.493, ppl=45.05, wps=25458.8, ups=6.59, wpb=3863.7, bsz=125.5, num_updates=66900, lr=0.000122261, gnorm=0.94, train_wall=15, wall=0
2024-07-10 20:09:23 | INFO | train_inner | epoch 006:   1980 / 13004 loss=6.6, nll_loss=5.499, ppl=45.23, wps=25677.3, ups=6.62, wpb=3876.4, bsz=141, num_updates=67000, lr=0.000122169, gnorm=0.93, train_wall=15, wall=0
2024-07-10 20:09:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:09:25 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.97 | nll_loss 5.85 | ppl 57.66 | wps 95534.5 | wpb 3703.5 | bsz 124.5 | num_updates 67000 | best_loss 6.955
2024-07-10 20:09:25 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:09:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_67000.pt (epoch 6 @ 67000 updates, score 6.97) (writing took 4.043303527869284 seconds)
2024-07-10 20:09:44 | INFO | train_inner | epoch 006:   2080 / 13004 loss=6.576, nll_loss=5.471, ppl=44.35, wps=19208.8, ups=4.89, wpb=3930.7, bsz=141.5, num_updates=67100, lr=0.000122078, gnorm=0.931, train_wall=15, wall=0
2024-07-10 20:09:59 | INFO | train_inner | epoch 006:   2180 / 13004 loss=6.584, nll_loss=5.48, ppl=44.64, wps=25875.1, ups=6.61, wpb=3912.5, bsz=133.3, num_updates=67200, lr=0.000121988, gnorm=0.925, train_wall=15, wall=0
2024-07-10 20:10:14 | INFO | train_inner | epoch 006:   2280 / 13004 loss=6.561, nll_loss=5.454, ppl=43.84, wps=25731.5, ups=6.55, wpb=3930.2, bsz=123.7, num_updates=67300, lr=0.000121897, gnorm=0.9, train_wall=15, wall=0
2024-07-10 20:10:30 | INFO | train_inner | epoch 006:   2380 / 13004 loss=6.633, nll_loss=5.536, ppl=46.41, wps=25788.5, ups=6.53, wpb=3948.8, bsz=157.3, num_updates=67400, lr=0.000121806, gnorm=0.962, train_wall=15, wall=0
2024-07-10 20:10:45 | INFO | train_inner | epoch 006:   2480 / 13004 loss=6.597, nll_loss=5.495, ppl=45.11, wps=25723.6, ups=6.53, wpb=3939.6, bsz=144.1, num_updates=67500, lr=0.000121716, gnorm=0.903, train_wall=15, wall=0
2024-07-10 20:11:00 | INFO | train_inner | epoch 006:   2580 / 13004 loss=6.583, nll_loss=5.479, ppl=44.6, wps=25676.4, ups=6.56, wpb=3913.8, bsz=127.5, num_updates=67600, lr=0.000121626, gnorm=0.918, train_wall=15, wall=0
2024-07-10 20:11:15 | INFO | train_inner | epoch 006:   2680 / 13004 loss=6.594, nll_loss=5.492, ppl=44.99, wps=26015.1, ups=6.64, wpb=3915.3, bsz=131.8, num_updates=67700, lr=0.000121536, gnorm=0.921, train_wall=15, wall=0
2024-07-10 20:11:30 | INFO | train_inner | epoch 006:   2780 / 13004 loss=6.571, nll_loss=5.466, ppl=44.19, wps=25817.1, ups=6.56, wpb=3935.8, bsz=130.5, num_updates=67800, lr=0.000121447, gnorm=0.91, train_wall=15, wall=0
2024-07-10 20:11:46 | INFO | train_inner | epoch 006:   2880 / 13004 loss=6.558, nll_loss=5.45, ppl=43.72, wps=25474.2, ups=6.5, wpb=3918.1, bsz=125, num_updates=67900, lr=0.000121357, gnorm=0.911, train_wall=15, wall=0
2024-07-10 20:12:01 | INFO | train_inner | epoch 006:   2980 / 13004 loss=6.569, nll_loss=5.463, ppl=44.11, wps=25956.2, ups=6.63, wpb=3915.8, bsz=129.4, num_updates=68000, lr=0.000121268, gnorm=0.92, train_wall=15, wall=0
2024-07-10 20:12:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:12:02 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.957 | nll_loss 5.833 | ppl 56.99 | wps 96152.7 | wpb 3703.5 | bsz 124.5 | num_updates 68000 | best_loss 6.955
2024-07-10 20:12:02 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:12:05 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_68000.pt (epoch 6 @ 68000 updates, score 6.957) (writing took 2.635545974597335 seconds)
2024-07-10 20:12:20 | INFO | train_inner | epoch 006:   3080 / 13004 loss=6.613, nll_loss=5.513, ppl=45.68, wps=20733.5, ups=5.31, wpb=3906.5, bsz=128.2, num_updates=68100, lr=0.000121179, gnorm=0.948, train_wall=15, wall=0
2024-07-10 20:12:35 | INFO | train_inner | epoch 006:   3180 / 13004 loss=6.599, nll_loss=5.498, ppl=45.18, wps=25731.7, ups=6.53, wpb=3942.4, bsz=141.4, num_updates=68200, lr=0.00012109, gnorm=0.918, train_wall=15, wall=0
2024-07-10 20:12:50 | INFO | train_inner | epoch 006:   3280 / 13004 loss=6.538, nll_loss=5.427, ppl=43.02, wps=25590.5, ups=6.5, wpb=3936.5, bsz=118.6, num_updates=68300, lr=0.000121001, gnorm=0.892, train_wall=15, wall=0
2024-07-10 20:13:06 | INFO | train_inner | epoch 006:   3380 / 13004 loss=6.582, nll_loss=5.478, ppl=44.56, wps=25532.2, ups=6.5, wpb=3926, bsz=140.6, num_updates=68400, lr=0.000120913, gnorm=0.955, train_wall=15, wall=0
2024-07-10 20:13:21 | INFO | train_inner | epoch 006:   3480 / 13004 loss=6.627, nll_loss=5.53, ppl=46.2, wps=25450.8, ups=6.57, wpb=3874.2, bsz=149.8, num_updates=68500, lr=0.000120824, gnorm=1.033, train_wall=15, wall=0
2024-07-10 20:13:36 | INFO | train_inner | epoch 006:   3580 / 13004 loss=6.576, nll_loss=5.471, ppl=44.37, wps=25698.5, ups=6.58, wpb=3903.2, bsz=139.8, num_updates=68600, lr=0.000120736, gnorm=0.935, train_wall=15, wall=0
2024-07-10 20:13:52 | INFO | train_inner | epoch 006:   3680 / 13004 loss=6.569, nll_loss=5.462, ppl=44.09, wps=25622.9, ups=6.5, wpb=3944.1, bsz=134.1, num_updates=68700, lr=0.000120648, gnorm=0.897, train_wall=15, wall=0
2024-07-10 20:14:07 | INFO | train_inner | epoch 006:   3780 / 13004 loss=6.546, nll_loss=5.436, ppl=43.3, wps=25840.9, ups=6.57, wpb=3932.4, bsz=126.6, num_updates=68800, lr=0.000120561, gnorm=0.895, train_wall=15, wall=0
2024-07-10 20:14:22 | INFO | train_inner | epoch 006:   3880 / 13004 loss=6.558, nll_loss=5.452, ppl=43.76, wps=25414.2, ups=6.48, wpb=3923.8, bsz=121.6, num_updates=68900, lr=0.000120473, gnorm=0.917, train_wall=15, wall=0
2024-07-10 20:14:38 | INFO | train_inner | epoch 006:   3980 / 13004 loss=6.643, nll_loss=5.547, ppl=46.75, wps=25628.5, ups=6.53, wpb=3922.1, bsz=150.7, num_updates=69000, lr=0.000120386, gnorm=0.992, train_wall=15, wall=0
2024-07-10 20:14:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:14:39 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.967 | nll_loss 5.844 | ppl 57.45 | wps 94947.6 | wpb 3703.5 | bsz 124.5 | num_updates 69000 | best_loss 6.955
2024-07-10 20:14:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:14:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_69000.pt (epoch 6 @ 69000 updates, score 6.967) (writing took 6.9161673644557595 seconds)
2024-07-10 20:15:01 | INFO | train_inner | epoch 006:   4080 / 13004 loss=6.556, nll_loss=5.448, ppl=43.66, wps=16779.8, ups=4.28, wpb=3917.6, bsz=138.4, num_updates=69100, lr=0.000120299, gnorm=0.911, train_wall=15, wall=0
2024-07-10 20:15:16 | INFO | train_inner | epoch 006:   4180 / 13004 loss=6.543, nll_loss=5.433, ppl=43.21, wps=25791.1, ups=6.59, wpb=3913.3, bsz=120.9, num_updates=69200, lr=0.000120212, gnorm=0.9, train_wall=15, wall=0
2024-07-10 20:15:31 | INFO | train_inner | epoch 006:   4280 / 13004 loss=6.619, nll_loss=5.52, ppl=45.88, wps=25775.3, ups=6.56, wpb=3926.3, bsz=141.8, num_updates=69300, lr=0.000120125, gnorm=0.967, train_wall=15, wall=0
2024-07-10 20:15:47 | INFO | train_inner | epoch 006:   4380 / 13004 loss=6.577, nll_loss=5.471, ppl=44.36, wps=25741.5, ups=6.53, wpb=3942.8, bsz=135.7, num_updates=69400, lr=0.000120038, gnorm=0.921, train_wall=15, wall=0
2024-07-10 20:16:02 | INFO | train_inner | epoch 006:   4480 / 13004 loss=6.605, nll_loss=5.504, ppl=45.39, wps=25791.8, ups=6.55, wpb=3934.7, bsz=140.8, num_updates=69500, lr=0.000119952, gnorm=0.929, train_wall=15, wall=0
2024-07-10 20:16:17 | INFO | train_inner | epoch 006:   4580 / 13004 loss=6.531, nll_loss=5.419, ppl=42.79, wps=25934.2, ups=6.65, wpb=3901.9, bsz=130.5, num_updates=69600, lr=0.000119866, gnorm=0.911, train_wall=15, wall=0
2024-07-10 20:16:32 | INFO | train_inner | epoch 006:   4680 / 13004 loss=6.549, nll_loss=5.44, ppl=43.42, wps=25977.9, ups=6.6, wpb=3933.8, bsz=135.8, num_updates=69700, lr=0.00011978, gnorm=0.903, train_wall=15, wall=0
2024-07-10 20:16:48 | INFO | train_inner | epoch 006:   4780 / 13004 loss=6.607, nll_loss=5.506, ppl=45.44, wps=25634.9, ups=6.5, wpb=3942.7, bsz=138.4, num_updates=69800, lr=0.000119694, gnorm=0.962, train_wall=15, wall=0
2024-07-10 20:17:03 | INFO | train_inner | epoch 006:   4880 / 13004 loss=6.58, nll_loss=5.475, ppl=44.48, wps=25628.7, ups=6.58, wpb=3896.3, bsz=129.8, num_updates=69900, lr=0.000119608, gnorm=0.958, train_wall=15, wall=0
2024-07-10 20:17:18 | INFO | train_inner | epoch 006:   4980 / 13004 loss=6.582, nll_loss=5.478, ppl=44.56, wps=25644.7, ups=6.55, wpb=3917, bsz=140.6, num_updates=70000, lr=0.000119523, gnorm=0.937, train_wall=15, wall=0
2024-07-10 20:17:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:17:19 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.976 | nll_loss 5.855 | ppl 57.86 | wps 94262.5 | wpb 3703.5 | bsz 124.5 | num_updates 70000 | best_loss 6.955
2024-07-10 20:17:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:17:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_70000.pt (epoch 6 @ 70000 updates, score 6.976) (writing took 2.8393097249791026 seconds)
2024-07-10 20:17:37 | INFO | train_inner | epoch 006:   5080 / 13004 loss=6.599, nll_loss=5.497, ppl=45.18, wps=20309.5, ups=5.17, wpb=3926.7, bsz=143.2, num_updates=70100, lr=0.000119438, gnorm=0.947, train_wall=15, wall=0
2024-07-10 20:17:53 | INFO | train_inner | epoch 006:   5180 / 13004 loss=6.599, nll_loss=5.498, ppl=45.19, wps=25710.7, ups=6.53, wpb=3937.6, bsz=136.5, num_updates=70200, lr=0.000119352, gnorm=0.943, train_wall=15, wall=0
2024-07-10 20:18:08 | INFO | train_inner | epoch 006:   5280 / 13004 loss=6.603, nll_loss=5.502, ppl=45.33, wps=25964.4, ups=6.65, wpb=3907.3, bsz=123.6, num_updates=70300, lr=0.000119268, gnorm=0.924, train_wall=15, wall=0
2024-07-10 20:18:23 | INFO | train_inner | epoch 006:   5380 / 13004 loss=6.604, nll_loss=5.504, ppl=45.37, wps=25608.4, ups=6.56, wpb=3906.2, bsz=137.9, num_updates=70400, lr=0.000119183, gnorm=0.94, train_wall=15, wall=0
2024-07-10 20:18:38 | INFO | train_inner | epoch 006:   5480 / 13004 loss=6.589, nll_loss=5.486, ppl=44.82, wps=25731.9, ups=6.61, wpb=3894.8, bsz=139.4, num_updates=70500, lr=0.000119098, gnorm=0.944, train_wall=15, wall=0
2024-07-10 20:18:53 | INFO | train_inner | epoch 006:   5580 / 13004 loss=6.572, nll_loss=5.467, ppl=44.22, wps=25613.2, ups=6.52, wpb=3930.5, bsz=130.9, num_updates=70600, lr=0.000119014, gnorm=0.914, train_wall=15, wall=0
2024-07-10 20:19:09 | INFO | train_inner | epoch 006:   5680 / 13004 loss=6.557, nll_loss=5.449, ppl=43.69, wps=25900.7, ups=6.61, wpb=3916.5, bsz=119.7, num_updates=70700, lr=0.00011893, gnorm=0.897, train_wall=15, wall=0
2024-07-10 20:19:24 | INFO | train_inner | epoch 006:   5780 / 13004 loss=6.625, nll_loss=5.527, ppl=46.11, wps=25863.6, ups=6.59, wpb=3924.3, bsz=155.3, num_updates=70800, lr=0.000118846, gnorm=0.958, train_wall=15, wall=0
2024-07-10 20:19:39 | INFO | train_inner | epoch 006:   5880 / 13004 loss=6.567, nll_loss=5.461, ppl=44.04, wps=25771.1, ups=6.57, wpb=3921.1, bsz=135.4, num_updates=70900, lr=0.000118762, gnorm=0.921, train_wall=15, wall=0
2024-07-10 20:19:54 | INFO | train_inner | epoch 006:   5980 / 13004 loss=6.578, nll_loss=5.474, ppl=44.45, wps=25640.8, ups=6.52, wpb=3932.4, bsz=148.2, num_updates=71000, lr=0.000118678, gnorm=0.95, train_wall=15, wall=0
2024-07-10 20:19:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:19:55 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.947 | nll_loss 5.82 | ppl 56.51 | wps 96092.1 | wpb 3703.5 | bsz 124.5 | num_updates 71000 | best_loss 6.947
2024-07-10 20:19:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:20:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_71000.pt (epoch 6 @ 71000 updates, score 6.947) (writing took 4.667392815463245 seconds)
2024-07-10 20:20:15 | INFO | train_inner | epoch 006:   6080 / 13004 loss=6.614, nll_loss=5.514, ppl=45.69, wps=18451.3, ups=4.74, wpb=3894.8, bsz=133.6, num_updates=71100, lr=0.000118595, gnorm=0.972, train_wall=15, wall=0
2024-07-10 20:20:30 | INFO | train_inner | epoch 006:   6180 / 13004 loss=6.566, nll_loss=5.46, ppl=44.02, wps=25892.9, ups=6.62, wpb=3912.1, bsz=130.6, num_updates=71200, lr=0.000118511, gnorm=0.914, train_wall=15, wall=0
2024-07-10 20:20:46 | INFO | train_inner | epoch 006:   6280 / 13004 loss=6.554, nll_loss=5.446, ppl=43.6, wps=25906.7, ups=6.55, wpb=3956.8, bsz=141, num_updates=71300, lr=0.000118428, gnorm=0.912, train_wall=15, wall=0
2024-07-10 20:21:01 | INFO | train_inner | epoch 006:   6380 / 13004 loss=6.567, nll_loss=5.461, ppl=44.04, wps=25615.7, ups=6.55, wpb=3909.3, bsz=122.2, num_updates=71400, lr=0.000118345, gnorm=0.917, train_wall=15, wall=0
2024-07-10 20:21:16 | INFO | train_inner | epoch 006:   6480 / 13004 loss=6.587, nll_loss=5.483, ppl=44.73, wps=25698.7, ups=6.55, wpb=3923.4, bsz=130.1, num_updates=71500, lr=0.000118262, gnorm=0.948, train_wall=15, wall=0
2024-07-10 20:21:32 | INFO | train_inner | epoch 006:   6580 / 13004 loss=6.59, nll_loss=5.486, ppl=44.82, wps=25546.5, ups=6.53, wpb=3914.1, bsz=129.3, num_updates=71600, lr=0.00011818, gnorm=0.931, train_wall=15, wall=0
2024-07-10 20:21:47 | INFO | train_inner | epoch 006:   6680 / 13004 loss=6.547, nll_loss=5.438, ppl=43.35, wps=25620.1, ups=6.5, wpb=3940.2, bsz=131.8, num_updates=71700, lr=0.000118097, gnorm=0.897, train_wall=15, wall=0
2024-07-10 20:22:02 | INFO | train_inner | epoch 006:   6780 / 13004 loss=6.594, nll_loss=5.491, ppl=44.97, wps=26065.8, ups=6.65, wpb=3916.9, bsz=131.8, num_updates=71800, lr=0.000118015, gnorm=0.923, train_wall=15, wall=0
2024-07-10 20:22:17 | INFO | train_inner | epoch 006:   6880 / 13004 loss=6.59, nll_loss=5.487, ppl=44.85, wps=26122, ups=6.69, wpb=3903.5, bsz=123.6, num_updates=71900, lr=0.000117933, gnorm=0.941, train_wall=15, wall=0
2024-07-10 20:22:32 | INFO | train_inner | epoch 006:   6980 / 13004 loss=6.581, nll_loss=5.477, ppl=44.54, wps=25638.6, ups=6.52, wpb=3934.8, bsz=144.6, num_updates=72000, lr=0.000117851, gnorm=0.948, train_wall=15, wall=0
2024-07-10 20:22:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:22:33 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.947 | nll_loss 5.822 | ppl 56.58 | wps 95651 | wpb 3703.5 | bsz 124.5 | num_updates 72000 | best_loss 6.947
2024-07-10 20:22:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:22:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_72000.pt (epoch 6 @ 72000 updates, score 6.947) (writing took 4.4662753930315375 seconds)
2024-07-10 20:22:53 | INFO | train_inner | epoch 006:   7080 / 13004 loss=6.594, nll_loss=5.492, ppl=45.01, wps=18613.8, ups=4.74, wpb=3928.6, bsz=142.7, num_updates=72100, lr=0.000117769, gnorm=0.943, train_wall=15, wall=0
2024-07-10 20:23:09 | INFO | train_inner | epoch 006:   7180 / 13004 loss=6.586, nll_loss=5.484, ppl=44.74, wps=25707.2, ups=6.59, wpb=3898.5, bsz=135.8, num_updates=72200, lr=0.000117688, gnorm=0.935, train_wall=15, wall=0
2024-07-10 20:23:24 | INFO | train_inner | epoch 006:   7280 / 13004 loss=6.587, nll_loss=5.484, ppl=44.75, wps=25611.9, ups=6.52, wpb=3928.1, bsz=131, num_updates=72300, lr=0.000117606, gnorm=0.928, train_wall=15, wall=0
2024-07-10 20:23:39 | INFO | train_inner | epoch 006:   7380 / 13004 loss=6.58, nll_loss=5.475, ppl=44.48, wps=25619.3, ups=6.61, wpb=3878.2, bsz=121.8, num_updates=72400, lr=0.000117525, gnorm=0.935, train_wall=15, wall=0
2024-07-10 20:23:54 | INFO | train_inner | epoch 006:   7480 / 13004 loss=6.545, nll_loss=5.436, ppl=43.28, wps=25634.4, ups=6.52, wpb=3928.8, bsz=132.7, num_updates=72500, lr=0.000117444, gnorm=0.902, train_wall=15, wall=0
2024-07-10 20:24:10 | INFO | train_inner | epoch 006:   7580 / 13004 loss=6.597, nll_loss=5.495, ppl=45.11, wps=25536.2, ups=6.53, wpb=3909.3, bsz=132.1, num_updates=72600, lr=0.000117363, gnorm=0.948, train_wall=15, wall=0
2024-07-10 20:24:25 | INFO | train_inner | epoch 006:   7680 / 13004 loss=6.617, nll_loss=5.518, ppl=45.83, wps=25619.2, ups=6.45, wpb=3969.8, bsz=139.9, num_updates=72700, lr=0.000117282, gnorm=0.941, train_wall=15, wall=0
2024-07-10 20:24:40 | INFO | train_inner | epoch 006:   7780 / 13004 loss=6.586, nll_loss=5.482, ppl=44.69, wps=25735.1, ups=6.58, wpb=3911.7, bsz=113.6, num_updates=72800, lr=0.000117202, gnorm=0.933, train_wall=15, wall=0
2024-07-10 20:24:56 | INFO | train_inner | epoch 006:   7880 / 13004 loss=6.576, nll_loss=5.472, ppl=44.37, wps=25691.4, ups=6.58, wpb=3905.6, bsz=129.8, num_updates=72900, lr=0.000117121, gnorm=0.932, train_wall=15, wall=0
2024-07-10 20:25:11 | INFO | train_inner | epoch 006:   7980 / 13004 loss=6.575, nll_loss=5.47, ppl=44.33, wps=25827.7, ups=6.59, wpb=3917.7, bsz=126.1, num_updates=73000, lr=0.000117041, gnorm=0.919, train_wall=15, wall=0
2024-07-10 20:25:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:25:12 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.935 | nll_loss 5.811 | ppl 56.14 | wps 94338.7 | wpb 3703.5 | bsz 124.5 | num_updates 73000 | best_loss 6.935
2024-07-10 20:25:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:25:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_73000.pt (epoch 6 @ 73000 updates, score 6.935) (writing took 4.508092419244349 seconds)
2024-07-10 20:25:32 | INFO | train_inner | epoch 006:   8080 / 13004 loss=6.598, nll_loss=5.496, ppl=45.13, wps=18400.3, ups=4.68, wpb=3933.8, bsz=126.1, num_updates=73100, lr=0.000116961, gnorm=0.952, train_wall=16, wall=0
2024-07-10 20:25:47 | INFO | train_inner | epoch 006:   8180 / 13004 loss=6.56, nll_loss=5.454, ppl=43.82, wps=25645.5, ups=6.52, wpb=3935.3, bsz=135.4, num_updates=73200, lr=0.000116881, gnorm=0.906, train_wall=15, wall=0
2024-07-10 20:26:03 | INFO | train_inner | epoch 006:   8280 / 13004 loss=6.586, nll_loss=5.483, ppl=44.72, wps=25907.3, ups=6.6, wpb=3925.6, bsz=140.2, num_updates=73300, lr=0.000116801, gnorm=0.931, train_wall=15, wall=0
2024-07-10 20:26:18 | INFO | train_inner | epoch 006:   8380 / 13004 loss=6.577, nll_loss=5.472, ppl=44.4, wps=25647.9, ups=6.59, wpb=3892.5, bsz=120.2, num_updates=73400, lr=0.000116722, gnorm=0.936, train_wall=15, wall=0
2024-07-10 20:26:33 | INFO | train_inner | epoch 006:   8480 / 13004 loss=6.543, nll_loss=5.434, ppl=43.22, wps=25773.6, ups=6.52, wpb=3952.1, bsz=112.6, num_updates=73500, lr=0.000116642, gnorm=0.894, train_wall=15, wall=0
2024-07-10 20:26:48 | INFO | train_inner | epoch 006:   8580 / 13004 loss=6.607, nll_loss=5.506, ppl=45.45, wps=25602.1, ups=6.55, wpb=3909.6, bsz=134.4, num_updates=73600, lr=0.000116563, gnorm=0.945, train_wall=15, wall=0
2024-07-10 20:27:04 | INFO | train_inner | epoch 006:   8680 / 13004 loss=6.58, nll_loss=5.476, ppl=44.5, wps=25594.8, ups=6.54, wpb=3911.6, bsz=149.4, num_updates=73700, lr=0.000116484, gnorm=0.983, train_wall=15, wall=0
2024-07-10 20:27:19 | INFO | train_inner | epoch 006:   8780 / 13004 loss=6.549, nll_loss=5.441, ppl=43.45, wps=25855, ups=6.61, wpb=3911.1, bsz=151.3, num_updates=73800, lr=0.000116405, gnorm=0.924, train_wall=15, wall=0
2024-07-10 20:27:34 | INFO | train_inner | epoch 006:   8880 / 13004 loss=6.58, nll_loss=5.476, ppl=44.51, wps=25656.1, ups=6.55, wpb=3917, bsz=148.4, num_updates=73900, lr=0.000116326, gnorm=0.943, train_wall=15, wall=0
2024-07-10 20:27:49 | INFO | train_inner | epoch 006:   8980 / 13004 loss=6.545, nll_loss=5.436, ppl=43.29, wps=25749, ups=6.59, wpb=3907.6, bsz=114.5, num_updates=74000, lr=0.000116248, gnorm=0.917, train_wall=15, wall=0
2024-07-10 20:27:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:27:50 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.94 | nll_loss 5.814 | ppl 56.26 | wps 94314.1 | wpb 3703.5 | bsz 124.5 | num_updates 74000 | best_loss 6.935
2024-07-10 20:27:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:27:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_74000.pt (epoch 6 @ 74000 updates, score 6.94) (writing took 2.767991814762354 seconds)
2024-07-10 20:28:08 | INFO | train_inner | epoch 006:   9080 / 13004 loss=6.63, nll_loss=5.533, ppl=46.31, wps=20424.1, ups=5.21, wpb=3921.3, bsz=141.3, num_updates=74100, lr=0.000116169, gnorm=0.958, train_wall=15, wall=0
2024-07-10 20:28:24 | INFO | train_inner | epoch 006:   9180 / 13004 loss=6.548, nll_loss=5.439, ppl=43.38, wps=25683.2, ups=6.52, wpb=3937.4, bsz=127.8, num_updates=74200, lr=0.000116091, gnorm=0.901, train_wall=15, wall=0
2024-07-10 20:28:39 | INFO | train_inner | epoch 006:   9280 / 13004 loss=6.558, nll_loss=5.451, ppl=43.74, wps=25694.5, ups=6.54, wpb=3927, bsz=127.9, num_updates=74300, lr=0.000116013, gnorm=0.908, train_wall=15, wall=0
2024-07-10 20:28:54 | INFO | train_inner | epoch 006:   9380 / 13004 loss=6.551, nll_loss=5.442, ppl=43.49, wps=25872.3, ups=6.61, wpb=3912.5, bsz=109.2, num_updates=74400, lr=0.000115935, gnorm=0.906, train_wall=15, wall=0
2024-07-10 20:29:09 | INFO | train_inner | epoch 006:   9480 / 13004 loss=6.607, nll_loss=5.506, ppl=45.46, wps=25828.2, ups=6.56, wpb=3936, bsz=134.2, num_updates=74500, lr=0.000115857, gnorm=0.938, train_wall=15, wall=0
2024-07-10 20:29:25 | INFO | train_inner | epoch 006:   9580 / 13004 loss=6.589, nll_loss=5.486, ppl=44.81, wps=25945, ups=6.64, wpb=3909.3, bsz=136.5, num_updates=74600, lr=0.000115779, gnorm=0.948, train_wall=15, wall=0
2024-07-10 20:29:40 | INFO | train_inner | epoch 006:   9680 / 13004 loss=6.544, nll_loss=5.435, ppl=43.25, wps=25764.7, ups=6.56, wpb=3926.9, bsz=130.7, num_updates=74700, lr=0.000115702, gnorm=0.918, train_wall=15, wall=0
2024-07-10 20:29:55 | INFO | train_inner | epoch 006:   9780 / 13004 loss=6.564, nll_loss=5.457, ppl=43.92, wps=25655, ups=6.56, wpb=3910.7, bsz=122.2, num_updates=74800, lr=0.000115624, gnorm=0.923, train_wall=15, wall=0
2024-07-10 20:30:10 | INFO | train_inner | epoch 006:   9880 / 13004 loss=6.624, nll_loss=5.526, ppl=46.07, wps=25834.5, ups=6.62, wpb=3903.9, bsz=121.9, num_updates=74900, lr=0.000115547, gnorm=0.963, train_wall=15, wall=0
2024-07-10 20:30:25 | INFO | train_inner | epoch 006:   9980 / 13004 loss=6.579, nll_loss=5.475, ppl=44.48, wps=25652.1, ups=6.52, wpb=3932.8, bsz=131.5, num_updates=75000, lr=0.00011547, gnorm=0.946, train_wall=15, wall=0
2024-07-10 20:30:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:30:27 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.95 | nll_loss 5.827 | ppl 56.78 | wps 93657.1 | wpb 3703.5 | bsz 124.5 | num_updates 75000 | best_loss 6.935
2024-07-10 20:30:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:30:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_75000.pt (epoch 6 @ 75000 updates, score 6.95) (writing took 2.8267171373590827 seconds)
2024-07-10 20:30:45 | INFO | train_inner | epoch 006:  10080 / 13004 loss=6.58, nll_loss=5.476, ppl=44.5, wps=20208.4, ups=5.16, wpb=3919, bsz=146.6, num_updates=75100, lr=0.000115393, gnorm=0.974, train_wall=15, wall=0
2024-07-10 20:31:00 | INFO | train_inner | epoch 006:  10180 / 13004 loss=6.574, nll_loss=5.469, ppl=44.3, wps=25714.7, ups=6.58, wpb=3910.5, bsz=127.6, num_updates=75200, lr=0.000115316, gnorm=0.939, train_wall=15, wall=0
2024-07-10 20:31:15 | INFO | train_inner | epoch 006:  10280 / 13004 loss=6.601, nll_loss=5.5, ppl=45.26, wps=25521.6, ups=6.51, wpb=3917.9, bsz=138.6, num_updates=75300, lr=0.00011524, gnorm=0.995, train_wall=15, wall=0
2024-07-10 20:31:31 | INFO | train_inner | epoch 006:  10380 / 13004 loss=6.566, nll_loss=5.461, ppl=44.04, wps=25493.8, ups=6.5, wpb=3921.4, bsz=125.2, num_updates=75400, lr=0.000115163, gnorm=0.903, train_wall=15, wall=0
2024-07-10 20:31:46 | INFO | train_inner | epoch 006:  10480 / 13004 loss=6.584, nll_loss=5.48, ppl=44.62, wps=25598.8, ups=6.53, wpb=3922.8, bsz=130.3, num_updates=75500, lr=0.000115087, gnorm=0.948, train_wall=15, wall=0
2024-07-10 20:32:01 | INFO | train_inner | epoch 006:  10580 / 13004 loss=6.567, nll_loss=5.461, ppl=44.03, wps=25597.1, ups=6.56, wpb=3904.2, bsz=119.1, num_updates=75600, lr=0.000115011, gnorm=0.908, train_wall=15, wall=0
2024-07-10 20:32:17 | INFO | train_inner | epoch 006:  10680 / 13004 loss=6.589, nll_loss=5.486, ppl=44.8, wps=25696.1, ups=6.6, wpb=3895.8, bsz=122.5, num_updates=75700, lr=0.000114935, gnorm=0.943, train_wall=15, wall=0
2024-07-10 20:32:32 | INFO | train_inner | epoch 006:  10780 / 13004 loss=6.628, nll_loss=5.531, ppl=46.24, wps=25454.2, ups=6.53, wpb=3899.3, bsz=145.7, num_updates=75800, lr=0.000114859, gnorm=0.991, train_wall=15, wall=0
2024-07-10 20:32:47 | INFO | train_inner | epoch 006:  10880 / 13004 loss=6.593, nll_loss=5.491, ppl=44.98, wps=25804.6, ups=6.52, wpb=3955.2, bsz=145.1, num_updates=75900, lr=0.000114783, gnorm=0.963, train_wall=15, wall=0
2024-07-10 20:33:02 | INFO | train_inner | epoch 006:  10980 / 13004 loss=6.552, nll_loss=5.444, ppl=43.52, wps=25607.5, ups=6.57, wpb=3896.3, bsz=126.6, num_updates=76000, lr=0.000114708, gnorm=0.923, train_wall=15, wall=0
2024-07-10 20:33:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:33:04 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.944 | nll_loss 5.817 | ppl 56.38 | wps 93651.1 | wpb 3703.5 | bsz 124.5 | num_updates 76000 | best_loss 6.935
2024-07-10 20:33:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:33:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_76000.pt (epoch 6 @ 76000 updates, score 6.944) (writing took 2.696054975502193 seconds)
2024-07-10 20:33:22 | INFO | train_inner | epoch 006:  11080 / 13004 loss=6.581, nll_loss=5.475, ppl=44.49, wps=20395.6, ups=5.22, wpb=3906.2, bsz=119.1, num_updates=76100, lr=0.000114632, gnorm=0.935, train_wall=15, wall=0
2024-07-10 20:33:37 | INFO | train_inner | epoch 006:  11180 / 13004 loss=6.577, nll_loss=5.473, ppl=44.41, wps=25551.8, ups=6.52, wpb=3916.8, bsz=138, num_updates=76200, lr=0.000114557, gnorm=0.933, train_wall=15, wall=0
2024-07-10 20:33:52 | INFO | train_inner | epoch 006:  11280 / 13004 loss=6.569, nll_loss=5.463, ppl=44.1, wps=25725.4, ups=6.54, wpb=3932.5, bsz=133.3, num_updates=76300, lr=0.000114482, gnorm=0.924, train_wall=15, wall=0
2024-07-10 20:34:07 | INFO | train_inner | epoch 006:  11380 / 13004 loss=6.538, nll_loss=5.428, ppl=43.04, wps=25755.2, ups=6.57, wpb=3920.2, bsz=125.4, num_updates=76400, lr=0.000114407, gnorm=0.904, train_wall=15, wall=0
2024-07-10 20:34:23 | INFO | train_inner | epoch 006:  11480 / 13004 loss=6.537, nll_loss=5.427, ppl=43.01, wps=25666.3, ups=6.52, wpb=3938.6, bsz=140.8, num_updates=76500, lr=0.000114332, gnorm=0.922, train_wall=15, wall=0
2024-07-10 20:34:38 | INFO | train_inner | epoch 006:  11580 / 13004 loss=6.551, nll_loss=5.443, ppl=43.49, wps=25588.4, ups=6.56, wpb=3897.8, bsz=131.7, num_updates=76600, lr=0.000114258, gnorm=0.942, train_wall=15, wall=0
2024-07-10 20:34:53 | INFO | train_inner | epoch 006:  11680 / 13004 loss=6.537, nll_loss=5.427, ppl=43.03, wps=25807.4, ups=6.57, wpb=3930.2, bsz=143.8, num_updates=76700, lr=0.000114183, gnorm=0.927, train_wall=15, wall=0
2024-07-10 20:35:08 | INFO | train_inner | epoch 006:  11780 / 13004 loss=6.574, nll_loss=5.469, ppl=44.28, wps=25759.1, ups=6.57, wpb=3920.2, bsz=133.5, num_updates=76800, lr=0.000114109, gnorm=0.937, train_wall=15, wall=0
2024-07-10 20:35:24 | INFO | train_inner | epoch 006:  11880 / 13004 loss=6.527, nll_loss=5.415, ppl=42.67, wps=25706.4, ups=6.56, wpb=3916.5, bsz=121.2, num_updates=76900, lr=0.000114035, gnorm=0.91, train_wall=15, wall=0
2024-07-10 20:35:39 | INFO | train_inner | epoch 006:  11980 / 13004 loss=6.574, nll_loss=5.469, ppl=44.3, wps=25810.4, ups=6.55, wpb=3941.4, bsz=149.8, num_updates=77000, lr=0.000113961, gnorm=0.934, train_wall=15, wall=0
2024-07-10 20:35:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:35:40 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.943 | nll_loss 5.821 | ppl 56.52 | wps 96264 | wpb 3703.5 | bsz 124.5 | num_updates 77000 | best_loss 6.935
2024-07-10 20:35:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:35:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_77000.pt (epoch 6 @ 77000 updates, score 6.943) (writing took 2.7275775503367186 seconds)
2024-07-10 20:35:58 | INFO | train_inner | epoch 006:  12080 / 13004 loss=6.578, nll_loss=5.474, ppl=44.46, wps=20505, ups=5.22, wpb=3931.8, bsz=144.4, num_updates=77100, lr=0.000113887, gnorm=0.948, train_wall=15, wall=0
2024-07-10 20:36:13 | INFO | train_inner | epoch 006:  12180 / 13004 loss=6.548, nll_loss=5.44, ppl=43.42, wps=25839.4, ups=6.6, wpb=3917.7, bsz=132.6, num_updates=77200, lr=0.000113813, gnorm=0.92, train_wall=15, wall=0
2024-07-10 20:36:29 | INFO | train_inner | epoch 006:  12280 / 13004 loss=6.583, nll_loss=5.479, ppl=44.59, wps=25722.9, ups=6.56, wpb=3922, bsz=134.2, num_updates=77300, lr=0.000113739, gnorm=0.96, train_wall=15, wall=0
2024-07-10 20:36:44 | INFO | train_inner | epoch 006:  12380 / 13004 loss=6.556, nll_loss=5.45, ppl=43.7, wps=25704.7, ups=6.52, wpb=3943.8, bsz=138.6, num_updates=77400, lr=0.000113666, gnorm=0.93, train_wall=15, wall=0
2024-07-10 20:36:59 | INFO | train_inner | epoch 006:  12480 / 13004 loss=6.566, nll_loss=5.459, ppl=43.99, wps=25652.3, ups=6.53, wpb=3928.6, bsz=133.7, num_updates=77500, lr=0.000113592, gnorm=0.935, train_wall=15, wall=0
2024-07-10 20:37:14 | INFO | train_inner | epoch 006:  12580 / 13004 loss=6.579, nll_loss=5.474, ppl=44.45, wps=25702.3, ups=6.59, wpb=3898.9, bsz=128.8, num_updates=77600, lr=0.000113519, gnorm=0.941, train_wall=15, wall=0
2024-07-10 20:37:30 | INFO | train_inner | epoch 006:  12680 / 13004 loss=6.596, nll_loss=5.495, ppl=45.1, wps=25689.2, ups=6.5, wpb=3952.6, bsz=126.6, num_updates=77700, lr=0.000113446, gnorm=0.921, train_wall=15, wall=0
2024-07-10 20:37:45 | INFO | train_inner | epoch 006:  12780 / 13004 loss=6.558, nll_loss=5.45, ppl=43.72, wps=25845.9, ups=6.61, wpb=3912.1, bsz=134.6, num_updates=77800, lr=0.000113373, gnorm=0.964, train_wall=15, wall=0
2024-07-10 20:38:00 | INFO | train_inner | epoch 006:  12880 / 13004 loss=6.602, nll_loss=5.501, ppl=45.27, wps=25778.9, ups=6.58, wpb=3915.7, bsz=149.8, num_updates=77900, lr=0.0001133, gnorm=0.969, train_wall=15, wall=0
2024-07-10 20:38:15 | INFO | train_inner | epoch 006:  12980 / 13004 loss=6.556, nll_loss=5.449, ppl=43.68, wps=25684.3, ups=6.54, wpb=3929.8, bsz=130.6, num_updates=78000, lr=0.000113228, gnorm=0.926, train_wall=15, wall=0
2024-07-10 20:38:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:38:17 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.948 | nll_loss 5.826 | ppl 56.74 | wps 95215.2 | wpb 3703.5 | bsz 124.5 | num_updates 78000 | best_loss 6.935
2024-07-10 20:38:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:38:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_78000.pt (epoch 6 @ 78000 updates, score 6.948) (writing took 2.6903256056830287 seconds)
2024-07-10 20:38:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:38:24 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.936 | nll_loss 5.808 | ppl 56.02 | wps 94187.2 | wpb 3703.5 | bsz 124.5 | num_updates 78024 | best_loss 6.935
2024-07-10 20:38:24 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:38:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 6 @ 78024 updates, score 6.936) (writing took 2.2101194178685546 seconds)
2024-07-10 20:38:26 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2024-07-10 20:38:26 | INFO | train | epoch 006 | loss 6.579 | nll_loss 5.475 | ppl 44.47 | wps 24877.3 | ups 6.35 | wpb 3919.8 | bsz 133.2 | num_updates 78024 | lr 0.00011321 | gnorm 0.932 | train_wall 1961 | wall 0
2024-07-10 20:38:26 | INFO | fairseq.trainer | begin training epoch 7
2024-07-10 20:38:38 | INFO | train_inner | epoch 007:     76 / 13004 loss=6.517, nll_loss=5.405, ppl=42.37, wps=17412.5, ups=4.41, wpb=3951, bsz=151.5, num_updates=78100, lr=0.000113155, gnorm=0.941, train_wall=15, wall=0
2024-07-10 20:38:53 | INFO | train_inner | epoch 007:    176 / 13004 loss=6.547, nll_loss=5.438, ppl=43.34, wps=25724.7, ups=6.59, wpb=3903.7, bsz=128.8, num_updates=78200, lr=0.000113083, gnorm=0.958, train_wall=15, wall=0
2024-07-10 20:39:09 | INFO | train_inner | epoch 007:    276 / 13004 loss=6.522, nll_loss=5.409, ppl=42.48, wps=25658.2, ups=6.53, wpb=3929.5, bsz=134.6, num_updates=78300, lr=0.000113011, gnorm=0.926, train_wall=15, wall=0
2024-07-10 20:39:24 | INFO | train_inner | epoch 007:    376 / 13004 loss=6.539, nll_loss=5.428, ppl=43.04, wps=25684, ups=6.55, wpb=3923.3, bsz=131.6, num_updates=78400, lr=0.000112938, gnorm=0.921, train_wall=15, wall=0
2024-07-10 20:39:39 | INFO | train_inner | epoch 007:    476 / 13004 loss=6.537, nll_loss=5.426, ppl=42.99, wps=25690.7, ups=6.58, wpb=3906.5, bsz=126.4, num_updates=78500, lr=0.000112867, gnorm=0.946, train_wall=15, wall=0
2024-07-10 20:39:54 | INFO | train_inner | epoch 007:    576 / 13004 loss=6.564, nll_loss=5.457, ppl=43.93, wps=25610.2, ups=6.58, wpb=3893, bsz=131.7, num_updates=78600, lr=0.000112795, gnorm=0.939, train_wall=15, wall=0
2024-07-10 20:40:09 | INFO | train_inner | epoch 007:    676 / 13004 loss=6.517, nll_loss=5.404, ppl=42.34, wps=25825.1, ups=6.58, wpb=3923.9, bsz=129.8, num_updates=78700, lr=0.000112723, gnorm=0.915, train_wall=15, wall=0
2024-07-10 20:40:25 | INFO | train_inner | epoch 007:    776 / 13004 loss=6.603, nll_loss=5.501, ppl=45.3, wps=25679.7, ups=6.58, wpb=3899.8, bsz=128.4, num_updates=78800, lr=0.000112651, gnorm=0.977, train_wall=15, wall=0
2024-07-10 20:40:40 | INFO | train_inner | epoch 007:    876 / 13004 loss=6.597, nll_loss=5.495, ppl=45.1, wps=25683, ups=6.55, wpb=3919.8, bsz=141.4, num_updates=78900, lr=0.00011258, gnorm=0.971, train_wall=15, wall=0
2024-07-10 20:40:55 | INFO | train_inner | epoch 007:    976 / 13004 loss=6.542, nll_loss=5.432, ppl=43.18, wps=25781.1, ups=6.6, wpb=3907.8, bsz=139, num_updates=79000, lr=0.000112509, gnorm=0.941, train_wall=15, wall=0
2024-07-10 20:40:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:40:56 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.94 | nll_loss 5.808 | ppl 56.03 | wps 93695 | wpb 3703.5 | bsz 124.5 | num_updates 79000 | best_loss 6.935
2024-07-10 20:40:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:40:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_7_79000.pt (epoch 7 @ 79000 updates, score 6.94) (writing took 2.8523278646171093 seconds)
2024-07-10 20:41:14 | INFO | train_inner | epoch 007:   1076 / 13004 loss=6.544, nll_loss=5.434, ppl=43.23, wps=20355.2, ups=5.18, wpb=3930.6, bsz=125.2, num_updates=79100, lr=0.000112438, gnorm=0.927, train_wall=15, wall=0
2024-07-10 20:41:30 | INFO | train_inner | epoch 007:   1176 / 13004 loss=6.559, nll_loss=5.452, ppl=43.76, wps=25712.9, ups=6.53, wpb=3934.7, bsz=136.4, num_updates=79200, lr=0.000112367, gnorm=0.955, train_wall=15, wall=0
2024-07-10 20:41:45 | INFO | train_inner | epoch 007:   1276 / 13004 loss=6.58, nll_loss=5.475, ppl=44.47, wps=25750.9, ups=6.57, wpb=3922.4, bsz=118.2, num_updates=79300, lr=0.000112296, gnorm=0.94, train_wall=15, wall=0
2024-07-10 20:42:00 | INFO | train_inner | epoch 007:   1376 / 13004 loss=6.56, nll_loss=5.452, ppl=43.76, wps=25783.7, ups=6.58, wpb=3916, bsz=140.3, num_updates=79400, lr=0.000112225, gnorm=0.963, train_wall=15, wall=0
2024-07-10 20:42:16 | INFO | train_inner | epoch 007:   1476 / 13004 loss=6.539, nll_loss=5.429, ppl=43.08, wps=25403.4, ups=6.46, wpb=3931.1, bsz=131.4, num_updates=79500, lr=0.000112154, gnorm=0.944, train_wall=15, wall=0
2024-07-10 20:42:31 | INFO | train_inner | epoch 007:   1576 / 13004 loss=6.567, nll_loss=5.461, ppl=44.03, wps=25686.4, ups=6.56, wpb=3918.1, bsz=143, num_updates=79600, lr=0.000112084, gnorm=0.951, train_wall=15, wall=0
2024-07-10 20:42:46 | INFO | train_inner | epoch 007:   1676 / 13004 loss=6.557, nll_loss=5.45, ppl=43.72, wps=25594.1, ups=6.52, wpb=3926.4, bsz=146.1, num_updates=79700, lr=0.000112014, gnorm=1.008, train_wall=15, wall=0
2024-07-10 20:43:01 | INFO | train_inner | epoch 007:   1776 / 13004 loss=6.538, nll_loss=5.428, ppl=43.06, wps=26055.9, ups=6.62, wpb=3937.7, bsz=147.1, num_updates=79800, lr=0.000111943, gnorm=0.936, train_wall=15, wall=0
2024-07-10 20:43:16 | INFO | train_inner | epoch 007:   1876 / 13004 loss=6.539, nll_loss=5.429, ppl=43.07, wps=25744.4, ups=6.57, wpb=3919.7, bsz=132.2, num_updates=79900, lr=0.000111873, gnorm=0.935, train_wall=15, wall=0
2024-07-10 20:43:32 | INFO | train_inner | epoch 007:   1976 / 13004 loss=6.521, nll_loss=5.408, ppl=42.47, wps=25656.6, ups=6.54, wpb=3922.5, bsz=133, num_updates=80000, lr=0.000111803, gnorm=0.929, train_wall=15, wall=0
2024-07-10 20:43:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:43:33 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.946 | nll_loss 5.823 | ppl 56.6 | wps 96043.6 | wpb 3703.5 | bsz 124.5 | num_updates 80000 | best_loss 6.935
2024-07-10 20:43:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:43:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_7_80000.pt (epoch 7 @ 80000 updates, score 6.946) (writing took 2.969487660564482 seconds)
2024-07-10 20:43:51 | INFO | train_inner | epoch 007:   2076 / 13004 loss=6.549, nll_loss=5.441, ppl=43.44, wps=20259.3, ups=5.14, wpb=3944.6, bsz=143.4, num_updates=80100, lr=0.000111734, gnorm=0.927, train_wall=15, wall=0
2024-07-10 20:44:06 | INFO | train_inner | epoch 007:   2176 / 13004 loss=6.519, nll_loss=5.406, ppl=42.39, wps=25902.7, ups=6.62, wpb=3914.3, bsz=135.4, num_updates=80200, lr=0.000111664, gnorm=0.928, train_wall=15, wall=0
2024-07-10 20:44:22 | INFO | train_inner | epoch 007:   2276 / 13004 loss=6.553, nll_loss=5.444, ppl=43.55, wps=25636.6, ups=6.59, wpb=3888.8, bsz=123.6, num_updates=80300, lr=0.000111594, gnorm=0.957, train_wall=15, wall=0
2024-07-10 20:44:37 | INFO | train_inner | epoch 007:   2376 / 13004 loss=6.588, nll_loss=5.484, ppl=44.77, wps=25693.1, ups=6.61, wpb=3888.8, bsz=133.8, num_updates=80400, lr=0.000111525, gnorm=0.964, train_wall=15, wall=0
2024-07-10 20:44:52 | INFO | train_inner | epoch 007:   2476 / 13004 loss=6.546, nll_loss=5.437, ppl=43.32, wps=26044.2, ups=6.69, wpb=3894.8, bsz=130.3, num_updates=80500, lr=0.000111456, gnorm=0.943, train_wall=15, wall=0
2024-07-10 20:45:07 | INFO | train_inner | epoch 007:   2576 / 13004 loss=6.603, nll_loss=5.502, ppl=45.31, wps=25620.7, ups=6.56, wpb=3905.6, bsz=144.4, num_updates=80600, lr=0.000111386, gnorm=1.021, train_wall=15, wall=0
2024-07-10 20:45:22 | INFO | train_inner | epoch 007:   2676 / 13004 loss=6.542, nll_loss=5.432, ppl=43.17, wps=25710.6, ups=6.55, wpb=3924.5, bsz=119.2, num_updates=80700, lr=0.000111317, gnorm=0.922, train_wall=15, wall=0
2024-07-10 20:45:37 | INFO | train_inner | epoch 007:   2776 / 13004 loss=6.515, nll_loss=5.401, ppl=42.26, wps=25919.3, ups=6.6, wpb=3928.9, bsz=124.9, num_updates=80800, lr=0.000111249, gnorm=0.92, train_wall=15, wall=0
2024-07-10 20:45:53 | INFO | train_inner | epoch 007:   2876 / 13004 loss=6.563, nll_loss=5.456, ppl=43.91, wps=25624.1, ups=6.56, wpb=3908.2, bsz=130.6, num_updates=80900, lr=0.00011118, gnorm=0.958, train_wall=15, wall=0
2024-07-10 20:46:08 | INFO | train_inner | epoch 007:   2976 / 13004 loss=6.568, nll_loss=5.461, ppl=44.06, wps=25621.3, ups=6.58, wpb=3895.7, bsz=132.2, num_updates=81000, lr=0.000111111, gnorm=0.958, train_wall=15, wall=0
2024-07-10 20:46:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:46:09 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.93 | nll_loss 5.806 | ppl 55.94 | wps 96886.3 | wpb 3703.5 | bsz 124.5 | num_updates 81000 | best_loss 6.93
2024-07-10 20:46:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:46:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_7_81000.pt (epoch 7 @ 81000 updates, score 6.93) (writing took 4.471548965200782 seconds)
2024-07-10 20:46:29 | INFO | train_inner | epoch 007:   3076 / 13004 loss=6.583, nll_loss=5.479, ppl=44.6, wps=18793.5, ups=4.79, wpb=3920.3, bsz=143.2, num_updates=81100, lr=0.000111043, gnorm=0.967, train_wall=15, wall=0
2024-07-10 20:46:44 | INFO | train_inner | epoch 007:   3176 / 13004 loss=6.567, nll_loss=5.462, ppl=44.07, wps=25842.7, ups=6.6, wpb=3915.3, bsz=137.7, num_updates=81200, lr=0.000110974, gnorm=0.962, train_wall=15, wall=0
2024-07-10 20:46:59 | INFO | train_inner | epoch 007:   3276 / 13004 loss=6.564, nll_loss=5.458, ppl=43.95, wps=25746.6, ups=6.56, wpb=3925.7, bsz=143, num_updates=81300, lr=0.000110906, gnorm=0.945, train_wall=15, wall=0
2024-07-10 20:47:14 | INFO | train_inner | epoch 007:   3376 / 13004 loss=6.648, nll_loss=5.555, ppl=47, wps=25670.4, ups=6.53, wpb=3931.8, bsz=168.1, num_updates=81400, lr=0.000110838, gnorm=1.052, train_wall=15, wall=0
2024-07-10 20:47:29 | INFO | train_inner | epoch 007:   3476 / 13004 loss=6.57, nll_loss=5.464, ppl=44.13, wps=26357.7, ups=6.67, wpb=3949.8, bsz=134, num_updates=81500, lr=0.00011077, gnorm=0.939, train_wall=15, wall=0
2024-07-10 20:47:44 | INFO | train_inner | epoch 007:   3576 / 13004 loss=6.567, nll_loss=5.46, ppl=44.02, wps=26050.1, ups=6.64, wpb=3926, bsz=129.8, num_updates=81600, lr=0.000110702, gnorm=0.958, train_wall=15, wall=0
2024-07-10 20:48:00 | INFO | train_inner | epoch 007:   3676 / 13004 loss=6.507, nll_loss=5.392, ppl=42, wps=25727.8, ups=6.56, wpb=3921.9, bsz=136.6, num_updates=81700, lr=0.000110634, gnorm=0.926, train_wall=15, wall=0
2024-07-10 20:48:15 | INFO | train_inner | epoch 007:   3776 / 13004 loss=6.571, nll_loss=5.465, ppl=44.18, wps=25652.3, ups=6.56, wpb=3908.2, bsz=140.6, num_updates=81800, lr=0.000110566, gnorm=0.989, train_wall=15, wall=0
2024-07-10 20:48:30 | INFO | train_inner | epoch 007:   3876 / 13004 loss=6.544, nll_loss=5.435, ppl=43.25, wps=25819.2, ups=6.55, wpb=3941.4, bsz=123.2, num_updates=81900, lr=0.000110499, gnorm=0.919, train_wall=15, wall=0
2024-07-10 20:48:45 | INFO | train_inner | epoch 007:   3976 / 13004 loss=6.555, nll_loss=5.446, ppl=43.6, wps=25677.7, ups=6.5, wpb=3949.8, bsz=142.9, num_updates=82000, lr=0.000110432, gnorm=0.957, train_wall=15, wall=0
2024-07-10 20:48:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:48:47 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.942 | nll_loss 5.815 | ppl 56.3 | wps 95563 | wpb 3703.5 | bsz 124.5 | num_updates 82000 | best_loss 6.93
2024-07-10 20:48:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:48:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_7_82000.pt (epoch 7 @ 82000 updates, score 6.942) (writing took 2.7385266153141856 seconds)
2024-07-10 20:49:05 | INFO | train_inner | epoch 007:   4076 / 13004 loss=6.536, nll_loss=5.426, ppl=42.98, wps=20468.7, ups=5.22, wpb=3919.2, bsz=129.8, num_updates=82100, lr=0.000110364, gnorm=0.937, train_wall=15, wall=0
2024-07-10 20:49:20 | INFO | train_inner | epoch 007:   4176 / 13004 loss=6.526, nll_loss=5.414, ppl=42.63, wps=25806.1, ups=6.58, wpb=3923.2, bsz=120.1, num_updates=82200, lr=0.000110297, gnorm=0.934, train_wall=15, wall=0
2024-07-10 20:49:35 | INFO | train_inner | epoch 007:   4276 / 13004 loss=6.531, nll_loss=5.419, ppl=42.79, wps=25826.9, ups=6.62, wpb=3899.3, bsz=112.8, num_updates=82300, lr=0.00011023, gnorm=0.932, train_wall=15, wall=0
2024-07-10 20:49:50 | INFO | train_inner | epoch 007:   4376 / 13004 loss=6.566, nll_loss=5.46, ppl=44.01, wps=25799.5, ups=6.62, wpb=3895.6, bsz=127.8, num_updates=82400, lr=0.000110163, gnorm=0.967, train_wall=15, wall=0
2024-07-10 20:50:05 | INFO | train_inner | epoch 007:   4476 / 13004 loss=6.564, nll_loss=5.457, ppl=43.93, wps=25517.4, ups=6.53, wpb=3906.8, bsz=136.4, num_updates=82500, lr=0.000110096, gnorm=0.971, train_wall=15, wall=0
2024-07-10 20:50:21 | INFO | train_inner | epoch 007:   4576 / 13004 loss=6.497, nll_loss=5.38, ppl=41.64, wps=25618.3, ups=6.53, wpb=3924.6, bsz=122, num_updates=82600, lr=0.00011003, gnorm=0.911, train_wall=15, wall=0
2024-07-10 20:50:36 | INFO | train_inner | epoch 007:   4676 / 13004 loss=6.622, nll_loss=5.524, ppl=46.02, wps=25327.2, ups=6.44, wpb=3934, bsz=161.8, num_updates=82700, lr=0.000109963, gnorm=1.07, train_wall=15, wall=0
2024-07-10 20:50:51 | INFO | train_inner | epoch 007:   4776 / 13004 loss=6.566, nll_loss=5.46, ppl=44.02, wps=25844.4, ups=6.61, wpb=3910, bsz=135.3, num_updates=82800, lr=0.000109897, gnorm=0.943, train_wall=15, wall=0
2024-07-10 20:51:07 | INFO | train_inner | epoch 007:   4876 / 13004 loss=6.555, nll_loss=5.448, ppl=43.64, wps=25728.8, ups=6.59, wpb=3902.7, bsz=130.9, num_updates=82900, lr=0.00010983, gnorm=0.963, train_wall=15, wall=0
2024-07-10 20:51:22 | INFO | train_inner | epoch 007:   4976 / 13004 loss=6.554, nll_loss=5.446, ppl=43.6, wps=25738.9, ups=6.56, wpb=3925.3, bsz=132.1, num_updates=83000, lr=0.000109764, gnorm=0.948, train_wall=15, wall=0
2024-07-10 20:51:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:51:23 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.926 | nll_loss 5.799 | ppl 55.68 | wps 94395.1 | wpb 3703.5 | bsz 124.5 | num_updates 83000 | best_loss 6.926
2024-07-10 20:51:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:51:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_7_83000.pt (epoch 7 @ 83000 updates, score 6.926) (writing took 10.794118450023234 seconds)
2024-07-10 20:51:49 | INFO | train_inner | epoch 007:   5076 / 13004 loss=6.522, nll_loss=5.409, ppl=42.49, wps=14471, ups=3.67, wpb=3940.9, bsz=129.7, num_updates=83100, lr=0.000109698, gnorm=0.932, train_wall=15, wall=0
2024-07-10 20:52:04 | INFO | train_inner | epoch 007:   5176 / 13004 loss=6.55, nll_loss=5.442, ppl=43.48, wps=25928.4, ups=6.58, wpb=3940.2, bsz=138.3, num_updates=83200, lr=0.000109632, gnorm=0.945, train_wall=15, wall=0
2024-07-10 20:52:19 | INFO | train_inner | epoch 007:   5276 / 13004 loss=6.532, nll_loss=5.421, ppl=42.83, wps=25746, ups=6.57, wpb=3921.6, bsz=137.5, num_updates=83300, lr=0.000109566, gnorm=0.949, train_wall=15, wall=0
2024-07-10 20:52:35 | INFO | train_inner | epoch 007:   5376 / 13004 loss=6.562, nll_loss=5.455, ppl=43.87, wps=25713.3, ups=6.57, wpb=3912.2, bsz=126.5, num_updates=83400, lr=0.000109501, gnorm=0.955, train_wall=15, wall=0
2024-07-10 20:52:50 | INFO | train_inner | epoch 007:   5476 / 13004 loss=6.562, nll_loss=5.455, ppl=43.87, wps=25622.9, ups=6.52, wpb=3927.9, bsz=119.8, num_updates=83500, lr=0.000109435, gnorm=0.961, train_wall=15, wall=0
2024-07-10 20:53:05 | INFO | train_inner | epoch 007:   5576 / 13004 loss=6.544, nll_loss=5.435, ppl=43.26, wps=25806, ups=6.58, wpb=3924.3, bsz=138.3, num_updates=83600, lr=0.00010937, gnorm=0.949, train_wall=15, wall=0
2024-07-10 20:53:20 | INFO | train_inner | epoch 007:   5676 / 13004 loss=6.586, nll_loss=5.482, ppl=44.7, wps=25721.7, ups=6.58, wpb=3911.1, bsz=131.1, num_updates=83700, lr=0.000109304, gnorm=0.97, train_wall=15, wall=0
2024-07-10 20:53:36 | INFO | train_inner | epoch 007:   5776 / 13004 loss=6.533, nll_loss=5.423, ppl=42.89, wps=25803.4, ups=6.54, wpb=3945.8, bsz=142.3, num_updates=83800, lr=0.000109239, gnorm=0.935, train_wall=15, wall=0
2024-07-10 20:53:51 | INFO | train_inner | epoch 007:   5876 / 13004 loss=6.565, nll_loss=5.458, ppl=43.97, wps=25803.1, ups=6.62, wpb=3896.7, bsz=131.1, num_updates=83900, lr=0.000109174, gnorm=0.951, train_wall=15, wall=0
2024-07-10 20:54:06 | INFO | train_inner | epoch 007:   5976 / 13004 loss=6.596, nll_loss=5.494, ppl=45.06, wps=25906.6, ups=6.58, wpb=3936, bsz=141.9, num_updates=84000, lr=0.000109109, gnorm=0.971, train_wall=15, wall=0
2024-07-10 20:54:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:54:07 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.933 | nll_loss 5.809 | ppl 56.05 | wps 96315.5 | wpb 3703.5 | bsz 124.5 | num_updates 84000 | best_loss 6.926
2024-07-10 20:54:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:54:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_7_84000.pt (epoch 7 @ 84000 updates, score 6.933) (writing took 2.8853730587288737 seconds)
2024-07-10 20:54:25 | INFO | train_inner | epoch 007:   6076 / 13004 loss=6.569, nll_loss=5.464, ppl=44.14, wps=20350.4, ups=5.21, wpb=3906.6, bsz=140, num_updates=84100, lr=0.000109044, gnorm=0.954, train_wall=15, wall=0
2024-07-10 20:54:40 | INFO | train_inner | epoch 007:   6176 / 13004 loss=6.547, nll_loss=5.439, ppl=43.37, wps=25859.8, ups=6.56, wpb=3940.8, bsz=138.6, num_updates=84200, lr=0.000108979, gnorm=0.935, train_wall=15, wall=0
2024-07-10 20:54:56 | INFO | train_inner | epoch 007:   6276 / 13004 loss=6.565, nll_loss=5.459, ppl=43.98, wps=25958.9, ups=6.57, wpb=3951, bsz=137.6, num_updates=84300, lr=0.000108915, gnorm=0.954, train_wall=15, wall=0
2024-07-10 20:55:11 | INFO | train_inner | epoch 007:   6376 / 13004 loss=6.522, nll_loss=5.409, ppl=42.49, wps=25687.6, ups=6.55, wpb=3924.2, bsz=115.4, num_updates=84400, lr=0.00010885, gnorm=0.924, train_wall=15, wall=0
2024-07-10 20:55:26 | INFO | train_inner | epoch 007:   6476 / 13004 loss=6.536, nll_loss=5.426, ppl=43, wps=25955.8, ups=6.57, wpb=3949.7, bsz=148.9, num_updates=84500, lr=0.000108786, gnorm=0.947, train_wall=15, wall=0
2024-07-10 20:55:41 | INFO | train_inner | epoch 007:   6576 / 13004 loss=6.541, nll_loss=5.431, ppl=43.15, wps=25713.1, ups=6.54, wpb=3929.3, bsz=134.8, num_updates=84600, lr=0.000108721, gnorm=0.968, train_wall=15, wall=0
2024-07-10 20:55:57 | INFO | train_inner | epoch 007:   6676 / 13004 loss=6.512, nll_loss=5.398, ppl=42.16, wps=25707.6, ups=6.57, wpb=3915.2, bsz=128, num_updates=84700, lr=0.000108657, gnorm=0.941, train_wall=15, wall=0
2024-07-10 20:56:12 | INFO | train_inner | epoch 007:   6776 / 13004 loss=6.531, nll_loss=5.421, ppl=42.84, wps=25816.8, ups=6.57, wpb=3932.2, bsz=146.1, num_updates=84800, lr=0.000108593, gnorm=0.957, train_wall=15, wall=0
2024-07-10 20:56:27 | INFO | train_inner | epoch 007:   6876 / 13004 loss=6.527, nll_loss=5.415, ppl=42.68, wps=25902.7, ups=6.59, wpb=3931.2, bsz=130.9, num_updates=84900, lr=0.000108529, gnorm=0.928, train_wall=15, wall=0
2024-07-10 20:56:42 | INFO | train_inner | epoch 007:   6976 / 13004 loss=6.498, nll_loss=5.382, ppl=41.71, wps=25771.9, ups=6.57, wpb=3924, bsz=136.2, num_updates=85000, lr=0.000108465, gnorm=0.932, train_wall=15, wall=0
2024-07-10 20:56:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:56:43 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.933 | nll_loss 5.803 | ppl 55.82 | wps 89675.6 | wpb 3703.5 | bsz 124.5 | num_updates 85000 | best_loss 6.926
2024-07-10 20:56:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:56:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_7_85000.pt (epoch 7 @ 85000 updates, score 6.933) (writing took 2.7503748890012503 seconds)
2024-07-10 20:57:01 | INFO | train_inner | epoch 007:   7076 / 13004 loss=6.559, nll_loss=5.451, ppl=43.75, wps=20491, ups=5.26, wpb=3897, bsz=104.6, num_updates=85100, lr=0.000108401, gnorm=0.937, train_wall=15, wall=0
2024-07-10 20:57:16 | INFO | train_inner | epoch 007:   7176 / 13004 loss=6.566, nll_loss=5.459, ppl=43.98, wps=25868.3, ups=6.66, wpb=3883.2, bsz=115.2, num_updates=85200, lr=0.000108338, gnorm=0.983, train_wall=15, wall=0
2024-07-10 20:57:31 | INFO | train_inner | epoch 007:   7276 / 13004 loss=6.564, nll_loss=5.457, ppl=43.94, wps=25708.3, ups=6.61, wpb=3891.5, bsz=128.6, num_updates=85300, lr=0.000108274, gnorm=0.971, train_wall=15, wall=0
2024-07-10 20:57:46 | INFO | train_inner | epoch 007:   7376 / 13004 loss=6.523, nll_loss=5.41, ppl=42.53, wps=25983.1, ups=6.65, wpb=3908.8, bsz=125, num_updates=85400, lr=0.000108211, gnorm=0.942, train_wall=15, wall=0
2024-07-10 20:58:02 | INFO | train_inner | epoch 007:   7476 / 13004 loss=6.571, nll_loss=5.465, ppl=44.18, wps=25652.4, ups=6.51, wpb=3941, bsz=154, num_updates=85500, lr=0.000108148, gnorm=0.982, train_wall=15, wall=0
2024-07-10 20:58:17 | INFO | train_inner | epoch 007:   7576 / 13004 loss=6.543, nll_loss=5.433, ppl=43.19, wps=26480.8, ups=6.76, wpb=3918, bsz=131.1, num_updates=85600, lr=0.000108084, gnorm=0.959, train_wall=15, wall=0
2024-07-10 20:58:32 | INFO | train_inner | epoch 007:   7676 / 13004 loss=6.553, nll_loss=5.446, ppl=43.61, wps=25996.3, ups=6.62, wpb=3927.4, bsz=140.4, num_updates=85700, lr=0.000108021, gnorm=0.972, train_wall=15, wall=0
2024-07-10 20:58:47 | INFO | train_inner | epoch 007:   7776 / 13004 loss=6.534, nll_loss=5.424, ppl=42.93, wps=25776.5, ups=6.54, wpb=3943.1, bsz=143, num_updates=85800, lr=0.000107958, gnorm=0.936, train_wall=15, wall=0
2024-07-10 20:59:02 | INFO | train_inner | epoch 007:   7876 / 13004 loss=6.548, nll_loss=5.44, ppl=43.4, wps=25680.2, ups=6.59, wpb=3895.6, bsz=118.2, num_updates=85900, lr=0.000107896, gnorm=0.947, train_wall=15, wall=0
2024-07-10 20:59:17 | INFO | train_inner | epoch 007:   7976 / 13004 loss=6.556, nll_loss=5.448, ppl=43.65, wps=25728.7, ups=6.6, wpb=3899.2, bsz=121.6, num_updates=86000, lr=0.000107833, gnorm=0.967, train_wall=15, wall=0
2024-07-10 20:59:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 20:59:19 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.928 | nll_loss 5.799 | ppl 55.69 | wps 91557.7 | wpb 3703.5 | bsz 124.5 | num_updates 86000 | best_loss 6.926
2024-07-10 20:59:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 20:59:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_7_86000.pt (epoch 7 @ 86000 updates, score 6.928) (writing took 2.945832883939147 seconds)
2024-07-10 20:59:37 | INFO | train_inner | epoch 007:   8076 / 13004 loss=6.553, nll_loss=5.444, ppl=43.54, wps=20289.5, ups=5.17, wpb=3920.8, bsz=124.9, num_updates=86100, lr=0.00010777, gnorm=0.983, train_wall=15, wall=0
2024-07-10 20:59:52 | INFO | train_inner | epoch 007:   8176 / 13004 loss=6.543, nll_loss=5.433, ppl=43.21, wps=25672.2, ups=6.53, wpb=3929.8, bsz=134.9, num_updates=86200, lr=0.000107708, gnorm=0.953, train_wall=15, wall=0
2024-07-10 21:00:07 | INFO | train_inner | epoch 007:   8276 / 13004 loss=6.527, nll_loss=5.415, ppl=42.67, wps=25639.7, ups=6.53, wpb=3925, bsz=142.5, num_updates=86300, lr=0.000107645, gnorm=0.955, train_wall=15, wall=0
2024-07-10 21:00:23 | INFO | train_inner | epoch 007:   8376 / 13004 loss=6.588, nll_loss=5.485, ppl=44.78, wps=25723.8, ups=6.55, wpb=3925.4, bsz=152.2, num_updates=86400, lr=0.000107583, gnorm=1.041, train_wall=15, wall=0
2024-07-10 21:00:38 | INFO | train_inner | epoch 007:   8476 / 13004 loss=6.54, nll_loss=5.43, ppl=43.11, wps=25923.4, ups=6.63, wpb=3909.5, bsz=127.4, num_updates=86500, lr=0.000107521, gnorm=0.953, train_wall=15, wall=0
2024-07-10 21:00:53 | INFO | train_inner | epoch 007:   8576 / 13004 loss=6.529, nll_loss=5.418, ppl=42.75, wps=25546.4, ups=6.55, wpb=3902.3, bsz=120.2, num_updates=86600, lr=0.000107459, gnorm=0.928, train_wall=15, wall=0
2024-07-10 21:01:08 | INFO | train_inner | epoch 007:   8676 / 13004 loss=6.529, nll_loss=5.418, ppl=42.75, wps=25680.2, ups=6.53, wpb=3934.2, bsz=128.5, num_updates=86700, lr=0.000107397, gnorm=0.944, train_wall=15, wall=0
2024-07-10 21:01:23 | INFO | train_inner | epoch 007:   8776 / 13004 loss=6.548, nll_loss=5.44, ppl=43.4, wps=25668.2, ups=6.59, wpb=3896.3, bsz=133, num_updates=86800, lr=0.000107335, gnorm=0.97, train_wall=15, wall=0
2024-07-10 21:01:39 | INFO | train_inner | epoch 007:   8876 / 13004 loss=6.553, nll_loss=5.445, ppl=43.57, wps=25865.7, ups=6.57, wpb=3938.6, bsz=131.7, num_updates=86900, lr=0.000107273, gnorm=0.928, train_wall=15, wall=0
2024-07-10 21:01:54 | INFO | train_inner | epoch 007:   8976 / 13004 loss=6.543, nll_loss=5.434, ppl=43.22, wps=25649.3, ups=6.52, wpb=3933.3, bsz=134.3, num_updates=87000, lr=0.000107211, gnorm=0.939, train_wall=15, wall=0
2024-07-10 21:01:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 21:01:55 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.913 | nll_loss 5.783 | ppl 55.07 | wps 95706 | wpb 3703.5 | bsz 124.5 | num_updates 87000 | best_loss 6.913
2024-07-10 21:01:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 21:02:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_7_87000.pt (epoch 7 @ 87000 updates, score 6.913) (writing took 4.6346284337341785 seconds)
2024-07-10 21:02:15 | INFO | train_inner | epoch 007:   9076 / 13004 loss=6.517, nll_loss=5.404, ppl=42.34, wps=18356.4, ups=4.75, wpb=3866.2, bsz=125, num_updates=87100, lr=0.00010715, gnorm=0.957, train_wall=15, wall=0
2024-07-10 21:02:30 | INFO | train_inner | epoch 007:   9176 / 13004 loss=6.509, nll_loss=5.394, ppl=42.05, wps=25654.5, ups=6.54, wpb=3925, bsz=130.1, num_updates=87200, lr=0.000107088, gnorm=0.936, train_wall=15, wall=0
2024-07-10 21:02:46 | INFO | train_inner | epoch 007:   9276 / 13004 loss=6.507, nll_loss=5.393, ppl=42.02, wps=25319.8, ups=6.47, wpb=3910.8, bsz=129.4, num_updates=87300, lr=0.000107027, gnorm=0.941, train_wall=15, wall=0
2024-07-10 21:03:01 | INFO | train_inner | epoch 007:   9376 / 13004 loss=6.54, nll_loss=5.431, ppl=43.13, wps=25684.9, ups=6.53, wpb=3934, bsz=123.3, num_updates=87400, lr=0.000106966, gnorm=0.941, train_wall=15, wall=0
2024-07-10 21:03:17 | INFO | train_inner | epoch 007:   9476 / 13004 loss=6.546, nll_loss=5.437, ppl=43.31, wps=25523.8, ups=6.51, wpb=3923.4, bsz=130.2, num_updates=87500, lr=0.000106904, gnorm=0.957, train_wall=15, wall=0
2024-07-10 21:03:32 | INFO | train_inner | epoch 007:   9576 / 13004 loss=6.524, nll_loss=5.412, ppl=42.57, wps=25239.2, ups=6.44, wpb=3919.4, bsz=133.6, num_updates=87600, lr=0.000106843, gnorm=0.946, train_wall=15, wall=0
2024-07-10 21:03:47 | INFO | train_inner | epoch 007:   9676 / 13004 loss=6.584, nll_loss=5.48, ppl=44.62, wps=25620.8, ups=6.54, wpb=3919.1, bsz=138.2, num_updates=87700, lr=0.000106783, gnorm=1.008, train_wall=15, wall=0
2024-07-10 21:04:03 | INFO | train_inner | epoch 007:   9776 / 13004 loss=6.514, nll_loss=5.4, ppl=42.24, wps=25565, ups=6.51, wpb=3925.7, bsz=136.4, num_updates=87800, lr=0.000106722, gnorm=0.943, train_wall=15, wall=0
2024-07-10 21:04:18 | INFO | train_inner | epoch 007:   9876 / 13004 loss=6.558, nll_loss=5.451, ppl=43.74, wps=25510.7, ups=6.5, wpb=3925.6, bsz=129.9, num_updates=87900, lr=0.000106661, gnorm=0.964, train_wall=15, wall=0
2024-07-10 21:04:33 | INFO | train_inner | epoch 007:   9976 / 13004 loss=6.515, nll_loss=5.401, ppl=42.26, wps=25780.7, ups=6.58, wpb=3915.7, bsz=124.2, num_updates=88000, lr=0.0001066, gnorm=0.94, train_wall=15, wall=0
2024-07-10 21:04:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 21:04:34 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.921 | nll_loss 5.79 | ppl 55.34 | wps 95706.7 | wpb 3703.5 | bsz 124.5 | num_updates 88000 | best_loss 6.913
2024-07-10 21:04:34 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 21:04:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_7_88000.pt (epoch 7 @ 88000 updates, score 6.921) (writing took 2.8013085862621665 seconds)
2024-07-10 21:04:52 | INFO | train_inner | epoch 007:  10076 / 13004 loss=6.572, nll_loss=5.466, ppl=44.22, wps=20411.5, ups=5.2, wpb=3925.8, bsz=144, num_updates=88100, lr=0.00010654, gnorm=1.039, train_wall=15, wall=0
2024-07-10 21:05:08 | INFO | train_inner | epoch 007:  10176 / 13004 loss=6.591, nll_loss=5.488, ppl=44.89, wps=25807.9, ups=6.58, wpb=3920, bsz=134.9, num_updates=88200, lr=0.000106479, gnorm=0.985, train_wall=15, wall=0
2024-07-10 21:05:23 | INFO | train_inner | epoch 007:  10276 / 13004 loss=6.539, nll_loss=5.429, ppl=43.09, wps=25571.2, ups=6.55, wpb=3903.2, bsz=135.7, num_updates=88300, lr=0.000106419, gnorm=0.974, train_wall=15, wall=0
2024-07-10 21:05:38 | INFO | train_inner | epoch 007:  10376 / 13004 loss=6.534, nll_loss=5.423, ppl=42.89, wps=25681, ups=6.54, wpb=3924.6, bsz=119.9, num_updates=88400, lr=0.000106359, gnorm=0.937, train_wall=15, wall=0
2024-07-10 21:05:54 | INFO | train_inner | epoch 007:  10476 / 13004 loss=6.556, nll_loss=5.448, ppl=43.64, wps=25564.7, ups=6.5, wpb=3930.3, bsz=119.5, num_updates=88500, lr=0.000106299, gnorm=0.949, train_wall=15, wall=0
2024-07-10 21:06:09 | INFO | train_inner | epoch 007:  10576 / 13004 loss=6.516, nll_loss=5.403, ppl=42.32, wps=25612.9, ups=6.51, wpb=3934.1, bsz=122.8, num_updates=88600, lr=0.000106239, gnorm=0.935, train_wall=15, wall=0
2024-07-10 21:06:24 | INFO | train_inner | epoch 007:  10676 / 13004 loss=6.521, nll_loss=5.409, ppl=42.48, wps=25702.9, ups=6.5, wpb=3951.8, bsz=139.9, num_updates=88700, lr=0.000106179, gnorm=0.951, train_wall=15, wall=0
2024-07-10 21:06:39 | INFO | train_inner | epoch 007:  10776 / 13004 loss=6.511, nll_loss=5.395, ppl=42.09, wps=26812.4, ups=6.9, wpb=3887.3, bsz=115.4, num_updates=88800, lr=0.000106119, gnorm=0.952, train_wall=14, wall=0
2024-07-10 21:06:54 | INFO | train_inner | epoch 007:  10876 / 13004 loss=6.556, nll_loss=5.449, ppl=43.67, wps=26049.9, ups=6.64, wpb=3925.7, bsz=135.6, num_updates=88900, lr=0.000106059, gnorm=0.98, train_wall=15, wall=0
2024-07-10 21:07:09 | INFO | train_inner | epoch 007:  10976 / 13004 loss=6.57, nll_loss=5.464, ppl=44.14, wps=26238.6, ups=6.67, wpb=3936.7, bsz=138.7, num_updates=89000, lr=0.000106, gnorm=0.982, train_wall=15, wall=0
2024-07-10 21:07:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 21:07:10 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.921 | nll_loss 5.789 | ppl 55.29 | wps 97036.8 | wpb 3703.5 | bsz 124.5 | num_updates 89000 | best_loss 6.913
2024-07-10 21:07:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 21:07:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_7_89000.pt (epoch 7 @ 89000 updates, score 6.921) (writing took 2.7015892770141363 seconds)
2024-07-10 21:07:28 | INFO | train_inner | epoch 007:  11076 / 13004 loss=6.568, nll_loss=5.463, ppl=44.11, wps=20584.6, ups=5.25, wpb=3924, bsz=155, num_updates=89100, lr=0.00010594, gnorm=1.004, train_wall=15, wall=0
2024-07-10 21:07:43 | INFO | train_inner | epoch 007:  11176 / 13004 loss=6.532, nll_loss=5.421, ppl=42.85, wps=26128.5, ups=6.64, wpb=3934.4, bsz=132.7, num_updates=89200, lr=0.000105881, gnorm=0.945, train_wall=15, wall=0
2024-07-10 21:07:58 | INFO | train_inner | epoch 007:  11276 / 13004 loss=6.495, nll_loss=5.379, ppl=41.61, wps=25472.5, ups=6.48, wpb=3928.4, bsz=131.3, num_updates=89300, lr=0.000105822, gnorm=0.93, train_wall=15, wall=0
2024-07-10 21:08:14 | INFO | train_inner | epoch 007:  11376 / 13004 loss=6.562, nll_loss=5.455, ppl=43.86, wps=25953.7, ups=6.63, wpb=3911.9, bsz=143.4, num_updates=89400, lr=0.000105762, gnorm=0.998, train_wall=15, wall=0
2024-07-10 21:08:29 | INFO | train_inner | epoch 007:  11476 / 13004 loss=6.592, nll_loss=5.49, ppl=44.93, wps=25901.9, ups=6.63, wpb=3907.9, bsz=142.6, num_updates=89500, lr=0.000105703, gnorm=1.004, train_wall=15, wall=0
2024-07-10 21:08:44 | INFO | train_inner | epoch 007:  11576 / 13004 loss=6.553, nll_loss=5.445, ppl=43.56, wps=25968.1, ups=6.61, wpb=3927.3, bsz=128.6, num_updates=89600, lr=0.000105644, gnorm=0.938, train_wall=15, wall=0
2024-07-10 21:08:59 | INFO | train_inner | epoch 007:  11676 / 13004 loss=6.528, nll_loss=5.417, ppl=42.74, wps=25775.6, ups=6.57, wpb=3924.2, bsz=149.3, num_updates=89700, lr=0.000105585, gnorm=0.96, train_wall=15, wall=0
2024-07-10 21:09:14 | INFO | train_inner | epoch 007:  11776 / 13004 loss=6.57, nll_loss=5.466, ppl=44.2, wps=25802.8, ups=6.57, wpb=3928.2, bsz=146.2, num_updates=89800, lr=0.000105527, gnorm=0.986, train_wall=15, wall=0
2024-07-10 21:09:29 | INFO | train_inner | epoch 007:  11876 / 13004 loss=6.525, nll_loss=5.413, ppl=42.61, wps=25895.8, ups=6.56, wpb=3947.8, bsz=136.1, num_updates=89900, lr=0.000105468, gnorm=0.932, train_wall=15, wall=0
2024-07-10 21:09:44 | INFO | train_inner | epoch 007:  11976 / 13004 loss=6.529, nll_loss=5.417, ppl=42.73, wps=26064.3, ups=6.65, wpb=3921, bsz=135, num_updates=90000, lr=0.000105409, gnorm=0.955, train_wall=15, wall=0
2024-07-10 21:09:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 21:09:46 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.921 | nll_loss 5.79 | ppl 55.32 | wps 97297.9 | wpb 3703.5 | bsz 124.5 | num_updates 90000 | best_loss 6.913
2024-07-10 21:09:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 21:09:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_7_90000.pt (epoch 7 @ 90000 updates, score 6.921) (writing took 2.6200976613909006 seconds)
2024-07-10 21:10:03 | INFO | train_inner | epoch 007:  12076 / 13004 loss=6.547, nll_loss=5.438, ppl=43.36, wps=20545.5, ups=5.27, wpb=3898.5, bsz=123.3, num_updates=90100, lr=0.000105351, gnorm=0.951, train_wall=15, wall=0
2024-07-10 21:10:19 | INFO | train_inner | epoch 007:  12176 / 13004 loss=6.529, nll_loss=5.418, ppl=42.75, wps=25671.6, ups=6.56, wpb=3912.2, bsz=125.8, num_updates=90200, lr=0.000105292, gnorm=0.937, train_wall=15, wall=0
2024-07-10 21:10:34 | INFO | train_inner | epoch 007:  12276 / 13004 loss=6.595, nll_loss=5.492, ppl=45.01, wps=25705.6, ups=6.6, wpb=3895.3, bsz=136.5, num_updates=90300, lr=0.000105234, gnorm=1.048, train_wall=15, wall=0
2024-07-10 21:10:49 | INFO | train_inner | epoch 007:  12376 / 13004 loss=6.528, nll_loss=5.417, ppl=42.73, wps=26028.6, ups=6.62, wpb=3929.4, bsz=146.9, num_updates=90400, lr=0.000105176, gnorm=0.968, train_wall=15, wall=0
2024-07-10 21:11:04 | INFO | train_inner | epoch 007:  12476 / 13004 loss=6.537, nll_loss=5.427, ppl=43.02, wps=25834.9, ups=6.64, wpb=3888.3, bsz=129.8, num_updates=90500, lr=0.000105118, gnorm=0.959, train_wall=15, wall=0
2024-07-10 21:11:19 | INFO | train_inner | epoch 007:  12576 / 13004 loss=6.6, nll_loss=5.498, ppl=45.21, wps=25844.9, ups=6.6, wpb=3917.1, bsz=134.6, num_updates=90600, lr=0.00010506, gnorm=0.993, train_wall=15, wall=0
2024-07-10 21:11:35 | INFO | train_inner | epoch 007:  12676 / 13004 loss=6.534, nll_loss=5.423, ppl=42.91, wps=24386.2, ups=6.21, wpb=3924.1, bsz=123.7, num_updates=90700, lr=0.000105002, gnorm=0.971, train_wall=16, wall=0
2024-07-10 21:11:50 | INFO | train_inner | epoch 007:  12776 / 13004 loss=6.538, nll_loss=5.428, ppl=43.04, wps=25730.4, ups=6.58, wpb=3911, bsz=122.7, num_updates=90800, lr=0.000104944, gnorm=0.949, train_wall=15, wall=0
2024-07-10 21:12:05 | INFO | train_inner | epoch 007:  12876 / 13004 loss=6.561, nll_loss=5.454, ppl=43.83, wps=25985.7, ups=6.67, wpb=3895.2, bsz=117.8, num_updates=90900, lr=0.000104886, gnorm=0.965, train_wall=15, wall=0
2024-07-10 21:12:21 | INFO | train_inner | epoch 007:  12976 / 13004 loss=6.514, nll_loss=5.401, ppl=42.24, wps=25597, ups=6.52, wpb=3927.1, bsz=130, num_updates=91000, lr=0.000104828, gnorm=0.956, train_wall=15, wall=0
2024-07-10 21:12:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 21:12:22 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.918 | nll_loss 5.787 | ppl 55.21 | wps 95098 | wpb 3703.5 | bsz 124.5 | num_updates 91000 | best_loss 6.913
2024-07-10 21:12:22 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 21:12:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_7_91000.pt (epoch 7 @ 91000 updates, score 6.918) (writing took 2.7156697642058134 seconds)
2024-07-10 21:12:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 21:12:30 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.917 | nll_loss 5.79 | ppl 55.34 | wps 96664.4 | wpb 3703.5 | bsz 124.5 | num_updates 91028 | best_loss 6.913
2024-07-10 21:12:30 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 21:12:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 7 @ 91028 updates, score 6.917) (writing took 2.2012220807373524 seconds)
2024-07-10 21:12:32 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2024-07-10 21:12:32 | INFO | train | epoch 007 | loss 6.549 | nll_loss 5.44 | ppl 43.41 | wps 24913.1 | ups 6.36 | wpb 3919.8 | bsz 133.2 | num_updates 91028 | lr 0.000104812 | gnorm 0.956 | train_wall 1957 | wall 0
2024-07-10 21:12:32 | INFO | fairseq.trainer | begin training epoch 8
2024-07-10 21:12:43 | INFO | train_inner | epoch 008:     72 / 13004 loss=6.548, nll_loss=5.439, ppl=43.37, wps=17645.3, ups=4.52, wpb=3904, bsz=132.5, num_updates=91100, lr=0.000104771, gnorm=0.963, train_wall=14, wall=0
2024-07-10 21:12:57 | INFO | train_inner | epoch 008:    172 / 13004 loss=6.525, nll_loss=5.412, ppl=42.57, wps=27409.4, ups=7.05, wpb=3885.8, bsz=122.2, num_updates=91200, lr=0.000104713, gnorm=0.982, train_wall=14, wall=0
2024-07-10 21:13:11 | INFO | train_inner | epoch 008:    272 / 13004 loss=6.586, nll_loss=5.482, ppl=44.71, wps=27300.2, ups=6.98, wpb=3910.4, bsz=155.6, num_updates=91300, lr=0.000104656, gnorm=1.057, train_wall=14, wall=0
2024-07-10 21:13:26 | INFO | train_inner | epoch 008:    372 / 13004 loss=6.533, nll_loss=5.422, ppl=42.88, wps=26237.5, ups=6.72, wpb=3902.3, bsz=129.2, num_updates=91400, lr=0.000104599, gnorm=0.971, train_wall=15, wall=0
2024-07-10 21:13:41 | INFO | train_inner | epoch 008:    472 / 13004 loss=6.487, nll_loss=5.37, ppl=41.35, wps=25835.3, ups=6.6, wpb=3915.7, bsz=125.3, num_updates=91500, lr=0.000104542, gnorm=0.955, train_wall=15, wall=0
2024-07-10 21:13:57 | INFO | train_inner | epoch 008:    572 / 13004 loss=6.505, nll_loss=5.39, ppl=41.94, wps=25941.5, ups=6.64, wpb=3908.8, bsz=131.1, num_updates=91600, lr=0.000104485, gnorm=0.953, train_wall=15, wall=0
2024-07-10 21:14:12 | INFO | train_inner | epoch 008:    672 / 13004 loss=6.521, nll_loss=5.408, ppl=42.46, wps=26030, ups=6.62, wpb=3934.8, bsz=123, num_updates=91700, lr=0.000104428, gnorm=0.964, train_wall=15, wall=0
2024-07-10 21:14:26 | INFO | train_inner | epoch 008:    772 / 13004 loss=6.499, nll_loss=5.383, ppl=41.73, wps=26735.8, ups=6.77, wpb=3951.5, bsz=127.7, num_updates=91800, lr=0.000104371, gnorm=0.952, train_wall=15, wall=0
2024-07-10 21:14:41 | INFO | train_inner | epoch 008:    872 / 13004 loss=6.504, nll_loss=5.389, ppl=41.89, wps=26705.2, ups=6.78, wpb=3939.1, bsz=130.7, num_updates=91900, lr=0.000104314, gnorm=0.958, train_wall=15, wall=0
2024-07-10 21:14:56 | INFO | train_inner | epoch 008:    972 / 13004 loss=6.558, nll_loss=5.451, ppl=43.74, wps=26003.4, ups=6.58, wpb=3953.5, bsz=153, num_updates=92000, lr=0.000104257, gnorm=1.005, train_wall=15, wall=0
2024-07-10 21:14:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 21:14:58 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.923 | nll_loss 5.797 | ppl 55.61 | wps 96082 | wpb 3703.5 | bsz 124.5 | num_updates 92000 | best_loss 6.913
2024-07-10 21:14:58 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 21:15:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_92000.pt (epoch 8 @ 92000 updates, score 6.923) (writing took 2.9437273032963276 seconds)
2024-07-10 21:15:16 | INFO | train_inner | epoch 008:   1072 / 13004 loss=6.491, nll_loss=5.374, ppl=41.47, wps=20185.4, ups=5.17, wpb=3903.5, bsz=114.5, num_updates=92100, lr=0.000104201, gnorm=0.94, train_wall=15, wall=0
2024-07-10 21:15:31 | INFO | train_inner | epoch 008:   1172 / 13004 loss=6.504, nll_loss=5.388, ppl=41.88, wps=25859.3, ups=6.62, wpb=3906, bsz=129.8, num_updates=92200, lr=0.000104144, gnorm=0.962, train_wall=15, wall=0
2024-07-10 21:15:46 | INFO | train_inner | epoch 008:   1272 / 13004 loss=6.51, nll_loss=5.394, ppl=42.06, wps=25611.6, ups=6.61, wpb=3875.7, bsz=115.6, num_updates=92300, lr=0.000104088, gnorm=0.97, train_wall=15, wall=0
2024-07-10 21:16:01 | INFO | train_inner | epoch 008:   1372 / 13004 loss=6.515, nll_loss=5.401, ppl=42.25, wps=25925.2, ups=6.62, wpb=3915.3, bsz=128.1, num_updates=92400, lr=0.000104031, gnorm=0.983, train_wall=15, wall=0
2024-07-10 21:16:16 | INFO | train_inner | epoch 008:   1472 / 13004 loss=6.553, nll_loss=5.445, ppl=43.56, wps=25868.4, ups=6.61, wpb=3913, bsz=135.4, num_updates=92500, lr=0.000103975, gnorm=1.007, train_wall=15, wall=0
2024-07-10 21:16:31 | INFO | train_inner | epoch 008:   1572 / 13004 loss=6.537, nll_loss=5.427, ppl=43.02, wps=26218.6, ups=6.68, wpb=3925.8, bsz=129.9, num_updates=92600, lr=0.000103919, gnorm=0.959, train_wall=15, wall=0
2024-07-10 21:16:46 | INFO | train_inner | epoch 008:   1672 / 13004 loss=6.515, nll_loss=5.402, ppl=42.28, wps=26104.9, ups=6.64, wpb=3934, bsz=137.8, num_updates=92700, lr=0.000103863, gnorm=0.967, train_wall=15, wall=0
2024-07-10 21:17:01 | INFO | train_inner | epoch 008:   1772 / 13004 loss=6.506, nll_loss=5.391, ppl=41.96, wps=26178.6, ups=6.68, wpb=3919.3, bsz=118.6, num_updates=92800, lr=0.000103807, gnorm=0.948, train_wall=15, wall=0
2024-07-10 21:17:16 | INFO | train_inner | epoch 008:   1872 / 13004 loss=6.533, nll_loss=5.421, ppl=42.85, wps=26118.3, ups=6.66, wpb=3919.9, bsz=121, num_updates=92900, lr=0.000103751, gnorm=0.963, train_wall=15, wall=0
2024-07-10 21:17:31 | INFO | train_inner | epoch 008:   1972 / 13004 loss=6.516, nll_loss=5.403, ppl=42.3, wps=26180.6, ups=6.64, wpb=3940.7, bsz=135.7, num_updates=93000, lr=0.000103695, gnorm=0.97, train_wall=15, wall=0
2024-07-10 21:17:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 21:17:32 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.907 | nll_loss 5.775 | ppl 54.76 | wps 96634.7 | wpb 3703.5 | bsz 124.5 | num_updates 93000 | best_loss 6.907
2024-07-10 21:17:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 21:17:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_93000.pt (epoch 8 @ 93000 updates, score 6.907) (writing took 4.453962318599224 seconds)
2024-07-10 21:17:52 | INFO | train_inner | epoch 008:   2072 / 13004 loss=6.495, nll_loss=5.379, ppl=41.62, wps=19072.6, ups=4.85, wpb=3932.4, bsz=137.8, num_updates=93100, lr=0.000103639, gnorm=0.955, train_wall=15, wall=0
2024-07-10 21:18:07 | INFO | train_inner | epoch 008:   2172 / 13004 loss=6.545, nll_loss=5.435, ppl=43.27, wps=25036.3, ups=6.43, wpb=3895.8, bsz=134.6, num_updates=93200, lr=0.000103584, gnorm=0.998, train_wall=15, wall=0
2024-07-10 21:18:23 | INFO | train_inner | epoch 008:   2272 / 13004 loss=6.494, nll_loss=5.376, ppl=41.53, wps=24957.5, ups=6.4, wpb=3900.2, bsz=115.9, num_updates=93300, lr=0.000103528, gnorm=0.958, train_wall=15, wall=0
2024-07-10 21:18:38 | INFO | train_inner | epoch 008:   2372 / 13004 loss=6.507, nll_loss=5.392, ppl=42, wps=25587.4, ups=6.54, wpb=3910.6, bsz=122.9, num_updates=93400, lr=0.000103473, gnorm=0.952, train_wall=15, wall=0
2024-07-10 21:18:54 | INFO | train_inner | epoch 008:   2472 / 13004 loss=6.543, nll_loss=5.433, ppl=43.21, wps=25318.2, ups=6.47, wpb=3910.4, bsz=141, num_updates=93500, lr=0.000103418, gnorm=0.992, train_wall=15, wall=0
2024-07-10 21:19:09 | INFO | train_inner | epoch 008:   2572 / 13004 loss=6.542, nll_loss=5.432, ppl=43.18, wps=25846.5, ups=6.62, wpb=3901.4, bsz=134, num_updates=93600, lr=0.000103362, gnorm=0.982, train_wall=15, wall=0
2024-07-10 21:19:24 | INFO | train_inner | epoch 008:   2672 / 13004 loss=6.584, nll_loss=5.48, ppl=44.65, wps=26607.7, ups=6.77, wpb=3927.6, bsz=151.4, num_updates=93700, lr=0.000103307, gnorm=1.006, train_wall=15, wall=0
2024-07-10 21:19:39 | INFO | train_inner | epoch 008:   2772 / 13004 loss=6.557, nll_loss=5.449, ppl=43.69, wps=26007.4, ups=6.63, wpb=3920.3, bsz=130.6, num_updates=93800, lr=0.000103252, gnorm=0.991, train_wall=15, wall=0
2024-07-10 21:19:53 | INFO | train_inner | epoch 008:   2872 / 13004 loss=6.558, nll_loss=5.45, ppl=43.72, wps=26328.6, ups=6.78, wpb=3882.5, bsz=116.8, num_updates=93900, lr=0.000103197, gnorm=0.971, train_wall=15, wall=0
2024-07-10 21:20:09 | INFO | train_inner | epoch 008:   2972 / 13004 loss=6.528, nll_loss=5.417, ppl=42.73, wps=25598.2, ups=6.53, wpb=3917.9, bsz=141.9, num_updates=94000, lr=0.000103142, gnorm=0.99, train_wall=15, wall=0
2024-07-10 21:20:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 21:20:10 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.902 | nll_loss 5.771 | ppl 54.63 | wps 95195.9 | wpb 3703.5 | bsz 124.5 | num_updates 94000 | best_loss 6.902
2024-07-10 21:20:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 21:20:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_94000.pt (epoch 8 @ 94000 updates, score 6.902) (writing took 4.589237581938505 seconds)
2024-07-10 21:20:30 | INFO | train_inner | epoch 008:   3072 / 13004 loss=6.546, nll_loss=5.438, ppl=43.34, wps=18505.9, ups=4.72, wpb=3920.5, bsz=154, num_updates=94100, lr=0.000103087, gnorm=0.997, train_wall=15, wall=0
2024-07-10 21:20:45 | INFO | train_inner | epoch 008:   3172 / 13004 loss=6.515, nll_loss=5.402, ppl=42.28, wps=25632.3, ups=6.51, wpb=3940.1, bsz=137.9, num_updates=94200, lr=0.000103033, gnorm=0.95, train_wall=15, wall=0
2024-07-10 21:21:00 | INFO | train_inner | epoch 008:   3272 / 13004 loss=6.541, nll_loss=5.431, ppl=43.14, wps=25755.7, ups=6.6, wpb=3904.4, bsz=135.6, num_updates=94300, lr=0.000102978, gnorm=0.985, train_wall=15, wall=0
2024-07-10 21:21:16 | INFO | train_inner | epoch 008:   3372 / 13004 loss=6.538, nll_loss=5.427, ppl=43.03, wps=25654.8, ups=6.56, wpb=3909.3, bsz=139.7, num_updates=94400, lr=0.000102923, gnorm=0.989, train_wall=15, wall=0
2024-07-10 21:21:31 | INFO | train_inner | epoch 008:   3472 / 13004 loss=6.489, nll_loss=5.371, ppl=41.38, wps=26033, ups=6.62, wpb=3931.8, bsz=114.2, num_updates=94500, lr=0.000102869, gnorm=0.953, train_wall=15, wall=0
2024-07-10 21:21:46 | INFO | train_inner | epoch 008:   3572 / 13004 loss=6.494, nll_loss=5.377, ppl=41.56, wps=25803.5, ups=6.57, wpb=3925.6, bsz=132.5, num_updates=94600, lr=0.000102815, gnorm=0.954, train_wall=15, wall=0
2024-07-10 21:22:01 | INFO | train_inner | epoch 008:   3672 / 13004 loss=6.542, nll_loss=5.432, ppl=43.18, wps=25457.7, ups=6.48, wpb=3931.6, bsz=127.8, num_updates=94700, lr=0.00010276, gnorm=0.99, train_wall=15, wall=0
2024-07-10 21:22:17 | INFO | train_inner | epoch 008:   3772 / 13004 loss=6.512, nll_loss=5.398, ppl=42.16, wps=25521.2, ups=6.51, wpb=3919.7, bsz=134, num_updates=94800, lr=0.000102706, gnorm=0.961, train_wall=15, wall=0
2024-07-10 21:22:32 | INFO | train_inner | epoch 008:   3872 / 13004 loss=6.504, nll_loss=5.389, ppl=41.9, wps=25789.4, ups=6.54, wpb=3940.6, bsz=144.9, num_updates=94900, lr=0.000102652, gnorm=0.956, train_wall=15, wall=0
2024-07-10 21:22:47 | INFO | train_inner | epoch 008:   3972 / 13004 loss=6.534, nll_loss=5.423, ppl=42.91, wps=25676.3, ups=6.58, wpb=3903.9, bsz=133.6, num_updates=95000, lr=0.000102598, gnorm=0.99, train_wall=15, wall=0
2024-07-10 21:22:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 21:22:48 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.901 | nll_loss 5.771 | ppl 54.61 | wps 96826.7 | wpb 3703.5 | bsz 124.5 | num_updates 95000 | best_loss 6.901
2024-07-10 21:22:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 21:22:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_95000.pt (epoch 8 @ 95000 updates, score 6.901) (writing took 4.433267210610211 seconds)
2024-07-10 21:23:08 | INFO | train_inner | epoch 008:   4072 / 13004 loss=6.571, nll_loss=5.464, ppl=44.15, wps=18702.4, ups=4.78, wpb=3914.4, bsz=140, num_updates=95100, lr=0.000102544, gnorm=1.025, train_wall=15, wall=0
2024-07-10 21:23:23 | INFO | train_inner | epoch 008:   4172 / 13004 loss=6.531, nll_loss=5.42, ppl=42.8, wps=26389.3, ups=6.78, wpb=3892.3, bsz=131.8, num_updates=95200, lr=0.00010249, gnorm=0.985, train_wall=15, wall=0
2024-07-10 21:23:38 | INFO | train_inner | epoch 008:   4272 / 13004 loss=6.504, nll_loss=5.389, ppl=41.9, wps=25711.5, ups=6.57, wpb=3914.8, bsz=130.6, num_updates=95300, lr=0.000102436, gnorm=0.956, train_wall=15, wall=0
2024-07-10 21:23:53 | INFO | train_inner | epoch 008:   4372 / 13004 loss=6.495, nll_loss=5.379, ppl=41.61, wps=26106.3, ups=6.6, wpb=3955, bsz=135.8, num_updates=95400, lr=0.000102383, gnorm=0.944, train_wall=15, wall=0
2024-07-10 21:24:09 | INFO | train_inner | epoch 008:   4472 / 13004 loss=6.523, nll_loss=5.409, ppl=42.49, wps=25828.2, ups=6.57, wpb=3933.9, bsz=121.8, num_updates=95500, lr=0.000102329, gnorm=0.966, train_wall=15, wall=0
2024-07-10 21:24:24 | INFO | train_inner | epoch 008:   4572 / 13004 loss=6.543, nll_loss=5.434, ppl=43.23, wps=25555.6, ups=6.53, wpb=3915.3, bsz=152.1, num_updates=95600, lr=0.000102275, gnorm=1.022, train_wall=15, wall=0
2024-07-10 21:24:39 | INFO | train_inner | epoch 008:   4672 / 13004 loss=6.538, nll_loss=5.429, ppl=43.08, wps=25781.7, ups=6.56, wpb=3928.2, bsz=142.8, num_updates=95700, lr=0.000102222, gnorm=0.985, train_wall=15, wall=0
2024-07-10 21:24:54 | INFO | train_inner | epoch 008:   4772 / 13004 loss=6.52, nll_loss=5.407, ppl=42.43, wps=25717.7, ups=6.58, wpb=3909.6, bsz=134, num_updates=95800, lr=0.000102169, gnorm=0.999, train_wall=15, wall=0
2024-07-10 21:25:10 | INFO | train_inner | epoch 008:   4872 / 13004 loss=6.512, nll_loss=5.398, ppl=42.15, wps=24982.6, ups=6.38, wpb=3914, bsz=127.6, num_updates=95900, lr=0.000102115, gnorm=0.966, train_wall=15, wall=0
2024-07-10 21:25:25 | INFO | train_inner | epoch 008:   4972 / 13004 loss=6.528, nll_loss=5.416, ppl=42.7, wps=25649.4, ups=6.58, wpb=3896.7, bsz=125.3, num_updates=96000, lr=0.000102062, gnorm=0.966, train_wall=15, wall=0
2024-07-10 21:25:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 21:25:26 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.913 | nll_loss 5.784 | ppl 55.12 | wps 93821.4 | wpb 3703.5 | bsz 124.5 | num_updates 96000 | best_loss 6.901
2024-07-10 21:25:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 21:25:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_96000.pt (epoch 8 @ 96000 updates, score 6.913) (writing took 2.801800385117531 seconds)
2024-07-10 21:25:44 | INFO | train_inner | epoch 008:   5072 / 13004 loss=6.518, nll_loss=5.404, ppl=42.35, wps=20409.7, ups=5.21, wpb=3916.8, bsz=121.4, num_updates=96100, lr=0.000102009, gnorm=0.954, train_wall=15, wall=0
2024-07-10 21:26:00 | INFO | train_inner | epoch 008:   5172 / 13004 loss=6.55, nll_loss=5.441, ppl=43.46, wps=26094.4, ups=6.63, wpb=3938.3, bsz=150, num_updates=96200, lr=0.000101956, gnorm=0.993, train_wall=15, wall=0
2024-07-10 21:26:15 | INFO | train_inner | epoch 008:   5272 / 13004 loss=6.549, nll_loss=5.441, ppl=43.46, wps=25826.7, ups=6.57, wpb=3929.6, bsz=139.3, num_updates=96300, lr=0.000101903, gnorm=0.969, train_wall=15, wall=0
2024-07-10 21:26:30 | INFO | train_inner | epoch 008:   5372 / 13004 loss=6.512, nll_loss=5.397, ppl=42.13, wps=25965.1, ups=6.62, wpb=3920.9, bsz=108.4, num_updates=96400, lr=0.00010185, gnorm=0.93, train_wall=15, wall=0
2024-07-10 21:26:46 | INFO | train_inner | epoch 008:   5472 / 13004 loss=6.544, nll_loss=5.435, ppl=43.27, wps=24896.7, ups=6.33, wpb=3932.3, bsz=144.3, num_updates=96500, lr=0.000101797, gnorm=0.991, train_wall=16, wall=0
2024-07-10 21:27:01 | INFO | train_inner | epoch 008:   5572 / 13004 loss=6.505, nll_loss=5.39, ppl=41.94, wps=25502.3, ups=6.5, wpb=3923.9, bsz=122.4, num_updates=96600, lr=0.000101745, gnorm=0.954, train_wall=15, wall=0
2024-07-10 21:27:16 | INFO | train_inner | epoch 008:   5672 / 13004 loss=6.525, nll_loss=5.412, ppl=42.59, wps=25316.2, ups=6.49, wpb=3902.9, bsz=115.1, num_updates=96700, lr=0.000101692, gnorm=0.962, train_wall=15, wall=0
2024-07-10 21:27:32 | INFO | train_inner | epoch 008:   5772 / 13004 loss=6.546, nll_loss=5.437, ppl=43.31, wps=25060.5, ups=6.44, wpb=3893.4, bsz=136.6, num_updates=96800, lr=0.000101639, gnorm=1.012, train_wall=15, wall=0
2024-07-10 21:27:48 | INFO | train_inner | epoch 008:   5872 / 13004 loss=6.482, nll_loss=5.364, ppl=41.2, wps=25153.5, ups=6.42, wpb=3917.7, bsz=135.7, num_updates=96900, lr=0.000101587, gnorm=0.946, train_wall=15, wall=0
2024-07-10 21:28:03 | INFO | train_inner | epoch 008:   5972 / 13004 loss=6.542, nll_loss=5.432, ppl=43.16, wps=25723, ups=6.56, wpb=3919.6, bsz=136.2, num_updates=97000, lr=0.000101535, gnorm=0.985, train_wall=15, wall=0
2024-07-10 21:28:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 21:28:04 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.897 | nll_loss 5.772 | ppl 54.63 | wps 94826.6 | wpb 3703.5 | bsz 124.5 | num_updates 97000 | best_loss 6.897
2024-07-10 21:28:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 21:28:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_97000.pt (epoch 8 @ 97000 updates, score 6.897) (writing took 4.892773572355509 seconds)
2024-07-10 21:28:24 | INFO | train_inner | epoch 008:   6072 / 13004 loss=6.523, nll_loss=5.411, ppl=42.55, wps=18564.3, ups=4.71, wpb=3943, bsz=145.7, num_updates=97100, lr=0.000101482, gnorm=0.995, train_wall=15, wall=0
2024-07-10 21:28:39 | INFO | train_inner | epoch 008:   6172 / 13004 loss=6.512, nll_loss=5.398, ppl=42.17, wps=26063.1, ups=6.67, wpb=3908.6, bsz=136, num_updates=97200, lr=0.00010143, gnorm=0.963, train_wall=15, wall=0
2024-07-10 21:28:54 | INFO | train_inner | epoch 008:   6272 / 13004 loss=6.505, nll_loss=5.39, ppl=41.94, wps=25818.5, ups=6.56, wpb=3938.1, bsz=135.4, num_updates=97300, lr=0.000101378, gnorm=0.944, train_wall=15, wall=0
2024-07-10 21:29:09 | INFO | train_inner | epoch 008:   6372 / 13004 loss=6.569, nll_loss=5.463, ppl=44.1, wps=25791.1, ups=6.6, wpb=3906.5, bsz=129.4, num_updates=97400, lr=0.000101326, gnorm=1.022, train_wall=15, wall=0
2024-07-10 21:29:24 | INFO | train_inner | epoch 008:   6472 / 13004 loss=6.498, nll_loss=5.381, ppl=41.67, wps=26232.7, ups=6.69, wpb=3922.4, bsz=125.6, num_updates=97500, lr=0.000101274, gnorm=0.956, train_wall=15, wall=0
2024-07-10 21:29:39 | INFO | train_inner | epoch 008:   6572 / 13004 loss=6.532, nll_loss=5.42, ppl=42.83, wps=26006.4, ups=6.64, wpb=3919.1, bsz=121.8, num_updates=97600, lr=0.000101222, gnorm=0.973, train_wall=15, wall=0
2024-07-10 21:29:55 | INFO | train_inner | epoch 008:   6672 / 13004 loss=6.517, nll_loss=5.404, ppl=42.34, wps=25827.4, ups=6.56, wpb=3937.9, bsz=146.1, num_updates=97700, lr=0.00010117, gnorm=0.985, train_wall=15, wall=0
2024-07-10 21:30:10 | INFO | train_inner | epoch 008:   6772 / 13004 loss=6.497, nll_loss=5.38, ppl=41.66, wps=25413.9, ups=6.49, wpb=3917.6, bsz=126.1, num_updates=97800, lr=0.000101118, gnorm=0.952, train_wall=15, wall=0
2024-07-10 21:30:25 | INFO | train_inner | epoch 008:   6872 / 13004 loss=6.516, nll_loss=5.402, ppl=42.29, wps=25777.4, ups=6.53, wpb=3945.8, bsz=136.8, num_updates=97900, lr=0.000101067, gnorm=0.966, train_wall=15, wall=0
2024-07-10 21:30:41 | INFO | train_inner | epoch 008:   6972 / 13004 loss=6.498, nll_loss=5.382, ppl=41.69, wps=25737.2, ups=6.6, wpb=3900.4, bsz=108.2, num_updates=98000, lr=0.000101015, gnorm=0.95, train_wall=15, wall=0
2024-07-10 21:30:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 21:30:42 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.914 | nll_loss 5.785 | ppl 55.13 | wps 96169.7 | wpb 3703.5 | bsz 124.5 | num_updates 98000 | best_loss 6.897
2024-07-10 21:30:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 21:30:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_98000.pt (epoch 8 @ 98000 updates, score 6.914) (writing took 2.707305932417512 seconds)
2024-07-10 21:31:00 | INFO | train_inner | epoch 008:   7072 / 13004 loss=6.523, nll_loss=5.41, ppl=42.52, wps=20394.1, ups=5.24, wpb=3890.7, bsz=130.8, num_updates=98100, lr=0.000100964, gnorm=1.008, train_wall=15, wall=0
2024-07-10 21:31:15 | INFO | train_inner | epoch 008:   7172 / 13004 loss=6.492, nll_loss=5.376, ppl=41.54, wps=25640.3, ups=6.49, wpb=3948, bsz=144.1, num_updates=98200, lr=0.000100912, gnorm=0.962, train_wall=15, wall=0
2024-07-10 21:31:31 | INFO | train_inner | epoch 008:   7272 / 13004 loss=6.54, nll_loss=5.431, ppl=43.13, wps=25446.1, ups=6.45, wpb=3943.9, bsz=138.6, num_updates=98300, lr=0.000100861, gnorm=0.971, train_wall=15, wall=0
2024-07-10 21:31:46 | INFO | train_inner | epoch 008:   7372 / 13004 loss=6.511, nll_loss=5.397, ppl=42.13, wps=25764, ups=6.57, wpb=3920.8, bsz=124.3, num_updates=98400, lr=0.00010081, gnorm=0.957, train_wall=15, wall=0
2024-07-10 21:32:01 | INFO | train_inner | epoch 008:   7472 / 13004 loss=6.568, nll_loss=5.462, ppl=44.08, wps=25875.4, ups=6.62, wpb=3907.5, bsz=124.2, num_updates=98500, lr=0.000100759, gnorm=1.042, train_wall=15, wall=0
2024-07-10 21:32:16 | INFO | train_inner | epoch 008:   7572 / 13004 loss=6.513, nll_loss=5.399, ppl=42.2, wps=25629.2, ups=6.53, wpb=3926.6, bsz=143.8, num_updates=98600, lr=0.000100707, gnorm=0.979, train_wall=15, wall=0
2024-07-10 21:32:31 | INFO | train_inner | epoch 008:   7672 / 13004 loss=6.496, nll_loss=5.38, ppl=41.65, wps=25823.4, ups=6.55, wpb=3942.5, bsz=144.1, num_updates=98700, lr=0.000100656, gnorm=0.965, train_wall=15, wall=0
2024-07-10 21:32:47 | INFO | train_inner | epoch 008:   7772 / 13004 loss=6.529, nll_loss=5.418, ppl=42.74, wps=25618.4, ups=6.51, wpb=3934.7, bsz=133.1, num_updates=98800, lr=0.000100605, gnorm=0.98, train_wall=15, wall=0
2024-07-10 21:33:02 | INFO | train_inner | epoch 008:   7872 / 13004 loss=6.551, nll_loss=5.442, ppl=43.48, wps=25735.5, ups=6.54, wpb=3935.7, bsz=142.5, num_updates=98900, lr=0.000100555, gnorm=0.989, train_wall=15, wall=0
2024-07-10 21:33:17 | INFO | train_inner | epoch 008:   7972 / 13004 loss=6.558, nll_loss=5.45, ppl=43.72, wps=25607.9, ups=6.55, wpb=3910, bsz=120.4, num_updates=99000, lr=0.000100504, gnorm=1.018, train_wall=15, wall=0
2024-07-10 21:33:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 21:33:19 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.901 | nll_loss 5.77 | ppl 54.58 | wps 94752.9 | wpb 3703.5 | bsz 124.5 | num_updates 99000 | best_loss 6.897
2024-07-10 21:33:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 21:33:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_99000.pt (epoch 8 @ 99000 updates, score 6.901) (writing took 2.7237301683053374 seconds)
2024-07-10 21:33:36 | INFO | train_inner | epoch 008:   8072 / 13004 loss=6.538, nll_loss=5.427, ppl=43.03, wps=20612, ups=5.25, wpb=3922.7, bsz=128.8, num_updates=99100, lr=0.000100453, gnorm=0.975, train_wall=15, wall=0
2024-07-10 21:33:52 | INFO | train_inner | epoch 008:   8172 / 13004 loss=6.508, nll_loss=5.394, ppl=42.04, wps=26023.3, ups=6.61, wpb=3934.4, bsz=143.1, num_updates=99200, lr=0.000100402, gnorm=0.978, train_wall=15, wall=0
2024-07-10 21:34:07 | INFO | train_inner | epoch 008:   8272 / 13004 loss=6.554, nll_loss=5.446, ppl=43.6, wps=25779, ups=6.62, wpb=3892.8, bsz=142.2, num_updates=99300, lr=0.000100352, gnorm=0.985, train_wall=15, wall=0
2024-07-10 21:34:22 | INFO | train_inner | epoch 008:   8372 / 13004 loss=6.491, nll_loss=5.374, ppl=41.48, wps=25798.4, ups=6.58, wpb=3918.9, bsz=134.8, num_updates=99400, lr=0.000100301, gnorm=0.96, train_wall=15, wall=0
2024-07-10 21:34:37 | INFO | train_inner | epoch 008:   8472 / 13004 loss=6.555, nll_loss=5.448, ppl=43.64, wps=26080.2, ups=6.63, wpb=3932.9, bsz=153, num_updates=99500, lr=0.000100251, gnorm=1.007, train_wall=15, wall=0
2024-07-10 21:34:52 | INFO | train_inner | epoch 008:   8572 / 13004 loss=6.531, nll_loss=5.419, ppl=42.78, wps=25736.6, ups=6.59, wpb=3906.9, bsz=122.2, num_updates=99600, lr=0.000100201, gnorm=0.973, train_wall=15, wall=0
2024-07-10 21:35:07 | INFO | train_inner | epoch 008:   8672 / 13004 loss=6.493, nll_loss=5.377, ppl=41.55, wps=25744.7, ups=6.61, wpb=3894.2, bsz=119.4, num_updates=99700, lr=0.00010015, gnorm=0.968, train_wall=15, wall=0
2024-07-10 21:35:23 | INFO | train_inner | epoch 008:   8772 / 13004 loss=6.524, nll_loss=5.412, ppl=42.57, wps=25508.6, ups=6.5, wpb=3922.7, bsz=146.7, num_updates=99800, lr=0.0001001, gnorm=0.989, train_wall=15, wall=0
2024-07-10 21:35:37 | INFO | train_inner | epoch 008:   8872 / 13004 loss=6.554, nll_loss=5.446, ppl=43.6, wps=26370.1, ups=6.73, wpb=3916.5, bsz=144, num_updates=99900, lr=0.00010005, gnorm=0.993, train_wall=15, wall=0
2024-07-10 21:35:52 | INFO | train_inner | epoch 008:   8972 / 13004 loss=6.528, nll_loss=5.416, ppl=42.7, wps=26198.5, ups=6.71, wpb=3906.2, bsz=128.8, num_updates=100000, lr=0.0001, gnorm=0.987, train_wall=15, wall=0
2024-07-10 21:35:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-10 21:35:54 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.914 | nll_loss 5.788 | ppl 55.27 | wps 96061.6 | wpb 3703.5 | bsz 124.5 | num_updates 100000 | best_loss 6.897
2024-07-10 21:35:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-10 21:35:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_100000.pt (epoch 8 @ 100000 updates, score 6.914) (writing took 2.7016758723184466 seconds)
2024-07-10 21:35:56 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2024-07-10 21:35:56 | INFO | train | epoch 008 | loss 6.525 | nll_loss 5.413 | ppl 42.61 | wps 25043.7 | ups 6.39 | wpb 3919 | bsz 132.8 | num_updates 100000 | lr 0.0001 | gnorm 0.976 | train_wall 1345 | wall 0
2024-07-10 21:35:56 | INFO | fairseq_cli.train | done training in 14292.5 seconds
