2024-07-15 17:51:57 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt22.sep.tokenized.fr-de', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=200000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=1000, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-15 17:51:57 | INFO | fairseq.tasks.translation | [fr] dictionary: 9960 types
2024-07-15 17:51:57 | INFO | fairseq.tasks.translation | [de] dictionary: 9960 types
2024-07-15 17:51:57 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.fr
2024-07-15 17:51:57 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.de
2024-07-15 17:51:57 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de valid fr-de 3238 examples
2024-07-15 17:51:58 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9960, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9960, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=9960, bias=False)
  )
)
2024-07-15 17:51:58 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-15 17:51:58 | INFO | fairseq_cli.train | model: transformer_wmt_en_de (TransformerModel)
2024-07-15 17:51:58 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-15 17:51:58 | INFO | fairseq_cli.train | num. model params: 54337536 (num. trained: 54337536)
2024-07-15 17:52:16 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-15 17:52:16 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-15 17:52:16 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-15 17:52:16 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-15 17:52:16 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-15 17:52:16 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-15 17:52:23 | INFO | fairseq.trainer | loaded checkpoint checkpoints/checkpoint_last.pt (epoch 7 @ 100000 updates)
2024-07-15 17:52:23 | INFO | fairseq.trainer | loading train data for epoch 7
2024-07-15 17:52:24 | INFO | fairseq.data.data_utils | loaded 1732407 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.fr
2024-07-15 17:52:25 | INFO | fairseq.data.data_utils | loaded 1732407 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.de
2024-07-15 17:52:25 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de train fr-de 1732407 examples
2024-07-15 17:52:27 | INFO | fairseq.trainer | begin training epoch 7
2024-07-15 17:52:51 | INFO | train_inner | epoch 007:  12308 / 14632 loss=5.359, nll_loss=4.074, ppl=16.85, wps=12082.8, ups=3.39, wpb=3567.7, bsz=131.5, num_updates=100100, lr=9.995e-05, gnorm=1.186, train_wall=23, wall=0
2024-07-15 17:53:13 | INFO | train_inner | epoch 007:  12408 / 14632 loss=5.351, nll_loss=4.067, ppl=16.76, wps=15504.4, ups=4.39, wpb=3534, bsz=129.4, num_updates=100200, lr=9.99001e-05, gnorm=1.178, train_wall=23, wall=0
2024-07-15 17:53:36 | INFO | train_inner | epoch 007:  12508 / 14632 loss=5.47, nll_loss=4.202, ppl=18.4, wps=15209.9, ups=4.43, wpb=3433.1, bsz=120.2, num_updates=100300, lr=9.98503e-05, gnorm=1.313, train_wall=22, wall=0
2024-07-15 17:53:59 | INFO | train_inner | epoch 007:  12608 / 14632 loss=5.325, nll_loss=4.037, ppl=16.41, wps=15017.3, ups=4.39, wpb=3417.5, bsz=120.5, num_updates=100400, lr=9.98006e-05, gnorm=1.201, train_wall=23, wall=0
2024-07-15 17:54:21 | INFO | train_inner | epoch 007:  12708 / 14632 loss=5.348, nll_loss=4.063, ppl=16.71, wps=15329.7, ups=4.39, wpb=3493.3, bsz=116.9, num_updates=100500, lr=9.97509e-05, gnorm=1.159, train_wall=23, wall=0
2024-07-15 17:54:44 | INFO | train_inner | epoch 007:  12808 / 14632 loss=5.391, nll_loss=4.11, ppl=17.27, wps=15742.8, ups=4.42, wpb=3563.2, bsz=136.6, num_updates=100600, lr=9.97013e-05, gnorm=1.237, train_wall=22, wall=0
2024-07-15 17:55:07 | INFO | train_inner | epoch 007:  12908 / 14632 loss=5.479, nll_loss=4.212, ppl=18.53, wps=15134.5, ups=4.38, wpb=3451.7, bsz=123.3, num_updates=100700, lr=9.96518e-05, gnorm=1.204, train_wall=23, wall=0
2024-07-15 17:55:30 | INFO | train_inner | epoch 007:  13008 / 14632 loss=5.452, nll_loss=4.181, ppl=18.14, wps=15235.1, ups=4.37, wpb=3488.5, bsz=115.3, num_updates=100800, lr=9.96024e-05, gnorm=1.153, train_wall=23, wall=0
2024-07-15 17:55:53 | INFO | train_inner | epoch 007:  13108 / 14632 loss=5.302, nll_loss=4.009, ppl=16.1, wps=15476.6, ups=4.35, wpb=3560.4, bsz=137.1, num_updates=100900, lr=9.9553e-05, gnorm=1.166, train_wall=23, wall=0
2024-07-15 17:56:16 | INFO | train_inner | epoch 007:  13208 / 14632 loss=5.413, nll_loss=4.136, ppl=17.59, wps=15552.3, ups=4.39, wpb=3538.7, bsz=123.4, num_updates=101000, lr=9.95037e-05, gnorm=1.194, train_wall=23, wall=0
2024-07-15 17:56:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-15 17:56:18 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.389 | nll_loss 5.186 | ppl 36.42 | wps 42743 | wpb 2469 | bsz 83 | num_updates 101000 | best_loss 12.212
2024-07-15 17:56:18 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 17:56:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_7_101000.pt (epoch 7 @ 101000 updates, score 6.389) (writing took 4.753809214569628 seconds)
2024-07-15 17:56:45 | INFO | train_inner | epoch 007:  13308 / 14632 loss=5.422, nll_loss=4.148, ppl=17.72, wps=11431.2, ups=3.35, wpb=3416.8, bsz=113.7, num_updates=101100, lr=9.94545e-05, gnorm=1.202, train_wall=23, wall=0
2024-07-15 17:57:09 | INFO | train_inner | epoch 007:  13408 / 14632 loss=5.343, nll_loss=4.057, ppl=16.65, wps=15111.7, ups=4.32, wpb=3494.5, bsz=122.8, num_updates=101200, lr=9.94053e-05, gnorm=1.192, train_wall=23, wall=0
2024-07-15 17:57:31 | INFO | train_inner | epoch 007:  13508 / 14632 loss=5.37, nll_loss=4.087, ppl=17, wps=15381.8, ups=4.38, wpb=3511.5, bsz=121.9, num_updates=101300, lr=9.93563e-05, gnorm=1.185, train_wall=23, wall=0
2024-07-15 17:57:54 | INFO | train_inner | epoch 007:  13608 / 14632 loss=5.465, nll_loss=4.197, ppl=18.34, wps=15193.7, ups=4.37, wpb=3479.9, bsz=109.9, num_updates=101400, lr=9.93073e-05, gnorm=1.217, train_wall=23, wall=0
2024-07-15 17:58:17 | INFO | train_inner | epoch 007:  13708 / 14632 loss=5.416, nll_loss=4.141, ppl=17.64, wps=15046.3, ups=4.4, wpb=3422.4, bsz=111.8, num_updates=101500, lr=9.92583e-05, gnorm=1.187, train_wall=23, wall=0
2024-07-15 17:58:40 | INFO | train_inner | epoch 007:  13808 / 14632 loss=5.387, nll_loss=4.108, ppl=17.24, wps=15081.7, ups=4.37, wpb=3448, bsz=131.8, num_updates=101600, lr=9.92095e-05, gnorm=1.229, train_wall=23, wall=0
2024-07-15 17:59:03 | INFO | train_inner | epoch 007:  13908 / 14632 loss=5.414, nll_loss=4.138, ppl=17.6, wps=15280.9, ups=4.39, wpb=3483.8, bsz=122.2, num_updates=101700, lr=9.91607e-05, gnorm=1.23, train_wall=23, wall=0
2024-07-15 17:59:26 | INFO | train_inner | epoch 007:  14008 / 14632 loss=5.436, nll_loss=4.163, ppl=17.91, wps=15521, ups=4.35, wpb=3568.3, bsz=120.1, num_updates=101800, lr=9.9112e-05, gnorm=1.176, train_wall=23, wall=0
2024-07-15 17:59:49 | INFO | train_inner | epoch 007:  14108 / 14632 loss=5.38, nll_loss=4.099, ppl=17.14, wps=15276.3, ups=4.36, wpb=3500, bsz=129.5, num_updates=101900, lr=9.90633e-05, gnorm=1.251, train_wall=23, wall=0
2024-07-15 18:00:12 | INFO | train_inner | epoch 007:  14208 / 14632 loss=5.384, nll_loss=4.103, ppl=17.18, wps=15473.1, ups=4.34, wpb=3567.3, bsz=119, num_updates=102000, lr=9.90148e-05, gnorm=1.154, train_wall=23, wall=0
2024-07-15 18:00:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 18:00:14 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.4 | nll_loss 5.192 | ppl 36.55 | wps 42407.6 | wpb 2469 | bsz 83 | num_updates 102000 | best_loss 12.212
2024-07-15 18:00:14 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 18:00:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_7_102000.pt (epoch 7 @ 102000 updates, score 6.4) (writing took 4.5609561232849956 seconds)
2024-07-15 18:00:42 | INFO | train_inner | epoch 007:  14308 / 14632 loss=5.487, nll_loss=4.222, ppl=18.66, wps=11633.1, ups=3.34, wpb=3478.7, bsz=106.5, num_updates=102100, lr=9.89663e-05, gnorm=1.208, train_wall=23, wall=0
2024-07-15 18:01:05 | INFO | train_inner | epoch 007:  14408 / 14632 loss=5.446, nll_loss=4.175, ppl=18.06, wps=15443.2, ups=4.35, wpb=3550.5, bsz=108.6, num_updates=102200, lr=9.89178e-05, gnorm=1.18, train_wall=23, wall=0
2024-07-15 18:01:27 | INFO | train_inner | epoch 007:  14508 / 14632 loss=5.473, nll_loss=4.206, ppl=18.45, wps=15160.6, ups=4.37, wpb=3468.7, bsz=107, num_updates=102300, lr=9.88695e-05, gnorm=1.18, train_wall=23, wall=0
2024-07-15 18:01:50 | INFO | train_inner | epoch 007:  14608 / 14632 loss=5.424, nll_loss=4.15, ppl=17.76, wps=15391.7, ups=4.42, wpb=3481.1, bsz=114.1, num_updates=102400, lr=9.88212e-05, gnorm=1.179, train_wall=22, wall=0
2024-07-15 18:01:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 18:01:58 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.364 | nll_loss 5.163 | ppl 35.82 | wps 42306.8 | wpb 2469 | bsz 83 | num_updates 102424 | best_loss 12.212
2024-07-15 18:01:58 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 18:02:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 7 @ 102424 updates, score 6.364) (writing took 3.885001940652728 seconds)
2024-07-15 18:02:02 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2024-07-15 18:02:02 | INFO | train | epoch 007 | loss 5.426 | nll_loss 4.151 | ppl 17.76 | wps 14855.4 | ups 4.26 | wpb 3483.6 | bsz 118.4 | num_updates 102424 | lr 9.88096e-05 | gnorm 1.178 | train_wall 3297 | wall 0
2024-07-15 18:02:02 | INFO | fairseq.trainer | begin training epoch 8
2024-07-15 18:02:20 | INFO | train_inner | epoch 008:     76 / 14632 loss=5.323, nll_loss=4.033, ppl=16.38, wps=11871.3, ups=3.4, wpb=3496.6, bsz=125.1, num_updates=102500, lr=9.8773e-05, gnorm=1.183, train_wall=23, wall=0
2024-07-15 18:02:42 | INFO | train_inner | epoch 008:    176 / 14632 loss=5.433, nll_loss=4.159, ppl=17.87, wps=15096.9, ups=4.44, wpb=3402.8, bsz=100.8, num_updates=102600, lr=9.87248e-05, gnorm=1.19, train_wall=22, wall=0
2024-07-15 18:03:05 | INFO | train_inner | epoch 008:    276 / 14632 loss=5.381, nll_loss=4.1, ppl=17.14, wps=15256, ups=4.34, wpb=3517.6, bsz=117.7, num_updates=102700, lr=9.86767e-05, gnorm=1.201, train_wall=23, wall=0
2024-07-15 18:03:28 | INFO | train_inner | epoch 008:    376 / 14632 loss=5.349, nll_loss=4.064, ppl=16.73, wps=15025.4, ups=4.42, wpb=3400.2, bsz=129.2, num_updates=102800, lr=9.86287e-05, gnorm=1.218, train_wall=22, wall=0
2024-07-15 18:03:51 | INFO | train_inner | epoch 008:    476 / 14632 loss=5.32, nll_loss=4.029, ppl=16.33, wps=15198.2, ups=4.29, wpb=3538.6, bsz=133.2, num_updates=102900, lr=9.85808e-05, gnorm=1.178, train_wall=23, wall=0
2024-07-15 18:04:14 | INFO | train_inner | epoch 008:    576 / 14632 loss=5.405, nll_loss=4.127, ppl=17.48, wps=14996.5, ups=4.43, wpb=3383.4, bsz=112.6, num_updates=103000, lr=9.85329e-05, gnorm=1.235, train_wall=22, wall=0
2024-07-15 18:04:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 18:04:16 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.358 | nll_loss 5.151 | ppl 35.53 | wps 42425.8 | wpb 2469 | bsz 83 | num_updates 103000 | best_loss 12.212
2024-07-15 18:04:16 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 18:04:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_103000.pt (epoch 8 @ 103000 updates, score 6.358) (writing took 4.68505066819489 seconds)
2024-07-15 18:04:44 | INFO | train_inner | epoch 008:    676 / 14632 loss=5.401, nll_loss=4.122, ppl=17.41, wps=11662.8, ups=3.34, wpb=3496.2, bsz=112.2, num_updates=103100, lr=9.84851e-05, gnorm=1.162, train_wall=23, wall=0
2024-07-15 18:05:06 | INFO | train_inner | epoch 008:    776 / 14632 loss=5.336, nll_loss=4.049, ppl=16.55, wps=15260.9, ups=4.42, wpb=3452.6, bsz=114.8, num_updates=103200, lr=9.84374e-05, gnorm=1.177, train_wall=22, wall=0
2024-07-15 18:05:29 | INFO | train_inner | epoch 008:    876 / 14632 loss=5.329, nll_loss=4.041, ppl=16.46, wps=15263.4, ups=4.44, wpb=3436.6, bsz=126.4, num_updates=103300, lr=9.83897e-05, gnorm=1.235, train_wall=22, wall=0
2024-07-15 18:05:52 | INFO | train_inner | epoch 008:    976 / 14632 loss=5.359, nll_loss=4.074, ppl=16.85, wps=15289.7, ups=4.35, wpb=3516.2, bsz=112.1, num_updates=103400, lr=9.83422e-05, gnorm=1.181, train_wall=23, wall=0
2024-07-15 18:06:15 | INFO | train_inner | epoch 008:   1076 / 14632 loss=5.379, nll_loss=4.097, ppl=17.12, wps=15217.9, ups=4.38, wpb=3470.8, bsz=110, num_updates=103500, lr=9.82946e-05, gnorm=1.208, train_wall=23, wall=0
2024-07-15 18:06:37 | INFO | train_inner | epoch 008:   1176 / 14632 loss=5.425, nll_loss=4.15, ppl=17.75, wps=15235.9, ups=4.4, wpb=3464.9, bsz=111.4, num_updates=103600, lr=9.82472e-05, gnorm=1.213, train_wall=23, wall=0
2024-07-15 18:07:00 | INFO | train_inner | epoch 008:   1276 / 14632 loss=5.441, nll_loss=4.169, ppl=17.98, wps=15022.6, ups=4.4, wpb=3412.3, bsz=119.4, num_updates=103700, lr=9.81998e-05, gnorm=1.238, train_wall=23, wall=0
2024-07-15 18:07:23 | INFO | train_inner | epoch 008:   1376 / 14632 loss=5.373, nll_loss=4.09, ppl=17.03, wps=15413.3, ups=4.34, wpb=3552.1, bsz=123.6, num_updates=103800, lr=9.81525e-05, gnorm=1.195, train_wall=23, wall=0
2024-07-15 18:07:46 | INFO | train_inner | epoch 008:   1476 / 14632 loss=5.396, nll_loss=4.116, ppl=17.34, wps=15023.7, ups=4.44, wpb=3383, bsz=123.3, num_updates=103900, lr=9.81052e-05, gnorm=1.289, train_wall=22, wall=0
2024-07-15 18:08:08 | INFO | train_inner | epoch 008:   1576 / 14632 loss=5.36, nll_loss=4.075, ppl=16.86, wps=15161.5, ups=4.36, wpb=3474.4, bsz=114.6, num_updates=104000, lr=9.80581e-05, gnorm=1.199, train_wall=23, wall=0
2024-07-15 18:08:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 18:08:11 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.366 | nll_loss 5.155 | ppl 35.64 | wps 42304.3 | wpb 2469 | bsz 83 | num_updates 104000 | best_loss 12.212
2024-07-15 18:08:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 18:08:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_104000.pt (epoch 8 @ 104000 updates, score 6.366) (writing took 4.506484684534371 seconds)
2024-07-15 18:08:38 | INFO | train_inner | epoch 008:   1676 / 14632 loss=5.468, nll_loss=4.198, ppl=18.36, wps=11592.1, ups=3.36, wpb=3454.6, bsz=111.5, num_updates=104100, lr=9.8011e-05, gnorm=1.261, train_wall=23, wall=0
2024-07-15 18:09:01 | INFO | train_inner | epoch 008:   1776 / 14632 loss=5.402, nll_loss=4.123, ppl=17.43, wps=15326.5, ups=4.37, wpb=3508.1, bsz=111.4, num_updates=104200, lr=9.79639e-05, gnorm=1.169, train_wall=23, wall=0
2024-07-15 18:09:24 | INFO | train_inner | epoch 008:   1876 / 14632 loss=5.367, nll_loss=4.084, ppl=16.96, wps=15484.8, ups=4.34, wpb=3569, bsz=124.3, num_updates=104300, lr=9.79169e-05, gnorm=1.178, train_wall=23, wall=0
2024-07-15 18:09:47 | INFO | train_inner | epoch 008:   1976 / 14632 loss=5.442, nll_loss=4.169, ppl=17.99, wps=15105.1, ups=4.4, wpb=3435.8, bsz=99.6, num_updates=104400, lr=9.787e-05, gnorm=1.192, train_wall=23, wall=0
2024-07-15 18:10:10 | INFO | train_inner | epoch 008:   2076 / 14632 loss=5.427, nll_loss=4.153, ppl=17.79, wps=14979.1, ups=4.4, wpb=3400.9, bsz=104.6, num_updates=104500, lr=9.78232e-05, gnorm=1.209, train_wall=23, wall=0
2024-07-15 18:10:32 | INFO | train_inner | epoch 008:   2176 / 14632 loss=5.423, nll_loss=4.148, ppl=17.73, wps=15117.4, ups=4.43, wpb=3410.9, bsz=101.6, num_updates=104600, lr=9.77764e-05, gnorm=1.212, train_wall=22, wall=0
2024-07-15 18:10:55 | INFO | train_inner | epoch 008:   2276 / 14632 loss=5.324, nll_loss=4.033, ppl=16.37, wps=15294.5, ups=4.33, wpb=3530.1, bsz=118.3, num_updates=104700, lr=9.77297e-05, gnorm=1.146, train_wall=23, wall=0
2024-07-15 18:11:18 | INFO | train_inner | epoch 008:   2376 / 14632 loss=5.334, nll_loss=4.045, ppl=16.51, wps=15435.5, ups=4.4, wpb=3504.2, bsz=130.6, num_updates=104800, lr=9.76831e-05, gnorm=1.229, train_wall=23, wall=0
2024-07-15 18:11:41 | INFO | train_inner | epoch 008:   2476 / 14632 loss=5.358, nll_loss=4.073, ppl=16.83, wps=15177.4, ups=4.37, wpb=3474.1, bsz=112.1, num_updates=104900, lr=9.76365e-05, gnorm=1.17, train_wall=23, wall=0
2024-07-15 18:12:04 | INFO | train_inner | epoch 008:   2576 / 14632 loss=5.376, nll_loss=4.094, ppl=17.08, wps=15121.9, ups=4.38, wpb=3448.7, bsz=107.7, num_updates=105000, lr=9.759e-05, gnorm=1.25, train_wall=23, wall=0
2024-07-15 18:12:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 18:12:06 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.352 | nll_loss 5.146 | ppl 35.4 | wps 42488.4 | wpb 2469 | bsz 83 | num_updates 105000 | best_loss 12.212
2024-07-15 18:12:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 18:12:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_105000.pt (epoch 8 @ 105000 updates, score 6.352) (writing took 4.33389631845057 seconds)
2024-07-15 18:12:33 | INFO | train_inner | epoch 008:   2676 / 14632 loss=5.443, nll_loss=4.17, ppl=18.01, wps=11818.3, ups=3.39, wpb=3485.8, bsz=114.2, num_updates=105100, lr=9.75436e-05, gnorm=1.2, train_wall=23, wall=0
2024-07-15 18:12:56 | INFO | train_inner | epoch 008:   2776 / 14632 loss=5.329, nll_loss=4.04, ppl=16.45, wps=14992.4, ups=4.39, wpb=3412.7, bsz=124, num_updates=105200, lr=9.74972e-05, gnorm=1.232, train_wall=23, wall=0
2024-07-15 18:13:19 | INFO | train_inner | epoch 008:   2876 / 14632 loss=5.504, nll_loss=4.239, ppl=18.88, wps=15404.7, ups=4.42, wpb=3485.8, bsz=108.6, num_updates=105300, lr=9.74509e-05, gnorm=1.211, train_wall=22, wall=0
2024-07-15 18:13:42 | INFO | train_inner | epoch 008:   2976 / 14632 loss=5.315, nll_loss=4.024, ppl=16.27, wps=15314.5, ups=4.34, wpb=3528.1, bsz=120.7, num_updates=105400, lr=9.74047e-05, gnorm=1.165, train_wall=23, wall=0
2024-07-15 18:14:04 | INFO | train_inner | epoch 008:   3076 / 14632 loss=5.514, nll_loss=4.252, ppl=19.05, wps=15155.9, ups=4.4, wpb=3441.6, bsz=97.1, num_updates=105500, lr=9.73585e-05, gnorm=1.228, train_wall=23, wall=0
2024-07-15 18:14:27 | INFO | train_inner | epoch 008:   3176 / 14632 loss=5.369, nll_loss=4.086, ppl=16.98, wps=15150.9, ups=4.39, wpb=3454.9, bsz=115.4, num_updates=105600, lr=9.73124e-05, gnorm=1.2, train_wall=23, wall=0
2024-07-15 18:14:50 | INFO | train_inner | epoch 008:   3276 / 14632 loss=5.34, nll_loss=4.053, ppl=16.6, wps=15248.1, ups=4.38, wpb=3479.8, bsz=121.5, num_updates=105700, lr=9.72663e-05, gnorm=1.18, train_wall=23, wall=0
2024-07-15 18:15:13 | INFO | train_inner | epoch 008:   3376 / 14632 loss=5.338, nll_loss=4.052, ppl=16.59, wps=15313.6, ups=4.4, wpb=3483.3, bsz=118.7, num_updates=105800, lr=9.72203e-05, gnorm=1.169, train_wall=23, wall=0
2024-07-15 18:15:36 | INFO | train_inner | epoch 008:   3476 / 14632 loss=5.368, nll_loss=4.084, ppl=16.96, wps=15439.3, ups=4.29, wpb=3600.4, bsz=121, num_updates=105900, lr=9.71744e-05, gnorm=1.17, train_wall=23, wall=0
2024-07-15 18:15:58 | INFO | train_inner | epoch 008:   3576 / 14632 loss=5.427, nll_loss=4.152, ppl=17.78, wps=15336.4, ups=4.48, wpb=3426.9, bsz=112.5, num_updates=106000, lr=9.71286e-05, gnorm=1.217, train_wall=22, wall=0
2024-07-15 18:15:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 18:16:01 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.364 | nll_loss 5.155 | ppl 35.62 | wps 42607.7 | wpb 2469 | bsz 83 | num_updates 106000 | best_loss 12.212
2024-07-15 18:16:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 18:16:05 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_106000.pt (epoch 8 @ 106000 updates, score 6.364) (writing took 4.391431012190878 seconds)
2024-07-15 18:16:28 | INFO | train_inner | epoch 008:   3676 / 14632 loss=5.423, nll_loss=4.148, ppl=17.72, wps=11688, ups=3.39, wpb=3445.2, bsz=114.4, num_updates=106100, lr=9.70828e-05, gnorm=1.21, train_wall=23, wall=0
2024-07-15 18:16:51 | INFO | train_inner | epoch 008:   3776 / 14632 loss=5.39, nll_loss=4.11, ppl=17.27, wps=15197.9, ups=4.38, wpb=3470.7, bsz=111.5, num_updates=106200, lr=9.70371e-05, gnorm=1.183, train_wall=23, wall=0
2024-07-15 18:17:14 | INFO | train_inner | epoch 008:   3876 / 14632 loss=5.289, nll_loss=3.995, ppl=15.95, wps=15070, ups=4.34, wpb=3470.1, bsz=131.9, num_updates=106300, lr=9.69914e-05, gnorm=1.247, train_wall=23, wall=0
2024-07-15 18:17:36 | INFO | train_inner | epoch 008:   3976 / 14632 loss=5.441, nll_loss=4.168, ppl=17.97, wps=15262.6, ups=4.4, wpb=3467, bsz=102.3, num_updates=106400, lr=9.69458e-05, gnorm=1.232, train_wall=23, wall=0
2024-07-15 18:17:59 | INFO | train_inner | epoch 008:   4076 / 14632 loss=5.349, nll_loss=4.062, ppl=16.7, wps=14999.5, ups=4.4, wpb=3406.3, bsz=124.3, num_updates=106500, lr=9.69003e-05, gnorm=1.246, train_wall=23, wall=0
2024-07-15 18:18:22 | INFO | train_inner | epoch 008:   4176 / 14632 loss=5.295, nll_loss=4, ppl=16, wps=15322, ups=4.39, wpb=3493, bsz=138.7, num_updates=106600, lr=9.68549e-05, gnorm=1.223, train_wall=23, wall=0
2024-07-15 18:18:45 | INFO | train_inner | epoch 008:   4276 / 14632 loss=5.32, nll_loss=4.029, ppl=16.33, wps=15146.3, ups=4.37, wpb=3465.4, bsz=121.5, num_updates=106700, lr=9.68095e-05, gnorm=1.268, train_wall=23, wall=0
2024-07-15 18:19:08 | INFO | train_inner | epoch 008:   4376 / 14632 loss=5.322, nll_loss=4.032, ppl=16.36, wps=14975, ups=4.36, wpb=3432.2, bsz=124.8, num_updates=106800, lr=9.67641e-05, gnorm=1.233, train_wall=23, wall=0
2024-07-15 18:19:30 | INFO | train_inner | epoch 008:   4476 / 14632 loss=5.264, nll_loss=3.964, ppl=15.61, wps=15379.3, ups=4.4, wpb=3493.9, bsz=141.5, num_updates=106900, lr=9.67189e-05, gnorm=1.254, train_wall=23, wall=0
2024-07-15 18:19:54 | INFO | train_inner | epoch 008:   4576 / 14632 loss=5.28, nll_loss=3.985, ppl=15.83, wps=15242.4, ups=4.33, wpb=3518.3, bsz=118.3, num_updates=107000, lr=9.66736e-05, gnorm=1.207, train_wall=23, wall=0
2024-07-15 18:19:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 18:19:56 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.266 | nll_loss 5.046 | ppl 33.04 | wps 42262.9 | wpb 2469 | bsz 83 | num_updates 107000 | best_loss 12.212
2024-07-15 18:19:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 18:20:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_107000.pt (epoch 8 @ 107000 updates, score 6.266) (writing took 4.5031776605173945 seconds)
2024-07-15 18:20:23 | INFO | train_inner | epoch 008:   4676 / 14632 loss=5.26, nll_loss=3.961, ppl=15.57, wps=11772.6, ups=3.37, wpb=3490.6, bsz=137.6, num_updates=107100, lr=9.66285e-05, gnorm=1.262, train_wall=23, wall=0
2024-07-15 18:20:46 | INFO | train_inner | epoch 008:   4776 / 14632 loss=5.353, nll_loss=4.067, ppl=16.76, wps=15149.5, ups=4.35, wpb=3478.8, bsz=120.9, num_updates=107200, lr=9.65834e-05, gnorm=1.241, train_wall=23, wall=0
2024-07-15 18:21:09 | INFO | train_inner | epoch 008:   4876 / 14632 loss=5.395, nll_loss=4.115, ppl=17.33, wps=15259.4, ups=4.39, wpb=3477.7, bsz=116.2, num_updates=107300, lr=9.65384e-05, gnorm=1.246, train_wall=23, wall=0
2024-07-15 18:21:32 | INFO | train_inner | epoch 008:   4976 / 14632 loss=5.286, nll_loss=3.991, ppl=15.9, wps=15154.7, ups=4.38, wpb=3461.9, bsz=119.1, num_updates=107400, lr=9.64935e-05, gnorm=1.23, train_wall=23, wall=0
2024-07-15 18:21:55 | INFO | train_inner | epoch 008:   5076 / 14632 loss=5.335, nll_loss=4.046, ppl=16.52, wps=15456.4, ups=4.33, wpb=3573.2, bsz=122.8, num_updates=107500, lr=9.64486e-05, gnorm=1.215, train_wall=23, wall=0
2024-07-15 18:22:18 | INFO | train_inner | epoch 008:   5176 / 14632 loss=5.387, nll_loss=4.107, ppl=17.23, wps=15531.2, ups=4.39, wpb=3537.9, bsz=109, num_updates=107600, lr=9.64037e-05, gnorm=1.23, train_wall=23, wall=0
2024-07-15 18:22:40 | INFO | train_inner | epoch 008:   5276 / 14632 loss=5.361, nll_loss=4.076, ppl=16.87, wps=14937, ups=4.4, wpb=3396.6, bsz=116.1, num_updates=107700, lr=9.6359e-05, gnorm=1.398, train_wall=23, wall=0
2024-07-15 18:23:03 | INFO | train_inner | epoch 008:   5376 / 14632 loss=5.26, nll_loss=3.962, ppl=15.58, wps=15191, ups=4.35, wpb=3490.5, bsz=118.4, num_updates=107800, lr=9.63143e-05, gnorm=1.214, train_wall=23, wall=0
2024-07-15 18:23:26 | INFO | train_inner | epoch 008:   5476 / 14632 loss=5.259, nll_loss=3.961, ppl=15.57, wps=15026.3, ups=4.39, wpb=3426.2, bsz=116.1, num_updates=107900, lr=9.62696e-05, gnorm=1.234, train_wall=23, wall=0
2024-07-15 18:23:49 | INFO | train_inner | epoch 008:   5576 / 14632 loss=5.295, nll_loss=4.001, ppl=16.01, wps=15129.7, ups=4.42, wpb=3425.2, bsz=114.4, num_updates=108000, lr=9.6225e-05, gnorm=1.248, train_wall=22, wall=0
2024-07-15 18:23:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 18:23:51 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.268 | nll_loss 5.054 | ppl 33.23 | wps 42271.6 | wpb 2469 | bsz 83 | num_updates 108000 | best_loss 12.212
2024-07-15 18:23:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 18:23:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_108000.pt (epoch 8 @ 108000 updates, score 6.268) (writing took 4.367687265388668 seconds)
2024-07-15 18:24:18 | INFO | train_inner | epoch 008:   5676 / 14632 loss=5.363, nll_loss=4.079, ppl=16.9, wps=11824.3, ups=3.39, wpb=3485.1, bsz=102.6, num_updates=108100, lr=9.61805e-05, gnorm=1.206, train_wall=23, wall=0
2024-07-15 18:24:41 | INFO | train_inner | epoch 008:   5776 / 14632 loss=5.282, nll_loss=3.987, ppl=15.86, wps=15114.1, ups=4.37, wpb=3461.8, bsz=132.6, num_updates=108200, lr=9.61361e-05, gnorm=1.275, train_wall=23, wall=0
2024-07-15 18:25:04 | INFO | train_inner | epoch 008:   5876 / 14632 loss=5.297, nll_loss=4.003, ppl=16.04, wps=15024, ups=4.35, wpb=3457.4, bsz=123.4, num_updates=108300, lr=9.60917e-05, gnorm=1.238, train_wall=23, wall=0
2024-07-15 18:25:27 | INFO | train_inner | epoch 008:   5976 / 14632 loss=5.286, nll_loss=3.989, ppl=15.88, wps=15533.3, ups=4.36, wpb=3565.6, bsz=132.2, num_updates=108400, lr=9.60473e-05, gnorm=1.227, train_wall=23, wall=0
2024-07-15 18:25:50 | INFO | train_inner | epoch 008:   6076 / 14632 loss=5.409, nll_loss=4.132, ppl=17.53, wps=15343.7, ups=4.35, wpb=3523.4, bsz=111, num_updates=108500, lr=9.60031e-05, gnorm=1.251, train_wall=23, wall=0
2024-07-15 18:26:13 | INFO | train_inner | epoch 008:   6176 / 14632 loss=5.28, nll_loss=3.985, ppl=15.84, wps=15032.7, ups=4.37, wpb=3442.1, bsz=115.3, num_updates=108600, lr=9.59589e-05, gnorm=1.245, train_wall=23, wall=0
2024-07-15 18:26:36 | INFO | train_inner | epoch 008:   6276 / 14632 loss=5.33, nll_loss=4.039, ppl=16.44, wps=15333.9, ups=4.41, wpb=3475.1, bsz=106.3, num_updates=108700, lr=9.59147e-05, gnorm=1.263, train_wall=22, wall=0
2024-07-15 18:26:58 | INFO | train_inner | epoch 008:   6376 / 14632 loss=5.338, nll_loss=4.051, ppl=16.57, wps=15336.5, ups=4.41, wpb=3474.8, bsz=113.4, num_updates=108800, lr=9.58706e-05, gnorm=1.248, train_wall=22, wall=0
2024-07-15 18:27:21 | INFO | train_inner | epoch 008:   6476 / 14632 loss=5.24, nll_loss=3.939, ppl=15.33, wps=15133.5, ups=4.38, wpb=3452, bsz=129.8, num_updates=108900, lr=9.58266e-05, gnorm=1.237, train_wall=23, wall=0
2024-07-15 18:27:44 | INFO | train_inner | epoch 008:   6576 / 14632 loss=5.219, nll_loss=3.914, ppl=15.07, wps=15355.4, ups=4.37, wpb=3511.8, bsz=127.1, num_updates=109000, lr=9.57826e-05, gnorm=1.208, train_wall=23, wall=0
2024-07-15 18:27:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 18:27:46 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.208 | nll_loss 4.986 | ppl 31.68 | wps 42538.6 | wpb 2469 | bsz 83 | num_updates 109000 | best_loss 12.212
2024-07-15 18:27:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 18:27:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_109000.pt (epoch 8 @ 109000 updates, score 6.208) (writing took 4.360412359237671 seconds)
2024-07-15 18:28:14 | INFO | train_inner | epoch 008:   6676 / 14632 loss=5.213, nll_loss=3.907, ppl=15, wps=11692.5, ups=3.38, wpb=3454.8, bsz=124.4, num_updates=109100, lr=9.57387e-05, gnorm=1.231, train_wall=23, wall=0
2024-07-15 18:28:36 | INFO | train_inner | epoch 008:   6776 / 14632 loss=5.373, nll_loss=4.09, ppl=17.04, wps=14798.2, ups=4.4, wpb=3367, bsz=90.3, num_updates=109200, lr=9.56949e-05, gnorm=1.254, train_wall=23, wall=0
2024-07-15 18:28:59 | INFO | train_inner | epoch 008:   6876 / 14632 loss=5.317, nll_loss=4.026, ppl=16.29, wps=15499.4, ups=4.45, wpb=3483.2, bsz=120.2, num_updates=109300, lr=9.56511e-05, gnorm=1.253, train_wall=22, wall=0
2024-07-15 18:29:22 | INFO | train_inner | epoch 008:   6976 / 14632 loss=5.249, nll_loss=3.948, ppl=15.44, wps=15282.7, ups=4.32, wpb=3539.8, bsz=128.2, num_updates=109400, lr=9.56074e-05, gnorm=1.252, train_wall=23, wall=0
2024-07-15 18:29:45 | INFO | train_inner | epoch 008:   7076 / 14632 loss=5.275, nll_loss=3.977, ppl=15.75, wps=15586.3, ups=4.36, wpb=3575.5, bsz=119.2, num_updates=109500, lr=9.55637e-05, gnorm=1.223, train_wall=23, wall=0
2024-07-15 18:30:08 | INFO | train_inner | epoch 008:   7176 / 14632 loss=5.405, nll_loss=4.127, ppl=17.47, wps=15080.6, ups=4.41, wpb=3420.9, bsz=98.1, num_updates=109600, lr=9.55201e-05, gnorm=1.255, train_wall=22, wall=0
2024-07-15 18:30:30 | INFO | train_inner | epoch 008:   7276 / 14632 loss=5.321, nll_loss=4.031, ppl=16.34, wps=15051.6, ups=4.37, wpb=3444.2, bsz=104.4, num_updates=109700, lr=9.54765e-05, gnorm=1.253, train_wall=23, wall=0
2024-07-15 18:30:53 | INFO | train_inner | epoch 008:   7376 / 14632 loss=5.235, nll_loss=3.932, ppl=15.26, wps=15401.7, ups=4.35, wpb=3542.9, bsz=130.2, num_updates=109800, lr=9.54331e-05, gnorm=1.218, train_wall=23, wall=0
2024-07-15 18:31:16 | INFO | train_inner | epoch 008:   7476 / 14632 loss=5.272, nll_loss=3.975, ppl=15.73, wps=15076.3, ups=4.36, wpb=3457.3, bsz=113.4, num_updates=109900, lr=9.53896e-05, gnorm=1.246, train_wall=23, wall=0
2024-07-15 18:31:39 | INFO | train_inner | epoch 008:   7576 / 14632 loss=5.324, nll_loss=4.033, ppl=16.37, wps=15666.9, ups=4.38, wpb=3573.2, bsz=118.7, num_updates=110000, lr=9.53463e-05, gnorm=1.232, train_wall=23, wall=0
2024-07-15 18:31:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 18:31:42 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.154 | nll_loss 4.921 | ppl 30.3 | wps 41593.4 | wpb 2469 | bsz 83 | num_updates 110000 | best_loss 12.212
2024-07-15 18:31:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 18:31:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_110000.pt (epoch 8 @ 110000 updates, score 6.154) (writing took 4.634086198173463 seconds)
2024-07-15 18:32:09 | INFO | train_inner | epoch 008:   7676 / 14632 loss=5.295, nll_loss=4.001, ppl=16.01, wps=11638.1, ups=3.33, wpb=3494.1, bsz=125.4, num_updates=110100, lr=9.53029e-05, gnorm=1.251, train_wall=23, wall=0
2024-07-15 18:32:32 | INFO | train_inner | epoch 008:   7776 / 14632 loss=5.278, nll_loss=3.981, ppl=15.79, wps=15321.9, ups=4.33, wpb=3537, bsz=120.6, num_updates=110200, lr=9.52597e-05, gnorm=1.221, train_wall=23, wall=0
2024-07-15 18:32:55 | INFO | train_inner | epoch 008:   7876 / 14632 loss=5.328, nll_loss=4.039, ppl=16.44, wps=15303.8, ups=4.41, wpb=3472.3, bsz=105, num_updates=110300, lr=9.52165e-05, gnorm=1.243, train_wall=23, wall=0
2024-07-15 18:33:18 | INFO | train_inner | epoch 008:   7976 / 14632 loss=5.297, nll_loss=4.004, ppl=16.05, wps=15047.7, ups=4.38, wpb=3434.2, bsz=116.5, num_updates=110400, lr=9.51734e-05, gnorm=1.241, train_wall=23, wall=0
2024-07-15 18:33:41 | INFO | train_inner | epoch 008:   8076 / 14632 loss=5.405, nll_loss=4.127, ppl=17.47, wps=15291.3, ups=4.33, wpb=3532.5, bsz=117.3, num_updates=110500, lr=9.51303e-05, gnorm=1.325, train_wall=23, wall=0
2024-07-15 18:34:04 | INFO | train_inner | epoch 008:   8176 / 14632 loss=5.279, nll_loss=3.984, ppl=15.82, wps=14957.9, ups=4.4, wpb=3399.4, bsz=108.2, num_updates=110600, lr=9.50873e-05, gnorm=1.245, train_wall=23, wall=0
2024-07-15 18:34:27 | INFO | train_inner | epoch 008:   8276 / 14632 loss=5.203, nll_loss=3.896, ppl=14.89, wps=15338.4, ups=4.34, wpb=3533.4, bsz=135.1, num_updates=110700, lr=9.50443e-05, gnorm=1.239, train_wall=23, wall=0
2024-07-15 18:34:50 | INFO | train_inner | epoch 008:   8376 / 14632 loss=5.346, nll_loss=4.059, ppl=16.67, wps=15125.3, ups=4.39, wpb=3447.2, bsz=113.8, num_updates=110800, lr=9.50014e-05, gnorm=1.25, train_wall=23, wall=0
2024-07-15 18:35:12 | INFO | train_inner | epoch 008:   8476 / 14632 loss=5.177, nll_loss=3.867, ppl=14.59, wps=15142.4, ups=4.36, wpb=3473.3, bsz=126.2, num_updates=110900, lr=9.49586e-05, gnorm=1.217, train_wall=23, wall=0
2024-07-15 18:35:35 | INFO | train_inner | epoch 008:   8576 / 14632 loss=5.334, nll_loss=4.045, ppl=16.5, wps=15370.3, ups=4.41, wpb=3485.7, bsz=113.8, num_updates=111000, lr=9.49158e-05, gnorm=1.237, train_wall=23, wall=0
2024-07-15 18:35:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 18:35:38 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.06 | nll_loss 4.812 | ppl 28.08 | wps 42425.8 | wpb 2469 | bsz 83 | num_updates 111000 | best_loss 12.212
2024-07-15 18:35:38 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 18:35:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_111000.pt (epoch 8 @ 111000 updates, score 6.06) (writing took 4.501544438302517 seconds)
2024-07-15 18:36:05 | INFO | train_inner | epoch 008:   8676 / 14632 loss=5.266, nll_loss=3.968, ppl=15.65, wps=11508.2, ups=3.35, wpb=3437.5, bsz=120, num_updates=111100, lr=9.48731e-05, gnorm=1.258, train_wall=23, wall=0
2024-07-15 18:36:28 | INFO | train_inner | epoch 008:   8776 / 14632 loss=5.312, nll_loss=4.02, ppl=16.22, wps=15403.5, ups=4.4, wpb=3497, bsz=118.7, num_updates=111200, lr=9.48304e-05, gnorm=1.259, train_wall=23, wall=0
2024-07-15 18:36:51 | INFO | train_inner | epoch 008:   8876 / 14632 loss=5.298, nll_loss=4.004, ppl=16.04, wps=15423.3, ups=4.38, wpb=3523.6, bsz=123.4, num_updates=111300, lr=9.47878e-05, gnorm=1.302, train_wall=23, wall=0
2024-07-15 18:37:14 | INFO | train_inner | epoch 008:   8976 / 14632 loss=5.305, nll_loss=4.012, ppl=16.13, wps=15582.9, ups=4.36, wpb=3577.4, bsz=117.4, num_updates=111400, lr=9.47452e-05, gnorm=1.205, train_wall=23, wall=0
2024-07-15 18:37:36 | INFO | train_inner | epoch 008:   9076 / 14632 loss=5.311, nll_loss=4.019, ppl=16.22, wps=15080.6, ups=4.38, wpb=3443.9, bsz=126.5, num_updates=111500, lr=9.47027e-05, gnorm=1.275, train_wall=23, wall=0
2024-07-15 18:37:59 | INFO | train_inner | epoch 008:   9176 / 14632 loss=5.304, nll_loss=4.011, ppl=16.13, wps=15247.3, ups=4.33, wpb=3519.5, bsz=102.6, num_updates=111600, lr=9.46603e-05, gnorm=1.229, train_wall=23, wall=0
2024-07-15 18:38:22 | INFO | train_inner | epoch 008:   9276 / 14632 loss=5.24, nll_loss=3.937, ppl=15.32, wps=15269.9, ups=4.35, wpb=3511.9, bsz=125.4, num_updates=111700, lr=9.46179e-05, gnorm=1.239, train_wall=23, wall=0
2024-07-15 18:38:45 | INFO | train_inner | epoch 008:   9376 / 14632 loss=5.26, nll_loss=3.962, ppl=15.58, wps=15294.1, ups=4.34, wpb=3522.2, bsz=126.5, num_updates=111800, lr=9.45756e-05, gnorm=1.288, train_wall=23, wall=0
2024-07-15 18:39:08 | INFO | train_inner | epoch 008:   9476 / 14632 loss=5.243, nll_loss=3.942, ppl=15.37, wps=15317.8, ups=4.37, wpb=3505.6, bsz=117.5, num_updates=111900, lr=9.45333e-05, gnorm=1.262, train_wall=23, wall=0
2024-07-15 18:39:31 | INFO | train_inner | epoch 008:   9576 / 14632 loss=5.2, nll_loss=3.891, ppl=14.84, wps=15296.9, ups=4.33, wpb=3531.9, bsz=140.1, num_updates=112000, lr=9.44911e-05, gnorm=1.25, train_wall=23, wall=0
2024-07-15 18:39:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 18:39:34 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 5.956 | nll_loss 4.695 | ppl 25.9 | wps 41752.2 | wpb 2469 | bsz 83 | num_updates 112000 | best_loss 12.212
2024-07-15 18:39:34 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 18:39:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_112000.pt (epoch 8 @ 112000 updates, score 5.956) (writing took 4.8260811269283295 seconds)
2024-07-15 18:40:02 | INFO | train_inner | epoch 008:   9676 / 14632 loss=5.3, nll_loss=4.007, ppl=16.08, wps=11610.8, ups=3.3, wpb=3518.8, bsz=108.6, num_updates=112100, lr=9.4449e-05, gnorm=1.214, train_wall=23, wall=0
2024-07-15 18:40:25 | INFO | train_inner | epoch 008:   9776 / 14632 loss=5.301, nll_loss=4.008, ppl=16.09, wps=15386, ups=4.31, wpb=3566.3, bsz=108.6, num_updates=112200, lr=9.44069e-05, gnorm=1.218, train_wall=23, wall=0
2024-07-15 18:40:48 | INFO | train_inner | epoch 008:   9876 / 14632 loss=5.169, nll_loss=3.857, ppl=14.49, wps=15328.1, ups=4.3, wpb=3565.6, bsz=133.6, num_updates=112300, lr=9.43648e-05, gnorm=1.246, train_wall=23, wall=0
2024-07-15 18:41:11 | INFO | train_inner | epoch 008:   9976 / 14632 loss=5.206, nll_loss=3.899, ppl=14.92, wps=15017.2, ups=4.34, wpb=3458.4, bsz=133.8, num_updates=112400, lr=9.43228e-05, gnorm=1.29, train_wall=23, wall=0
2024-07-15 18:41:34 | INFO | train_inner | epoch 008:  10076 / 14632 loss=5.248, nll_loss=3.946, ppl=15.41, wps=15144.6, ups=4.36, wpb=3471.2, bsz=117.8, num_updates=112500, lr=9.42809e-05, gnorm=1.248, train_wall=23, wall=0
2024-07-15 18:41:57 | INFO | train_inner | epoch 008:  10176 / 14632 loss=5.327, nll_loss=4.038, ppl=16.43, wps=15391.5, ups=4.38, wpb=3515.7, bsz=113, num_updates=112600, lr=9.4239e-05, gnorm=1.249, train_wall=23, wall=0
2024-07-15 18:42:20 | INFO | train_inner | epoch 008:  10276 / 14632 loss=5.385, nll_loss=4.104, ppl=17.19, wps=14814.5, ups=4.4, wpb=3370.7, bsz=95.3, num_updates=112700, lr=9.41972e-05, gnorm=1.311, train_wall=23, wall=0
2024-07-15 18:42:43 | INFO | train_inner | epoch 008:  10376 / 14632 loss=5.209, nll_loss=3.903, ppl=14.96, wps=15300, ups=4.39, wpb=3485.3, bsz=128.2, num_updates=112800, lr=9.41554e-05, gnorm=1.229, train_wall=23, wall=0
2024-07-15 18:43:05 | INFO | train_inner | epoch 008:  10476 / 14632 loss=5.269, nll_loss=3.971, ppl=15.68, wps=14974.1, ups=4.42, wpb=3389.2, bsz=117.2, num_updates=112900, lr=9.41137e-05, gnorm=1.332, train_wall=22, wall=0
2024-07-15 18:43:28 | INFO | train_inner | epoch 008:  10576 / 14632 loss=5.295, nll_loss=4, ppl=16, wps=15082.5, ups=4.34, wpb=3474.8, bsz=100.4, num_updates=113000, lr=9.40721e-05, gnorm=1.223, train_wall=23, wall=0
2024-07-15 18:43:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 18:43:31 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 5.849 | nll_loss 4.564 | ppl 23.65 | wps 42470.8 | wpb 2469 | bsz 83 | num_updates 113000 | best_loss 12.212
2024-07-15 18:43:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 18:43:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_113000.pt (epoch 8 @ 113000 updates, score 5.849) (writing took 4.21868013869971 seconds)
2024-07-15 18:43:58 | INFO | train_inner | epoch 008:  10676 / 14632 loss=5.31, nll_loss=4.017, ppl=16.19, wps=11898, ups=3.39, wpb=3510.5, bsz=104.8, num_updates=113100, lr=9.40305e-05, gnorm=1.22, train_wall=23, wall=0
2024-07-15 18:44:21 | INFO | train_inner | epoch 008:  10776 / 14632 loss=5.341, nll_loss=4.053, ppl=16.6, wps=15049.4, ups=4.34, wpb=3468.4, bsz=108.6, num_updates=113200, lr=9.39889e-05, gnorm=1.253, train_wall=23, wall=0
2024-07-15 18:44:44 | INFO | train_inner | epoch 008:  10876 / 14632 loss=5.33, nll_loss=4.041, ppl=16.47, wps=15377.3, ups=4.39, wpb=3500.9, bsz=122.8, num_updates=113300, lr=9.39475e-05, gnorm=1.362, train_wall=23, wall=0
2024-07-15 18:45:06 | INFO | train_inner | epoch 008:  10976 / 14632 loss=5.288, nll_loss=3.993, ppl=15.92, wps=15252.7, ups=4.37, wpb=3486.5, bsz=109.8, num_updates=113400, lr=9.3906e-05, gnorm=1.216, train_wall=23, wall=0
2024-07-15 18:45:29 | INFO | train_inner | epoch 008:  11076 / 14632 loss=5.242, nll_loss=3.941, ppl=15.35, wps=14894.1, ups=4.35, wpb=3427.3, bsz=130.6, num_updates=113500, lr=9.38647e-05, gnorm=1.271, train_wall=23, wall=0
2024-07-15 18:45:53 | INFO | train_inner | epoch 008:  11176 / 14632 loss=5.112, nll_loss=3.791, ppl=13.85, wps=15295.3, ups=4.32, wpb=3543.6, bsz=145.1, num_updates=113600, lr=9.38233e-05, gnorm=1.268, train_wall=23, wall=0
2024-07-15 18:46:15 | INFO | train_inner | epoch 008:  11276 / 14632 loss=5.244, nll_loss=3.943, ppl=15.38, wps=15482.4, ups=4.36, wpb=3553.6, bsz=116.6, num_updates=113700, lr=9.37821e-05, gnorm=1.239, train_wall=23, wall=0
2024-07-15 18:46:38 | INFO | train_inner | epoch 008:  11376 / 14632 loss=5.211, nll_loss=3.906, ppl=14.99, wps=15376, ups=4.41, wpb=3487.3, bsz=125.7, num_updates=113800, lr=9.37408e-05, gnorm=1.26, train_wall=23, wall=0
2024-07-15 18:47:01 | INFO | train_inner | epoch 008:  11476 / 14632 loss=5.226, nll_loss=3.922, ppl=15.16, wps=15130.2, ups=4.38, wpb=3450.5, bsz=115.7, num_updates=113900, lr=9.36997e-05, gnorm=1.251, train_wall=23, wall=0
2024-07-15 18:47:24 | INFO | train_inner | epoch 008:  11576 / 14632 loss=5.143, nll_loss=3.827, ppl=14.19, wps=15320, ups=4.35, wpb=3520.5, bsz=136, num_updates=114000, lr=9.36586e-05, gnorm=1.239, train_wall=23, wall=0
2024-07-15 18:47:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 18:47:26 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 5.75 | nll_loss 4.454 | ppl 21.92 | wps 42221.4 | wpb 2469 | bsz 83 | num_updates 114000 | best_loss 12.212
2024-07-15 18:47:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 18:47:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_114000.pt (epoch 8 @ 114000 updates, score 5.75) (writing took 4.851551298983395 seconds)
2024-07-15 18:47:54 | INFO | train_inner | epoch 008:  11676 / 14632 loss=5.244, nll_loss=3.942, ppl=15.37, wps=11823.3, ups=3.29, wpb=3596.4, bsz=121.9, num_updates=114100, lr=9.36175e-05, gnorm=1.25, train_wall=23, wall=0
2024-07-15 18:48:18 | INFO | train_inner | epoch 008:  11776 / 14632 loss=5.207, nll_loss=3.901, ppl=14.93, wps=15272.1, ups=4.3, wpb=3555.4, bsz=122.2, num_updates=114200, lr=9.35765e-05, gnorm=1.211, train_wall=23, wall=0
2024-07-15 18:48:41 | INFO | train_inner | epoch 008:  11876 / 14632 loss=5.248, nll_loss=3.949, ppl=15.44, wps=15013.8, ups=4.37, wpb=3433.1, bsz=118.6, num_updates=114300, lr=9.35356e-05, gnorm=1.426, train_wall=23, wall=0
2024-07-15 18:49:03 | INFO | train_inner | epoch 008:  11976 / 14632 loss=5.229, nll_loss=3.926, ppl=15.2, wps=15145.1, ups=4.39, wpb=3451.8, bsz=130.7, num_updates=114400, lr=9.34947e-05, gnorm=1.32, train_wall=23, wall=0
2024-07-15 18:49:26 | INFO | train_inner | epoch 008:  12076 / 14632 loss=5.236, nll_loss=3.935, ppl=15.29, wps=15329.3, ups=4.33, wpb=3540.2, bsz=126.6, num_updates=114500, lr=9.34539e-05, gnorm=1.263, train_wall=23, wall=0
2024-07-15 18:49:49 | INFO | train_inner | epoch 008:  12176 / 14632 loss=5.241, nll_loss=3.94, ppl=15.34, wps=15077.8, ups=4.35, wpb=3463.5, bsz=122.3, num_updates=114600, lr=9.34131e-05, gnorm=1.283, train_wall=23, wall=0
2024-07-15 18:50:12 | INFO | train_inner | epoch 008:  12276 / 14632 loss=5.356, nll_loss=4.071, ppl=16.81, wps=15177.6, ups=4.36, wpb=3483.5, bsz=98.6, num_updates=114700, lr=9.33724e-05, gnorm=1.246, train_wall=23, wall=0
2024-07-15 18:50:35 | INFO | train_inner | epoch 008:  12376 / 14632 loss=5.259, nll_loss=3.959, ppl=15.56, wps=15291.1, ups=4.35, wpb=3515.5, bsz=122.2, num_updates=114800, lr=9.33317e-05, gnorm=1.251, train_wall=23, wall=0
2024-07-15 18:50:58 | INFO | train_inner | epoch 008:  12476 / 14632 loss=5.207, nll_loss=3.899, ppl=14.92, wps=15382.8, ups=4.34, wpb=3542.8, bsz=123, num_updates=114900, lr=9.32911e-05, gnorm=1.219, train_wall=23, wall=0
2024-07-15 18:51:21 | INFO | train_inner | epoch 008:  12576 / 14632 loss=5.258, nll_loss=3.958, ppl=15.54, wps=15183.7, ups=4.35, wpb=3487.4, bsz=106.8, num_updates=115000, lr=9.32505e-05, gnorm=1.255, train_wall=23, wall=0
2024-07-15 18:51:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 18:51:24 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 5.739 | nll_loss 4.429 | ppl 21.55 | wps 42350.2 | wpb 2469 | bsz 83 | num_updates 115000 | best_loss 12.212
2024-07-15 18:51:24 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 18:51:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_115000.pt (epoch 8 @ 115000 updates, score 5.739) (writing took 4.591186619363725 seconds)
2024-07-15 18:51:51 | INFO | train_inner | epoch 008:  12676 / 14632 loss=5.305, nll_loss=4.012, ppl=16.14, wps=11665.4, ups=3.35, wpb=3480.2, bsz=109.5, num_updates=115100, lr=9.321e-05, gnorm=1.24, train_wall=23, wall=0
2024-07-15 18:52:14 | INFO | train_inner | epoch 008:  12776 / 14632 loss=5.275, nll_loss=3.979, ppl=15.76, wps=15460.4, ups=4.43, wpb=3492.1, bsz=115.7, num_updates=115200, lr=9.31695e-05, gnorm=1.241, train_wall=22, wall=0
2024-07-15 18:52:37 | INFO | train_inner | epoch 008:  12876 / 14632 loss=5.231, nll_loss=3.929, ppl=15.23, wps=15216.7, ups=4.35, wpb=3500.4, bsz=120.5, num_updates=115300, lr=9.31291e-05, gnorm=1.272, train_wall=23, wall=0
2024-07-15 18:53:00 | INFO | train_inner | epoch 008:  12976 / 14632 loss=5.308, nll_loss=4.016, ppl=16.18, wps=15267.6, ups=4.34, wpb=3518.8, bsz=114.3, num_updates=115400, lr=9.30887e-05, gnorm=1.218, train_wall=23, wall=0
2024-07-15 18:53:23 | INFO | train_inner | epoch 008:  13076 / 14632 loss=5.228, nll_loss=3.925, ppl=15.19, wps=15688.5, ups=4.35, wpb=3605.6, bsz=128.5, num_updates=115500, lr=9.30484e-05, gnorm=1.232, train_wall=23, wall=0
2024-07-15 18:53:45 | INFO | train_inner | epoch 008:  13176 / 14632 loss=5.286, nll_loss=3.992, ppl=15.91, wps=14905, ups=4.41, wpb=3379.3, bsz=114.2, num_updates=115600, lr=9.30082e-05, gnorm=1.301, train_wall=23, wall=0
2024-07-15 18:54:09 | INFO | train_inner | epoch 008:  13276 / 14632 loss=5.248, nll_loss=3.948, ppl=15.43, wps=15243.4, ups=4.33, wpb=3522.6, bsz=117.8, num_updates=115700, lr=9.2968e-05, gnorm=1.253, train_wall=23, wall=0
2024-07-15 18:54:31 | INFO | train_inner | epoch 008:  13376 / 14632 loss=5.281, nll_loss=3.985, ppl=15.83, wps=15191.8, ups=4.38, wpb=3467.1, bsz=122.9, num_updates=115800, lr=9.29278e-05, gnorm=1.309, train_wall=23, wall=0
2024-07-15 18:54:55 | INFO | train_inner | epoch 008:  13476 / 14632 loss=5.244, nll_loss=3.944, ppl=15.4, wps=15272.8, ups=4.31, wpb=3546.6, bsz=114.1, num_updates=115900, lr=9.28877e-05, gnorm=1.245, train_wall=23, wall=0
2024-07-15 18:55:18 | INFO | train_inner | epoch 008:  13576 / 14632 loss=5.278, nll_loss=3.981, ppl=15.79, wps=15399.9, ups=4.32, wpb=3564.7, bsz=119, num_updates=116000, lr=9.28477e-05, gnorm=1.274, train_wall=23, wall=0
2024-07-15 18:55:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 18:55:20 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 5.723 | nll_loss 4.411 | ppl 21.27 | wps 42445 | wpb 2469 | bsz 83 | num_updates 116000 | best_loss 12.212
2024-07-15 18:55:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 18:55:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_116000.pt (epoch 8 @ 116000 updates, score 5.723) (writing took 4.8196204248815775 seconds)
2024-07-15 18:55:48 | INFO | train_inner | epoch 008:  13676 / 14632 loss=5.245, nll_loss=3.946, ppl=15.41, wps=11454.6, ups=3.33, wpb=3443.1, bsz=115.4, num_updates=116100, lr=9.28077e-05, gnorm=1.335, train_wall=23, wall=0
2024-07-15 18:56:11 | INFO | train_inner | epoch 008:  13776 / 14632 loss=5.254, nll_loss=3.955, ppl=15.51, wps=15085.8, ups=4.35, wpb=3471.4, bsz=132.2, num_updates=116200, lr=9.27677e-05, gnorm=1.426, train_wall=23, wall=0
2024-07-15 18:56:33 | INFO | train_inner | epoch 008:  13876 / 14632 loss=5.314, nll_loss=4.023, ppl=16.26, wps=15002.2, ups=4.42, wpb=3395.4, bsz=117.9, num_updates=116300, lr=9.27278e-05, gnorm=1.425, train_wall=22, wall=0
2024-07-15 18:56:57 | INFO | train_inner | epoch 008:  13976 / 14632 loss=5.185, nll_loss=3.876, ppl=14.68, wps=15517.6, ups=4.32, wpb=3588.5, bsz=136.2, num_updates=116400, lr=9.2688e-05, gnorm=1.268, train_wall=23, wall=0
2024-07-15 18:57:20 | INFO | train_inner | epoch 008:  14076 / 14632 loss=5.112, nll_loss=3.792, ppl=13.85, wps=15046, ups=4.36, wpb=3450.8, bsz=148.1, num_updates=116500, lr=9.26482e-05, gnorm=1.398, train_wall=23, wall=0
2024-07-15 18:57:42 | INFO | train_inner | epoch 008:  14176 / 14632 loss=5.289, nll_loss=3.995, ppl=15.94, wps=15346.4, ups=4.38, wpb=3504.9, bsz=109.2, num_updates=116600, lr=9.26085e-05, gnorm=1.236, train_wall=23, wall=0
2024-07-15 18:58:05 | INFO | train_inner | epoch 008:  14276 / 14632 loss=5.187, nll_loss=3.878, ppl=14.71, wps=15278.7, ups=4.37, wpb=3499.8, bsz=128.1, num_updates=116700, lr=9.25688e-05, gnorm=1.262, train_wall=23, wall=0
2024-07-15 18:58:28 | INFO | train_inner | epoch 008:  14376 / 14632 loss=5.239, nll_loss=3.936, ppl=15.31, wps=15212.1, ups=4.32, wpb=3517.9, bsz=116, num_updates=116800, lr=9.25292e-05, gnorm=1.252, train_wall=23, wall=0
2024-07-15 18:58:51 | INFO | train_inner | epoch 008:  14476 / 14632 loss=5.274, nll_loss=3.977, ppl=15.75, wps=15115, ups=4.4, wpb=3432.7, bsz=110.4, num_updates=116900, lr=9.24896e-05, gnorm=1.402, train_wall=23, wall=0
2024-07-15 18:59:14 | INFO | train_inner | epoch 008:  14576 / 14632 loss=5.206, nll_loss=3.9, ppl=14.93, wps=15205.4, ups=4.4, wpb=3458.8, bsz=108.2, num_updates=117000, lr=9.245e-05, gnorm=1.285, train_wall=23, wall=0
2024-07-15 18:59:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 18:59:16 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 5.622 | nll_loss 4.298 | ppl 19.67 | wps 42381.3 | wpb 2469 | bsz 83 | num_updates 117000 | best_loss 12.212
2024-07-15 18:59:16 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 18:59:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_117000.pt (epoch 8 @ 117000 updates, score 5.622) (writing took 5.493566284887493 seconds)
2024-07-15 18:59:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 18:59:37 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 5.632 | nll_loss 4.305 | ppl 19.76 | wps 42409.3 | wpb 2469 | bsz 83 | num_updates 117056 | best_loss 12.212
2024-07-15 18:59:37 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 18:59:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 8 @ 117056 updates, score 5.632) (writing took 4.973122728057206 seconds)
2024-07-15 18:59:42 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2024-07-15 18:59:42 | INFO | train | epoch 008 | loss 5.306 | nll_loss 4.014 | ppl 16.15 | wps 14731.5 | ups 4.23 | wpb 3483.6 | bsz 118.4 | num_updates 117056 | lr 9.24279e-05 | gnorm 1.245 | train_wall 3322 | wall 0
2024-07-15 18:59:42 | INFO | fairseq.trainer | begin training epoch 9
2024-07-15 18:59:52 | INFO | train_inner | epoch 009:     44 / 14632 loss=5.233, nll_loss=3.931, ppl=15.25, wps=8918.6, ups=2.61, wpb=3416.6, bsz=110.3, num_updates=117100, lr=9.24105e-05, gnorm=1.285, train_wall=23, wall=0
2024-07-15 19:00:15 | INFO | train_inner | epoch 009:    144 / 14632 loss=5.253, nll_loss=3.953, ppl=15.48, wps=15027.4, ups=4.37, wpb=3435.6, bsz=112.2, num_updates=117200, lr=9.23711e-05, gnorm=1.278, train_wall=23, wall=0
2024-07-15 19:00:38 | INFO | train_inner | epoch 009:    244 / 14632 loss=5.151, nll_loss=3.837, ppl=14.29, wps=15189, ups=4.37, wpb=3478.7, bsz=137, num_updates=117300, lr=9.23317e-05, gnorm=1.291, train_wall=23, wall=0
2024-07-15 19:01:01 | INFO | train_inner | epoch 009:    344 / 14632 loss=5.119, nll_loss=3.799, ppl=13.92, wps=15463.6, ups=4.4, wpb=3516.9, bsz=129.9, num_updates=117400, lr=9.22924e-05, gnorm=1.261, train_wall=23, wall=0
2024-07-15 19:01:23 | INFO | train_inner | epoch 009:    444 / 14632 loss=5.242, nll_loss=3.941, ppl=15.36, wps=15408, ups=4.42, wpb=3485.2, bsz=114, num_updates=117500, lr=9.22531e-05, gnorm=1.269, train_wall=22, wall=0
2024-07-15 19:01:47 | INFO | train_inner | epoch 009:    544 / 14632 loss=5.111, nll_loss=3.791, ppl=13.84, wps=15252.1, ups=4.3, wpb=3550.8, bsz=118.6, num_updates=117600, lr=9.22139e-05, gnorm=1.24, train_wall=23, wall=0
2024-07-15 19:02:09 | INFO | train_inner | epoch 009:    644 / 14632 loss=5.246, nll_loss=3.945, ppl=15.41, wps=15400.4, ups=4.38, wpb=3512.2, bsz=104, num_updates=117700, lr=9.21747e-05, gnorm=1.288, train_wall=23, wall=0
2024-07-15 19:02:32 | INFO | train_inner | epoch 009:    744 / 14632 loss=5.248, nll_loss=3.948, ppl=15.44, wps=15082, ups=4.42, wpb=3415.8, bsz=104.6, num_updates=117800, lr=9.21356e-05, gnorm=1.307, train_wall=22, wall=0
2024-07-15 19:02:55 | INFO | train_inner | epoch 009:    844 / 14632 loss=5.227, nll_loss=3.923, ppl=15.17, wps=15158.6, ups=4.4, wpb=3447.7, bsz=112.5, num_updates=117900, lr=9.20965e-05, gnorm=1.312, train_wall=23, wall=0
2024-07-15 19:03:18 | INFO | train_inner | epoch 009:    944 / 14632 loss=5.194, nll_loss=3.885, ppl=14.78, wps=15063.1, ups=4.38, wpb=3436.5, bsz=110.7, num_updates=118000, lr=9.20575e-05, gnorm=1.312, train_wall=23, wall=0
2024-07-15 19:03:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 19:03:20 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.559 | nll_loss 4.22 | ppl 18.63 | wps 42068.8 | wpb 2469 | bsz 83 | num_updates 118000 | best_loss 12.212
2024-07-15 19:03:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 19:03:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_9_118000.pt (epoch 9 @ 118000 updates, score 5.559) (writing took 5.971581102348864 seconds)
2024-07-15 19:03:49 | INFO | train_inner | epoch 009:   1044 / 14632 loss=5.142, nll_loss=3.827, ppl=14.19, wps=11321.1, ups=3.16, wpb=3579.3, bsz=127.4, num_updates=118100, lr=9.20185e-05, gnorm=1.288, train_wall=23, wall=0
2024-07-15 19:04:12 | INFO | train_inner | epoch 009:   1144 / 14632 loss=5.104, nll_loss=3.783, ppl=13.77, wps=15052.5, ups=4.31, wpb=3492.2, bsz=129.5, num_updates=118200, lr=9.19795e-05, gnorm=1.318, train_wall=23, wall=0
2024-07-15 19:04:36 | INFO | train_inner | epoch 009:   1244 / 14632 loss=5.099, nll_loss=3.776, ppl=13.7, wps=15079.8, ups=4.31, wpb=3496, bsz=135.8, num_updates=118300, lr=9.19407e-05, gnorm=1.308, train_wall=23, wall=0
2024-07-15 19:04:58 | INFO | train_inner | epoch 009:   1344 / 14632 loss=5.144, nll_loss=3.829, ppl=14.21, wps=15292.4, ups=4.38, wpb=3490.5, bsz=122.7, num_updates=118400, lr=9.19018e-05, gnorm=1.29, train_wall=23, wall=0
2024-07-15 19:05:21 | INFO | train_inner | epoch 009:   1444 / 14632 loss=5.205, nll_loss=3.898, ppl=14.91, wps=14972.1, ups=4.38, wpb=3420.1, bsz=109.8, num_updates=118500, lr=9.1863e-05, gnorm=1.315, train_wall=23, wall=0
2024-07-15 19:05:44 | INFO | train_inner | epoch 009:   1544 / 14632 loss=5.193, nll_loss=3.884, ppl=14.76, wps=15190.4, ups=4.35, wpb=3490.4, bsz=115.4, num_updates=118600, lr=9.18243e-05, gnorm=1.329, train_wall=23, wall=0
2024-07-15 19:06:07 | INFO | train_inner | epoch 009:   1644 / 14632 loss=5.208, nll_loss=3.902, ppl=14.95, wps=15191.8, ups=4.37, wpb=3479.4, bsz=123.4, num_updates=118700, lr=9.17856e-05, gnorm=1.305, train_wall=23, wall=0
2024-07-15 19:06:30 | INFO | train_inner | epoch 009:   1744 / 14632 loss=5.142, nll_loss=3.826, ppl=14.18, wps=15422.3, ups=4.33, wpb=3561.8, bsz=127.9, num_updates=118800, lr=9.1747e-05, gnorm=1.307, train_wall=23, wall=0
2024-07-15 19:06:53 | INFO | train_inner | epoch 009:   1844 / 14632 loss=5.147, nll_loss=3.831, ppl=14.23, wps=15355.2, ups=4.37, wpb=3513, bsz=131, num_updates=118900, lr=9.17084e-05, gnorm=1.327, train_wall=23, wall=0
2024-07-15 19:07:16 | INFO | train_inner | epoch 009:   1944 / 14632 loss=5.135, nll_loss=3.817, ppl=14.1, wps=15097.7, ups=4.33, wpb=3490.1, bsz=119.7, num_updates=119000, lr=9.16698e-05, gnorm=1.291, train_wall=23, wall=0
2024-07-15 19:07:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 19:07:19 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.533 | nll_loss 4.189 | ppl 18.24 | wps 41623.5 | wpb 2469 | bsz 83 | num_updates 119000 | best_loss 12.212
2024-07-15 19:07:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 19:07:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_9_119000.pt (epoch 9 @ 119000 updates, score 5.533) (writing took 6.177491541951895 seconds)
2024-07-15 19:07:47 | INFO | train_inner | epoch 009:   2044 / 14632 loss=5.145, nll_loss=3.83, ppl=14.22, wps=10928.6, ups=3.2, wpb=3414.5, bsz=114.8, num_updates=119100, lr=9.16314e-05, gnorm=1.403, train_wall=22, wall=0
2024-07-15 19:08:11 | INFO | train_inner | epoch 009:   2144 / 14632 loss=5.201, nll_loss=3.892, ppl=14.85, wps=15252.4, ups=4.33, wpb=3519.3, bsz=110.6, num_updates=119200, lr=9.15929e-05, gnorm=1.282, train_wall=23, wall=0
2024-07-15 19:08:33 | INFO | train_inner | epoch 009:   2244 / 14632 loss=5.16, nll_loss=3.847, ppl=14.39, wps=15130.6, ups=4.37, wpb=3460.7, bsz=131.8, num_updates=119300, lr=9.15545e-05, gnorm=1.356, train_wall=23, wall=0
2024-07-15 19:08:56 | INFO | train_inner | epoch 009:   2344 / 14632 loss=5.193, nll_loss=3.884, ppl=14.77, wps=14908.8, ups=4.43, wpb=3367.2, bsz=115.8, num_updates=119400, lr=9.15162e-05, gnorm=1.348, train_wall=22, wall=0
2024-07-15 19:09:19 | INFO | train_inner | epoch 009:   2444 / 14632 loss=5.077, nll_loss=3.752, ppl=13.47, wps=15335.9, ups=4.36, wpb=3519.8, bsz=143.7, num_updates=119500, lr=9.14779e-05, gnorm=1.322, train_wall=23, wall=0
2024-07-15 19:09:42 | INFO | train_inner | epoch 009:   2544 / 14632 loss=5.172, nll_loss=3.859, ppl=14.51, wps=15014.1, ups=4.39, wpb=3423.5, bsz=105.4, num_updates=119600, lr=9.14396e-05, gnorm=1.318, train_wall=23, wall=0
2024-07-15 19:10:05 | INFO | train_inner | epoch 009:   2644 / 14632 loss=5.235, nll_loss=3.932, ppl=15.26, wps=15326.5, ups=4.4, wpb=3487, bsz=107.8, num_updates=119700, lr=9.14014e-05, gnorm=1.318, train_wall=23, wall=0
2024-07-15 19:10:28 | INFO | train_inner | epoch 009:   2744 / 14632 loss=5.181, nll_loss=3.87, ppl=14.63, wps=15179.9, ups=4.35, wpb=3487.9, bsz=117.3, num_updates=119800, lr=9.13633e-05, gnorm=1.333, train_wall=23, wall=0
2024-07-15 19:10:50 | INFO | train_inner | epoch 009:   2844 / 14632 loss=5.246, nll_loss=3.945, ppl=15.4, wps=14879.4, ups=4.4, wpb=3380, bsz=111, num_updates=119900, lr=9.13252e-05, gnorm=1.33, train_wall=23, wall=0
2024-07-15 19:11:13 | INFO | train_inner | epoch 009:   2944 / 14632 loss=5.114, nll_loss=3.793, ppl=13.86, wps=15250.4, ups=4.34, wpb=3511.9, bsz=126.3, num_updates=120000, lr=9.12871e-05, gnorm=1.323, train_wall=23, wall=0
2024-07-15 19:11:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 19:11:16 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.489 | nll_loss 4.138 | ppl 17.61 | wps 42355.8 | wpb 2469 | bsz 83 | num_updates 120000 | best_loss 12.212
2024-07-15 19:11:16 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 19:11:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_9_120000.pt (epoch 9 @ 120000 updates, score 5.489) (writing took 5.645603595301509 seconds)
2024-07-15 19:11:44 | INFO | train_inner | epoch 009:   3044 / 14632 loss=5.144, nll_loss=3.828, ppl=14.2, wps=11161.1, ups=3.2, wpb=3482.6, bsz=118.6, num_updates=120100, lr=9.12491e-05, gnorm=1.326, train_wall=23, wall=0
2024-07-15 19:12:07 | INFO | train_inner | epoch 009:   3144 / 14632 loss=5.157, nll_loss=3.843, ppl=14.35, wps=15525.4, ups=4.38, wpb=3545.8, bsz=125.3, num_updates=120200, lr=9.12111e-05, gnorm=1.316, train_wall=23, wall=0
2024-07-15 19:12:30 | INFO | train_inner | epoch 009:   3244 / 14632 loss=5.07, nll_loss=3.743, ppl=13.39, wps=15393.2, ups=4.33, wpb=3554.3, bsz=133.8, num_updates=120300, lr=9.11732e-05, gnorm=1.324, train_wall=23, wall=0
2024-07-15 19:12:53 | INFO | train_inner | epoch 009:   3344 / 14632 loss=5.223, nll_loss=3.918, ppl=15.12, wps=15169.6, ups=4.33, wpb=3504.8, bsz=105.9, num_updates=120400, lr=9.11353e-05, gnorm=1.41, train_wall=23, wall=0
2024-07-15 19:13:17 | INFO | train_inner | epoch 009:   3444 / 14632 loss=5.136, nll_loss=3.818, ppl=14.11, wps=15298, ups=4.34, wpb=3528.4, bsz=127, num_updates=120500, lr=9.10975e-05, gnorm=1.351, train_wall=23, wall=0
2024-07-15 19:13:39 | INFO | train_inner | epoch 009:   3544 / 14632 loss=5.047, nll_loss=3.717, ppl=13.15, wps=15323.2, ups=4.39, wpb=3492.2, bsz=120.8, num_updates=120600, lr=9.10597e-05, gnorm=1.316, train_wall=23, wall=0
2024-07-15 19:14:02 | INFO | train_inner | epoch 009:   3644 / 14632 loss=5.162, nll_loss=3.848, ppl=14.4, wps=15107, ups=4.4, wpb=3433.5, bsz=109.7, num_updates=120700, lr=9.1022e-05, gnorm=1.336, train_wall=23, wall=0
2024-07-15 19:14:25 | INFO | train_inner | epoch 009:   3744 / 14632 loss=5.201, nll_loss=3.894, ppl=14.86, wps=15008.4, ups=4.42, wpb=3396.6, bsz=108.3, num_updates=120800, lr=9.09843e-05, gnorm=1.337, train_wall=22, wall=0
2024-07-15 19:14:48 | INFO | train_inner | epoch 009:   3844 / 14632 loss=5.108, nll_loss=3.786, ppl=13.8, wps=15204.5, ups=4.39, wpb=3467.3, bsz=115.6, num_updates=120900, lr=9.09467e-05, gnorm=1.319, train_wall=23, wall=0
2024-07-15 19:15:11 | INFO | train_inner | epoch 009:   3944 / 14632 loss=5.146, nll_loss=3.829, ppl=14.21, wps=15073.4, ups=4.35, wpb=3465.6, bsz=109, num_updates=121000, lr=9.09091e-05, gnorm=1.38, train_wall=23, wall=0
2024-07-15 19:15:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 19:15:13 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.399 | nll_loss 4.03 | ppl 16.33 | wps 42346.9 | wpb 2469 | bsz 83 | num_updates 121000 | best_loss 12.212
2024-07-15 19:15:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 19:15:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_9_121000.pt (epoch 9 @ 121000 updates, score 5.399) (writing took 6.980181586928666 seconds)
2024-07-15 19:15:43 | INFO | train_inner | epoch 009:   4044 / 14632 loss=5.138, nll_loss=3.822, ppl=14.14, wps=10647.4, ups=3.09, wpb=3444.4, bsz=116.5, num_updates=121100, lr=9.08715e-05, gnorm=1.357, train_wall=23, wall=0
2024-07-15 19:16:06 | INFO | train_inner | epoch 009:   4144 / 14632 loss=5.132, nll_loss=3.815, ppl=14.07, wps=15006.7, ups=4.4, wpb=3413.7, bsz=122.9, num_updates=121200, lr=9.08341e-05, gnorm=1.357, train_wall=23, wall=0
2024-07-15 19:16:29 | INFO | train_inner | epoch 009:   4244 / 14632 loss=5.133, nll_loss=3.816, ppl=14.08, wps=15172, ups=4.34, wpb=3498.1, bsz=111.8, num_updates=121300, lr=9.07966e-05, gnorm=1.345, train_wall=23, wall=0
2024-07-15 19:16:52 | INFO | train_inner | epoch 009:   4344 / 14632 loss=5.088, nll_loss=3.763, ppl=13.57, wps=14656.3, ups=4.34, wpb=3374, bsz=119.8, num_updates=121400, lr=9.07592e-05, gnorm=1.366, train_wall=23, wall=0
2024-07-15 19:17:15 | INFO | train_inner | epoch 009:   4444 / 14632 loss=5.121, nll_loss=3.802, ppl=13.95, wps=15338.1, ups=4.38, wpb=3501.6, bsz=126.7, num_updates=121500, lr=9.07218e-05, gnorm=1.407, train_wall=23, wall=0
2024-07-15 19:17:37 | INFO | train_inner | epoch 009:   4544 / 14632 loss=5.139, nll_loss=3.822, ppl=14.14, wps=15148.3, ups=4.38, wpb=3460.3, bsz=118.7, num_updates=121600, lr=9.06845e-05, gnorm=1.366, train_wall=23, wall=0
2024-07-15 19:18:00 | INFO | train_inner | epoch 009:   4644 / 14632 loss=5.188, nll_loss=3.878, ppl=14.7, wps=15470.2, ups=4.34, wpb=3567.2, bsz=124.2, num_updates=121700, lr=9.06473e-05, gnorm=1.358, train_wall=23, wall=0
2024-07-15 19:18:23 | INFO | train_inner | epoch 009:   4744 / 14632 loss=5.077, nll_loss=3.752, ppl=13.48, wps=15050.6, ups=4.42, wpb=3404, bsz=119.9, num_updates=121800, lr=9.061e-05, gnorm=1.385, train_wall=22, wall=0
2024-07-15 19:18:46 | INFO | train_inner | epoch 009:   4844 / 14632 loss=5.098, nll_loss=3.776, ppl=13.7, wps=15000.5, ups=4.32, wpb=3473.9, bsz=119.9, num_updates=121900, lr=9.05729e-05, gnorm=1.361, train_wall=23, wall=0
2024-07-15 19:19:10 | INFO | train_inner | epoch 009:   4944 / 14632 loss=5.065, nll_loss=3.736, ppl=13.33, wps=15266.5, ups=4.28, wpb=3570.9, bsz=132.7, num_updates=122000, lr=9.05357e-05, gnorm=1.396, train_wall=23, wall=0
2024-07-15 19:19:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 19:19:12 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.359 | nll_loss 3.989 | ppl 15.88 | wps 41980.3 | wpb 2469 | bsz 83 | num_updates 122000 | best_loss 12.212
2024-07-15 19:19:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 19:19:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_9_122000.pt (epoch 9 @ 122000 updates, score 5.359) (writing took 5.729476793669164 seconds)
2024-07-15 19:19:41 | INFO | train_inner | epoch 009:   5044 / 14632 loss=5.022, nll_loss=3.689, ppl=12.9, wps=11150.1, ups=3.19, wpb=3499.6, bsz=130.2, num_updates=122100, lr=9.04987e-05, gnorm=1.448, train_wall=23, wall=0
2024-07-15 19:20:04 | INFO | train_inner | epoch 009:   5144 / 14632 loss=5.125, nll_loss=3.807, ppl=14, wps=15147.4, ups=4.33, wpb=3497.8, bsz=117.5, num_updates=122200, lr=9.04616e-05, gnorm=1.394, train_wall=23, wall=0
2024-07-15 19:20:27 | INFO | train_inner | epoch 009:   5244 / 14632 loss=5.149, nll_loss=3.835, ppl=14.27, wps=15055.6, ups=4.38, wpb=3435.8, bsz=114.5, num_updates=122300, lr=9.04246e-05, gnorm=1.351, train_wall=23, wall=0
2024-07-15 19:20:50 | INFO | train_inner | epoch 009:   5344 / 14632 loss=5.167, nll_loss=3.853, ppl=14.45, wps=15270.5, ups=4.4, wpb=3470.1, bsz=106.6, num_updates=122400, lr=9.03877e-05, gnorm=1.34, train_wall=23, wall=0
2024-07-15 19:21:13 | INFO | train_inner | epoch 009:   5444 / 14632 loss=5.18, nll_loss=3.869, ppl=14.61, wps=15276.5, ups=4.36, wpb=3500.8, bsz=109, num_updates=122500, lr=9.03508e-05, gnorm=1.34, train_wall=23, wall=0
2024-07-15 19:21:36 | INFO | train_inner | epoch 009:   5544 / 14632 loss=5.055, nll_loss=3.727, ppl=13.24, wps=15317.8, ups=4.27, wpb=3583.7, bsz=121.9, num_updates=122600, lr=9.03139e-05, gnorm=1.281, train_wall=23, wall=0
2024-07-15 19:21:59 | INFO | train_inner | epoch 009:   5644 / 14632 loss=5.108, nll_loss=3.787, ppl=13.8, wps=15482.3, ups=4.35, wpb=3561.4, bsz=117.3, num_updates=122700, lr=9.02771e-05, gnorm=1.307, train_wall=23, wall=0
2024-07-15 19:22:22 | INFO | train_inner | epoch 009:   5744 / 14632 loss=5.059, nll_loss=3.73, ppl=13.27, wps=15278.8, ups=4.33, wpb=3526.5, bsz=133.6, num_updates=122800, lr=9.02404e-05, gnorm=1.368, train_wall=23, wall=0
2024-07-15 19:22:45 | INFO | train_inner | epoch 009:   5844 / 14632 loss=5.049, nll_loss=3.72, ppl=13.18, wps=15178.2, ups=4.35, wpb=3491, bsz=123.2, num_updates=122900, lr=9.02036e-05, gnorm=1.376, train_wall=23, wall=0
2024-07-15 19:23:08 | INFO | train_inner | epoch 009:   5944 / 14632 loss=5.129, nll_loss=3.812, ppl=14.04, wps=15006.9, ups=4.37, wpb=3432.9, bsz=111.3, num_updates=123000, lr=9.0167e-05, gnorm=1.329, train_wall=23, wall=0
2024-07-15 19:23:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 19:23:10 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.381 | nll_loss 4.01 | ppl 16.11 | wps 42112.3 | wpb 2469 | bsz 83 | num_updates 123000 | best_loss 12.212
2024-07-15 19:23:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 19:23:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_9_123000.pt (epoch 9 @ 123000 updates, score 5.381) (writing took 5.461371526122093 seconds)
2024-07-15 19:23:39 | INFO | train_inner | epoch 009:   6044 / 14632 loss=5.102, nll_loss=3.781, ppl=13.75, wps=11388.3, ups=3.27, wpb=3487.4, bsz=113.8, num_updates=123100, lr=9.01303e-05, gnorm=1.367, train_wall=23, wall=0
2024-07-15 19:24:01 | INFO | train_inner | epoch 009:   6144 / 14632 loss=5.136, nll_loss=3.819, ppl=14.12, wps=15326.9, ups=4.37, wpb=3505.2, bsz=117.8, num_updates=123200, lr=9.00937e-05, gnorm=1.351, train_wall=23, wall=0
2024-07-15 19:24:24 | INFO | train_inner | epoch 009:   6244 / 14632 loss=5.172, nll_loss=3.859, ppl=14.51, wps=15476.7, ups=4.39, wpb=3527.1, bsz=116.1, num_updates=123300, lr=9.00572e-05, gnorm=1.407, train_wall=23, wall=0
2024-07-15 19:24:47 | INFO | train_inner | epoch 009:   6344 / 14632 loss=5.103, nll_loss=3.781, ppl=13.75, wps=15285.6, ups=4.37, wpb=3495.9, bsz=117.4, num_updates=123400, lr=9.00207e-05, gnorm=1.355, train_wall=23, wall=0
2024-07-15 19:25:10 | INFO | train_inner | epoch 009:   6444 / 14632 loss=5.133, nll_loss=3.815, ppl=14.08, wps=15249.7, ups=4.33, wpb=3522.4, bsz=118.6, num_updates=123500, lr=8.99843e-05, gnorm=1.332, train_wall=23, wall=0
2024-07-15 19:25:33 | INFO | train_inner | epoch 009:   6544 / 14632 loss=5.083, nll_loss=3.758, ppl=13.53, wps=15288.5, ups=4.36, wpb=3509.8, bsz=119.5, num_updates=123600, lr=8.99478e-05, gnorm=1.389, train_wall=23, wall=0
2024-07-15 19:25:56 | INFO | train_inner | epoch 009:   6644 / 14632 loss=5.183, nll_loss=3.872, ppl=14.65, wps=15400.8, ups=4.39, wpb=3509.7, bsz=112.7, num_updates=123700, lr=8.99115e-05, gnorm=1.414, train_wall=23, wall=0
2024-07-15 19:26:19 | INFO | train_inner | epoch 009:   6744 / 14632 loss=5.104, nll_loss=3.782, ppl=13.76, wps=15299.8, ups=4.41, wpb=3465.6, bsz=116, num_updates=123800, lr=8.98752e-05, gnorm=1.377, train_wall=22, wall=0
2024-07-15 19:26:42 | INFO | train_inner | epoch 009:   6844 / 14632 loss=5.121, nll_loss=3.801, ppl=13.94, wps=15488.7, ups=4.33, wpb=3574.7, bsz=111.4, num_updates=123900, lr=8.98389e-05, gnorm=1.365, train_wall=23, wall=0
2024-07-15 19:27:04 | INFO | train_inner | epoch 009:   6944 / 14632 loss=5.101, nll_loss=3.78, ppl=13.74, wps=15105.8, ups=4.37, wpb=3453.9, bsz=118.9, num_updates=124000, lr=8.98027e-05, gnorm=1.381, train_wall=23, wall=0
2024-07-15 19:27:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 19:27:07 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.326 | nll_loss 3.94 | ppl 15.35 | wps 42348.6 | wpb 2469 | bsz 83 | num_updates 124000 | best_loss 12.212
2024-07-15 19:27:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 19:27:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_9_124000.pt (epoch 9 @ 124000 updates, score 5.326) (writing took 6.641394034959376 seconds)
2024-07-15 19:27:36 | INFO | train_inner | epoch 009:   7044 / 14632 loss=5.05, nll_loss=3.721, ppl=13.19, wps=10982.4, ups=3.15, wpb=3488.9, bsz=125.2, num_updates=124100, lr=8.97665e-05, gnorm=1.405, train_wall=23, wall=0
2024-07-15 19:27:59 | INFO | train_inner | epoch 009:   7144 / 14632 loss=5.114, nll_loss=3.793, ppl=13.86, wps=15225.9, ups=4.36, wpb=3489.9, bsz=106.8, num_updates=124200, lr=8.97303e-05, gnorm=1.364, train_wall=23, wall=0
2024-07-15 19:28:22 | INFO | train_inner | epoch 009:   7244 / 14632 loss=5.051, nll_loss=3.724, ppl=13.21, wps=15070.6, ups=4.37, wpb=3450.9, bsz=125.4, num_updates=124300, lr=8.96942e-05, gnorm=1.354, train_wall=23, wall=0
2024-07-15 19:28:45 | INFO | train_inner | epoch 009:   7344 / 14632 loss=5.149, nll_loss=3.833, ppl=14.26, wps=15156.7, ups=4.42, wpb=3426.6, bsz=109.2, num_updates=124400, lr=8.96582e-05, gnorm=1.418, train_wall=22, wall=0
2024-07-15 19:29:07 | INFO | train_inner | epoch 009:   7444 / 14632 loss=5.174, nll_loss=3.862, ppl=14.55, wps=15176.6, ups=4.41, wpb=3437.7, bsz=110.8, num_updates=124500, lr=8.96221e-05, gnorm=1.409, train_wall=22, wall=0
2024-07-15 19:29:30 | INFO | train_inner | epoch 009:   7544 / 14632 loss=5.08, nll_loss=3.755, ppl=13.5, wps=15234.6, ups=4.41, wpb=3456.9, bsz=118.8, num_updates=124600, lr=8.95862e-05, gnorm=1.386, train_wall=23, wall=0
2024-07-15 19:29:53 | INFO | train_inner | epoch 009:   7644 / 14632 loss=5.011, nll_loss=3.676, ppl=12.78, wps=15183.4, ups=4.33, wpb=3508.3, bsz=134.6, num_updates=124700, lr=8.95502e-05, gnorm=1.434, train_wall=23, wall=0
2024-07-15 19:30:16 | INFO | train_inner | epoch 009:   7744 / 14632 loss=5.122, nll_loss=3.804, ppl=13.97, wps=15022.8, ups=4.37, wpb=3437, bsz=115.4, num_updates=124800, lr=8.95144e-05, gnorm=1.405, train_wall=23, wall=0
2024-07-15 19:30:39 | INFO | train_inner | epoch 009:   7844 / 14632 loss=5.061, nll_loss=3.733, ppl=13.3, wps=15184.4, ups=4.37, wpb=3476, bsz=126.7, num_updates=124900, lr=8.94785e-05, gnorm=1.371, train_wall=23, wall=0
2024-07-15 19:31:02 | INFO | train_inner | epoch 009:   7944 / 14632 loss=5.117, nll_loss=3.799, ppl=13.92, wps=14819.3, ups=4.39, wpb=3372.2, bsz=123, num_updates=125000, lr=8.94427e-05, gnorm=1.488, train_wall=23, wall=0
2024-07-15 19:31:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 19:31:04 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.278 | nll_loss 3.89 | ppl 14.83 | wps 42364.8 | wpb 2469 | bsz 83 | num_updates 125000 | best_loss 12.212
2024-07-15 19:31:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 19:31:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_9_125000.pt (epoch 9 @ 125000 updates, score 5.278) (writing took 6.1451549446210265 seconds)
2024-07-15 19:31:33 | INFO | train_inner | epoch 009:   8044 / 14632 loss=5.074, nll_loss=3.748, ppl=13.44, wps=11066.7, ups=3.17, wpb=3491.2, bsz=123.4, num_updates=125100, lr=8.9407e-05, gnorm=1.371, train_wall=23, wall=0
2024-07-15 19:31:56 | INFO | train_inner | epoch 009:   8144 / 14632 loss=5.107, nll_loss=3.786, ppl=13.8, wps=15001.8, ups=4.39, wpb=3417.3, bsz=105.4, num_updates=125200, lr=8.93713e-05, gnorm=1.409, train_wall=23, wall=0
2024-07-15 19:32:19 | INFO | train_inner | epoch 009:   8244 / 14632 loss=5.133, nll_loss=3.816, ppl=14.09, wps=15109.2, ups=4.39, wpb=3439.1, bsz=110.4, num_updates=125300, lr=8.93356e-05, gnorm=1.378, train_wall=23, wall=0
2024-07-15 19:32:42 | INFO | train_inner | epoch 009:   8344 / 14632 loss=5.026, nll_loss=3.693, ppl=12.93, wps=15305.1, ups=4.34, wpb=3525, bsz=125.4, num_updates=125400, lr=8.93e-05, gnorm=1.42, train_wall=23, wall=0
2024-07-15 19:33:05 | INFO | train_inner | epoch 009:   8444 / 14632 loss=5.098, nll_loss=3.776, ppl=13.7, wps=15046.4, ups=4.35, wpb=3458.7, bsz=106.7, num_updates=125500, lr=8.92644e-05, gnorm=1.407, train_wall=23, wall=0
2024-07-15 19:33:28 | INFO | train_inner | epoch 009:   8544 / 14632 loss=5.09, nll_loss=3.766, ppl=13.61, wps=15116.9, ups=4.34, wpb=3483, bsz=109.3, num_updates=125600, lr=8.92288e-05, gnorm=1.368, train_wall=23, wall=0
2024-07-15 19:33:51 | INFO | train_inner | epoch 009:   8644 / 14632 loss=5.123, nll_loss=3.804, ppl=13.97, wps=15316.1, ups=4.32, wpb=3547.2, bsz=121.1, num_updates=125700, lr=8.91933e-05, gnorm=1.363, train_wall=23, wall=0
2024-07-15 19:34:14 | INFO | train_inner | epoch 009:   8744 / 14632 loss=5.085, nll_loss=3.761, ppl=13.56, wps=15324.2, ups=4.31, wpb=3557.7, bsz=140.6, num_updates=125800, lr=8.91579e-05, gnorm=1.475, train_wall=23, wall=0
2024-07-15 19:34:37 | INFO | train_inner | epoch 009:   8844 / 14632 loss=5.053, nll_loss=3.724, ppl=13.22, wps=15012, ups=4.38, wpb=3426.6, bsz=121.7, num_updates=125900, lr=8.91225e-05, gnorm=1.478, train_wall=23, wall=0
2024-07-15 19:35:00 | INFO | train_inner | epoch 009:   8944 / 14632 loss=5.131, nll_loss=3.813, ppl=14.06, wps=15386.4, ups=4.34, wpb=3544.8, bsz=107.2, num_updates=126000, lr=8.90871e-05, gnorm=1.322, train_wall=23, wall=0
2024-07-15 19:35:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 19:35:02 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.222 | nll_loss 3.822 | ppl 14.15 | wps 42099.5 | wpb 2469 | bsz 83 | num_updates 126000 | best_loss 12.212
2024-07-15 19:35:02 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 19:35:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_9_126000.pt (epoch 9 @ 126000 updates, score 5.222) (writing took 5.852855402044952 seconds)
2024-07-15 19:35:32 | INFO | train_inner | epoch 009:   9044 / 14632 loss=4.955, nll_loss=3.612, ppl=12.23, wps=11150.9, ups=3.17, wpb=3517.9, bsz=146.2, num_updates=126100, lr=8.90517e-05, gnorm=1.434, train_wall=23, wall=0
2024-07-15 19:35:55 | INFO | train_inner | epoch 009:   9144 / 14632 loss=5.092, nll_loss=3.768, ppl=13.62, wps=15278.6, ups=4.34, wpb=3522.9, bsz=117.2, num_updates=126200, lr=8.90165e-05, gnorm=1.432, train_wall=23, wall=0
2024-07-15 19:36:17 | INFO | train_inner | epoch 009:   9244 / 14632 loss=5.053, nll_loss=3.724, ppl=13.22, wps=15166, ups=4.4, wpb=3446.1, bsz=117.4, num_updates=126300, lr=8.89812e-05, gnorm=1.366, train_wall=23, wall=0
2024-07-15 19:36:40 | INFO | train_inner | epoch 009:   9344 / 14632 loss=5.115, nll_loss=3.795, ppl=13.88, wps=15113.2, ups=4.35, wpb=3476.2, bsz=114.7, num_updates=126400, lr=8.8946e-05, gnorm=1.374, train_wall=23, wall=0
2024-07-15 19:37:03 | INFO | train_inner | epoch 009:   9444 / 14632 loss=4.979, nll_loss=3.641, ppl=12.47, wps=15404.2, ups=4.38, wpb=3513.1, bsz=123.9, num_updates=126500, lr=8.89108e-05, gnorm=1.326, train_wall=23, wall=0
2024-07-15 19:37:26 | INFO | train_inner | epoch 009:   9544 / 14632 loss=5.128, nll_loss=3.809, ppl=14.02, wps=15167.9, ups=4.34, wpb=3495, bsz=97, num_updates=126600, lr=8.88757e-05, gnorm=1.348, train_wall=23, wall=0
2024-07-15 19:37:49 | INFO | train_inner | epoch 009:   9644 / 14632 loss=5.11, nll_loss=3.79, ppl=13.84, wps=15025.2, ups=4.42, wpb=3396.4, bsz=120.6, num_updates=126700, lr=8.88406e-05, gnorm=1.497, train_wall=22, wall=0
2024-07-15 19:38:12 | INFO | train_inner | epoch 009:   9744 / 14632 loss=5.132, nll_loss=3.815, ppl=14.07, wps=15234.5, ups=4.39, wpb=3472.3, bsz=101.2, num_updates=126800, lr=8.88056e-05, gnorm=1.375, train_wall=23, wall=0
2024-07-15 19:38:35 | INFO | train_inner | epoch 009:   9844 / 14632 loss=5.041, nll_loss=3.71, ppl=13.09, wps=15296.2, ups=4.29, wpb=3561.4, bsz=127.5, num_updates=126900, lr=8.87706e-05, gnorm=1.404, train_wall=23, wall=0
2024-07-15 19:38:58 | INFO | train_inner | epoch 009:   9944 / 14632 loss=5.141, nll_loss=3.826, ppl=14.19, wps=14869.2, ups=4.39, wpb=3384.8, bsz=110.6, num_updates=127000, lr=8.87357e-05, gnorm=1.394, train_wall=23, wall=0
2024-07-15 19:38:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 19:39:00 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.188 | nll_loss 3.779 | ppl 13.72 | wps 41993.9 | wpb 2469 | bsz 83 | num_updates 127000 | best_loss 12.212
2024-07-15 19:39:00 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 19:39:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_9_127000.pt (epoch 9 @ 127000 updates, score 5.188) (writing took 5.6546808537095785 seconds)
2024-07-15 19:39:29 | INFO | train_inner | epoch 009:  10044 / 14632 loss=5.115, nll_loss=3.795, ppl=13.88, wps=11310.1, ups=3.23, wpb=3506.3, bsz=102.6, num_updates=127100, lr=8.87007e-05, gnorm=1.374, train_wall=23, wall=0
2024-07-15 19:39:52 | INFO | train_inner | epoch 009:  10144 / 14632 loss=4.947, nll_loss=3.604, ppl=12.16, wps=15156.8, ups=4.34, wpb=3494.2, bsz=124.7, num_updates=127200, lr=8.86659e-05, gnorm=1.462, train_wall=23, wall=0
2024-07-15 19:40:15 | INFO | train_inner | epoch 009:  10244 / 14632 loss=5.095, nll_loss=3.772, ppl=13.66, wps=15064.3, ups=4.36, wpb=3458.6, bsz=111.4, num_updates=127300, lr=8.8631e-05, gnorm=1.386, train_wall=23, wall=0
2024-07-15 19:40:38 | INFO | train_inner | epoch 009:  10344 / 14632 loss=5.106, nll_loss=3.785, ppl=13.79, wps=14887.1, ups=4.38, wpb=3401.9, bsz=112.4, num_updates=127400, lr=8.85962e-05, gnorm=1.431, train_wall=23, wall=0
2024-07-15 19:41:01 | INFO | train_inner | epoch 009:  10444 / 14632 loss=4.967, nll_loss=3.626, ppl=12.34, wps=15553.2, ups=4.31, wpb=3608.8, bsz=131.8, num_updates=127500, lr=8.85615e-05, gnorm=1.356, train_wall=23, wall=0
2024-07-15 19:41:24 | INFO | train_inner | epoch 009:  10544 / 14632 loss=4.98, nll_loss=3.642, ppl=12.49, wps=14944, ups=4.35, wpb=3432.4, bsz=125.4, num_updates=127600, lr=8.85268e-05, gnorm=1.421, train_wall=23, wall=0
2024-07-15 19:41:47 | INFO | train_inner | epoch 009:  10644 / 14632 loss=5.013, nll_loss=3.679, ppl=12.81, wps=15196.1, ups=4.31, wpb=3521.8, bsz=130.2, num_updates=127700, lr=8.84921e-05, gnorm=1.521, train_wall=23, wall=0
2024-07-15 19:42:10 | INFO | train_inner | epoch 009:  10744 / 14632 loss=5.053, nll_loss=3.725, ppl=13.22, wps=15073.7, ups=4.36, wpb=3455.6, bsz=131.2, num_updates=127800, lr=8.84575e-05, gnorm=1.412, train_wall=23, wall=0
2024-07-15 19:42:33 | INFO | train_inner | epoch 009:  10844 / 14632 loss=5.015, nll_loss=3.683, ppl=12.84, wps=14937.2, ups=4.36, wpb=3428.7, bsz=117.5, num_updates=127900, lr=8.84229e-05, gnorm=1.46, train_wall=23, wall=0
2024-07-15 19:42:56 | INFO | train_inner | epoch 009:  10944 / 14632 loss=5.023, nll_loss=3.69, ppl=12.91, wps=15183.2, ups=4.38, wpb=3466.2, bsz=128.9, num_updates=128000, lr=8.83883e-05, gnorm=1.559, train_wall=23, wall=0
2024-07-15 19:42:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 19:42:58 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.167 | nll_loss 3.759 | ppl 13.54 | wps 42376.1 | wpb 2469 | bsz 83 | num_updates 128000 | best_loss 12.212
2024-07-15 19:42:58 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 19:43:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_9_128000.pt (epoch 9 @ 128000 updates, score 5.167) (writing took 6.491303572431207 seconds)
2024-07-15 19:43:27 | INFO | train_inner | epoch 009:  11044 / 14632 loss=5.058, nll_loss=3.73, ppl=13.27, wps=10958.9, ups=3.14, wpb=3488.7, bsz=113.7, num_updates=128100, lr=8.83538e-05, gnorm=1.412, train_wall=23, wall=0
2024-07-15 19:43:51 | INFO | train_inner | epoch 009:  11144 / 14632 loss=5.101, nll_loss=3.781, ppl=13.74, wps=15085.6, ups=4.32, wpb=3492.6, bsz=99.4, num_updates=128200, lr=8.83194e-05, gnorm=1.41, train_wall=23, wall=0
2024-07-15 19:44:14 | INFO | train_inner | epoch 009:  11244 / 14632 loss=5.041, nll_loss=3.711, ppl=13.1, wps=15180.6, ups=4.35, wpb=3487.1, bsz=120.1, num_updates=128300, lr=8.82849e-05, gnorm=1.403, train_wall=23, wall=0
2024-07-15 19:44:36 | INFO | train_inner | epoch 009:  11344 / 14632 loss=5.021, nll_loss=3.689, ppl=12.9, wps=15121.1, ups=4.37, wpb=3457.1, bsz=114, num_updates=128400, lr=8.82506e-05, gnorm=1.404, train_wall=23, wall=0
2024-07-15 19:44:59 | INFO | train_inner | epoch 009:  11444 / 14632 loss=5.018, nll_loss=3.685, ppl=12.87, wps=14942.5, ups=4.43, wpb=3376.1, bsz=112.4, num_updates=128500, lr=8.82162e-05, gnorm=1.442, train_wall=22, wall=0
2024-07-15 19:45:22 | INFO | train_inner | epoch 009:  11544 / 14632 loss=5.055, nll_loss=3.727, ppl=13.25, wps=15177.7, ups=4.35, wpb=3485.2, bsz=113.9, num_updates=128600, lr=8.81819e-05, gnorm=1.389, train_wall=23, wall=0
2024-07-15 19:45:45 | INFO | train_inner | epoch 009:  11644 / 14632 loss=5.06, nll_loss=3.733, ppl=13.29, wps=15203.9, ups=4.35, wpb=3494.9, bsz=112.6, num_updates=128700, lr=8.81476e-05, gnorm=1.377, train_wall=23, wall=0
2024-07-15 19:46:08 | INFO | train_inner | epoch 009:  11744 / 14632 loss=5.021, nll_loss=3.688, ppl=12.89, wps=14780.3, ups=4.42, wpb=3343.6, bsz=125.8, num_updates=128800, lr=8.81134e-05, gnorm=1.442, train_wall=22, wall=0
2024-07-15 19:46:31 | INFO | train_inner | epoch 009:  11844 / 14632 loss=5.089, nll_loss=3.766, ppl=13.6, wps=15430.9, ups=4.31, wpb=3578.1, bsz=117.4, num_updates=128900, lr=8.80792e-05, gnorm=1.4, train_wall=23, wall=0
2024-07-15 19:46:54 | INFO | train_inner | epoch 009:  11944 / 14632 loss=5.079, nll_loss=3.754, ppl=13.49, wps=15464.7, ups=4.35, wpb=3556.1, bsz=122.4, num_updates=129000, lr=8.80451e-05, gnorm=1.417, train_wall=23, wall=0
2024-07-15 19:46:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 19:46:56 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.128 | nll_loss 3.708 | ppl 13.07 | wps 42284.8 | wpb 2469 | bsz 83 | num_updates 129000 | best_loss 12.212
2024-07-15 19:46:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 19:47:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_9_129000.pt (epoch 9 @ 129000 updates, score 5.128) (writing took 6.232637006789446 seconds)
2024-07-15 19:47:25 | INFO | train_inner | epoch 009:  12044 / 14632 loss=5.043, nll_loss=3.713, ppl=13.11, wps=10953.5, ups=3.18, wpb=3441.6, bsz=119.8, num_updates=129100, lr=8.8011e-05, gnorm=1.437, train_wall=23, wall=0
2024-07-15 19:47:48 | INFO | train_inner | epoch 009:  12144 / 14632 loss=4.974, nll_loss=3.635, ppl=12.43, wps=15424.9, ups=4.3, wpb=3583.1, bsz=123.2, num_updates=129200, lr=8.79769e-05, gnorm=1.354, train_wall=23, wall=0
2024-07-15 19:48:12 | INFO | train_inner | epoch 009:  12244 / 14632 loss=5.014, nll_loss=3.68, ppl=12.82, wps=14977.8, ups=4.32, wpb=3464.2, bsz=124.2, num_updates=129300, lr=8.79429e-05, gnorm=1.471, train_wall=23, wall=0
2024-07-15 19:48:34 | INFO | train_inner | epoch 009:  12344 / 14632 loss=5.013, nll_loss=3.68, ppl=12.82, wps=15101.9, ups=4.39, wpb=3438.8, bsz=114.6, num_updates=129400, lr=8.79089e-05, gnorm=1.436, train_wall=23, wall=0
2024-07-15 19:48:57 | INFO | train_inner | epoch 009:  12444 / 14632 loss=4.981, nll_loss=3.642, ppl=12.49, wps=15246.2, ups=4.32, wpb=3526.9, bsz=146.2, num_updates=129500, lr=8.7875e-05, gnorm=1.627, train_wall=23, wall=0
2024-07-15 19:49:21 | INFO | train_inner | epoch 009:  12544 / 14632 loss=4.999, nll_loss=3.662, ppl=12.66, wps=15283.8, ups=4.29, wpb=3559.8, bsz=118.2, num_updates=129600, lr=8.7841e-05, gnorm=1.391, train_wall=23, wall=0
2024-07-15 19:49:44 | INFO | train_inner | epoch 009:  12644 / 14632 loss=5.029, nll_loss=3.698, ppl=12.97, wps=15302.4, ups=4.36, wpb=3507.4, bsz=121.9, num_updates=129700, lr=8.78072e-05, gnorm=1.468, train_wall=23, wall=0
2024-07-15 19:50:06 | INFO | train_inner | epoch 009:  12744 / 14632 loss=5.051, nll_loss=3.723, ppl=13.2, wps=15290.6, ups=4.43, wpb=3455.1, bsz=118.6, num_updates=129800, lr=8.77733e-05, gnorm=1.424, train_wall=22, wall=0
2024-07-15 19:50:29 | INFO | train_inner | epoch 009:  12844 / 14632 loss=4.996, nll_loss=3.661, ppl=12.65, wps=14905.3, ups=4.33, wpb=3440.6, bsz=123.9, num_updates=129900, lr=8.77396e-05, gnorm=1.654, train_wall=23, wall=0
2024-07-15 19:50:52 | INFO | train_inner | epoch 009:  12944 / 14632 loss=5, nll_loss=3.665, ppl=12.68, wps=14935.5, ups=4.36, wpb=3425.1, bsz=116, num_updates=130000, lr=8.77058e-05, gnorm=1.423, train_wall=23, wall=0
2024-07-15 19:50:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 19:50:55 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.043 | nll_loss 3.607 | ppl 12.18 | wps 41193.2 | wpb 2469 | bsz 83 | num_updates 130000 | best_loss 12.212
2024-07-15 19:50:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 19:51:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_9_130000.pt (epoch 9 @ 130000 updates, score 5.043) (writing took 6.406426997855306 seconds)
2024-07-15 19:51:24 | INFO | train_inner | epoch 009:  13044 / 14632 loss=5.063, nll_loss=3.737, ppl=13.33, wps=11061.8, ups=3.14, wpb=3525.5, bsz=103, num_updates=130100, lr=8.76721e-05, gnorm=1.442, train_wall=23, wall=0
2024-07-15 19:51:47 | INFO | train_inner | epoch 009:  13144 / 14632 loss=4.982, nll_loss=3.643, ppl=12.49, wps=15597.5, ups=4.38, wpb=3559.6, bsz=116, num_updates=130200, lr=8.76384e-05, gnorm=1.362, train_wall=23, wall=0
2024-07-15 19:52:10 | INFO | train_inner | epoch 009:  13244 / 14632 loss=5.053, nll_loss=3.725, ppl=13.22, wps=15148.9, ups=4.39, wpb=3451.9, bsz=107.2, num_updates=130300, lr=8.76048e-05, gnorm=1.415, train_wall=23, wall=0
2024-07-15 19:52:33 | INFO | train_inner | epoch 009:  13344 / 14632 loss=5.046, nll_loss=3.717, ppl=13.15, wps=15372, ups=4.36, wpb=3522.5, bsz=108.5, num_updates=130400, lr=8.75712e-05, gnorm=1.652, train_wall=23, wall=0
2024-07-15 19:52:56 | INFO | train_inner | epoch 009:  13444 / 14632 loss=4.892, nll_loss=3.541, ppl=11.64, wps=15149.8, ups=4.34, wpb=3492.5, bsz=136.3, num_updates=130500, lr=8.75376e-05, gnorm=1.403, train_wall=23, wall=0
2024-07-15 19:53:19 | INFO | train_inner | epoch 009:  13544 / 14632 loss=4.946, nll_loss=3.602, ppl=12.14, wps=14994.3, ups=4.33, wpb=3463.2, bsz=122.5, num_updates=130600, lr=8.75041e-05, gnorm=1.832, train_wall=23, wall=0
2024-07-15 19:53:42 | INFO | train_inner | epoch 009:  13644 / 14632 loss=5.052, nll_loss=3.725, ppl=13.22, wps=15262, ups=4.37, wpb=3494.1, bsz=106.6, num_updates=130700, lr=8.74706e-05, gnorm=1.381, train_wall=23, wall=0
2024-07-15 19:54:05 | INFO | train_inner | epoch 009:  13744 / 14632 loss=4.98, nll_loss=3.641, ppl=12.47, wps=15243.2, ups=4.34, wpb=3510.5, bsz=121.3, num_updates=130800, lr=8.74372e-05, gnorm=1.398, train_wall=23, wall=0
2024-07-15 19:54:28 | INFO | train_inner | epoch 009:  13844 / 14632 loss=5.086, nll_loss=3.762, ppl=13.57, wps=15370.9, ups=4.32, wpb=3560.1, bsz=94.7, num_updates=130900, lr=8.74038e-05, gnorm=1.401, train_wall=23, wall=0
2024-07-15 19:54:51 | INFO | train_inner | epoch 009:  13944 / 14632 loss=5.041, nll_loss=3.711, ppl=13.1, wps=15264.6, ups=4.34, wpb=3514.1, bsz=111.4, num_updates=131000, lr=8.73704e-05, gnorm=1.426, train_wall=23, wall=0
2024-07-15 19:54:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 19:54:53 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.023 | nll_loss 3.58 | ppl 11.96 | wps 42209.9 | wpb 2469 | bsz 83 | num_updates 131000 | best_loss 12.212
2024-07-15 19:54:53 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 19:54:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_9_131000.pt (epoch 9 @ 131000 updates, score 5.023) (writing took 5.857957880944014 seconds)
2024-07-15 19:55:22 | INFO | train_inner | epoch 009:  14044 / 14632 loss=4.985, nll_loss=3.647, ppl=12.53, wps=11115, ups=3.2, wpb=3477.1, bsz=112, num_updates=131100, lr=8.73371e-05, gnorm=1.506, train_wall=23, wall=0
2024-07-15 19:55:45 | INFO | train_inner | epoch 009:  14144 / 14632 loss=5.007, nll_loss=3.672, ppl=12.75, wps=15338.9, ups=4.34, wpb=3537.3, bsz=119.6, num_updates=131200, lr=8.73038e-05, gnorm=1.432, train_wall=23, wall=0
2024-07-15 19:56:08 | INFO | train_inner | epoch 009:  14244 / 14632 loss=5.055, nll_loss=3.727, ppl=13.24, wps=15237.3, ups=4.37, wpb=3489, bsz=119.8, num_updates=131300, lr=8.72705e-05, gnorm=1.381, train_wall=23, wall=0
2024-07-15 19:56:31 | INFO | train_inner | epoch 009:  14344 / 14632 loss=5.049, nll_loss=3.72, ppl=13.18, wps=15352.3, ups=4.4, wpb=3491.1, bsz=115, num_updates=131400, lr=8.72373e-05, gnorm=1.498, train_wall=23, wall=0
2024-07-15 19:56:54 | INFO | train_inner | epoch 009:  14444 / 14632 loss=5.038, nll_loss=3.708, ppl=13.07, wps=15445.5, ups=4.36, wpb=3546.3, bsz=107.4, num_updates=131500, lr=8.72041e-05, gnorm=1.422, train_wall=23, wall=0
2024-07-15 19:57:17 | INFO | train_inner | epoch 009:  14544 / 14632 loss=5.018, nll_loss=3.686, ppl=12.87, wps=15069.3, ups=4.36, wpb=3455.8, bsz=117.6, num_updates=131600, lr=8.7171e-05, gnorm=1.393, train_wall=23, wall=0
2024-07-15 19:57:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 19:57:39 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 4.956 | nll_loss 3.506 | ppl 11.36 | wps 42218.1 | wpb 2469 | bsz 83 | num_updates 131688 | best_loss 12.212
2024-07-15 19:57:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 19:57:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 9 @ 131688 updates, score 4.956) (writing took 3.8654583850875497 seconds)
2024-07-15 19:57:43 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2024-07-15 19:57:43 | INFO | train | epoch 009 | loss 5.094 | nll_loss 3.771 | ppl 13.65 | wps 14641.7 | ups 4.2 | wpb 3483.6 | bsz 118.4 | num_updates 131688 | lr 8.71419e-05 | gnorm 1.385 | train_wall 3330 | wall 0
2024-07-15 19:57:43 | INFO | fairseq.trainer | begin training epoch 10
2024-07-15 19:57:46 | INFO | train_inner | epoch 010:     12 / 14632 loss=4.925, nll_loss=3.578, ppl=11.94, wps=11773.3, ups=3.42, wpb=3443.4, bsz=126.6, num_updates=131700, lr=8.71379e-05, gnorm=1.396, train_wall=23, wall=0
2024-07-15 19:58:09 | INFO | train_inner | epoch 010:    112 / 14632 loss=4.965, nll_loss=3.624, ppl=12.33, wps=15517.1, ups=4.38, wpb=3544.8, bsz=122.4, num_updates=131800, lr=8.71048e-05, gnorm=1.598, train_wall=23, wall=0
2024-07-15 19:58:32 | INFO | train_inner | epoch 010:    212 / 14632 loss=4.891, nll_loss=3.54, ppl=11.63, wps=15046.6, ups=4.31, wpb=3489.2, bsz=121.8, num_updates=131900, lr=8.70718e-05, gnorm=1.38, train_wall=23, wall=0
2024-07-15 19:58:55 | INFO | train_inner | epoch 010:    312 / 14632 loss=4.991, nll_loss=3.655, ppl=12.6, wps=15112.5, ups=4.4, wpb=3431.1, bsz=110.9, num_updates=132000, lr=8.70388e-05, gnorm=1.402, train_wall=23, wall=0
2024-07-15 19:58:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 19:58:57 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.994 | nll_loss 3.546 | ppl 11.68 | wps 42238.9 | wpb 2469 | bsz 83 | num_updates 132000 | best_loss 12.212
2024-07-15 19:58:57 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 19:59:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_10_132000.pt (epoch 10 @ 132000 updates, score 4.994) (writing took 6.122489304281771 seconds)
2024-07-15 19:59:26 | INFO | train_inner | epoch 010:    412 / 14632 loss=4.927, nll_loss=3.582, ppl=11.98, wps=10905.5, ups=3.2, wpb=3411.2, bsz=119.7, num_updates=132100, lr=8.70059e-05, gnorm=1.407, train_wall=23, wall=0
2024-07-15 19:59:49 | INFO | train_inner | epoch 010:    512 / 14632 loss=4.839, nll_loss=3.48, ppl=11.16, wps=15138.6, ups=4.3, wpb=3519.6, bsz=135.4, num_updates=132200, lr=8.6973e-05, gnorm=1.387, train_wall=23, wall=0
2024-07-15 20:00:12 | INFO | train_inner | epoch 010:    612 / 14632 loss=4.955, nll_loss=3.613, ppl=12.23, wps=15323.2, ups=4.33, wpb=3542.3, bsz=121.8, num_updates=132300, lr=8.69401e-05, gnorm=1.411, train_wall=23, wall=0
2024-07-15 20:00:36 | INFO | train_inner | epoch 010:    712 / 14632 loss=4.995, nll_loss=3.658, ppl=12.62, wps=15354.6, ups=4.31, wpb=3561.3, bsz=119.4, num_updates=132400, lr=8.69072e-05, gnorm=1.486, train_wall=23, wall=0
2024-07-15 20:00:58 | INFO | train_inner | epoch 010:    812 / 14632 loss=4.911, nll_loss=3.564, ppl=11.83, wps=14811, ups=4.39, wpb=3371.2, bsz=110.6, num_updates=132500, lr=8.68744e-05, gnorm=1.385, train_wall=23, wall=0
2024-07-15 20:01:21 | INFO | train_inner | epoch 010:    912 / 14632 loss=4.917, nll_loss=3.568, ppl=11.86, wps=15296.2, ups=4.34, wpb=3524.2, bsz=119.9, num_updates=132600, lr=8.68417e-05, gnorm=1.341, train_wall=23, wall=0
2024-07-15 20:01:44 | INFO | train_inner | epoch 010:   1012 / 14632 loss=4.964, nll_loss=3.624, ppl=12.33, wps=15279.7, ups=4.37, wpb=3498.1, bsz=115.3, num_updates=132700, lr=8.6809e-05, gnorm=1.386, train_wall=23, wall=0
2024-07-15 20:02:08 | INFO | train_inner | epoch 010:   1112 / 14632 loss=4.875, nll_loss=3.521, ppl=11.48, wps=15348.6, ups=4.31, wpb=3560.5, bsz=123.6, num_updates=132800, lr=8.67763e-05, gnorm=1.345, train_wall=23, wall=0
2024-07-15 20:02:30 | INFO | train_inner | epoch 010:   1212 / 14632 loss=4.889, nll_loss=3.538, ppl=11.61, wps=15026.7, ups=4.36, wpb=3445.3, bsz=120.3, num_updates=132900, lr=8.67436e-05, gnorm=1.408, train_wall=23, wall=0
2024-07-15 20:02:53 | INFO | train_inner | epoch 010:   1312 / 14632 loss=4.981, nll_loss=3.642, ppl=12.49, wps=15314.9, ups=4.41, wpb=3473.9, bsz=115, num_updates=133000, lr=8.6711e-05, gnorm=1.42, train_wall=23, wall=0
2024-07-15 20:02:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 20:02:56 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.935 | nll_loss 3.48 | ppl 11.15 | wps 42127.3 | wpb 2469 | bsz 83 | num_updates 133000 | best_loss 12.212
2024-07-15 20:02:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 20:03:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_10_133000.pt (epoch 10 @ 133000 updates, score 4.935) (writing took 7.836166729219258 seconds)
2024-07-15 20:03:26 | INFO | train_inner | epoch 010:   1412 / 14632 loss=4.985, nll_loss=3.646, ppl=12.52, wps=10608.6, ups=3.03, wpb=3504, bsz=115, num_updates=133100, lr=8.66784e-05, gnorm=1.405, train_wall=23, wall=0
2024-07-15 20:03:49 | INFO | train_inner | epoch 010:   1512 / 14632 loss=4.922, nll_loss=3.575, ppl=11.91, wps=15071.8, ups=4.37, wpb=3451.7, bsz=113.6, num_updates=133200, lr=8.66459e-05, gnorm=1.372, train_wall=23, wall=0
2024-07-15 20:04:12 | INFO | train_inner | epoch 010:   1612 / 14632 loss=4.884, nll_loss=3.532, ppl=11.57, wps=15250.8, ups=4.29, wpb=3551, bsz=111.4, num_updates=133300, lr=8.66134e-05, gnorm=1.356, train_wall=23, wall=0
2024-07-15 20:04:35 | INFO | train_inner | epoch 010:   1712 / 14632 loss=4.983, nll_loss=3.646, ppl=12.52, wps=14928.9, ups=4.41, wpb=3385.4, bsz=121.5, num_updates=133400, lr=8.65809e-05, gnorm=1.447, train_wall=22, wall=0
2024-07-15 20:04:58 | INFO | train_inner | epoch 010:   1812 / 14632 loss=4.938, nll_loss=3.593, ppl=12.06, wps=15257.5, ups=4.31, wpb=3539.8, bsz=110.9, num_updates=133500, lr=8.65485e-05, gnorm=1.354, train_wall=23, wall=0
2024-07-15 20:05:21 | INFO | train_inner | epoch 010:   1912 / 14632 loss=4.869, nll_loss=3.515, ppl=11.44, wps=15168.4, ups=4.33, wpb=3504.3, bsz=127.5, num_updates=133600, lr=8.65161e-05, gnorm=1.379, train_wall=23, wall=0
2024-07-15 20:05:44 | INFO | train_inner | epoch 010:   2012 / 14632 loss=4.939, nll_loss=3.596, ppl=12.09, wps=15114.7, ups=4.35, wpb=3477.1, bsz=115.2, num_updates=133700, lr=8.64837e-05, gnorm=1.357, train_wall=23, wall=0
2024-07-15 20:06:07 | INFO | train_inner | epoch 010:   2112 / 14632 loss=4.896, nll_loss=3.546, ppl=11.68, wps=15134.7, ups=4.37, wpb=3466, bsz=120.4, num_updates=133800, lr=8.64514e-05, gnorm=1.357, train_wall=23, wall=0
2024-07-15 20:06:30 | INFO | train_inner | epoch 010:   2212 / 14632 loss=4.837, nll_loss=3.477, ppl=11.14, wps=15108.5, ups=4.35, wpb=3473.4, bsz=120.2, num_updates=133900, lr=8.64191e-05, gnorm=1.351, train_wall=23, wall=0
2024-07-15 20:06:53 | INFO | train_inner | epoch 010:   2312 / 14632 loss=4.902, nll_loss=3.553, ppl=11.74, wps=14853.2, ups=4.36, wpb=3409, bsz=124.3, num_updates=134000, lr=8.63868e-05, gnorm=1.503, train_wall=23, wall=0
2024-07-15 20:06:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 20:06:56 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.929 | nll_loss 3.465 | ppl 11.04 | wps 42230.1 | wpb 2469 | bsz 83 | num_updates 134000 | best_loss 12.212
2024-07-15 20:06:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 20:07:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_10_134000.pt (epoch 10 @ 134000 updates, score 4.929) (writing took 8.072466919198632 seconds)
2024-07-15 20:07:27 | INFO | train_inner | epoch 010:   2412 / 14632 loss=4.892, nll_loss=3.542, ppl=11.65, wps=10407.1, ups=2.99, wpb=3478.7, bsz=117.1, num_updates=134100, lr=8.63546e-05, gnorm=1.393, train_wall=23, wall=0
2024-07-15 20:07:50 | INFO | train_inner | epoch 010:   2512 / 14632 loss=4.964, nll_loss=3.625, ppl=12.34, wps=15515, ups=4.35, wpb=3567, bsz=117.3, num_updates=134200, lr=8.63224e-05, gnorm=1.386, train_wall=23, wall=0
2024-07-15 20:08:12 | INFO | train_inner | epoch 010:   2612 / 14632 loss=4.89, nll_loss=3.539, ppl=11.62, wps=15160.2, ups=4.39, wpb=3449.6, bsz=120.4, num_updates=134300, lr=8.62903e-05, gnorm=1.407, train_wall=23, wall=0
2024-07-15 20:08:35 | INFO | train_inner | epoch 010:   2712 / 14632 loss=4.921, nll_loss=3.574, ppl=11.91, wps=15260.2, ups=4.36, wpb=3497, bsz=119, num_updates=134400, lr=8.62582e-05, gnorm=1.361, train_wall=23, wall=0
2024-07-15 20:08:58 | INFO | train_inner | epoch 010:   2812 / 14632 loss=4.933, nll_loss=3.589, ppl=12.03, wps=15179.5, ups=4.39, wpb=3461.3, bsz=138.5, num_updates=134500, lr=8.62261e-05, gnorm=1.546, train_wall=23, wall=0
2024-07-15 20:09:21 | INFO | train_inner | epoch 010:   2912 / 14632 loss=4.878, nll_loss=3.525, ppl=11.51, wps=15265.3, ups=4.35, wpb=3506.4, bsz=121.6, num_updates=134600, lr=8.61941e-05, gnorm=1.428, train_wall=23, wall=0
2024-07-15 20:09:44 | INFO | train_inner | epoch 010:   3012 / 14632 loss=4.806, nll_loss=3.442, ppl=10.87, wps=15106.8, ups=4.35, wpb=3472.1, bsz=125.4, num_updates=134700, lr=8.61621e-05, gnorm=1.361, train_wall=23, wall=0
2024-07-15 20:10:07 | INFO | train_inner | epoch 010:   3112 / 14632 loss=4.994, nll_loss=3.659, ppl=12.63, wps=15235.9, ups=4.39, wpb=3468.4, bsz=118.4, num_updates=134800, lr=8.61301e-05, gnorm=1.439, train_wall=23, wall=0
2024-07-15 20:10:30 | INFO | train_inner | epoch 010:   3212 / 14632 loss=4.806, nll_loss=3.443, ppl=10.87, wps=15195.3, ups=4.32, wpb=3514.5, bsz=135.6, num_updates=134900, lr=8.60982e-05, gnorm=1.369, train_wall=23, wall=0
2024-07-15 20:10:53 | INFO | train_inner | epoch 010:   3312 / 14632 loss=4.932, nll_loss=3.588, ppl=12.02, wps=15030.5, ups=4.43, wpb=3394.5, bsz=119, num_updates=135000, lr=8.60663e-05, gnorm=1.463, train_wall=22, wall=0
2024-07-15 20:10:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 20:10:55 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.894 | nll_loss 3.428 | ppl 10.76 | wps 42065.1 | wpb 2469 | bsz 83 | num_updates 135000 | best_loss 12.212
2024-07-15 20:10:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 20:11:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_10_135000.pt (epoch 10 @ 135000 updates, score 4.894) (writing took 6.367915113456547 seconds)
2024-07-15 20:11:24 | INFO | train_inner | epoch 010:   3412 / 14632 loss=4.876, nll_loss=3.524, ppl=11.5, wps=10997, ups=3.16, wpb=3480.6, bsz=129.3, num_updates=135100, lr=8.60344e-05, gnorm=1.387, train_wall=23, wall=0
2024-07-15 20:11:47 | INFO | train_inner | epoch 010:   3512 / 14632 loss=4.847, nll_loss=3.489, ppl=11.23, wps=15153.1, ups=4.34, wpb=3490.2, bsz=117.2, num_updates=135200, lr=8.60026e-05, gnorm=1.359, train_wall=23, wall=0
2024-07-15 20:12:10 | INFO | train_inner | epoch 010:   3612 / 14632 loss=4.903, nll_loss=3.555, ppl=11.75, wps=15241.6, ups=4.4, wpb=3461.4, bsz=120.8, num_updates=135300, lr=8.59708e-05, gnorm=1.373, train_wall=23, wall=0
2024-07-15 20:12:33 | INFO | train_inner | epoch 010:   3712 / 14632 loss=4.857, nll_loss=3.502, ppl=11.33, wps=15279.5, ups=4.35, wpb=3510.4, bsz=124.8, num_updates=135400, lr=8.59391e-05, gnorm=1.37, train_wall=23, wall=0
2024-07-15 20:12:56 | INFO | train_inner | epoch 010:   3812 / 14632 loss=4.945, nll_loss=3.602, ppl=12.15, wps=14952.5, ups=4.38, wpb=3412.8, bsz=106.1, num_updates=135500, lr=8.59074e-05, gnorm=1.39, train_wall=23, wall=0
2024-07-15 20:13:19 | INFO | train_inner | epoch 010:   3912 / 14632 loss=4.917, nll_loss=3.57, ppl=11.88, wps=15251.1, ups=4.36, wpb=3496.3, bsz=120.1, num_updates=135600, lr=8.58757e-05, gnorm=1.392, train_wall=23, wall=0
2024-07-15 20:13:42 | INFO | train_inner | epoch 010:   4012 / 14632 loss=4.934, nll_loss=3.589, ppl=12.04, wps=15292, ups=4.38, wpb=3492, bsz=121.1, num_updates=135700, lr=8.5844e-05, gnorm=1.382, train_wall=23, wall=0
2024-07-15 20:14:05 | INFO | train_inner | epoch 010:   4112 / 14632 loss=4.779, nll_loss=3.413, ppl=10.65, wps=15001.3, ups=4.3, wpb=3487.2, bsz=127.8, num_updates=135800, lr=8.58124e-05, gnorm=1.329, train_wall=23, wall=0
2024-07-15 20:14:28 | INFO | train_inner | epoch 010:   4212 / 14632 loss=4.832, nll_loss=3.473, ppl=11.11, wps=15081.6, ups=4.37, wpb=3450.1, bsz=134.7, num_updates=135900, lr=8.57808e-05, gnorm=1.403, train_wall=23, wall=0
2024-07-15 20:14:51 | INFO | train_inner | epoch 010:   4312 / 14632 loss=4.874, nll_loss=3.522, ppl=11.49, wps=15195.1, ups=4.31, wpb=3523.8, bsz=120.9, num_updates=136000, lr=8.57493e-05, gnorm=1.369, train_wall=23, wall=0
2024-07-15 20:14:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 20:14:53 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.88 | nll_loss 3.409 | ppl 10.62 | wps 42280.9 | wpb 2469 | bsz 83 | num_updates 136000 | best_loss 12.212
2024-07-15 20:14:53 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 20:14:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_10_136000.pt (epoch 10 @ 136000 updates, score 4.88) (writing took 4.597287839278579 seconds)
2024-07-15 20:15:21 | INFO | train_inner | epoch 010:   4412 / 14632 loss=4.902, nll_loss=3.553, ppl=11.73, wps=11740.7, ups=3.33, wpb=3522.9, bsz=115.8, num_updates=136100, lr=8.57178e-05, gnorm=1.368, train_wall=23, wall=0
2024-07-15 20:15:44 | INFO | train_inner | epoch 010:   4512 / 14632 loss=4.86, nll_loss=3.505, ppl=11.35, wps=15155.1, ups=4.36, wpb=3473.1, bsz=120.2, num_updates=136200, lr=8.56863e-05, gnorm=1.36, train_wall=23, wall=0
2024-07-15 20:16:06 | INFO | train_inner | epoch 010:   4612 / 14632 loss=4.858, nll_loss=3.502, ppl=11.33, wps=15194, ups=4.42, wpb=3440.1, bsz=114.9, num_updates=136300, lr=8.56549e-05, gnorm=1.383, train_wall=22, wall=0
2024-07-15 20:16:29 | INFO | train_inner | epoch 010:   4712 / 14632 loss=4.822, nll_loss=3.462, ppl=11.02, wps=15140.9, ups=4.37, wpb=3461, bsz=127.4, num_updates=136400, lr=8.56235e-05, gnorm=1.365, train_wall=23, wall=0
2024-07-15 20:16:52 | INFO | train_inner | epoch 010:   4812 / 14632 loss=4.91, nll_loss=3.563, ppl=11.82, wps=15293.2, ups=4.39, wpb=3484.4, bsz=115.4, num_updates=136500, lr=8.55921e-05, gnorm=1.374, train_wall=23, wall=0
2024-07-15 20:17:15 | INFO | train_inner | epoch 010:   4912 / 14632 loss=4.862, nll_loss=3.507, ppl=11.37, wps=14938.2, ups=4.37, wpb=3417.9, bsz=111.3, num_updates=136600, lr=8.55608e-05, gnorm=1.381, train_wall=23, wall=0
2024-07-15 20:17:38 | INFO | train_inner | epoch 010:   5012 / 14632 loss=4.92, nll_loss=3.573, ppl=11.9, wps=15263.1, ups=4.33, wpb=3528.9, bsz=114.1, num_updates=136700, lr=8.55295e-05, gnorm=1.386, train_wall=23, wall=0
2024-07-15 20:18:01 | INFO | train_inner | epoch 010:   5112 / 14632 loss=4.914, nll_loss=3.566, ppl=11.85, wps=15518.6, ups=4.36, wpb=3558.2, bsz=109.5, num_updates=136800, lr=8.54982e-05, gnorm=1.379, train_wall=23, wall=0
2024-07-15 20:18:24 | INFO | train_inner | epoch 010:   5212 / 14632 loss=4.931, nll_loss=3.586, ppl=12, wps=15417.4, ups=4.41, wpb=3492.8, bsz=116, num_updates=136900, lr=8.5467e-05, gnorm=1.404, train_wall=22, wall=0
2024-07-15 20:18:46 | INFO | train_inner | epoch 010:   5312 / 14632 loss=4.947, nll_loss=3.605, ppl=12.17, wps=14944.3, ups=4.42, wpb=3381.9, bsz=100.9, num_updates=137000, lr=8.54358e-05, gnorm=1.404, train_wall=22, wall=0
2024-07-15 20:18:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 20:18:49 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.847 | nll_loss 3.375 | ppl 10.38 | wps 42179.8 | wpb 2469 | bsz 83 | num_updates 137000 | best_loss 12.212
2024-07-15 20:18:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 20:18:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_10_137000.pt (epoch 10 @ 137000 updates, score 4.847) (writing took 4.452460924163461 seconds)
2024-07-15 20:19:16 | INFO | train_inner | epoch 010:   5412 / 14632 loss=4.95, nll_loss=3.608, ppl=12.19, wps=11606.3, ups=3.39, wpb=3420, bsz=117.5, num_updates=137100, lr=8.54046e-05, gnorm=1.434, train_wall=22, wall=0
2024-07-15 20:19:38 | INFO | train_inner | epoch 010:   5512 / 14632 loss=4.905, nll_loss=3.558, ppl=11.78, wps=15323.5, ups=4.42, wpb=3467.2, bsz=142.2, num_updates=137200, lr=8.53735e-05, gnorm=1.526, train_wall=22, wall=0
2024-07-15 20:20:01 | INFO | train_inner | epoch 010:   5612 / 14632 loss=4.875, nll_loss=3.523, ppl=11.5, wps=15041.3, ups=4.39, wpb=3427.8, bsz=116.4, num_updates=137300, lr=8.53424e-05, gnorm=1.363, train_wall=23, wall=0
2024-07-15 20:20:24 | INFO | train_inner | epoch 010:   5712 / 14632 loss=4.921, nll_loss=3.575, ppl=11.92, wps=15289.7, ups=4.34, wpb=3525.2, bsz=114.6, num_updates=137400, lr=8.53113e-05, gnorm=1.418, train_wall=23, wall=0
2024-07-15 20:20:47 | INFO | train_inner | epoch 010:   5812 / 14632 loss=4.903, nll_loss=3.555, ppl=11.75, wps=15207, ups=4.38, wpb=3474.3, bsz=108.8, num_updates=137500, lr=8.52803e-05, gnorm=1.397, train_wall=23, wall=0
2024-07-15 20:21:10 | INFO | train_inner | epoch 010:   5912 / 14632 loss=4.84, nll_loss=3.483, ppl=11.18, wps=14998.7, ups=4.33, wpb=3466.5, bsz=118.6, num_updates=137600, lr=8.52493e-05, gnorm=1.347, train_wall=23, wall=0
2024-07-15 20:21:33 | INFO | train_inner | epoch 010:   6012 / 14632 loss=4.886, nll_loss=3.535, ppl=11.59, wps=15028, ups=4.39, wpb=3422.3, bsz=112.6, num_updates=137700, lr=8.52183e-05, gnorm=1.361, train_wall=23, wall=0
2024-07-15 20:21:56 | INFO | train_inner | epoch 010:   6112 / 14632 loss=4.926, nll_loss=3.582, ppl=11.97, wps=15035.4, ups=4.36, wpb=3446.4, bsz=109.2, num_updates=137800, lr=8.51874e-05, gnorm=1.451, train_wall=23, wall=0
2024-07-15 20:22:19 | INFO | train_inner | epoch 010:   6212 / 14632 loss=4.87, nll_loss=3.517, ppl=11.45, wps=15357.3, ups=4.3, wpb=3570.1, bsz=115.1, num_updates=137900, lr=8.51565e-05, gnorm=1.339, train_wall=23, wall=0
2024-07-15 20:22:42 | INFO | train_inner | epoch 010:   6312 / 14632 loss=4.829, nll_loss=3.471, ppl=11.09, wps=15014.7, ups=4.37, wpb=3438.1, bsz=117.2, num_updates=138000, lr=8.51257e-05, gnorm=1.346, train_wall=23, wall=0
2024-07-15 20:22:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 20:22:44 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.831 | nll_loss 3.352 | ppl 10.21 | wps 42152.1 | wpb 2469 | bsz 83 | num_updates 138000 | best_loss 12.212
2024-07-15 20:22:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 20:22:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_10_138000.pt (epoch 10 @ 138000 updates, score 4.831) (writing took 4.402110746130347 seconds)
2024-07-15 20:23:12 | INFO | train_inner | epoch 010:   6412 / 14632 loss=4.805, nll_loss=3.444, ppl=10.88, wps=11654, ups=3.33, wpb=3504.8, bsz=129.7, num_updates=138100, lr=8.50948e-05, gnorm=1.382, train_wall=23, wall=0
2024-07-15 20:23:35 | INFO | train_inner | epoch 010:   6512 / 14632 loss=4.881, nll_loss=3.53, ppl=11.55, wps=15032, ups=4.36, wpb=3448.5, bsz=117.1, num_updates=138200, lr=8.5064e-05, gnorm=1.423, train_wall=23, wall=0
2024-07-15 20:23:58 | INFO | train_inner | epoch 010:   6612 / 14632 loss=4.87, nll_loss=3.517, ppl=11.45, wps=15108.5, ups=4.37, wpb=3454.3, bsz=111, num_updates=138300, lr=8.50333e-05, gnorm=1.38, train_wall=23, wall=0
2024-07-15 20:24:21 | INFO | train_inner | epoch 010:   6712 / 14632 loss=4.909, nll_loss=3.563, ppl=11.82, wps=15000.9, ups=4.38, wpb=3425.7, bsz=95.2, num_updates=138400, lr=8.50026e-05, gnorm=1.364, train_wall=23, wall=0
2024-07-15 20:24:44 | INFO | train_inner | epoch 010:   6812 / 14632 loss=4.91, nll_loss=3.563, ppl=11.82, wps=15082.2, ups=4.36, wpb=3459.8, bsz=116.8, num_updates=138500, lr=8.49719e-05, gnorm=1.475, train_wall=23, wall=0
2024-07-15 20:25:07 | INFO | train_inner | epoch 010:   6912 / 14632 loss=4.911, nll_loss=3.564, ppl=11.83, wps=15305.3, ups=4.37, wpb=3502.3, bsz=108.4, num_updates=138600, lr=8.49412e-05, gnorm=1.368, train_wall=23, wall=0
2024-07-15 20:25:29 | INFO | train_inner | epoch 010:   7012 / 14632 loss=4.927, nll_loss=3.583, ppl=11.98, wps=15136.2, ups=4.43, wpb=3415.6, bsz=119.2, num_updates=138700, lr=8.49106e-05, gnorm=1.455, train_wall=22, wall=0
2024-07-15 20:25:52 | INFO | train_inner | epoch 010:   7112 / 14632 loss=4.777, nll_loss=3.411, ppl=10.63, wps=15495.7, ups=4.37, wpb=3544.6, bsz=128.6, num_updates=138800, lr=8.488e-05, gnorm=1.343, train_wall=23, wall=0
2024-07-15 20:26:15 | INFO | train_inner | epoch 010:   7212 / 14632 loss=4.719, nll_loss=3.345, ppl=10.16, wps=15408.3, ups=4.34, wpb=3553.2, bsz=141.1, num_updates=138900, lr=8.48494e-05, gnorm=1.336, train_wall=23, wall=0
2024-07-15 20:26:38 | INFO | train_inner | epoch 010:   7312 / 14632 loss=4.847, nll_loss=3.492, ppl=11.25, wps=15066.1, ups=4.4, wpb=3421.9, bsz=123.5, num_updates=139000, lr=8.48189e-05, gnorm=1.411, train_wall=23, wall=0
2024-07-15 20:26:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 20:26:40 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.81 | nll_loss 3.328 | ppl 10.04 | wps 41950.9 | wpb 2469 | bsz 83 | num_updates 139000 | best_loss 12.212
2024-07-15 20:26:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 20:26:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_10_139000.pt (epoch 10 @ 139000 updates, score 4.81) (writing took 4.6531269839033484 seconds)
2024-07-15 20:27:08 | INFO | train_inner | epoch 010:   7412 / 14632 loss=4.889, nll_loss=3.54, ppl=11.63, wps=11594, ups=3.32, wpb=3489.1, bsz=120.4, num_updates=139100, lr=8.47884e-05, gnorm=1.391, train_wall=23, wall=0
2024-07-15 20:27:31 | INFO | train_inner | epoch 010:   7512 / 14632 loss=4.812, nll_loss=3.451, ppl=10.94, wps=15418.8, ups=4.34, wpb=3556.4, bsz=126.5, num_updates=139200, lr=8.47579e-05, gnorm=1.375, train_wall=23, wall=0
2024-07-15 20:27:54 | INFO | train_inner | epoch 010:   7612 / 14632 loss=4.916, nll_loss=3.57, ppl=11.87, wps=15227.7, ups=4.36, wpb=3491.4, bsz=104.2, num_updates=139300, lr=8.47275e-05, gnorm=1.369, train_wall=23, wall=0
2024-07-15 20:28:17 | INFO | train_inner | epoch 010:   7712 / 14632 loss=4.839, nll_loss=3.481, ppl=11.17, wps=15321.8, ups=4.35, wpb=3523.4, bsz=118.9, num_updates=139400, lr=8.46971e-05, gnorm=1.349, train_wall=23, wall=0
2024-07-15 20:28:40 | INFO | train_inner | epoch 010:   7812 / 14632 loss=4.859, nll_loss=3.505, ppl=11.35, wps=15247.6, ups=4.37, wpb=3486.8, bsz=116, num_updates=139500, lr=8.46668e-05, gnorm=1.379, train_wall=23, wall=0
2024-07-15 20:29:03 | INFO | train_inner | epoch 010:   7912 / 14632 loss=4.775, nll_loss=3.408, ppl=10.61, wps=15202.7, ups=4.36, wpb=3485.1, bsz=125.1, num_updates=139600, lr=8.46364e-05, gnorm=1.429, train_wall=23, wall=0
2024-07-15 20:29:26 | INFO | train_inner | epoch 010:   8012 / 14632 loss=4.759, nll_loss=3.392, ppl=10.5, wps=15050.5, ups=4.35, wpb=3463.1, bsz=123, num_updates=139700, lr=8.46061e-05, gnorm=1.359, train_wall=23, wall=0
2024-07-15 20:29:49 | INFO | train_inner | epoch 010:   8112 / 14632 loss=4.953, nll_loss=3.612, ppl=12.23, wps=15290.3, ups=4.36, wpb=3506.5, bsz=100.7, num_updates=139800, lr=8.45759e-05, gnorm=1.353, train_wall=23, wall=0
2024-07-15 20:30:12 | INFO | train_inner | epoch 010:   8212 / 14632 loss=4.764, nll_loss=3.396, ppl=10.52, wps=15102.8, ups=4.29, wpb=3524.2, bsz=125.7, num_updates=139900, lr=8.45456e-05, gnorm=1.35, train_wall=23, wall=0
2024-07-15 20:30:35 | INFO | train_inner | epoch 010:   8312 / 14632 loss=4.862, nll_loss=3.508, ppl=11.38, wps=15065.4, ups=4.38, wpb=3436.5, bsz=111.6, num_updates=140000, lr=8.45154e-05, gnorm=1.365, train_wall=23, wall=0
2024-07-15 20:30:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 20:30:37 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.8 | nll_loss 3.315 | ppl 9.96 | wps 42253.1 | wpb 2469 | bsz 83 | num_updates 140000 | best_loss 12.212
2024-07-15 20:30:37 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 20:30:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_10_140000.pt (epoch 10 @ 140000 updates, score 4.8) (writing took 4.6284278919920325 seconds)
2024-07-15 20:31:04 | INFO | train_inner | epoch 010:   8412 / 14632 loss=4.892, nll_loss=3.543, ppl=11.66, wps=11573.8, ups=3.38, wpb=3426.4, bsz=109.4, num_updates=140100, lr=8.44853e-05, gnorm=1.398, train_wall=22, wall=0
2024-07-15 20:31:27 | INFO | train_inner | epoch 010:   8512 / 14632 loss=4.878, nll_loss=3.527, ppl=11.53, wps=15533.5, ups=4.35, wpb=3574.2, bsz=105.6, num_updates=140200, lr=8.44551e-05, gnorm=1.361, train_wall=23, wall=0
2024-07-15 20:31:51 | INFO | train_inner | epoch 010:   8612 / 14632 loss=4.75, nll_loss=3.38, ppl=10.41, wps=15248.9, ups=4.32, wpb=3533.8, bsz=124.6, num_updates=140300, lr=8.4425e-05, gnorm=1.383, train_wall=23, wall=0
2024-07-15 20:32:14 | INFO | train_inner | epoch 010:   8712 / 14632 loss=4.843, nll_loss=3.486, ppl=11.2, wps=15212.1, ups=4.34, wpb=3503.3, bsz=106, num_updates=140400, lr=8.43949e-05, gnorm=1.399, train_wall=23, wall=0
2024-07-15 20:32:37 | INFO | train_inner | epoch 010:   8812 / 14632 loss=4.806, nll_loss=3.445, ppl=10.89, wps=15291.1, ups=4.36, wpb=3510.7, bsz=127.2, num_updates=140500, lr=8.43649e-05, gnorm=1.349, train_wall=23, wall=0
2024-07-15 20:32:59 | INFO | train_inner | epoch 010:   8912 / 14632 loss=4.715, nll_loss=3.342, ppl=10.14, wps=15198.1, ups=4.35, wpb=3494.2, bsz=135.9, num_updates=140600, lr=8.43349e-05, gnorm=1.346, train_wall=23, wall=0
2024-07-15 20:33:22 | INFO | train_inner | epoch 010:   9012 / 14632 loss=4.814, nll_loss=3.454, ppl=10.96, wps=15159, ups=4.37, wpb=3467.9, bsz=122.9, num_updates=140700, lr=8.43049e-05, gnorm=1.356, train_wall=23, wall=0
2024-07-15 20:33:45 | INFO | train_inner | epoch 010:   9112 / 14632 loss=4.775, nll_loss=3.408, ppl=10.62, wps=15367.7, ups=4.38, wpb=3510.5, bsz=117.6, num_updates=140800, lr=8.4275e-05, gnorm=1.364, train_wall=23, wall=0
2024-07-15 20:34:08 | INFO | train_inner | epoch 010:   9212 / 14632 loss=4.778, nll_loss=3.413, ppl=10.65, wps=14980.8, ups=4.4, wpb=3408.4, bsz=114.2, num_updates=140900, lr=8.42451e-05, gnorm=1.369, train_wall=23, wall=0
2024-07-15 20:34:31 | INFO | train_inner | epoch 010:   9312 / 14632 loss=4.827, nll_loss=3.469, ppl=11.07, wps=15281.5, ups=4.4, wpb=3474.2, bsz=123.4, num_updates=141000, lr=8.42152e-05, gnorm=1.384, train_wall=23, wall=0
2024-07-15 20:34:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 20:34:33 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.774 | nll_loss 3.288 | ppl 9.77 | wps 42209.8 | wpb 2469 | bsz 83 | num_updates 141000 | best_loss 12.212
2024-07-15 20:34:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 20:34:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_10_141000.pt (epoch 10 @ 141000 updates, score 4.774) (writing took 4.383500867523253 seconds)
2024-07-15 20:35:01 | INFO | train_inner | epoch 010:   9412 / 14632 loss=4.784, nll_loss=3.42, ppl=10.7, wps=11852.2, ups=3.34, wpb=3549.7, bsz=111.5, num_updates=141100, lr=8.41853e-05, gnorm=1.331, train_wall=23, wall=0
2024-07-15 20:35:24 | INFO | train_inner | epoch 010:   9512 / 14632 loss=4.84, nll_loss=3.484, ppl=11.19, wps=15315.1, ups=4.35, wpb=3519.6, bsz=121.7, num_updates=141200, lr=8.41555e-05, gnorm=1.4, train_wall=23, wall=0
2024-07-15 20:35:47 | INFO | train_inner | epoch 010:   9612 / 14632 loss=4.755, nll_loss=3.387, ppl=10.46, wps=14977.8, ups=4.33, wpb=3458.2, bsz=142.7, num_updates=141300, lr=8.41257e-05, gnorm=1.411, train_wall=23, wall=0
2024-07-15 20:36:10 | INFO | train_inner | epoch 010:   9712 / 14632 loss=4.757, nll_loss=3.388, ppl=10.47, wps=15396.2, ups=4.28, wpb=3593.4, bsz=133.9, num_updates=141400, lr=8.4096e-05, gnorm=1.364, train_wall=23, wall=0
2024-07-15 20:36:33 | INFO | train_inner | epoch 010:   9812 / 14632 loss=4.844, nll_loss=3.489, ppl=11.23, wps=14990.2, ups=4.45, wpb=3369.9, bsz=114.2, num_updates=141500, lr=8.40663e-05, gnorm=1.434, train_wall=22, wall=0
2024-07-15 20:36:55 | INFO | train_inner | epoch 010:   9912 / 14632 loss=4.919, nll_loss=3.574, ppl=11.91, wps=15491.4, ups=4.41, wpb=3512.4, bsz=101.4, num_updates=141600, lr=8.40366e-05, gnorm=1.361, train_wall=23, wall=0
2024-07-15 20:37:18 | INFO | train_inner | epoch 010:  10012 / 14632 loss=4.836, nll_loss=3.479, ppl=11.15, wps=14951.6, ups=4.4, wpb=3399.9, bsz=120.9, num_updates=141700, lr=8.40069e-05, gnorm=1.398, train_wall=23, wall=0
2024-07-15 20:37:41 | INFO | train_inner | epoch 010:  10112 / 14632 loss=4.731, nll_loss=3.36, ppl=10.26, wps=15108.1, ups=4.3, wpb=3510.9, bsz=121.5, num_updates=141800, lr=8.39773e-05, gnorm=1.35, train_wall=23, wall=0
2024-07-15 20:38:04 | INFO | train_inner | epoch 010:  10212 / 14632 loss=4.852, nll_loss=3.498, ppl=11.3, wps=14993.6, ups=4.39, wpb=3414.6, bsz=124.9, num_updates=141900, lr=8.39477e-05, gnorm=1.446, train_wall=23, wall=0
2024-07-15 20:38:27 | INFO | train_inner | epoch 010:  10312 / 14632 loss=4.783, nll_loss=3.418, ppl=10.69, wps=15144.9, ups=4.37, wpb=3467.2, bsz=105.3, num_updates=142000, lr=8.39181e-05, gnorm=1.365, train_wall=23, wall=0
2024-07-15 20:38:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 20:38:29 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.756 | nll_loss 3.265 | ppl 9.61 | wps 41645.5 | wpb 2469 | bsz 83 | num_updates 142000 | best_loss 12.212
2024-07-15 20:38:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 20:38:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_10_142000.pt (epoch 10 @ 142000 updates, score 4.756) (writing took 4.496809903532267 seconds)
2024-07-15 20:38:57 | INFO | train_inner | epoch 010:  10412 / 14632 loss=4.861, nll_loss=3.507, ppl=11.37, wps=11620, ups=3.34, wpb=3483.7, bsz=103.6, num_updates=142100, lr=8.38886e-05, gnorm=1.374, train_wall=23, wall=0
2024-07-15 20:39:20 | INFO | train_inner | epoch 010:  10512 / 14632 loss=4.837, nll_loss=3.481, ppl=11.17, wps=15145.4, ups=4.38, wpb=3455.9, bsz=114.4, num_updates=142200, lr=8.38591e-05, gnorm=1.366, train_wall=23, wall=0
2024-07-15 20:39:43 | INFO | train_inner | epoch 010:  10612 / 14632 loss=4.837, nll_loss=3.481, ppl=11.16, wps=15375.6, ups=4.34, wpb=3542.1, bsz=111, num_updates=142300, lr=8.38296e-05, gnorm=1.366, train_wall=23, wall=0
2024-07-15 20:40:06 | INFO | train_inner | epoch 010:  10712 / 14632 loss=4.788, nll_loss=3.424, ppl=10.74, wps=14987.7, ups=4.38, wpb=3424, bsz=111.6, num_updates=142400, lr=8.38002e-05, gnorm=1.386, train_wall=23, wall=0
2024-07-15 20:40:28 | INFO | train_inner | epoch 010:  10812 / 14632 loss=4.774, nll_loss=3.409, ppl=10.62, wps=15368, ups=4.36, wpb=3521, bsz=119.5, num_updates=142500, lr=8.37708e-05, gnorm=1.36, train_wall=23, wall=0
2024-07-15 20:40:51 | INFO | train_inner | epoch 010:  10912 / 14632 loss=4.718, nll_loss=3.345, ppl=10.16, wps=14988, ups=4.36, wpb=3435.5, bsz=126.4, num_updates=142600, lr=8.37414e-05, gnorm=1.365, train_wall=23, wall=0
2024-07-15 20:41:15 | INFO | train_inner | epoch 010:  11012 / 14632 loss=4.791, nll_loss=3.429, ppl=10.77, wps=15174.1, ups=4.29, wpb=3535.5, bsz=107.6, num_updates=142700, lr=8.37121e-05, gnorm=1.361, train_wall=23, wall=0
2024-07-15 20:41:38 | INFO | train_inner | epoch 010:  11112 / 14632 loss=4.847, nll_loss=3.492, ppl=11.25, wps=15085.6, ups=4.36, wpb=3458.1, bsz=119.5, num_updates=142800, lr=8.36827e-05, gnorm=1.46, train_wall=23, wall=0
2024-07-15 20:42:00 | INFO | train_inner | epoch 010:  11212 / 14632 loss=4.909, nll_loss=3.564, ppl=11.82, wps=15139.9, ups=4.4, wpb=3440.7, bsz=100.8, num_updates=142900, lr=8.36535e-05, gnorm=1.407, train_wall=23, wall=0
2024-07-15 20:42:23 | INFO | train_inner | epoch 010:  11312 / 14632 loss=4.853, nll_loss=3.499, ppl=11.3, wps=15376.6, ups=4.33, wpb=3553.9, bsz=107.3, num_updates=143000, lr=8.36242e-05, gnorm=1.351, train_wall=23, wall=0
2024-07-15 20:42:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 20:42:26 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.752 | nll_loss 3.258 | ppl 9.57 | wps 42048 | wpb 2469 | bsz 83 | num_updates 143000 | best_loss 12.212
2024-07-15 20:42:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 20:42:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_10_143000.pt (epoch 10 @ 143000 updates, score 4.752) (writing took 4.415622810833156 seconds)
2024-07-15 20:42:53 | INFO | train_inner | epoch 010:  11412 / 14632 loss=4.775, nll_loss=3.409, ppl=10.63, wps=11869, ups=3.36, wpb=3534.3, bsz=120.1, num_updates=143100, lr=8.3595e-05, gnorm=1.332, train_wall=23, wall=0
2024-07-15 20:43:16 | INFO | train_inner | epoch 010:  11512 / 14632 loss=4.859, nll_loss=3.505, ppl=11.35, wps=15129.1, ups=4.33, wpb=3491.6, bsz=109, num_updates=143200, lr=8.35658e-05, gnorm=1.383, train_wall=23, wall=0
2024-07-15 20:43:39 | INFO | train_inner | epoch 010:  11612 / 14632 loss=4.799, nll_loss=3.437, ppl=10.83, wps=15262.2, ups=4.33, wpb=3522.8, bsz=117.3, num_updates=143300, lr=8.35366e-05, gnorm=1.353, train_wall=23, wall=0
2024-07-15 20:44:02 | INFO | train_inner | epoch 010:  11712 / 14632 loss=4.713, nll_loss=3.339, ppl=10.12, wps=15248.1, ups=4.33, wpb=3517.8, bsz=126.2, num_updates=143400, lr=8.35075e-05, gnorm=1.325, train_wall=23, wall=0
2024-07-15 20:44:25 | INFO | train_inner | epoch 010:  11812 / 14632 loss=4.747, nll_loss=3.378, ppl=10.39, wps=15097.6, ups=4.34, wpb=3475.8, bsz=116.1, num_updates=143500, lr=8.34784e-05, gnorm=1.344, train_wall=23, wall=0
2024-07-15 20:44:48 | INFO | train_inner | epoch 010:  11912 / 14632 loss=4.832, nll_loss=3.476, ppl=11.13, wps=15137.7, ups=4.38, wpb=3459.3, bsz=105.3, num_updates=143600, lr=8.34493e-05, gnorm=1.369, train_wall=23, wall=0
2024-07-15 20:45:11 | INFO | train_inner | epoch 010:  12012 / 14632 loss=4.862, nll_loss=3.509, ppl=11.39, wps=15194.1, ups=4.41, wpb=3448.2, bsz=103.6, num_updates=143700, lr=8.34203e-05, gnorm=1.398, train_wall=23, wall=0
2024-07-15 20:45:34 | INFO | train_inner | epoch 010:  12112 / 14632 loss=4.733, nll_loss=3.363, ppl=10.29, wps=15283.1, ups=4.4, wpb=3474.7, bsz=130.9, num_updates=143800, lr=8.33913e-05, gnorm=1.366, train_wall=23, wall=0
2024-07-15 20:45:57 | INFO | train_inner | epoch 010:  12212 / 14632 loss=4.737, nll_loss=3.366, ppl=10.31, wps=15414.9, ups=4.37, wpb=3530.3, bsz=127.2, num_updates=143900, lr=8.33623e-05, gnorm=1.337, train_wall=23, wall=0
2024-07-15 20:46:20 | INFO | train_inner | epoch 010:  12312 / 14632 loss=4.854, nll_loss=3.501, ppl=11.32, wps=15117.8, ups=4.36, wpb=3463.7, bsz=112.8, num_updates=144000, lr=8.33333e-05, gnorm=1.418, train_wall=23, wall=0
2024-07-15 20:46:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 20:46:22 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.764 | nll_loss 3.274 | ppl 9.67 | wps 42015.6 | wpb 2469 | bsz 83 | num_updates 144000 | best_loss 12.212
2024-07-15 20:46:22 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 20:46:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_10_144000.pt (epoch 10 @ 144000 updates, score 4.764) (writing took 4.3932569324970245 seconds)
2024-07-15 20:46:49 | INFO | train_inner | epoch 010:  12412 / 14632 loss=4.749, nll_loss=3.38, ppl=10.41, wps=11651.3, ups=3.36, wpb=3469.5, bsz=109.5, num_updates=144100, lr=8.33044e-05, gnorm=1.363, train_wall=23, wall=0
2024-07-15 20:47:12 | INFO | train_inner | epoch 010:  12512 / 14632 loss=4.8, nll_loss=3.439, ppl=10.84, wps=15555.6, ups=4.35, wpb=3572.7, bsz=118.5, num_updates=144200, lr=8.32755e-05, gnorm=1.352, train_wall=23, wall=0
2024-07-15 20:47:35 | INFO | train_inner | epoch 010:  12612 / 14632 loss=4.615, nll_loss=3.229, ppl=9.37, wps=15253.3, ups=4.33, wpb=3523.7, bsz=137.5, num_updates=144300, lr=8.32467e-05, gnorm=1.342, train_wall=23, wall=0
2024-07-15 20:47:58 | INFO | train_inner | epoch 010:  12712 / 14632 loss=4.779, nll_loss=3.415, ppl=10.66, wps=14968.2, ups=4.36, wpb=3431.8, bsz=110.3, num_updates=144400, lr=8.32178e-05, gnorm=1.373, train_wall=23, wall=0
2024-07-15 20:48:21 | INFO | train_inner | epoch 010:  12812 / 14632 loss=4.824, nll_loss=3.466, ppl=11.05, wps=15067.3, ups=4.35, wpb=3460.5, bsz=103.3, num_updates=144500, lr=8.3189e-05, gnorm=1.373, train_wall=23, wall=0
2024-07-15 20:48:45 | INFO | train_inner | epoch 010:  12912 / 14632 loss=4.785, nll_loss=3.421, ppl=10.71, wps=15179, ups=4.3, wpb=3533.9, bsz=114, num_updates=144600, lr=8.31603e-05, gnorm=1.377, train_wall=23, wall=0
2024-07-15 20:49:08 | INFO | train_inner | epoch 010:  13012 / 14632 loss=4.716, nll_loss=3.343, ppl=10.15, wps=15068.9, ups=4.33, wpb=3479, bsz=108.4, num_updates=144700, lr=8.31315e-05, gnorm=1.352, train_wall=23, wall=0
2024-07-15 20:49:31 | INFO | train_inner | epoch 010:  13112 / 14632 loss=4.832, nll_loss=3.474, ppl=11.12, wps=15176.9, ups=4.38, wpb=3467.2, bsz=103.6, num_updates=144800, lr=8.31028e-05, gnorm=1.407, train_wall=23, wall=0
2024-07-15 20:49:53 | INFO | train_inner | epoch 010:  13212 / 14632 loss=4.68, nll_loss=3.301, ppl=9.86, wps=15186, ups=4.36, wpb=3480.8, bsz=134.8, num_updates=144900, lr=8.30741e-05, gnorm=1.365, train_wall=23, wall=0
2024-07-15 20:50:17 | INFO | train_inner | epoch 010:  13312 / 14632 loss=4.657, nll_loss=3.277, ppl=9.69, wps=15004.3, ups=4.34, wpb=3456.4, bsz=136.3, num_updates=145000, lr=8.30455e-05, gnorm=1.359, train_wall=23, wall=0
2024-07-15 20:50:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 20:50:19 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.728 | nll_loss 3.229 | ppl 9.38 | wps 42095.3 | wpb 2469 | bsz 83 | num_updates 145000 | best_loss 12.212
2024-07-15 20:50:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 20:50:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_10_145000.pt (epoch 10 @ 145000 updates, score 4.728) (writing took 4.424770774319768 seconds)
2024-07-15 20:50:47 | INFO | train_inner | epoch 010:  13412 / 14632 loss=4.714, nll_loss=3.34, ppl=10.13, wps=11788, ups=3.33, wpb=3540.9, bsz=120.5, num_updates=145100, lr=8.30169e-05, gnorm=1.318, train_wall=23, wall=0
2024-07-15 20:51:10 | INFO | train_inner | epoch 010:  13512 / 14632 loss=4.692, nll_loss=3.316, ppl=9.96, wps=15264, ups=4.33, wpb=3527.3, bsz=133.4, num_updates=145200, lr=8.29883e-05, gnorm=1.383, train_wall=23, wall=0
2024-07-15 20:51:33 | INFO | train_inner | epoch 010:  13612 / 14632 loss=4.751, nll_loss=3.382, ppl=10.43, wps=15337.1, ups=4.38, wpb=3504.3, bsz=117.3, num_updates=145300, lr=8.29597e-05, gnorm=1.384, train_wall=23, wall=0
2024-07-15 20:51:56 | INFO | train_inner | epoch 010:  13712 / 14632 loss=4.754, nll_loss=3.387, ppl=10.46, wps=15363.3, ups=4.33, wpb=3550.2, bsz=119.8, num_updates=145400, lr=8.29312e-05, gnorm=1.367, train_wall=23, wall=0
2024-07-15 20:52:19 | INFO | train_inner | epoch 010:  13812 / 14632 loss=4.72, nll_loss=3.347, ppl=10.18, wps=15307.1, ups=4.37, wpb=3504.4, bsz=121, num_updates=145500, lr=8.29027e-05, gnorm=1.375, train_wall=23, wall=0
2024-07-15 20:52:42 | INFO | train_inner | epoch 010:  13912 / 14632 loss=4.79, nll_loss=3.427, ppl=10.76, wps=15423.3, ups=4.34, wpb=3556.1, bsz=116.2, num_updates=145600, lr=8.28742e-05, gnorm=1.35, train_wall=23, wall=0
2024-07-15 20:53:04 | INFO | train_inner | epoch 010:  14012 / 14632 loss=4.706, nll_loss=3.333, ppl=10.08, wps=15218.1, ups=4.37, wpb=3481.1, bsz=138.5, num_updates=145700, lr=8.28457e-05, gnorm=1.349, train_wall=23, wall=0
2024-07-15 20:53:27 | INFO | train_inner | epoch 010:  14112 / 14632 loss=4.738, nll_loss=3.369, ppl=10.33, wps=15253.7, ups=4.4, wpb=3465.6, bsz=132.9, num_updates=145800, lr=8.28173e-05, gnorm=1.36, train_wall=23, wall=0
2024-07-15 20:53:50 | INFO | train_inner | epoch 010:  14212 / 14632 loss=4.744, nll_loss=3.375, ppl=10.37, wps=15283.7, ups=4.35, wpb=3515.7, bsz=118, num_updates=145900, lr=8.27889e-05, gnorm=1.357, train_wall=23, wall=0
2024-07-15 20:54:13 | INFO | train_inner | epoch 010:  14312 / 14632 loss=4.864, nll_loss=3.513, ppl=11.42, wps=15160.5, ups=4.38, wpb=3458.4, bsz=112.5, num_updates=146000, lr=8.27606e-05, gnorm=1.4, train_wall=23, wall=0
2024-07-15 20:54:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 20:54:15 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.701 | nll_loss 3.203 | ppl 9.21 | wps 41815 | wpb 2469 | bsz 83 | num_updates 146000 | best_loss 12.212
2024-07-15 20:54:15 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 20:54:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_10_146000.pt (epoch 10 @ 146000 updates, score 4.701) (writing took 4.62529818341136 seconds)
2024-07-15 20:54:43 | INFO | train_inner | epoch 010:  14412 / 14632 loss=4.778, nll_loss=3.414, ppl=10.66, wps=11552.8, ups=3.37, wpb=3432.5, bsz=116, num_updates=146100, lr=8.27323e-05, gnorm=1.475, train_wall=22, wall=0
2024-07-15 20:55:06 | INFO | train_inner | epoch 010:  14512 / 14632 loss=4.732, nll_loss=3.363, ppl=10.29, wps=15220.5, ups=4.38, wpb=3472.7, bsz=119.3, num_updates=146200, lr=8.2704e-05, gnorm=1.405, train_wall=23, wall=0
2024-07-15 20:55:28 | INFO | train_inner | epoch 010:  14612 / 14632 loss=4.833, nll_loss=3.477, ppl=11.14, wps=15128.4, ups=4.43, wpb=3412.4, bsz=107, num_updates=146300, lr=8.26757e-05, gnorm=1.391, train_wall=22, wall=0
2024-07-15 20:55:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 20:55:35 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.702 | nll_loss 3.204 | ppl 9.22 | wps 42183.6 | wpb 2469 | bsz 83 | num_updates 146320 | best_loss 12.212
2024-07-15 20:55:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 20:55:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 10 @ 146320 updates, score 4.702) (writing took 3.8888984452933073 seconds)
2024-07-15 20:55:39 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2024-07-15 20:55:39 | INFO | train | epoch 010 | loss 4.845 | nll_loss 3.489 | ppl 11.23 | wps 14665.6 | ups 4.21 | wpb 3483.6 | bsz 118.4 | num_updates 146320 | lr 8.267e-05 | gnorm 1.385 | train_wall 3329 | wall 0
2024-07-15 20:55:39 | INFO | fairseq.trainer | begin training epoch 11
2024-07-15 20:55:57 | INFO | train_inner | epoch 011:     80 / 14632 loss=4.807, nll_loss=3.447, ppl=10.91, wps=11849.5, ups=3.43, wpb=3450, bsz=115, num_updates=146400, lr=8.26475e-05, gnorm=1.428, train_wall=22, wall=0
2024-07-15 20:56:20 | INFO | train_inner | epoch 011:    180 / 14632 loss=4.712, nll_loss=3.339, ppl=10.12, wps=15224.8, ups=4.33, wpb=3517.1, bsz=117.2, num_updates=146500, lr=8.26192e-05, gnorm=1.338, train_wall=23, wall=0
2024-07-15 20:56:43 | INFO | train_inner | epoch 011:    280 / 14632 loss=4.751, nll_loss=3.382, ppl=10.43, wps=15462.7, ups=4.37, wpb=3540.3, bsz=107.3, num_updates=146600, lr=8.25911e-05, gnorm=1.348, train_wall=23, wall=0
2024-07-15 20:57:06 | INFO | train_inner | epoch 011:    380 / 14632 loss=4.736, nll_loss=3.366, ppl=10.31, wps=15082.2, ups=4.35, wpb=3464.5, bsz=108.5, num_updates=146700, lr=8.25629e-05, gnorm=1.407, train_wall=23, wall=0
2024-07-15 20:57:29 | INFO | train_inner | epoch 011:    480 / 14632 loss=4.74, nll_loss=3.37, ppl=10.34, wps=15338, ups=4.4, wpb=3487.9, bsz=116.4, num_updates=146800, lr=8.25348e-05, gnorm=1.376, train_wall=23, wall=0
2024-07-15 20:57:52 | INFO | train_inner | epoch 011:    580 / 14632 loss=4.688, nll_loss=3.313, ppl=9.94, wps=15189.3, ups=4.33, wpb=3505, bsz=118.6, num_updates=146900, lr=8.25067e-05, gnorm=1.346, train_wall=23, wall=0
2024-07-15 20:58:15 | INFO | train_inner | epoch 011:    680 / 14632 loss=4.735, nll_loss=3.364, ppl=10.3, wps=15122.2, ups=4.44, wpb=3408.5, bsz=124.6, num_updates=147000, lr=8.24786e-05, gnorm=1.407, train_wall=22, wall=0
2024-07-15 20:58:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 20:58:17 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.692 | nll_loss 3.188 | ppl 9.11 | wps 42115.2 | wpb 2469 | bsz 83 | num_updates 147000 | best_loss 12.212
2024-07-15 20:58:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 20:58:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_11_147000.pt (epoch 11 @ 147000 updates, score 4.692) (writing took 4.645280193537474 seconds)
2024-07-15 20:58:45 | INFO | train_inner | epoch 011:    780 / 14632 loss=4.699, nll_loss=3.324, ppl=10.02, wps=11508.8, ups=3.32, wpb=3466.2, bsz=114.9, num_updates=147100, lr=8.24506e-05, gnorm=1.352, train_wall=23, wall=0
2024-07-15 20:59:07 | INFO | train_inner | epoch 011:    880 / 14632 loss=4.693, nll_loss=3.318, ppl=9.97, wps=14986.4, ups=4.4, wpb=3408.2, bsz=108.8, num_updates=147200, lr=8.24226e-05, gnorm=1.35, train_wall=23, wall=0
2024-07-15 20:59:30 | INFO | train_inner | epoch 011:    980 / 14632 loss=4.657, nll_loss=3.277, ppl=9.7, wps=15277.8, ups=4.39, wpb=3480.1, bsz=126, num_updates=147300, lr=8.23946e-05, gnorm=1.351, train_wall=23, wall=0
2024-07-15 20:59:53 | INFO | train_inner | epoch 011:   1080 / 14632 loss=4.723, nll_loss=3.351, ppl=10.2, wps=15408.9, ups=4.35, wpb=3540.7, bsz=126.6, num_updates=147400, lr=8.23666e-05, gnorm=1.375, train_wall=23, wall=0
2024-07-15 21:00:16 | INFO | train_inner | epoch 011:   1180 / 14632 loss=4.725, nll_loss=3.354, ppl=10.22, wps=15386, ups=4.34, wpb=3546.2, bsz=127.4, num_updates=147500, lr=8.23387e-05, gnorm=1.422, train_wall=23, wall=0
2024-07-15 21:00:39 | INFO | train_inner | epoch 011:   1280 / 14632 loss=4.707, nll_loss=3.332, ppl=10.07, wps=15312.1, ups=4.37, wpb=3506.5, bsz=127.3, num_updates=147600, lr=8.23108e-05, gnorm=1.364, train_wall=23, wall=0
2024-07-15 21:01:02 | INFO | train_inner | epoch 011:   1380 / 14632 loss=4.628, nll_loss=3.243, ppl=9.46, wps=15316.1, ups=4.36, wpb=3513.8, bsz=131, num_updates=147700, lr=8.22829e-05, gnorm=1.328, train_wall=23, wall=0
2024-07-15 21:01:25 | INFO | train_inner | epoch 011:   1480 / 14632 loss=4.697, nll_loss=3.321, ppl=9.99, wps=15095, ups=4.36, wpb=3462.5, bsz=114.3, num_updates=147800, lr=8.22551e-05, gnorm=1.373, train_wall=23, wall=0
2024-07-15 21:01:48 | INFO | train_inner | epoch 011:   1580 / 14632 loss=4.71, nll_loss=3.337, ppl=10.11, wps=15268.9, ups=4.38, wpb=3488.7, bsz=119.7, num_updates=147900, lr=8.22273e-05, gnorm=1.529, train_wall=23, wall=0
2024-07-15 21:02:11 | INFO | train_inner | epoch 011:   1680 / 14632 loss=4.677, nll_loss=3.298, ppl=9.84, wps=15281.9, ups=4.34, wpb=3524.1, bsz=114.6, num_updates=148000, lr=8.21995e-05, gnorm=1.366, train_wall=23, wall=0
2024-07-15 21:02:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 21:02:13 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.672 | nll_loss 3.164 | ppl 8.96 | wps 42347.3 | wpb 2469 | bsz 83 | num_updates 148000 | best_loss 12.212
2024-07-15 21:02:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 21:02:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_11_148000.pt (epoch 11 @ 148000 updates, score 4.672) (writing took 4.487432105466723 seconds)
2024-07-15 21:02:41 | INFO | train_inner | epoch 011:   1780 / 14632 loss=4.612, nll_loss=3.224, ppl=9.34, wps=11859, ups=3.35, wpb=3539.6, bsz=122.3, num_updates=148100, lr=8.21717e-05, gnorm=1.311, train_wall=23, wall=0
2024-07-15 21:03:04 | INFO | train_inner | epoch 011:   1880 / 14632 loss=4.618, nll_loss=3.231, ppl=9.39, wps=15305, ups=4.29, wpb=3567.4, bsz=121.8, num_updates=148200, lr=8.2144e-05, gnorm=1.308, train_wall=23, wall=0
2024-07-15 21:03:27 | INFO | train_inner | epoch 011:   1980 / 14632 loss=4.667, nll_loss=3.289, ppl=9.77, wps=15190.9, ups=4.35, wpb=3494.3, bsz=118.8, num_updates=148300, lr=8.21163e-05, gnorm=1.351, train_wall=23, wall=0
2024-07-15 21:03:50 | INFO | train_inner | epoch 011:   2080 / 14632 loss=4.603, nll_loss=3.215, ppl=9.28, wps=15243.3, ups=4.3, wpb=3548.9, bsz=123, num_updates=148400, lr=8.20886e-05, gnorm=1.341, train_wall=23, wall=0
2024-07-15 21:04:13 | INFO | train_inner | epoch 011:   2180 / 14632 loss=4.751, nll_loss=3.385, ppl=10.45, wps=14995.7, ups=4.36, wpb=3441.8, bsz=117.4, num_updates=148500, lr=8.2061e-05, gnorm=1.404, train_wall=23, wall=0
2024-07-15 21:04:36 | INFO | train_inner | epoch 011:   2280 / 14632 loss=4.786, nll_loss=3.423, ppl=10.73, wps=15148.9, ups=4.38, wpb=3459.9, bsz=111.5, num_updates=148600, lr=8.20334e-05, gnorm=1.374, train_wall=23, wall=0
2024-07-15 21:04:59 | INFO | train_inner | epoch 011:   2380 / 14632 loss=4.673, nll_loss=3.294, ppl=9.81, wps=15150.1, ups=4.3, wpb=3519.6, bsz=107.1, num_updates=148700, lr=8.20058e-05, gnorm=1.344, train_wall=23, wall=0
2024-07-15 21:05:22 | INFO | train_inner | epoch 011:   2480 / 14632 loss=4.713, nll_loss=3.34, ppl=10.12, wps=15249.7, ups=4.35, wpb=3507.2, bsz=109.3, num_updates=148800, lr=8.19782e-05, gnorm=1.389, train_wall=23, wall=0
2024-07-15 21:05:45 | INFO | train_inner | epoch 011:   2580 / 14632 loss=4.756, nll_loss=3.39, ppl=10.48, wps=14829.6, ups=4.4, wpb=3367.3, bsz=110.6, num_updates=148900, lr=8.19507e-05, gnorm=1.438, train_wall=23, wall=0
2024-07-15 21:06:08 | INFO | train_inner | epoch 011:   2680 / 14632 loss=4.725, nll_loss=3.354, ppl=10.22, wps=15245.1, ups=4.4, wpb=3464, bsz=118.2, num_updates=149000, lr=8.19232e-05, gnorm=1.392, train_wall=23, wall=0
2024-07-15 21:06:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 21:06:10 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.671 | nll_loss 3.166 | ppl 8.98 | wps 42195.7 | wpb 2469 | bsz 83 | num_updates 149000 | best_loss 12.212
2024-07-15 21:06:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 21:06:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_11_149000.pt (epoch 11 @ 149000 updates, score 4.671) (writing took 4.450606814585626 seconds)
2024-07-15 21:06:37 | INFO | train_inner | epoch 011:   2780 / 14632 loss=4.763, nll_loss=3.398, ppl=10.54, wps=11451.9, ups=3.37, wpb=3396, bsz=103.7, num_updates=149100, lr=8.18957e-05, gnorm=1.381, train_wall=23, wall=0
2024-07-15 21:07:00 | INFO | train_inner | epoch 011:   2880 / 14632 loss=4.732, nll_loss=3.361, ppl=10.28, wps=15255, ups=4.36, wpb=3502.3, bsz=118.2, num_updates=149200, lr=8.18683e-05, gnorm=1.367, train_wall=23, wall=0
2024-07-15 21:07:23 | INFO | train_inner | epoch 011:   2980 / 14632 loss=4.692, nll_loss=3.316, ppl=9.96, wps=15267.8, ups=4.35, wpb=3507, bsz=116.2, num_updates=149300, lr=8.18408e-05, gnorm=1.344, train_wall=23, wall=0
2024-07-15 21:07:46 | INFO | train_inner | epoch 011:   3080 / 14632 loss=4.755, nll_loss=3.389, ppl=10.47, wps=14606.3, ups=4.43, wpb=3293.8, bsz=110.6, num_updates=149400, lr=8.18134e-05, gnorm=1.429, train_wall=22, wall=0
2024-07-15 21:08:09 | INFO | train_inner | epoch 011:   3180 / 14632 loss=4.661, nll_loss=3.281, ppl=9.72, wps=14997.1, ups=4.37, wpb=3433.3, bsz=121.5, num_updates=149500, lr=8.17861e-05, gnorm=1.373, train_wall=23, wall=0
2024-07-15 21:08:32 | INFO | train_inner | epoch 011:   3280 / 14632 loss=4.705, nll_loss=3.331, ppl=10.07, wps=14921.1, ups=4.34, wpb=3437.5, bsz=116.7, num_updates=149600, lr=8.17587e-05, gnorm=1.35, train_wall=23, wall=0
2024-07-15 21:08:55 | INFO | train_inner | epoch 011:   3380 / 14632 loss=4.738, nll_loss=3.368, ppl=10.32, wps=15137.8, ups=4.41, wpb=3434, bsz=106.2, num_updates=149700, lr=8.17314e-05, gnorm=1.386, train_wall=23, wall=0
2024-07-15 21:09:18 | INFO | train_inner | epoch 011:   3480 / 14632 loss=4.635, nll_loss=3.251, ppl=9.52, wps=15211.4, ups=4.29, wpb=3544.1, bsz=127.1, num_updates=149800, lr=8.17041e-05, gnorm=1.383, train_wall=23, wall=0
2024-07-15 21:09:41 | INFO | train_inner | epoch 011:   3580 / 14632 loss=4.672, nll_loss=3.293, ppl=9.8, wps=15171.9, ups=4.34, wpb=3497.1, bsz=120.2, num_updates=149900, lr=8.16769e-05, gnorm=1.372, train_wall=23, wall=0
2024-07-15 21:10:04 | INFO | train_inner | epoch 011:   3680 / 14632 loss=4.636, nll_loss=3.251, ppl=9.52, wps=15255.6, ups=4.28, wpb=3567.1, bsz=121, num_updates=150000, lr=8.16497e-05, gnorm=1.345, train_wall=23, wall=0
2024-07-15 21:10:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 21:10:07 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.666 | nll_loss 3.158 | ppl 8.92 | wps 41912.9 | wpb 2469 | bsz 83 | num_updates 150000 | best_loss 12.212
2024-07-15 21:10:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 21:10:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_11_150000.pt (epoch 11 @ 150000 updates, score 4.666) (writing took 4.682278887368739 seconds)
2024-07-15 21:10:34 | INFO | train_inner | epoch 011:   3780 / 14632 loss=4.725, nll_loss=3.355, ppl=10.23, wps=11763.9, ups=3.33, wpb=3535.1, bsz=111, num_updates=150100, lr=8.16225e-05, gnorm=1.358, train_wall=23, wall=0
2024-07-15 21:10:57 | INFO | train_inner | epoch 011:   3880 / 14632 loss=4.716, nll_loss=3.343, ppl=10.15, wps=14919.7, ups=4.4, wpb=3387.2, bsz=103.4, num_updates=150200, lr=8.15953e-05, gnorm=1.411, train_wall=23, wall=0
2024-07-15 21:11:20 | INFO | train_inner | epoch 011:   3980 / 14632 loss=4.705, nll_loss=3.331, ppl=10.06, wps=14991.8, ups=4.35, wpb=3447.9, bsz=119.6, num_updates=150300, lr=8.15681e-05, gnorm=1.388, train_wall=23, wall=0
2024-07-15 21:11:43 | INFO | train_inner | epoch 011:   4080 / 14632 loss=4.684, nll_loss=3.308, ppl=9.91, wps=15090.2, ups=4.32, wpb=3495.6, bsz=116.8, num_updates=150400, lr=8.1541e-05, gnorm=1.353, train_wall=23, wall=0
2024-07-15 21:12:06 | INFO | train_inner | epoch 011:   4180 / 14632 loss=4.692, nll_loss=3.318, ppl=9.97, wps=14718.6, ups=4.33, wpb=3398.7, bsz=111.9, num_updates=150500, lr=8.15139e-05, gnorm=1.372, train_wall=23, wall=0
2024-07-15 21:12:29 | INFO | train_inner | epoch 011:   4280 / 14632 loss=4.671, nll_loss=3.293, ppl=9.8, wps=15276.2, ups=4.36, wpb=3506, bsz=120.7, num_updates=150600, lr=8.14868e-05, gnorm=1.383, train_wall=23, wall=0
2024-07-15 21:12:52 | INFO | train_inner | epoch 011:   4380 / 14632 loss=4.741, nll_loss=3.373, ppl=10.36, wps=14929.9, ups=4.34, wpb=3437, bsz=116.9, num_updates=150700, lr=8.14598e-05, gnorm=1.392, train_wall=23, wall=0
2024-07-15 21:13:16 | INFO | train_inner | epoch 011:   4480 / 14632 loss=4.751, nll_loss=3.385, ppl=10.44, wps=14771.4, ups=4.25, wpb=3475.2, bsz=109.3, num_updates=150800, lr=8.14328e-05, gnorm=1.37, train_wall=23, wall=0
2024-07-15 21:13:39 | INFO | train_inner | epoch 011:   4580 / 14632 loss=4.682, nll_loss=3.306, ppl=9.89, wps=14944.4, ups=4.28, wpb=3489.9, bsz=111.9, num_updates=150900, lr=8.14058e-05, gnorm=1.354, train_wall=23, wall=0
2024-07-15 21:14:03 | INFO | train_inner | epoch 011:   4680 / 14632 loss=4.65, nll_loss=3.268, ppl=9.63, wps=15105.5, ups=4.28, wpb=3532.8, bsz=117.8, num_updates=151000, lr=8.13788e-05, gnorm=1.352, train_wall=23, wall=0
2024-07-15 21:14:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 21:14:05 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.647 | nll_loss 3.137 | ppl 8.8 | wps 42143.5 | wpb 2469 | bsz 83 | num_updates 151000 | best_loss 12.212
2024-07-15 21:14:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 21:14:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_11_151000.pt (epoch 11 @ 151000 updates, score 4.647) (writing took 5.06613676995039 seconds)
2024-07-15 21:14:33 | INFO | train_inner | epoch 011:   4780 / 14632 loss=4.612, nll_loss=3.227, ppl=9.36, wps=10943, ups=3.23, wpb=3384.8, bsz=128.4, num_updates=151100, lr=8.13519e-05, gnorm=1.39, train_wall=23, wall=0
2024-07-15 21:14:57 | INFO | train_inner | epoch 011:   4880 / 14632 loss=4.682, nll_loss=3.305, ppl=9.88, wps=14687.1, ups=4.21, wpb=3484.5, bsz=116.2, num_updates=151200, lr=8.1325e-05, gnorm=1.396, train_wall=24, wall=0
2024-07-15 21:15:20 | INFO | train_inner | epoch 011:   4980 / 14632 loss=4.668, nll_loss=3.291, ppl=9.78, wps=15210.4, ups=4.3, wpb=3539.1, bsz=124.5, num_updates=151300, lr=8.12981e-05, gnorm=1.356, train_wall=23, wall=0
2024-07-15 21:15:43 | INFO | train_inner | epoch 011:   5080 / 14632 loss=4.679, nll_loss=3.301, ppl=9.85, wps=15221.4, ups=4.34, wpb=3508.2, bsz=115, num_updates=151400, lr=8.12713e-05, gnorm=1.354, train_wall=23, wall=0
2024-07-15 21:16:07 | INFO | train_inner | epoch 011:   5180 / 14632 loss=4.64, nll_loss=3.258, ppl=9.56, wps=14834.9, ups=4.28, wpb=3462.6, bsz=112.9, num_updates=151500, lr=8.12444e-05, gnorm=1.367, train_wall=23, wall=0
2024-07-15 21:16:30 | INFO | train_inner | epoch 011:   5280 / 14632 loss=4.699, nll_loss=3.325, ppl=10.02, wps=15048.9, ups=4.32, wpb=3481.1, bsz=116, num_updates=151600, lr=8.12176e-05, gnorm=1.381, train_wall=23, wall=0
2024-07-15 21:16:53 | INFO | train_inner | epoch 011:   5380 / 14632 loss=4.63, nll_loss=3.246, ppl=9.49, wps=15205.3, ups=4.31, wpb=3529.6, bsz=121.9, num_updates=151700, lr=8.11909e-05, gnorm=1.342, train_wall=23, wall=0
2024-07-15 21:17:17 | INFO | train_inner | epoch 011:   5480 / 14632 loss=4.701, nll_loss=3.328, ppl=10.04, wps=14625.7, ups=4.24, wpb=3448.3, bsz=116.6, num_updates=151800, lr=8.11641e-05, gnorm=1.393, train_wall=23, wall=0
2024-07-15 21:17:40 | INFO | train_inner | epoch 011:   5580 / 14632 loss=4.626, nll_loss=3.243, ppl=9.47, wps=14705.5, ups=4.26, wpb=3449.3, bsz=129.1, num_updates=151900, lr=8.11374e-05, gnorm=1.332, train_wall=23, wall=0
2024-07-15 21:18:04 | INFO | train_inner | epoch 011:   5680 / 14632 loss=4.695, nll_loss=3.32, ppl=9.99, wps=15065, ups=4.29, wpb=3511.9, bsz=113.2, num_updates=152000, lr=8.11107e-05, gnorm=1.348, train_wall=23, wall=0
2024-07-15 21:18:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 21:18:06 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.616 | nll_loss 3.104 | ppl 8.6 | wps 42271.7 | wpb 2469 | bsz 83 | num_updates 152000 | best_loss 12.212
2024-07-15 21:18:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 21:18:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_11_152000.pt (epoch 11 @ 152000 updates, score 4.616) (writing took 4.485470347106457 seconds)
2024-07-15 21:18:33 | INFO | train_inner | epoch 011:   5780 / 14632 loss=4.733, nll_loss=3.365, ppl=10.3, wps=11592.2, ups=3.41, wpb=3396.8, bsz=118.9, num_updates=152100, lr=8.1084e-05, gnorm=1.436, train_wall=22, wall=0
2024-07-15 21:18:56 | INFO | train_inner | epoch 011:   5880 / 14632 loss=4.699, nll_loss=3.326, ppl=10.03, wps=14775.5, ups=4.26, wpb=3465.2, bsz=110, num_updates=152200, lr=8.10574e-05, gnorm=1.472, train_wall=23, wall=0
2024-07-15 21:19:20 | INFO | train_inner | epoch 011:   5980 / 14632 loss=4.635, nll_loss=3.253, ppl=9.53, wps=14835.5, ups=4.27, wpb=3471.4, bsz=117.9, num_updates=152300, lr=8.10308e-05, gnorm=1.385, train_wall=23, wall=0
2024-07-15 21:19:43 | INFO | train_inner | epoch 011:   6080 / 14632 loss=4.674, nll_loss=3.295, ppl=9.81, wps=15101, ups=4.32, wpb=3495, bsz=110.9, num_updates=152400, lr=8.10042e-05, gnorm=1.359, train_wall=23, wall=0
2024-07-15 21:20:06 | INFO | train_inner | epoch 011:   6180 / 14632 loss=4.707, nll_loss=3.335, ppl=10.09, wps=14846.5, ups=4.37, wpb=3398.1, bsz=106.3, num_updates=152500, lr=8.09776e-05, gnorm=1.428, train_wall=23, wall=0
2024-07-15 21:20:29 | INFO | train_inner | epoch 011:   6280 / 14632 loss=4.616, nll_loss=3.23, ppl=9.38, wps=15063.4, ups=4.27, wpb=3525.1, bsz=126.7, num_updates=152600, lr=8.09511e-05, gnorm=1.345, train_wall=23, wall=0
2024-07-15 21:20:52 | INFO | train_inner | epoch 011:   6380 / 14632 loss=4.667, nll_loss=3.289, ppl=9.78, wps=14975, ups=4.34, wpb=3449.7, bsz=109, num_updates=152700, lr=8.09246e-05, gnorm=1.385, train_wall=23, wall=0
2024-07-15 21:21:15 | INFO | train_inner | epoch 011:   6480 / 14632 loss=4.726, nll_loss=3.356, ppl=10.24, wps=15223.5, ups=4.33, wpb=3518.1, bsz=109.5, num_updates=152800, lr=8.08981e-05, gnorm=1.354, train_wall=23, wall=0
2024-07-15 21:21:39 | INFO | train_inner | epoch 011:   6580 / 14632 loss=4.624, nll_loss=3.239, ppl=9.44, wps=15267.3, ups=4.29, wpb=3561.9, bsz=129, num_updates=152900, lr=8.08716e-05, gnorm=1.341, train_wall=23, wall=0
2024-07-15 21:22:02 | INFO | train_inner | epoch 011:   6680 / 14632 loss=4.644, nll_loss=3.263, ppl=9.6, wps=15072.8, ups=4.3, wpb=3501.4, bsz=117.8, num_updates=153000, lr=8.08452e-05, gnorm=1.356, train_wall=23, wall=0
2024-07-15 21:22:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 21:22:04 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.626 | nll_loss 3.109 | ppl 8.63 | wps 41984.1 | wpb 2469 | bsz 83 | num_updates 153000 | best_loss 12.212
2024-07-15 21:22:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 21:22:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_11_153000.pt (epoch 11 @ 153000 updates, score 4.626) (writing took 4.637961961328983 seconds)
2024-07-15 21:22:32 | INFO | train_inner | epoch 011:   6780 / 14632 loss=4.67, nll_loss=3.292, ppl=9.8, wps=11854.5, ups=3.31, wpb=3582.5, bsz=109, num_updates=153100, lr=8.08188e-05, gnorm=1.318, train_wall=23, wall=0
2024-07-15 21:22:55 | INFO | train_inner | epoch 011:   6880 / 14632 loss=4.579, nll_loss=3.189, ppl=9.12, wps=14875.3, ups=4.28, wpb=3473.8, bsz=130.7, num_updates=153200, lr=8.07924e-05, gnorm=1.339, train_wall=23, wall=0
2024-07-15 21:23:18 | INFO | train_inner | epoch 011:   6980 / 14632 loss=4.677, nll_loss=3.301, ppl=9.85, wps=15074.4, ups=4.34, wpb=3475.3, bsz=118.7, num_updates=153300, lr=8.07661e-05, gnorm=1.462, train_wall=23, wall=0
2024-07-15 21:23:42 | INFO | train_inner | epoch 011:   7080 / 14632 loss=4.63, nll_loss=3.246, ppl=9.49, wps=14916.8, ups=4.33, wpb=3442.4, bsz=107.8, num_updates=153400, lr=8.07397e-05, gnorm=1.362, train_wall=23, wall=0
2024-07-15 21:24:04 | INFO | train_inner | epoch 011:   7180 / 14632 loss=4.745, nll_loss=3.379, ppl=10.4, wps=15213.7, ups=4.41, wpb=3448.4, bsz=104.6, num_updates=153500, lr=8.07134e-05, gnorm=1.403, train_wall=23, wall=0
2024-07-15 21:24:27 | INFO | train_inner | epoch 011:   7280 / 14632 loss=4.609, nll_loss=3.224, ppl=9.34, wps=15183.4, ups=4.34, wpb=3500.1, bsz=128.1, num_updates=153600, lr=8.06872e-05, gnorm=1.338, train_wall=23, wall=0
2024-07-15 21:24:50 | INFO | train_inner | epoch 011:   7380 / 14632 loss=4.676, nll_loss=3.3, ppl=9.85, wps=15051.7, ups=4.37, wpb=3447.9, bsz=122.2, num_updates=153700, lr=8.06609e-05, gnorm=1.363, train_wall=23, wall=0
2024-07-15 21:25:13 | INFO | train_inner | epoch 011:   7480 / 14632 loss=4.668, nll_loss=3.29, ppl=9.78, wps=15134, ups=4.33, wpb=3498.9, bsz=106.1, num_updates=153800, lr=8.06347e-05, gnorm=1.349, train_wall=23, wall=0
2024-07-15 21:25:37 | INFO | train_inner | epoch 011:   7580 / 14632 loss=4.621, nll_loss=3.237, ppl=9.43, wps=15241.3, ups=4.27, wpb=3567.8, bsz=135.3, num_updates=153900, lr=8.06085e-05, gnorm=1.336, train_wall=23, wall=0
2024-07-15 21:26:00 | INFO | train_inner | epoch 011:   7680 / 14632 loss=4.563, nll_loss=3.171, ppl=9.01, wps=15276.5, ups=4.37, wpb=3494.3, bsz=126.5, num_updates=154000, lr=8.05823e-05, gnorm=1.333, train_wall=23, wall=0
2024-07-15 21:26:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 21:26:02 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.61 | nll_loss 3.097 | ppl 8.56 | wps 42424.2 | wpb 2469 | bsz 83 | num_updates 154000 | best_loss 12.212
2024-07-15 21:26:02 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 21:26:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_11_154000.pt (epoch 11 @ 154000 updates, score 4.61) (writing took 4.462183884344995 seconds)
2024-07-15 21:26:29 | INFO | train_inner | epoch 011:   7780 / 14632 loss=4.603, nll_loss=3.217, ppl=9.3, wps=11859.5, ups=3.35, wpb=3543.1, bsz=121.4, num_updates=154100, lr=8.05561e-05, gnorm=1.307, train_wall=23, wall=0
2024-07-15 21:26:52 | INFO | train_inner | epoch 011:   7880 / 14632 loss=4.651, nll_loss=3.272, ppl=9.66, wps=15583.5, ups=4.51, wpb=3457.2, bsz=115.6, num_updates=154200, lr=8.053e-05, gnorm=1.409, train_wall=22, wall=0
2024-07-15 21:27:15 | INFO | train_inner | epoch 011:   7980 / 14632 loss=4.705, nll_loss=3.334, ppl=10.08, wps=15139.5, ups=4.37, wpb=3466.4, bsz=118.6, num_updates=154300, lr=8.05039e-05, gnorm=1.377, train_wall=23, wall=0
2024-07-15 21:27:38 | INFO | train_inner | epoch 011:   8080 / 14632 loss=4.626, nll_loss=3.243, ppl=9.47, wps=15151.5, ups=4.31, wpb=3514.6, bsz=115.8, num_updates=154400, lr=8.04778e-05, gnorm=1.337, train_wall=23, wall=0
2024-07-15 21:28:01 | INFO | train_inner | epoch 011:   8180 / 14632 loss=4.695, nll_loss=3.321, ppl=9.99, wps=15154.1, ups=4.32, wpb=3506, bsz=116.3, num_updates=154500, lr=8.04518e-05, gnorm=1.368, train_wall=23, wall=0
2024-07-15 21:28:24 | INFO | train_inner | epoch 011:   8280 / 14632 loss=4.715, nll_loss=3.345, ppl=10.16, wps=14974.7, ups=4.35, wpb=3445.4, bsz=109, num_updates=154600, lr=8.04258e-05, gnorm=1.411, train_wall=23, wall=0
2024-07-15 21:28:47 | INFO | train_inner | epoch 011:   8380 / 14632 loss=4.648, nll_loss=3.268, ppl=9.64, wps=14846.5, ups=4.31, wpb=3444.9, bsz=115, num_updates=154700, lr=8.03998e-05, gnorm=1.36, train_wall=23, wall=0
2024-07-15 21:29:10 | INFO | train_inner | epoch 011:   8480 / 14632 loss=4.642, nll_loss=3.259, ppl=9.58, wps=15453.2, ups=4.36, wpb=3547, bsz=109.9, num_updates=154800, lr=8.03738e-05, gnorm=1.342, train_wall=23, wall=0
2024-07-15 21:29:33 | INFO | train_inner | epoch 011:   8580 / 14632 loss=4.635, nll_loss=3.253, ppl=9.53, wps=15209.4, ups=4.34, wpb=3504, bsz=121.6, num_updates=154900, lr=8.03479e-05, gnorm=1.35, train_wall=23, wall=0
2024-07-15 21:29:56 | INFO | train_inner | epoch 011:   8680 / 14632 loss=4.622, nll_loss=3.238, ppl=9.43, wps=14898.9, ups=4.31, wpb=3458.2, bsz=99.4, num_updates=155000, lr=8.03219e-05, gnorm=1.344, train_wall=23, wall=0
2024-07-15 21:29:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 21:29:59 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.588 | nll_loss 3.07 | ppl 8.4 | wps 42263.8 | wpb 2469 | bsz 83 | num_updates 155000 | best_loss 12.212
2024-07-15 21:29:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 21:30:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_11_155000.pt (epoch 11 @ 155000 updates, score 4.588) (writing took 4.631222428753972 seconds)
2024-07-15 21:30:27 | INFO | train_inner | epoch 011:   8780 / 14632 loss=4.633, nll_loss=3.252, ppl=9.52, wps=11286.3, ups=3.27, wpb=3447.6, bsz=115.2, num_updates=155100, lr=8.0296e-05, gnorm=1.385, train_wall=23, wall=0
2024-07-15 21:30:50 | INFO | train_inner | epoch 011:   8880 / 14632 loss=4.622, nll_loss=3.238, ppl=9.44, wps=14739.4, ups=4.26, wpb=3463.8, bsz=119, num_updates=155200, lr=8.02702e-05, gnorm=1.371, train_wall=23, wall=0
2024-07-15 21:31:14 | INFO | train_inner | epoch 011:   8980 / 14632 loss=4.528, nll_loss=3.131, ppl=8.76, wps=15210.9, ups=4.27, wpb=3559.3, bsz=136, num_updates=155300, lr=8.02443e-05, gnorm=1.298, train_wall=23, wall=0
2024-07-15 21:31:36 | INFO | train_inner | epoch 011:   9080 / 14632 loss=4.612, nll_loss=3.228, ppl=9.37, wps=15188.5, ups=4.42, wpb=3437.7, bsz=115.4, num_updates=155400, lr=8.02185e-05, gnorm=1.353, train_wall=22, wall=0
2024-07-15 21:31:59 | INFO | train_inner | epoch 011:   9180 / 14632 loss=4.667, nll_loss=3.29, ppl=9.78, wps=15460.9, ups=4.32, wpb=3577.7, bsz=116, num_updates=155500, lr=8.01927e-05, gnorm=1.355, train_wall=23, wall=0
2024-07-15 21:32:22 | INFO | train_inner | epoch 011:   9280 / 14632 loss=4.724, nll_loss=3.354, ppl=10.22, wps=15129, ups=4.43, wpb=3417.3, bsz=103.4, num_updates=155600, lr=8.01669e-05, gnorm=1.409, train_wall=22, wall=0
2024-07-15 21:32:45 | INFO | train_inner | epoch 011:   9380 / 14632 loss=4.783, nll_loss=3.422, ppl=10.72, wps=14947.5, ups=4.32, wpb=3462.8, bsz=90, num_updates=155700, lr=8.01412e-05, gnorm=1.373, train_wall=23, wall=0
2024-07-15 21:33:08 | INFO | train_inner | epoch 011:   9480 / 14632 loss=4.527, nll_loss=3.13, ppl=8.76, wps=15354.1, ups=4.4, wpb=3491.9, bsz=118.9, num_updates=155800, lr=8.01154e-05, gnorm=1.34, train_wall=23, wall=0
2024-07-15 21:33:31 | INFO | train_inner | epoch 011:   9580 / 14632 loss=4.631, nll_loss=3.25, ppl=9.51, wps=15269.3, ups=4.36, wpb=3498.2, bsz=120.9, num_updates=155900, lr=8.00898e-05, gnorm=1.347, train_wall=23, wall=0
2024-07-15 21:33:54 | INFO | train_inner | epoch 011:   9680 / 14632 loss=4.58, nll_loss=3.19, ppl=9.13, wps=15197.3, ups=4.38, wpb=3467, bsz=124.6, num_updates=156000, lr=8.00641e-05, gnorm=1.332, train_wall=23, wall=0
2024-07-15 21:33:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 21:33:56 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.574 | nll_loss 3.058 | ppl 8.33 | wps 42211.6 | wpb 2469 | bsz 83 | num_updates 156000 | best_loss 12.212
2024-07-15 21:33:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 21:34:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_11_156000.pt (epoch 11 @ 156000 updates, score 4.574) (writing took 4.50609037745744 seconds)
2024-07-15 21:34:24 | INFO | train_inner | epoch 011:   9780 / 14632 loss=4.575, nll_loss=3.185, ppl=9.1, wps=11560, ups=3.35, wpb=3451.1, bsz=113.3, num_updates=156100, lr=8.00384e-05, gnorm=1.366, train_wall=23, wall=0
2024-07-15 21:34:47 | INFO | train_inner | epoch 011:   9880 / 14632 loss=4.617, nll_loss=3.232, ppl=9.39, wps=15220.4, ups=4.35, wpb=3501.9, bsz=115.1, num_updates=156200, lr=8.00128e-05, gnorm=1.341, train_wall=23, wall=0
2024-07-15 21:35:09 | INFO | train_inner | epoch 011:   9980 / 14632 loss=4.686, nll_loss=3.312, ppl=9.93, wps=15392, ups=4.4, wpb=3501.7, bsz=108.3, num_updates=156300, lr=7.99872e-05, gnorm=1.372, train_wall=23, wall=0
2024-07-15 21:35:33 | INFO | train_inner | epoch 011:  10080 / 14632 loss=4.581, nll_loss=3.191, ppl=9.13, wps=14911.6, ups=4.25, wpb=3509.6, bsz=145.9, num_updates=156400, lr=7.99616e-05, gnorm=1.383, train_wall=23, wall=0
2024-07-15 21:35:56 | INFO | train_inner | epoch 011:  10180 / 14632 loss=4.608, nll_loss=3.222, ppl=9.33, wps=14889.1, ups=4.26, wpb=3495.6, bsz=112.5, num_updates=156500, lr=7.99361e-05, gnorm=1.329, train_wall=23, wall=0
2024-07-15 21:36:19 | INFO | train_inner | epoch 011:  10280 / 14632 loss=4.683, nll_loss=3.309, ppl=9.91, wps=15168.5, ups=4.41, wpb=3439.1, bsz=121.8, num_updates=156600, lr=7.99106e-05, gnorm=1.368, train_wall=23, wall=0
2024-07-15 21:36:42 | INFO | train_inner | epoch 011:  10380 / 14632 loss=4.615, nll_loss=3.231, ppl=9.39, wps=15001.1, ups=4.34, wpb=3454.5, bsz=115.2, num_updates=156700, lr=7.9885e-05, gnorm=1.375, train_wall=23, wall=0
2024-07-15 21:37:05 | INFO | train_inner | epoch 011:  10480 / 14632 loss=4.606, nll_loss=3.22, ppl=9.32, wps=15045.8, ups=4.28, wpb=3511.6, bsz=115.4, num_updates=156800, lr=7.98596e-05, gnorm=1.331, train_wall=23, wall=0
2024-07-15 21:37:28 | INFO | train_inner | epoch 011:  10580 / 14632 loss=4.585, nll_loss=3.196, ppl=9.17, wps=14919.5, ups=4.36, wpb=3422.6, bsz=129.4, num_updates=156900, lr=7.98341e-05, gnorm=1.392, train_wall=23, wall=0
2024-07-15 21:37:52 | INFO | train_inner | epoch 011:  10680 / 14632 loss=4.607, nll_loss=3.222, ppl=9.33, wps=14940.8, ups=4.26, wpb=3507.9, bsz=125.4, num_updates=157000, lr=7.98087e-05, gnorm=1.331, train_wall=23, wall=0
2024-07-15 21:37:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 21:37:54 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.574 | nll_loss 3.057 | ppl 8.33 | wps 42299 | wpb 2469 | bsz 83 | num_updates 157000 | best_loss 12.212
2024-07-15 21:37:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 21:37:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_11_157000.pt (epoch 11 @ 157000 updates, score 4.574) (writing took 4.489235004410148 seconds)
2024-07-15 21:38:22 | INFO | train_inner | epoch 011:  10780 / 14632 loss=4.564, nll_loss=3.173, ppl=9.02, wps=11754.4, ups=3.31, wpb=3554.4, bsz=119.8, num_updates=157100, lr=7.97833e-05, gnorm=1.303, train_wall=23, wall=0
2024-07-15 21:38:44 | INFO | train_inner | epoch 011:  10880 / 14632 loss=4.755, nll_loss=3.391, ppl=10.49, wps=15327.9, ups=4.46, wpb=3437.2, bsz=104, num_updates=157200, lr=7.97579e-05, gnorm=1.39, train_wall=22, wall=0
2024-07-15 21:39:07 | INFO | train_inner | epoch 011:  10980 / 14632 loss=4.556, nll_loss=3.164, ppl=8.96, wps=15015, ups=4.37, wpb=3435.5, bsz=115.8, num_updates=157300, lr=7.97325e-05, gnorm=1.339, train_wall=23, wall=0
2024-07-15 21:39:31 | INFO | train_inner | epoch 011:  11080 / 14632 loss=4.48, nll_loss=3.077, ppl=8.44, wps=14717.2, ups=4.18, wpb=3519.6, bsz=142.6, num_updates=157400, lr=7.97072e-05, gnorm=1.334, train_wall=24, wall=0
2024-07-15 21:39:54 | INFO | train_inner | epoch 011:  11180 / 14632 loss=4.629, nll_loss=3.247, ppl=9.49, wps=15199, ups=4.35, wpb=3490.6, bsz=116.9, num_updates=157500, lr=7.96819e-05, gnorm=1.377, train_wall=23, wall=0
2024-07-15 21:40:17 | INFO | train_inner | epoch 011:  11280 / 14632 loss=4.588, nll_loss=3.2, ppl=9.19, wps=14913.8, ups=4.35, wpb=3426.2, bsz=121.8, num_updates=157600, lr=7.96566e-05, gnorm=1.361, train_wall=23, wall=0
2024-07-15 21:40:40 | INFO | train_inner | epoch 011:  11380 / 14632 loss=4.541, nll_loss=3.147, ppl=8.86, wps=15415.1, ups=4.36, wpb=3532.8, bsz=142.2, num_updates=157700, lr=7.96314e-05, gnorm=1.327, train_wall=23, wall=0
2024-07-15 21:41:03 | INFO | train_inner | epoch 011:  11480 / 14632 loss=4.642, nll_loss=3.262, ppl=9.59, wps=15613.9, ups=4.4, wpb=3549.7, bsz=117.6, num_updates=157800, lr=7.96061e-05, gnorm=1.342, train_wall=23, wall=0
2024-07-15 21:41:26 | INFO | train_inner | epoch 011:  11580 / 14632 loss=4.626, nll_loss=3.243, ppl=9.47, wps=15031.6, ups=4.33, wpb=3468.3, bsz=111.1, num_updates=157900, lr=7.95809e-05, gnorm=1.354, train_wall=23, wall=0
2024-07-15 21:41:49 | INFO | train_inner | epoch 011:  11680 / 14632 loss=4.674, nll_loss=3.3, ppl=9.85, wps=15075.6, ups=4.33, wpb=3481.7, bsz=124.2, num_updates=158000, lr=7.95557e-05, gnorm=1.355, train_wall=23, wall=0
2024-07-15 21:41:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 21:41:51 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.569 | nll_loss 3.053 | ppl 8.3 | wps 42272 | wpb 2469 | bsz 83 | num_updates 158000 | best_loss 12.212
2024-07-15 21:41:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 21:41:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_11_158000.pt (epoch 11 @ 158000 updates, score 4.569) (writing took 4.6628971276804805 seconds)
2024-07-15 21:42:19 | INFO | train_inner | epoch 011:  11780 / 14632 loss=4.655, nll_loss=3.278, ppl=9.7, wps=11626.8, ups=3.33, wpb=3489.5, bsz=122.6, num_updates=158100, lr=7.95306e-05, gnorm=1.345, train_wall=23, wall=0
2024-07-15 21:42:42 | INFO | train_inner | epoch 011:  11880 / 14632 loss=4.594, nll_loss=3.208, ppl=9.24, wps=14938.2, ups=4.29, wpb=3482.6, bsz=117.2, num_updates=158200, lr=7.95054e-05, gnorm=1.331, train_wall=23, wall=0
2024-07-15 21:43:06 | INFO | train_inner | epoch 011:  11980 / 14632 loss=4.59, nll_loss=3.203, ppl=9.21, wps=15204.5, ups=4.31, wpb=3526, bsz=134.2, num_updates=158300, lr=7.94803e-05, gnorm=1.338, train_wall=23, wall=0
2024-07-15 21:43:29 | INFO | train_inner | epoch 011:  12080 / 14632 loss=4.613, nll_loss=3.229, ppl=9.38, wps=15256.7, ups=4.3, wpb=3545, bsz=125.8, num_updates=158400, lr=7.94552e-05, gnorm=1.337, train_wall=23, wall=0
2024-07-15 21:43:52 | INFO | train_inner | epoch 011:  12180 / 14632 loss=4.633, nll_loss=3.251, ppl=9.52, wps=14707.5, ups=4.24, wpb=3467.5, bsz=114.4, num_updates=158500, lr=7.94301e-05, gnorm=1.372, train_wall=23, wall=0
2024-07-15 21:44:15 | INFO | train_inner | epoch 011:  12280 / 14632 loss=4.62, nll_loss=3.238, ppl=9.43, wps=15283.8, ups=4.33, wpb=3527.8, bsz=119.7, num_updates=158600, lr=7.94051e-05, gnorm=1.379, train_wall=23, wall=0
2024-07-15 21:44:39 | INFO | train_inner | epoch 011:  12380 / 14632 loss=4.638, nll_loss=3.258, ppl=9.57, wps=14477.1, ups=4.23, wpb=3424.2, bsz=121.4, num_updates=158700, lr=7.93801e-05, gnorm=1.448, train_wall=23, wall=0
2024-07-15 21:45:02 | INFO | train_inner | epoch 011:  12480 / 14632 loss=4.606, nll_loss=3.221, ppl=9.32, wps=14983, ups=4.36, wpb=3434.8, bsz=116.1, num_updates=158800, lr=7.93551e-05, gnorm=1.36, train_wall=23, wall=0
2024-07-15 21:45:25 | INFO | train_inner | epoch 011:  12580 / 14632 loss=4.59, nll_loss=3.204, ppl=9.22, wps=15362.3, ups=4.31, wpb=3564.3, bsz=124.7, num_updates=158900, lr=7.93301e-05, gnorm=1.296, train_wall=23, wall=0
2024-07-15 21:45:48 | INFO | train_inner | epoch 011:  12680 / 14632 loss=4.587, nll_loss=3.2, ppl=9.19, wps=15379, ups=4.44, wpb=3460.2, bsz=116, num_updates=159000, lr=7.93052e-05, gnorm=1.332, train_wall=22, wall=0
2024-07-15 21:45:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 21:45:50 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.539 | nll_loss 3.019 | ppl 8.11 | wps 42290.1 | wpb 2469 | bsz 83 | num_updates 159000 | best_loss 12.212
2024-07-15 21:45:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 21:45:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_11_159000.pt (epoch 11 @ 159000 updates, score 4.539) (writing took 4.522085232660174 seconds)
2024-07-15 21:46:17 | INFO | train_inner | epoch 011:  12780 / 14632 loss=4.668, nll_loss=3.292, ppl=9.79, wps=11672.3, ups=3.37, wpb=3466, bsz=111, num_updates=159100, lr=7.92802e-05, gnorm=1.382, train_wall=23, wall=0
2024-07-15 21:46:40 | INFO | train_inner | epoch 011:  12880 / 14632 loss=4.592, nll_loss=3.206, ppl=9.23, wps=15219.9, ups=4.36, wpb=3492.8, bsz=128, num_updates=159200, lr=7.92553e-05, gnorm=1.349, train_wall=23, wall=0
2024-07-15 21:47:03 | INFO | train_inner | epoch 011:  12980 / 14632 loss=4.662, nll_loss=3.285, ppl=9.75, wps=15142.1, ups=4.35, wpb=3483.4, bsz=116.2, num_updates=159300, lr=7.92304e-05, gnorm=1.352, train_wall=23, wall=0
2024-07-15 21:47:27 | INFO | train_inner | epoch 011:  13080 / 14632 loss=4.515, nll_loss=3.12, ppl=8.69, wps=14925.6, ups=4.27, wpb=3493.3, bsz=138, num_updates=159400, lr=7.92056e-05, gnorm=1.372, train_wall=23, wall=0
2024-07-15 21:47:50 | INFO | train_inner | epoch 011:  13180 / 14632 loss=4.56, nll_loss=3.17, ppl=9, wps=15118.9, ups=4.38, wpb=3450.9, bsz=126.4, num_updates=159500, lr=7.91808e-05, gnorm=1.334, train_wall=23, wall=0
2024-07-15 21:48:13 | INFO | train_inner | epoch 011:  13280 / 14632 loss=4.649, nll_loss=3.271, ppl=9.65, wps=15615.8, ups=4.32, wpb=3617.2, bsz=117.4, num_updates=159600, lr=7.91559e-05, gnorm=1.32, train_wall=23, wall=0
2024-07-15 21:48:36 | INFO | train_inner | epoch 011:  13380 / 14632 loss=4.599, nll_loss=3.215, ppl=9.29, wps=14925, ups=4.36, wpb=3423.1, bsz=130.1, num_updates=159700, lr=7.91312e-05, gnorm=1.41, train_wall=23, wall=0
2024-07-15 21:48:59 | INFO | train_inner | epoch 011:  13480 / 14632 loss=4.627, nll_loss=3.244, ppl=9.48, wps=15081.9, ups=4.33, wpb=3486.4, bsz=115.5, num_updates=159800, lr=7.91064e-05, gnorm=1.364, train_wall=23, wall=0
2024-07-15 21:49:22 | INFO | train_inner | epoch 011:  13580 / 14632 loss=4.61, nll_loss=3.226, ppl=9.36, wps=15013, ups=4.34, wpb=3456.8, bsz=118.2, num_updates=159900, lr=7.90817e-05, gnorm=1.359, train_wall=23, wall=0
2024-07-15 21:49:45 | INFO | train_inner | epoch 011:  13680 / 14632 loss=4.698, nll_loss=3.325, ppl=10.02, wps=15460.1, ups=4.34, wpb=3561.3, bsz=101.2, num_updates=160000, lr=7.90569e-05, gnorm=1.368, train_wall=23, wall=0
2024-07-15 21:49:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 21:49:47 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.535 | nll_loss 3.016 | ppl 8.09 | wps 42199.5 | wpb 2469 | bsz 83 | num_updates 160000 | best_loss 12.212
2024-07-15 21:49:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 21:49:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_11_160000.pt (epoch 11 @ 160000 updates, score 4.535) (writing took 4.624839357100427 seconds)
2024-07-15 21:50:15 | INFO | train_inner | epoch 011:  13780 / 14632 loss=4.588, nll_loss=3.203, ppl=9.21, wps=11604.1, ups=3.34, wpb=3478, bsz=125.7, num_updates=160100, lr=7.90322e-05, gnorm=1.399, train_wall=23, wall=0
2024-07-15 21:50:38 | INFO | train_inner | epoch 011:  13880 / 14632 loss=4.614, nll_loss=3.23, ppl=9.38, wps=15489.5, ups=4.39, wpb=3527.5, bsz=112.8, num_updates=160200, lr=7.90076e-05, gnorm=1.342, train_wall=23, wall=0
2024-07-15 21:51:01 | INFO | train_inner | epoch 011:  13980 / 14632 loss=4.431, nll_loss=3.024, ppl=8.13, wps=14874.5, ups=4.33, wpb=3439, bsz=147.7, num_updates=160300, lr=7.89829e-05, gnorm=1.341, train_wall=23, wall=0
2024-07-15 21:51:24 | INFO | train_inner | epoch 011:  14080 / 14632 loss=4.538, nll_loss=3.144, ppl=8.84, wps=15026.3, ups=4.35, wpb=3457, bsz=115.9, num_updates=160400, lr=7.89583e-05, gnorm=1.338, train_wall=23, wall=0
2024-07-15 21:51:47 | INFO | train_inner | epoch 011:  14180 / 14632 loss=4.619, nll_loss=3.237, ppl=9.43, wps=15209.8, ups=4.35, wpb=3498.2, bsz=121.7, num_updates=160500, lr=7.89337e-05, gnorm=1.349, train_wall=23, wall=0
2024-07-15 21:52:10 | INFO | train_inner | epoch 011:  14280 / 14632 loss=4.514, nll_loss=3.117, ppl=8.68, wps=15180.3, ups=4.38, wpb=3467.8, bsz=123.2, num_updates=160600, lr=7.89091e-05, gnorm=1.329, train_wall=23, wall=0
2024-07-15 21:52:33 | INFO | train_inner | epoch 011:  14380 / 14632 loss=4.49, nll_loss=3.09, ppl=8.51, wps=15007.9, ups=4.33, wpb=3465.7, bsz=130.3, num_updates=160700, lr=7.88846e-05, gnorm=1.315, train_wall=23, wall=0
2024-07-15 21:52:55 | INFO | train_inner | epoch 011:  14480 / 14632 loss=4.574, nll_loss=3.186, ppl=9.1, wps=15150.5, ups=4.41, wpb=3432.8, bsz=111.8, num_updates=160800, lr=7.886e-05, gnorm=1.349, train_wall=22, wall=0
2024-07-15 21:53:19 | INFO | train_inner | epoch 011:  14580 / 14632 loss=4.536, nll_loss=3.143, ppl=8.83, wps=15057.7, ups=4.26, wpb=3531.3, bsz=140.6, num_updates=160900, lr=7.88355e-05, gnorm=1.322, train_wall=23, wall=0
2024-07-15 21:53:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 21:53:33 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.539 | nll_loss 3.019 | ppl 8.11 | wps 42362.4 | wpb 2469 | bsz 83 | num_updates 160952 | best_loss 12.212
2024-07-15 21:53:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 21:53:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 11 @ 160952 updates, score 4.539) (writing took 3.9031742103397846 seconds)
2024-07-15 21:53:37 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2024-07-15 21:53:37 | INFO | train | epoch 011 | loss 4.651 | nll_loss 3.271 | ppl 9.65 | wps 14654.9 | ups 4.21 | wpb 3483.6 | bsz 118.4 | num_updates 160952 | lr 7.88228e-05 | gnorm 1.364 | train_wall 3348 | wall 0
2024-07-15 21:53:37 | INFO | fairseq.trainer | begin training epoch 12
2024-07-15 21:53:48 | INFO | train_inner | epoch 012:     48 / 14632 loss=4.59, nll_loss=3.203, ppl=9.21, wps=11903.4, ups=3.37, wpb=3532, bsz=116.6, num_updates=161000, lr=7.8811e-05, gnorm=1.334, train_wall=23, wall=0
2024-07-15 21:53:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 21:53:51 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.528 | nll_loss 3.004 | ppl 8.02 | wps 42226.1 | wpb 2469 | bsz 83 | num_updates 161000 | best_loss 12.212
2024-07-15 21:53:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 21:53:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_12_161000.pt (epoch 12 @ 161000 updates, score 4.528) (writing took 4.7713921694085 seconds)
2024-07-15 21:54:19 | INFO | train_inner | epoch 012:    148 / 14632 loss=4.535, nll_loss=3.142, ppl=8.83, wps=11559.4, ups=3.32, wpb=3482.7, bsz=118.7, num_updates=161100, lr=7.87866e-05, gnorm=1.351, train_wall=23, wall=0
2024-07-15 21:54:42 | INFO | train_inner | epoch 012:    248 / 14632 loss=4.573, nll_loss=3.184, ppl=9.09, wps=15066.6, ups=4.33, wpb=3481, bsz=115, num_updates=161200, lr=7.87621e-05, gnorm=1.322, train_wall=23, wall=0
2024-07-15 21:55:04 | INFO | train_inner | epoch 012:    348 / 14632 loss=4.579, nll_loss=3.191, ppl=9.13, wps=15238.9, ups=4.4, wpb=3460.9, bsz=114.8, num_updates=161300, lr=7.87377e-05, gnorm=1.365, train_wall=23, wall=0
2024-07-15 21:55:28 | INFO | train_inner | epoch 012:    448 / 14632 loss=4.564, nll_loss=3.174, ppl=9.02, wps=14910, ups=4.24, wpb=3516.4, bsz=124.2, num_updates=161400, lr=7.87133e-05, gnorm=1.375, train_wall=23, wall=0
2024-07-15 21:55:51 | INFO | train_inner | epoch 012:    548 / 14632 loss=4.662, nll_loss=3.286, ppl=9.75, wps=15066.2, ups=4.42, wpb=3409.7, bsz=102.5, num_updates=161500, lr=7.86889e-05, gnorm=1.373, train_wall=22, wall=0
2024-07-15 21:56:14 | INFO | train_inner | epoch 012:    648 / 14632 loss=4.581, nll_loss=3.193, ppl=9.15, wps=15071.3, ups=4.35, wpb=3461.6, bsz=103.8, num_updates=161600, lr=7.86646e-05, gnorm=1.34, train_wall=23, wall=0
2024-07-15 21:56:37 | INFO | train_inner | epoch 012:    748 / 14632 loss=4.575, nll_loss=3.187, ppl=9.11, wps=15139.6, ups=4.29, wpb=3525.8, bsz=120.9, num_updates=161700, lr=7.86403e-05, gnorm=1.331, train_wall=23, wall=0
2024-07-15 21:57:00 | INFO | train_inner | epoch 012:    848 / 14632 loss=4.522, nll_loss=3.127, ppl=8.73, wps=15241.7, ups=4.33, wpb=3517.5, bsz=115.8, num_updates=161800, lr=7.8616e-05, gnorm=1.337, train_wall=23, wall=0
2024-07-15 21:57:23 | INFO | train_inner | epoch 012:    948 / 14632 loss=4.576, nll_loss=3.188, ppl=9.11, wps=15307, ups=4.38, wpb=3497.3, bsz=111.4, num_updates=161900, lr=7.85917e-05, gnorm=1.364, train_wall=23, wall=0
2024-07-15 21:57:46 | INFO | train_inner | epoch 012:   1048 / 14632 loss=4.542, nll_loss=3.149, ppl=8.87, wps=15101.7, ups=4.4, wpb=3431.5, bsz=108.5, num_updates=162000, lr=7.85674e-05, gnorm=1.374, train_wall=23, wall=0
2024-07-15 21:57:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 21:57:48 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.521 | nll_loss 3.002 | ppl 8.01 | wps 42274 | wpb 2469 | bsz 83 | num_updates 162000 | best_loss 12.212
2024-07-15 21:57:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 21:57:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_12_162000.pt (epoch 12 @ 162000 updates, score 4.521) (writing took 4.621506874449551 seconds)
2024-07-15 21:58:15 | INFO | train_inner | epoch 012:   1148 / 14632 loss=4.548, nll_loss=3.156, ppl=8.91, wps=11559.9, ups=3.35, wpb=3455.4, bsz=116.9, num_updates=162100, lr=7.85432e-05, gnorm=1.364, train_wall=23, wall=0
2024-07-15 21:58:38 | INFO | train_inner | epoch 012:   1248 / 14632 loss=4.554, nll_loss=3.162, ppl=8.95, wps=15642.3, ups=4.46, wpb=3508.8, bsz=118.7, num_updates=162200, lr=7.8519e-05, gnorm=1.322, train_wall=22, wall=0
2024-07-15 21:59:01 | INFO | train_inner | epoch 012:   1348 / 14632 loss=4.562, nll_loss=3.172, ppl=9.01, wps=15448.3, ups=4.39, wpb=3516.8, bsz=114.6, num_updates=162300, lr=7.84948e-05, gnorm=1.321, train_wall=23, wall=0
2024-07-15 21:59:25 | INFO | train_inner | epoch 012:   1448 / 14632 loss=4.528, nll_loss=3.133, ppl=8.77, wps=13909.7, ups=4.05, wpb=3432.6, bsz=123.2, num_updates=162400, lr=7.84706e-05, gnorm=1.385, train_wall=25, wall=0
2024-07-15 21:59:49 | INFO | train_inner | epoch 012:   1548 / 14632 loss=4.594, nll_loss=3.209, ppl=9.25, wps=15031.1, ups=4.29, wpb=3501.9, bsz=117.9, num_updates=162500, lr=7.84465e-05, gnorm=1.389, train_wall=23, wall=0
2024-07-15 22:00:12 | INFO | train_inner | epoch 012:   1648 / 14632 loss=4.529, nll_loss=3.134, ppl=8.78, wps=15458.8, ups=4.26, wpb=3625.4, bsz=114, num_updates=162600, lr=7.84223e-05, gnorm=1.289, train_wall=23, wall=0
2024-07-15 22:00:35 | INFO | train_inner | epoch 012:   1748 / 14632 loss=4.538, nll_loss=3.145, ppl=8.84, wps=15113.7, ups=4.37, wpb=3459.8, bsz=122.5, num_updates=162700, lr=7.83982e-05, gnorm=1.357, train_wall=23, wall=0
2024-07-15 22:00:58 | INFO | train_inner | epoch 012:   1848 / 14632 loss=4.589, nll_loss=3.203, ppl=9.21, wps=15027.8, ups=4.32, wpb=3474.7, bsz=136.6, num_updates=162800, lr=7.83741e-05, gnorm=1.386, train_wall=23, wall=0
2024-07-15 22:01:21 | INFO | train_inner | epoch 012:   1948 / 14632 loss=4.552, nll_loss=3.161, ppl=8.95, wps=15015.6, ups=4.37, wpb=3434.9, bsz=117.9, num_updates=162900, lr=7.83501e-05, gnorm=1.343, train_wall=23, wall=0
2024-07-15 22:01:44 | INFO | train_inner | epoch 012:   2048 / 14632 loss=4.536, nll_loss=3.142, ppl=8.83, wps=15042.3, ups=4.38, wpb=3434.3, bsz=121.8, num_updates=163000, lr=7.8326e-05, gnorm=1.365, train_wall=23, wall=0
2024-07-15 22:01:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 22:01:46 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.506 | nll_loss 2.983 | ppl 7.91 | wps 42260 | wpb 2469 | bsz 83 | num_updates 163000 | best_loss 12.212
2024-07-15 22:01:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 22:01:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_12_163000.pt (epoch 12 @ 163000 updates, score 4.506) (writing took 5.037508074194193 seconds)
2024-07-15 22:02:15 | INFO | train_inner | epoch 012:   2148 / 14632 loss=4.464, nll_loss=3.06, ppl=8.34, wps=11330.5, ups=3.24, wpb=3492.3, bsz=123.6, num_updates=163100, lr=7.8302e-05, gnorm=1.346, train_wall=23, wall=0
2024-07-15 22:02:38 | INFO | train_inner | epoch 012:   2248 / 14632 loss=4.479, nll_loss=3.078, ppl=8.44, wps=15062.1, ups=4.33, wpb=3477.6, bsz=145.8, num_updates=163200, lr=7.8278e-05, gnorm=1.338, train_wall=23, wall=0
2024-07-15 22:03:01 | INFO | train_inner | epoch 012:   2348 / 14632 loss=4.606, nll_loss=3.222, ppl=9.33, wps=14961.3, ups=4.37, wpb=3421, bsz=111, num_updates=163300, lr=7.82541e-05, gnorm=1.394, train_wall=23, wall=0
2024-07-15 22:03:23 | INFO | train_inner | epoch 012:   2448 / 14632 loss=4.595, nll_loss=3.209, ppl=9.25, wps=15168.5, ups=4.39, wpb=3458.1, bsz=110.4, num_updates=163400, lr=7.82301e-05, gnorm=1.361, train_wall=23, wall=0
2024-07-15 22:03:46 | INFO | train_inner | epoch 012:   2548 / 14632 loss=4.56, nll_loss=3.169, ppl=9, wps=14760.3, ups=4.33, wpb=3407.3, bsz=110.2, num_updates=163500, lr=7.82062e-05, gnorm=1.364, train_wall=23, wall=0
2024-07-15 22:04:09 | INFO | train_inner | epoch 012:   2648 / 14632 loss=4.53, nll_loss=3.135, ppl=8.79, wps=15334.1, ups=4.38, wpb=3498.8, bsz=116.8, num_updates=163600, lr=7.81823e-05, gnorm=1.316, train_wall=23, wall=0
2024-07-15 22:04:34 | INFO | train_inner | epoch 012:   2748 / 14632 loss=4.549, nll_loss=3.158, ppl=8.93, wps=13713, ups=4.1, wpb=3346.8, bsz=114.6, num_updates=163700, lr=7.81584e-05, gnorm=1.442, train_wall=24, wall=0
2024-07-15 22:04:56 | INFO | train_inner | epoch 012:   2848 / 14632 loss=4.597, nll_loss=3.212, ppl=9.27, wps=15248.8, ups=4.41, wpb=3458.9, bsz=111.4, num_updates=163800, lr=7.81345e-05, gnorm=1.373, train_wall=23, wall=0
2024-07-15 22:05:20 | INFO | train_inner | epoch 012:   2948 / 14632 loss=4.531, nll_loss=3.137, ppl=8.8, wps=15004.6, ups=4.31, wpb=3484.2, bsz=120, num_updates=163900, lr=7.81107e-05, gnorm=1.327, train_wall=23, wall=0
2024-07-15 22:05:43 | INFO | train_inner | epoch 012:   3048 / 14632 loss=4.503, nll_loss=3.104, ppl=8.6, wps=15331.2, ups=4.34, wpb=3531.6, bsz=121.9, num_updates=164000, lr=7.80869e-05, gnorm=1.306, train_wall=23, wall=0
2024-07-15 22:05:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 22:05:45 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.494 | nll_loss 2.97 | ppl 7.84 | wps 42277.7 | wpb 2469 | bsz 83 | num_updates 164000 | best_loss 12.212
2024-07-15 22:05:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 22:05:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_12_164000.pt (epoch 12 @ 164000 updates, score 4.494) (writing took 4.576589936390519 seconds)
2024-07-15 22:06:13 | INFO | train_inner | epoch 012:   3148 / 14632 loss=4.566, nll_loss=3.176, ppl=9.04, wps=11446.7, ups=3.31, wpb=3453, bsz=121, num_updates=164100, lr=7.80631e-05, gnorm=1.36, train_wall=23, wall=0
2024-07-15 22:06:36 | INFO | train_inner | epoch 012:   3248 / 14632 loss=4.545, nll_loss=3.153, ppl=8.9, wps=15028.9, ups=4.33, wpb=3471.2, bsz=121.2, num_updates=164200, lr=7.80393e-05, gnorm=1.349, train_wall=23, wall=0
2024-07-15 22:07:00 | INFO | train_inner | epoch 012:   3348 / 14632 loss=4.477, nll_loss=3.076, ppl=8.43, wps=14633.3, ups=4.16, wpb=3521.8, bsz=132.7, num_updates=164300, lr=7.80156e-05, gnorm=1.304, train_wall=24, wall=0
2024-07-15 22:07:24 | INFO | train_inner | epoch 012:   3448 / 14632 loss=4.446, nll_loss=3.04, ppl=8.22, wps=15050.8, ups=4.21, wpb=3578, bsz=131.7, num_updates=164400, lr=7.79918e-05, gnorm=1.291, train_wall=24, wall=0
2024-07-15 22:07:47 | INFO | train_inner | epoch 012:   3548 / 14632 loss=4.578, nll_loss=3.191, ppl=9.13, wps=15234.3, ups=4.39, wpb=3472.9, bsz=120.2, num_updates=164500, lr=7.79681e-05, gnorm=1.388, train_wall=23, wall=0
2024-07-15 22:08:10 | INFO | train_inner | epoch 012:   3648 / 14632 loss=4.491, nll_loss=3.092, ppl=8.52, wps=15270.7, ups=4.3, wpb=3551.5, bsz=111.4, num_updates=164600, lr=7.79444e-05, gnorm=1.279, train_wall=23, wall=0
2024-07-15 22:08:33 | INFO | train_inner | epoch 012:   3748 / 14632 loss=4.502, nll_loss=3.104, ppl=8.6, wps=15193.1, ups=4.31, wpb=3529.1, bsz=127.4, num_updates=164700, lr=7.79208e-05, gnorm=1.336, train_wall=23, wall=0
2024-07-15 22:08:56 | INFO | train_inner | epoch 012:   3848 / 14632 loss=4.404, nll_loss=2.993, ppl=7.96, wps=15180.9, ups=4.34, wpb=3495.1, bsz=134.2, num_updates=164800, lr=7.78971e-05, gnorm=1.293, train_wall=23, wall=0
2024-07-15 22:09:19 | INFO | train_inner | epoch 012:   3948 / 14632 loss=4.609, nll_loss=3.225, ppl=9.35, wps=15462.9, ups=4.4, wpb=3510.7, bsz=111.2, num_updates=164900, lr=7.78735e-05, gnorm=1.355, train_wall=23, wall=0
2024-07-15 22:09:42 | INFO | train_inner | epoch 012:   4048 / 14632 loss=4.517, nll_loss=3.121, ppl=8.7, wps=15363.3, ups=4.39, wpb=3500.9, bsz=119.2, num_updates=165000, lr=7.78499e-05, gnorm=1.345, train_wall=23, wall=0
2024-07-15 22:09:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 22:09:44 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.478 | nll_loss 2.961 | ppl 7.79 | wps 42265.2 | wpb 2469 | bsz 83 | num_updates 165000 | best_loss 12.212
2024-07-15 22:09:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 22:09:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_12_165000.pt (epoch 12 @ 165000 updates, score 4.478) (writing took 4.511637051589787 seconds)
2024-07-15 22:10:11 | INFO | train_inner | epoch 012:   4148 / 14632 loss=4.601, nll_loss=3.218, ppl=9.3, wps=11810.2, ups=3.35, wpb=3523.9, bsz=120.7, num_updates=165100, lr=7.78263e-05, gnorm=1.358, train_wall=23, wall=0
2024-07-15 22:10:35 | INFO | train_inner | epoch 012:   4248 / 14632 loss=4.548, nll_loss=3.156, ppl=8.91, wps=14812, ups=4.21, wpb=3515.1, bsz=102.2, num_updates=165200, lr=7.78028e-05, gnorm=1.324, train_wall=24, wall=0
2024-07-15 22:10:58 | INFO | train_inner | epoch 012:   4348 / 14632 loss=4.555, nll_loss=3.165, ppl=8.97, wps=15143.2, ups=4.36, wpb=3470.1, bsz=116.3, num_updates=165300, lr=7.77792e-05, gnorm=1.37, train_wall=23, wall=0
2024-07-15 22:11:22 | INFO | train_inner | epoch 012:   4448 / 14632 loss=4.551, nll_loss=3.16, ppl=8.94, wps=14604.4, ups=4.2, wpb=3473.4, bsz=108.5, num_updates=165400, lr=7.77557e-05, gnorm=1.343, train_wall=24, wall=0
2024-07-15 22:11:45 | INFO | train_inner | epoch 012:   4548 / 14632 loss=4.562, nll_loss=3.172, ppl=9.01, wps=14983.3, ups=4.34, wpb=3448.9, bsz=110.5, num_updates=165500, lr=7.77322e-05, gnorm=1.324, train_wall=23, wall=0
2024-07-15 22:12:08 | INFO | train_inner | epoch 012:   4648 / 14632 loss=4.487, nll_loss=3.087, ppl=8.49, wps=15096.4, ups=4.32, wpb=3496.4, bsz=124.2, num_updates=165600, lr=7.77087e-05, gnorm=1.349, train_wall=23, wall=0
2024-07-15 22:12:31 | INFO | train_inner | epoch 012:   4748 / 14632 loss=4.5, nll_loss=3.103, ppl=8.59, wps=15122.7, ups=4.3, wpb=3512.9, bsz=132.4, num_updates=165700, lr=7.76853e-05, gnorm=1.317, train_wall=23, wall=0
2024-07-15 22:12:54 | INFO | train_inner | epoch 012:   4848 / 14632 loss=4.549, nll_loss=3.158, ppl=8.93, wps=15181.1, ups=4.35, wpb=3492, bsz=111.8, num_updates=165800, lr=7.76619e-05, gnorm=1.353, train_wall=23, wall=0
2024-07-15 22:13:17 | INFO | train_inner | epoch 012:   4948 / 14632 loss=4.464, nll_loss=3.061, ppl=8.34, wps=14890.1, ups=4.39, wpb=3395, bsz=139.5, num_updates=165900, lr=7.76384e-05, gnorm=1.341, train_wall=23, wall=0
2024-07-15 22:13:40 | INFO | train_inner | epoch 012:   5048 / 14632 loss=4.513, nll_loss=3.116, ppl=8.67, wps=14811.9, ups=4.34, wpb=3415.2, bsz=114.6, num_updates=166000, lr=7.76151e-05, gnorm=1.369, train_wall=23, wall=0
2024-07-15 22:13:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 22:13:42 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.477 | nll_loss 2.951 | ppl 7.73 | wps 42351.1 | wpb 2469 | bsz 83 | num_updates 166000 | best_loss 12.212
2024-07-15 22:13:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 22:13:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_12_166000.pt (epoch 12 @ 166000 updates, score 4.477) (writing took 4.883797754533589 seconds)
2024-07-15 22:14:11 | INFO | train_inner | epoch 012:   5148 / 14632 loss=4.507, nll_loss=3.11, ppl=8.63, wps=11074.2, ups=3.21, wpb=3452.7, bsz=127, num_updates=166100, lr=7.75917e-05, gnorm=1.335, train_wall=24, wall=0
2024-07-15 22:14:34 | INFO | train_inner | epoch 012:   5248 / 14632 loss=4.482, nll_loss=3.082, ppl=8.47, wps=15317.3, ups=4.33, wpb=3540.1, bsz=127.3, num_updates=166200, lr=7.75683e-05, gnorm=1.412, train_wall=23, wall=0
2024-07-15 22:14:57 | INFO | train_inner | epoch 012:   5348 / 14632 loss=4.564, nll_loss=3.174, ppl=9.03, wps=15300.9, ups=4.37, wpb=3499.4, bsz=113, num_updates=166300, lr=7.7545e-05, gnorm=1.388, train_wall=23, wall=0
2024-07-15 22:15:21 | INFO | train_inner | epoch 012:   5448 / 14632 loss=4.556, nll_loss=3.166, ppl=8.98, wps=14616.9, ups=4.24, wpb=3446.7, bsz=115, num_updates=166400, lr=7.75217e-05, gnorm=1.353, train_wall=23, wall=0
2024-07-15 22:15:44 | INFO | train_inner | epoch 012:   5548 / 14632 loss=4.544, nll_loss=3.153, ppl=8.89, wps=14830.6, ups=4.35, wpb=3406.6, bsz=111.3, num_updates=166500, lr=7.74984e-05, gnorm=1.326, train_wall=23, wall=0
2024-07-15 22:16:07 | INFO | train_inner | epoch 012:   5648 / 14632 loss=4.542, nll_loss=3.15, ppl=8.88, wps=15205, ups=4.34, wpb=3505.4, bsz=109.2, num_updates=166600, lr=7.74752e-05, gnorm=1.328, train_wall=23, wall=0
2024-07-15 22:16:30 | INFO | train_inner | epoch 012:   5748 / 14632 loss=4.549, nll_loss=3.159, ppl=8.93, wps=14806.2, ups=4.37, wpb=3387.2, bsz=123.6, num_updates=166700, lr=7.74519e-05, gnorm=1.411, train_wall=23, wall=0
2024-07-15 22:16:53 | INFO | train_inner | epoch 012:   5848 / 14632 loss=4.543, nll_loss=3.152, ppl=8.89, wps=14947, ups=4.37, wpb=3419.5, bsz=108.1, num_updates=166800, lr=7.74287e-05, gnorm=1.367, train_wall=23, wall=0
2024-07-15 22:17:16 | INFO | train_inner | epoch 012:   5948 / 14632 loss=4.507, nll_loss=3.109, ppl=8.63, wps=14795.9, ups=4.3, wpb=3436.9, bsz=101, num_updates=166900, lr=7.74055e-05, gnorm=1.352, train_wall=23, wall=0
2024-07-15 22:17:39 | INFO | train_inner | epoch 012:   6048 / 14632 loss=4.49, nll_loss=3.092, ppl=8.52, wps=14862.1, ups=4.29, wpb=3468.1, bsz=118.6, num_updates=167000, lr=7.73823e-05, gnorm=1.306, train_wall=23, wall=0
2024-07-15 22:17:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 22:17:42 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.471 | nll_loss 2.944 | ppl 7.7 | wps 42239.9 | wpb 2469 | bsz 83 | num_updates 167000 | best_loss 12.212
2024-07-15 22:17:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 22:17:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_12_167000.pt (epoch 12 @ 167000 updates, score 4.471) (writing took 5.0201810877770185 seconds)
2024-07-15 22:18:10 | INFO | train_inner | epoch 012:   6148 / 14632 loss=4.542, nll_loss=3.15, ppl=8.88, wps=11394.1, ups=3.25, wpb=3509.3, bsz=118.1, num_updates=167100, lr=7.73592e-05, gnorm=1.328, train_wall=23, wall=0
2024-07-15 22:18:33 | INFO | train_inner | epoch 012:   6248 / 14632 loss=4.548, nll_loss=3.158, ppl=8.92, wps=15127.4, ups=4.34, wpb=3486.6, bsz=103.3, num_updates=167200, lr=7.7336e-05, gnorm=1.332, train_wall=23, wall=0
2024-07-15 22:18:56 | INFO | train_inner | epoch 012:   6348 / 14632 loss=4.634, nll_loss=3.255, ppl=9.55, wps=15211.9, ups=4.38, wpb=3473.9, bsz=100.4, num_updates=167300, lr=7.73129e-05, gnorm=1.378, train_wall=23, wall=0
2024-07-15 22:19:19 | INFO | train_inner | epoch 012:   6448 / 14632 loss=4.546, nll_loss=3.155, ppl=8.91, wps=15242.1, ups=4.36, wpb=3492, bsz=113.5, num_updates=167400, lr=7.72898e-05, gnorm=1.366, train_wall=23, wall=0
2024-07-15 22:19:41 | INFO | train_inner | epoch 012:   6548 / 14632 loss=4.537, nll_loss=3.145, ppl=8.85, wps=15314, ups=4.4, wpb=3476.9, bsz=118.8, num_updates=167500, lr=7.72667e-05, gnorm=1.348, train_wall=23, wall=0
2024-07-15 22:20:04 | INFO | train_inner | epoch 012:   6648 / 14632 loss=4.551, nll_loss=3.162, ppl=8.95, wps=14893.1, ups=4.37, wpb=3406.8, bsz=120.1, num_updates=167600, lr=7.72437e-05, gnorm=1.395, train_wall=23, wall=0
2024-07-15 22:20:28 | INFO | train_inner | epoch 012:   6748 / 14632 loss=4.48, nll_loss=3.079, ppl=8.45, wps=14846.6, ups=4.24, wpb=3502.5, bsz=117.8, num_updates=167700, lr=7.72207e-05, gnorm=1.302, train_wall=23, wall=0
2024-07-15 22:20:51 | INFO | train_inner | epoch 012:   6848 / 14632 loss=4.459, nll_loss=3.056, ppl=8.32, wps=15406.1, ups=4.37, wpb=3529.3, bsz=127.8, num_updates=167800, lr=7.71976e-05, gnorm=1.318, train_wall=23, wall=0
2024-07-15 22:21:14 | INFO | train_inner | epoch 012:   6948 / 14632 loss=4.489, nll_loss=3.09, ppl=8.51, wps=15190.6, ups=4.34, wpb=3504, bsz=124.2, num_updates=167900, lr=7.71746e-05, gnorm=1.353, train_wall=23, wall=0
2024-07-15 22:21:37 | INFO | train_inner | epoch 012:   7048 / 14632 loss=4.53, nll_loss=3.137, ppl=8.8, wps=15158.6, ups=4.34, wpb=3491.4, bsz=120.3, num_updates=168000, lr=7.71517e-05, gnorm=1.379, train_wall=23, wall=0
2024-07-15 22:21:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 22:21:39 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.462 | nll_loss 2.935 | ppl 7.65 | wps 42254.5 | wpb 2469 | bsz 83 | num_updates 168000 | best_loss 12.212
2024-07-15 22:21:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 22:21:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_12_168000.pt (epoch 12 @ 168000 updates, score 4.462) (writing took 4.660397643223405 seconds)
2024-07-15 22:22:07 | INFO | train_inner | epoch 012:   7148 / 14632 loss=4.309, nll_loss=2.886, ppl=7.39, wps=11656.3, ups=3.31, wpb=3525.1, bsz=158.6, num_updates=168100, lr=7.71287e-05, gnorm=1.355, train_wall=23, wall=0
2024-07-15 22:22:30 | INFO | train_inner | epoch 012:   7248 / 14632 loss=4.536, nll_loss=3.144, ppl=8.84, wps=15176.8, ups=4.39, wpb=3460, bsz=142.3, num_updates=168200, lr=7.71058e-05, gnorm=1.365, train_wall=23, wall=0
2024-07-15 22:22:53 | INFO | train_inner | epoch 012:   7348 / 14632 loss=4.5, nll_loss=3.103, ppl=8.59, wps=15271.4, ups=4.27, wpb=3573.9, bsz=120.9, num_updates=168300, lr=7.70829e-05, gnorm=1.307, train_wall=23, wall=0
2024-07-15 22:23:17 | INFO | train_inner | epoch 012:   7448 / 14632 loss=4.522, nll_loss=3.127, ppl=8.74, wps=14842.9, ups=4.29, wpb=3456.4, bsz=111.8, num_updates=168400, lr=7.706e-05, gnorm=1.358, train_wall=23, wall=0
2024-07-15 22:23:40 | INFO | train_inner | epoch 012:   7548 / 14632 loss=4.501, nll_loss=3.104, ppl=8.6, wps=15090.2, ups=4.31, wpb=3503.4, bsz=136.5, num_updates=168500, lr=7.70371e-05, gnorm=1.366, train_wall=23, wall=0
2024-07-15 22:24:03 | INFO | train_inner | epoch 012:   7648 / 14632 loss=4.578, nll_loss=3.193, ppl=9.14, wps=15315.6, ups=4.37, wpb=3503.9, bsz=113.7, num_updates=168600, lr=7.70143e-05, gnorm=1.333, train_wall=23, wall=0
2024-07-15 22:24:26 | INFO | train_inner | epoch 012:   7748 / 14632 loss=4.542, nll_loss=3.151, ppl=8.88, wps=15113.4, ups=4.31, wpb=3509.1, bsz=121.6, num_updates=168700, lr=7.69914e-05, gnorm=1.319, train_wall=23, wall=0
2024-07-15 22:24:49 | INFO | train_inner | epoch 012:   7848 / 14632 loss=4.552, nll_loss=3.163, ppl=8.96, wps=15275.1, ups=4.33, wpb=3529.4, bsz=114.5, num_updates=168800, lr=7.69686e-05, gnorm=1.318, train_wall=23, wall=0
2024-07-15 22:25:12 | INFO | train_inner | epoch 012:   7948 / 14632 loss=4.45, nll_loss=3.046, ppl=8.26, wps=15075.1, ups=4.27, wpb=3529, bsz=146.8, num_updates=168900, lr=7.69458e-05, gnorm=1.377, train_wall=23, wall=0
2024-07-15 22:25:36 | INFO | train_inner | epoch 012:   8048 / 14632 loss=4.49, nll_loss=3.091, ppl=8.52, wps=15304.8, ups=4.32, wpb=3539.7, bsz=116.7, num_updates=169000, lr=7.69231e-05, gnorm=1.313, train_wall=23, wall=0
2024-07-15 22:25:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 22:25:38 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.461 | nll_loss 2.935 | ppl 7.65 | wps 42222.8 | wpb 2469 | bsz 83 | num_updates 169000 | best_loss 12.212
2024-07-15 22:25:38 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 22:25:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_12_169000.pt (epoch 12 @ 169000 updates, score 4.461) (writing took 5.552385828457773 seconds)
2024-07-15 22:26:07 | INFO | train_inner | epoch 012:   8148 / 14632 loss=4.475, nll_loss=3.074, ppl=8.42, wps=11285.3, ups=3.23, wpb=3490.9, bsz=116.5, num_updates=169100, lr=7.69003e-05, gnorm=1.335, train_wall=23, wall=0
2024-07-15 22:26:30 | INFO | train_inner | epoch 012:   8248 / 14632 loss=4.495, nll_loss=3.098, ppl=8.56, wps=15403.9, ups=4.32, wpb=3565, bsz=145, num_updates=169200, lr=7.68776e-05, gnorm=1.325, train_wall=23, wall=0
2024-07-15 22:26:53 | INFO | train_inner | epoch 012:   8348 / 14632 loss=4.548, nll_loss=3.157, ppl=8.92, wps=15165, ups=4.35, wpb=3483.1, bsz=113.9, num_updates=169300, lr=7.68549e-05, gnorm=1.362, train_wall=23, wall=0
2024-07-15 22:27:16 | INFO | train_inner | epoch 012:   8448 / 14632 loss=4.538, nll_loss=3.147, ppl=8.86, wps=15250.2, ups=4.36, wpb=3500.9, bsz=123.6, num_updates=169400, lr=7.68322e-05, gnorm=1.343, train_wall=23, wall=0
2024-07-15 22:27:39 | INFO | train_inner | epoch 012:   8548 / 14632 loss=4.446, nll_loss=3.041, ppl=8.23, wps=14907.8, ups=4.29, wpb=3475.4, bsz=132.2, num_updates=169500, lr=7.68095e-05, gnorm=1.354, train_wall=23, wall=0
2024-07-15 22:28:02 | INFO | train_inner | epoch 012:   8648 / 14632 loss=4.585, nll_loss=3.2, ppl=9.19, wps=14839.8, ups=4.26, wpb=3482.5, bsz=105.6, num_updates=169600, lr=7.67869e-05, gnorm=1.383, train_wall=23, wall=0
2024-07-15 22:28:26 | INFO | train_inner | epoch 012:   8748 / 14632 loss=4.471, nll_loss=3.07, ppl=8.4, wps=14803.1, ups=4.3, wpb=3439.1, bsz=112.6, num_updates=169700, lr=7.67643e-05, gnorm=1.323, train_wall=23, wall=0
2024-07-15 22:28:49 | INFO | train_inner | epoch 012:   8848 / 14632 loss=4.49, nll_loss=3.091, ppl=8.52, wps=15225.5, ups=4.3, wpb=3542.1, bsz=114, num_updates=169800, lr=7.67417e-05, gnorm=1.316, train_wall=23, wall=0
2024-07-15 22:29:12 | INFO | train_inner | epoch 012:   8948 / 14632 loss=4.537, nll_loss=3.146, ppl=8.85, wps=14822, ups=4.34, wpb=3414.9, bsz=116.7, num_updates=169900, lr=7.67191e-05, gnorm=1.367, train_wall=23, wall=0
2024-07-15 22:29:35 | INFO | train_inner | epoch 012:   9048 / 14632 loss=4.51, nll_loss=3.114, ppl=8.66, wps=15621.2, ups=4.37, wpb=3574.3, bsz=124.8, num_updates=170000, lr=7.66965e-05, gnorm=1.334, train_wall=23, wall=0
2024-07-15 22:29:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 22:29:37 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.452 | nll_loss 2.926 | ppl 7.6 | wps 42375.2 | wpb 2469 | bsz 83 | num_updates 170000 | best_loss 12.212
2024-07-15 22:29:37 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 22:29:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_12_170000.pt (epoch 12 @ 170000 updates, score 4.452) (writing took 4.204945074394345 seconds)
2024-07-15 22:30:05 | INFO | train_inner | epoch 012:   9148 / 14632 loss=4.477, nll_loss=3.077, ppl=8.44, wps=11696.8, ups=3.36, wpb=3476.2, bsz=124.7, num_updates=170100, lr=7.6674e-05, gnorm=1.351, train_wall=23, wall=0
2024-07-15 22:30:28 | INFO | train_inner | epoch 012:   9248 / 14632 loss=4.487, nll_loss=3.089, ppl=8.51, wps=15109.9, ups=4.35, wpb=3472.7, bsz=122.2, num_updates=170200, lr=7.66514e-05, gnorm=1.343, train_wall=23, wall=0
2024-07-15 22:30:51 | INFO | train_inner | epoch 012:   9348 / 14632 loss=4.555, nll_loss=3.165, ppl=8.97, wps=14821, ups=4.28, wpb=3459.5, bsz=114.2, num_updates=170300, lr=7.66289e-05, gnorm=1.379, train_wall=23, wall=0
2024-07-15 22:31:15 | INFO | train_inner | epoch 012:   9448 / 14632 loss=4.535, nll_loss=3.144, ppl=8.84, wps=14442.6, ups=4.22, wpb=3419.4, bsz=115.4, num_updates=170400, lr=7.66064e-05, gnorm=1.407, train_wall=23, wall=0
2024-07-15 22:31:39 | INFO | train_inner | epoch 012:   9548 / 14632 loss=4.457, nll_loss=3.054, ppl=8.31, wps=14642.6, ups=4.15, wpb=3527.8, bsz=117.6, num_updates=170500, lr=7.6584e-05, gnorm=1.329, train_wall=24, wall=0
2024-07-15 22:32:02 | INFO | train_inner | epoch 012:   9648 / 14632 loss=4.531, nll_loss=3.139, ppl=8.81, wps=15454.8, ups=4.34, wpb=3561.2, bsz=114.4, num_updates=170600, lr=7.65615e-05, gnorm=1.334, train_wall=23, wall=0
2024-07-15 22:32:25 | INFO | train_inner | epoch 012:   9748 / 14632 loss=4.505, nll_loss=3.11, ppl=8.63, wps=14552.9, ups=4.25, wpb=3425.6, bsz=120.6, num_updates=170700, lr=7.65391e-05, gnorm=1.368, train_wall=23, wall=0
2024-07-15 22:32:48 | INFO | train_inner | epoch 012:   9848 / 14632 loss=4.56, nll_loss=3.171, ppl=9.01, wps=15193.5, ups=4.4, wpb=3455.2, bsz=134.4, num_updates=170800, lr=7.65167e-05, gnorm=1.379, train_wall=23, wall=0
2024-07-15 22:33:11 | INFO | train_inner | epoch 012:   9948 / 14632 loss=4.52, nll_loss=3.127, ppl=8.74, wps=15166.5, ups=4.36, wpb=3474.6, bsz=127, num_updates=170900, lr=7.64943e-05, gnorm=1.345, train_wall=23, wall=0
2024-07-15 22:33:35 | INFO | train_inner | epoch 012:  10048 / 14632 loss=4.445, nll_loss=3.042, ppl=8.23, wps=14204.1, ups=4.17, wpb=3403.9, bsz=109.1, num_updates=171000, lr=7.64719e-05, gnorm=1.343, train_wall=24, wall=0
2024-07-15 22:33:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 22:33:37 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.427 | nll_loss 2.902 | ppl 7.47 | wps 42206.6 | wpb 2469 | bsz 83 | num_updates 171000 | best_loss 12.212
2024-07-15 22:33:37 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 22:33:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_12_171000.pt (epoch 12 @ 171000 updates, score 4.427) (writing took 5.153754792176187 seconds)
2024-07-15 22:34:06 | INFO | train_inner | epoch 012:  10148 / 14632 loss=4.468, nll_loss=3.067, ppl=8.38, wps=11593, ups=3.24, wpb=3580.6, bsz=135.8, num_updates=171100, lr=7.64496e-05, gnorm=1.309, train_wall=23, wall=0
2024-07-15 22:34:29 | INFO | train_inner | epoch 012:  10248 / 14632 loss=4.532, nll_loss=3.139, ppl=8.81, wps=15334.4, ups=4.3, wpb=3564.6, bsz=113.4, num_updates=171200, lr=7.64272e-05, gnorm=1.315, train_wall=23, wall=0
2024-07-15 22:34:52 | INFO | train_inner | epoch 012:  10348 / 14632 loss=4.555, nll_loss=3.167, ppl=8.98, wps=15041, ups=4.35, wpb=3455.7, bsz=110, num_updates=171300, lr=7.64049e-05, gnorm=1.367, train_wall=23, wall=0
2024-07-15 22:35:15 | INFO | train_inner | epoch 012:  10448 / 14632 loss=4.538, nll_loss=3.146, ppl=8.85, wps=15164.4, ups=4.36, wpb=3478.9, bsz=105.2, num_updates=171400, lr=7.63826e-05, gnorm=1.33, train_wall=23, wall=0
2024-07-15 22:35:38 | INFO | train_inner | epoch 012:  10548 / 14632 loss=4.465, nll_loss=3.063, ppl=8.36, wps=15603.2, ups=4.32, wpb=3607.7, bsz=131.6, num_updates=171500, lr=7.63604e-05, gnorm=1.281, train_wall=23, wall=0
2024-07-15 22:36:01 | INFO | train_inner | epoch 012:  10648 / 14632 loss=4.504, nll_loss=3.108, ppl=8.62, wps=14580.1, ups=4.28, wpb=3405.8, bsz=109.6, num_updates=171600, lr=7.63381e-05, gnorm=1.345, train_wall=23, wall=0
2024-07-15 22:36:25 | INFO | train_inner | epoch 012:  10748 / 14632 loss=4.59, nll_loss=3.206, ppl=9.23, wps=14803.2, ups=4.29, wpb=3452.8, bsz=96.6, num_updates=171700, lr=7.63159e-05, gnorm=1.365, train_wall=23, wall=0
2024-07-15 22:36:48 | INFO | train_inner | epoch 012:  10848 / 14632 loss=4.504, nll_loss=3.107, ppl=8.62, wps=15031.5, ups=4.37, wpb=3441.6, bsz=103.9, num_updates=171800, lr=7.62937e-05, gnorm=1.373, train_wall=23, wall=0
2024-07-15 22:37:10 | INFO | train_inner | epoch 012:  10948 / 14632 loss=4.528, nll_loss=3.136, ppl=8.79, wps=15115.4, ups=4.37, wpb=3458.3, bsz=107, num_updates=171900, lr=7.62715e-05, gnorm=1.347, train_wall=23, wall=0
2024-07-15 22:37:33 | INFO | train_inner | epoch 012:  11048 / 14632 loss=4.429, nll_loss=3.023, ppl=8.13, wps=15332.2, ups=4.37, wpb=3507.9, bsz=128.1, num_updates=172000, lr=7.62493e-05, gnorm=1.305, train_wall=23, wall=0
2024-07-15 22:37:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 22:37:36 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.45 | nll_loss 2.92 | ppl 7.57 | wps 42354.9 | wpb 2469 | bsz 83 | num_updates 172000 | best_loss 12.212
2024-07-15 22:37:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 22:37:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_12_172000.pt (epoch 12 @ 172000 updates, score 4.45) (writing took 4.654793318361044 seconds)
2024-07-15 22:38:03 | INFO | train_inner | epoch 012:  11148 / 14632 loss=4.509, nll_loss=3.114, ppl=8.66, wps=11339.6, ups=3.35, wpb=3388.7, bsz=115.6, num_updates=172100, lr=7.62271e-05, gnorm=1.37, train_wall=23, wall=0
2024-07-15 22:38:26 | INFO | train_inner | epoch 012:  11248 / 14632 loss=4.441, nll_loss=3.037, ppl=8.21, wps=14894.3, ups=4.34, wpb=3433.1, bsz=119.4, num_updates=172200, lr=7.6205e-05, gnorm=1.314, train_wall=23, wall=0
2024-07-15 22:38:50 | INFO | train_inner | epoch 012:  11348 / 14632 loss=4.448, nll_loss=3.045, ppl=8.25, wps=14484.8, ups=4.15, wpb=3488.4, bsz=125.8, num_updates=172300, lr=7.61829e-05, gnorm=1.323, train_wall=24, wall=0
2024-07-15 22:39:13 | INFO | train_inner | epoch 012:  11448 / 14632 loss=4.526, nll_loss=3.134, ppl=8.78, wps=15126.8, ups=4.36, wpb=3467.7, bsz=104.9, num_updates=172400, lr=7.61608e-05, gnorm=1.355, train_wall=23, wall=0
2024-07-15 22:39:37 | INFO | train_inner | epoch 012:  11548 / 14632 loss=4.487, nll_loss=3.089, ppl=8.51, wps=15144, ups=4.28, wpb=3539.5, bsz=117.8, num_updates=172500, lr=7.61387e-05, gnorm=1.333, train_wall=23, wall=0
2024-07-15 22:40:00 | INFO | train_inner | epoch 012:  11648 / 14632 loss=4.539, nll_loss=3.149, ppl=8.87, wps=14858.3, ups=4.3, wpb=3453.3, bsz=128.7, num_updates=172600, lr=7.61166e-05, gnorm=1.418, train_wall=23, wall=0
2024-07-15 22:40:24 | INFO | train_inner | epoch 012:  11748 / 14632 loss=4.493, nll_loss=3.097, ppl=8.56, wps=14649.4, ups=4.22, wpb=3468.4, bsz=126.2, num_updates=172700, lr=7.60946e-05, gnorm=1.374, train_wall=24, wall=0
2024-07-15 22:40:47 | INFO | train_inner | epoch 012:  11848 / 14632 loss=4.396, nll_loss=2.987, ppl=7.93, wps=14865.2, ups=4.33, wpb=3430.2, bsz=130.8, num_updates=172800, lr=7.60726e-05, gnorm=1.377, train_wall=23, wall=0
2024-07-15 22:41:09 | INFO | train_inner | epoch 012:  11948 / 14632 loss=4.447, nll_loss=3.045, ppl=8.25, wps=14984.8, ups=4.39, wpb=3416.1, bsz=122.1, num_updates=172900, lr=7.60506e-05, gnorm=1.359, train_wall=23, wall=0
2024-07-15 22:41:33 | INFO | train_inner | epoch 012:  12048 / 14632 loss=4.498, nll_loss=3.102, ppl=8.59, wps=15013.9, ups=4.32, wpb=3474.4, bsz=117.8, num_updates=173000, lr=7.60286e-05, gnorm=1.328, train_wall=23, wall=0
2024-07-15 22:41:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 22:41:35 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.436 | nll_loss 2.91 | ppl 7.52 | wps 42300 | wpb 2469 | bsz 83 | num_updates 173000 | best_loss 12.212
2024-07-15 22:41:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 22:41:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_12_173000.pt (epoch 12 @ 173000 updates, score 4.436) (writing took 5.597889665514231 seconds)
2024-07-15 22:42:03 | INFO | train_inner | epoch 012:  12148 / 14632 loss=4.5, nll_loss=3.104, ppl=8.6, wps=10887, ups=3.25, wpb=3350.8, bsz=121, num_updates=173100, lr=7.60066e-05, gnorm=1.39, train_wall=23, wall=0
2024-07-15 22:42:27 | INFO | train_inner | epoch 012:  12248 / 14632 loss=4.455, nll_loss=3.051, ppl=8.29, wps=15192.4, ups=4.32, wpb=3516, bsz=112.8, num_updates=173200, lr=7.59847e-05, gnorm=1.305, train_wall=23, wall=0
2024-07-15 22:42:50 | INFO | train_inner | epoch 012:  12348 / 14632 loss=4.486, nll_loss=3.089, ppl=8.51, wps=15167.5, ups=4.35, wpb=3488.8, bsz=115.7, num_updates=173300, lr=7.59628e-05, gnorm=1.336, train_wall=23, wall=0
2024-07-15 22:43:13 | INFO | train_inner | epoch 012:  12448 / 14632 loss=4.483, nll_loss=3.084, ppl=8.48, wps=15200, ups=4.31, wpb=3528.4, bsz=114.9, num_updates=173400, lr=7.59408e-05, gnorm=1.334, train_wall=23, wall=0
2024-07-15 22:43:36 | INFO | train_inner | epoch 012:  12548 / 14632 loss=4.474, nll_loss=3.074, ppl=8.42, wps=15067.3, ups=4.35, wpb=3465.5, bsz=110.6, num_updates=173500, lr=7.5919e-05, gnorm=1.359, train_wall=23, wall=0
2024-07-15 22:43:59 | INFO | train_inner | epoch 012:  12648 / 14632 loss=4.571, nll_loss=3.184, ppl=9.09, wps=14894.1, ups=4.39, wpb=3391.5, bsz=105.1, num_updates=173600, lr=7.58971e-05, gnorm=1.379, train_wall=23, wall=0
2024-07-15 22:44:22 | INFO | train_inner | epoch 012:  12748 / 14632 loss=4.55, nll_loss=3.16, ppl=8.94, wps=14913.9, ups=4.31, wpb=3463.8, bsz=108.2, num_updates=173700, lr=7.58752e-05, gnorm=1.381, train_wall=23, wall=0
2024-07-15 22:44:45 | INFO | train_inner | epoch 012:  12848 / 14632 loss=4.461, nll_loss=3.061, ppl=8.34, wps=15138.6, ups=4.35, wpb=3481.1, bsz=112.6, num_updates=173800, lr=7.58534e-05, gnorm=1.353, train_wall=23, wall=0
2024-07-15 22:45:08 | INFO | train_inner | epoch 012:  12948 / 14632 loss=4.513, nll_loss=3.118, ppl=8.68, wps=15118.6, ups=4.3, wpb=3517.9, bsz=110.6, num_updates=173900, lr=7.58316e-05, gnorm=1.37, train_wall=23, wall=0
2024-07-15 22:45:32 | INFO | train_inner | epoch 012:  13048 / 14632 loss=4.553, nll_loss=3.164, ppl=8.97, wps=14468.1, ups=4.2, wpb=3442.2, bsz=109.1, num_updates=174000, lr=7.58098e-05, gnorm=1.366, train_wall=24, wall=0
2024-07-15 22:45:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 22:45:34 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.42 | nll_loss 2.887 | ppl 7.4 | wps 42255.3 | wpb 2469 | bsz 83 | num_updates 174000 | best_loss 12.212
2024-07-15 22:45:34 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 22:45:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_12_174000.pt (epoch 12 @ 174000 updates, score 4.42) (writing took 4.879733894020319 seconds)
2024-07-15 22:46:02 | INFO | train_inner | epoch 012:  13148 / 14632 loss=4.471, nll_loss=3.073, ppl=8.42, wps=11400.8, ups=3.28, wpb=3472.4, bsz=115, num_updates=174100, lr=7.5788e-05, gnorm=1.439, train_wall=23, wall=0
2024-07-15 22:46:26 | INFO | train_inner | epoch 012:  13248 / 14632 loss=4.465, nll_loss=3.065, ppl=8.37, wps=15360.4, ups=4.29, wpb=3580.2, bsz=134.9, num_updates=174200, lr=7.57663e-05, gnorm=1.326, train_wall=23, wall=0
2024-07-15 22:46:49 | INFO | train_inner | epoch 012:  13348 / 14632 loss=4.514, nll_loss=3.12, ppl=8.69, wps=15479.5, ups=4.32, wpb=3581.2, bsz=115.4, num_updates=174300, lr=7.57445e-05, gnorm=1.306, train_wall=23, wall=0
2024-07-15 22:47:12 | INFO | train_inner | epoch 012:  13448 / 14632 loss=4.439, nll_loss=3.034, ppl=8.19, wps=15309.8, ups=4.31, wpb=3554, bsz=133, num_updates=174400, lr=7.57228e-05, gnorm=1.307, train_wall=23, wall=0
2024-07-15 22:47:35 | INFO | train_inner | epoch 012:  13548 / 14632 loss=4.529, nll_loss=3.137, ppl=8.8, wps=14953.4, ups=4.34, wpb=3442, bsz=109.6, num_updates=174500, lr=7.57011e-05, gnorm=1.39, train_wall=23, wall=0
2024-07-15 22:47:58 | INFO | train_inner | epoch 012:  13648 / 14632 loss=4.464, nll_loss=3.064, ppl=8.37, wps=15106.2, ups=4.31, wpb=3502.2, bsz=117.8, num_updates=174600, lr=7.56794e-05, gnorm=1.299, train_wall=23, wall=0
2024-07-15 22:48:21 | INFO | train_inner | epoch 012:  13748 / 14632 loss=4.481, nll_loss=3.082, ppl=8.47, wps=15043.4, ups=4.37, wpb=3442, bsz=112.1, num_updates=174700, lr=7.56578e-05, gnorm=1.384, train_wall=23, wall=0
2024-07-15 22:48:44 | INFO | train_inner | epoch 012:  13848 / 14632 loss=4.532, nll_loss=3.141, ppl=8.82, wps=15045.1, ups=4.26, wpb=3531.3, bsz=110.1, num_updates=174800, lr=7.56361e-05, gnorm=1.335, train_wall=23, wall=0
2024-07-15 22:49:08 | INFO | train_inner | epoch 012:  13948 / 14632 loss=4.488, nll_loss=3.091, ppl=8.52, wps=14810.9, ups=4.19, wpb=3538.9, bsz=123.2, num_updates=174900, lr=7.56145e-05, gnorm=1.326, train_wall=24, wall=0
2024-07-15 22:49:32 | INFO | train_inner | epoch 012:  14048 / 14632 loss=4.477, nll_loss=3.078, ppl=8.44, wps=15017.5, ups=4.3, wpb=3496.4, bsz=104.2, num_updates=175000, lr=7.55929e-05, gnorm=1.343, train_wall=23, wall=0
2024-07-15 22:49:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 22:49:34 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.407 | nll_loss 2.878 | ppl 7.35 | wps 42402.3 | wpb 2469 | bsz 83 | num_updates 175000 | best_loss 12.212
2024-07-15 22:49:34 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 22:49:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_12_175000.pt (epoch 12 @ 175000 updates, score 4.407) (writing took 4.501242451369762 seconds)
2024-07-15 22:50:02 | INFO | train_inner | epoch 012:  14148 / 14632 loss=4.437, nll_loss=3.032, ppl=8.18, wps=11746.7, ups=3.34, wpb=3516.7, bsz=117.2, num_updates=175100, lr=7.55713e-05, gnorm=1.32, train_wall=23, wall=0
2024-07-15 22:50:25 | INFO | train_inner | epoch 012:  14248 / 14632 loss=4.487, nll_loss=3.091, ppl=8.52, wps=15132.1, ups=4.33, wpb=3491.2, bsz=117.8, num_updates=175200, lr=7.55497e-05, gnorm=1.339, train_wall=23, wall=0
2024-07-15 22:50:48 | INFO | train_inner | epoch 012:  14348 / 14632 loss=4.535, nll_loss=3.144, ppl=8.84, wps=15410.6, ups=4.34, wpb=3554.1, bsz=107.3, num_updates=175300, lr=7.55282e-05, gnorm=1.325, train_wall=23, wall=0
2024-07-15 22:51:11 | INFO | train_inner | epoch 012:  14448 / 14632 loss=4.519, nll_loss=3.126, ppl=8.73, wps=15476, ups=4.35, wpb=3559, bsz=117.5, num_updates=175400, lr=7.55067e-05, gnorm=1.367, train_wall=23, wall=0
2024-07-15 22:51:34 | INFO | train_inner | epoch 012:  14548 / 14632 loss=4.529, nll_loss=3.138, ppl=8.8, wps=15072.6, ups=4.37, wpb=3448.6, bsz=109.4, num_updates=175500, lr=7.54851e-05, gnorm=1.352, train_wall=23, wall=0
2024-07-15 22:51:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 22:51:55 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.395 | nll_loss 2.865 | ppl 7.29 | wps 42243.6 | wpb 2469 | bsz 83 | num_updates 175584 | best_loss 12.212
2024-07-15 22:51:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 22:51:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 12 @ 175584 updates, score 4.395) (writing took 3.9461141293868423 seconds)
2024-07-15 22:51:59 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2024-07-15 22:51:59 | INFO | train | epoch 012 | loss 4.518 | nll_loss 3.123 | ppl 8.71 | wps 14554.6 | ups 4.18 | wpb 3483.6 | bsz 118.4 | num_updates 175584 | lr 7.54671e-05 | gnorm 1.348 | train_wall 3362 | wall 0
2024-07-15 22:51:59 | INFO | fairseq.trainer | begin training epoch 13
2024-07-15 22:52:03 | INFO | train_inner | epoch 013:     16 / 14632 loss=4.395, nll_loss=2.986, ppl=7.92, wps=11743.3, ups=3.38, wpb=3473.6, bsz=137, num_updates=175600, lr=7.54636e-05, gnorm=1.346, train_wall=23, wall=0
2024-07-15 22:52:27 | INFO | train_inner | epoch 013:    116 / 14632 loss=4.428, nll_loss=3.022, ppl=8.12, wps=14483.8, ups=4.12, wpb=3511.3, bsz=111.9, num_updates=175700, lr=7.54422e-05, gnorm=1.334, train_wall=24, wall=0
2024-07-15 22:52:51 | INFO | train_inner | epoch 013:    216 / 14632 loss=4.443, nll_loss=3.039, ppl=8.22, wps=14866.4, ups=4.33, wpb=3434.4, bsz=111.4, num_updates=175800, lr=7.54207e-05, gnorm=1.352, train_wall=23, wall=0
2024-07-15 22:53:13 | INFO | train_inner | epoch 013:    316 / 14632 loss=4.456, nll_loss=3.054, ppl=8.31, wps=14850.8, ups=4.37, wpb=3397, bsz=120.3, num_updates=175900, lr=7.53993e-05, gnorm=1.341, train_wall=23, wall=0
2024-07-15 22:53:36 | INFO | train_inner | epoch 013:    416 / 14632 loss=4.475, nll_loss=3.075, ppl=8.43, wps=15135.2, ups=4.38, wpb=3458.6, bsz=106.3, num_updates=176000, lr=7.53778e-05, gnorm=1.355, train_wall=23, wall=0
2024-07-15 22:53:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 22:53:39 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.414 | nll_loss 2.881 | ppl 7.37 | wps 42019 | wpb 2469 | bsz 83 | num_updates 176000 | best_loss 12.212
2024-07-15 22:53:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 22:53:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_13_176000.pt (epoch 13 @ 176000 updates, score 4.414) (writing took 5.49040587618947 seconds)
2024-07-15 22:54:08 | INFO | train_inner | epoch 013:    516 / 14632 loss=4.474, nll_loss=3.074, ppl=8.42, wps=11175.7, ups=3.18, wpb=3514, bsz=112.4, num_updates=176100, lr=7.53564e-05, gnorm=1.317, train_wall=23, wall=0
2024-07-15 22:54:31 | INFO | train_inner | epoch 013:    616 / 14632 loss=4.405, nll_loss=2.996, ppl=7.98, wps=15193.9, ups=4.36, wpb=3481.9, bsz=133.4, num_updates=176200, lr=7.5335e-05, gnorm=1.314, train_wall=23, wall=0
2024-07-15 22:54:54 | INFO | train_inner | epoch 013:    716 / 14632 loss=4.344, nll_loss=2.926, ppl=7.6, wps=14735, ups=4.22, wpb=3493.1, bsz=136.5, num_updates=176300, lr=7.53137e-05, gnorm=1.299, train_wall=24, wall=0
2024-07-15 22:55:18 | INFO | train_inner | epoch 013:    816 / 14632 loss=4.454, nll_loss=3.052, ppl=8.29, wps=14744, ups=4.17, wpb=3532.2, bsz=121.6, num_updates=176400, lr=7.52923e-05, gnorm=1.31, train_wall=24, wall=0
2024-07-15 22:55:41 | INFO | train_inner | epoch 013:    916 / 14632 loss=4.417, nll_loss=3.01, ppl=8.06, wps=15304.9, ups=4.33, wpb=3535.3, bsz=125.7, num_updates=176500, lr=7.5271e-05, gnorm=1.32, train_wall=23, wall=0
2024-07-15 22:56:04 | INFO | train_inner | epoch 013:   1016 / 14632 loss=4.553, nll_loss=3.164, ppl=8.96, wps=15073.8, ups=4.44, wpb=3393.4, bsz=114.9, num_updates=176600, lr=7.52497e-05, gnorm=1.416, train_wall=22, wall=0
2024-07-15 22:56:27 | INFO | train_inner | epoch 013:   1116 / 14632 loss=4.358, nll_loss=2.942, ppl=7.69, wps=15472.3, ups=4.34, wpb=3567.7, bsz=140.6, num_updates=176700, lr=7.52284e-05, gnorm=1.303, train_wall=23, wall=0
2024-07-15 22:56:50 | INFO | train_inner | epoch 013:   1216 / 14632 loss=4.44, nll_loss=3.035, ppl=8.2, wps=14905, ups=4.28, wpb=3478.8, bsz=116.1, num_updates=176800, lr=7.52071e-05, gnorm=1.38, train_wall=23, wall=0
2024-07-15 22:57:13 | INFO | train_inner | epoch 013:   1316 / 14632 loss=4.457, nll_loss=3.055, ppl=8.31, wps=15342.9, ups=4.35, wpb=3529.8, bsz=124.4, num_updates=176900, lr=7.51858e-05, gnorm=1.356, train_wall=23, wall=0
2024-07-15 22:57:36 | INFO | train_inner | epoch 013:   1416 / 14632 loss=4.491, nll_loss=3.094, ppl=8.54, wps=15226.4, ups=4.37, wpb=3486.6, bsz=105.4, num_updates=177000, lr=7.51646e-05, gnorm=1.333, train_wall=23, wall=0
2024-07-15 22:57:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 22:57:39 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.395 | nll_loss 2.864 | ppl 7.28 | wps 42042.9 | wpb 2469 | bsz 83 | num_updates 177000 | best_loss 12.212
2024-07-15 22:57:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 22:57:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_13_177000.pt (epoch 13 @ 177000 updates, score 4.395) (writing took 6.075986661016941 seconds)
2024-07-15 22:58:08 | INFO | train_inner | epoch 013:   1516 / 14632 loss=4.543, nll_loss=3.154, ppl=8.9, wps=11044.2, ups=3.19, wpb=3465.3, bsz=101.8, num_updates=177100, lr=7.51434e-05, gnorm=1.367, train_wall=23, wall=0
2024-07-15 22:58:31 | INFO | train_inner | epoch 013:   1616 / 14632 loss=4.417, nll_loss=3.009, ppl=8.05, wps=14999.7, ups=4.3, wpb=3490.5, bsz=114.8, num_updates=177200, lr=7.51222e-05, gnorm=1.313, train_wall=23, wall=0
2024-07-15 22:58:55 | INFO | train_inner | epoch 013:   1716 / 14632 loss=4.401, nll_loss=2.991, ppl=7.95, wps=14743.5, ups=4.2, wpb=3510.4, bsz=115.6, num_updates=177300, lr=7.5101e-05, gnorm=1.291, train_wall=24, wall=0
2024-07-15 22:59:18 | INFO | train_inner | epoch 013:   1816 / 14632 loss=4.42, nll_loss=3.013, ppl=8.07, wps=14907.6, ups=4.3, wpb=3468.6, bsz=125.8, num_updates=177400, lr=7.50798e-05, gnorm=1.343, train_wall=23, wall=0
2024-07-15 22:59:41 | INFO | train_inner | epoch 013:   1916 / 14632 loss=4.406, nll_loss=2.997, ppl=7.98, wps=14921.6, ups=4.32, wpb=3454.3, bsz=119.3, num_updates=177500, lr=7.50587e-05, gnorm=1.332, train_wall=23, wall=0
2024-07-15 23:00:04 | INFO | train_inner | epoch 013:   2016 / 14632 loss=4.399, nll_loss=2.99, ppl=7.94, wps=15203.7, ups=4.31, wpb=3525.6, bsz=131, num_updates=177600, lr=7.50375e-05, gnorm=1.29, train_wall=23, wall=0
2024-07-15 23:00:28 | INFO | train_inner | epoch 013:   2116 / 14632 loss=4.502, nll_loss=3.107, ppl=8.61, wps=14999.7, ups=4.29, wpb=3493.4, bsz=112.7, num_updates=177700, lr=7.50164e-05, gnorm=1.353, train_wall=23, wall=0
2024-07-15 23:00:51 | INFO | train_inner | epoch 013:   2216 / 14632 loss=4.383, nll_loss=2.972, ppl=7.84, wps=14969.1, ups=4.21, wpb=3558.8, bsz=115.8, num_updates=177800, lr=7.49953e-05, gnorm=1.303, train_wall=24, wall=0
2024-07-15 23:01:14 | INFO | train_inner | epoch 013:   2316 / 14632 loss=4.462, nll_loss=3.062, ppl=8.35, wps=14989.2, ups=4.34, wpb=3455.3, bsz=121.6, num_updates=177900, lr=7.49742e-05, gnorm=1.342, train_wall=23, wall=0
2024-07-15 23:01:37 | INFO | train_inner | epoch 013:   2416 / 14632 loss=4.451, nll_loss=3.049, ppl=8.27, wps=15018.5, ups=4.33, wpb=3468.9, bsz=109.9, num_updates=178000, lr=7.49532e-05, gnorm=1.334, train_wall=23, wall=0
2024-07-15 23:01:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 23:01:40 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.406 | nll_loss 2.88 | ppl 7.36 | wps 42098.3 | wpb 2469 | bsz 83 | num_updates 178000 | best_loss 12.212
2024-07-15 23:01:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 23:01:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_13_178000.pt (epoch 13 @ 178000 updates, score 4.406) (writing took 8.045818344689906 seconds)
2024-07-15 23:02:11 | INFO | train_inner | epoch 013:   2516 / 14632 loss=4.424, nll_loss=3.017, ppl=8.09, wps=10340.4, ups=2.95, wpb=3510.7, bsz=112.6, num_updates=178100, lr=7.49321e-05, gnorm=1.313, train_wall=23, wall=0
2024-07-15 23:02:35 | INFO | train_inner | epoch 013:   2616 / 14632 loss=4.424, nll_loss=3.018, ppl=8.1, wps=15208.2, ups=4.24, wpb=3587.7, bsz=122.6, num_updates=178200, lr=7.49111e-05, gnorm=1.31, train_wall=23, wall=0
2024-07-15 23:02:58 | INFO | train_inner | epoch 013:   2716 / 14632 loss=4.439, nll_loss=3.036, ppl=8.2, wps=14909.6, ups=4.35, wpb=3429.7, bsz=123.8, num_updates=178300, lr=7.48901e-05, gnorm=1.34, train_wall=23, wall=0
2024-07-15 23:03:21 | INFO | train_inner | epoch 013:   2816 / 14632 loss=4.465, nll_loss=3.066, ppl=8.37, wps=15315.9, ups=4.38, wpb=3495, bsz=120, num_updates=178400, lr=7.48691e-05, gnorm=1.361, train_wall=23, wall=0
2024-07-15 23:03:43 | INFO | train_inner | epoch 013:   2916 / 14632 loss=4.457, nll_loss=3.056, ppl=8.32, wps=15952.7, ups=4.44, wpb=3591.7, bsz=130.1, num_updates=178500, lr=7.48481e-05, gnorm=1.321, train_wall=22, wall=0
2024-07-15 23:04:06 | INFO | train_inner | epoch 013:   3016 / 14632 loss=4.481, nll_loss=3.083, ppl=8.47, wps=15436.8, ups=4.45, wpb=3467.2, bsz=125, num_updates=178600, lr=7.48272e-05, gnorm=1.377, train_wall=22, wall=0
2024-07-15 23:04:29 | INFO | train_inner | epoch 013:   3116 / 14632 loss=4.41, nll_loss=3.004, ppl=8.02, wps=15573.6, ups=4.39, wpb=3547.9, bsz=134.9, num_updates=178700, lr=7.48062e-05, gnorm=1.324, train_wall=23, wall=0
2024-07-15 23:04:52 | INFO | train_inner | epoch 013:   3216 / 14632 loss=4.495, nll_loss=3.098, ppl=8.56, wps=14887.6, ups=4.2, wpb=3543.8, bsz=110.8, num_updates=178800, lr=7.47853e-05, gnorm=1.331, train_wall=24, wall=0
2024-07-15 23:05:16 | INFO | train_inner | epoch 013:   3316 / 14632 loss=4.4, nll_loss=2.992, ppl=7.95, wps=14577.4, ups=4.3, wpb=3388.4, bsz=134.3, num_updates=178900, lr=7.47644e-05, gnorm=1.42, train_wall=23, wall=0
2024-07-15 23:05:39 | INFO | train_inner | epoch 013:   3416 / 14632 loss=4.486, nll_loss=3.088, ppl=8.51, wps=15165.7, ups=4.35, wpb=3487, bsz=97.5, num_updates=179000, lr=7.47435e-05, gnorm=1.338, train_wall=23, wall=0
2024-07-15 23:05:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 23:05:41 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.388 | nll_loss 2.857 | ppl 7.24 | wps 42338.4 | wpb 2469 | bsz 83 | num_updates 179000 | best_loss 12.212
2024-07-15 23:05:41 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 23:06:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_13_179000.pt (epoch 13 @ 179000 updates, score 4.388) (writing took 18.96866005472839 seconds)
2024-07-15 23:06:23 | INFO | train_inner | epoch 013:   3516 / 14632 loss=4.515, nll_loss=3.12, ppl=8.69, wps=7871.3, ups=2.25, wpb=3492.9, bsz=100.8, num_updates=179100, lr=7.47226e-05, gnorm=1.367, train_wall=23, wall=0
2024-07-15 23:06:46 | INFO | train_inner | epoch 013:   3616 / 14632 loss=4.481, nll_loss=3.084, ppl=8.48, wps=14753.7, ups=4.33, wpb=3407.1, bsz=113.1, num_updates=179200, lr=7.47018e-05, gnorm=1.45, train_wall=23, wall=0
2024-07-15 23:07:09 | INFO | train_inner | epoch 013:   3716 / 14632 loss=4.387, nll_loss=2.977, ppl=7.88, wps=14771.2, ups=4.31, wpb=3426.1, bsz=122.2, num_updates=179300, lr=7.4681e-05, gnorm=1.362, train_wall=23, wall=0
2024-07-15 23:07:32 | INFO | train_inner | epoch 013:   3816 / 14632 loss=4.437, nll_loss=3.033, ppl=8.18, wps=15260.7, ups=4.4, wpb=3471.2, bsz=119.2, num_updates=179400, lr=7.46601e-05, gnorm=1.319, train_wall=23, wall=0
2024-07-15 23:07:55 | INFO | train_inner | epoch 013:   3916 / 14632 loss=4.307, nll_loss=2.886, ppl=7.39, wps=14933.4, ups=4.29, wpb=3482.4, bsz=133.7, num_updates=179500, lr=7.46393e-05, gnorm=1.31, train_wall=23, wall=0
2024-07-15 23:08:19 | INFO | train_inner | epoch 013:   4016 / 14632 loss=4.475, nll_loss=3.076, ppl=8.43, wps=14899.6, ups=4.27, wpb=3487.1, bsz=111.4, num_updates=179600, lr=7.46186e-05, gnorm=1.359, train_wall=23, wall=0
2024-07-15 23:08:42 | INFO | train_inner | epoch 013:   4116 / 14632 loss=4.434, nll_loss=3.031, ppl=8.17, wps=15141.5, ups=4.37, wpb=3465.9, bsz=105.1, num_updates=179700, lr=7.45978e-05, gnorm=1.364, train_wall=23, wall=0
2024-07-15 23:09:05 | INFO | train_inner | epoch 013:   4216 / 14632 loss=4.48, nll_loss=3.083, ppl=8.47, wps=15191.2, ups=4.36, wpb=3488, bsz=110.2, num_updates=179800, lr=7.4577e-05, gnorm=1.332, train_wall=23, wall=0
2024-07-15 23:09:28 | INFO | train_inner | epoch 013:   4316 / 14632 loss=4.383, nll_loss=2.972, ppl=7.85, wps=14860.2, ups=4.33, wpb=3429.4, bsz=117.2, num_updates=179900, lr=7.45563e-05, gnorm=1.345, train_wall=23, wall=0
2024-07-15 23:09:51 | INFO | train_inner | epoch 013:   4416 / 14632 loss=4.433, nll_loss=3.028, ppl=8.16, wps=14899.5, ups=4.34, wpb=3436.8, bsz=105.6, num_updates=180000, lr=7.45356e-05, gnorm=1.385, train_wall=23, wall=0
2024-07-15 23:09:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 23:09:53 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.396 | nll_loss 2.86 | ppl 7.26 | wps 42125 | wpb 2469 | bsz 83 | num_updates 180000 | best_loss 12.212
2024-07-15 23:09:53 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 23:09:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_13_180000.pt (epoch 13 @ 180000 updates, score 4.396) (writing took 4.619706276804209 seconds)
2024-07-15 23:10:21 | INFO | train_inner | epoch 013:   4516 / 14632 loss=4.408, nll_loss=3.001, ppl=8.01, wps=11638.5, ups=3.32, wpb=3506.5, bsz=121.8, num_updates=180100, lr=7.45149e-05, gnorm=1.308, train_wall=23, wall=0
2024-07-15 23:10:44 | INFO | train_inner | epoch 013:   4616 / 14632 loss=4.474, nll_loss=3.076, ppl=8.43, wps=15251.5, ups=4.34, wpb=3510.3, bsz=111.9, num_updates=180200, lr=7.44942e-05, gnorm=1.339, train_wall=23, wall=0
2024-07-15 23:11:07 | INFO | train_inner | epoch 013:   4716 / 14632 loss=4.429, nll_loss=3.024, ppl=8.13, wps=15076.9, ups=4.36, wpb=3461.7, bsz=111.4, num_updates=180300, lr=7.44736e-05, gnorm=1.358, train_wall=23, wall=0
2024-07-15 23:11:30 | INFO | train_inner | epoch 013:   4816 / 14632 loss=4.365, nll_loss=2.951, ppl=7.73, wps=15366.1, ups=4.34, wpb=3538, bsz=148.1, num_updates=180400, lr=7.44529e-05, gnorm=1.595, train_wall=23, wall=0
2024-07-15 23:11:53 | INFO | train_inner | epoch 013:   4916 / 14632 loss=4.464, nll_loss=3.064, ppl=8.37, wps=14781.3, ups=4.25, wpb=3480.1, bsz=107.9, num_updates=180500, lr=7.44323e-05, gnorm=1.349, train_wall=23, wall=0
2024-07-15 23:12:17 | INFO | train_inner | epoch 013:   5016 / 14632 loss=4.419, nll_loss=3.014, ppl=8.08, wps=14640.2, ups=4.3, wpb=3401.3, bsz=122.6, num_updates=180600, lr=7.44117e-05, gnorm=1.339, train_wall=23, wall=0
2024-07-15 23:12:39 | INFO | train_inner | epoch 013:   5116 / 14632 loss=4.439, nll_loss=3.035, ppl=8.2, wps=15200.1, ups=4.4, wpb=3455.1, bsz=105.8, num_updates=180700, lr=7.43911e-05, gnorm=1.323, train_wall=23, wall=0
2024-07-15 23:13:03 | INFO | train_inner | epoch 013:   5216 / 14632 loss=4.426, nll_loss=3.021, ppl=8.12, wps=14890.1, ups=4.25, wpb=3505.3, bsz=118.5, num_updates=180800, lr=7.43705e-05, gnorm=1.323, train_wall=23, wall=0
2024-07-15 23:13:26 | INFO | train_inner | epoch 013:   5316 / 14632 loss=4.496, nll_loss=3.1, ppl=8.57, wps=15151.5, ups=4.36, wpb=3477.9, bsz=121, num_updates=180900, lr=7.435e-05, gnorm=1.379, train_wall=23, wall=0
2024-07-15 23:13:49 | INFO | train_inner | epoch 013:   5416 / 14632 loss=4.376, nll_loss=2.964, ppl=7.81, wps=15331.5, ups=4.33, wpb=3538.2, bsz=122.2, num_updates=181000, lr=7.43294e-05, gnorm=1.292, train_wall=23, wall=0
2024-07-15 23:13:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 23:13:51 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.383 | nll_loss 2.847 | ppl 7.2 | wps 42255.3 | wpb 2469 | bsz 83 | num_updates 181000 | best_loss 12.212
2024-07-15 23:13:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 23:13:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_13_181000.pt (epoch 13 @ 181000 updates, score 4.383) (writing took 4.38156530726701 seconds)
2024-07-15 23:14:19 | INFO | train_inner | epoch 013:   5516 / 14632 loss=4.433, nll_loss=3.028, ppl=8.16, wps=11638.3, ups=3.37, wpb=3454.6, bsz=111.4, num_updates=181100, lr=7.43089e-05, gnorm=1.356, train_wall=23, wall=0
2024-07-15 23:14:42 | INFO | train_inner | epoch 013:   5616 / 14632 loss=4.415, nll_loss=3.009, ppl=8.05, wps=14916.2, ups=4.32, wpb=3456.8, bsz=118.7, num_updates=181200, lr=7.42884e-05, gnorm=1.332, train_wall=23, wall=0
2024-07-15 23:15:05 | INFO | train_inner | epoch 013:   5716 / 14632 loss=4.462, nll_loss=3.061, ppl=8.35, wps=15059.4, ups=4.26, wpb=3534.7, bsz=106.6, num_updates=181300, lr=7.42679e-05, gnorm=1.317, train_wall=23, wall=0
2024-07-15 23:15:28 | INFO | train_inner | epoch 013:   5816 / 14632 loss=4.458, nll_loss=3.057, ppl=8.32, wps=15195.8, ups=4.33, wpb=3512, bsz=119.8, num_updates=181400, lr=7.42474e-05, gnorm=1.355, train_wall=23, wall=0
2024-07-15 23:15:51 | INFO | train_inner | epoch 013:   5916 / 14632 loss=4.378, nll_loss=2.965, ppl=7.81, wps=14977.4, ups=4.35, wpb=3444.8, bsz=128.1, num_updates=181500, lr=7.4227e-05, gnorm=1.373, train_wall=23, wall=0
2024-07-15 23:16:14 | INFO | train_inner | epoch 013:   6016 / 14632 loss=4.472, nll_loss=3.073, ppl=8.42, wps=15136.7, ups=4.35, wpb=3481.1, bsz=106.4, num_updates=181600, lr=7.42065e-05, gnorm=1.355, train_wall=23, wall=0
2024-07-15 23:16:38 | INFO | train_inner | epoch 013:   6116 / 14632 loss=4.397, nll_loss=2.988, ppl=7.93, wps=15046, ups=4.27, wpb=3526.1, bsz=125.8, num_updates=181700, lr=7.41861e-05, gnorm=1.305, train_wall=23, wall=0
2024-07-15 23:17:01 | INFO | train_inner | epoch 013:   6216 / 14632 loss=4.419, nll_loss=3.013, ppl=8.07, wps=14997.1, ups=4.33, wpb=3463.1, bsz=114.8, num_updates=181800, lr=7.41657e-05, gnorm=1.33, train_wall=23, wall=0
2024-07-15 23:17:24 | INFO | train_inner | epoch 013:   6316 / 14632 loss=4.361, nll_loss=2.948, ppl=7.71, wps=15144.7, ups=4.34, wpb=3489.8, bsz=120.6, num_updates=181900, lr=7.41453e-05, gnorm=1.3, train_wall=23, wall=0
2024-07-15 23:17:47 | INFO | train_inner | epoch 013:   6416 / 14632 loss=4.417, nll_loss=3.011, ppl=8.06, wps=15252.2, ups=4.32, wpb=3534.2, bsz=127.4, num_updates=182000, lr=7.41249e-05, gnorm=1.327, train_wall=23, wall=0
2024-07-15 23:17:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 23:17:50 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.365 | nll_loss 2.833 | ppl 7.13 | wps 42140.8 | wpb 2469 | bsz 83 | num_updates 182000 | best_loss 12.212
2024-07-15 23:17:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 23:17:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_13_182000.pt (epoch 13 @ 182000 updates, score 4.365) (writing took 4.4967220816761255 seconds)
2024-07-15 23:18:17 | INFO | train_inner | epoch 013:   6516 / 14632 loss=4.39, nll_loss=2.98, ppl=7.89, wps=11638.2, ups=3.33, wpb=3492.1, bsz=123.9, num_updates=182100, lr=7.41046e-05, gnorm=1.305, train_wall=23, wall=0
2024-07-15 23:18:41 | INFO | train_inner | epoch 013:   6616 / 14632 loss=4.439, nll_loss=3.035, ppl=8.2, wps=14863.4, ups=4.21, wpb=3528.1, bsz=122.4, num_updates=182200, lr=7.40842e-05, gnorm=1.326, train_wall=24, wall=0
2024-07-15 23:19:04 | INFO | train_inner | epoch 013:   6716 / 14632 loss=4.428, nll_loss=3.024, ppl=8.13, wps=15364.2, ups=4.39, wpb=3503.5, bsz=115.9, num_updates=182300, lr=7.40639e-05, gnorm=1.33, train_wall=23, wall=0
2024-07-15 23:19:27 | INFO | train_inner | epoch 013:   6816 / 14632 loss=4.422, nll_loss=3.017, ppl=8.1, wps=15048.8, ups=4.32, wpb=3480.2, bsz=112.7, num_updates=182400, lr=7.40436e-05, gnorm=1.292, train_wall=23, wall=0
2024-07-15 23:19:50 | INFO | train_inner | epoch 013:   6916 / 14632 loss=4.438, nll_loss=3.036, ppl=8.2, wps=15231.4, ups=4.35, wpb=3499.8, bsz=117.9, num_updates=182500, lr=7.40233e-05, gnorm=1.304, train_wall=23, wall=0
2024-07-15 23:20:13 | INFO | train_inner | epoch 013:   7016 / 14632 loss=4.402, nll_loss=2.994, ppl=7.96, wps=14647.2, ups=4.29, wpb=3415.3, bsz=116.4, num_updates=182600, lr=7.4003e-05, gnorm=1.346, train_wall=23, wall=0
2024-07-15 23:20:36 | INFO | train_inner | epoch 013:   7116 / 14632 loss=4.404, nll_loss=2.997, ppl=7.98, wps=14869.7, ups=4.32, wpb=3445.4, bsz=124.3, num_updates=182700, lr=7.39828e-05, gnorm=1.339, train_wall=23, wall=0
2024-07-15 23:21:00 | INFO | train_inner | epoch 013:   7216 / 14632 loss=4.415, nll_loss=3.009, ppl=8.05, wps=14757.9, ups=4.18, wpb=3529.2, bsz=119.4, num_updates=182800, lr=7.39626e-05, gnorm=1.302, train_wall=24, wall=0
2024-07-15 23:21:23 | INFO | train_inner | epoch 013:   7316 / 14632 loss=4.391, nll_loss=2.982, ppl=7.9, wps=14841.4, ups=4.35, wpb=3415.3, bsz=133.9, num_updates=182900, lr=7.39423e-05, gnorm=1.358, train_wall=23, wall=0
2024-07-15 23:21:47 | INFO | train_inner | epoch 013:   7416 / 14632 loss=4.417, nll_loss=3.011, ppl=8.06, wps=14824.1, ups=4.28, wpb=3461.8, bsz=112.7, num_updates=183000, lr=7.39221e-05, gnorm=1.361, train_wall=23, wall=0
2024-07-15 23:21:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 23:21:49 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.365 | nll_loss 2.834 | ppl 7.13 | wps 42028.9 | wpb 2469 | bsz 83 | num_updates 183000 | best_loss 12.212
2024-07-15 23:21:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 23:21:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_13_183000.pt (epoch 13 @ 183000 updates, score 4.365) (writing took 4.850800095126033 seconds)
2024-07-15 23:22:17 | INFO | train_inner | epoch 013:   7516 / 14632 loss=4.525, nll_loss=3.134, ppl=8.78, wps=11405.6, ups=3.33, wpb=3426.7, bsz=114.6, num_updates=183100, lr=7.39019e-05, gnorm=1.401, train_wall=23, wall=0
2024-07-15 23:22:40 | INFO | train_inner | epoch 013:   7616 / 14632 loss=4.41, nll_loss=3.003, ppl=8.02, wps=15130.4, ups=4.28, wpb=3537.5, bsz=122, num_updates=183200, lr=7.38818e-05, gnorm=1.284, train_wall=23, wall=0
2024-07-15 23:23:03 | INFO | train_inner | epoch 013:   7716 / 14632 loss=4.436, nll_loss=3.033, ppl=8.19, wps=15023.5, ups=4.33, wpb=3471.9, bsz=105, num_updates=183300, lr=7.38616e-05, gnorm=1.351, train_wall=23, wall=0
2024-07-15 23:23:26 | INFO | train_inner | epoch 013:   7816 / 14632 loss=4.44, nll_loss=3.036, ppl=8.2, wps=15044.2, ups=4.4, wpb=3417.6, bsz=120.5, num_updates=183400, lr=7.38415e-05, gnorm=1.384, train_wall=23, wall=0
2024-07-15 23:23:48 | INFO | train_inner | epoch 013:   7916 / 14632 loss=4.521, nll_loss=3.13, ppl=8.75, wps=15323.6, ups=4.46, wpb=3432.6, bsz=109.9, num_updates=183500, lr=7.38213e-05, gnorm=1.342, train_wall=22, wall=0
2024-07-15 23:24:11 | INFO | train_inner | epoch 013:   8016 / 14632 loss=4.435, nll_loss=3.031, ppl=8.18, wps=15315.8, ups=4.32, wpb=3542.2, bsz=116.6, num_updates=183600, lr=7.38012e-05, gnorm=1.303, train_wall=23, wall=0
2024-07-15 23:24:34 | INFO | train_inner | epoch 013:   8116 / 14632 loss=4.495, nll_loss=3.102, ppl=8.59, wps=15401.9, ups=4.46, wpb=3451.8, bsz=107.8, num_updates=183700, lr=7.37812e-05, gnorm=1.345, train_wall=22, wall=0
2024-07-15 23:24:57 | INFO | train_inner | epoch 013:   8216 / 14632 loss=4.444, nll_loss=3.043, ppl=8.24, wps=15064.4, ups=4.37, wpb=3447.6, bsz=103.4, num_updates=183800, lr=7.37611e-05, gnorm=1.323, train_wall=23, wall=0
2024-07-15 23:25:20 | INFO | train_inner | epoch 013:   8316 / 14632 loss=4.472, nll_loss=3.074, ppl=8.42, wps=15065.5, ups=4.36, wpb=3458.8, bsz=113.1, num_updates=183900, lr=7.3741e-05, gnorm=1.365, train_wall=23, wall=0
2024-07-15 23:25:43 | INFO | train_inner | epoch 013:   8416 / 14632 loss=4.412, nll_loss=3.006, ppl=8.03, wps=14889.8, ups=4.35, wpb=3424, bsz=107.8, num_updates=184000, lr=7.3721e-05, gnorm=1.31, train_wall=23, wall=0
2024-07-15 23:25:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 23:25:45 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.352 | nll_loss 2.818 | ppl 7.05 | wps 42103.9 | wpb 2469 | bsz 83 | num_updates 184000 | best_loss 12.212
2024-07-15 23:25:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 23:25:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_13_184000.pt (epoch 13 @ 184000 updates, score 4.352) (writing took 4.661331356503069 seconds)
2024-07-15 23:26:13 | INFO | train_inner | epoch 013:   8516 / 14632 loss=4.348, nll_loss=2.933, ppl=7.64, wps=11758.1, ups=3.29, wpb=3577.5, bsz=132.5, num_updates=184100, lr=7.3701e-05, gnorm=1.28, train_wall=23, wall=0
2024-07-15 23:26:36 | INFO | train_inner | epoch 013:   8616 / 14632 loss=4.461, nll_loss=3.062, ppl=8.35, wps=14820.4, ups=4.29, wpb=3451.6, bsz=110.9, num_updates=184200, lr=7.36809e-05, gnorm=1.362, train_wall=23, wall=0
2024-07-15 23:26:59 | INFO | train_inner | epoch 013:   8716 / 14632 loss=4.356, nll_loss=2.943, ppl=7.69, wps=15279.8, ups=4.33, wpb=3532, bsz=128.8, num_updates=184300, lr=7.3661e-05, gnorm=1.339, train_wall=23, wall=0
2024-07-15 23:27:23 | INFO | train_inner | epoch 013:   8816 / 14632 loss=4.405, nll_loss=2.998, ppl=7.99, wps=15097.1, ups=4.29, wpb=3519.7, bsz=135.9, num_updates=184400, lr=7.3641e-05, gnorm=1.35, train_wall=23, wall=0
2024-07-15 23:27:46 | INFO | train_inner | epoch 013:   8916 / 14632 loss=4.346, nll_loss=2.93, ppl=7.62, wps=15050.9, ups=4.34, wpb=3470.6, bsz=113.3, num_updates=184500, lr=7.3621e-05, gnorm=1.347, train_wall=23, wall=0
2024-07-15 23:28:09 | INFO | train_inner | epoch 013:   9016 / 14632 loss=4.429, nll_loss=3.026, ppl=8.15, wps=14799.5, ups=4.29, wpb=3451.9, bsz=107, num_updates=184600, lr=7.36011e-05, gnorm=1.356, train_wall=23, wall=0
2024-07-15 23:28:32 | INFO | train_inner | epoch 013:   9116 / 14632 loss=4.329, nll_loss=2.912, ppl=7.53, wps=14918.3, ups=4.33, wpb=3446.6, bsz=138.2, num_updates=184700, lr=7.35811e-05, gnorm=1.336, train_wall=23, wall=0
2024-07-15 23:28:55 | INFO | train_inner | epoch 013:   9216 / 14632 loss=4.367, nll_loss=2.955, ppl=7.75, wps=15230.6, ups=4.36, wpb=3489.7, bsz=120.9, num_updates=184800, lr=7.35612e-05, gnorm=1.353, train_wall=23, wall=0
2024-07-15 23:29:18 | INFO | train_inner | epoch 013:   9316 / 14632 loss=4.391, nll_loss=2.982, ppl=7.9, wps=15301, ups=4.31, wpb=3546.1, bsz=131.2, num_updates=184900, lr=7.35413e-05, gnorm=1.32, train_wall=23, wall=0
2024-07-15 23:29:41 | INFO | train_inner | epoch 013:   9416 / 14632 loss=4.366, nll_loss=2.954, ppl=7.75, wps=14932.1, ups=4.33, wpb=3446, bsz=128.4, num_updates=185000, lr=7.35215e-05, gnorm=1.341, train_wall=23, wall=0
2024-07-15 23:29:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 23:29:44 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.359 | nll_loss 2.825 | ppl 7.09 | wps 42217.8 | wpb 2469 | bsz 83 | num_updates 185000 | best_loss 12.212
2024-07-15 23:29:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 23:29:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_13_185000.pt (epoch 13 @ 185000 updates, score 4.359) (writing took 4.589302023872733 seconds)
2024-07-15 23:30:12 | INFO | train_inner | epoch 013:   9516 / 14632 loss=4.42, nll_loss=3.014, ppl=8.08, wps=11505.2, ups=3.28, wpb=3504, bsz=107.7, num_updates=185100, lr=7.35016e-05, gnorm=1.331, train_wall=23, wall=0
2024-07-15 23:30:35 | INFO | train_inner | epoch 013:   9616 / 14632 loss=4.4, nll_loss=2.993, ppl=7.96, wps=15018.6, ups=4.31, wpb=3482.9, bsz=125.7, num_updates=185200, lr=7.34818e-05, gnorm=1.291, train_wall=23, wall=0
2024-07-15 23:30:59 | INFO | train_inner | epoch 013:   9716 / 14632 loss=4.434, nll_loss=3.032, ppl=8.18, wps=14727.2, ups=4.22, wpb=3493.2, bsz=110.6, num_updates=185300, lr=7.34619e-05, gnorm=1.302, train_wall=24, wall=0
2024-07-15 23:31:22 | INFO | train_inner | epoch 013:   9816 / 14632 loss=4.406, nll_loss=2.999, ppl=8, wps=15080.6, ups=4.31, wpb=3498.6, bsz=118.1, num_updates=185400, lr=7.34421e-05, gnorm=1.328, train_wall=23, wall=0
2024-07-15 23:31:45 | INFO | train_inner | epoch 013:   9916 / 14632 loss=4.416, nll_loss=3.011, ppl=8.06, wps=14861.3, ups=4.32, wpb=3441.3, bsz=110.2, num_updates=185500, lr=7.34223e-05, gnorm=1.321, train_wall=23, wall=0
2024-07-15 23:32:08 | INFO | train_inner | epoch 013:  10016 / 14632 loss=4.444, nll_loss=3.043, ppl=8.24, wps=15014, ups=4.37, wpb=3438.5, bsz=120, num_updates=185600, lr=7.34025e-05, gnorm=1.361, train_wall=23, wall=0
2024-07-15 23:32:31 | INFO | train_inner | epoch 013:  10116 / 14632 loss=4.529, nll_loss=3.139, ppl=8.81, wps=15133.7, ups=4.4, wpb=3437.4, bsz=107.4, num_updates=185700, lr=7.33828e-05, gnorm=1.356, train_wall=23, wall=0
2024-07-15 23:32:54 | INFO | train_inner | epoch 013:  10216 / 14632 loss=4.345, nll_loss=2.93, ppl=7.62, wps=15401.4, ups=4.34, wpb=3546.2, bsz=143.3, num_updates=185800, lr=7.3363e-05, gnorm=1.331, train_wall=23, wall=0
2024-07-15 23:33:17 | INFO | train_inner | epoch 013:  10316 / 14632 loss=4.501, nll_loss=3.109, ppl=8.63, wps=14835.6, ups=4.32, wpb=3430.9, bsz=115, num_updates=185900, lr=7.33433e-05, gnorm=1.373, train_wall=23, wall=0
2024-07-15 23:33:40 | INFO | train_inner | epoch 013:  10416 / 14632 loss=4.446, nll_loss=3.045, ppl=8.25, wps=15086.9, ups=4.4, wpb=3430.2, bsz=110.2, num_updates=186000, lr=7.33236e-05, gnorm=1.362, train_wall=23, wall=0
2024-07-15 23:33:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 23:33:42 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.337 | nll_loss 2.801 | ppl 6.97 | wps 42256.5 | wpb 2469 | bsz 83 | num_updates 186000 | best_loss 12.212
2024-07-15 23:33:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 23:33:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_13_186000.pt (epoch 13 @ 186000 updates, score 4.337) (writing took 4.480261058546603 seconds)
2024-07-15 23:34:09 | INFO | train_inner | epoch 013:  10516 / 14632 loss=4.437, nll_loss=3.034, ppl=8.19, wps=11790.4, ups=3.39, wpb=3473.8, bsz=133.5, num_updates=186100, lr=7.33039e-05, gnorm=1.356, train_wall=22, wall=0
2024-07-15 23:34:32 | INFO | train_inner | epoch 013:  10616 / 14632 loss=4.437, nll_loss=3.035, ppl=8.2, wps=15057.6, ups=4.33, wpb=3476.7, bsz=120.5, num_updates=186200, lr=7.32842e-05, gnorm=1.315, train_wall=23, wall=0
2024-07-15 23:34:55 | INFO | train_inner | epoch 013:  10716 / 14632 loss=4.378, nll_loss=2.968, ppl=7.82, wps=15338.9, ups=4.32, wpb=3549.4, bsz=130, num_updates=186300, lr=7.32645e-05, gnorm=1.311, train_wall=23, wall=0
2024-07-15 23:35:19 | INFO | train_inner | epoch 013:  10816 / 14632 loss=4.308, nll_loss=2.889, ppl=7.41, wps=14797.6, ups=4.29, wpb=3447.5, bsz=131.4, num_updates=186400, lr=7.32448e-05, gnorm=1.328, train_wall=23, wall=0
2024-07-15 23:35:42 | INFO | train_inner | epoch 013:  10916 / 14632 loss=4.514, nll_loss=3.122, ppl=8.71, wps=15339.5, ups=4.36, wpb=3520.7, bsz=106.3, num_updates=186500, lr=7.32252e-05, gnorm=1.317, train_wall=23, wall=0
2024-07-15 23:36:05 | INFO | train_inner | epoch 013:  11016 / 14632 loss=4.424, nll_loss=3.02, ppl=8.11, wps=14944.6, ups=4.33, wpb=3454.2, bsz=110.6, num_updates=186600, lr=7.32056e-05, gnorm=1.347, train_wall=23, wall=0
2024-07-15 23:36:27 | INFO | train_inner | epoch 013:  11116 / 14632 loss=4.453, nll_loss=3.053, ppl=8.3, wps=15092.2, ups=4.4, wpb=3429.9, bsz=108.2, num_updates=186700, lr=7.3186e-05, gnorm=1.369, train_wall=23, wall=0
2024-07-15 23:36:51 | INFO | train_inner | epoch 013:  11216 / 14632 loss=4.401, nll_loss=2.994, ppl=7.97, wps=14890.7, ups=4.25, wpb=3506.7, bsz=127.9, num_updates=186800, lr=7.31664e-05, gnorm=1.328, train_wall=23, wall=0
2024-07-15 23:37:14 | INFO | train_inner | epoch 013:  11316 / 14632 loss=4.444, nll_loss=3.042, ppl=8.24, wps=15333.2, ups=4.32, wpb=3553, bsz=119.4, num_updates=186900, lr=7.31468e-05, gnorm=1.311, train_wall=23, wall=0
2024-07-15 23:37:37 | INFO | train_inner | epoch 013:  11416 / 14632 loss=4.491, nll_loss=3.098, ppl=8.56, wps=15170.3, ups=4.41, wpb=3436.4, bsz=109.4, num_updates=187000, lr=7.31272e-05, gnorm=1.35, train_wall=22, wall=0
2024-07-15 23:37:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 23:37:39 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.349 | nll_loss 2.82 | ppl 7.06 | wps 41909 | wpb 2469 | bsz 83 | num_updates 187000 | best_loss 12.212
2024-07-15 23:37:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 23:37:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_13_187000.pt (epoch 13 @ 187000 updates, score 4.349) (writing took 4.728903621435165 seconds)
2024-07-15 23:38:07 | INFO | train_inner | epoch 013:  11516 / 14632 loss=4.446, nll_loss=3.046, ppl=8.26, wps=11564.8, ups=3.35, wpb=3452, bsz=118.3, num_updates=187100, lr=7.31077e-05, gnorm=1.356, train_wall=23, wall=0
2024-07-15 23:38:30 | INFO | train_inner | epoch 013:  11616 / 14632 loss=4.457, nll_loss=3.056, ppl=8.32, wps=15140.9, ups=4.38, wpb=3456.3, bsz=92.6, num_updates=187200, lr=7.30882e-05, gnorm=1.336, train_wall=23, wall=0
2024-07-15 23:38:53 | INFO | train_inner | epoch 013:  11716 / 14632 loss=4.392, nll_loss=2.983, ppl=7.91, wps=15053.8, ups=4.29, wpb=3506.2, bsz=123.4, num_updates=187300, lr=7.30687e-05, gnorm=1.329, train_wall=23, wall=0
2024-07-15 23:39:16 | INFO | train_inner | epoch 013:  11816 / 14632 loss=4.503, nll_loss=3.109, ppl=8.63, wps=15128.4, ups=4.39, wpb=3444.7, bsz=104.4, num_updates=187400, lr=7.30492e-05, gnorm=1.396, train_wall=23, wall=0
2024-07-15 23:39:39 | INFO | train_inner | epoch 013:  11916 / 14632 loss=4.366, nll_loss=2.954, ppl=7.75, wps=15135.8, ups=4.32, wpb=3501.1, bsz=129.1, num_updates=187500, lr=7.30297e-05, gnorm=1.312, train_wall=23, wall=0
2024-07-15 23:40:02 | INFO | train_inner | epoch 013:  12016 / 14632 loss=4.39, nll_loss=2.981, ppl=7.9, wps=15112.7, ups=4.27, wpb=3539.1, bsz=131.4, num_updates=187600, lr=7.30102e-05, gnorm=1.32, train_wall=23, wall=0
2024-07-15 23:40:25 | INFO | train_inner | epoch 013:  12116 / 14632 loss=4.499, nll_loss=3.105, ppl=8.61, wps=15023.9, ups=4.37, wpb=3438, bsz=101.5, num_updates=187700, lr=7.29908e-05, gnorm=1.393, train_wall=23, wall=0
2024-07-15 23:40:49 | INFO | train_inner | epoch 013:  12216 / 14632 loss=4.463, nll_loss=3.064, ppl=8.36, wps=14794.4, ups=4.24, wpb=3488.5, bsz=103.4, num_updates=187800, lr=7.29713e-05, gnorm=1.378, train_wall=23, wall=0
2024-07-15 23:41:12 | INFO | train_inner | epoch 013:  12316 / 14632 loss=4.39, nll_loss=2.981, ppl=7.9, wps=14743.8, ups=4.25, wpb=3467.6, bsz=113.5, num_updates=187900, lr=7.29519e-05, gnorm=1.362, train_wall=23, wall=0
2024-07-15 23:41:35 | INFO | train_inner | epoch 013:  12416 / 14632 loss=4.389, nll_loss=2.981, ppl=7.9, wps=15135.4, ups=4.33, wpb=3497.8, bsz=126.2, num_updates=188000, lr=7.29325e-05, gnorm=1.299, train_wall=23, wall=0
2024-07-15 23:41:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 23:41:38 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.326 | nll_loss 2.792 | ppl 6.93 | wps 42096.1 | wpb 2469 | bsz 83 | num_updates 188000 | best_loss 12.212
2024-07-15 23:41:38 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 23:41:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_13_188000.pt (epoch 13 @ 188000 updates, score 4.326) (writing took 4.515610869042575 seconds)
2024-07-15 23:42:06 | INFO | train_inner | epoch 013:  12516 / 14632 loss=4.41, nll_loss=3.006, ppl=8.03, wps=11371, ups=3.29, wpb=3452.4, bsz=112.2, num_updates=188100, lr=7.29131e-05, gnorm=1.352, train_wall=23, wall=0
2024-07-15 23:42:29 | INFO | train_inner | epoch 013:  12616 / 14632 loss=4.376, nll_loss=2.966, ppl=7.82, wps=14927.5, ups=4.31, wpb=3460.4, bsz=119, num_updates=188200, lr=7.28937e-05, gnorm=1.335, train_wall=23, wall=0
2024-07-15 23:42:52 | INFO | train_inner | epoch 013:  12716 / 14632 loss=4.357, nll_loss=2.944, ppl=7.7, wps=15386.7, ups=4.37, wpb=3524.8, bsz=120, num_updates=188300, lr=7.28744e-05, gnorm=1.321, train_wall=23, wall=0
2024-07-15 23:43:15 | INFO | train_inner | epoch 013:  12816 / 14632 loss=4.348, nll_loss=2.934, ppl=7.64, wps=15351.4, ups=4.32, wpb=3554.5, bsz=115.7, num_updates=188400, lr=7.2855e-05, gnorm=1.366, train_wall=23, wall=0
2024-07-15 23:43:38 | INFO | train_inner | epoch 013:  12916 / 14632 loss=4.365, nll_loss=2.955, ppl=7.75, wps=15169.1, ups=4.35, wpb=3487.7, bsz=128.8, num_updates=188500, lr=7.28357e-05, gnorm=1.326, train_wall=23, wall=0
2024-07-15 23:44:01 | INFO | train_inner | epoch 013:  13016 / 14632 loss=4.406, nll_loss=3.002, ppl=8.01, wps=14518.5, ups=4.22, wpb=3437.8, bsz=124, num_updates=188600, lr=7.28164e-05, gnorm=1.362, train_wall=24, wall=0
2024-07-15 23:44:25 | INFO | train_inner | epoch 013:  13116 / 14632 loss=4.396, nll_loss=2.989, ppl=7.94, wps=15249.9, ups=4.34, wpb=3517.3, bsz=111.6, num_updates=188700, lr=7.27971e-05, gnorm=1.325, train_wall=23, wall=0
2024-07-15 23:44:48 | INFO | train_inner | epoch 013:  13216 / 14632 loss=4.402, nll_loss=2.996, ppl=7.98, wps=15318.8, ups=4.33, wpb=3534.5, bsz=125.8, num_updates=188800, lr=7.27778e-05, gnorm=1.332, train_wall=23, wall=0
2024-07-15 23:45:11 | INFO | train_inner | epoch 013:  13316 / 14632 loss=4.376, nll_loss=2.966, ppl=7.81, wps=14875.8, ups=4.29, wpb=3466.6, bsz=118.5, num_updates=188900, lr=7.27585e-05, gnorm=1.324, train_wall=23, wall=0
2024-07-15 23:45:34 | INFO | train_inner | epoch 013:  13416 / 14632 loss=4.426, nll_loss=3.023, ppl=8.13, wps=15063.9, ups=4.27, wpb=3528.7, bsz=113, num_updates=189000, lr=7.27393e-05, gnorm=1.313, train_wall=23, wall=0
2024-07-15 23:45:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 23:45:37 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.334 | nll_loss 2.801 | ppl 6.97 | wps 41903.1 | wpb 2469 | bsz 83 | num_updates 189000 | best_loss 12.212
2024-07-15 23:45:37 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 23:45:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_13_189000.pt (epoch 13 @ 189000 updates, score 4.334) (writing took 4.663962058722973 seconds)
2024-07-15 23:46:05 | INFO | train_inner | epoch 013:  13516 / 14632 loss=4.437, nll_loss=3.034, ppl=8.19, wps=11740.2, ups=3.31, wpb=3547.1, bsz=116.9, num_updates=189100, lr=7.27201e-05, gnorm=1.334, train_wall=23, wall=0
2024-07-15 23:46:28 | INFO | train_inner | epoch 013:  13616 / 14632 loss=4.373, nll_loss=2.962, ppl=7.79, wps=14865.7, ups=4.29, wpb=3465.3, bsz=115.3, num_updates=189200, lr=7.27008e-05, gnorm=1.362, train_wall=23, wall=0
2024-07-15 23:46:51 | INFO | train_inner | epoch 013:  13716 / 14632 loss=4.407, nll_loss=3.001, ppl=8.01, wps=14939.1, ups=4.27, wpb=3498.3, bsz=119.3, num_updates=189300, lr=7.26816e-05, gnorm=1.315, train_wall=23, wall=0
2024-07-15 23:47:14 | INFO | train_inner | epoch 013:  13816 / 14632 loss=4.401, nll_loss=2.994, ppl=7.97, wps=15030.2, ups=4.34, wpb=3464.8, bsz=123.8, num_updates=189400, lr=7.26624e-05, gnorm=1.354, train_wall=23, wall=0
2024-07-15 23:47:37 | INFO | train_inner | epoch 013:  13916 / 14632 loss=4.403, nll_loss=2.997, ppl=7.98, wps=15315.1, ups=4.34, wpb=3532.1, bsz=123.8, num_updates=189500, lr=7.26433e-05, gnorm=1.313, train_wall=23, wall=0
2024-07-15 23:48:01 | INFO | train_inner | epoch 013:  14016 / 14632 loss=4.301, nll_loss=2.882, ppl=7.37, wps=15189.8, ups=4.31, wpb=3523.2, bsz=131.5, num_updates=189600, lr=7.26241e-05, gnorm=1.319, train_wall=23, wall=0
2024-07-15 23:48:24 | INFO | train_inner | epoch 013:  14116 / 14632 loss=4.397, nll_loss=2.989, ppl=7.94, wps=14928.1, ups=4.33, wpb=3449.3, bsz=102.1, num_updates=189700, lr=7.2605e-05, gnorm=1.365, train_wall=23, wall=0
2024-07-15 23:48:47 | INFO | train_inner | epoch 013:  14216 / 14632 loss=4.384, nll_loss=2.977, ppl=7.87, wps=14777.3, ups=4.38, wpb=3372.1, bsz=133.3, num_updates=189800, lr=7.25858e-05, gnorm=1.384, train_wall=23, wall=0
2024-07-15 23:49:09 | INFO | train_inner | epoch 013:  14316 / 14632 loss=4.401, nll_loss=2.995, ppl=7.97, wps=15122.3, ups=4.36, wpb=3465, bsz=120.7, num_updates=189900, lr=7.25667e-05, gnorm=1.332, train_wall=23, wall=0
2024-07-15 23:49:33 | INFO | train_inner | epoch 013:  14416 / 14632 loss=4.342, nll_loss=2.929, ppl=7.61, wps=15304, ups=4.28, wpb=3579.7, bsz=134.4, num_updates=190000, lr=7.25476e-05, gnorm=1.277, train_wall=23, wall=0
2024-07-15 23:49:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 23:49:35 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.325 | nll_loss 2.789 | ppl 6.91 | wps 42092 | wpb 2469 | bsz 83 | num_updates 190000 | best_loss 12.212
2024-07-15 23:49:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 23:49:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_13_190000.pt (epoch 13 @ 190000 updates, score 4.325) (writing took 4.611076213419437 seconds)
2024-07-15 23:50:04 | INFO | train_inner | epoch 013:  14516 / 14632 loss=4.394, nll_loss=2.987, ppl=7.93, wps=11249.8, ups=3.21, wpb=3501, bsz=111.1, num_updates=190100, lr=7.25285e-05, gnorm=1.311, train_wall=24, wall=0
2024-07-15 23:50:27 | INFO | train_inner | epoch 013:  14616 / 14632 loss=4.435, nll_loss=3.033, ppl=8.19, wps=14995.3, ups=4.3, wpb=3488.1, bsz=115.5, num_updates=190200, lr=7.25095e-05, gnorm=1.345, train_wall=23, wall=0
2024-07-15 23:50:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 23:50:33 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.334 | nll_loss 2.793 | ppl 6.93 | wps 42126.4 | wpb 2469 | bsz 83 | num_updates 190216 | best_loss 12.212
2024-07-15 23:50:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 23:50:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 13 @ 190216 updates, score 4.334) (writing took 3.9246730962768197 seconds)
2024-07-15 23:50:37 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2024-07-15 23:50:37 | INFO | train | epoch 013 | loss 4.424 | nll_loss 3.019 | ppl 8.11 | wps 14489.1 | ups 4.16 | wpb 3483.6 | bsz 118.4 | num_updates 190216 | lr 7.25064e-05 | gnorm 1.34 | train_wall 3361 | wall 0
2024-07-15 23:50:37 | INFO | fairseq.trainer | begin training epoch 14
2024-07-15 23:50:57 | INFO | train_inner | epoch 014:     84 / 14632 loss=4.389, nll_loss=2.979, ppl=7.88, wps=11889.8, ups=3.38, wpb=3516.8, bsz=110, num_updates=190300, lr=7.24904e-05, gnorm=1.313, train_wall=23, wall=0
2024-07-15 23:51:19 | INFO | train_inner | epoch 014:    184 / 14632 loss=4.41, nll_loss=3.004, ppl=8.02, wps=15119.8, ups=4.42, wpb=3417.6, bsz=113, num_updates=190400, lr=7.24714e-05, gnorm=1.351, train_wall=22, wall=0
2024-07-15 23:51:42 | INFO | train_inner | epoch 014:    284 / 14632 loss=4.4, nll_loss=2.993, ppl=7.96, wps=15089.2, ups=4.39, wpb=3437.1, bsz=113.6, num_updates=190500, lr=7.24524e-05, gnorm=1.349, train_wall=23, wall=0
2024-07-15 23:52:06 | INFO | train_inner | epoch 014:    384 / 14632 loss=4.299, nll_loss=2.879, ppl=7.35, wps=14991, ups=4.26, wpb=3516.1, bsz=127.7, num_updates=190600, lr=7.24333e-05, gnorm=1.287, train_wall=23, wall=0
2024-07-15 23:52:29 | INFO | train_inner | epoch 014:    484 / 14632 loss=4.378, nll_loss=2.968, ppl=7.83, wps=14729.3, ups=4.29, wpb=3429.6, bsz=114.6, num_updates=190700, lr=7.24144e-05, gnorm=1.374, train_wall=23, wall=0
2024-07-15 23:52:52 | INFO | train_inner | epoch 014:    584 / 14632 loss=4.351, nll_loss=2.937, ppl=7.66, wps=14901.5, ups=4.31, wpb=3460.9, bsz=118.4, num_updates=190800, lr=7.23954e-05, gnorm=1.327, train_wall=23, wall=0
2024-07-15 23:53:15 | INFO | train_inner | epoch 014:    684 / 14632 loss=4.401, nll_loss=2.995, ppl=7.97, wps=15268.7, ups=4.38, wpb=3483.1, bsz=108.2, num_updates=190900, lr=7.23764e-05, gnorm=1.346, train_wall=23, wall=0
2024-07-15 23:53:38 | INFO | train_inner | epoch 014:    784 / 14632 loss=4.353, nll_loss=2.941, ppl=7.68, wps=14874.6, ups=4.27, wpb=3484.3, bsz=123.8, num_updates=191000, lr=7.23575e-05, gnorm=1.317, train_wall=23, wall=0
2024-07-15 23:53:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 23:53:41 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.333 | nll_loss 2.793 | ppl 6.93 | wps 42150.9 | wpb 2469 | bsz 83 | num_updates 191000 | best_loss 12.212
2024-07-15 23:53:41 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 23:53:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_14_191000.pt (epoch 14 @ 191000 updates, score 4.333) (writing took 4.644903576001525 seconds)
2024-07-15 23:54:09 | INFO | train_inner | epoch 014:    884 / 14632 loss=4.391, nll_loss=2.983, ppl=7.9, wps=11436.9, ups=3.31, wpb=3455.9, bsz=124, num_updates=191100, lr=7.23385e-05, gnorm=1.337, train_wall=23, wall=0
2024-07-15 23:54:31 | INFO | train_inner | epoch 014:    984 / 14632 loss=4.332, nll_loss=2.916, ppl=7.55, wps=15174.9, ups=4.38, wpb=3465.4, bsz=127.3, num_updates=191200, lr=7.23196e-05, gnorm=1.284, train_wall=23, wall=0
2024-07-15 23:54:55 | INFO | train_inner | epoch 014:   1084 / 14632 loss=4.377, nll_loss=2.966, ppl=7.81, wps=15225.2, ups=4.31, wpb=3535.9, bsz=101.2, num_updates=191300, lr=7.23007e-05, gnorm=1.308, train_wall=23, wall=0
2024-07-15 23:55:18 | INFO | train_inner | epoch 014:   1184 / 14632 loss=4.405, nll_loss=3, ppl=8, wps=15176.3, ups=4.38, wpb=3468.2, bsz=125, num_updates=191400, lr=7.22818e-05, gnorm=1.345, train_wall=23, wall=0
2024-07-15 23:55:41 | INFO | train_inner | epoch 014:   1284 / 14632 loss=4.258, nll_loss=2.833, ppl=7.12, wps=15385.9, ups=4.32, wpb=3560.1, bsz=139.8, num_updates=191500, lr=7.22629e-05, gnorm=1.269, train_wall=23, wall=0
2024-07-15 23:56:04 | INFO | train_inner | epoch 014:   1384 / 14632 loss=4.364, nll_loss=2.953, ppl=7.74, wps=15157, ups=4.33, wpb=3500.5, bsz=121.8, num_updates=191600, lr=7.22441e-05, gnorm=1.327, train_wall=23, wall=0
2024-07-15 23:56:27 | INFO | train_inner | epoch 014:   1484 / 14632 loss=4.238, nll_loss=2.809, ppl=7.01, wps=14757, ups=4.3, wpb=3431.5, bsz=145.9, num_updates=191700, lr=7.22252e-05, gnorm=1.344, train_wall=23, wall=0
2024-07-15 23:56:50 | INFO | train_inner | epoch 014:   1584 / 14632 loss=4.387, nll_loss=2.98, ppl=7.89, wps=14884.6, ups=4.39, wpb=3392, bsz=121.5, num_updates=191800, lr=7.22064e-05, gnorm=1.385, train_wall=23, wall=0
2024-07-15 23:57:13 | INFO | train_inner | epoch 014:   1684 / 14632 loss=4.331, nll_loss=2.916, ppl=7.55, wps=14890.5, ups=4.29, wpb=3472.4, bsz=136.6, num_updates=191900, lr=7.21876e-05, gnorm=1.343, train_wall=23, wall=0
2024-07-15 23:57:36 | INFO | train_inner | epoch 014:   1784 / 14632 loss=4.465, nll_loss=3.066, ppl=8.38, wps=15652.8, ups=4.45, wpb=3515, bsz=111, num_updates=192000, lr=7.21688e-05, gnorm=1.347, train_wall=22, wall=0
2024-07-15 23:57:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 23:57:38 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.313 | nll_loss 2.78 | ppl 6.87 | wps 41709 | wpb 2469 | bsz 83 | num_updates 192000 | best_loss 12.212
2024-07-15 23:57:38 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 23:57:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_14_192000.pt (epoch 14 @ 192000 updates, score 4.313) (writing took 4.570521381683648 seconds)
2024-07-15 23:58:06 | INFO | train_inner | epoch 014:   1884 / 14632 loss=4.373, nll_loss=2.963, ppl=7.8, wps=11509.8, ups=3.31, wpb=3479.2, bsz=116.5, num_updates=192100, lr=7.215e-05, gnorm=1.36, train_wall=23, wall=0
2024-07-15 23:58:29 | INFO | train_inner | epoch 014:   1984 / 14632 loss=4.46, nll_loss=3.061, ppl=8.35, wps=14983.6, ups=4.34, wpb=3450.7, bsz=104.4, num_updates=192200, lr=7.21312e-05, gnorm=1.337, train_wall=23, wall=0
2024-07-15 23:58:52 | INFO | train_inner | epoch 014:   2084 / 14632 loss=4.359, nll_loss=2.947, ppl=7.71, wps=14891, ups=4.33, wpb=3437.6, bsz=115, num_updates=192300, lr=7.21125e-05, gnorm=1.324, train_wall=23, wall=0
2024-07-15 23:59:15 | INFO | train_inner | epoch 014:   2184 / 14632 loss=4.39, nll_loss=2.982, ppl=7.9, wps=14863.5, ups=4.38, wpb=3393.4, bsz=122.3, num_updates=192400, lr=7.20937e-05, gnorm=1.362, train_wall=23, wall=0
2024-07-15 23:59:38 | INFO | train_inner | epoch 014:   2284 / 14632 loss=4.361, nll_loss=2.948, ppl=7.71, wps=15336.6, ups=4.34, wpb=3536.7, bsz=129, num_updates=192500, lr=7.2075e-05, gnorm=1.329, train_wall=23, wall=0
2024-07-16 00:00:01 | INFO | train_inner | epoch 014:   2384 / 14632 loss=4.496, nll_loss=3.103, ppl=8.59, wps=15103.4, ups=4.39, wpb=3440.3, bsz=97.7, num_updates=192600, lr=7.20563e-05, gnorm=1.387, train_wall=23, wall=0
2024-07-16 00:00:24 | INFO | train_inner | epoch 014:   2484 / 14632 loss=4.373, nll_loss=2.964, ppl=7.8, wps=15201.4, ups=4.32, wpb=3517.6, bsz=131.8, num_updates=192700, lr=7.20376e-05, gnorm=1.328, train_wall=23, wall=0
2024-07-16 00:00:47 | INFO | train_inner | epoch 014:   2584 / 14632 loss=4.362, nll_loss=2.951, ppl=7.73, wps=15056.1, ups=4.35, wpb=3465.1, bsz=114.7, num_updates=192800, lr=7.20189e-05, gnorm=1.324, train_wall=23, wall=0
2024-07-16 00:01:10 | INFO | train_inner | epoch 014:   2684 / 14632 loss=4.361, nll_loss=2.949, ppl=7.72, wps=15001.6, ups=4.33, wpb=3465.9, bsz=118.6, num_updates=192900, lr=7.20002e-05, gnorm=1.378, train_wall=23, wall=0
2024-07-16 00:01:33 | INFO | train_inner | epoch 014:   2784 / 14632 loss=4.338, nll_loss=2.922, ppl=7.58, wps=15096.6, ups=4.29, wpb=3518, bsz=110.1, num_updates=193000, lr=7.19816e-05, gnorm=1.3, train_wall=23, wall=0
2024-07-16 00:01:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-16 00:01:36 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.313 | nll_loss 2.774 | ppl 6.84 | wps 41902.3 | wpb 2469 | bsz 83 | num_updates 193000 | best_loss 12.212
2024-07-16 00:01:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-16 00:01:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_14_193000.pt (epoch 14 @ 193000 updates, score 4.313) (writing took 4.605360317975283 seconds)
2024-07-16 00:02:04 | INFO | train_inner | epoch 014:   2884 / 14632 loss=4.424, nll_loss=3.021, ppl=8.12, wps=11339.8, ups=3.26, wpb=3475.1, bsz=107.3, num_updates=193100, lr=7.19629e-05, gnorm=1.325, train_wall=23, wall=0
2024-07-16 00:02:27 | INFO | train_inner | epoch 014:   2984 / 14632 loss=4.315, nll_loss=2.896, ppl=7.44, wps=15214, ups=4.3, wpb=3540, bsz=128.6, num_updates=193200, lr=7.19443e-05, gnorm=1.301, train_wall=23, wall=0
2024-07-16 00:02:50 | INFO | train_inner | epoch 014:   3084 / 14632 loss=4.358, nll_loss=2.946, ppl=7.71, wps=14725.8, ups=4.27, wpb=3445.5, bsz=113, num_updates=193300, lr=7.19257e-05, gnorm=1.32, train_wall=23, wall=0
2024-07-16 00:03:14 | INFO | train_inner | epoch 014:   3184 / 14632 loss=4.328, nll_loss=2.912, ppl=7.53, wps=15299.4, ups=4.33, wpb=3535.4, bsz=129.9, num_updates=193400, lr=7.19071e-05, gnorm=1.286, train_wall=23, wall=0
2024-07-16 00:03:36 | INFO | train_inner | epoch 014:   3284 / 14632 loss=4.411, nll_loss=3.006, ppl=8.04, wps=14861.2, ups=4.39, wpb=3386.2, bsz=107.4, num_updates=193500, lr=7.18885e-05, gnorm=1.352, train_wall=23, wall=0
2024-07-16 00:04:00 | INFO | train_inner | epoch 014:   3384 / 14632 loss=4.344, nll_loss=2.93, ppl=7.62, wps=15183.6, ups=4.3, wpb=3528.8, bsz=116.7, num_updates=193600, lr=7.18699e-05, gnorm=1.337, train_wall=23, wall=0
2024-07-16 00:04:23 | INFO | train_inner | epoch 014:   3484 / 14632 loss=4.419, nll_loss=3.015, ppl=8.08, wps=15219.8, ups=4.35, wpb=3495.4, bsz=106.5, num_updates=193700, lr=7.18514e-05, gnorm=1.367, train_wall=23, wall=0
2024-07-16 00:04:46 | INFO | train_inner | epoch 014:   3584 / 14632 loss=4.405, nll_loss=2.999, ppl=7.99, wps=15259.6, ups=4.28, wpb=3565.7, bsz=113.8, num_updates=193800, lr=7.18329e-05, gnorm=1.286, train_wall=23, wall=0
2024-07-16 00:05:09 | INFO | train_inner | epoch 014:   3684 / 14632 loss=4.43, nll_loss=3.029, ppl=8.16, wps=14986.9, ups=4.4, wpb=3403.8, bsz=111, num_updates=193900, lr=7.18143e-05, gnorm=1.363, train_wall=23, wall=0
2024-07-16 00:05:32 | INFO | train_inner | epoch 014:   3784 / 14632 loss=4.306, nll_loss=2.886, ppl=7.39, wps=15094, ups=4.29, wpb=3519.6, bsz=133.1, num_updates=194000, lr=7.17958e-05, gnorm=1.29, train_wall=23, wall=0
2024-07-16 00:05:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-16 00:05:34 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.308 | nll_loss 2.769 | ppl 6.82 | wps 41786.9 | wpb 2469 | bsz 83 | num_updates 194000 | best_loss 12.212
2024-07-16 00:05:34 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-16 00:05:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_14_194000.pt (epoch 14 @ 194000 updates, score 4.308) (writing took 5.120184105820954 seconds)
2024-07-16 00:06:03 | INFO | train_inner | epoch 014:   3884 / 14632 loss=4.308, nll_loss=2.891, ppl=7.42, wps=11137.1, ups=3.24, wpb=3432.8, bsz=115.4, num_updates=194100, lr=7.17773e-05, gnorm=1.325, train_wall=23, wall=0
2024-07-16 00:06:26 | INFO | train_inner | epoch 014:   3984 / 14632 loss=4.375, nll_loss=2.965, ppl=7.81, wps=15092.6, ups=4.4, wpb=3428, bsz=104.2, num_updates=194200, lr=7.17588e-05, gnorm=1.348, train_wall=23, wall=0
2024-07-16 00:06:49 | INFO | train_inner | epoch 014:   4084 / 14632 loss=4.365, nll_loss=2.954, ppl=7.75, wps=15215.2, ups=4.32, wpb=3520.2, bsz=119.4, num_updates=194300, lr=7.17404e-05, gnorm=1.321, train_wall=23, wall=0
2024-07-16 00:07:12 | INFO | train_inner | epoch 014:   4184 / 14632 loss=4.461, nll_loss=3.064, ppl=8.36, wps=15147, ups=4.35, wpb=3480.8, bsz=110, num_updates=194400, lr=7.17219e-05, gnorm=1.426, train_wall=23, wall=0
2024-07-16 00:07:35 | INFO | train_inner | epoch 014:   4284 / 14632 loss=4.338, nll_loss=2.923, ppl=7.59, wps=14857.4, ups=4.26, wpb=3487.1, bsz=120.6, num_updates=194500, lr=7.17035e-05, gnorm=1.31, train_wall=23, wall=0
2024-07-16 00:07:58 | INFO | train_inner | epoch 014:   4384 / 14632 loss=4.373, nll_loss=2.962, ppl=7.79, wps=15143.8, ups=4.32, wpb=3504.8, bsz=111.8, num_updates=194600, lr=7.1685e-05, gnorm=1.364, train_wall=23, wall=0
2024-07-16 00:08:21 | INFO | train_inner | epoch 014:   4484 / 14632 loss=4.379, nll_loss=2.972, ppl=7.84, wps=15187, ups=4.43, wpb=3427.2, bsz=119, num_updates=194700, lr=7.16666e-05, gnorm=1.302, train_wall=22, wall=0
2024-07-16 00:08:44 | INFO | train_inner | epoch 014:   4584 / 14632 loss=4.382, nll_loss=2.974, ppl=7.86, wps=15136.1, ups=4.33, wpb=3496.2, bsz=113.8, num_updates=194800, lr=7.16482e-05, gnorm=1.343, train_wall=23, wall=0
2024-07-16 00:09:07 | INFO | train_inner | epoch 014:   4684 / 14632 loss=4.415, nll_loss=3.009, ppl=8.05, wps=15064.9, ups=4.35, wpb=3463.7, bsz=100.5, num_updates=194900, lr=7.16299e-05, gnorm=1.351, train_wall=23, wall=0
2024-07-16 00:09:30 | INFO | train_inner | epoch 014:   4784 / 14632 loss=4.229, nll_loss=2.8, ppl=6.96, wps=15105.8, ups=4.27, wpb=3539.8, bsz=139, num_updates=195000, lr=7.16115e-05, gnorm=1.311, train_wall=23, wall=0
2024-07-16 00:09:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-16 00:09:33 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.312 | nll_loss 2.775 | ppl 6.84 | wps 42295.2 | wpb 2469 | bsz 83 | num_updates 195000 | best_loss 12.212
2024-07-16 00:09:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-16 00:09:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_14_195000.pt (epoch 14 @ 195000 updates, score 4.312) (writing took 4.468127814121544 seconds)
2024-07-16 00:10:00 | INFO | train_inner | epoch 014:   4884 / 14632 loss=4.399, nll_loss=2.992, ppl=7.96, wps=11749.4, ups=3.33, wpb=3527.9, bsz=124.8, num_updates=195100, lr=7.15931e-05, gnorm=1.337, train_wall=23, wall=0
2024-07-16 00:10:24 | INFO | train_inner | epoch 014:   4984 / 14632 loss=4.346, nll_loss=2.932, ppl=7.63, wps=15403.7, ups=4.31, wpb=3574.8, bsz=134.7, num_updates=195200, lr=7.15748e-05, gnorm=1.3, train_wall=23, wall=0
2024-07-16 00:10:47 | INFO | train_inner | epoch 014:   5084 / 14632 loss=4.365, nll_loss=2.955, ppl=7.75, wps=15029.4, ups=4.25, wpb=3539, bsz=127, num_updates=195300, lr=7.15565e-05, gnorm=1.306, train_wall=23, wall=0
2024-07-16 00:11:10 | INFO | train_inner | epoch 014:   5184 / 14632 loss=4.403, nll_loss=2.998, ppl=7.99, wps=15141.2, ups=4.33, wpb=3493.7, bsz=115, num_updates=195400, lr=7.15382e-05, gnorm=1.321, train_wall=23, wall=0
2024-07-16 00:11:34 | INFO | train_inner | epoch 014:   5284 / 14632 loss=4.37, nll_loss=2.959, ppl=7.78, wps=14864, ups=4.23, wpb=3513.8, bsz=107.8, num_updates=195500, lr=7.15199e-05, gnorm=1.313, train_wall=23, wall=0
2024-07-16 00:11:57 | INFO | train_inner | epoch 014:   5384 / 14632 loss=4.343, nll_loss=2.93, ppl=7.62, wps=14935.2, ups=4.32, wpb=3460.8, bsz=112.6, num_updates=195600, lr=7.15016e-05, gnorm=1.324, train_wall=23, wall=0
2024-07-16 00:12:20 | INFO | train_inner | epoch 014:   5484 / 14632 loss=4.377, nll_loss=2.968, ppl=7.82, wps=15455.5, ups=4.37, wpb=3533.6, bsz=117, num_updates=195700, lr=7.14833e-05, gnorm=1.307, train_wall=23, wall=0
2024-07-16 00:12:43 | INFO | train_inner | epoch 014:   5584 / 14632 loss=4.314, nll_loss=2.895, ppl=7.44, wps=15378.7, ups=4.27, wpb=3604.2, bsz=118.9, num_updates=195800, lr=7.1465e-05, gnorm=1.289, train_wall=23, wall=0
2024-07-16 00:13:06 | INFO | train_inner | epoch 014:   5684 / 14632 loss=4.348, nll_loss=2.936, ppl=7.66, wps=14801.5, ups=4.35, wpb=3403.3, bsz=108.2, num_updates=195900, lr=7.14468e-05, gnorm=1.337, train_wall=23, wall=0
2024-07-16 00:13:29 | INFO | train_inner | epoch 014:   5784 / 14632 loss=4.308, nll_loss=2.89, ppl=7.41, wps=15076.7, ups=4.33, wpb=3481.2, bsz=130, num_updates=196000, lr=7.14286e-05, gnorm=1.298, train_wall=23, wall=0
2024-07-16 00:13:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-16 00:13:32 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.307 | nll_loss 2.77 | ppl 6.82 | wps 42145.5 | wpb 2469 | bsz 83 | num_updates 196000 | best_loss 12.212
2024-07-16 00:13:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-16 00:13:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_14_196000.pt (epoch 14 @ 196000 updates, score 4.307) (writing took 4.58740714378655 seconds)
2024-07-16 00:13:59 | INFO | train_inner | epoch 014:   5884 / 14632 loss=4.337, nll_loss=2.922, ppl=7.58, wps=11739.1, ups=3.33, wpb=3524.2, bsz=124.1, num_updates=196100, lr=7.14104e-05, gnorm=1.313, train_wall=23, wall=0
2024-07-16 00:14:22 | INFO | train_inner | epoch 014:   5984 / 14632 loss=4.4, nll_loss=2.994, ppl=7.97, wps=14623.1, ups=4.35, wpb=3358.3, bsz=118.6, num_updates=196200, lr=7.13922e-05, gnorm=1.36, train_wall=23, wall=0
2024-07-16 00:14:45 | INFO | train_inner | epoch 014:   6084 / 14632 loss=4.361, nll_loss=2.949, ppl=7.72, wps=15512.6, ups=4.43, wpb=3502.4, bsz=124.6, num_updates=196300, lr=7.1374e-05, gnorm=1.348, train_wall=22, wall=0
2024-07-16 00:15:08 | INFO | train_inner | epoch 014:   6184 / 14632 loss=4.402, nll_loss=2.998, ppl=7.99, wps=14808.1, ups=4.32, wpb=3430.6, bsz=119.8, num_updates=196400, lr=7.13558e-05, gnorm=1.36, train_wall=23, wall=0
2024-07-16 00:15:32 | INFO | train_inner | epoch 014:   6284 / 14632 loss=4.314, nll_loss=2.897, ppl=7.45, wps=15042.8, ups=4.24, wpb=3551.9, bsz=122.2, num_updates=196500, lr=7.13376e-05, gnorm=1.268, train_wall=23, wall=0
2024-07-16 00:15:55 | INFO | train_inner | epoch 014:   6384 / 14632 loss=4.35, nll_loss=2.937, ppl=7.66, wps=15310.6, ups=4.34, wpb=3530.5, bsz=117.1, num_updates=196600, lr=7.13195e-05, gnorm=1.307, train_wall=23, wall=0
2024-07-16 00:16:18 | INFO | train_inner | epoch 014:   6484 / 14632 loss=4.381, nll_loss=2.972, ppl=7.85, wps=14929.6, ups=4.39, wpb=3403.6, bsz=95.5, num_updates=196700, lr=7.13014e-05, gnorm=1.394, train_wall=23, wall=0
2024-07-16 00:16:41 | INFO | train_inner | epoch 014:   6584 / 14632 loss=4.298, nll_loss=2.879, ppl=7.35, wps=14959.7, ups=4.32, wpb=3462.5, bsz=130.6, num_updates=196800, lr=7.12832e-05, gnorm=1.3, train_wall=23, wall=0
2024-07-16 00:17:04 | INFO | train_inner | epoch 014:   6684 / 14632 loss=4.338, nll_loss=2.922, ppl=7.58, wps=15175.9, ups=4.25, wpb=3567.4, bsz=127.3, num_updates=196900, lr=7.12651e-05, gnorm=1.307, train_wall=23, wall=0
2024-07-16 00:17:27 | INFO | train_inner | epoch 014:   6784 / 14632 loss=4.459, nll_loss=3.062, ppl=8.35, wps=15206.9, ups=4.41, wpb=3447.2, bsz=102, num_updates=197000, lr=7.1247e-05, gnorm=1.396, train_wall=23, wall=0
2024-07-16 00:17:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-16 00:17:29 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.295 | nll_loss 2.763 | ppl 6.79 | wps 41360.5 | wpb 2469 | bsz 83 | num_updates 197000 | best_loss 12.212
2024-07-16 00:17:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-16 00:17:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_14_197000.pt (epoch 14 @ 197000 updates, score 4.295) (writing took 4.689780589193106 seconds)
2024-07-16 00:17:57 | INFO | train_inner | epoch 014:   6884 / 14632 loss=4.382, nll_loss=2.974, ppl=7.85, wps=11401.2, ups=3.33, wpb=3422.4, bsz=111.8, num_updates=197100, lr=7.1229e-05, gnorm=1.391, train_wall=23, wall=0
2024-07-16 00:18:20 | INFO | train_inner | epoch 014:   6984 / 14632 loss=4.392, nll_loss=2.985, ppl=7.92, wps=15257.3, ups=4.35, wpb=3508.4, bsz=111, num_updates=197200, lr=7.12109e-05, gnorm=1.312, train_wall=23, wall=0
2024-07-16 00:18:43 | INFO | train_inner | epoch 014:   7084 / 14632 loss=4.323, nll_loss=2.906, ppl=7.49, wps=15167.1, ups=4.33, wpb=3500.8, bsz=107.4, num_updates=197300, lr=7.11929e-05, gnorm=1.305, train_wall=23, wall=0
2024-07-16 00:19:06 | INFO | train_inner | epoch 014:   7184 / 14632 loss=4.281, nll_loss=2.86, ppl=7.26, wps=15070.1, ups=4.34, wpb=3475.8, bsz=134.6, num_updates=197400, lr=7.11748e-05, gnorm=1.338, train_wall=23, wall=0
2024-07-16 00:19:29 | INFO | train_inner | epoch 014:   7284 / 14632 loss=4.391, nll_loss=2.983, ppl=7.91, wps=15376.8, ups=4.37, wpb=3520.2, bsz=121.4, num_updates=197500, lr=7.11568e-05, gnorm=1.326, train_wall=23, wall=0
2024-07-16 00:19:52 | INFO | train_inner | epoch 014:   7384 / 14632 loss=4.384, nll_loss=2.977, ppl=7.87, wps=15014, ups=4.38, wpb=3428.2, bsz=117.5, num_updates=197600, lr=7.11388e-05, gnorm=1.347, train_wall=23, wall=0
2024-07-16 00:20:15 | INFO | train_inner | epoch 014:   7484 / 14632 loss=4.381, nll_loss=2.973, ppl=7.85, wps=14980.1, ups=4.38, wpb=3421.1, bsz=108.6, num_updates=197700, lr=7.11208e-05, gnorm=1.338, train_wall=23, wall=0
2024-07-16 00:20:38 | INFO | train_inner | epoch 014:   7584 / 14632 loss=4.301, nll_loss=2.882, ppl=7.37, wps=15193.5, ups=4.33, wpb=3507, bsz=121, num_updates=197800, lr=7.11028e-05, gnorm=1.316, train_wall=23, wall=0
2024-07-16 00:21:01 | INFO | train_inner | epoch 014:   7684 / 14632 loss=4.242, nll_loss=2.815, ppl=7.04, wps=15214, ups=4.37, wpb=3484.5, bsz=139.8, num_updates=197900, lr=7.10849e-05, gnorm=1.285, train_wall=23, wall=0
2024-07-16 00:21:24 | INFO | train_inner | epoch 014:   7784 / 14632 loss=4.29, nll_loss=2.869, ppl=7.31, wps=14978.2, ups=4.3, wpb=3486.7, bsz=132.6, num_updates=198000, lr=7.10669e-05, gnorm=1.351, train_wall=23, wall=0
2024-07-16 00:21:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-16 00:21:26 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.285 | nll_loss 2.75 | ppl 6.73 | wps 42079.9 | wpb 2469 | bsz 83 | num_updates 198000 | best_loss 12.212
2024-07-16 00:21:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-16 00:21:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_14_198000.pt (epoch 14 @ 198000 updates, score 4.285) (writing took 4.474468593485653 seconds)
2024-07-16 00:21:54 | INFO | train_inner | epoch 014:   7884 / 14632 loss=4.368, nll_loss=2.958, ppl=7.77, wps=11737.6, ups=3.35, wpb=3507.1, bsz=114.7, num_updates=198100, lr=7.1049e-05, gnorm=1.312, train_wall=23, wall=0
2024-07-16 00:22:17 | INFO | train_inner | epoch 014:   7984 / 14632 loss=4.412, nll_loss=3.009, ppl=8.05, wps=14906.4, ups=4.38, wpb=3402.6, bsz=110.4, num_updates=198200, lr=7.1031e-05, gnorm=1.366, train_wall=23, wall=0
2024-07-16 00:22:40 | INFO | train_inner | epoch 014:   8084 / 14632 loss=4.303, nll_loss=2.883, ppl=7.38, wps=15165.5, ups=4.3, wpb=3523.6, bsz=126.7, num_updates=198300, lr=7.10131e-05, gnorm=1.299, train_wall=23, wall=0
2024-07-16 00:23:03 | INFO | train_inner | epoch 014:   8184 / 14632 loss=4.367, nll_loss=2.958, ppl=7.77, wps=15174.6, ups=4.34, wpb=3493.2, bsz=125.2, num_updates=198400, lr=7.09952e-05, gnorm=1.312, train_wall=23, wall=0
2024-07-16 00:23:26 | INFO | train_inner | epoch 014:   8284 / 14632 loss=4.345, nll_loss=2.932, ppl=7.63, wps=15256, ups=4.32, wpb=3530, bsz=125.7, num_updates=198500, lr=7.09773e-05, gnorm=1.327, train_wall=23, wall=0
2024-07-16 00:23:49 | INFO | train_inner | epoch 014:   8384 / 14632 loss=4.357, nll_loss=2.945, ppl=7.7, wps=15226, ups=4.33, wpb=3514.1, bsz=111.5, num_updates=198600, lr=7.09595e-05, gnorm=1.343, train_wall=23, wall=0
2024-07-16 00:24:12 | INFO | train_inner | epoch 014:   8484 / 14632 loss=4.347, nll_loss=2.935, ppl=7.65, wps=14884.1, ups=4.28, wpb=3475.1, bsz=122.2, num_updates=198700, lr=7.09416e-05, gnorm=1.33, train_wall=23, wall=0
2024-07-16 00:24:35 | INFO | train_inner | epoch 014:   8584 / 14632 loss=4.389, nll_loss=2.983, ppl=7.91, wps=15095.3, ups=4.39, wpb=3438.3, bsz=118.2, num_updates=198800, lr=7.09238e-05, gnorm=1.337, train_wall=23, wall=0
2024-07-16 00:24:58 | INFO | train_inner | epoch 014:   8684 / 14632 loss=4.377, nll_loss=2.969, ppl=7.83, wps=14896.4, ups=4.3, wpb=3464.9, bsz=106.9, num_updates=198900, lr=7.09059e-05, gnorm=1.303, train_wall=23, wall=0
2024-07-16 00:25:22 | INFO | train_inner | epoch 014:   8784 / 14632 loss=4.31, nll_loss=2.892, ppl=7.42, wps=14923, ups=4.29, wpb=3474.6, bsz=116.6, num_updates=199000, lr=7.08881e-05, gnorm=1.327, train_wall=23, wall=0
2024-07-16 00:25:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-16 00:25:24 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.287 | nll_loss 2.75 | ppl 6.73 | wps 42059.1 | wpb 2469 | bsz 83 | num_updates 199000 | best_loss 12.212
2024-07-16 00:25:24 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-16 00:25:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_14_199000.pt (epoch 14 @ 199000 updates, score 4.287) (writing took 4.58371371589601 seconds)
2024-07-16 00:25:52 | INFO | train_inner | epoch 014:   8884 / 14632 loss=4.3, nll_loss=2.881, ppl=7.37, wps=11575.6, ups=3.33, wpb=3475.1, bsz=119.2, num_updates=199100, lr=7.08703e-05, gnorm=1.341, train_wall=23, wall=0
2024-07-16 00:26:15 | INFO | train_inner | epoch 014:   8984 / 14632 loss=4.404, nll_loss=2.999, ppl=7.99, wps=15019.7, ups=4.39, wpb=3423.6, bsz=115.4, num_updates=199200, lr=7.08525e-05, gnorm=1.582, train_wall=23, wall=0
2024-07-16 00:26:37 | INFO | train_inner | epoch 014:   9084 / 14632 loss=4.352, nll_loss=2.94, ppl=7.67, wps=15306.9, ups=4.37, wpb=3506.7, bsz=129.7, num_updates=199300, lr=7.08347e-05, gnorm=1.309, train_wall=23, wall=0
2024-07-16 00:27:01 | INFO | train_inner | epoch 014:   9184 / 14632 loss=4.352, nll_loss=2.94, ppl=7.68, wps=15141.4, ups=4.29, wpb=3526.9, bsz=120.6, num_updates=199400, lr=7.0817e-05, gnorm=1.319, train_wall=23, wall=0
2024-07-16 00:27:24 | INFO | train_inner | epoch 014:   9284 / 14632 loss=4.296, nll_loss=2.877, ppl=7.35, wps=15098.3, ups=4.32, wpb=3495.4, bsz=121.9, num_updates=199500, lr=7.07992e-05, gnorm=1.287, train_wall=23, wall=0
2024-07-16 00:27:47 | INFO | train_inner | epoch 014:   9384 / 14632 loss=4.355, nll_loss=2.943, ppl=7.69, wps=14851, ups=4.27, wpb=3474.7, bsz=115.2, num_updates=199600, lr=7.07815e-05, gnorm=1.378, train_wall=23, wall=0
2024-07-16 00:28:10 | INFO | train_inner | epoch 014:   9484 / 14632 loss=4.336, nll_loss=2.922, ppl=7.58, wps=15161.2, ups=4.33, wpb=3498.7, bsz=119.9, num_updates=199700, lr=7.07638e-05, gnorm=1.308, train_wall=23, wall=0
2024-07-16 00:28:33 | INFO | train_inner | epoch 014:   9584 / 14632 loss=4.365, nll_loss=2.954, ppl=7.75, wps=15234.6, ups=4.34, wpb=3513.3, bsz=112.3, num_updates=199800, lr=7.07461e-05, gnorm=1.328, train_wall=23, wall=0
2024-07-16 00:28:56 | INFO | train_inner | epoch 014:   9684 / 14632 loss=4.3, nll_loss=2.882, ppl=7.37, wps=14942.1, ups=4.4, wpb=3397.2, bsz=122.6, num_updates=199900, lr=7.07284e-05, gnorm=1.388, train_wall=23, wall=0
2024-07-16 00:29:19 | INFO | train_inner | epoch 014:   9784 / 14632 loss=4.346, nll_loss=2.933, ppl=7.64, wps=15287.2, ups=4.35, wpb=3511, bsz=131.4, num_updates=200000, lr=7.07107e-05, gnorm=1.324, train_wall=23, wall=0
2024-07-16 00:29:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-16 00:29:22 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.277 | nll_loss 2.736 | ppl 6.66 | wps 41980.5 | wpb 2469 | bsz 83 | num_updates 200000 | best_loss 12.212
2024-07-16 00:29:22 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-16 00:29:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_14_200000.pt (epoch 14 @ 200000 updates, score 4.277) (writing took 4.470620919950306 seconds)
2024-07-16 00:29:26 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2024-07-16 00:29:26 | INFO | train | epoch 014 | loss 4.36 | nll_loss 2.949 | ppl 7.72 | wps 14629.2 | ups 4.2 | wpb 3482.2 | bsz 118.8 | num_updates 200000 | lr 7.07107e-05 | gnorm 1.333 | train_wall 2241 | wall 0
2024-07-16 00:29:26 | INFO | fairseq_cli.train | done training in 23819.2 seconds
