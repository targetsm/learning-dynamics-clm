2024-07-12 17:20:59 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.sep.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=1000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=100, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-12 17:20:59 | INFO | fairseq.tasks.translation | [de] dictionary: 9952 types
2024-07-12 17:20:59 | INFO | fairseq.tasks.translation | [en] dictionary: 9840 types
2024-07-12 17:20:59 | INFO | fairseq.data.data_utils | loaded 7283 examples from: data-bin/iwslt14.sep.tokenized.de-en/valid.de-en.de
2024-07-12 17:20:59 | INFO | fairseq.data.data_utils | loaded 7283 examples from: data-bin/iwslt14.sep.tokenized.de-en/valid.de-en.en
2024-07-12 17:20:59 | INFO | fairseq.tasks.translation | data-bin/iwslt14.sep.tokenized.de-en valid de-en 7283 examples
2024-07-12 17:21:00 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9952, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9840, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=9840, bias=False)
  )
)
2024-07-12 17:21:00 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-12 17:21:00 | INFO | fairseq_cli.train | model: transformer_wmt_en_de (TransformerModel)
2024-07-12 17:21:00 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-12 17:21:00 | INFO | fairseq_cli.train | num. model params: 54272000 (num. trained: 54272000)
2024-07-12 17:21:24 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-12 17:21:24 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-12 17:21:24 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-12 17:21:24 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-12 17:21:24 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-12 17:21:24 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-12 17:21:24 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/checkpoint_last.pt
2024-07-12 17:21:24 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-12 17:21:24 | INFO | fairseq.data.data_utils | loaded 160239 examples from: data-bin/iwslt14.sep.tokenized.de-en/train.de-en.de
2024-07-12 17:21:24 | INFO | fairseq.data.data_utils | loaded 160239 examples from: data-bin/iwslt14.sep.tokenized.de-en/train.de-en.en
2024-07-12 17:21:24 | INFO | fairseq.tasks.translation | data-bin/iwslt14.sep.tokenized.de-en train de-en 160239 examples
2024-07-12 17:21:24 | INFO | fairseq.trainer | begin training epoch 1
2024-07-12 17:21:51 | INFO | train_inner | epoch 001:    100 / 1132 loss=12.377, nll_loss=12.193, ppl=4681.84, wps=14884, ups=4.18, wpb=3559.9, bsz=121.1, num_updates=100, lr=1.25e-05, gnorm=4.125, train_wall=27, wall=28
2024-07-12 17:21:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-12 17:21:56 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.022 | nll_loss 10.671 | ppl 1630.25 | wps 44959 | wpb 2685.2 | bsz 107.1 | num_updates 100
2024-07-12 17:21:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:21:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_100.pt (epoch 1 @ 100 updates, score 11.022) (writing took 2.8097343146800995 seconds)
2024-07-12 17:22:21 | INFO | train_inner | epoch 001:    200 / 1132 loss=10.782, nll_loss=10.412, ppl=1362.66, wps=11949.5, ups=3.34, wpb=3580.7, bsz=147, num_updates=200, lr=2.5e-05, gnorm=2.118, train_wall=23, wall=58
2024-07-12 17:22:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:22:26 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.114 | nll_loss 9.656 | ppl 806.64 | wps 44883 | wpb 2685.2 | bsz 107.1 | num_updates 200 | best_loss 11.022
2024-07-12 17:22:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:22:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_200.pt (epoch 1 @ 200 updates, score 10.114) (writing took 4.973908453248441 seconds)
2024-07-12 17:22:54 | INFO | train_inner | epoch 001:    300 / 1132 loss=9.74, nll_loss=9.222, ppl=597.18, wps=10836.7, ups=3.08, wpb=3521.9, bsz=131.7, num_updates=300, lr=3.75e-05, gnorm=2.085, train_wall=23, wall=90
2024-07-12 17:22:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:22:58 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.148 | nll_loss 8.479 | ppl 356.93 | wps 44832.7 | wpb 2685.2 | bsz 107.1 | num_updates 300 | best_loss 11.022
2024-07-12 17:22:58 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:23:05 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_300.pt (epoch 1 @ 300 updates, score 9.148) (writing took 7.113690107129514 seconds)
2024-07-12 17:23:29 | INFO | train_inner | epoch 001:    400 / 1132 loss=9.192, nll_loss=8.552, ppl=375.41, wps=9964.7, ups=2.89, wpb=3450.9, bsz=145.2, num_updates=400, lr=5e-05, gnorm=2.21, train_wall=23, wall=125
2024-07-12 17:23:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:23:33 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.902 | nll_loss 8.169 | ppl 287.81 | wps 45064.9 | wpb 2685.2 | bsz 107.1 | num_updates 400 | best_loss 11.022
2024-07-12 17:23:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:23:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_400.pt (epoch 1 @ 400 updates, score 8.902) (writing took 5.11966915987432 seconds)
2024-07-12 17:24:01 | INFO | train_inner | epoch 001:    500 / 1132 loss=8.793, nll_loss=8.079, ppl=270.38, wps=11131.7, ups=3.08, wpb=3609.1, bsz=165.4, num_updates=500, lr=6.25e-05, gnorm=2.073, train_wall=23, wall=157
2024-07-12 17:24:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:24:05 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.799 | nll_loss 8.039 | ppl 262.95 | wps 45113.9 | wpb 2685.2 | bsz 107.1 | num_updates 500 | best_loss 11.022
2024-07-12 17:24:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:24:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_500.pt (epoch 1 @ 500 updates, score 8.799) (writing took 10.57195165939629 seconds)
2024-07-12 17:24:38 | INFO | train_inner | epoch 001:    600 / 1132 loss=8.574, nll_loss=7.822, ppl=226.31, wps=9516.9, ups=2.67, wpb=3562.1, bsz=134.6, num_updates=600, lr=7.5e-05, gnorm=1.85, train_wall=23, wall=195
2024-07-12 17:24:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:24:43 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.52 | nll_loss 7.705 | ppl 208.59 | wps 44964.8 | wpb 2685.2 | bsz 107.1 | num_updates 600 | best_loss 11.022
2024-07-12 17:24:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:24:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_600.pt (epoch 1 @ 600 updates, score 8.52) (writing took 4.960270047187805 seconds)
2024-07-12 17:25:11 | INFO | train_inner | epoch 001:    700 / 1132 loss=8.437, nll_loss=7.666, ppl=203.04, wps=11048.4, ups=3.07, wpb=3597.5, bsz=159.4, num_updates=700, lr=8.75e-05, gnorm=1.752, train_wall=23, wall=227
2024-07-12 17:25:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:25:15 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.299 | nll_loss 7.461 | ppl 176.22 | wps 44780.2 | wpb 2685.2 | bsz 107.1 | num_updates 700 | best_loss 11.022
2024-07-12 17:25:15 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:25:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_700.pt (epoch 1 @ 700 updates, score 8.299) (writing took 8.063893055543303 seconds)
2024-07-12 17:25:46 | INFO | train_inner | epoch 001:    800 / 1132 loss=8.33, nll_loss=7.538, ppl=185.79, wps=10106.7, ups=2.82, wpb=3578.7, bsz=133.7, num_updates=800, lr=0.0001, gnorm=1.817, train_wall=23, wall=263
2024-07-12 17:25:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:25:51 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.24 | nll_loss 7.385 | ppl 167.18 | wps 44674 | wpb 2685.2 | bsz 107.1 | num_updates 800 | best_loss 11.022
2024-07-12 17:25:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:25:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_800.pt (epoch 1 @ 800 updates, score 8.24) (writing took 5.408457750454545 seconds)
2024-07-12 17:26:19 | INFO | train_inner | epoch 001:    900 / 1132 loss=8.201, nll_loss=7.39, ppl=167.75, wps=10899, ups=3.04, wpb=3590.2, bsz=147.1, num_updates=900, lr=0.0001125, gnorm=1.671, train_wall=23, wall=296
2024-07-12 17:26:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:26:23 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.096 | nll_loss 7.197 | ppl 146.74 | wps 44844.4 | wpb 2685.2 | bsz 107.1 | num_updates 900 | best_loss 11.022
2024-07-12 17:26:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:26:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_900.pt (epoch 1 @ 900 updates, score 8.096) (writing took 5.089478869922459 seconds)
2024-07-12 17:26:52 | INFO | train_inner | epoch 001:   1000 / 1132 loss=8.213, nll_loss=7.402, ppl=169.14, wps=10753.2, ups=3.08, wpb=3486.1, bsz=139.7, num_updates=1000, lr=0.000125, gnorm=1.658, train_wall=23, wall=328
2024-07-12 17:26:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:26:56 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.978 | nll_loss 7.081 | ppl 135.37 | wps 44795.8 | wpb 2685.2 | bsz 107.1 | num_updates 1000 | best_loss 11.022
2024-07-12 17:26:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:27:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 7.978) (writing took 9.746100274845958 seconds)
2024-07-12 17:27:06 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-12 17:27:06 | INFO | train | epoch 001 | loss 9.264 | nll_loss 8.627 | ppl 395.44 | wps 10506.3 | ups 2.96 | wpb 3553.7 | bsz 142.5 | num_updates 1000 | lr 0.000125 | gnorm 2.136 | train_wall 234 | wall 342
2024-07-12 17:27:06 | INFO | fairseq_cli.train | done training in 341.5 seconds
2024-07-12 17:27:17 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.sep.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=10000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=500, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-12 17:27:17 | INFO | fairseq.tasks.translation | [de] dictionary: 9952 types
2024-07-12 17:27:17 | INFO | fairseq.tasks.translation | [en] dictionary: 9840 types
2024-07-12 17:27:17 | INFO | fairseq.data.data_utils | loaded 7283 examples from: data-bin/iwslt14.sep.tokenized.de-en/valid.de-en.de
2024-07-12 17:27:17 | INFO | fairseq.data.data_utils | loaded 7283 examples from: data-bin/iwslt14.sep.tokenized.de-en/valid.de-en.en
2024-07-12 17:27:17 | INFO | fairseq.tasks.translation | data-bin/iwslt14.sep.tokenized.de-en valid de-en 7283 examples
2024-07-12 17:27:18 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9952, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9840, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=9840, bias=False)
  )
)
2024-07-12 17:27:18 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-12 17:27:18 | INFO | fairseq_cli.train | model: transformer_wmt_en_de (TransformerModel)
2024-07-12 17:27:18 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-12 17:27:18 | INFO | fairseq_cli.train | num. model params: 54272000 (num. trained: 54272000)
2024-07-12 17:27:29 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-12 17:27:29 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-12 17:27:29 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-12 17:27:29 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-12 17:27:29 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-12 17:27:29 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-12 17:27:31 | INFO | fairseq.trainer | loaded checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 1000 updates)
2024-07-12 17:27:31 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-12 17:27:31 | INFO | fairseq.data.data_utils | loaded 160239 examples from: data-bin/iwslt14.sep.tokenized.de-en/train.de-en.de
2024-07-12 17:27:31 | INFO | fairseq.data.data_utils | loaded 160239 examples from: data-bin/iwslt14.sep.tokenized.de-en/train.de-en.en
2024-07-12 17:27:31 | INFO | fairseq.tasks.translation | data-bin/iwslt14.sep.tokenized.de-en train de-en 160239 examples
2024-07-12 17:27:31 | INFO | fairseq.trainer | begin training epoch 1
2024-07-12 17:27:57 | INFO | train_inner | epoch 001:   1100 / 1132 loss=8.073, nll_loss=7.24, ppl=151.12, wps=11936.6, ups=3.36, wpb=3551.7, bsz=135, num_updates=1100, lr=0.0001375, gnorm=1.503, train_wall=25, wall=0
2024-07-12 17:28:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-12 17:28:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.733 | nll_loss 6.809 | ppl 112.11 | wps 44777.5 | wpb 2685.2 | bsz 107.1 | num_updates 1132 | best_loss 11.022
2024-07-12 17:28:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:28:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 1132 updates, score 7.733) (writing took 4.968634020537138 seconds)
2024-07-12 17:28:13 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-12 17:28:13 | INFO | train | epoch 001 | loss 9.12 | nll_loss 8.459 | ppl 352.01 | wps 10862.6 | ups 3.05 | wpb 3556.4 | bsz 141.6 | num_updates 1132 | lr 0.0001415 | gnorm 2.06 | train_wall 266 | wall 0
2024-07-12 17:28:13 | INFO | fairseq.trainer | begin training epoch 2
2024-07-12 17:28:29 | INFO | train_inner | epoch 002:     68 / 1132 loss=7.915, nll_loss=7.057, ppl=133.13, wps=10993.3, ups=3.09, wpb=3553.3, bsz=126.2, num_updates=1200, lr=0.00015, gnorm=1.539, train_wall=23, wall=0
2024-07-12 17:28:52 | INFO | train_inner | epoch 002:    168 / 1132 loss=7.712, nll_loss=6.822, ppl=113.13, wps=15279, ups=4.36, wpb=3508.3, bsz=159.3, num_updates=1300, lr=0.0001625, gnorm=1.554, train_wall=23, wall=0
2024-07-12 17:29:15 | INFO | train_inner | epoch 002:    268 / 1132 loss=7.683, nll_loss=6.788, ppl=110.54, wps=15377.8, ups=4.34, wpb=3545.4, bsz=136.7, num_updates=1400, lr=0.000175, gnorm=1.358, train_wall=23, wall=0
2024-07-12 17:29:38 | INFO | train_inner | epoch 002:    368 / 1132 loss=7.601, nll_loss=6.693, ppl=103.46, wps=15585.2, ups=4.35, wpb=3580.1, bsz=148, num_updates=1500, lr=0.0001875, gnorm=1.415, train_wall=23, wall=0
2024-07-12 17:29:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:29:42 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.452 | nll_loss 6.466 | ppl 88.43 | wps 44617.6 | wpb 2685.2 | bsz 107.1 | num_updates 1500 | best_loss 11.022
2024-07-12 17:29:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:29:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_1500.pt (epoch 2 @ 1500 updates, score 7.452) (writing took 5.125058215111494 seconds)
2024-07-12 17:30:11 | INFO | train_inner | epoch 002:    468 / 1132 loss=7.647, nll_loss=6.745, ppl=107.28, wps=10942.2, ups=3.06, wpb=3575.4, bsz=136.5, num_updates=1600, lr=0.0002, gnorm=1.322, train_wall=23, wall=0
2024-07-12 17:30:34 | INFO | train_inner | epoch 002:    568 / 1132 loss=7.583, nll_loss=6.672, ppl=101.95, wps=15282, ups=4.33, wpb=3532.1, bsz=146.7, num_updates=1700, lr=0.0002125, gnorm=1.317, train_wall=23, wall=0
2024-07-12 17:30:57 | INFO | train_inner | epoch 002:    668 / 1132 loss=7.343, nll_loss=6.395, ppl=84.15, wps=15404.8, ups=4.28, wpb=3595.3, bsz=153.3, num_updates=1800, lr=0.000225, gnorm=1.307, train_wall=23, wall=0
2024-07-12 17:31:20 | INFO | train_inner | epoch 002:    768 / 1132 loss=7.415, nll_loss=6.477, ppl=89.07, wps=15510.8, ups=4.32, wpb=3588.3, bsz=140.2, num_updates=1900, lr=0.0002375, gnorm=1.25, train_wall=23, wall=0
2024-07-12 17:31:43 | INFO | train_inner | epoch 002:    868 / 1132 loss=7.294, nll_loss=6.338, ppl=80.92, wps=15598.1, ups=4.36, wpb=3578.8, bsz=145.6, num_updates=2000, lr=0.00025, gnorm=1.256, train_wall=23, wall=0
2024-07-12 17:31:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:31:47 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.2 | nll_loss 6.199 | ppl 73.49 | wps 44769.4 | wpb 2685.2 | bsz 107.1 | num_updates 2000 | best_loss 11.022
2024-07-12 17:31:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:31:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 7.2) (writing took 5.496793384663761 seconds)
2024-07-12 17:32:17 | INFO | train_inner | epoch 002:    968 / 1132 loss=7.39, nll_loss=6.448, ppl=87.28, wps=10795.5, ups=2.98, wpb=3623.2, bsz=130.5, num_updates=2100, lr=0.0002625, gnorm=1.124, train_wall=24, wall=0
2024-07-12 17:32:40 | INFO | train_inner | epoch 002:   1068 / 1132 loss=7.241, nll_loss=6.276, ppl=77.51, wps=15078.7, ups=4.32, wpb=3493.3, bsz=142.2, num_updates=2200, lr=0.000275, gnorm=1.232, train_wall=23, wall=0
2024-07-12 17:32:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:32:59 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.051 | nll_loss 6.012 | ppl 64.52 | wps 44712.4 | wpb 2685.2 | bsz 107.1 | num_updates 2264 | best_loss 11.022
2024-07-12 17:32:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:33:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 2 @ 2264 updates, score 7.051) (writing took 4.117564719170332 seconds)
2024-07-12 17:33:03 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2024-07-12 17:33:03 | INFO | train | epoch 002 | loss 7.503 | nll_loss 6.579 | ppl 95.62 | wps 13897.9 | ups 3.91 | wpb 3556.4 | bsz 141.6 | num_updates 2264 | lr 0.000283 | gnorm 1.321 | train_wall 260 | wall 0
2024-07-12 17:33:03 | INFO | fairseq.trainer | begin training epoch 3
2024-07-12 17:33:11 | INFO | train_inner | epoch 003:     36 / 1132 loss=7.165, nll_loss=6.189, ppl=72.97, wps=11309.1, ups=3.17, wpb=3564.6, bsz=132.2, num_updates=2300, lr=0.0002875, gnorm=1.125, train_wall=23, wall=0
2024-07-12 17:33:35 | INFO | train_inner | epoch 003:    136 / 1132 loss=7.142, nll_loss=6.163, ppl=71.66, wps=15489.7, ups=4.3, wpb=3604.4, bsz=148.6, num_updates=2400, lr=0.0003, gnorm=1.207, train_wall=23, wall=0
2024-07-12 17:33:57 | INFO | train_inner | epoch 003:    236 / 1132 loss=7.248, nll_loss=6.284, ppl=77.95, wps=14871.5, ups=4.37, wpb=3400.3, bsz=120.2, num_updates=2500, lr=0.0003125, gnorm=1.153, train_wall=23, wall=0
2024-07-12 17:33:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:34:02 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 6.944 | nll_loss 5.891 | ppl 59.36 | wps 44773.9 | wpb 2685.2 | bsz 107.1 | num_updates 2500 | best_loss 11.022
2024-07-12 17:34:02 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:34:07 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_2500.pt (epoch 3 @ 2500 updates, score 6.944) (writing took 5.470627099275589 seconds)
2024-07-12 17:34:30 | INFO | train_inner | epoch 003:    336 / 1132 loss=7, nll_loss=5.999, ppl=63.97, wps=10821.7, ups=3.08, wpb=3512.2, bsz=140.4, num_updates=2600, lr=0.000325, gnorm=1.048, train_wall=23, wall=0
2024-07-12 17:34:53 | INFO | train_inner | epoch 003:    436 / 1132 loss=6.947, nll_loss=5.938, ppl=61.3, wps=15275.4, ups=4.28, wpb=3569.5, bsz=142.8, num_updates=2700, lr=0.0003375, gnorm=1.133, train_wall=23, wall=0
2024-07-12 17:35:16 | INFO | train_inner | epoch 003:    536 / 1132 loss=6.932, nll_loss=5.92, ppl=60.54, wps=15499.8, ups=4.34, wpb=3572.9, bsz=133.8, num_updates=2800, lr=0.00035, gnorm=1.096, train_wall=23, wall=0
2024-07-12 17:35:39 | INFO | train_inner | epoch 003:    636 / 1132 loss=6.679, nll_loss=5.63, ppl=49.51, wps=15719.3, ups=4.32, wpb=3636.1, bsz=147.6, num_updates=2900, lr=0.0003625, gnorm=1.084, train_wall=23, wall=0
2024-07-12 17:36:03 | INFO | train_inner | epoch 003:    736 / 1132 loss=6.807, nll_loss=5.776, ppl=54.8, wps=15338.1, ups=4.35, wpb=3529.7, bsz=157.7, num_updates=3000, lr=0.000375, gnorm=1.145, train_wall=23, wall=0
2024-07-12 17:36:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:36:07 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 6.579 | nll_loss 5.455 | ppl 43.87 | wps 44739.4 | wpb 2685.2 | bsz 107.1 | num_updates 3000 | best_loss 11.022
2024-07-12 17:36:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:36:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_3000.pt (epoch 3 @ 3000 updates, score 6.579) (writing took 5.416022622957826 seconds)
2024-07-12 17:36:35 | INFO | train_inner | epoch 003:    836 / 1132 loss=6.676, nll_loss=5.626, ppl=49.39, wps=10732.7, ups=3.04, wpb=3528.8, bsz=145.2, num_updates=3100, lr=0.0003875, gnorm=1.109, train_wall=23, wall=0
2024-07-12 17:36:59 | INFO | train_inner | epoch 003:    936 / 1132 loss=6.751, nll_loss=5.711, ppl=52.37, wps=15065.3, ups=4.21, wpb=3576.1, bsz=128.5, num_updates=3200, lr=0.0004, gnorm=1.082, train_wall=24, wall=0
2024-07-12 17:37:22 | INFO | train_inner | epoch 003:   1036 / 1132 loss=6.607, nll_loss=5.544, ppl=46.67, wps=15467.3, ups=4.3, wpb=3600.2, bsz=143.4, num_updates=3300, lr=0.0004125, gnorm=1.137, train_wall=23, wall=0
2024-07-12 17:37:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:37:49 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 6.343 | nll_loss 5.171 | ppl 36.02 | wps 44688 | wpb 2685.2 | bsz 107.1 | num_updates 3396 | best_loss 11.022
2024-07-12 17:37:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:37:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 3 @ 3396 updates, score 6.343) (writing took 5.617563302628696 seconds)
2024-07-12 17:37:55 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2024-07-12 17:37:55 | INFO | train | epoch 003 | loss 6.846 | nll_loss 5.821 | ppl 56.55 | wps 13797.4 | ups 3.88 | wpb 3556.4 | bsz 141.6 | num_updates 3396 | lr 0.0004245 | gnorm 1.125 | train_wall 261 | wall 0
2024-07-12 17:37:55 | INFO | fairseq.trainer | begin training epoch 4
2024-07-12 17:37:56 | INFO | train_inner | epoch 004:      4 / 1132 loss=6.465, nll_loss=5.383, ppl=41.73, wps=10711.3, ups=3, wpb=3571.7, bsz=148, num_updates=3400, lr=0.000425, gnorm=1.205, train_wall=23, wall=0
2024-07-12 17:38:19 | INFO | train_inner | epoch 004:    104 / 1132 loss=6.446, nll_loss=5.36, ppl=41.08, wps=15191.3, ups=4.35, wpb=3489.2, bsz=146.2, num_updates=3500, lr=0.0004375, gnorm=1.17, train_wall=23, wall=0
2024-07-12 17:38:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:38:23 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 6.292 | nll_loss 5.105 | ppl 34.42 | wps 44636.1 | wpb 2685.2 | bsz 107.1 | num_updates 3500 | best_loss 11.022
2024-07-12 17:38:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:38:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_3500.pt (epoch 4 @ 3500 updates, score 6.292) (writing took 6.720883505418897 seconds)
2024-07-12 17:38:53 | INFO | train_inner | epoch 004:    204 / 1132 loss=6.401, nll_loss=5.306, ppl=39.57, wps=10610.2, ups=2.94, wpb=3614.8, bsz=139.3, num_updates=3600, lr=0.00045, gnorm=1.143, train_wall=23, wall=0
2024-07-12 17:39:16 | INFO | train_inner | epoch 004:    304 / 1132 loss=6.301, nll_loss=5.192, ppl=36.54, wps=15590.4, ups=4.35, wpb=3585, bsz=127.4, num_updates=3700, lr=0.0004625, gnorm=1.115, train_wall=23, wall=0
2024-07-12 17:39:39 | INFO | train_inner | epoch 004:    404 / 1132 loss=6.38, nll_loss=5.281, ppl=38.88, wps=15227.5, ups=4.37, wpb=3484.7, bsz=130.6, num_updates=3800, lr=0.000475, gnorm=1.223, train_wall=23, wall=0
2024-07-12 17:40:01 | INFO | train_inner | epoch 004:    504 / 1132 loss=6.274, nll_loss=5.16, ppl=35.76, wps=15247.4, ups=4.39, wpb=3471.6, bsz=134, num_updates=3900, lr=0.0004875, gnorm=1.12, train_wall=23, wall=0
2024-07-12 17:40:25 | INFO | train_inner | epoch 004:    604 / 1132 loss=6.133, nll_loss=5, ppl=31.99, wps=15389.3, ups=4.31, wpb=3574.4, bsz=142.9, num_updates=4000, lr=0.0005, gnorm=1.167, train_wall=23, wall=0
2024-07-12 17:40:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:40:29 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 6.07 | nll_loss 4.817 | ppl 28.2 | wps 44603.5 | wpb 2685.2 | bsz 107.1 | num_updates 4000 | best_loss 11.022
2024-07-12 17:40:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:40:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_4000.pt (epoch 4 @ 4000 updates, score 6.07) (writing took 5.233062699437141 seconds)
2024-07-12 17:40:58 | INFO | train_inner | epoch 004:    704 / 1132 loss=6.102, nll_loss=4.961, ppl=31.15, wps=10978, ups=3.03, wpb=3619.5, bsz=151.3, num_updates=4100, lr=0.000493865, gnorm=1.181, train_wall=23, wall=0
2024-07-12 17:41:21 | INFO | train_inner | epoch 004:    804 / 1132 loss=6.022, nll_loss=4.87, ppl=29.24, wps=15563.9, ups=4.34, wpb=3582.1, bsz=142.2, num_updates=4200, lr=0.00048795, gnorm=1.174, train_wall=23, wall=0
2024-07-12 17:41:44 | INFO | train_inner | epoch 004:    904 / 1132 loss=5.923, nll_loss=4.756, ppl=27.02, wps=15309.5, ups=4.33, wpb=3533.6, bsz=146.6, num_updates=4300, lr=0.000482243, gnorm=1.12, train_wall=23, wall=0
2024-07-12 17:42:07 | INFO | train_inner | epoch 004:   1004 / 1132 loss=5.915, nll_loss=4.746, ppl=26.83, wps=15363.6, ups=4.31, wpb=3560.5, bsz=150, num_updates=4400, lr=0.000476731, gnorm=1.195, train_wall=23, wall=0
2024-07-12 17:42:30 | INFO | train_inner | epoch 004:   1104 / 1132 loss=5.834, nll_loss=4.654, ppl=25.17, wps=15692.6, ups=4.31, wpb=3641.5, bsz=143.9, num_updates=4500, lr=0.000471405, gnorm=1.121, train_wall=23, wall=0
2024-07-12 17:42:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:42:34 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 5.595 | nll_loss 4.267 | ppl 19.26 | wps 44745 | wpb 2685.2 | bsz 107.1 | num_updates 4500 | best_loss 11.022
2024-07-12 17:42:34 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:42:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_4500.pt (epoch 4 @ 4500 updates, score 5.595) (writing took 5.801815554499626 seconds)
2024-07-12 17:42:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:42:51 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 5.598 | nll_loss 4.28 | ppl 19.43 | wps 44919.8 | wpb 2685.2 | bsz 107.1 | num_updates 4528 | best_loss 11.022
2024-07-12 17:42:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:42:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 4 @ 4528 updates, score 5.598) (writing took 4.94215006288141 seconds)
2024-07-12 17:42:56 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2024-07-12 17:42:56 | INFO | train | epoch 004 | loss 6.15 | nll_loss 5.018 | ppl 32.4 | wps 13369.4 | ups 3.76 | wpb 3556.4 | bsz 141.6 | num_updates 4528 | lr 0.000469945 | gnorm 1.157 | train_wall 259 | wall 0
2024-07-12 17:42:56 | INFO | fairseq.trainer | begin training epoch 5
2024-07-12 17:43:13 | INFO | train_inner | epoch 005:     72 / 1132 loss=5.716, nll_loss=4.517, ppl=22.9, wps=8209.7, ups=2.35, wpb=3492.9, bsz=147.4, num_updates=4600, lr=0.000466252, gnorm=1.148, train_wall=23, wall=0
2024-07-12 17:43:36 | INFO | train_inner | epoch 005:    172 / 1132 loss=5.707, nll_loss=4.505, ppl=22.71, wps=15313, ups=4.29, wpb=3566.3, bsz=143.6, num_updates=4700, lr=0.000461266, gnorm=1.185, train_wall=23, wall=0
2024-07-12 17:43:59 | INFO | train_inner | epoch 005:    272 / 1132 loss=5.577, nll_loss=4.357, ppl=20.49, wps=15488.2, ups=4.38, wpb=3536.5, bsz=145.3, num_updates=4800, lr=0.000456435, gnorm=1.078, train_wall=23, wall=0
2024-07-12 17:44:22 | INFO | train_inner | epoch 005:    372 / 1132 loss=5.662, nll_loss=4.452, ppl=21.89, wps=15562.4, ups=4.38, wpb=3553.3, bsz=134.4, num_updates=4900, lr=0.000451754, gnorm=1.131, train_wall=23, wall=0
2024-07-12 17:44:45 | INFO | train_inner | epoch 005:    472 / 1132 loss=5.495, nll_loss=4.26, ppl=19.16, wps=15450.3, ups=4.32, wpb=3577.6, bsz=145.9, num_updates=5000, lr=0.000447214, gnorm=1.092, train_wall=23, wall=0
2024-07-12 17:44:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:44:49 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 5.393 | nll_loss 4.024 | ppl 16.27 | wps 44684.1 | wpb 2685.2 | bsz 107.1 | num_updates 5000 | best_loss 11.022
2024-07-12 17:44:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:44:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_5000.pt (epoch 5 @ 5000 updates, score 5.393) (writing took 5.439603576436639 seconds)
2024-07-12 17:45:18 | INFO | train_inner | epoch 005:    572 / 1132 loss=5.562, nll_loss=4.335, ppl=20.18, wps=10919.7, ups=3.03, wpb=3600.5, bsz=125.5, num_updates=5100, lr=0.000442807, gnorm=1.082, train_wall=23, wall=0
2024-07-12 17:45:41 | INFO | train_inner | epoch 005:    672 / 1132 loss=5.511, nll_loss=4.276, ppl=19.37, wps=15523.7, ups=4.35, wpb=3570.9, bsz=137.1, num_updates=5200, lr=0.000438529, gnorm=1.093, train_wall=23, wall=0
2024-07-12 17:46:04 | INFO | train_inner | epoch 005:    772 / 1132 loss=5.348, nll_loss=4.09, ppl=17.04, wps=15462.8, ups=4.36, wpb=3550.4, bsz=153.2, num_updates=5300, lr=0.000434372, gnorm=1.082, train_wall=23, wall=0
2024-07-12 17:46:27 | INFO | train_inner | epoch 005:    872 / 1132 loss=5.389, nll_loss=4.136, ppl=17.58, wps=15490.3, ups=4.35, wpb=3563.7, bsz=145, num_updates=5400, lr=0.000430331, gnorm=1.119, train_wall=23, wall=0
2024-07-12 17:46:50 | INFO | train_inner | epoch 005:    972 / 1132 loss=5.367, nll_loss=4.11, ppl=17.27, wps=15125.5, ups=4.34, wpb=3488.4, bsz=149.9, num_updates=5500, lr=0.000426401, gnorm=1.109, train_wall=23, wall=0
2024-07-12 17:46:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:46:54 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 5.144 | nll_loss 3.742 | ppl 13.38 | wps 44550.3 | wpb 2685.2 | bsz 107.1 | num_updates 5500 | best_loss 11.022
2024-07-12 17:46:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:46:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_5500.pt (epoch 5 @ 5500 updates, score 5.144) (writing took 4.923038248904049 seconds)
2024-07-12 17:47:22 | INFO | train_inner | epoch 005:   1072 / 1132 loss=5.415, nll_loss=4.165, ppl=17.94, wps=11016.4, ups=3.1, wpb=3549.8, bsz=128.8, num_updates=5600, lr=0.000422577, gnorm=1.074, train_wall=23, wall=0
2024-07-12 17:47:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:47:40 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 5.122 | nll_loss 3.711 | ppl 13.1 | wps 44086.9 | wpb 2685.2 | bsz 107.1 | num_updates 5660 | best_loss 11.022
2024-07-12 17:47:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:47:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 5 @ 5660 updates, score 5.122) (writing took 5.093217263929546 seconds)
2024-07-12 17:47:45 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2024-07-12 17:47:45 | INFO | train | epoch 005 | loss 5.5 | nll_loss 4.265 | ppl 19.22 | wps 13911.2 | ups 3.91 | wpb 3556.4 | bsz 141.6 | num_updates 5660 | lr 0.000420331 | gnorm 1.11 | train_wall 259 | wall 0
2024-07-12 17:47:45 | INFO | fairseq.trainer | begin training epoch 6
2024-07-12 17:47:54 | INFO | train_inner | epoch 006:     40 / 1132 loss=5.22, nll_loss=3.942, ppl=15.37, wps=10949.1, ups=3.08, wpb=3555.6, bsz=140.6, num_updates=5700, lr=0.000418854, gnorm=1.1, train_wall=23, wall=0
2024-07-12 17:48:18 | INFO | train_inner | epoch 006:    140 / 1132 loss=5.149, nll_loss=3.858, ppl=14.5, wps=15591, ups=4.33, wpb=3600.3, bsz=142.6, num_updates=5800, lr=0.000415227, gnorm=1.061, train_wall=23, wall=0
2024-07-12 17:48:40 | INFO | train_inner | epoch 006:    240 / 1132 loss=5.112, nll_loss=3.815, ppl=14.08, wps=15324.4, ups=4.36, wpb=3512.5, bsz=148, num_updates=5900, lr=0.000411693, gnorm=1.085, train_wall=23, wall=0
2024-07-12 17:49:03 | INFO | train_inner | epoch 006:    340 / 1132 loss=5.105, nll_loss=3.806, ppl=13.98, wps=15450.3, ups=4.35, wpb=3552.8, bsz=139.3, num_updates=6000, lr=0.000408248, gnorm=1.036, train_wall=23, wall=0
2024-07-12 17:49:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:49:08 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 4.97 | nll_loss 3.547 | ppl 11.69 | wps 44558.4 | wpb 2685.2 | bsz 107.1 | num_updates 6000 | best_loss 11.022
2024-07-12 17:49:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:49:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_6000.pt (epoch 6 @ 6000 updates, score 4.97) (writing took 5.110131287947297 seconds)
2024-07-12 17:49:36 | INFO | train_inner | epoch 006:    440 / 1132 loss=5.055, nll_loss=3.749, ppl=13.44, wps=11000, ups=3.09, wpb=3560.5, bsz=144.2, num_updates=6100, lr=0.000404888, gnorm=1.067, train_wall=23, wall=0
2024-07-12 17:49:59 | INFO | train_inner | epoch 006:    540 / 1132 loss=5.03, nll_loss=3.72, ppl=13.17, wps=15625, ups=4.41, wpb=3545.2, bsz=129.8, num_updates=6200, lr=0.00040161, gnorm=1.051, train_wall=23, wall=0
2024-07-12 17:50:21 | INFO | train_inner | epoch 006:    640 / 1132 loss=5.094, nll_loss=3.793, ppl=13.86, wps=15327.7, ups=4.36, wpb=3515, bsz=134.6, num_updates=6300, lr=0.00039841, gnorm=1.089, train_wall=23, wall=0
2024-07-12 17:50:45 | INFO | train_inner | epoch 006:    740 / 1132 loss=4.863, nll_loss=3.529, ppl=11.54, wps=15621, ups=4.29, wpb=3642.3, bsz=166.2, num_updates=6400, lr=0.000395285, gnorm=1.014, train_wall=23, wall=0
2024-07-12 17:51:08 | INFO | train_inner | epoch 006:    840 / 1132 loss=4.82, nll_loss=3.48, ppl=11.16, wps=15674.9, ups=4.36, wpb=3594.6, bsz=152.2, num_updates=6500, lr=0.000392232, gnorm=1.002, train_wall=23, wall=0
2024-07-12 17:51:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:51:12 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 4.839 | nll_loss 3.38 | ppl 10.41 | wps 44607.6 | wpb 2685.2 | bsz 107.1 | num_updates 6500 | best_loss 11.022
2024-07-12 17:51:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:51:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_6500.pt (epoch 6 @ 6500 updates, score 4.839) (writing took 4.866871626116335 seconds)
2024-07-12 17:51:40 | INFO | train_inner | epoch 006:    940 / 1132 loss=5.078, nll_loss=3.773, ppl=13.67, wps=10976.4, ups=3.09, wpb=3552.2, bsz=135.5, num_updates=6600, lr=0.000389249, gnorm=1.08, train_wall=23, wall=0
2024-07-12 17:52:03 | INFO | train_inner | epoch 006:   1040 / 1132 loss=5.033, nll_loss=3.722, ppl=13.19, wps=15275.8, ups=4.32, wpb=3532.4, bsz=130.7, num_updates=6700, lr=0.000386334, gnorm=1.076, train_wall=23, wall=0
2024-07-12 17:52:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:52:28 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 4.756 | nll_loss 3.291 | ppl 9.79 | wps 44359.6 | wpb 2685.2 | bsz 107.1 | num_updates 6792 | best_loss 11.022
2024-07-12 17:52:28 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:52:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 6 @ 6792 updates, score 4.756) (writing took 4.39600942004472 seconds)
2024-07-12 17:52:33 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2024-07-12 17:52:33 | INFO | train | epoch 006 | loss 5.028 | nll_loss 3.718 | ppl 13.16 | wps 13990 | ups 3.93 | wpb 3556.4 | bsz 141.6 | num_updates 6792 | lr 0.000383708 | gnorm 1.055 | train_wall 258 | wall 0
2024-07-12 17:52:33 | INFO | fairseq.trainer | begin training epoch 7
2024-07-12 17:52:35 | INFO | train_inner | epoch 007:      8 / 1132 loss=4.9, nll_loss=3.571, ppl=11.88, wps=11128.6, ups=3.15, wpb=3535.9, bsz=141, num_updates=6800, lr=0.000383482, gnorm=1.048, train_wall=23, wall=0
2024-07-12 17:52:58 | INFO | train_inner | epoch 007:    108 / 1132 loss=4.697, nll_loss=3.337, ppl=10.1, wps=15812.2, ups=4.36, wpb=3628.7, bsz=146.5, num_updates=6900, lr=0.000380693, gnorm=0.993, train_wall=23, wall=0
2024-07-12 17:53:20 | INFO | train_inner | epoch 007:    208 / 1132 loss=4.774, nll_loss=3.425, ppl=10.74, wps=15242.6, ups=4.44, wpb=3429.3, bsz=131.1, num_updates=7000, lr=0.000377964, gnorm=1.079, train_wall=22, wall=0
2024-07-12 17:53:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:53:25 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 4.736 | nll_loss 3.254 | ppl 9.54 | wps 44748.7 | wpb 2685.2 | bsz 107.1 | num_updates 7000 | best_loss 11.022
2024-07-12 17:53:25 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:53:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_7_7000.pt (epoch 7 @ 7000 updates, score 4.736) (writing took 11.978034931235015 seconds)
2024-07-12 17:54:00 | INFO | train_inner | epoch 007:    308 / 1132 loss=4.642, nll_loss=3.274, ppl=9.67, wps=9262.7, ups=2.53, wpb=3659.2, bsz=165, num_updates=7100, lr=0.000375293, gnorm=1.001, train_wall=23, wall=0
2024-07-12 17:54:23 | INFO | train_inner | epoch 007:    408 / 1132 loss=4.804, nll_loss=3.458, ppl=10.99, wps=15392.4, ups=4.37, wpb=3520.3, bsz=136, num_updates=7200, lr=0.000372678, gnorm=1.066, train_wall=23, wall=0
2024-07-12 17:54:46 | INFO | train_inner | epoch 007:    508 / 1132 loss=4.765, nll_loss=3.413, ppl=10.65, wps=15479, ups=4.34, wpb=3562.6, bsz=128.8, num_updates=7300, lr=0.000370117, gnorm=1.016, train_wall=23, wall=0
2024-07-12 17:55:09 | INFO | train_inner | epoch 007:    608 / 1132 loss=4.732, nll_loss=3.374, ppl=10.37, wps=15419.8, ups=4.33, wpb=3562.9, bsz=136.2, num_updates=7400, lr=0.000367607, gnorm=1.047, train_wall=23, wall=0
2024-07-12 17:55:32 | INFO | train_inner | epoch 007:    708 / 1132 loss=4.78, nll_loss=3.43, ppl=10.78, wps=15421.1, ups=4.32, wpb=3566.2, bsz=133.3, num_updates=7500, lr=0.000365148, gnorm=1.046, train_wall=23, wall=0
2024-07-12 17:55:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:55:36 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 4.624 | nll_loss 3.138 | ppl 8.81 | wps 44474.4 | wpb 2685.2 | bsz 107.1 | num_updates 7500 | best_loss 11.022
2024-07-12 17:55:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:55:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_7_7500.pt (epoch 7 @ 7500 updates, score 4.624) (writing took 5.430567247793078 seconds)
2024-07-12 17:56:05 | INFO | train_inner | epoch 007:    808 / 1132 loss=4.705, nll_loss=3.345, ppl=10.16, wps=10802.2, ups=3.07, wpb=3522.4, bsz=147.2, num_updates=7600, lr=0.000362738, gnorm=1.067, train_wall=23, wall=0
2024-07-12 17:56:27 | INFO | train_inner | epoch 007:    908 / 1132 loss=4.662, nll_loss=3.296, ppl=9.82, wps=15139.8, ups=4.39, wpb=3451.4, bsz=147.8, num_updates=7700, lr=0.000360375, gnorm=1.025, train_wall=23, wall=0
2024-07-12 17:56:51 | INFO | train_inner | epoch 007:   1008 / 1132 loss=4.68, nll_loss=3.317, ppl=9.97, wps=15637.3, ups=4.31, wpb=3625, bsz=139, num_updates=7800, lr=0.000358057, gnorm=1.015, train_wall=23, wall=0
2024-07-12 17:57:14 | INFO | train_inner | epoch 007:   1108 / 1132 loss=4.67, nll_loss=3.306, ppl=9.89, wps=15519.8, ups=4.35, wpb=3566.3, bsz=142.1, num_updates=7900, lr=0.000355784, gnorm=1.033, train_wall=23, wall=0
2024-07-12 17:57:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:57:23 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 4.55 | nll_loss 3.057 | ppl 8.32 | wps 44651.9 | wpb 2685.2 | bsz 107.1 | num_updates 7924 | best_loss 11.022
2024-07-12 17:57:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:57:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 7 @ 7924 updates, score 4.55) (writing took 4.71148098539561 seconds)
2024-07-12 17:57:28 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2024-07-12 17:57:28 | INFO | train | epoch 007 | loss 4.718 | nll_loss 3.36 | ppl 10.27 | wps 13632.7 | ups 3.83 | wpb 3556.4 | bsz 141.6 | num_updates 7924 | lr 0.000355245 | gnorm 1.033 | train_wall 258 | wall 0
2024-07-12 17:57:28 | INFO | fairseq.trainer | begin training epoch 8
2024-07-12 17:57:46 | INFO | train_inner | epoch 008:     76 / 1132 loss=4.491, nll_loss=3.1, ppl=8.58, wps=11304.3, ups=3.09, wpb=3662, bsz=152.7, num_updates=8000, lr=0.000353553, gnorm=0.973, train_wall=23, wall=0
2024-07-12 17:57:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:57:50 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 4.552 | nll_loss 3.05 | ppl 8.28 | wps 44577.6 | wpb 2685.2 | bsz 107.1 | num_updates 8000 | best_loss 11.022
2024-07-12 17:57:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:57:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_8000.pt (epoch 8 @ 8000 updates, score 4.552) (writing took 5.4747713515535 seconds)
2024-07-12 17:58:18 | INFO | train_inner | epoch 008:    176 / 1132 loss=4.539, nll_loss=3.156, ppl=8.91, wps=10905.3, ups=3.08, wpb=3537.3, bsz=145.3, num_updates=8100, lr=0.000351364, gnorm=1.033, train_wall=23, wall=0
2024-07-12 17:58:42 | INFO | train_inner | epoch 008:    276 / 1132 loss=4.574, nll_loss=3.194, ppl=9.15, wps=15465, ups=4.34, wpb=3565.1, bsz=135.2, num_updates=8200, lr=0.000349215, gnorm=1.019, train_wall=23, wall=0
2024-07-12 17:59:04 | INFO | train_inner | epoch 008:    376 / 1132 loss=4.549, nll_loss=3.165, ppl=8.97, wps=15389.3, ups=4.36, wpb=3526.4, bsz=125, num_updates=8300, lr=0.000347105, gnorm=1.015, train_wall=23, wall=0
2024-07-12 17:59:27 | INFO | train_inner | epoch 008:    476 / 1132 loss=4.406, nll_loss=3.004, ppl=8.02, wps=15630.8, ups=4.36, wpb=3584.7, bsz=166.6, num_updates=8400, lr=0.000345033, gnorm=0.972, train_wall=23, wall=0
2024-07-12 17:59:50 | INFO | train_inner | epoch 008:    576 / 1132 loss=4.504, nll_loss=3.114, ppl=8.66, wps=15251.2, ups=4.38, wpb=3482.1, bsz=143.2, num_updates=8500, lr=0.000342997, gnorm=1.063, train_wall=23, wall=0
2024-07-12 17:59:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 17:59:54 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 4.5 | nll_loss 2.999 | ppl 7.99 | wps 44563.7 | wpb 2685.2 | bsz 107.1 | num_updates 8500 | best_loss 11.022
2024-07-12 17:59:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 17:59:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_8500.pt (epoch 8 @ 8500 updates, score 4.5) (writing took 4.884418953210115 seconds)
2024-07-12 18:00:23 | INFO | train_inner | epoch 008:    676 / 1132 loss=4.467, nll_loss=3.072, ppl=8.41, wps=11146, ups=3.09, wpb=3611.2, bsz=147.9, num_updates=8600, lr=0.000340997, gnorm=0.974, train_wall=23, wall=0
2024-07-12 18:00:46 | INFO | train_inner | epoch 008:    776 / 1132 loss=4.512, nll_loss=3.125, ppl=8.73, wps=15332.9, ups=4.32, wpb=3551.3, bsz=139.8, num_updates=8700, lr=0.000339032, gnorm=1.042, train_wall=23, wall=0
2024-07-12 18:01:09 | INFO | train_inner | epoch 008:    876 / 1132 loss=4.541, nll_loss=3.156, ppl=8.91, wps=15370.9, ups=4.31, wpb=3568.9, bsz=132.3, num_updates=8800, lr=0.0003371, gnorm=1.013, train_wall=23, wall=0
2024-07-12 18:01:32 | INFO | train_inner | epoch 008:    976 / 1132 loss=4.472, nll_loss=3.079, ppl=8.45, wps=15459.1, ups=4.35, wpb=3555.7, bsz=135.8, num_updates=8900, lr=0.000335201, gnorm=0.98, train_wall=23, wall=0
2024-07-12 18:01:55 | INFO | train_inner | epoch 008:   1076 / 1132 loss=4.542, nll_loss=3.158, ppl=8.93, wps=15045.2, ups=4.35, wpb=3455.8, bsz=131, num_updates=9000, lr=0.000333333, gnorm=1.044, train_wall=23, wall=0
2024-07-12 18:01:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:01:59 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 4.429 | nll_loss 2.921 | ppl 7.57 | wps 44245 | wpb 2685.2 | bsz 107.1 | num_updates 9000 | best_loss 11.022
2024-07-12 18:01:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:02:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_9000.pt (epoch 8 @ 9000 updates, score 4.429) (writing took 10.145757368765771 seconds)
2024-07-12 18:02:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:02:27 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 4.397 | nll_loss 2.884 | ppl 7.38 | wps 44130 | wpb 2685.2 | bsz 107.1 | num_updates 9056 | best_loss 11.022
2024-07-12 18:02:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:02:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 8 @ 9056 updates, score 4.397) (writing took 4.5993433725088835 seconds)
2024-07-12 18:02:31 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2024-07-12 18:02:31 | INFO | train | epoch 008 | loss 4.501 | nll_loss 3.111 | ppl 8.64 | wps 13278.6 | ups 3.73 | wpb 3556.4 | bsz 141.6 | num_updates 9056 | lr 0.000332301 | gnorm 1.01 | train_wall 259 | wall 0
2024-07-12 18:02:31 | INFO | fairseq.trainer | begin training epoch 9
2024-07-12 18:02:42 | INFO | train_inner | epoch 009:     44 / 1132 loss=4.348, nll_loss=2.936, ppl=7.66, wps=7795.4, ups=2.14, wpb=3650, bsz=146.2, num_updates=9100, lr=0.000331497, gnorm=0.955, train_wall=23, wall=0
2024-07-12 18:03:05 | INFO | train_inner | epoch 009:    144 / 1132 loss=4.296, nll_loss=2.878, ppl=7.35, wps=15526.9, ups=4.34, wpb=3575.4, bsz=140.3, num_updates=9200, lr=0.00032969, gnorm=0.982, train_wall=23, wall=0
2024-07-12 18:03:28 | INFO | train_inner | epoch 009:    244 / 1132 loss=4.378, nll_loss=2.97, ppl=7.83, wps=15300.4, ups=4.39, wpb=3485.7, bsz=132.5, num_updates=9300, lr=0.000327913, gnorm=1.04, train_wall=23, wall=0
2024-07-12 18:03:51 | INFO | train_inner | epoch 009:    344 / 1132 loss=4.351, nll_loss=2.939, ppl=7.67, wps=15484.4, ups=4.28, wpb=3620.1, bsz=141.8, num_updates=9400, lr=0.000326164, gnorm=1.012, train_wall=23, wall=0
2024-07-12 18:04:14 | INFO | train_inner | epoch 009:    444 / 1132 loss=4.3, nll_loss=2.881, ppl=7.37, wps=15604.2, ups=4.32, wpb=3614.7, bsz=147.8, num_updates=9500, lr=0.000324443, gnorm=0.953, train_wall=23, wall=0
2024-07-12 18:04:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:04:18 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 4.37 | nll_loss 2.846 | ppl 7.19 | wps 44228.1 | wpb 2685.2 | bsz 107.1 | num_updates 9500 | best_loss 11.022
2024-07-12 18:04:18 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:04:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_9_9500.pt (epoch 9 @ 9500 updates, score 4.37) (writing took 5.229737428016961 seconds)
2024-07-12 18:04:47 | INFO | train_inner | epoch 009:    544 / 1132 loss=4.317, nll_loss=2.902, ppl=7.47, wps=10909.1, ups=3.07, wpb=3552.4, bsz=147.1, num_updates=9600, lr=0.000322749, gnorm=1.042, train_wall=23, wall=0
2024-07-12 18:05:10 | INFO | train_inner | epoch 009:    644 / 1132 loss=4.364, nll_loss=2.955, ppl=7.76, wps=15380.6, ups=4.36, wpb=3528.6, bsz=138.2, num_updates=9700, lr=0.000321081, gnorm=1.016, train_wall=23, wall=0
2024-07-12 18:05:32 | INFO | train_inner | epoch 009:    744 / 1132 loss=4.335, nll_loss=2.922, ppl=7.58, wps=15488.4, ups=4.38, wpb=3534.8, bsz=135, num_updates=9800, lr=0.000319438, gnorm=1.003, train_wall=23, wall=0
2024-07-12 18:05:55 | INFO | train_inner | epoch 009:    844 / 1132 loss=4.351, nll_loss=2.94, ppl=7.68, wps=15674.7, ups=4.38, wpb=3580.6, bsz=150.1, num_updates=9900, lr=0.000317821, gnorm=1.012, train_wall=23, wall=0
2024-07-12 18:06:18 | INFO | train_inner | epoch 009:    944 / 1132 loss=4.357, nll_loss=2.948, ppl=7.71, wps=15313.2, ups=4.35, wpb=3523.7, bsz=139.5, num_updates=10000, lr=0.000316228, gnorm=1.002, train_wall=23, wall=0
2024-07-12 18:06:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:06:23 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 4.328 | nll_loss 2.803 | ppl 6.98 | wps 44533 | wpb 2685.2 | bsz 107.1 | num_updates 10000 | best_loss 11.022
2024-07-12 18:06:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:06:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_9_10000.pt (epoch 9 @ 10000 updates, score 4.328) (writing took 4.9625739101320505 seconds)
2024-07-12 18:06:28 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2024-07-12 18:06:28 | INFO | train | epoch 009 | loss 4.335 | nll_loss 2.921 | ppl 7.58 | wps 14240.3 | ups 4 | wpb 3562.2 | bsz 141.5 | num_updates 10000 | lr 0.000316228 | gnorm 1.004 | train_wall 215 | wall 0
2024-07-12 18:06:28 | INFO | fairseq_cli.train | done training in 2336.2 seconds
2024-07-12 18:06:31 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.sep.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=100000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=1000, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-12 18:06:31 | INFO | fairseq.tasks.translation | [de] dictionary: 9952 types
2024-07-12 18:06:31 | INFO | fairseq.tasks.translation | [en] dictionary: 9840 types
2024-07-12 18:06:31 | INFO | fairseq.data.data_utils | loaded 7283 examples from: data-bin/iwslt14.sep.tokenized.de-en/valid.de-en.de
2024-07-12 18:06:31 | INFO | fairseq.data.data_utils | loaded 7283 examples from: data-bin/iwslt14.sep.tokenized.de-en/valid.de-en.en
2024-07-12 18:06:31 | INFO | fairseq.tasks.translation | data-bin/iwslt14.sep.tokenized.de-en valid de-en 7283 examples
2024-07-12 18:06:32 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9952, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9840, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=9840, bias=False)
  )
)
2024-07-12 18:06:32 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-12 18:06:32 | INFO | fairseq_cli.train | model: transformer_wmt_en_de (TransformerModel)
2024-07-12 18:06:32 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-12 18:06:32 | INFO | fairseq_cli.train | num. model params: 54272000 (num. trained: 54272000)
2024-07-12 18:06:39 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-12 18:06:39 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-12 18:06:39 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-12 18:06:39 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-12 18:06:39 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-12 18:06:39 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-12 18:06:41 | INFO | fairseq.trainer | loaded checkpoint checkpoints/checkpoint_last.pt (epoch 9 @ 10000 updates)
2024-07-12 18:06:41 | INFO | fairseq.trainer | loading train data for epoch 9
2024-07-12 18:06:41 | INFO | fairseq.data.data_utils | loaded 160239 examples from: data-bin/iwslt14.sep.tokenized.de-en/train.de-en.de
2024-07-12 18:06:41 | INFO | fairseq.data.data_utils | loaded 160239 examples from: data-bin/iwslt14.sep.tokenized.de-en/train.de-en.en
2024-07-12 18:06:41 | INFO | fairseq.tasks.translation | data-bin/iwslt14.sep.tokenized.de-en train de-en 160239 examples
2024-07-12 18:06:41 | INFO | fairseq.trainer | begin training epoch 9
2024-07-12 18:07:05 | INFO | train_inner | epoch 009:   1044 / 1132 loss=4.373, nll_loss=2.966, ppl=7.81, wps=12555.1, ups=3.55, wpb=3532.7, bsz=140.4, num_updates=10100, lr=0.000314658, gnorm=1.011, train_wall=23, wall=0
2024-07-12 18:07:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-12 18:07:29 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 4.343 | nll_loss 2.832 | ppl 7.12 | wps 44953.1 | wpb 2685.2 | bsz 107.1 | num_updates 10188 | best_loss 11.022
2024-07-12 18:07:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:07:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 9 @ 10188 updates, score 4.343) (writing took 4.42273342050612 seconds)
2024-07-12 18:07:34 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2024-07-12 18:07:34 | INFO | train | epoch 009 | loss 4.337 | nll_loss 2.925 | ppl 7.59 | wps 14179.9 | ups 3.99 | wpb 3556.4 | bsz 141.6 | num_updates 10188 | lr 0.000313296 | gnorm 1.005 | train_wall 259 | wall 0
2024-07-12 18:07:34 | INFO | fairseq.trainer | begin training epoch 10
2024-07-12 18:07:37 | INFO | train_inner | epoch 010:     12 / 1132 loss=4.315, nll_loss=2.901, ppl=7.47, wps=11117.7, ups=3.15, wpb=3534.3, bsz=143, num_updates=10200, lr=0.000313112, gnorm=1.033, train_wall=23, wall=0
2024-07-12 18:07:59 | INFO | train_inner | epoch 010:    112 / 1132 loss=4.172, nll_loss=2.736, ppl=6.66, wps=15716.3, ups=4.4, wpb=3572.9, bsz=147.4, num_updates=10300, lr=0.000311588, gnorm=0.99, train_wall=23, wall=0
2024-07-12 18:08:22 | INFO | train_inner | epoch 010:    212 / 1132 loss=4.226, nll_loss=2.797, ppl=6.95, wps=15501.4, ups=4.41, wpb=3514.7, bsz=131, num_updates=10400, lr=0.000310087, gnorm=1.006, train_wall=22, wall=0
2024-07-12 18:08:45 | INFO | train_inner | epoch 010:    312 / 1132 loss=4.191, nll_loss=2.757, ppl=6.76, wps=15560.1, ups=4.32, wpb=3601, bsz=143.2, num_updates=10500, lr=0.000308607, gnorm=0.964, train_wall=23, wall=0
2024-07-12 18:09:08 | INFO | train_inner | epoch 010:    412 / 1132 loss=4.165, nll_loss=2.728, ppl=6.63, wps=15811.1, ups=4.33, wpb=3651.6, bsz=150.5, num_updates=10600, lr=0.000307148, gnorm=0.954, train_wall=23, wall=0
2024-07-12 18:09:31 | INFO | train_inner | epoch 010:    512 / 1132 loss=4.239, nll_loss=2.812, ppl=7.02, wps=15336.8, ups=4.43, wpb=3465.6, bsz=137.4, num_updates=10700, lr=0.000305709, gnorm=1.047, train_wall=22, wall=0
2024-07-12 18:09:54 | INFO | train_inner | epoch 010:    612 / 1132 loss=4.216, nll_loss=2.785, ppl=6.89, wps=15444.7, ups=4.36, wpb=3539.9, bsz=140, num_updates=10800, lr=0.00030429, gnorm=0.971, train_wall=23, wall=0
2024-07-12 18:10:17 | INFO | train_inner | epoch 010:    712 / 1132 loss=4.186, nll_loss=2.753, ppl=6.74, wps=15684.7, ups=4.37, wpb=3588.7, bsz=138.2, num_updates=10900, lr=0.000302891, gnorm=0.956, train_wall=23, wall=0
2024-07-12 18:10:40 | INFO | train_inner | epoch 010:    812 / 1132 loss=4.199, nll_loss=2.767, ppl=6.8, wps=15528.8, ups=4.3, wpb=3612.7, bsz=143.8, num_updates=11000, lr=0.000301511, gnorm=0.974, train_wall=23, wall=0
2024-07-12 18:10:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:10:44 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.262 | nll_loss 2.716 | ppl 6.57 | wps 44985.3 | wpb 2685.2 | bsz 107.1 | num_updates 11000 | best_loss 11.022
2024-07-12 18:10:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:10:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_10_11000.pt (epoch 10 @ 11000 updates, score 4.262) (writing took 5.151006358675659 seconds)
2024-07-12 18:11:12 | INFO | train_inner | epoch 010:    912 / 1132 loss=4.284, nll_loss=2.864, ppl=7.28, wps=10993.5, ups=3.14, wpb=3505.6, bsz=129, num_updates=11100, lr=0.00030015, gnorm=1.026, train_wall=22, wall=0
2024-07-12 18:11:35 | INFO | train_inner | epoch 010:   1012 / 1132 loss=4.203, nll_loss=2.773, ppl=6.83, wps=15667.5, ups=4.39, wpb=3569.3, bsz=149.9, num_updates=11200, lr=0.000298807, gnorm=1.006, train_wall=23, wall=0
2024-07-12 18:11:58 | INFO | train_inner | epoch 010:   1112 / 1132 loss=4.166, nll_loss=2.731, ppl=6.64, wps=15435.5, ups=4.38, wpb=3521.6, bsz=156.1, num_updates=11300, lr=0.000297482, gnorm=0.996, train_wall=23, wall=0
2024-07-12 18:12:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:12:06 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.262 | nll_loss 2.73 | ppl 6.63 | wps 44491.8 | wpb 2685.2 | bsz 107.1 | num_updates 11320 | best_loss 11.022
2024-07-12 18:12:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:12:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 10 @ 11320 updates, score 4.262) (writing took 15.035132422111928 seconds)
2024-07-12 18:12:21 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2024-07-12 18:12:21 | INFO | train | epoch 010 | loss 4.209 | nll_loss 2.778 | ppl 6.86 | wps 14005.6 | ups 3.94 | wpb 3556.4 | bsz 141.6 | num_updates 11320 | lr 0.000297219 | gnorm 0.997 | train_wall 257 | wall 0
2024-07-12 18:12:21 | INFO | fairseq.trainer | begin training epoch 11
2024-07-12 18:12:40 | INFO | train_inner | epoch 011:     80 / 1132 loss=4.196, nll_loss=2.763, ppl=6.79, wps=8298.5, ups=2.37, wpb=3505, bsz=124.5, num_updates=11400, lr=0.000296174, gnorm=1.055, train_wall=23, wall=0
2024-07-12 18:13:03 | INFO | train_inner | epoch 011:    180 / 1132 loss=4.099, nll_loss=2.652, ppl=6.29, wps=15590.9, ups=4.38, wpb=3563.1, bsz=140.6, num_updates=11500, lr=0.000294884, gnorm=0.992, train_wall=23, wall=0
2024-07-12 18:13:26 | INFO | train_inner | epoch 011:    280 / 1132 loss=4.107, nll_loss=2.661, ppl=6.33, wps=15550.5, ups=4.35, wpb=3576.6, bsz=132.6, num_updates=11600, lr=0.00029361, gnorm=0.984, train_wall=23, wall=0
2024-07-12 18:13:49 | INFO | train_inner | epoch 011:    380 / 1132 loss=4.099, nll_loss=2.652, ppl=6.28, wps=15488.4, ups=4.35, wpb=3562.7, bsz=144.6, num_updates=11700, lr=0.000292353, gnorm=0.968, train_wall=23, wall=0
2024-07-12 18:14:11 | INFO | train_inner | epoch 011:    480 / 1132 loss=4.061, nll_loss=2.612, ppl=6.11, wps=15800.3, ups=4.38, wpb=3606.3, bsz=152.1, num_updates=11800, lr=0.000291111, gnorm=0.965, train_wall=23, wall=0
2024-07-12 18:14:35 | INFO | train_inner | epoch 011:    580 / 1132 loss=4.078, nll_loss=2.628, ppl=6.18, wps=15536.8, ups=4.34, wpb=3582.6, bsz=145.3, num_updates=11900, lr=0.000289886, gnorm=0.967, train_wall=23, wall=0
2024-07-12 18:14:57 | INFO | train_inner | epoch 011:    680 / 1132 loss=4.059, nll_loss=2.608, ppl=6.1, wps=15522.6, ups=4.39, wpb=3537.9, bsz=154.9, num_updates=12000, lr=0.000288675, gnorm=0.991, train_wall=23, wall=0
2024-07-12 18:14:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:15:02 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.21 | nll_loss 2.668 | ppl 6.35 | wps 45121.3 | wpb 2685.2 | bsz 107.1 | num_updates 12000 | best_loss 11.022
2024-07-12 18:15:02 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:15:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_11_12000.pt (epoch 11 @ 12000 updates, score 4.21) (writing took 14.473581414669752 seconds)
2024-07-12 18:15:39 | INFO | train_inner | epoch 011:    780 / 1132 loss=4.092, nll_loss=2.646, ppl=6.26, wps=8471.3, ups=2.42, wpb=3507.6, bsz=150.6, num_updates=12100, lr=0.00028748, gnorm=1.022, train_wall=23, wall=0
2024-07-12 18:16:02 | INFO | train_inner | epoch 011:    880 / 1132 loss=4.14, nll_loss=2.701, ppl=6.5, wps=15507.3, ups=4.36, wpb=3555.6, bsz=139.7, num_updates=12200, lr=0.000286299, gnorm=1.007, train_wall=23, wall=0
2024-07-12 18:16:25 | INFO | train_inner | epoch 011:    980 / 1132 loss=4.156, nll_loss=2.719, ppl=6.58, wps=15533.9, ups=4.35, wpb=3572.8, bsz=128, num_updates=12300, lr=0.000285133, gnorm=0.984, train_wall=23, wall=0
2024-07-12 18:16:47 | INFO | train_inner | epoch 011:   1080 / 1132 loss=4.136, nll_loss=2.696, ppl=6.48, wps=15492.3, ups=4.4, wpb=3522.4, bsz=134.7, num_updates=12400, lr=0.000283981, gnorm=1.019, train_wall=23, wall=0
2024-07-12 18:16:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:17:03 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.17 | nll_loss 2.626 | ppl 6.17 | wps 44914.9 | wpb 2685.2 | bsz 107.1 | num_updates 12452 | best_loss 11.022
2024-07-12 18:17:03 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:17:07 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 11 @ 12452 updates, score 4.17) (writing took 3.4365608543157578 seconds)
2024-07-12 18:17:07 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2024-07-12 18:17:07 | INFO | train | epoch 011 | loss 4.104 | nll_loss 2.659 | ppl 6.32 | wps 14095.6 | ups 3.96 | wpb 3556.4 | bsz 141.6 | num_updates 12452 | lr 0.000283387 | gnorm 0.992 | train_wall 257 | wall 0
2024-07-12 18:17:07 | INFO | fairseq.trainer | begin training epoch 12
2024-07-12 18:17:18 | INFO | train_inner | epoch 012:     48 / 1132 loss=4.025, nll_loss=2.57, ppl=5.94, wps=11628.4, ups=3.26, wpb=3570.3, bsz=150.9, num_updates=12500, lr=0.000282843, gnorm=0.986, train_wall=23, wall=0
2024-07-12 18:17:41 | INFO | train_inner | epoch 012:    148 / 1132 loss=4.018, nll_loss=2.56, ppl=5.9, wps=15636.8, ups=4.32, wpb=3622.5, bsz=143.3, num_updates=12600, lr=0.000281718, gnorm=0.982, train_wall=23, wall=0
2024-07-12 18:18:04 | INFO | train_inner | epoch 012:    248 / 1132 loss=4.032, nll_loss=2.575, ppl=5.96, wps=15391.7, ups=4.39, wpb=3502.5, bsz=132.3, num_updates=12700, lr=0.000280607, gnorm=1.004, train_wall=23, wall=0
2024-07-12 18:18:27 | INFO | train_inner | epoch 012:    348 / 1132 loss=3.929, nll_loss=2.46, ppl=5.5, wps=15698.3, ups=4.32, wpb=3634.4, bsz=160.2, num_updates=12800, lr=0.000279508, gnorm=0.952, train_wall=23, wall=0
2024-07-12 18:18:50 | INFO | train_inner | epoch 012:    448 / 1132 loss=4.006, nll_loss=2.547, ppl=5.84, wps=15482.3, ups=4.4, wpb=3517.8, bsz=135.3, num_updates=12900, lr=0.000278423, gnorm=0.976, train_wall=23, wall=0
2024-07-12 18:19:13 | INFO | train_inner | epoch 012:    548 / 1132 loss=4.009, nll_loss=2.552, ppl=5.87, wps=15485.6, ups=4.42, wpb=3506.8, bsz=143.4, num_updates=13000, lr=0.00027735, gnorm=0.982, train_wall=22, wall=0
2024-07-12 18:19:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:19:17 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.16 | nll_loss 2.603 | ppl 6.08 | wps 45000.8 | wpb 2685.2 | bsz 107.1 | num_updates 13000 | best_loss 11.022
2024-07-12 18:19:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:19:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_12_13000.pt (epoch 12 @ 13000 updates, score 4.16) (writing took 4.092489765956998 seconds)
2024-07-12 18:19:44 | INFO | train_inner | epoch 012:    648 / 1132 loss=4.041, nll_loss=2.587, ppl=6.01, wps=11419.6, ups=3.21, wpb=3558.4, bsz=131.5, num_updates=13100, lr=0.000276289, gnorm=0.978, train_wall=23, wall=0
2024-07-12 18:20:06 | INFO | train_inner | epoch 012:    748 / 1132 loss=4.034, nll_loss=2.58, ppl=5.98, wps=15746.4, ups=4.42, wpb=3560.4, bsz=136.6, num_updates=13200, lr=0.000275241, gnorm=0.986, train_wall=22, wall=0
2024-07-12 18:20:29 | INFO | train_inner | epoch 012:    848 / 1132 loss=4.059, nll_loss=2.609, ppl=6.1, wps=15328.5, ups=4.42, wpb=3470.6, bsz=143.3, num_updates=13300, lr=0.000274204, gnorm=1.05, train_wall=22, wall=0
2024-07-12 18:20:52 | INFO | train_inner | epoch 012:    948 / 1132 loss=4.019, nll_loss=2.563, ppl=5.91, wps=15671.8, ups=4.41, wpb=3554.3, bsz=135.6, num_updates=13400, lr=0.000273179, gnorm=0.973, train_wall=23, wall=0
2024-07-12 18:21:14 | INFO | train_inner | epoch 012:   1048 / 1132 loss=4, nll_loss=2.543, ppl=5.83, wps=15984.1, ups=4.43, wpb=3610.5, bsz=140.2, num_updates=13500, lr=0.000272166, gnorm=0.962, train_wall=22, wall=0
2024-07-12 18:21:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:21:38 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.114 | nll_loss 2.566 | ppl 5.92 | wps 45029.2 | wpb 2685.2 | bsz 107.1 | num_updates 13584 | best_loss 11.022
2024-07-12 18:21:38 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:21:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 12 @ 13584 updates, score 4.114) (writing took 3.3996069645509124 seconds)
2024-07-12 18:21:41 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2024-07-12 18:21:41 | INFO | train | epoch 012 | loss 4.013 | nll_loss 2.556 | ppl 5.88 | wps 14683 | ups 4.13 | wpb 3556.4 | bsz 141.6 | num_updates 13584 | lr 0.000271323 | gnorm 0.984 | train_wall 256 | wall 0
2024-07-12 18:21:41 | INFO | fairseq.trainer | begin training epoch 13
2024-07-12 18:21:45 | INFO | train_inner | epoch 013:     16 / 1132 loss=4.021, nll_loss=2.566, ppl=5.92, wps=11580.9, ups=3.27, wpb=3544.4, bsz=143, num_updates=13600, lr=0.000271163, gnorm=0.997, train_wall=23, wall=0
2024-07-12 18:22:08 | INFO | train_inner | epoch 013:    116 / 1132 loss=3.908, nll_loss=2.435, ppl=5.41, wps=15702, ups=4.38, wpb=3582.2, bsz=133.4, num_updates=13700, lr=0.000270172, gnorm=0.942, train_wall=23, wall=0
2024-07-12 18:22:31 | INFO | train_inner | epoch 013:    216 / 1132 loss=3.868, nll_loss=2.391, ppl=5.24, wps=15536.5, ups=4.35, wpb=3572.4, bsz=153, num_updates=13800, lr=0.000269191, gnorm=0.941, train_wall=23, wall=0
2024-07-12 18:22:54 | INFO | train_inner | epoch 013:    316 / 1132 loss=3.929, nll_loss=2.46, ppl=5.5, wps=15392.5, ups=4.35, wpb=3536.8, bsz=139.3, num_updates=13900, lr=0.000268221, gnorm=1.009, train_wall=23, wall=0
2024-07-12 18:23:17 | INFO | train_inner | epoch 013:    416 / 1132 loss=3.944, nll_loss=2.477, ppl=5.57, wps=15303, ups=4.36, wpb=3513.1, bsz=144.6, num_updates=14000, lr=0.000267261, gnorm=1.001, train_wall=23, wall=0
2024-07-12 18:23:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:23:21 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.135 | nll_loss 2.567 | ppl 5.92 | wps 44921.4 | wpb 2685.2 | bsz 107.1 | num_updates 14000 | best_loss 11.022
2024-07-12 18:23:21 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:23:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_13_14000.pt (epoch 13 @ 14000 updates, score 4.135) (writing took 4.26316315215081 seconds)
2024-07-12 18:23:48 | INFO | train_inner | epoch 013:    516 / 1132 loss=3.935, nll_loss=2.467, ppl=5.53, wps=11373.5, ups=3.19, wpb=3561.1, bsz=139.6, num_updates=14100, lr=0.000266312, gnorm=0.971, train_wall=23, wall=0
2024-07-12 18:24:11 | INFO | train_inner | epoch 013:    616 / 1132 loss=3.922, nll_loss=2.451, ppl=5.47, wps=15764, ups=4.32, wpb=3646.9, bsz=154.1, num_updates=14200, lr=0.000265372, gnorm=0.943, train_wall=23, wall=0
2024-07-12 18:24:34 | INFO | train_inner | epoch 013:    716 / 1132 loss=3.946, nll_loss=2.48, ppl=5.58, wps=15458.3, ups=4.38, wpb=3528.1, bsz=144.6, num_updates=14300, lr=0.000264443, gnorm=0.982, train_wall=23, wall=0
2024-07-12 18:24:57 | INFO | train_inner | epoch 013:    816 / 1132 loss=3.981, nll_loss=2.519, ppl=5.73, wps=15375.2, ups=4.4, wpb=3492.1, bsz=129.3, num_updates=14400, lr=0.000263523, gnorm=1.019, train_wall=23, wall=0
2024-07-12 18:25:20 | INFO | train_inner | epoch 013:    916 / 1132 loss=3.965, nll_loss=2.503, ppl=5.67, wps=15726.7, ups=4.31, wpb=3648.9, bsz=135.8, num_updates=14500, lr=0.000262613, gnorm=0.957, train_wall=23, wall=0
2024-07-12 18:25:42 | INFO | train_inner | epoch 013:   1016 / 1132 loss=3.922, nll_loss=2.454, ppl=5.48, wps=15652.5, ups=4.44, wpb=3526.8, bsz=137.8, num_updates=14600, lr=0.000261712, gnorm=0.972, train_wall=22, wall=0
2024-07-12 18:26:05 | INFO | train_inner | epoch 013:   1116 / 1132 loss=3.957, nll_loss=2.495, ppl=5.64, wps=15494.3, ups=4.41, wpb=3517.3, bsz=151, num_updates=14700, lr=0.00026082, gnorm=1.045, train_wall=23, wall=0
2024-07-12 18:26:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:26:13 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.11 | nll_loss 2.549 | ppl 5.85 | wps 44875.8 | wpb 2685.2 | bsz 107.1 | num_updates 14716 | best_loss 11.022
2024-07-12 18:26:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:26:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 13 @ 14716 updates, score 4.11) (writing took 3.634146328084171 seconds)
2024-07-12 18:26:16 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2024-07-12 18:26:16 | INFO | train | epoch 013 | loss 3.936 | nll_loss 2.468 | ppl 5.53 | wps 14614 | ups 4.11 | wpb 3556.4 | bsz 141.6 | num_updates 14716 | lr 0.000260678 | gnorm 0.983 | train_wall 257 | wall 0
2024-07-12 18:26:17 | INFO | fairseq.trainer | begin training epoch 14
2024-07-12 18:26:36 | INFO | train_inner | epoch 014:     84 / 1132 loss=3.825, nll_loss=2.343, ppl=5.07, wps=11461.1, ups=3.25, wpb=3525.2, bsz=143.1, num_updates=14800, lr=0.000259938, gnorm=0.978, train_wall=23, wall=0
2024-07-12 18:26:59 | INFO | train_inner | epoch 014:    184 / 1132 loss=3.835, nll_loss=2.353, ppl=5.11, wps=15610.1, ups=4.36, wpb=3579.2, bsz=136.2, num_updates=14900, lr=0.000259064, gnorm=0.957, train_wall=23, wall=0
2024-07-12 18:27:21 | INFO | train_inner | epoch 014:    284 / 1132 loss=3.867, nll_loss=2.391, ppl=5.24, wps=15658, ups=4.5, wpb=3481, bsz=128.2, num_updates=15000, lr=0.000258199, gnorm=0.985, train_wall=22, wall=0
2024-07-12 18:27:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:27:25 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.097 | nll_loss 2.534 | ppl 5.79 | wps 44764.2 | wpb 2685.2 | bsz 107.1 | num_updates 15000 | best_loss 11.022
2024-07-12 18:27:25 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:27:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_14_15000.pt (epoch 14 @ 15000 updates, score 4.097) (writing took 4.196195472031832 seconds)
2024-07-12 18:27:52 | INFO | train_inner | epoch 014:    384 / 1132 loss=3.872, nll_loss=2.395, ppl=5.26, wps=11320.2, ups=3.18, wpb=3559.1, bsz=136.7, num_updates=15100, lr=0.000257343, gnorm=0.987, train_wall=23, wall=0
2024-07-12 18:28:16 | INFO | train_inner | epoch 014:    484 / 1132 loss=3.87, nll_loss=2.393, ppl=5.25, wps=15835, ups=4.29, wpb=3694, bsz=142, num_updates=15200, lr=0.000256495, gnorm=0.939, train_wall=23, wall=0
2024-07-12 18:28:39 | INFO | train_inner | epoch 014:    584 / 1132 loss=3.88, nll_loss=2.404, ppl=5.29, wps=15715.1, ups=4.37, wpb=3597.1, bsz=137.4, num_updates=15300, lr=0.000255655, gnorm=0.98, train_wall=23, wall=0
2024-07-12 18:29:02 | INFO | train_inner | epoch 014:    684 / 1132 loss=3.855, nll_loss=2.375, ppl=5.19, wps=15436.3, ups=4.32, wpb=3572.6, bsz=157.7, num_updates=15400, lr=0.000254824, gnorm=0.992, train_wall=23, wall=0
2024-07-12 18:29:25 | INFO | train_inner | epoch 014:    784 / 1132 loss=3.876, nll_loss=2.402, ppl=5.28, wps=15744, ups=4.37, wpb=3604.2, bsz=145.7, num_updates=15500, lr=0.000254, gnorm=0.975, train_wall=23, wall=0
2024-07-12 18:29:48 | INFO | train_inner | epoch 014:    884 / 1132 loss=3.883, nll_loss=2.409, ppl=5.31, wps=15378.7, ups=4.36, wpb=3528.9, bsz=149.8, num_updates=15600, lr=0.000253185, gnorm=0.995, train_wall=23, wall=0
2024-07-12 18:30:10 | INFO | train_inner | epoch 014:    984 / 1132 loss=3.903, nll_loss=2.431, ppl=5.39, wps=15480.1, ups=4.38, wpb=3531.3, bsz=140.3, num_updates=15700, lr=0.000252377, gnorm=1.048, train_wall=23, wall=0
2024-07-12 18:30:33 | INFO | train_inner | epoch 014:   1084 / 1132 loss=3.896, nll_loss=2.424, ppl=5.36, wps=15479.4, ups=4.36, wpb=3552.1, bsz=133, num_updates=15800, lr=0.000251577, gnorm=0.976, train_wall=23, wall=0
2024-07-12 18:30:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:30:48 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.06 | nll_loss 2.501 | ppl 5.66 | wps 44775.8 | wpb 2685.2 | bsz 107.1 | num_updates 15848 | best_loss 11.022
2024-07-12 18:30:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:30:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 14 @ 15848 updates, score 4.06) (writing took 3.8814461901783943 seconds)
2024-07-12 18:30:52 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2024-07-12 18:30:52 | INFO | train | epoch 014 | loss 3.868 | nll_loss 2.391 | ppl 5.24 | wps 14611.3 | ups 4.11 | wpb 3556.4 | bsz 141.6 | num_updates 15848 | lr 0.000251196 | gnorm 0.983 | train_wall 257 | wall 0
2024-07-12 18:30:52 | INFO | fairseq.trainer | begin training epoch 15
2024-07-12 18:31:04 | INFO | train_inner | epoch 015:     52 / 1132 loss=3.816, nll_loss=2.333, ppl=5.04, wps=11206.2, ups=3.26, wpb=3439.1, bsz=140.5, num_updates=15900, lr=0.000250785, gnorm=0.989, train_wall=22, wall=0
2024-07-12 18:31:27 | INFO | train_inner | epoch 015:    152 / 1132 loss=3.783, nll_loss=2.293, ppl=4.9, wps=15451.2, ups=4.35, wpb=3550, bsz=138.1, num_updates=16000, lr=0.00025, gnorm=0.961, train_wall=23, wall=0
2024-07-12 18:31:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:31:31 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.054 | nll_loss 2.489 | ppl 5.61 | wps 45018.8 | wpb 2685.2 | bsz 107.1 | num_updates 16000 | best_loss 11.022
2024-07-12 18:31:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:31:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_15_16000.pt (epoch 15 @ 16000 updates, score 4.054) (writing took 4.194896753877401 seconds)
2024-07-12 18:31:58 | INFO | train_inner | epoch 015:    252 / 1132 loss=3.767, nll_loss=2.276, ppl=4.84, wps=11513.1, ups=3.18, wpb=3620.3, bsz=145.4, num_updates=16100, lr=0.000249222, gnorm=0.939, train_wall=23, wall=0
2024-07-12 18:32:21 | INFO | train_inner | epoch 015:    352 / 1132 loss=3.833, nll_loss=2.349, ppl=5.1, wps=15397.8, ups=4.36, wpb=3533.9, bsz=125.8, num_updates=16200, lr=0.000248452, gnorm=0.993, train_wall=23, wall=0
2024-07-12 18:32:44 | INFO | train_inner | epoch 015:    452 / 1132 loss=3.762, nll_loss=2.271, ppl=4.83, wps=15334.7, ups=4.38, wpb=3504.3, bsz=159.4, num_updates=16300, lr=0.000247689, gnorm=0.987, train_wall=23, wall=0
2024-07-12 18:33:07 | INFO | train_inner | epoch 015:    552 / 1132 loss=3.822, nll_loss=2.338, ppl=5.06, wps=15444.4, ups=4.33, wpb=3564.4, bsz=145.4, num_updates=16400, lr=0.000246932, gnorm=0.998, train_wall=23, wall=0
2024-07-12 18:33:30 | INFO | train_inner | epoch 015:    652 / 1132 loss=3.763, nll_loss=2.272, ppl=4.83, wps=15661, ups=4.34, wpb=3608.3, bsz=163.3, num_updates=16500, lr=0.000246183, gnorm=0.953, train_wall=23, wall=0
2024-07-12 18:33:53 | INFO | train_inner | epoch 015:    752 / 1132 loss=3.858, nll_loss=2.38, ppl=5.2, wps=15560.6, ups=4.4, wpb=3535, bsz=122.6, num_updates=16600, lr=0.00024544, gnorm=1.022, train_wall=23, wall=0
2024-07-12 18:34:16 | INFO | train_inner | epoch 015:    852 / 1132 loss=3.846, nll_loss=2.366, ppl=5.15, wps=15621.4, ups=4.36, wpb=3582, bsz=128.6, num_updates=16700, lr=0.000244704, gnorm=0.977, train_wall=23, wall=0
2024-07-12 18:34:39 | INFO | train_inner | epoch 015:    952 / 1132 loss=3.81, nll_loss=2.327, ppl=5.02, wps=15669.1, ups=4.37, wpb=3588.9, bsz=147.7, num_updates=16800, lr=0.000243975, gnorm=0.968, train_wall=23, wall=0
2024-07-12 18:35:02 | INFO | train_inner | epoch 015:   1052 / 1132 loss=3.843, nll_loss=2.365, ppl=5.15, wps=15521.3, ups=4.42, wpb=3511.7, bsz=148.2, num_updates=16900, lr=0.000243252, gnorm=1.067, train_wall=22, wall=0
2024-07-12 18:35:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:35:24 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.025 | nll_loss 2.454 | ppl 5.48 | wps 44882.5 | wpb 2685.2 | bsz 107.1 | num_updates 16980 | best_loss 11.022
2024-07-12 18:35:24 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:35:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 15 @ 16980 updates, score 4.025) (writing took 6.608891662210226 seconds)
2024-07-12 18:35:31 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2024-07-12 18:35:31 | INFO | train | epoch 015 | loss 3.808 | nll_loss 2.323 | ppl 5 | wps 14451.8 | ups 4.06 | wpb 3556.4 | bsz 141.6 | num_updates 16980 | lr 0.000242678 | gnorm 0.983 | train_wall 257 | wall 0
2024-07-12 18:35:31 | INFO | fairseq.trainer | begin training epoch 16
2024-07-12 18:35:35 | INFO | train_inner | epoch 016:     20 / 1132 loss=3.806, nll_loss=2.321, ppl=5, wps=10436.5, ups=2.95, wpb=3540.2, bsz=138.4, num_updates=17000, lr=0.000242536, gnorm=0.968, train_wall=23, wall=0
2024-07-12 18:35:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:35:40 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.041 | nll_loss 2.474 | ppl 5.55 | wps 45025.4 | wpb 2685.2 | bsz 107.1 | num_updates 17000 | best_loss 11.022
2024-07-12 18:35:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:35:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_16_17000.pt (epoch 16 @ 17000 updates, score 4.041) (writing took 9.12637459859252 seconds)
2024-07-12 18:36:12 | INFO | train_inner | epoch 016:    120 / 1132 loss=3.688, nll_loss=2.186, ppl=4.55, wps=9838.9, ups=2.75, wpb=3576.5, bsz=142, num_updates=17100, lr=0.000241825, gnorm=0.958, train_wall=23, wall=0
2024-07-12 18:36:35 | INFO | train_inner | epoch 016:    220 / 1132 loss=3.734, nll_loss=2.238, ppl=4.72, wps=15391.4, ups=4.37, wpb=3519.1, bsz=135.5, num_updates=17200, lr=0.000241121, gnorm=0.999, train_wall=23, wall=0
2024-07-12 18:36:58 | INFO | train_inner | epoch 016:    320 / 1132 loss=3.754, nll_loss=2.26, ppl=4.79, wps=15561.1, ups=4.33, wpb=3595.5, bsz=139.7, num_updates=17300, lr=0.000240424, gnorm=0.969, train_wall=23, wall=0
2024-07-12 18:37:20 | INFO | train_inner | epoch 016:    420 / 1132 loss=3.73, nll_loss=2.233, ppl=4.7, wps=15390.8, ups=4.42, wpb=3480.3, bsz=143.8, num_updates=17400, lr=0.000239732, gnorm=1.007, train_wall=22, wall=0
2024-07-12 18:37:43 | INFO | train_inner | epoch 016:    520 / 1132 loss=3.804, nll_loss=2.316, ppl=4.98, wps=15269.4, ups=4.4, wpb=3472.3, bsz=130.4, num_updates=17500, lr=0.000239046, gnorm=1.026, train_wall=23, wall=0
2024-07-12 18:38:06 | INFO | train_inner | epoch 016:    620 / 1132 loss=3.732, nll_loss=2.237, ppl=4.71, wps=15675.8, ups=4.36, wpb=3597.1, bsz=144.5, num_updates=17600, lr=0.000238366, gnorm=0.959, train_wall=23, wall=0
2024-07-12 18:38:29 | INFO | train_inner | epoch 016:    720 / 1132 loss=3.743, nll_loss=2.251, ppl=4.76, wps=15731.3, ups=4.34, wpb=3621.8, bsz=154.6, num_updates=17700, lr=0.000237691, gnorm=0.982, train_wall=23, wall=0
2024-07-12 18:38:52 | INFO | train_inner | epoch 016:    820 / 1132 loss=3.778, nll_loss=2.289, ppl=4.89, wps=15634.9, ups=4.3, wpb=3635.6, bsz=137.3, num_updates=17800, lr=0.000237023, gnorm=0.969, train_wall=23, wall=0
2024-07-12 18:39:15 | INFO | train_inner | epoch 016:    920 / 1132 loss=3.79, nll_loss=2.302, ppl=4.93, wps=15398.4, ups=4.32, wpb=3560.4, bsz=153.6, num_updates=17900, lr=0.00023636, gnorm=1.06, train_wall=23, wall=0
2024-07-12 18:39:38 | INFO | train_inner | epoch 016:   1020 / 1132 loss=3.758, nll_loss=2.268, ppl=4.82, wps=15643.7, ups=4.4, wpb=3555.4, bsz=144, num_updates=18000, lr=0.000235702, gnorm=0.982, train_wall=23, wall=0
2024-07-12 18:39:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:39:42 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.02 | nll_loss 2.459 | ppl 5.5 | wps 44857.4 | wpb 2685.2 | bsz 107.1 | num_updates 18000 | best_loss 11.022
2024-07-12 18:39:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:39:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_16_18000.pt (epoch 16 @ 18000 updates, score 4.02) (writing took 14.682025984860957 seconds)
2024-07-12 18:40:20 | INFO | train_inner | epoch 016:   1120 / 1132 loss=3.78, nll_loss=2.293, ppl=4.9, wps=8471.1, ups=2.4, wpb=3527.1, bsz=135.9, num_updates=18100, lr=0.00023505, gnorm=0.986, train_wall=22, wall=0
2024-07-12 18:40:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:40:27 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.006 | nll_loss 2.44 | ppl 5.42 | wps 44821.6 | wpb 2685.2 | bsz 107.1 | num_updates 18112 | best_loss 11.022
2024-07-12 18:40:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:40:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 16 @ 18112 updates, score 4.006) (writing took 4.714809017255902 seconds)
2024-07-12 18:40:31 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2024-07-12 18:40:31 | INFO | train | epoch 016 | loss 3.754 | nll_loss 2.262 | ppl 4.8 | wps 13381.1 | ups 3.76 | wpb 3556.4 | bsz 141.6 | num_updates 18112 | lr 0.000234972 | gnorm 0.991 | train_wall 257 | wall 0
2024-07-12 18:40:32 | INFO | fairseq.trainer | begin training epoch 17
2024-07-12 18:40:52 | INFO | train_inner | epoch 017:     88 / 1132 loss=3.71, nll_loss=2.21, ppl=4.63, wps=10930.5, ups=3.12, wpb=3503.9, bsz=130.6, num_updates=18200, lr=0.000234404, gnorm=0.995, train_wall=23, wall=0
2024-07-12 18:41:15 | INFO | train_inner | epoch 017:    188 / 1132 loss=3.644, nll_loss=2.136, ppl=4.4, wps=15684.6, ups=4.3, wpb=3644.5, bsz=151, num_updates=18300, lr=0.000233762, gnorm=0.978, train_wall=23, wall=0
2024-07-12 18:41:38 | INFO | train_inner | epoch 017:    288 / 1132 loss=3.687, nll_loss=2.185, ppl=4.55, wps=15763.9, ups=4.35, wpb=3625.3, bsz=140.3, num_updates=18400, lr=0.000233126, gnorm=0.958, train_wall=23, wall=0
2024-07-12 18:42:01 | INFO | train_inner | epoch 017:    388 / 1132 loss=3.682, nll_loss=2.179, ppl=4.53, wps=15499.7, ups=4.35, wpb=3560.7, bsz=146.7, num_updates=18500, lr=0.000232495, gnorm=0.98, train_wall=23, wall=0
2024-07-12 18:42:24 | INFO | train_inner | epoch 017:    488 / 1132 loss=3.688, nll_loss=2.187, ppl=4.55, wps=15698.3, ups=4.46, wpb=3521.2, bsz=137.9, num_updates=18600, lr=0.000231869, gnorm=0.977, train_wall=22, wall=0
2024-07-12 18:42:46 | INFO | train_inner | epoch 017:    588 / 1132 loss=3.722, nll_loss=2.223, ppl=4.67, wps=15501.5, ups=4.4, wpb=3520.3, bsz=135.2, num_updates=18700, lr=0.000231249, gnorm=1.006, train_wall=23, wall=0
2024-07-12 18:43:09 | INFO | train_inner | epoch 017:    688 / 1132 loss=3.704, nll_loss=2.205, ppl=4.61, wps=15460, ups=4.37, wpb=3537.3, bsz=148.1, num_updates=18800, lr=0.000230633, gnorm=0.998, train_wall=23, wall=0
2024-07-12 18:43:32 | INFO | train_inner | epoch 017:    788 / 1132 loss=3.724, nll_loss=2.227, ppl=4.68, wps=15655.7, ups=4.31, wpb=3632.9, bsz=145.2, num_updates=18900, lr=0.000230022, gnorm=0.979, train_wall=23, wall=0
2024-07-12 18:43:55 | INFO | train_inner | epoch 017:    888 / 1132 loss=3.691, nll_loss=2.191, ppl=4.57, wps=15632, ups=4.36, wpb=3582, bsz=151, num_updates=19000, lr=0.000229416, gnorm=0.974, train_wall=23, wall=0
2024-07-12 18:43:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:43:59 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 3.993 | nll_loss 2.421 | ppl 5.36 | wps 44705.8 | wpb 2685.2 | bsz 107.1 | num_updates 19000 | best_loss 11.022
2024-07-12 18:43:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:44:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_17_19000.pt (epoch 17 @ 19000 updates, score 3.993) (writing took 4.797475661151111 seconds)
2024-07-12 18:44:27 | INFO | train_inner | epoch 017:    988 / 1132 loss=3.754, nll_loss=2.261, ppl=4.79, wps=11081.4, ups=3.14, wpb=3525, bsz=127.2, num_updates=19100, lr=0.000228814, gnorm=0.998, train_wall=23, wall=0
2024-07-12 18:44:50 | INFO | train_inner | epoch 017:   1088 / 1132 loss=3.729, nll_loss=2.234, ppl=4.71, wps=15371.7, ups=4.43, wpb=3473, bsz=151.9, num_updates=19200, lr=0.000228218, gnorm=1.04, train_wall=22, wall=0
2024-07-12 18:44:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:45:04 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 3.991 | nll_loss 2.425 | ppl 5.37 | wps 44767 | wpb 2685.2 | bsz 107.1 | num_updates 19244 | best_loss 11.022
2024-07-12 18:45:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:45:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 17 @ 19244 updates, score 3.991) (writing took 4.770228184759617 seconds)
2024-07-12 18:45:08 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2024-07-12 18:45:08 | INFO | train | epoch 017 | loss 3.704 | nll_loss 2.205 | ppl 4.61 | wps 14533.3 | ups 4.09 | wpb 3556.4 | bsz 141.6 | num_updates 19244 | lr 0.000227957 | gnorm 0.989 | train_wall 257 | wall 0
2024-07-12 18:45:09 | INFO | fairseq.trainer | begin training epoch 18
2024-07-12 18:45:22 | INFO | train_inner | epoch 018:     56 / 1132 loss=3.684, nll_loss=2.181, ppl=4.53, wps=11109.2, ups=3.13, wpb=3554.2, bsz=119.9, num_updates=19300, lr=0.000227626, gnorm=0.964, train_wall=23, wall=0
2024-07-12 18:45:44 | INFO | train_inner | epoch 018:    156 / 1132 loss=3.658, nll_loss=2.15, ppl=4.44, wps=15421.3, ups=4.39, wpb=3509.2, bsz=126.8, num_updates=19400, lr=0.000227038, gnorm=1.024, train_wall=23, wall=0
2024-07-12 18:46:07 | INFO | train_inner | epoch 018:    256 / 1132 loss=3.639, nll_loss=2.129, ppl=4.37, wps=15520, ups=4.41, wpb=3518.5, bsz=136.9, num_updates=19500, lr=0.000226455, gnorm=0.982, train_wall=22, wall=0
2024-07-12 18:46:30 | INFO | train_inner | epoch 018:    356 / 1132 loss=3.654, nll_loss=2.146, ppl=4.43, wps=15702.1, ups=4.38, wpb=3588.6, bsz=135, num_updates=19600, lr=0.000225877, gnorm=0.997, train_wall=23, wall=0
2024-07-12 18:46:53 | INFO | train_inner | epoch 018:    456 / 1132 loss=3.736, nll_loss=2.237, ppl=4.71, wps=15386.8, ups=4.38, wpb=3514.8, bsz=115.6, num_updates=19700, lr=0.000225303, gnorm=1.028, train_wall=23, wall=0
2024-07-12 18:47:16 | INFO | train_inner | epoch 018:    556 / 1132 loss=3.622, nll_loss=2.112, ppl=4.32, wps=15304.6, ups=4.36, wpb=3507.8, bsz=156.9, num_updates=19800, lr=0.000224733, gnorm=0.985, train_wall=23, wall=0
2024-07-12 18:47:39 | INFO | train_inner | epoch 018:    656 / 1132 loss=3.645, nll_loss=2.138, ppl=4.4, wps=15751.1, ups=4.34, wpb=3627.5, bsz=150.9, num_updates=19900, lr=0.000224168, gnorm=0.953, train_wall=23, wall=0
2024-07-12 18:48:02 | INFO | train_inner | epoch 018:    756 / 1132 loss=3.622, nll_loss=2.114, ppl=4.33, wps=15727.9, ups=4.34, wpb=3620.2, bsz=165, num_updates=20000, lr=0.000223607, gnorm=0.968, train_wall=23, wall=0
2024-07-12 18:48:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:48:06 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.994 | nll_loss 2.417 | ppl 5.34 | wps 44948 | wpb 2685.2 | bsz 107.1 | num_updates 20000 | best_loss 11.022
2024-07-12 18:48:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:48:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_18_20000.pt (epoch 18 @ 20000 updates, score 3.994) (writing took 5.965101584792137 seconds)
2024-07-12 18:48:35 | INFO | train_inner | epoch 018:    856 / 1132 loss=3.655, nll_loss=2.149, ppl=4.44, wps=10867.3, ups=3, wpb=3617.6, bsz=151.4, num_updates=20100, lr=0.00022305, gnorm=0.971, train_wall=23, wall=0
2024-07-12 18:48:58 | INFO | train_inner | epoch 018:    956 / 1132 loss=3.698, nll_loss=2.198, ppl=4.59, wps=15425.9, ups=4.41, wpb=3500.7, bsz=137.4, num_updates=20200, lr=0.000222497, gnorm=1.066, train_wall=23, wall=0
2024-07-12 18:49:21 | INFO | train_inner | epoch 018:   1056 / 1132 loss=3.696, nll_loss=2.196, ppl=4.58, wps=15086.3, ups=4.31, wpb=3500.3, bsz=156.7, num_updates=20300, lr=0.000221948, gnorm=1.04, train_wall=23, wall=0
2024-07-12 18:49:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:49:43 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.973 | nll_loss 2.396 | ppl 5.26 | wps 44384.8 | wpb 2685.2 | bsz 107.1 | num_updates 20376 | best_loss 11.022
2024-07-12 18:49:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:49:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 18 @ 20376 updates, score 3.973) (writing took 6.008743306621909 seconds)
2024-07-12 18:49:49 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2024-07-12 18:49:49 | INFO | train | epoch 018 | loss 3.661 | nll_loss 2.155 | ppl 4.46 | wps 14373.2 | ups 4.04 | wpb 3556.4 | bsz 141.6 | num_updates 20376 | lr 0.000221534 | gnorm 0.996 | train_wall 257 | wall 0
2024-07-12 18:49:49 | INFO | fairseq.trainer | begin training epoch 19
2024-07-12 18:49:54 | INFO | train_inner | epoch 019:     24 / 1132 loss=3.663, nll_loss=2.16, ppl=4.47, wps=10698.6, ups=3.01, wpb=3558.8, bsz=129.8, num_updates=20400, lr=0.000221404, gnorm=0.977, train_wall=23, wall=0
2024-07-12 18:50:17 | INFO | train_inner | epoch 019:    124 / 1132 loss=3.594, nll_loss=2.076, ppl=4.22, wps=15358.4, ups=4.36, wpb=3525.1, bsz=128.4, num_updates=20500, lr=0.000220863, gnorm=0.991, train_wall=23, wall=0
2024-07-12 18:50:40 | INFO | train_inner | epoch 019:    224 / 1132 loss=3.578, nll_loss=2.059, ppl=4.17, wps=15417.3, ups=4.35, wpb=3544.5, bsz=153.6, num_updates=20600, lr=0.000220326, gnorm=0.974, train_wall=23, wall=0
2024-07-12 18:51:03 | INFO | train_inner | epoch 019:    324 / 1132 loss=3.6, nll_loss=2.085, ppl=4.24, wps=15452.5, ups=4.39, wpb=3518.3, bsz=134, num_updates=20700, lr=0.000219793, gnorm=1.019, train_wall=23, wall=0
2024-07-12 18:51:26 | INFO | train_inner | epoch 019:    424 / 1132 loss=3.595, nll_loss=2.08, ppl=4.23, wps=15504.6, ups=4.37, wpb=3550.8, bsz=138.4, num_updates=20800, lr=0.000219265, gnorm=0.977, train_wall=23, wall=0
2024-07-12 18:51:49 | INFO | train_inner | epoch 019:    524 / 1132 loss=3.648, nll_loss=2.139, ppl=4.41, wps=15348.6, ups=4.33, wpb=3540.9, bsz=143, num_updates=20900, lr=0.000218739, gnorm=1.001, train_wall=23, wall=0
2024-07-12 18:52:12 | INFO | train_inner | epoch 019:    624 / 1132 loss=3.621, nll_loss=2.11, ppl=4.32, wps=15617.6, ups=4.33, wpb=3604.6, bsz=136.9, num_updates=21000, lr=0.000218218, gnorm=0.976, train_wall=23, wall=0
2024-07-12 18:52:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:52:16 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 3.984 | nll_loss 2.409 | ppl 5.31 | wps 44954 | wpb 2685.2 | bsz 107.1 | num_updates 21000 | best_loss 11.022
2024-07-12 18:52:16 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:52:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_19_21000.pt (epoch 19 @ 21000 updates, score 3.984) (writing took 12.721743975766003 seconds)
2024-07-12 18:52:52 | INFO | train_inner | epoch 019:    724 / 1132 loss=3.609, nll_loss=2.096, ppl=4.28, wps=8737.2, ups=2.51, wpb=3475.3, bsz=158, num_updates=21100, lr=0.0002177, gnorm=1.03, train_wall=23, wall=0
2024-07-12 18:53:15 | INFO | train_inner | epoch 019:    824 / 1132 loss=3.656, nll_loss=2.15, ppl=4.44, wps=15330, ups=4.38, wpb=3500.9, bsz=132.2, num_updates=21200, lr=0.000217186, gnorm=1.024, train_wall=23, wall=0
2024-07-12 18:53:37 | INFO | train_inner | epoch 019:    924 / 1132 loss=3.66, nll_loss=2.155, ppl=4.45, wps=16010.2, ups=4.38, wpb=3657, bsz=129.1, num_updates=21300, lr=0.000216676, gnorm=0.976, train_wall=23, wall=0
2024-07-12 18:54:00 | INFO | train_inner | epoch 019:   1024 / 1132 loss=3.589, nll_loss=2.075, ppl=4.21, wps=15755.6, ups=4.36, wpb=3612.8, bsz=165.4, num_updates=21400, lr=0.000216169, gnorm=0.965, train_wall=23, wall=0
2024-07-12 18:54:23 | INFO | train_inner | epoch 019:   1124 / 1132 loss=3.631, nll_loss=2.123, ppl=4.36, wps=15746.5, ups=4.33, wpb=3637.2, bsz=145.9, num_updates=21500, lr=0.000215666, gnorm=0.964, train_wall=23, wall=0
2024-07-12 18:54:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:54:29 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 3.962 | nll_loss 2.388 | ppl 5.24 | wps 44896.8 | wpb 2685.2 | bsz 107.1 | num_updates 21508 | best_loss 11.022
2024-07-12 18:54:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:54:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 19 @ 21508 updates, score 3.962) (writing took 14.448038826696575 seconds)
2024-07-12 18:54:44 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2024-07-12 18:54:44 | INFO | train | epoch 019 | loss 3.617 | nll_loss 2.106 | ppl 4.3 | wps 13631.9 | ups 3.83 | wpb 3556.4 | bsz 141.6 | num_updates 21508 | lr 0.000215625 | gnorm 0.992 | train_wall 258 | wall 0
2024-07-12 18:54:44 | INFO | fairseq.trainer | begin training epoch 20
2024-07-12 18:55:05 | INFO | train_inner | epoch 020:     92 / 1132 loss=3.563, nll_loss=2.043, ppl=4.12, wps=8340.9, ups=2.39, wpb=3485.4, bsz=135.7, num_updates=21600, lr=0.000215166, gnorm=0.997, train_wall=23, wall=0
2024-07-12 18:55:28 | INFO | train_inner | epoch 020:    192 / 1132 loss=3.56, nll_loss=2.039, ppl=4.11, wps=15628, ups=4.31, wpb=3622.3, bsz=132.1, num_updates=21700, lr=0.000214669, gnorm=0.965, train_wall=23, wall=0
2024-07-12 18:55:51 | INFO | train_inner | epoch 020:    292 / 1132 loss=3.575, nll_loss=2.056, ppl=4.16, wps=15589.8, ups=4.4, wpb=3540.5, bsz=137.6, num_updates=21800, lr=0.000214176, gnorm=1.02, train_wall=23, wall=0
2024-07-12 18:56:14 | INFO | train_inner | epoch 020:    392 / 1132 loss=3.548, nll_loss=2.027, ppl=4.08, wps=15440.9, ups=4.4, wpb=3510.3, bsz=147.9, num_updates=21900, lr=0.000213687, gnorm=1.009, train_wall=23, wall=0
2024-07-12 18:56:36 | INFO | train_inner | epoch 020:    492 / 1132 loss=3.586, nll_loss=2.069, ppl=4.2, wps=15502.8, ups=4.44, wpb=3492.3, bsz=137.4, num_updates=22000, lr=0.000213201, gnorm=1.056, train_wall=22, wall=0
2024-07-12 18:56:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:56:41 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.966 | nll_loss 2.388 | ppl 5.24 | wps 44892.6 | wpb 2685.2 | bsz 107.1 | num_updates 22000 | best_loss 11.022
2024-07-12 18:56:41 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:56:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_20_22000.pt (epoch 20 @ 22000 updates, score 3.966) (writing took 9.331465163268149 seconds)
2024-07-12 18:57:13 | INFO | train_inner | epoch 020:    592 / 1132 loss=3.557, nll_loss=2.037, ppl=4.1, wps=9776, ups=2.72, wpb=3598.1, bsz=163.8, num_updates=22100, lr=0.000212718, gnorm=0.988, train_wall=23, wall=0
2024-07-12 18:57:36 | INFO | train_inner | epoch 020:    692 / 1132 loss=3.604, nll_loss=2.09, ppl=4.26, wps=15621.7, ups=4.34, wpb=3603.5, bsz=139.4, num_updates=22200, lr=0.000212238, gnorm=0.993, train_wall=23, wall=0
2024-07-12 18:57:59 | INFO | train_inner | epoch 020:    792 / 1132 loss=3.604, nll_loss=2.09, ppl=4.26, wps=15271.9, ups=4.37, wpb=3491.8, bsz=135.5, num_updates=22300, lr=0.000211762, gnorm=1.031, train_wall=23, wall=0
2024-07-12 18:58:22 | INFO | train_inner | epoch 020:    892 / 1132 loss=3.614, nll_loss=2.1, ppl=4.29, wps=15497.5, ups=4.34, wpb=3570.5, bsz=136.4, num_updates=22400, lr=0.000211289, gnorm=1.003, train_wall=23, wall=0
2024-07-12 18:58:45 | INFO | train_inner | epoch 020:    992 / 1132 loss=3.58, nll_loss=2.065, ppl=4.18, wps=15629.5, ups=4.33, wpb=3606.7, bsz=145.8, num_updates=22500, lr=0.000210819, gnorm=0.973, train_wall=23, wall=0
2024-07-12 18:59:08 | INFO | train_inner | epoch 020:   1092 / 1132 loss=3.588, nll_loss=2.072, ppl=4.2, wps=15583.8, ups=4.34, wpb=3587, bsz=148, num_updates=22600, lr=0.000210352, gnorm=0.994, train_wall=23, wall=0
2024-07-12 18:59:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 18:59:22 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.966 | nll_loss 2.393 | ppl 5.25 | wps 44756.5 | wpb 2685.2 | bsz 107.1 | num_updates 22640 | best_loss 11.022
2024-07-12 18:59:22 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 18:59:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 20 @ 22640 updates, score 3.966) (writing took 4.540384220890701 seconds)
2024-07-12 18:59:26 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2024-07-12 18:59:26 | INFO | train | epoch 020 | loss 3.581 | nll_loss 2.064 | ppl 4.18 | wps 14256.7 | ups 4.01 | wpb 3556.4 | bsz 141.6 | num_updates 22640 | lr 0.000210166 | gnorm 1.003 | train_wall 258 | wall 0
2024-07-12 18:59:26 | INFO | fairseq.trainer | begin training epoch 21
2024-07-12 18:59:40 | INFO | train_inner | epoch 021:     60 / 1132 loss=3.578, nll_loss=2.061, ppl=4.17, wps=11071.5, ups=3.14, wpb=3521, bsz=132.6, num_updates=22700, lr=0.000209888, gnorm=1.051, train_wall=23, wall=0
2024-07-12 19:00:03 | INFO | train_inner | epoch 021:    160 / 1132 loss=3.485, nll_loss=1.953, ppl=3.87, wps=15465.1, ups=4.45, wpb=3478.3, bsz=142.2, num_updates=22800, lr=0.000209427, gnorm=0.996, train_wall=22, wall=0
2024-07-12 19:00:26 | INFO | train_inner | epoch 021:    260 / 1132 loss=3.477, nll_loss=1.946, ppl=3.85, wps=15583.4, ups=4.33, wpb=3598.5, bsz=157.2, num_updates=22900, lr=0.000208969, gnorm=0.962, train_wall=23, wall=0
2024-07-12 19:00:48 | INFO | train_inner | epoch 021:    360 / 1132 loss=3.556, nll_loss=2.035, ppl=4.1, wps=15555.3, ups=4.4, wpb=3534.5, bsz=129.1, num_updates=23000, lr=0.000208514, gnorm=1.027, train_wall=23, wall=0
2024-07-12 19:00:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:00:53 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 3.966 | nll_loss 2.394 | ppl 5.26 | wps 44621.9 | wpb 2685.2 | bsz 107.1 | num_updates 23000 | best_loss 11.022
2024-07-12 19:00:53 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:01:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_21_23000.pt (epoch 21 @ 23000 updates, score 3.966) (writing took 15.958010848611593 seconds)
2024-07-12 19:01:31 | INFO | train_inner | epoch 021:    460 / 1132 loss=3.564, nll_loss=2.043, ppl=4.12, wps=8186.4, ups=2.32, wpb=3523.9, bsz=126.1, num_updates=23100, lr=0.000208063, gnorm=1.022, train_wall=23, wall=0
2024-07-12 19:01:55 | INFO | train_inner | epoch 021:    560 / 1132 loss=3.535, nll_loss=2.012, ppl=4.03, wps=15852, ups=4.32, wpb=3668.3, bsz=148.5, num_updates=23200, lr=0.000207614, gnorm=0.967, train_wall=23, wall=0
2024-07-12 19:02:18 | INFO | train_inner | epoch 021:    660 / 1132 loss=3.573, nll_loss=2.055, ppl=4.15, wps=15651.3, ups=4.32, wpb=3621, bsz=142.7, num_updates=23300, lr=0.000207168, gnorm=1.018, train_wall=23, wall=0
2024-07-12 19:02:40 | INFO | train_inner | epoch 021:    760 / 1132 loss=3.563, nll_loss=2.045, ppl=4.13, wps=15545.2, ups=4.39, wpb=3543.1, bsz=146.6, num_updates=23400, lr=0.000206725, gnorm=1.016, train_wall=23, wall=0
2024-07-12 19:03:04 | INFO | train_inner | epoch 021:    860 / 1132 loss=3.544, nll_loss=2.023, ppl=4.06, wps=15429.1, ups=4.33, wpb=3563, bsz=154.1, num_updates=23500, lr=0.000206284, gnorm=1.005, train_wall=23, wall=0
2024-07-12 19:03:27 | INFO | train_inner | epoch 021:    960 / 1132 loss=3.571, nll_loss=2.053, ppl=4.15, wps=15299.8, ups=4.31, wpb=3551.1, bsz=136.2, num_updates=23600, lr=0.000205847, gnorm=1.003, train_wall=23, wall=0
2024-07-12 19:03:50 | INFO | train_inner | epoch 021:   1060 / 1132 loss=3.533, nll_loss=2.011, ppl=4.03, wps=15449.7, ups=4.35, wpb=3548.4, bsz=159.2, num_updates=23700, lr=0.000205412, gnorm=1.001, train_wall=23, wall=0
2024-07-12 19:04:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:04:10 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 3.94 | nll_loss 2.362 | ppl 5.14 | wps 44833.1 | wpb 2685.2 | bsz 107.1 | num_updates 23772 | best_loss 11.022
2024-07-12 19:04:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:04:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 21 @ 23772 updates, score 3.94) (writing took 5.150498376227915 seconds)
2024-07-12 19:04:16 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2024-07-12 19:04:16 | INFO | train | epoch 021 | loss 3.547 | nll_loss 2.025 | ppl 4.07 | wps 13916.7 | ups 3.91 | wpb 3556.4 | bsz 141.6 | num_updates 23772 | lr 0.000205101 | gnorm 1.009 | train_wall 257 | wall 0
2024-07-12 19:04:16 | INFO | fairseq.trainer | begin training epoch 22
2024-07-12 19:04:22 | INFO | train_inner | epoch 022:     28 / 1132 loss=3.624, nll_loss=2.11, ppl=4.32, wps=10865, ups=3.08, wpb=3533, bsz=114, num_updates=23800, lr=0.00020498, gnorm=1.044, train_wall=23, wall=0
2024-07-12 19:04:45 | INFO | train_inner | epoch 022:    128 / 1132 loss=3.468, nll_loss=1.935, ppl=3.82, wps=15597.1, ups=4.35, wpb=3587.4, bsz=137, num_updates=23900, lr=0.000204551, gnorm=0.96, train_wall=23, wall=0
2024-07-12 19:05:08 | INFO | train_inner | epoch 022:    228 / 1132 loss=3.464, nll_loss=1.932, ppl=3.82, wps=15733.4, ups=4.31, wpb=3648.2, bsz=152.8, num_updates=24000, lr=0.000204124, gnorm=0.962, train_wall=23, wall=0
2024-07-12 19:05:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:05:13 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 3.96 | nll_loss 2.371 | ppl 5.17 | wps 44702.5 | wpb 2685.2 | bsz 107.1 | num_updates 24000 | best_loss 11.022
2024-07-12 19:05:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:05:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_22_24000.pt (epoch 22 @ 24000 updates, score 3.96) (writing took 7.857619711197913 seconds)
2024-07-12 19:05:44 | INFO | train_inner | epoch 022:    328 / 1132 loss=3.48, nll_loss=1.947, ppl=3.85, wps=10042.2, ups=2.82, wpb=3558.4, bsz=151.5, num_updates=24100, lr=0.0002037, gnorm=0.989, train_wall=23, wall=0
2024-07-12 19:06:07 | INFO | train_inner | epoch 022:    428 / 1132 loss=3.497, nll_loss=1.968, ppl=3.91, wps=15493.8, ups=4.35, wpb=3559.3, bsz=154, num_updates=24200, lr=0.000203279, gnorm=1.04, train_wall=23, wall=0
2024-07-12 19:06:30 | INFO | train_inner | epoch 022:    528 / 1132 loss=3.503, nll_loss=1.975, ppl=3.93, wps=15592.2, ups=4.38, wpb=3556.9, bsz=150, num_updates=24300, lr=0.00020286, gnorm=1.002, train_wall=23, wall=0
2024-07-12 19:06:52 | INFO | train_inner | epoch 022:    628 / 1132 loss=3.547, nll_loss=2.024, ppl=4.07, wps=15539.7, ups=4.45, wpb=3488.3, bsz=125, num_updates=24400, lr=0.000202444, gnorm=1.048, train_wall=22, wall=0
2024-07-12 19:07:16 | INFO | train_inner | epoch 022:    728 / 1132 loss=3.513, nll_loss=1.987, ppl=3.96, wps=15356.1, ups=4.26, wpb=3600.7, bsz=138.8, num_updates=24500, lr=0.000202031, gnorm=1.001, train_wall=23, wall=0
2024-07-12 19:07:39 | INFO | train_inner | epoch 022:    828 / 1132 loss=3.514, nll_loss=1.988, ppl=3.97, wps=15156.7, ups=4.35, wpb=3483.3, bsz=148.4, num_updates=24600, lr=0.000201619, gnorm=1.025, train_wall=23, wall=0
2024-07-12 19:08:02 | INFO | train_inner | epoch 022:    928 / 1132 loss=3.548, nll_loss=2.025, ppl=4.07, wps=15521.9, ups=4.31, wpb=3601.6, bsz=132.8, num_updates=24700, lr=0.000201211, gnorm=1.008, train_wall=23, wall=0
2024-07-12 19:08:25 | INFO | train_inner | epoch 022:   1028 / 1132 loss=3.58, nll_loss=2.063, ppl=4.18, wps=15278.5, ups=4.38, wpb=3484.9, bsz=123.6, num_updates=24800, lr=0.000200805, gnorm=1.065, train_wall=23, wall=0
2024-07-12 19:08:48 | INFO | train_inner | epoch 022:   1128 / 1132 loss=3.518, nll_loss=1.995, ppl=3.99, wps=15221.8, ups=4.3, wpb=3542.3, bsz=150.5, num_updates=24900, lr=0.000200401, gnorm=1.005, train_wall=23, wall=0
2024-07-12 19:08:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:08:53 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 3.946 | nll_loss 2.368 | ppl 5.16 | wps 44676.3 | wpb 2685.2 | bsz 107.1 | num_updates 24904 | best_loss 11.022
2024-07-12 19:08:53 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:09:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 22 @ 24904 updates, score 3.946) (writing took 10.921770150773227 seconds)
2024-07-12 19:09:04 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2024-07-12 19:09:04 | INFO | train | epoch 022 | loss 3.513 | nll_loss 1.986 | ppl 3.96 | wps 13960.4 | ups 3.93 | wpb 3556.4 | bsz 141.6 | num_updates 24904 | lr 0.000200385 | gnorm 1.009 | train_wall 259 | wall 0
2024-07-12 19:09:04 | INFO | fairseq.trainer | begin training epoch 23
2024-07-12 19:09:26 | INFO | train_inner | epoch 023:     96 / 1132 loss=3.429, nll_loss=1.89, ppl=3.71, wps=9315.3, ups=2.64, wpb=3526.2, bsz=143.4, num_updates=25000, lr=0.0002, gnorm=1.004, train_wall=22, wall=0
2024-07-12 19:09:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:09:30 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.954 | nll_loss 2.372 | ppl 5.18 | wps 44877.2 | wpb 2685.2 | bsz 107.1 | num_updates 25000 | best_loss 11.022
2024-07-12 19:09:30 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:09:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_23_25000.pt (epoch 23 @ 25000 updates, score 3.954) (writing took 12.662434117868543 seconds)
2024-07-12 19:10:06 | INFO | train_inner | epoch 023:    196 / 1132 loss=3.461, nll_loss=1.925, ppl=3.8, wps=8866.1, ups=2.5, wpb=3553.1, bsz=134.4, num_updates=25100, lr=0.000199601, gnorm=0.993, train_wall=23, wall=0
2024-07-12 19:10:29 | INFO | train_inner | epoch 023:    296 / 1132 loss=3.471, nll_loss=1.936, ppl=3.83, wps=15471.9, ups=4.36, wpb=3551.6, bsz=130, num_updates=25200, lr=0.000199205, gnorm=1.01, train_wall=23, wall=0
2024-07-12 19:10:52 | INFO | train_inner | epoch 023:    396 / 1132 loss=3.459, nll_loss=1.923, ppl=3.79, wps=15474.3, ups=4.26, wpb=3636.1, bsz=155.8, num_updates=25300, lr=0.000198811, gnorm=0.995, train_wall=23, wall=0
2024-07-12 19:11:15 | INFO | train_inner | epoch 023:    496 / 1132 loss=3.483, nll_loss=1.952, ppl=3.87, wps=15473.9, ups=4.4, wpb=3518.5, bsz=144.4, num_updates=25400, lr=0.000198419, gnorm=1.01, train_wall=23, wall=0
2024-07-12 19:11:38 | INFO | train_inner | epoch 023:    596 / 1132 loss=3.509, nll_loss=1.98, ppl=3.95, wps=15433.1, ups=4.39, wpb=3515.2, bsz=124, num_updates=25500, lr=0.00019803, gnorm=1.052, train_wall=23, wall=0
2024-07-12 19:12:01 | INFO | train_inner | epoch 023:    696 / 1132 loss=3.525, nll_loss=1.999, ppl=4, wps=15537.3, ups=4.39, wpb=3540.9, bsz=129.2, num_updates=25600, lr=0.000197642, gnorm=1.049, train_wall=23, wall=0
2024-07-12 19:12:24 | INFO | train_inner | epoch 023:    796 / 1132 loss=3.473, nll_loss=1.942, ppl=3.84, wps=15570.8, ups=4.32, wpb=3603.9, bsz=152.2, num_updates=25700, lr=0.000197257, gnorm=1, train_wall=23, wall=0
2024-07-12 19:12:47 | INFO | train_inner | epoch 023:    896 / 1132 loss=3.494, nll_loss=1.965, ppl=3.9, wps=15408.8, ups=4.35, wpb=3543.9, bsz=146.7, num_updates=25800, lr=0.000196875, gnorm=1.031, train_wall=23, wall=0
2024-07-12 19:13:10 | INFO | train_inner | epoch 023:    996 / 1132 loss=3.497, nll_loss=1.968, ppl=3.91, wps=15537.1, ups=4.34, wpb=3579.1, bsz=144.1, num_updates=25900, lr=0.000196494, gnorm=1.012, train_wall=23, wall=0
2024-07-12 19:13:33 | INFO | train_inner | epoch 023:   1096 / 1132 loss=3.486, nll_loss=1.957, ppl=3.88, wps=15389.6, ups=4.37, wpb=3525.2, bsz=151.3, num_updates=26000, lr=0.000196116, gnorm=1.027, train_wall=23, wall=0
2024-07-12 19:13:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:13:37 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.936 | nll_loss 2.36 | ppl 5.14 | wps 44549 | wpb 2685.2 | bsz 107.1 | num_updates 26000 | best_loss 11.022
2024-07-12 19:13:37 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:13:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_23_26000.pt (epoch 23 @ 26000 updates, score 3.936) (writing took 5.736914338544011 seconds)
2024-07-12 19:13:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:13:55 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.945 | nll_loss 2.363 | ppl 5.14 | wps 44484.3 | wpb 2685.2 | bsz 107.1 | num_updates 26036 | best_loss 11.022
2024-07-12 19:13:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:14:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 23 @ 26036 updates, score 3.945) (writing took 5.482191233895719 seconds)
2024-07-12 19:14:01 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2024-07-12 19:14:01 | INFO | train | epoch 023 | loss 3.482 | nll_loss 1.95 | ppl 3.86 | wps 13564.3 | ups 3.81 | wpb 3556.4 | bsz 141.6 | num_updates 26036 | lr 0.000195981 | gnorm 1.017 | train_wall 258 | wall 0
2024-07-12 19:14:01 | INFO | fairseq.trainer | begin training epoch 24
2024-07-12 19:14:15 | INFO | train_inner | epoch 024:     64 / 1132 loss=3.443, nll_loss=1.907, ppl=3.75, wps=8356.1, ups=2.34, wpb=3572.7, bsz=137, num_updates=26100, lr=0.00019574, gnorm=1.005, train_wall=23, wall=0
2024-07-12 19:14:39 | INFO | train_inner | epoch 024:    164 / 1132 loss=3.39, nll_loss=1.847, ppl=3.6, wps=16027.5, ups=4.3, wpb=3724.7, bsz=154.6, num_updates=26200, lr=0.000195366, gnorm=0.944, train_wall=23, wall=0
2024-07-12 19:15:02 | INFO | train_inner | epoch 024:    264 / 1132 loss=3.468, nll_loss=1.932, ppl=3.82, wps=15432, ups=4.35, wpb=3546.9, bsz=132.3, num_updates=26300, lr=0.000194994, gnorm=1.038, train_wall=23, wall=0
2024-07-12 19:15:25 | INFO | train_inner | epoch 024:    364 / 1132 loss=3.452, nll_loss=1.914, ppl=3.77, wps=15614.2, ups=4.37, wpb=3577.1, bsz=136.7, num_updates=26400, lr=0.000194625, gnorm=1.036, train_wall=23, wall=0
2024-07-12 19:15:48 | INFO | train_inner | epoch 024:    464 / 1132 loss=3.464, nll_loss=1.928, ppl=3.81, wps=15507.4, ups=4.32, wpb=3587.2, bsz=142.6, num_updates=26500, lr=0.000194257, gnorm=1.05, train_wall=23, wall=0
2024-07-12 19:16:11 | INFO | train_inner | epoch 024:    564 / 1132 loss=3.432, nll_loss=1.894, ppl=3.72, wps=15462.8, ups=4.36, wpb=3550.3, bsz=150.1, num_updates=26600, lr=0.000193892, gnorm=1.001, train_wall=23, wall=0
2024-07-12 19:16:34 | INFO | train_inner | epoch 024:    664 / 1132 loss=3.473, nll_loss=1.939, ppl=3.83, wps=15598.2, ups=4.37, wpb=3569.6, bsz=133.8, num_updates=26700, lr=0.000193528, gnorm=1.029, train_wall=23, wall=0
2024-07-12 19:16:56 | INFO | train_inner | epoch 024:    764 / 1132 loss=3.474, nll_loss=1.942, ppl=3.84, wps=15163.3, ups=4.44, wpb=3416, bsz=139.4, num_updates=26800, lr=0.000193167, gnorm=1.061, train_wall=22, wall=0
2024-07-12 19:17:19 | INFO | train_inner | epoch 024:    864 / 1132 loss=3.451, nll_loss=1.918, ppl=3.78, wps=15700.7, ups=4.4, wpb=3564.5, bsz=147.2, num_updates=26900, lr=0.000192807, gnorm=0.999, train_wall=23, wall=0
2024-07-12 19:17:41 | INFO | train_inner | epoch 024:    964 / 1132 loss=3.457, nll_loss=1.922, ppl=3.79, wps=15253.4, ups=4.42, wpb=3454.7, bsz=140.6, num_updates=27000, lr=0.00019245, gnorm=1.042, train_wall=22, wall=0
2024-07-12 19:17:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:17:46 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 3.938 | nll_loss 2.354 | ppl 5.11 | wps 44172.1 | wpb 2685.2 | bsz 107.1 | num_updates 27000 | best_loss 11.022
2024-07-12 19:17:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:18:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_24_27000.pt (epoch 24 @ 27000 updates, score 3.938) (writing took 14.605220616795123 seconds)
2024-07-12 19:18:23 | INFO | train_inner | epoch 024:   1064 / 1132 loss=3.469, nll_loss=1.937, ppl=3.83, wps=8534.7, ups=2.39, wpb=3577.8, bsz=146.7, num_updates=27100, lr=0.000192095, gnorm=1.032, train_wall=23, wall=0
2024-07-12 19:18:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:18:43 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 3.926 | nll_loss 2.348 | ppl 5.09 | wps 44699.8 | wpb 2685.2 | bsz 107.1 | num_updates 27168 | best_loss 11.022
2024-07-12 19:18:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:18:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 24 @ 27168 updates, score 3.926) (writing took 4.0310145523399115 seconds)
2024-07-12 19:18:47 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2024-07-12 19:18:47 | INFO | train | epoch 024 | loss 3.452 | nll_loss 1.916 | ppl 3.77 | wps 14056.5 | ups 3.95 | wpb 3556.4 | bsz 141.6 | num_updates 27168 | lr 0.000191854 | gnorm 1.022 | train_wall 257 | wall 0
2024-07-12 19:18:47 | INFO | fairseq.trainer | begin training epoch 25
2024-07-12 19:18:55 | INFO | train_inner | epoch 025:     32 / 1132 loss=3.475, nll_loss=1.942, ppl=3.84, wps=11312.2, ups=3.18, wpb=3553.8, bsz=131.8, num_updates=27200, lr=0.000191741, gnorm=1.034, train_wall=23, wall=0
2024-07-12 19:19:18 | INFO | train_inner | epoch 025:    132 / 1132 loss=3.381, nll_loss=1.833, ppl=3.56, wps=15408.7, ups=4.31, wpb=3576.4, bsz=143.6, num_updates=27300, lr=0.00019139, gnorm=0.994, train_wall=23, wall=0
2024-07-12 19:19:41 | INFO | train_inner | epoch 025:    232 / 1132 loss=3.383, nll_loss=1.834, ppl=3.56, wps=15158.4, ups=4.35, wpb=3484.8, bsz=151, num_updates=27400, lr=0.00019104, gnorm=1.031, train_wall=23, wall=0
2024-07-12 19:20:04 | INFO | train_inner | epoch 025:    332 / 1132 loss=3.389, nll_loss=1.843, ppl=3.59, wps=15622.5, ups=4.32, wpb=3618.7, bsz=156.1, num_updates=27500, lr=0.000190693, gnorm=0.997, train_wall=23, wall=0
2024-07-12 19:20:27 | INFO | train_inner | epoch 025:    432 / 1132 loss=3.443, nll_loss=1.904, ppl=3.74, wps=15506.6, ups=4.36, wpb=3559.8, bsz=134.1, num_updates=27600, lr=0.000190347, gnorm=1.055, train_wall=23, wall=0
2024-07-12 19:20:50 | INFO | train_inner | epoch 025:    532 / 1132 loss=3.433, nll_loss=1.894, ppl=3.72, wps=15663.3, ups=4.4, wpb=3562.3, bsz=124.8, num_updates=27700, lr=0.000190003, gnorm=1.006, train_wall=23, wall=0
2024-07-12 19:21:13 | INFO | train_inner | epoch 025:    632 / 1132 loss=3.425, nll_loss=1.885, ppl=3.69, wps=15692.7, ups=4.38, wpb=3579.8, bsz=140.6, num_updates=27800, lr=0.000189661, gnorm=1.017, train_wall=23, wall=0
2024-07-12 19:21:36 | INFO | train_inner | epoch 025:    732 / 1132 loss=3.473, nll_loss=1.938, ppl=3.83, wps=15260.6, ups=4.32, wpb=3530.6, bsz=132.9, num_updates=27900, lr=0.000189321, gnorm=1.057, train_wall=23, wall=0
2024-07-12 19:21:58 | INFO | train_inner | epoch 025:    832 / 1132 loss=3.445, nll_loss=1.909, ppl=3.76, wps=15560.3, ups=4.43, wpb=3514.6, bsz=133.2, num_updates=28000, lr=0.000188982, gnorm=1.045, train_wall=22, wall=0
2024-07-12 19:21:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:22:03 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 3.934 | nll_loss 2.35 | ppl 5.1 | wps 44974.2 | wpb 2685.2 | bsz 107.1 | num_updates 28000 | best_loss 11.022
2024-07-12 19:22:03 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:22:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_25_28000.pt (epoch 25 @ 28000 updates, score 3.934) (writing took 5.7767501920461655 seconds)
2024-07-12 19:22:31 | INFO | train_inner | epoch 025:    932 / 1132 loss=3.43, nll_loss=1.893, ppl=3.71, wps=11024.2, ups=3.03, wpb=3639.3, bsz=152.4, num_updates=28100, lr=0.000188646, gnorm=0.998, train_wall=23, wall=0
2024-07-12 19:22:54 | INFO | train_inner | epoch 025:   1032 / 1132 loss=3.409, nll_loss=1.87, ppl=3.66, wps=15300.3, ups=4.42, wpb=3457.8, bsz=149.4, num_updates=28200, lr=0.000188311, gnorm=1.039, train_wall=22, wall=0
2024-07-12 19:23:17 | INFO | train_inner | epoch 025:   1132 / 1132 loss=3.458, nll_loss=1.927, ppl=3.8, wps=15785.7, ups=4.37, wpb=3614, bsz=144.1, num_updates=28300, lr=0.000187978, gnorm=1.013, train_wall=23, wall=0
2024-07-12 19:23:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:23:21 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 3.932 | nll_loss 2.35 | ppl 5.1 | wps 44772.3 | wpb 2685.2 | bsz 107.1 | num_updates 28300 | best_loss 11.022
2024-07-12 19:23:21 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:23:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 25 @ 28300 updates, score 3.932) (writing took 4.564539662562311 seconds)
2024-07-12 19:23:26 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2024-07-12 19:23:26 | INFO | train | epoch 025 | loss 3.424 | nll_loss 1.884 | ppl 3.69 | wps 14456.4 | ups 4.06 | wpb 3556.4 | bsz 141.6 | num_updates 28300 | lr 0.000187978 | gnorm 1.023 | train_wall 258 | wall 0
2024-07-12 19:23:26 | INFO | fairseq.trainer | begin training epoch 26
2024-07-12 19:23:49 | INFO | train_inner | epoch 026:    100 / 1132 loss=3.305, nll_loss=1.75, ppl=3.36, wps=11286.5, ups=3.13, wpb=3609.5, bsz=163.9, num_updates=28400, lr=0.000187647, gnorm=0.978, train_wall=23, wall=0
2024-07-12 19:24:11 | INFO | train_inner | epoch 026:    200 / 1132 loss=3.366, nll_loss=1.819, ppl=3.53, wps=15472.1, ups=4.47, wpb=3464.7, bsz=131.5, num_updates=28500, lr=0.000187317, gnorm=1.044, train_wall=22, wall=0
2024-07-12 19:24:34 | INFO | train_inner | epoch 026:    300 / 1132 loss=3.38, nll_loss=1.833, ppl=3.56, wps=15591, ups=4.31, wpb=3618.6, bsz=149.2, num_updates=28600, lr=0.000186989, gnorm=1.005, train_wall=23, wall=0
2024-07-12 19:24:57 | INFO | train_inner | epoch 026:    400 / 1132 loss=3.413, nll_loss=1.869, ppl=3.65, wps=15518.1, ups=4.36, wpb=3555.5, bsz=126.5, num_updates=28700, lr=0.000186663, gnorm=1.03, train_wall=23, wall=0
2024-07-12 19:25:20 | INFO | train_inner | epoch 026:    500 / 1132 loss=3.395, nll_loss=1.85, ppl=3.6, wps=15526.2, ups=4.35, wpb=3570.7, bsz=140.2, num_updates=28800, lr=0.000186339, gnorm=1.021, train_wall=23, wall=0
2024-07-12 19:25:43 | INFO | train_inner | epoch 026:    600 / 1132 loss=3.427, nll_loss=1.887, ppl=3.7, wps=15541.9, ups=4.4, wpb=3534.6, bsz=130.9, num_updates=28900, lr=0.000186016, gnorm=1.082, train_wall=23, wall=0
2024-07-12 19:26:06 | INFO | train_inner | epoch 026:    700 / 1132 loss=3.398, nll_loss=1.854, ppl=3.62, wps=15479.9, ups=4.38, wpb=3534.1, bsz=140.5, num_updates=29000, lr=0.000185695, gnorm=1.025, train_wall=23, wall=0
2024-07-12 19:26:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:26:10 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 3.935 | nll_loss 2.351 | ppl 5.1 | wps 44725.3 | wpb 2685.2 | bsz 107.1 | num_updates 29000 | best_loss 11.022
2024-07-12 19:26:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:26:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_26_29000.pt (epoch 26 @ 29000 updates, score 3.935) (writing took 5.242459666915238 seconds)
2024-07-12 19:26:39 | INFO | train_inner | epoch 026:    800 / 1132 loss=3.431, nll_loss=1.891, ppl=3.71, wps=10917.4, ups=3.06, wpb=3564.9, bsz=140.2, num_updates=29100, lr=0.000185376, gnorm=1.049, train_wall=23, wall=0
2024-07-12 19:27:02 | INFO | train_inner | epoch 026:    900 / 1132 loss=3.415, nll_loss=1.875, ppl=3.67, wps=15600.6, ups=4.35, wpb=3588.6, bsz=144.9, num_updates=29200, lr=0.000185058, gnorm=1.017, train_wall=23, wall=0
2024-07-12 19:27:24 | INFO | train_inner | epoch 026:   1000 / 1132 loss=3.418, nll_loss=1.879, ppl=3.68, wps=15722.7, ups=4.4, wpb=3574.2, bsz=152.1, num_updates=29300, lr=0.000184742, gnorm=1.03, train_wall=23, wall=0
2024-07-12 19:27:47 | INFO | train_inner | epoch 026:   1100 / 1132 loss=3.416, nll_loss=1.876, ppl=3.67, wps=15400.1, ups=4.35, wpb=3540.1, bsz=145.3, num_updates=29400, lr=0.000184428, gnorm=1.039, train_wall=23, wall=0
2024-07-12 19:27:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:27:59 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 3.925 | nll_loss 2.343 | ppl 5.07 | wps 44512.6 | wpb 2685.2 | bsz 107.1 | num_updates 29432 | best_loss 11.022
2024-07-12 19:27:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:28:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 26 @ 29432 updates, score 3.925) (writing took 4.877517540939152 seconds)
2024-07-12 19:28:04 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2024-07-12 19:28:04 | INFO | train | epoch 026 | loss 3.398 | nll_loss 1.855 | ppl 3.62 | wps 14477.5 | ups 4.07 | wpb 3556.4 | bsz 141.6 | num_updates 29432 | lr 0.000184327 | gnorm 1.032 | train_wall 257 | wall 0
2024-07-12 19:28:04 | INFO | fairseq.trainer | begin training epoch 27
2024-07-12 19:28:20 | INFO | train_inner | epoch 027:     68 / 1132 loss=3.364, nll_loss=1.814, ppl=3.52, wps=10837.2, ups=3.1, wpb=3497.3, bsz=134.9, num_updates=29500, lr=0.000184115, gnorm=1.045, train_wall=23, wall=0
2024-07-12 19:28:43 | INFO | train_inner | epoch 027:    168 / 1132 loss=3.313, nll_loss=1.756, ppl=3.38, wps=15335.1, ups=4.34, wpb=3530.9, bsz=153.1, num_updates=29600, lr=0.000183804, gnorm=1.01, train_wall=23, wall=0
2024-07-12 19:29:06 | INFO | train_inner | epoch 027:    268 / 1132 loss=3.358, nll_loss=1.808, ppl=3.5, wps=15651.8, ups=4.35, wpb=3599.9, bsz=141.5, num_updates=29700, lr=0.000183494, gnorm=1.031, train_wall=23, wall=0
2024-07-12 19:29:29 | INFO | train_inner | epoch 027:    368 / 1132 loss=3.366, nll_loss=1.816, ppl=3.52, wps=15647.8, ups=4.34, wpb=3603.9, bsz=137.8, num_updates=29800, lr=0.000183186, gnorm=1.023, train_wall=23, wall=0
2024-07-12 19:29:51 | INFO | train_inner | epoch 027:    468 / 1132 loss=3.361, nll_loss=1.812, ppl=3.51, wps=15521.5, ups=4.38, wpb=3540.6, bsz=140.8, num_updates=29900, lr=0.000182879, gnorm=1.034, train_wall=23, wall=0
2024-07-12 19:30:15 | INFO | train_inner | epoch 027:    568 / 1132 loss=3.357, nll_loss=1.809, ppl=3.5, wps=15757.5, ups=4.32, wpb=3646.5, bsz=148.6, num_updates=30000, lr=0.000182574, gnorm=1.006, train_wall=23, wall=0
2024-07-12 19:30:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:30:19 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 3.93 | nll_loss 2.348 | ppl 5.09 | wps 44684.1 | wpb 2685.2 | bsz 107.1 | num_updates 30000 | best_loss 11.022
2024-07-12 19:30:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:30:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_27_30000.pt (epoch 27 @ 30000 updates, score 3.93) (writing took 4.356003085151315 seconds)
2024-07-12 19:30:46 | INFO | train_inner | epoch 027:    668 / 1132 loss=3.375, nll_loss=1.828, ppl=3.55, wps=11139.4, ups=3.18, wpb=3503.9, bsz=141.3, num_updates=30100, lr=0.000182271, gnorm=1.04, train_wall=23, wall=0
2024-07-12 19:31:09 | INFO | train_inner | epoch 027:    768 / 1132 loss=3.397, nll_loss=1.853, ppl=3.61, wps=15398.9, ups=4.38, wpb=3517.7, bsz=137.3, num_updates=30200, lr=0.000181969, gnorm=1.07, train_wall=23, wall=0
2024-07-12 19:31:32 | INFO | train_inner | epoch 027:    868 / 1132 loss=3.378, nll_loss=1.834, ppl=3.56, wps=15580.5, ups=4.39, wpb=3549.7, bsz=142.6, num_updates=30300, lr=0.000181668, gnorm=1.048, train_wall=23, wall=0
2024-07-12 19:31:55 | INFO | train_inner | epoch 027:    968 / 1132 loss=3.429, nll_loss=1.888, ppl=3.7, wps=15553.4, ups=4.34, wpb=3584.5, bsz=128, num_updates=30400, lr=0.000181369, gnorm=1.048, train_wall=23, wall=0
2024-07-12 19:32:18 | INFO | train_inner | epoch 027:   1068 / 1132 loss=3.413, nll_loss=1.872, ppl=3.66, wps=15270.9, ups=4.38, wpb=3487.1, bsz=142.5, num_updates=30500, lr=0.000181071, gnorm=1.082, train_wall=23, wall=0
2024-07-12 19:32:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:32:37 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 3.925 | nll_loss 2.343 | ppl 5.07 | wps 44734.2 | wpb 2685.2 | bsz 107.1 | num_updates 30564 | best_loss 11.022
2024-07-12 19:32:37 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:32:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 27 @ 30564 updates, score 3.925) (writing took 4.089338787831366 seconds)
2024-07-12 19:32:41 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2024-07-12 19:32:41 | INFO | train | epoch 027 | loss 3.374 | nll_loss 1.827 | ppl 3.55 | wps 14534.4 | ups 4.09 | wpb 3556.4 | bsz 141.6 | num_updates 30564 | lr 0.000180882 | gnorm 1.037 | train_wall 258 | wall 0
2024-07-12 19:32:41 | INFO | fairseq.trainer | begin training epoch 28
2024-07-12 19:32:49 | INFO | train_inner | epoch 028:     36 / 1132 loss=3.393, nll_loss=1.847, ppl=3.6, wps=11353.4, ups=3.17, wpb=3583.5, bsz=135.9, num_updates=30600, lr=0.000180775, gnorm=1.021, train_wall=23, wall=0
2024-07-12 19:33:12 | INFO | train_inner | epoch 028:    136 / 1132 loss=3.312, nll_loss=1.754, ppl=3.37, wps=15431.5, ups=4.38, wpb=3523.7, bsz=138.2, num_updates=30700, lr=0.000180481, gnorm=1.049, train_wall=23, wall=0
2024-07-12 19:33:35 | INFO | train_inner | epoch 028:    236 / 1132 loss=3.309, nll_loss=1.752, ppl=3.37, wps=15701.2, ups=4.33, wpb=3628.1, bsz=153.3, num_updates=30800, lr=0.000180187, gnorm=1.014, train_wall=23, wall=0
2024-07-12 19:33:57 | INFO | train_inner | epoch 028:    336 / 1132 loss=3.321, nll_loss=1.766, ppl=3.4, wps=15192.9, ups=4.47, wpb=3395.7, bsz=131.4, num_updates=30900, lr=0.000179896, gnorm=1.086, train_wall=22, wall=0
2024-07-12 19:34:20 | INFO | train_inner | epoch 028:    436 / 1132 loss=3.336, nll_loss=1.782, ppl=3.44, wps=15286.8, ups=4.38, wpb=3493.7, bsz=149.5, num_updates=31000, lr=0.000179605, gnorm=1.071, train_wall=23, wall=0
2024-07-12 19:34:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:34:24 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 3.953 | nll_loss 2.365 | ppl 5.15 | wps 44721.9 | wpb 2685.2 | bsz 107.1 | num_updates 31000 | best_loss 11.022
2024-07-12 19:34:24 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:34:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_28_31000.pt (epoch 28 @ 31000 updates, score 3.953) (writing took 4.646206167526543 seconds)
2024-07-12 19:34:52 | INFO | train_inner | epoch 028:    536 / 1132 loss=3.367, nll_loss=1.817, ppl=3.52, wps=11232.4, ups=3.14, wpb=3575.2, bsz=132.4, num_updates=31100, lr=0.000179316, gnorm=1.043, train_wall=23, wall=0
2024-07-12 19:35:15 | INFO | train_inner | epoch 028:    636 / 1132 loss=3.354, nll_loss=1.804, ppl=3.49, wps=15602.8, ups=4.32, wpb=3613.7, bsz=143.2, num_updates=31200, lr=0.000179029, gnorm=1.033, train_wall=23, wall=0
2024-07-12 19:35:38 | INFO | train_inner | epoch 028:    736 / 1132 loss=3.343, nll_loss=1.794, ppl=3.47, wps=15950.4, ups=4.38, wpb=3644.1, bsz=148, num_updates=31300, lr=0.000178743, gnorm=1.029, train_wall=23, wall=0
2024-07-12 19:36:01 | INFO | train_inner | epoch 028:    836 / 1132 loss=3.398, nll_loss=1.852, ppl=3.61, wps=15214.3, ups=4.41, wpb=3448.6, bsz=128.8, num_updates=31400, lr=0.000178458, gnorm=1.106, train_wall=22, wall=0
2024-07-12 19:36:24 | INFO | train_inner | epoch 028:    936 / 1132 loss=3.377, nll_loss=1.831, ppl=3.56, wps=15662.6, ups=4.36, wpb=3592.1, bsz=140.5, num_updates=31500, lr=0.000178174, gnorm=1.033, train_wall=23, wall=0
2024-07-12 19:36:47 | INFO | train_inner | epoch 028:   1036 / 1132 loss=3.353, nll_loss=1.805, ppl=3.49, wps=15681.8, ups=4.34, wpb=3612.4, bsz=151.4, num_updates=31600, lr=0.000177892, gnorm=1.005, train_wall=23, wall=0
2024-07-12 19:37:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:37:13 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 3.919 | nll_loss 2.334 | ppl 5.04 | wps 44811.5 | wpb 2685.2 | bsz 107.1 | num_updates 31696 | best_loss 11.022
2024-07-12 19:37:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:37:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 28 @ 31696 updates, score 3.919) (writing took 3.8671494787558913 seconds)
2024-07-12 19:37:17 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2024-07-12 19:37:17 | INFO | train | epoch 028 | loss 3.35 | nll_loss 1.799 | ppl 3.48 | wps 14578.9 | ups 4.1 | wpb 3556.4 | bsz 141.6 | num_updates 31696 | lr 0.000177622 | gnorm 1.045 | train_wall 257 | wall 0
2024-07-12 19:37:17 | INFO | fairseq.trainer | begin training epoch 29
2024-07-12 19:37:18 | INFO | train_inner | epoch 029:      4 / 1132 loss=3.379, nll_loss=1.833, ppl=3.56, wps=11499.7, ups=3.19, wpb=3602.3, bsz=148.8, num_updates=31700, lr=0.000177611, gnorm=1.04, train_wall=23, wall=0
2024-07-12 19:37:41 | INFO | train_inner | epoch 029:    104 / 1132 loss=3.275, nll_loss=1.712, ppl=3.28, wps=15212.1, ups=4.35, wpb=3499.6, bsz=141.4, num_updates=31800, lr=0.000177332, gnorm=1.04, train_wall=23, wall=0
2024-07-12 19:38:04 | INFO | train_inner | epoch 029:    204 / 1132 loss=3.302, nll_loss=1.739, ppl=3.34, wps=15328.2, ups=4.41, wpb=3478.5, bsz=129.9, num_updates=31900, lr=0.000177054, gnorm=1.058, train_wall=23, wall=0
2024-07-12 19:38:27 | INFO | train_inner | epoch 029:    304 / 1132 loss=3.295, nll_loss=1.738, ppl=3.34, wps=15996, ups=4.37, wpb=3662.8, bsz=150.3, num_updates=32000, lr=0.000176777, gnorm=0.991, train_wall=23, wall=0
2024-07-12 19:38:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:38:31 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 3.935 | nll_loss 2.35 | ppl 5.1 | wps 44765.4 | wpb 2685.2 | bsz 107.1 | num_updates 32000 | best_loss 11.022
2024-07-12 19:38:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:38:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_29_32000.pt (epoch 29 @ 32000 updates, score 3.935) (writing took 4.103806941770017 seconds)
2024-07-12 19:38:58 | INFO | train_inner | epoch 029:    404 / 1132 loss=3.335, nll_loss=1.78, ppl=3.43, wps=11343.2, ups=3.22, wpb=3518.2, bsz=135.3, num_updates=32100, lr=0.000176501, gnorm=1.063, train_wall=23, wall=0
2024-07-12 19:39:20 | INFO | train_inner | epoch 029:    504 / 1132 loss=3.304, nll_loss=1.749, ppl=3.36, wps=15973.5, ups=4.42, wpb=3612.5, bsz=142.8, num_updates=32200, lr=0.000176227, gnorm=1.004, train_wall=22, wall=0
2024-07-12 19:39:43 | INFO | train_inner | epoch 029:    604 / 1132 loss=3.326, nll_loss=1.773, ppl=3.42, wps=15832.3, ups=4.32, wpb=3662, bsz=148.3, num_updates=32300, lr=0.000175954, gnorm=1.017, train_wall=23, wall=0
2024-07-12 19:40:07 | INFO | train_inner | epoch 029:    704 / 1132 loss=3.344, nll_loss=1.793, ppl=3.47, wps=15662.3, ups=4.32, wpb=3623.1, bsz=143.4, num_updates=32400, lr=0.000175682, gnorm=1.034, train_wall=23, wall=0
2024-07-12 19:40:29 | INFO | train_inner | epoch 029:    804 / 1132 loss=3.359, nll_loss=1.808, ppl=3.5, wps=15234.8, ups=4.4, wpb=3459.3, bsz=130.2, num_updates=32500, lr=0.000175412, gnorm=1.102, train_wall=23, wall=0
2024-07-12 19:40:52 | INFO | train_inner | epoch 029:    904 / 1132 loss=3.361, nll_loss=1.81, ppl=3.51, wps=15255.4, ups=4.38, wpb=3485.4, bsz=136.2, num_updates=32600, lr=0.000175142, gnorm=1.115, train_wall=23, wall=0
2024-07-12 19:41:15 | INFO | train_inner | epoch 029:   1004 / 1132 loss=3.333, nll_loss=1.782, ppl=3.44, wps=15445.4, ups=4.35, wpb=3548.7, bsz=161.3, num_updates=32700, lr=0.000174874, gnorm=1.038, train_wall=23, wall=0
2024-07-12 19:41:38 | INFO | train_inner | epoch 029:   1104 / 1132 loss=3.381, nll_loss=1.835, ppl=3.57, wps=15598.4, ups=4.37, wpb=3566, bsz=135.3, num_updates=32800, lr=0.000174608, gnorm=1.077, train_wall=23, wall=0
2024-07-12 19:41:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:41:49 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 3.929 | nll_loss 2.346 | ppl 5.09 | wps 44299.2 | wpb 2685.2 | bsz 107.1 | num_updates 32828 | best_loss 11.022
2024-07-12 19:41:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:41:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 29 @ 32828 updates, score 3.929) (writing took 3.350003364495933 seconds)
2024-07-12 19:41:52 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2024-07-12 19:41:52 | INFO | train | epoch 029 | loss 3.329 | nll_loss 1.775 | ppl 3.42 | wps 14632.5 | ups 4.11 | wpb 3556.4 | bsz 141.6 | num_updates 32828 | lr 0.000174533 | gnorm 1.05 | train_wall 257 | wall 0
2024-07-12 19:41:52 | INFO | fairseq.trainer | begin training epoch 30
2024-07-12 19:42:09 | INFO | train_inner | epoch 030:     72 / 1132 loss=3.291, nll_loss=1.73, ppl=3.32, wps=11560.1, ups=3.23, wpb=3575, bsz=143, num_updates=32900, lr=0.000174342, gnorm=1.056, train_wall=23, wall=0
2024-07-12 19:42:32 | INFO | train_inner | epoch 030:    172 / 1132 loss=3.288, nll_loss=1.726, ppl=3.31, wps=15468.8, ups=4.37, wpb=3542.5, bsz=131, num_updates=33000, lr=0.000174078, gnorm=1.074, train_wall=23, wall=0
2024-07-12 19:42:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:42:36 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 3.938 | nll_loss 2.352 | ppl 5.11 | wps 44855.6 | wpb 2685.2 | bsz 107.1 | num_updates 33000 | best_loss 11.022
2024-07-12 19:42:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:42:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_30_33000.pt (epoch 30 @ 33000 updates, score 3.938) (writing took 4.248605201952159 seconds)
2024-07-12 19:43:03 | INFO | train_inner | epoch 030:    272 / 1132 loss=3.306, nll_loss=1.746, ppl=3.36, wps=11339.7, ups=3.19, wpb=3557.6, bsz=131.4, num_updates=33100, lr=0.000173814, gnorm=1.061, train_wall=23, wall=0
2024-07-12 19:43:26 | INFO | train_inner | epoch 030:    372 / 1132 loss=3.252, nll_loss=1.689, ppl=3.22, wps=15719.3, ups=4.29, wpb=3660.4, bsz=177.7, num_updates=33200, lr=0.000173553, gnorm=0.987, train_wall=23, wall=0
2024-07-12 19:43:49 | INFO | train_inner | epoch 030:    472 / 1132 loss=3.291, nll_loss=1.732, ppl=3.32, wps=15546.2, ups=4.42, wpb=3519.4, bsz=134.6, num_updates=33300, lr=0.000173292, gnorm=1.051, train_wall=22, wall=0
2024-07-12 19:44:12 | INFO | train_inner | epoch 030:    572 / 1132 loss=3.299, nll_loss=1.74, ppl=3.34, wps=15576.6, ups=4.37, wpb=3562.2, bsz=140, num_updates=33400, lr=0.000173032, gnorm=1.053, train_wall=23, wall=0
2024-07-12 19:44:35 | INFO | train_inner | epoch 030:    672 / 1132 loss=3.312, nll_loss=1.756, ppl=3.38, wps=15355.4, ups=4.39, wpb=3496.2, bsz=140.2, num_updates=33500, lr=0.000172774, gnorm=1.062, train_wall=23, wall=0
2024-07-12 19:44:58 | INFO | train_inner | epoch 030:    772 / 1132 loss=3.351, nll_loss=1.799, ppl=3.48, wps=15316.2, ups=4.37, wpb=3506.2, bsz=123, num_updates=33600, lr=0.000172516, gnorm=1.091, train_wall=23, wall=0
2024-07-12 19:45:21 | INFO | train_inner | epoch 030:    872 / 1132 loss=3.303, nll_loss=1.747, ppl=3.36, wps=15308.9, ups=4.34, wpb=3530.5, bsz=156.2, num_updates=33700, lr=0.00017226, gnorm=1.046, train_wall=23, wall=0
2024-07-12 19:45:44 | INFO | train_inner | epoch 030:    972 / 1132 loss=3.352, nll_loss=1.799, ppl=3.48, wps=15478.9, ups=4.3, wpb=3596, bsz=132.9, num_updates=33800, lr=0.000172005, gnorm=1.061, train_wall=23, wall=0
2024-07-12 19:46:07 | INFO | train_inner | epoch 030:   1072 / 1132 loss=3.323, nll_loss=1.77, ppl=3.41, wps=15584.6, ups=4.33, wpb=3600.5, bsz=151.8, num_updates=33900, lr=0.000171751, gnorm=1.029, train_wall=23, wall=0
2024-07-12 19:46:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:46:25 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 3.931 | nll_loss 2.351 | ppl 5.1 | wps 44477.8 | wpb 2685.2 | bsz 107.1 | num_updates 33960 | best_loss 11.022
2024-07-12 19:46:25 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:46:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 30 @ 33960 updates, score 3.931) (writing took 4.012416278012097 seconds)
2024-07-12 19:46:29 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2024-07-12 19:46:29 | INFO | train | epoch 030 | loss 3.306 | nll_loss 1.749 | ppl 3.36 | wps 14542.6 | ups 4.09 | wpb 3556.4 | bsz 141.6 | num_updates 33960 | lr 0.0001716 | gnorm 1.053 | train_wall 258 | wall 0
2024-07-12 19:46:29 | INFO | fairseq.trainer | begin training epoch 31
2024-07-12 19:46:38 | INFO | train_inner | epoch 031:     40 / 1132 loss=3.298, nll_loss=1.74, ppl=3.34, wps=11048.7, ups=3.21, wpb=3438.4, bsz=136.2, num_updates=34000, lr=0.000171499, gnorm=1.093, train_wall=23, wall=0
2024-07-12 19:46:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:46:42 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 3.95 | nll_loss 2.359 | ppl 5.13 | wps 44551.2 | wpb 2685.2 | bsz 107.1 | num_updates 34000 | best_loss 11.022
2024-07-12 19:46:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:46:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_31_34000.pt (epoch 31 @ 34000 updates, score 3.95) (writing took 8.574815813452005 seconds)
2024-07-12 19:47:14 | INFO | train_inner | epoch 031:    140 / 1132 loss=3.2, nll_loss=1.628, ppl=3.09, wps=9922.5, ups=2.77, wpb=3579.8, bsz=158.2, num_updates=34100, lr=0.000171247, gnorm=1.013, train_wall=23, wall=0
2024-07-12 19:47:37 | INFO | train_inner | epoch 031:    240 / 1132 loss=3.26, nll_loss=1.696, ppl=3.24, wps=15653.2, ups=4.35, wpb=3601.7, bsz=146.5, num_updates=34200, lr=0.000170996, gnorm=1.028, train_wall=23, wall=0
2024-07-12 19:48:00 | INFO | train_inner | epoch 031:    340 / 1132 loss=3.263, nll_loss=1.7, ppl=3.25, wps=15476.4, ups=4.31, wpb=3591.1, bsz=152.2, num_updates=34300, lr=0.000170747, gnorm=1.05, train_wall=23, wall=0
2024-07-12 19:48:24 | INFO | train_inner | epoch 031:    440 / 1132 loss=3.32, nll_loss=1.762, ppl=3.39, wps=15462.8, ups=4.32, wpb=3578.1, bsz=124.3, num_updates=34400, lr=0.000170499, gnorm=1.059, train_wall=23, wall=0
2024-07-12 19:48:47 | INFO | train_inner | epoch 031:    540 / 1132 loss=3.316, nll_loss=1.757, ppl=3.38, wps=15451.1, ups=4.3, wpb=3591.7, bsz=122.6, num_updates=34500, lr=0.000170251, gnorm=1.063, train_wall=23, wall=0
2024-07-12 19:49:10 | INFO | train_inner | epoch 031:    640 / 1132 loss=3.269, nll_loss=1.707, ppl=3.27, wps=15458.2, ups=4.38, wpb=3528.8, bsz=155.2, num_updates=34600, lr=0.000170005, gnorm=1.045, train_wall=23, wall=0
2024-07-12 19:49:32 | INFO | train_inner | epoch 031:    740 / 1132 loss=3.285, nll_loss=1.725, ppl=3.31, wps=15405, ups=4.39, wpb=3506.2, bsz=142.5, num_updates=34700, lr=0.00016976, gnorm=1.091, train_wall=23, wall=0
2024-07-12 19:49:56 | INFO | train_inner | epoch 031:    840 / 1132 loss=3.317, nll_loss=1.76, ppl=3.39, wps=15458.9, ups=4.32, wpb=3580.6, bsz=138.6, num_updates=34800, lr=0.000169516, gnorm=1.067, train_wall=23, wall=0
2024-07-12 19:50:19 | INFO | train_inner | epoch 031:    940 / 1132 loss=3.325, nll_loss=1.769, ppl=3.41, wps=15294.7, ups=4.35, wpb=3518.7, bsz=130.9, num_updates=34900, lr=0.000169273, gnorm=1.089, train_wall=23, wall=0
2024-07-12 19:50:42 | INFO | train_inner | epoch 031:   1040 / 1132 loss=3.331, nll_loss=1.778, ppl=3.43, wps=15564.1, ups=4.33, wpb=3596.8, bsz=134.4, num_updates=35000, lr=0.000169031, gnorm=1.051, train_wall=23, wall=0
2024-07-12 19:50:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:50:46 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 3.93 | nll_loss 2.345 | ppl 5.08 | wps 44627.9 | wpb 2685.2 | bsz 107.1 | num_updates 35000 | best_loss 11.022
2024-07-12 19:50:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:50:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_31_35000.pt (epoch 31 @ 35000 updates, score 3.93) (writing took 5.855260195210576 seconds)
2024-07-12 19:51:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:51:17 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 3.924 | nll_loss 2.343 | ppl 5.07 | wps 44966.5 | wpb 2685.2 | bsz 107.1 | num_updates 35092 | best_loss 11.022
2024-07-12 19:51:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:51:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 31 @ 35092 updates, score 3.924) (writing took 10.966965763829648 seconds)
2024-07-12 19:51:28 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2024-07-12 19:51:28 | INFO | train | epoch 031 | loss 3.286 | nll_loss 1.726 | ppl 3.31 | wps 13462.3 | ups 3.79 | wpb 3556.4 | bsz 141.6 | num_updates 35092 | lr 0.000168809 | gnorm 1.056 | train_wall 259 | wall 0
2024-07-12 19:51:28 | INFO | fairseq.trainer | begin training epoch 32
2024-07-12 19:51:30 | INFO | train_inner | epoch 032:      8 / 1132 loss=3.283, nll_loss=1.726, ppl=3.31, wps=7326.3, ups=2.08, wpb=3529.3, bsz=152.1, num_updates=35100, lr=0.00016879, gnorm=1.048, train_wall=23, wall=0
2024-07-12 19:51:53 | INFO | train_inner | epoch 032:    108 / 1132 loss=3.233, nll_loss=1.663, ppl=3.17, wps=15492, ups=4.31, wpb=3590.7, bsz=136.9, num_updates=35200, lr=0.00016855, gnorm=1.057, train_wall=23, wall=0
2024-07-12 19:52:16 | INFO | train_inner | epoch 032:    208 / 1132 loss=3.236, nll_loss=1.668, ppl=3.18, wps=15463.4, ups=4.34, wpb=3562.6, bsz=136.3, num_updates=35300, lr=0.000168311, gnorm=1.069, train_wall=23, wall=0
2024-07-12 19:52:39 | INFO | train_inner | epoch 032:    308 / 1132 loss=3.242, nll_loss=1.675, ppl=3.19, wps=15639.5, ups=4.32, wpb=3619.8, bsz=143, num_updates=35400, lr=0.000168073, gnorm=1.042, train_wall=23, wall=0
2024-07-12 19:53:02 | INFO | train_inner | epoch 032:    408 / 1132 loss=3.235, nll_loss=1.666, ppl=3.17, wps=15330.9, ups=4.35, wpb=3521.9, bsz=146.2, num_updates=35500, lr=0.000167836, gnorm=1.048, train_wall=23, wall=0
2024-07-12 19:53:25 | INFO | train_inner | epoch 032:    508 / 1132 loss=3.257, nll_loss=1.693, ppl=3.23, wps=15489.8, ups=4.38, wpb=3538.7, bsz=142.6, num_updates=35600, lr=0.0001676, gnorm=1.092, train_wall=23, wall=0
2024-07-12 19:53:48 | INFO | train_inner | epoch 032:    608 / 1132 loss=3.309, nll_loss=1.75, ppl=3.36, wps=15324.9, ups=4.31, wpb=3555, bsz=125.9, num_updates=35700, lr=0.000167365, gnorm=1.09, train_wall=23, wall=0
2024-07-12 19:54:12 | INFO | train_inner | epoch 032:    708 / 1132 loss=3.26, nll_loss=1.694, ppl=3.24, wps=15097.3, ups=4.29, wpb=3516.2, bsz=148.6, num_updates=35800, lr=0.000167132, gnorm=1.049, train_wall=23, wall=0
2024-07-12 19:54:35 | INFO | train_inner | epoch 032:    808 / 1132 loss=3.291, nll_loss=1.731, ppl=3.32, wps=15272.8, ups=4.32, wpb=3534.8, bsz=136.2, num_updates=35900, lr=0.000166899, gnorm=1.082, train_wall=23, wall=0
2024-07-12 19:54:58 | INFO | train_inner | epoch 032:    908 / 1132 loss=3.312, nll_loss=1.755, ppl=3.38, wps=15570.4, ups=4.34, wpb=3589.5, bsz=136.6, num_updates=36000, lr=0.000166667, gnorm=1.07, train_wall=23, wall=0
2024-07-12 19:54:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:55:02 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 3.935 | nll_loss 2.352 | ppl 5.1 | wps 44509.3 | wpb 2685.2 | bsz 107.1 | num_updates 36000 | best_loss 11.022
2024-07-12 19:55:02 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:55:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_32_36000.pt (epoch 32 @ 36000 updates, score 3.935) (writing took 12.721710793673992 seconds)
2024-07-12 19:55:37 | INFO | train_inner | epoch 032:   1008 / 1132 loss=3.29, nll_loss=1.732, ppl=3.32, wps=8829.3, ups=2.52, wpb=3500.1, bsz=146.2, num_updates=36100, lr=0.000166436, gnorm=1.102, train_wall=22, wall=0
2024-07-12 19:56:00 | INFO | train_inner | epoch 032:   1108 / 1132 loss=3.268, nll_loss=1.709, ppl=3.27, wps=15712.3, ups=4.37, wpb=3597.5, bsz=160, num_updates=36200, lr=0.000166206, gnorm=1.046, train_wall=23, wall=0
2024-07-12 19:56:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:56:10 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 3.917 | nll_loss 2.337 | ppl 5.05 | wps 44296.2 | wpb 2685.2 | bsz 107.1 | num_updates 36224 | best_loss 11.022
2024-07-12 19:56:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:56:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 32 @ 36224 updates, score 3.917) (writing took 12.56015882641077 seconds)
2024-07-12 19:56:23 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2024-07-12 19:56:23 | INFO | train | epoch 032 | loss 3.267 | nll_loss 1.703 | ppl 3.26 | wps 13660.1 | ups 3.84 | wpb 3556.4 | bsz 141.6 | num_updates 36224 | lr 0.000166151 | gnorm 1.068 | train_wall 259 | wall 0
2024-07-12 19:56:23 | INFO | fairseq.trainer | begin training epoch 33
2024-07-12 19:56:41 | INFO | train_inner | epoch 033:     76 / 1132 loss=3.229, nll_loss=1.661, ppl=3.16, wps=8957.7, ups=2.48, wpb=3613, bsz=133.9, num_updates=36300, lr=0.000165977, gnorm=1.024, train_wall=23, wall=0
2024-07-12 19:57:03 | INFO | train_inner | epoch 033:    176 / 1132 loss=3.211, nll_loss=1.64, ppl=3.12, wps=15721.6, ups=4.37, wpb=3599.2, bsz=145, num_updates=36400, lr=0.000165748, gnorm=1.04, train_wall=23, wall=0
2024-07-12 19:57:27 | INFO | train_inner | epoch 033:    276 / 1132 loss=3.209, nll_loss=1.637, ppl=3.11, wps=15000.3, ups=4.28, wpb=3508.7, bsz=145, num_updates=36500, lr=0.000165521, gnorm=1.091, train_wall=23, wall=0
2024-07-12 19:57:50 | INFO | train_inner | epoch 033:    376 / 1132 loss=3.266, nll_loss=1.699, ppl=3.25, wps=15616.2, ups=4.35, wpb=3588.6, bsz=129.3, num_updates=36600, lr=0.000165295, gnorm=1.065, train_wall=23, wall=0
2024-07-12 19:58:13 | INFO | train_inner | epoch 033:    476 / 1132 loss=3.234, nll_loss=1.664, ppl=3.17, wps=15086.6, ups=4.35, wpb=3465.2, bsz=140.2, num_updates=36700, lr=0.00016507, gnorm=1.097, train_wall=23, wall=0
2024-07-12 19:58:36 | INFO | train_inner | epoch 033:    576 / 1132 loss=3.258, nll_loss=1.692, ppl=3.23, wps=15227, ups=4.34, wpb=3509.7, bsz=128.5, num_updates=36800, lr=0.000164845, gnorm=1.067, train_wall=23, wall=0
2024-07-12 19:58:59 | INFO | train_inner | epoch 033:    676 / 1132 loss=3.256, nll_loss=1.691, ppl=3.23, wps=15534.7, ups=4.4, wpb=3531, bsz=139.8, num_updates=36900, lr=0.000164622, gnorm=1.105, train_wall=23, wall=0
2024-07-12 19:59:22 | INFO | train_inner | epoch 033:    776 / 1132 loss=3.247, nll_loss=1.682, ppl=3.21, wps=15544.4, ups=4.31, wpb=3602.7, bsz=157.7, num_updates=37000, lr=0.000164399, gnorm=1.056, train_wall=23, wall=0
2024-07-12 19:59:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 19:59:26 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 3.94 | nll_loss 2.352 | ppl 5.11 | wps 44991.3 | wpb 2685.2 | bsz 107.1 | num_updates 37000 | best_loss 11.022
2024-07-12 19:59:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 19:59:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_33_37000.pt (epoch 33 @ 37000 updates, score 3.94) (writing took 5.2382219191640615 seconds)
2024-07-12 19:59:54 | INFO | train_inner | epoch 033:    876 / 1132 loss=3.276, nll_loss=1.713, ppl=3.28, wps=10892.2, ups=3.08, wpb=3533.9, bsz=145.7, num_updates=37100, lr=0.000164177, gnorm=1.09, train_wall=23, wall=0
2024-07-12 20:00:17 | INFO | train_inner | epoch 033:    976 / 1132 loss=3.268, nll_loss=1.706, ppl=3.26, wps=15807, ups=4.32, wpb=3662.7, bsz=156.3, num_updates=37200, lr=0.000163956, gnorm=1.048, train_wall=23, wall=0
2024-07-12 20:00:40 | INFO | train_inner | epoch 033:   1076 / 1132 loss=3.286, nll_loss=1.727, ppl=3.31, wps=15594.7, ups=4.43, wpb=3523.3, bsz=131, num_updates=37300, lr=0.000163737, gnorm=1.095, train_wall=22, wall=0
2024-07-12 20:00:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:00:57 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 3.933 | nll_loss 2.346 | ppl 5.09 | wps 44737.9 | wpb 2685.2 | bsz 107.1 | num_updates 37356 | best_loss 11.022
2024-07-12 20:00:57 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:01:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 33 @ 37356 updates, score 3.933) (writing took 13.368320237845182 seconds)
2024-07-12 20:01:11 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2024-07-12 20:01:11 | INFO | train | epoch 033 | loss 3.249 | nll_loss 1.683 | ppl 3.21 | wps 13963.8 | ups 3.93 | wpb 3556.4 | bsz 141.6 | num_updates 37356 | lr 0.000163614 | gnorm 1.071 | train_wall 259 | wall 0
2024-07-12 20:01:11 | INFO | fairseq.trainer | begin training epoch 34
2024-07-12 20:01:21 | INFO | train_inner | epoch 034:     44 / 1132 loss=3.224, nll_loss=1.654, ppl=3.15, wps=8557.3, ups=2.43, wpb=3526.6, bsz=151.2, num_updates=37400, lr=0.000163517, gnorm=1.065, train_wall=23, wall=0
2024-07-12 20:01:44 | INFO | train_inner | epoch 034:    144 / 1132 loss=3.188, nll_loss=1.613, ppl=3.06, wps=15842, ups=4.36, wpb=3632.6, bsz=144.9, num_updates=37500, lr=0.000163299, gnorm=1.039, train_wall=23, wall=0
2024-07-12 20:02:07 | INFO | train_inner | epoch 034:    244 / 1132 loss=3.194, nll_loss=1.622, ppl=3.08, wps=15917.7, ups=4.34, wpb=3670.8, bsz=155.5, num_updates=37600, lr=0.000163082, gnorm=1.031, train_wall=23, wall=0
2024-07-12 20:02:30 | INFO | train_inner | epoch 034:    344 / 1132 loss=3.211, nll_loss=1.639, ppl=3.11, wps=15359.5, ups=4.36, wpb=3522.4, bsz=145.5, num_updates=37700, lr=0.000162866, gnorm=1.074, train_wall=23, wall=0
2024-07-12 20:02:53 | INFO | train_inner | epoch 034:    444 / 1132 loss=3.218, nll_loss=1.646, ppl=3.13, wps=15493.8, ups=4.39, wpb=3530.9, bsz=138.5, num_updates=37800, lr=0.00016265, gnorm=1.077, train_wall=23, wall=0
2024-07-12 20:03:16 | INFO | train_inner | epoch 034:    544 / 1132 loss=3.274, nll_loss=1.707, ppl=3.26, wps=15081.1, ups=4.33, wpb=3481.9, bsz=114, num_updates=37900, lr=0.000162435, gnorm=1.124, train_wall=23, wall=0
2024-07-12 20:03:39 | INFO | train_inner | epoch 034:    644 / 1132 loss=3.213, nll_loss=1.642, ppl=3.12, wps=15573.1, ups=4.37, wpb=3560.8, bsz=153.5, num_updates=38000, lr=0.000162221, gnorm=1.056, train_wall=23, wall=0
2024-07-12 20:03:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:03:43 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 3.936 | nll_loss 2.351 | ppl 5.1 | wps 44501.7 | wpb 2685.2 | bsz 107.1 | num_updates 38000 | best_loss 11.022
2024-07-12 20:03:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:03:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_34_38000.pt (epoch 34 @ 38000 updates, score 3.936) (writing took 5.065042833797634 seconds)
2024-07-12 20:04:11 | INFO | train_inner | epoch 034:    744 / 1132 loss=3.234, nll_loss=1.667, ppl=3.18, wps=11048.4, ups=3.07, wpb=3597.6, bsz=152.4, num_updates=38100, lr=0.000162008, gnorm=1.058, train_wall=23, wall=0
2024-07-12 20:04:35 | INFO | train_inner | epoch 034:    844 / 1132 loss=3.243, nll_loss=1.677, ppl=3.2, wps=15288.8, ups=4.29, wpb=3560, bsz=145, num_updates=38200, lr=0.000161796, gnorm=1.092, train_wall=23, wall=0
2024-07-12 20:04:58 | INFO | train_inner | epoch 034:    944 / 1132 loss=3.244, nll_loss=1.678, ppl=3.2, wps=15192.4, ups=4.36, wpb=3483.1, bsz=139.4, num_updates=38300, lr=0.000161585, gnorm=1.102, train_wall=23, wall=0
2024-07-12 20:05:21 | INFO | train_inner | epoch 034:   1044 / 1132 loss=3.271, nll_loss=1.709, ppl=3.27, wps=15571.4, ups=4.36, wpb=3570.2, bsz=134.5, num_updates=38400, lr=0.000161374, gnorm=1.076, train_wall=23, wall=0
2024-07-12 20:05:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:05:45 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 3.932 | nll_loss 2.351 | ppl 5.1 | wps 44651.6 | wpb 2685.2 | bsz 107.1 | num_updates 38488 | best_loss 11.022
2024-07-12 20:05:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:05:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 34 @ 38488 updates, score 3.932) (writing took 5.157440195791423 seconds)
2024-07-12 20:05:50 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2024-07-12 20:05:50 | INFO | train | epoch 034 | loss 3.231 | nll_loss 1.662 | ppl 3.16 | wps 14415.3 | ups 4.05 | wpb 3556.4 | bsz 141.6 | num_updates 38488 | lr 0.00016119 | gnorm 1.076 | train_wall 258 | wall 0
2024-07-12 20:05:50 | INFO | fairseq.trainer | begin training epoch 35
2024-07-12 20:05:53 | INFO | train_inner | epoch 035:     12 / 1132 loss=3.256, nll_loss=1.691, ppl=3.23, wps=10835.4, ups=3.08, wpb=3520.3, bsz=135, num_updates=38500, lr=0.000161165, gnorm=1.105, train_wall=23, wall=0
2024-07-12 20:06:16 | INFO | train_inner | epoch 035:    112 / 1132 loss=3.157, nll_loss=1.577, ppl=2.98, wps=15596.2, ups=4.39, wpb=3556.1, bsz=143.9, num_updates=38600, lr=0.000160956, gnorm=1.052, train_wall=23, wall=0
2024-07-12 20:06:39 | INFO | train_inner | epoch 035:    212 / 1132 loss=3.179, nll_loss=1.601, ppl=3.03, wps=15364, ups=4.36, wpb=3520.2, bsz=132.2, num_updates=38700, lr=0.000160748, gnorm=1.084, train_wall=23, wall=0
2024-07-12 20:07:02 | INFO | train_inner | epoch 035:    312 / 1132 loss=3.19, nll_loss=1.613, ppl=3.06, wps=15285.7, ups=4.38, wpb=3492.7, bsz=134, num_updates=38800, lr=0.00016054, gnorm=1.085, train_wall=23, wall=0
2024-07-12 20:07:25 | INFO | train_inner | epoch 035:    412 / 1132 loss=3.191, nll_loss=1.617, ppl=3.07, wps=15564, ups=4.3, wpb=3622.7, bsz=154.1, num_updates=38900, lr=0.000160334, gnorm=1.054, train_wall=23, wall=0
2024-07-12 20:07:48 | INFO | train_inner | epoch 035:    512 / 1132 loss=3.23, nll_loss=1.658, ppl=3.16, wps=15567.2, ups=4.37, wpb=3559.8, bsz=131.8, num_updates=39000, lr=0.000160128, gnorm=1.103, train_wall=23, wall=0
2024-07-12 20:07:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:07:52 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 3.948 | nll_loss 2.362 | ppl 5.14 | wps 44762.3 | wpb 2685.2 | bsz 107.1 | num_updates 39000 | best_loss 11.022
2024-07-12 20:07:52 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:08:05 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_35_39000.pt (epoch 35 @ 39000 updates, score 3.948) (writing took 12.69076347630471 seconds)
2024-07-12 20:08:28 | INFO | train_inner | epoch 035:    612 / 1132 loss=3.238, nll_loss=1.671, ppl=3.18, wps=9178.1, ups=2.49, wpb=3681.6, bsz=149, num_updates=39100, lr=0.000159923, gnorm=1.049, train_wall=23, wall=0
2024-07-12 20:08:51 | INFO | train_inner | epoch 035:    712 / 1132 loss=3.212, nll_loss=1.641, ppl=3.12, wps=15523.7, ups=4.37, wpb=3549.6, bsz=149.2, num_updates=39200, lr=0.000159719, gnorm=1.069, train_wall=23, wall=0
2024-07-12 20:09:14 | INFO | train_inner | epoch 035:    812 / 1132 loss=3.206, nll_loss=1.635, ppl=3.11, wps=15315.4, ups=4.35, wpb=3524.2, bsz=164.7, num_updates=39300, lr=0.000159516, gnorm=1.09, train_wall=23, wall=0
2024-07-12 20:09:37 | INFO | train_inner | epoch 035:    912 / 1132 loss=3.228, nll_loss=1.658, ppl=3.16, wps=15417.8, ups=4.38, wpb=3518.2, bsz=136.6, num_updates=39400, lr=0.000159313, gnorm=1.102, train_wall=23, wall=0
2024-07-12 20:09:59 | INFO | train_inner | epoch 035:   1012 / 1132 loss=3.273, nll_loss=1.711, ppl=3.27, wps=15908.3, ups=4.37, wpb=3642.4, bsz=128.2, num_updates=39500, lr=0.000159111, gnorm=1.089, train_wall=23, wall=0
2024-07-12 20:10:22 | INFO | train_inner | epoch 035:   1112 / 1132 loss=3.245, nll_loss=1.678, ppl=3.2, wps=15599.6, ups=4.51, wpb=3456.6, bsz=131.8, num_updates=39600, lr=0.00015891, gnorm=1.126, train_wall=22, wall=0
2024-07-12 20:10:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:10:30 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 3.941 | nll_loss 2.356 | ppl 5.12 | wps 45028.4 | wpb 2685.2 | bsz 107.1 | num_updates 39620 | best_loss 11.022
2024-07-12 20:10:30 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:10:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 35 @ 39620 updates, score 3.941) (writing took 4.403079450130463 seconds)
2024-07-12 20:10:35 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2024-07-12 20:10:35 | INFO | train | epoch 035 | loss 3.214 | nll_loss 1.642 | ppl 3.12 | wps 14140.4 | ups 3.98 | wpb 3556.4 | bsz 141.6 | num_updates 39620 | lr 0.00015887 | gnorm 1.082 | train_wall 257 | wall 0
2024-07-12 20:10:35 | INFO | fairseq.trainer | begin training epoch 36
2024-07-12 20:10:54 | INFO | train_inner | epoch 036:     80 / 1132 loss=3.196, nll_loss=1.619, ppl=3.07, wps=11232.4, ups=3.11, wpb=3606.4, bsz=136.3, num_updates=39700, lr=0.00015871, gnorm=1.056, train_wall=23, wall=0
2024-07-12 20:11:17 | INFO | train_inner | epoch 036:    180 / 1132 loss=3.157, nll_loss=1.575, ppl=2.98, wps=15293.3, ups=4.33, wpb=3530.2, bsz=145.8, num_updates=39800, lr=0.000158511, gnorm=1.07, train_wall=23, wall=0
2024-07-12 20:11:40 | INFO | train_inner | epoch 036:    280 / 1132 loss=3.143, nll_loss=1.562, ppl=2.95, wps=15646.1, ups=4.38, wpb=3570, bsz=158.4, num_updates=39900, lr=0.000158312, gnorm=1.05, train_wall=23, wall=0
2024-07-12 20:12:02 | INFO | train_inner | epoch 036:    380 / 1132 loss=3.178, nll_loss=1.601, ppl=3.03, wps=15683.9, ups=4.41, wpb=3559.4, bsz=142.6, num_updates=40000, lr=0.000158114, gnorm=1.088, train_wall=23, wall=0
2024-07-12 20:12:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:12:07 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 3.951 | nll_loss 2.364 | ppl 5.15 | wps 45102.6 | wpb 2685.2 | bsz 107.1 | num_updates 40000 | best_loss 11.022
2024-07-12 20:12:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:12:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_36_40000.pt (epoch 36 @ 40000 updates, score 3.951) (writing took 9.06829363014549 seconds)
2024-07-12 20:12:39 | INFO | train_inner | epoch 036:    480 / 1132 loss=3.182, nll_loss=1.607, ppl=3.05, wps=9703.6, ups=2.73, wpb=3551.2, bsz=143.2, num_updates=40100, lr=0.000157917, gnorm=1.071, train_wall=23, wall=0
2024-07-12 20:13:02 | INFO | train_inner | epoch 036:    580 / 1132 loss=3.195, nll_loss=1.621, ppl=3.08, wps=14975, ups=4.25, wpb=3522.7, bsz=136.3, num_updates=40200, lr=0.00015772, gnorm=1.101, train_wall=23, wall=0
2024-07-12 20:13:25 | INFO | train_inner | epoch 036:    680 / 1132 loss=3.21, nll_loss=1.636, ppl=3.11, wps=15738.9, ups=4.37, wpb=3602.6, bsz=143.2, num_updates=40300, lr=0.000157524, gnorm=1.082, train_wall=23, wall=0
2024-07-12 20:13:48 | INFO | train_inner | epoch 036:    780 / 1132 loss=3.209, nll_loss=1.638, ppl=3.11, wps=15517.8, ups=4.4, wpb=3525.9, bsz=129.5, num_updates=40400, lr=0.000157329, gnorm=1.111, train_wall=23, wall=0
2024-07-12 20:14:12 | INFO | train_inner | epoch 036:    880 / 1132 loss=3.195, nll_loss=1.623, ppl=3.08, wps=15422.9, ups=4.26, wpb=3619.5, bsz=153.2, num_updates=40500, lr=0.000157135, gnorm=1.054, train_wall=23, wall=0
2024-07-12 20:14:34 | INFO | train_inner | epoch 036:    980 / 1132 loss=3.248, nll_loss=1.68, ppl=3.2, wps=15452.3, ups=4.39, wpb=3519.5, bsz=131.6, num_updates=40600, lr=0.000156941, gnorm=1.109, train_wall=23, wall=0
2024-07-12 20:14:57 | INFO | train_inner | epoch 036:   1080 / 1132 loss=3.245, nll_loss=1.678, ppl=3.2, wps=15528.2, ups=4.38, wpb=3543.1, bsz=139, num_updates=40700, lr=0.000156748, gnorm=1.124, train_wall=23, wall=0
2024-07-12 20:15:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:15:13 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 3.938 | nll_loss 2.357 | ppl 5.12 | wps 44911.5 | wpb 2685.2 | bsz 107.1 | num_updates 40752 | best_loss 11.022
2024-07-12 20:15:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:15:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 36 @ 40752 updates, score 3.938) (writing took 6.511786749586463 seconds)
2024-07-12 20:15:20 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2024-07-12 20:15:20 | INFO | train | epoch 036 | loss 3.197 | nll_loss 1.622 | ppl 3.08 | wps 14138.5 | ups 3.98 | wpb 3556.4 | bsz 141.6 | num_updates 40752 | lr 0.000156648 | gnorm 1.085 | train_wall 259 | wall 0
2024-07-12 20:15:20 | INFO | fairseq.trainer | begin training epoch 37
2024-07-12 20:15:31 | INFO | train_inner | epoch 037:     48 / 1132 loss=3.195, nll_loss=1.619, ppl=3.07, wps=10510.5, ups=2.98, wpb=3528.8, bsz=137, num_updates=40800, lr=0.000156556, gnorm=1.113, train_wall=23, wall=0
2024-07-12 20:15:54 | INFO | train_inner | epoch 037:    148 / 1132 loss=3.119, nll_loss=1.535, ppl=2.9, wps=15686.3, ups=4.39, wpb=3576.3, bsz=150.6, num_updates=40900, lr=0.000156365, gnorm=1.066, train_wall=23, wall=0
2024-07-12 20:16:16 | INFO | train_inner | epoch 037:    248 / 1132 loss=3.139, nll_loss=1.558, ppl=2.94, wps=15833.7, ups=4.38, wpb=3617.3, bsz=154.9, num_updates=41000, lr=0.000156174, gnorm=1.052, train_wall=23, wall=0
2024-07-12 20:16:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:16:21 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 3.95 | nll_loss 2.367 | ppl 5.16 | wps 45194 | wpb 2685.2 | bsz 107.1 | num_updates 41000 | best_loss 11.022
2024-07-12 20:16:21 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:16:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_37_41000.pt (epoch 37 @ 41000 updates, score 3.95) (writing took 8.732993108220398 seconds)
2024-07-12 20:16:52 | INFO | train_inner | epoch 037:    348 / 1132 loss=3.168, nll_loss=1.588, ppl=3.01, wps=9892.1, ups=2.78, wpb=3563.8, bsz=138.6, num_updates=41100, lr=0.000155984, gnorm=1.092, train_wall=23, wall=0
2024-07-12 20:17:15 | INFO | train_inner | epoch 037:    448 / 1132 loss=3.169, nll_loss=1.591, ppl=3.01, wps=15686.6, ups=4.42, wpb=3547.3, bsz=138.4, num_updates=41200, lr=0.000155794, gnorm=1.083, train_wall=22, wall=0
2024-07-12 20:17:38 | INFO | train_inner | epoch 037:    548 / 1132 loss=3.184, nll_loss=1.608, ppl=3.05, wps=15767.7, ups=4.39, wpb=3590.9, bsz=137.9, num_updates=41300, lr=0.000155606, gnorm=1.075, train_wall=23, wall=0
2024-07-12 20:18:01 | INFO | train_inner | epoch 037:    648 / 1132 loss=3.204, nll_loss=1.629, ppl=3.09, wps=15377.1, ups=4.38, wpb=3512.3, bsz=129.9, num_updates=41400, lr=0.000155417, gnorm=1.113, train_wall=23, wall=0
2024-07-12 20:18:24 | INFO | train_inner | epoch 037:    748 / 1132 loss=3.195, nll_loss=1.621, ppl=3.07, wps=15343, ups=4.33, wpb=3544.2, bsz=135, num_updates=41500, lr=0.00015523, gnorm=1.108, train_wall=23, wall=0
2024-07-12 20:18:47 | INFO | train_inner | epoch 037:    848 / 1132 loss=3.192, nll_loss=1.617, ppl=3.07, wps=15351.4, ups=4.35, wpb=3527.4, bsz=154.2, num_updates=41600, lr=0.000155043, gnorm=1.088, train_wall=23, wall=0
2024-07-12 20:19:09 | INFO | train_inner | epoch 037:    948 / 1132 loss=3.215, nll_loss=1.644, ppl=3.13, wps=15738.5, ups=4.43, wpb=3556.4, bsz=128.3, num_updates=41700, lr=0.000154857, gnorm=1.115, train_wall=22, wall=0
2024-07-12 20:19:32 | INFO | train_inner | epoch 037:   1048 / 1132 loss=3.222, nll_loss=1.648, ppl=3.13, wps=15585, ups=4.4, wpb=3544.9, bsz=140.7, num_updates=41800, lr=0.000154672, gnorm=1.112, train_wall=23, wall=0
2024-07-12 20:19:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:19:55 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 3.945 | nll_loss 2.361 | ppl 5.14 | wps 44686.8 | wpb 2685.2 | bsz 107.1 | num_updates 41884 | best_loss 11.022
2024-07-12 20:19:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:20:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 37 @ 41884 updates, score 3.945) (writing took 8.973878842778504 seconds)
2024-07-12 20:20:04 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2024-07-12 20:20:04 | INFO | train | epoch 037 | loss 3.18 | nll_loss 1.603 | ppl 3.04 | wps 14149.6 | ups 3.98 | wpb 3556.4 | bsz 141.6 | num_updates 41884 | lr 0.000154517 | gnorm 1.092 | train_wall 256 | wall 0
2024-07-12 20:20:04 | INFO | fairseq.trainer | begin training epoch 38
2024-07-12 20:20:08 | INFO | train_inner | epoch 038:     16 / 1132 loss=3.186, nll_loss=1.613, ppl=3.06, wps=9845.9, ups=2.79, wpb=3535, bsz=143.2, num_updates=41900, lr=0.000154487, gnorm=1.101, train_wall=22, wall=0
2024-07-12 20:20:31 | INFO | train_inner | epoch 038:    116 / 1132 loss=3.112, nll_loss=1.524, ppl=2.88, wps=15737.1, ups=4.42, wpb=3557.7, bsz=149.2, num_updates=42000, lr=0.000154303, gnorm=1.084, train_wall=22, wall=0
2024-07-12 20:20:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:20:35 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 3.956 | nll_loss 2.371 | ppl 5.17 | wps 44702.4 | wpb 2685.2 | bsz 107.1 | num_updates 42000 | best_loss 11.022
2024-07-12 20:20:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:20:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_38_42000.pt (epoch 38 @ 42000 updates, score 3.956) (writing took 6.046678361482918 seconds)
2024-07-12 20:21:04 | INFO | train_inner | epoch 038:    216 / 1132 loss=3.138, nll_loss=1.556, ppl=2.94, wps=10809.3, ups=3.02, wpb=3574.9, bsz=147.8, num_updates=42100, lr=0.00015412, gnorm=1.082, train_wall=23, wall=0
2024-07-12 20:21:26 | INFO | train_inner | epoch 038:    316 / 1132 loss=3.138, nll_loss=1.555, ppl=2.94, wps=15539.9, ups=4.43, wpb=3504.9, bsz=143.5, num_updates=42200, lr=0.000153937, gnorm=1.091, train_wall=22, wall=0
2024-07-12 20:21:49 | INFO | train_inner | epoch 038:    416 / 1132 loss=3.153, nll_loss=1.57, ppl=2.97, wps=15247.9, ups=4.43, wpb=3442.5, bsz=135.6, num_updates=42300, lr=0.000153755, gnorm=1.111, train_wall=22, wall=0
2024-07-12 20:22:12 | INFO | train_inner | epoch 038:    516 / 1132 loss=3.163, nll_loss=1.582, ppl=2.99, wps=15748.5, ups=4.37, wpb=3601.3, bsz=141, num_updates=42400, lr=0.000153574, gnorm=1.082, train_wall=23, wall=0
2024-07-12 20:22:35 | INFO | train_inner | epoch 038:    616 / 1132 loss=3.176, nll_loss=1.6, ppl=3.03, wps=15821.2, ups=4.31, wpb=3667.1, bsz=143.4, num_updates=42500, lr=0.000153393, gnorm=1.072, train_wall=23, wall=0
2024-07-12 20:22:58 | INFO | train_inner | epoch 038:    716 / 1132 loss=3.197, nll_loss=1.621, ppl=3.08, wps=15603.6, ups=4.33, wpb=3600.7, bsz=137, num_updates=42600, lr=0.000153213, gnorm=1.109, train_wall=23, wall=0
2024-07-12 20:23:21 | INFO | train_inner | epoch 038:    816 / 1132 loss=3.157, nll_loss=1.578, ppl=2.99, wps=15793.8, ups=4.37, wpb=3617, bsz=151.7, num_updates=42700, lr=0.000153033, gnorm=1.073, train_wall=23, wall=0
2024-07-12 20:23:43 | INFO | train_inner | epoch 038:    916 / 1132 loss=3.189, nll_loss=1.616, ppl=3.07, wps=15567.4, ups=4.41, wpb=3528, bsz=139.2, num_updates=42800, lr=0.000152854, gnorm=1.117, train_wall=22, wall=0
2024-07-12 20:24:07 | INFO | train_inner | epoch 038:   1016 / 1132 loss=3.198, nll_loss=1.624, ppl=3.08, wps=15279.8, ups=4.3, wpb=3550.7, bsz=137.2, num_updates=42900, lr=0.000152676, gnorm=1.108, train_wall=23, wall=0
2024-07-12 20:24:30 | INFO | train_inner | epoch 038:   1116 / 1132 loss=3.199, nll_loss=1.625, ppl=3.08, wps=14962.1, ups=4.3, wpb=3478.6, bsz=134.7, num_updates=43000, lr=0.000152499, gnorm=1.165, train_wall=23, wall=0
2024-07-12 20:24:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:24:34 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 3.954 | nll_loss 2.367 | ppl 5.16 | wps 44757.9 | wpb 2685.2 | bsz 107.1 | num_updates 43000 | best_loss 11.022
2024-07-12 20:24:34 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:24:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_38_43000.pt (epoch 38 @ 43000 updates, score 3.954) (writing took 16.588153407908976 seconds)
2024-07-12 20:24:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:24:59 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 3.949 | nll_loss 2.371 | ppl 5.17 | wps 44814.5 | wpb 2685.2 | bsz 107.1 | num_updates 43016 | best_loss 11.022
2024-07-12 20:24:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:25:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 38 @ 43016 updates, score 3.949) (writing took 14.721738879568875 seconds)
2024-07-12 20:25:13 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2024-07-12 20:25:13 | INFO | train | epoch 038 | loss 3.166 | nll_loss 1.587 | ppl 3 | wps 13016 | ups 3.66 | wpb 3556.4 | bsz 141.6 | num_updates 43016 | lr 0.00015247 | gnorm 1.099 | train_wall 257 | wall 0
2024-07-12 20:25:13 | INFO | fairseq.trainer | begin training epoch 39
2024-07-12 20:25:33 | INFO | train_inner | epoch 039:     84 / 1132 loss=3.14, nll_loss=1.553, ppl=2.93, wps=5714.1, ups=1.6, wpb=3576.5, bsz=139.8, num_updates=43100, lr=0.000152322, gnorm=1.106, train_wall=22, wall=0
2024-07-12 20:25:55 | INFO | train_inner | epoch 039:    184 / 1132 loss=3.089, nll_loss=1.5, ppl=2.83, wps=15544.5, ups=4.38, wpb=3547.8, bsz=156, num_updates=43200, lr=0.000152145, gnorm=1.063, train_wall=23, wall=0
2024-07-12 20:26:18 | INFO | train_inner | epoch 039:    284 / 1132 loss=3.118, nll_loss=1.531, ppl=2.89, wps=15601.2, ups=4.4, wpb=3542, bsz=140.9, num_updates=43300, lr=0.000151969, gnorm=1.088, train_wall=23, wall=0
2024-07-12 20:26:41 | INFO | train_inner | epoch 039:    384 / 1132 loss=3.122, nll_loss=1.537, ppl=2.9, wps=15659.8, ups=4.4, wpb=3559.4, bsz=147.7, num_updates=43400, lr=0.000151794, gnorm=1.08, train_wall=23, wall=0
2024-07-12 20:27:03 | INFO | train_inner | epoch 039:    484 / 1132 loss=3.142, nll_loss=1.562, ppl=2.95, wps=15858.6, ups=4.43, wpb=3578.5, bsz=142.1, num_updates=43500, lr=0.00015162, gnorm=1.092, train_wall=22, wall=0
2024-07-12 20:27:26 | INFO | train_inner | epoch 039:    584 / 1132 loss=3.136, nll_loss=1.553, ppl=2.93, wps=15630.2, ups=4.36, wpb=3584.6, bsz=144.6, num_updates=43600, lr=0.000151446, gnorm=1.078, train_wall=23, wall=0
2024-07-12 20:27:49 | INFO | train_inner | epoch 039:    684 / 1132 loss=3.156, nll_loss=1.576, ppl=2.98, wps=15596.1, ups=4.38, wpb=3557.3, bsz=140.2, num_updates=43700, lr=0.000151272, gnorm=1.105, train_wall=23, wall=0
2024-07-12 20:28:12 | INFO | train_inner | epoch 039:    784 / 1132 loss=3.171, nll_loss=1.592, ppl=3.01, wps=15483.9, ups=4.38, wpb=3532.8, bsz=136.5, num_updates=43800, lr=0.000151099, gnorm=1.112, train_wall=23, wall=0
2024-07-12 20:28:35 | INFO | train_inner | epoch 039:    884 / 1132 loss=3.185, nll_loss=1.609, ppl=3.05, wps=15388.7, ups=4.35, wpb=3539.7, bsz=136.2, num_updates=43900, lr=0.000150927, gnorm=1.119, train_wall=23, wall=0
2024-07-12 20:28:58 | INFO | train_inner | epoch 039:    984 / 1132 loss=3.188, nll_loss=1.61, ppl=3.05, wps=15450.9, ups=4.37, wpb=3536.7, bsz=136, num_updates=44000, lr=0.000150756, gnorm=1.134, train_wall=23, wall=0
2024-07-12 20:28:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:29:02 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 3.943 | nll_loss 2.359 | ppl 5.13 | wps 44691.8 | wpb 2685.2 | bsz 107.1 | num_updates 44000 | best_loss 11.022
2024-07-12 20:29:02 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:29:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_39_44000.pt (epoch 39 @ 44000 updates, score 3.943) (writing took 8.110558480024338 seconds)
2024-07-12 20:29:33 | INFO | train_inner | epoch 039:   1084 / 1132 loss=3.202, nll_loss=1.627, ppl=3.09, wps=9998.2, ups=2.83, wpb=3531.6, bsz=136.2, num_updates=44100, lr=0.000150585, gnorm=1.134, train_wall=23, wall=0
2024-07-12 20:29:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:29:48 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 3.937 | nll_loss 2.354 | ppl 5.11 | wps 44956.3 | wpb 2685.2 | bsz 107.1 | num_updates 44148 | best_loss 11.022
2024-07-12 20:29:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:29:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 39 @ 44148 updates, score 3.937) (writing took 9.482168096117675 seconds)
2024-07-12 20:29:58 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2024-07-12 20:29:58 | INFO | train | epoch 039 | loss 3.15 | nll_loss 1.569 | ppl 2.97 | wps 14155 | ups 3.98 | wpb 3556.4 | bsz 141.6 | num_updates 44148 | lr 0.000150503 | gnorm 1.101 | train_wall 256 | wall 0
2024-07-12 20:29:58 | INFO | fairseq.trainer | begin training epoch 40
2024-07-12 20:30:10 | INFO | train_inner | epoch 040:     52 / 1132 loss=3.133, nll_loss=1.549, ppl=2.93, wps=9687.8, ups=2.68, wpb=3609.2, bsz=143.5, num_updates=44200, lr=0.000150414, gnorm=1.081, train_wall=23, wall=0
2024-07-12 20:30:34 | INFO | train_inner | epoch 040:    152 / 1132 loss=3.101, nll_loss=1.509, ppl=2.85, wps=15275, ups=4.31, wpb=3544.4, bsz=128.6, num_updates=44300, lr=0.000150244, gnorm=1.096, train_wall=23, wall=0
2024-07-12 20:30:56 | INFO | train_inner | epoch 040:    252 / 1132 loss=3.125, nll_loss=1.539, ppl=2.91, wps=15991.9, ups=4.39, wpb=3645.3, bsz=133.2, num_updates=44400, lr=0.000150075, gnorm=1.08, train_wall=23, wall=0
2024-07-12 20:31:20 | INFO | train_inner | epoch 040:    352 / 1132 loss=3.119, nll_loss=1.53, ppl=2.89, wps=14756.7, ups=4.27, wpb=3452.4, bsz=133.6, num_updates=44500, lr=0.000149906, gnorm=1.129, train_wall=23, wall=0
2024-07-12 20:31:43 | INFO | train_inner | epoch 040:    452 / 1132 loss=3.149, nll_loss=1.566, ppl=2.96, wps=15407.9, ups=4.29, wpb=3592.8, bsz=135.7, num_updates=44600, lr=0.000149738, gnorm=1.13, train_wall=23, wall=0
2024-07-12 20:32:06 | INFO | train_inner | epoch 040:    552 / 1132 loss=3.119, nll_loss=1.533, ppl=2.89, wps=15519.9, ups=4.43, wpb=3502.3, bsz=148.6, num_updates=44700, lr=0.000149571, gnorm=1.103, train_wall=22, wall=0
2024-07-12 20:32:28 | INFO | train_inner | epoch 040:    652 / 1132 loss=3.128, nll_loss=1.544, ppl=2.92, wps=15497.7, ups=4.41, wpb=3514.3, bsz=148.1, num_updates=44800, lr=0.000149404, gnorm=1.118, train_wall=23, wall=0
2024-07-12 20:32:52 | INFO | train_inner | epoch 040:    752 / 1132 loss=3.144, nll_loss=1.564, ppl=2.96, wps=15391.6, ups=4.22, wpb=3650.2, bsz=147.3, num_updates=44900, lr=0.000149237, gnorm=1.082, train_wall=24, wall=0
2024-07-12 20:33:15 | INFO | train_inner | epoch 040:    852 / 1132 loss=3.165, nll_loss=1.586, ppl=3, wps=15485.7, ups=4.43, wpb=3495, bsz=132.6, num_updates=45000, lr=0.000149071, gnorm=1.159, train_wall=22, wall=0
2024-07-12 20:33:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:33:19 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 3.952 | nll_loss 2.371 | ppl 5.17 | wps 44939 | wpb 2685.2 | bsz 107.1 | num_updates 45000 | best_loss 11.022
2024-07-12 20:33:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:33:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_40_45000.pt (epoch 40 @ 45000 updates, score 3.952) (writing took 18.80909758526832 seconds)
2024-07-12 20:34:01 | INFO | train_inner | epoch 040:    952 / 1132 loss=3.156, nll_loss=1.577, ppl=2.98, wps=7794.7, ups=2.18, wpb=3578.9, bsz=146.4, num_updates=45100, lr=0.000148906, gnorm=1.092, train_wall=23, wall=0
2024-07-12 20:34:23 | INFO | train_inner | epoch 040:   1052 / 1132 loss=3.132, nll_loss=1.551, ppl=2.93, wps=15675.2, ups=4.42, wpb=3550.3, bsz=161.2, num_updates=45200, lr=0.000148741, gnorm=1.088, train_wall=22, wall=0
2024-07-12 20:34:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:34:46 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 3.951 | nll_loss 2.364 | ppl 5.15 | wps 44951.2 | wpb 2685.2 | bsz 107.1 | num_updates 45280 | best_loss 11.022
2024-07-12 20:34:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:34:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 40 @ 45280 updates, score 3.951) (writing took 5.411045338958502 seconds)
2024-07-12 20:34:51 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2024-07-12 20:34:51 | INFO | train | epoch 040 | loss 3.134 | nll_loss 1.55 | ppl 2.93 | wps 13734.5 | ups 3.86 | wpb 3556.4 | bsz 141.6 | num_updates 45280 | lr 0.00014861 | gnorm 1.106 | train_wall 258 | wall 0
2024-07-12 20:34:51 | INFO | fairseq.trainer | begin training epoch 41
2024-07-12 20:34:56 | INFO | train_inner | epoch 041:     20 / 1132 loss=3.15, nll_loss=1.569, ppl=2.97, wps=10977.6, ups=3.09, wpb=3556.3, bsz=137.5, num_updates=45300, lr=0.000148577, gnorm=1.114, train_wall=22, wall=0
2024-07-12 20:35:19 | INFO | train_inner | epoch 041:    120 / 1132 loss=3.057, nll_loss=1.462, ppl=2.76, wps=15755.1, ups=4.35, wpb=3618.8, bsz=155.4, num_updates=45400, lr=0.000148413, gnorm=1.045, train_wall=23, wall=0
2024-07-12 20:35:42 | INFO | train_inner | epoch 041:    220 / 1132 loss=3.093, nll_loss=1.505, ppl=2.84, wps=15958.6, ups=4.37, wpb=3649.8, bsz=148.6, num_updates=45500, lr=0.00014825, gnorm=1.058, train_wall=23, wall=0
2024-07-12 20:36:05 | INFO | train_inner | epoch 041:    320 / 1132 loss=3.122, nll_loss=1.536, ppl=2.9, wps=15762, ups=4.34, wpb=3630.1, bsz=145.3, num_updates=45600, lr=0.000148087, gnorm=1.109, train_wall=23, wall=0
2024-07-12 20:36:27 | INFO | train_inner | epoch 041:    420 / 1132 loss=3.101, nll_loss=1.512, ppl=2.85, wps=15356.5, ups=4.44, wpb=3462.1, bsz=143.5, num_updates=45700, lr=0.000147925, gnorm=1.114, train_wall=22, wall=0
2024-07-12 20:36:50 | INFO | train_inner | epoch 041:    520 / 1132 loss=3.13, nll_loss=1.545, ppl=2.92, wps=15886.8, ups=4.41, wpb=3605, bsz=134.2, num_updates=45800, lr=0.000147764, gnorm=1.107, train_wall=23, wall=0
2024-07-12 20:37:12 | INFO | train_inner | epoch 041:    620 / 1132 loss=3.122, nll_loss=1.537, ppl=2.9, wps=15895.9, ups=4.42, wpb=3600.3, bsz=146.6, num_updates=45900, lr=0.000147602, gnorm=1.106, train_wall=22, wall=0
2024-07-12 20:37:35 | INFO | train_inner | epoch 041:    720 / 1132 loss=3.101, nll_loss=1.513, ppl=2.85, wps=15524.4, ups=4.39, wpb=3537.8, bsz=153.2, num_updates=46000, lr=0.000147442, gnorm=1.092, train_wall=23, wall=0
2024-07-12 20:37:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:37:39 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 3.959 | nll_loss 2.373 | ppl 5.18 | wps 45044.7 | wpb 2685.2 | bsz 107.1 | num_updates 46000 | best_loss 11.022
2024-07-12 20:37:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:37:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_41_46000.pt (epoch 41 @ 46000 updates, score 3.959) (writing took 5.755372245796025 seconds)
2024-07-12 20:38:08 | INFO | train_inner | epoch 041:    820 / 1132 loss=3.132, nll_loss=1.547, ppl=2.92, wps=10628.9, ups=3.08, wpb=3447.9, bsz=139.4, num_updates=46100, lr=0.000147282, gnorm=1.164, train_wall=22, wall=0
2024-07-12 20:38:31 | INFO | train_inner | epoch 041:    920 / 1132 loss=3.155, nll_loss=1.574, ppl=2.98, wps=15188.9, ups=4.38, wpb=3471.3, bsz=125, num_updates=46200, lr=0.000147122, gnorm=1.15, train_wall=23, wall=0
2024-07-12 20:38:53 | INFO | train_inner | epoch 041:   1020 / 1132 loss=3.167, nll_loss=1.587, ppl=3, wps=15799.4, ups=4.48, wpb=3527.6, bsz=127.2, num_updates=46300, lr=0.000146964, gnorm=1.142, train_wall=22, wall=0
2024-07-12 20:39:16 | INFO | train_inner | epoch 041:   1120 / 1132 loss=3.155, nll_loss=1.575, ppl=2.98, wps=15767.5, ups=4.37, wpb=3607.4, bsz=144.3, num_updates=46400, lr=0.000146805, gnorm=1.097, train_wall=23, wall=0
2024-07-12 20:39:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:39:23 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 3.957 | nll_loss 2.374 | ppl 5.18 | wps 44747.4 | wpb 2685.2 | bsz 107.1 | num_updates 46412 | best_loss 11.022
2024-07-12 20:39:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:39:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 41 @ 46412 updates, score 3.957) (writing took 4.774669417180121 seconds)
2024-07-12 20:39:27 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2024-07-12 20:39:27 | INFO | train | epoch 041 | loss 3.121 | nll_loss 1.535 | ppl 2.9 | wps 14562.1 | ups 4.09 | wpb 3556.4 | bsz 141.6 | num_updates 46412 | lr 0.000146786 | gnorm 1.109 | train_wall 256 | wall 0
2024-07-12 20:39:27 | INFO | fairseq.trainer | begin training epoch 42
2024-07-12 20:39:48 | INFO | train_inner | epoch 042:     88 / 1132 loss=3.064, nll_loss=1.467, ppl=2.76, wps=10915.8, ups=3.14, wpb=3481.2, bsz=136.4, num_updates=46500, lr=0.000146647, gnorm=1.107, train_wall=23, wall=0
2024-07-12 20:40:10 | INFO | train_inner | epoch 042:    188 / 1132 loss=3.088, nll_loss=1.495, ppl=2.82, wps=15658.8, ups=4.39, wpb=3571, bsz=135.4, num_updates=46600, lr=0.00014649, gnorm=1.098, train_wall=23, wall=0
2024-07-12 20:40:33 | INFO | train_inner | epoch 042:    288 / 1132 loss=3.076, nll_loss=1.483, ppl=2.8, wps=15662.7, ups=4.37, wpb=3581.6, bsz=148.5, num_updates=46700, lr=0.000146333, gnorm=1.098, train_wall=23, wall=0
2024-07-12 20:40:56 | INFO | train_inner | epoch 042:    388 / 1132 loss=3.106, nll_loss=1.516, ppl=2.86, wps=15518.2, ups=4.42, wpb=3513.2, bsz=129.1, num_updates=46800, lr=0.000146176, gnorm=1.124, train_wall=22, wall=0
2024-07-12 20:41:19 | INFO | train_inner | epoch 042:    488 / 1132 loss=3.118, nll_loss=1.528, ppl=2.88, wps=15379.2, ups=4.38, wpb=3507.9, bsz=132.2, num_updates=46900, lr=0.00014602, gnorm=1.147, train_wall=23, wall=0
2024-07-12 20:41:42 | INFO | train_inner | epoch 042:    588 / 1132 loss=3.118, nll_loss=1.529, ppl=2.89, wps=15538.3, ups=4.38, wpb=3545.7, bsz=134.3, num_updates=47000, lr=0.000145865, gnorm=1.124, train_wall=23, wall=0
2024-07-12 20:41:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:41:46 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 3.967 | nll_loss 2.381 | ppl 5.21 | wps 44844.8 | wpb 2685.2 | bsz 107.1 | num_updates 47000 | best_loss 11.022
2024-07-12 20:41:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:41:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_42_47000.pt (epoch 42 @ 47000 updates, score 3.967) (writing took 5.779458274133503 seconds)
2024-07-12 20:42:14 | INFO | train_inner | epoch 042:    688 / 1132 loss=3.11, nll_loss=1.523, ppl=2.87, wps=10690.8, ups=3.05, wpb=3505, bsz=137.4, num_updates=47100, lr=0.00014571, gnorm=1.126, train_wall=23, wall=0
2024-07-12 20:42:37 | INFO | train_inner | epoch 042:    788 / 1132 loss=3.108, nll_loss=1.521, ppl=2.87, wps=15736.3, ups=4.44, wpb=3546.7, bsz=152.3, num_updates=47200, lr=0.000145556, gnorm=1.106, train_wall=22, wall=0
2024-07-12 20:43:00 | INFO | train_inner | epoch 042:    888 / 1132 loss=3.122, nll_loss=1.539, ppl=2.91, wps=15798.1, ups=4.33, wpb=3650.2, bsz=154.4, num_updates=47300, lr=0.000145402, gnorm=1.09, train_wall=23, wall=0
2024-07-12 20:43:23 | INFO | train_inner | epoch 042:    988 / 1132 loss=3.119, nll_loss=1.535, ppl=2.9, wps=15728.8, ups=4.39, wpb=3580.6, bsz=153.1, num_updates=47400, lr=0.000145248, gnorm=1.12, train_wall=23, wall=0
2024-07-12 20:43:46 | INFO | train_inner | epoch 042:   1088 / 1132 loss=3.149, nll_loss=1.569, ppl=2.97, wps=15671.4, ups=4.4, wpb=3559.8, bsz=135.2, num_updates=47500, lr=0.000145095, gnorm=1.15, train_wall=23, wall=0
2024-07-12 20:43:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:44:00 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 3.937 | nll_loss 2.357 | ppl 5.12 | wps 44918.4 | wpb 2685.2 | bsz 107.1 | num_updates 47544 | best_loss 11.022
2024-07-12 20:44:00 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:44:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 42 @ 47544 updates, score 3.937) (writing took 4.4840098628774285 seconds)
2024-07-12 20:44:04 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2024-07-12 20:44:04 | INFO | train | epoch 042 | loss 3.107 | nll_loss 1.519 | ppl 2.87 | wps 14534.6 | ups 4.09 | wpb 3556.4 | bsz 141.6 | num_updates 47544 | lr 0.000145028 | gnorm 1.114 | train_wall 256 | wall 0
2024-07-12 20:44:04 | INFO | fairseq.trainer | begin training epoch 43
2024-07-12 20:44:18 | INFO | train_inner | epoch 043:     56 / 1132 loss=3.085, nll_loss=1.496, ppl=2.82, wps=11488.4, ups=3.12, wpb=3677.9, bsz=150.8, num_updates=47600, lr=0.000144943, gnorm=1.07, train_wall=23, wall=0
2024-07-12 20:44:41 | INFO | train_inner | epoch 043:    156 / 1132 loss=3.03, nll_loss=1.432, ppl=2.7, wps=15458.8, ups=4.3, wpb=3592.9, bsz=167.8, num_updates=47700, lr=0.000144791, gnorm=1.068, train_wall=23, wall=0
2024-07-12 20:45:04 | INFO | train_inner | epoch 043:    256 / 1132 loss=3.076, nll_loss=1.483, ppl=2.79, wps=15078.5, ups=4.22, wpb=3570.7, bsz=147.8, num_updates=47800, lr=0.000144639, gnorm=1.112, train_wall=24, wall=0
2024-07-12 20:45:27 | INFO | train_inner | epoch 043:    356 / 1132 loss=3.068, nll_loss=1.473, ppl=2.78, wps=15432.9, ups=4.45, wpb=3469, bsz=135.7, num_updates=47900, lr=0.000144488, gnorm=1.145, train_wall=22, wall=0
2024-07-12 20:45:50 | INFO | train_inner | epoch 043:    456 / 1132 loss=3.114, nll_loss=1.525, ppl=2.88, wps=15740.1, ups=4.42, wpb=3562.9, bsz=124.3, num_updates=48000, lr=0.000144338, gnorm=1.141, train_wall=22, wall=0
2024-07-12 20:45:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:45:54 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 3.969 | nll_loss 2.387 | ppl 5.23 | wps 44851.7 | wpb 2685.2 | bsz 107.1 | num_updates 48000 | best_loss 11.022
2024-07-12 20:45:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:46:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_43_48000.pt (epoch 43 @ 48000 updates, score 3.969) (writing took 5.995339467190206 seconds)
2024-07-12 20:46:22 | INFO | train_inner | epoch 043:    556 / 1132 loss=3.105, nll_loss=1.516, ppl=2.86, wps=11071.8, ups=3.07, wpb=3605.1, bsz=132.3, num_updates=48100, lr=0.000144187, gnorm=1.11, train_wall=22, wall=0
2024-07-12 20:46:46 | INFO | train_inner | epoch 043:    656 / 1132 loss=3.097, nll_loss=1.508, ppl=2.84, wps=14971.6, ups=4.14, wpb=3614.2, bsz=147.6, num_updates=48200, lr=0.000144038, gnorm=1.106, train_wall=24, wall=0
2024-07-12 20:47:09 | INFO | train_inner | epoch 043:    756 / 1132 loss=3.1, nll_loss=1.514, ppl=2.86, wps=15500.8, ups=4.45, wpb=3484.6, bsz=141.4, num_updates=48300, lr=0.000143889, gnorm=1.161, train_wall=22, wall=0
2024-07-12 20:47:31 | INFO | train_inner | epoch 043:    856 / 1132 loss=3.116, nll_loss=1.527, ppl=2.88, wps=15608, ups=4.43, wpb=3521.2, bsz=129.6, num_updates=48400, lr=0.00014374, gnorm=1.148, train_wall=22, wall=0
2024-07-12 20:47:54 | INFO | train_inner | epoch 043:    956 / 1132 loss=3.107, nll_loss=1.52, ppl=2.87, wps=15435, ups=4.32, wpb=3573.6, bsz=147.4, num_updates=48500, lr=0.000143592, gnorm=1.111, train_wall=23, wall=0
2024-07-12 20:48:17 | INFO | train_inner | epoch 043:   1056 / 1132 loss=3.138, nll_loss=1.553, ppl=2.93, wps=15154.8, ups=4.37, wpb=3467.5, bsz=130.2, num_updates=48600, lr=0.000143444, gnorm=1.174, train_wall=23, wall=0
2024-07-12 20:48:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:48:39 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 3.975 | nll_loss 2.394 | ppl 5.26 | wps 45050 | wpb 2685.2 | bsz 107.1 | num_updates 48676 | best_loss 11.022
2024-07-12 20:48:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:48:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 43 @ 48676 updates, score 3.975) (writing took 5.3004374876618385 seconds)
2024-07-12 20:48:44 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2024-07-12 20:48:44 | INFO | train | epoch 043 | loss 3.095 | nll_loss 1.505 | ppl 2.84 | wps 14395.9 | ups 4.05 | wpb 3556.4 | bsz 141.6 | num_updates 48676 | lr 0.000143332 | gnorm 1.124 | train_wall 258 | wall 0
2024-07-12 20:48:44 | INFO | fairseq.trainer | begin training epoch 44
2024-07-12 20:48:50 | INFO | train_inner | epoch 044:     24 / 1132 loss=3.1, nll_loss=1.512, ppl=2.85, wps=10963.8, ups=3.09, wpb=3543, bsz=141.8, num_updates=48700, lr=0.000143296, gnorm=1.127, train_wall=22, wall=0
2024-07-12 20:49:12 | INFO | train_inner | epoch 044:    124 / 1132 loss=3.048, nll_loss=1.447, ppl=2.73, wps=15731.8, ups=4.43, wpb=3547.8, bsz=141.9, num_updates=48800, lr=0.00014315, gnorm=1.113, train_wall=22, wall=0
2024-07-12 20:49:35 | INFO | train_inner | epoch 044:    224 / 1132 loss=3.054, nll_loss=1.457, ppl=2.75, wps=15473.5, ups=4.4, wpb=3519.9, bsz=137.5, num_updates=48900, lr=0.000143003, gnorm=1.115, train_wall=23, wall=0
2024-07-12 20:49:58 | INFO | train_inner | epoch 044:    324 / 1132 loss=3.039, nll_loss=1.445, ppl=2.72, wps=15845, ups=4.44, wpb=3572.5, bsz=156.6, num_updates=49000, lr=0.000142857, gnorm=1.099, train_wall=22, wall=0
2024-07-12 20:49:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:50:02 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 3.977 | nll_loss 2.395 | ppl 5.26 | wps 45033.7 | wpb 2685.2 | bsz 107.1 | num_updates 49000 | best_loss 11.022
2024-07-12 20:50:02 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:50:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_44_49000.pt (epoch 44 @ 49000 updates, score 3.977) (writing took 6.7919953521341085 seconds)
2024-07-12 20:50:31 | INFO | train_inner | epoch 044:    424 / 1132 loss=3.044, nll_loss=1.448, ppl=2.73, wps=10383.1, ups=2.96, wpb=3508.1, bsz=164.4, num_updates=49100, lr=0.000142712, gnorm=1.119, train_wall=23, wall=0
2024-07-12 20:50:54 | INFO | train_inner | epoch 044:    524 / 1132 loss=3.085, nll_loss=1.493, ppl=2.81, wps=15623.8, ups=4.37, wpb=3571.8, bsz=134.7, num_updates=49200, lr=0.000142566, gnorm=1.118, train_wall=23, wall=0
2024-07-12 20:51:17 | INFO | train_inner | epoch 044:    624 / 1132 loss=3.105, nll_loss=1.517, ppl=2.86, wps=15890.6, ups=4.39, wpb=3620.5, bsz=143.9, num_updates=49300, lr=0.000142422, gnorm=1.115, train_wall=23, wall=0
2024-07-12 20:51:40 | INFO | train_inner | epoch 044:    724 / 1132 loss=3.09, nll_loss=1.499, ppl=2.83, wps=15853.8, ups=4.38, wpb=3623.5, bsz=140.6, num_updates=49400, lr=0.000142278, gnorm=1.102, train_wall=23, wall=0
2024-07-12 20:52:03 | INFO | train_inner | epoch 044:    824 / 1132 loss=3.099, nll_loss=1.509, ppl=2.85, wps=15558.7, ups=4.4, wpb=3539.3, bsz=140.6, num_updates=49500, lr=0.000142134, gnorm=1.145, train_wall=23, wall=0
2024-07-12 20:52:25 | INFO | train_inner | epoch 044:    924 / 1132 loss=3.096, nll_loss=1.506, ppl=2.84, wps=15590.6, ups=4.43, wpb=3521.3, bsz=137.4, num_updates=49600, lr=0.00014199, gnorm=1.145, train_wall=22, wall=0
2024-07-12 20:52:48 | INFO | train_inner | epoch 044:   1024 / 1132 loss=3.122, nll_loss=1.534, ppl=2.9, wps=15476.6, ups=4.37, wpb=3545.1, bsz=135.3, num_updates=49700, lr=0.000141848, gnorm=1.161, train_wall=23, wall=0
2024-07-12 20:53:11 | INFO | train_inner | epoch 044:   1124 / 1132 loss=3.124, nll_loss=1.537, ppl=2.9, wps=15823.8, ups=4.4, wpb=3593.3, bsz=130.7, num_updates=49800, lr=0.000141705, gnorm=1.141, train_wall=23, wall=0
2024-07-12 20:53:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:53:17 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 3.954 | nll_loss 2.378 | ppl 5.2 | wps 45056.6 | wpb 2685.2 | bsz 107.1 | num_updates 49808 | best_loss 11.022
2024-07-12 20:53:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:53:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 44 @ 49808 updates, score 3.954) (writing took 5.4622618881985545 seconds)
2024-07-12 20:53:22 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2024-07-12 20:53:22 | INFO | train | epoch 044 | loss 3.081 | nll_loss 1.489 | ppl 2.81 | wps 14471.2 | ups 4.07 | wpb 3556.4 | bsz 141.6 | num_updates 49808 | lr 0.000141694 | gnorm 1.126 | train_wall 256 | wall 0
2024-07-12 20:53:22 | INFO | fairseq.trainer | begin training epoch 45
2024-07-12 20:53:44 | INFO | train_inner | epoch 045:     92 / 1132 loss=3.027, nll_loss=1.425, ppl=2.69, wps=10813.3, ups=3.03, wpb=3565.7, bsz=147.9, num_updates=49900, lr=0.000141563, gnorm=1.101, train_wall=23, wall=0
2024-07-12 20:54:07 | INFO | train_inner | epoch 045:    192 / 1132 loss=3.007, nll_loss=1.404, ppl=2.65, wps=15172.5, ups=4.32, wpb=3510.9, bsz=162.6, num_updates=50000, lr=0.000141421, gnorm=1.096, train_wall=23, wall=0
2024-07-12 20:54:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:54:11 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 3.975 | nll_loss 2.389 | ppl 5.24 | wps 45045.2 | wpb 2685.2 | bsz 107.1 | num_updates 50000 | best_loss 11.022
2024-07-12 20:54:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:54:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_45_50000.pt (epoch 45 @ 50000 updates, score 3.975) (writing took 6.095015839673579 seconds)
2024-07-12 20:54:40 | INFO | train_inner | epoch 045:    292 / 1132 loss=3.043, nll_loss=1.445, ppl=2.72, wps=10864.3, ups=3.01, wpb=3605.4, bsz=151.2, num_updates=50100, lr=0.00014128, gnorm=1.089, train_wall=23, wall=0
2024-07-12 20:55:03 | INFO | train_inner | epoch 045:    392 / 1132 loss=3.066, nll_loss=1.471, ppl=2.77, wps=15772.1, ups=4.43, wpb=3558.4, bsz=124.5, num_updates=50200, lr=0.000141139, gnorm=1.13, train_wall=22, wall=0
2024-07-12 20:55:26 | INFO | train_inner | epoch 045:    492 / 1132 loss=3.064, nll_loss=1.471, ppl=2.77, wps=15899.2, ups=4.35, wpb=3654.8, bsz=154.2, num_updates=50300, lr=0.000140999, gnorm=1.091, train_wall=23, wall=0
2024-07-12 20:55:49 | INFO | train_inner | epoch 045:    592 / 1132 loss=3.063, nll_loss=1.469, ppl=2.77, wps=15649.1, ups=4.36, wpb=3585.7, bsz=153.9, num_updates=50400, lr=0.000140859, gnorm=1.129, train_wall=23, wall=0
2024-07-12 20:56:10 | INFO | train_inner | epoch 045:    692 / 1132 loss=3.068, nll_loss=1.475, ppl=2.78, wps=16082.4, ups=4.57, wpb=3522.4, bsz=139.3, num_updates=50500, lr=0.00014072, gnorm=1.134, train_wall=22, wall=0
2024-07-12 20:56:32 | INFO | train_inner | epoch 045:    792 / 1132 loss=3.084, nll_loss=1.494, ppl=2.82, wps=16137.3, ups=4.58, wpb=3524.1, bsz=139.9, num_updates=50600, lr=0.00014058, gnorm=1.161, train_wall=22, wall=0
2024-07-12 20:56:55 | INFO | train_inner | epoch 045:    892 / 1132 loss=3.109, nll_loss=1.521, ppl=2.87, wps=15860.4, ups=4.42, wpb=3584.5, bsz=132.2, num_updates=50700, lr=0.000140442, gnorm=1.145, train_wall=22, wall=0
2024-07-12 20:57:18 | INFO | train_inner | epoch 045:    992 / 1132 loss=3.115, nll_loss=1.527, ppl=2.88, wps=15046.1, ups=4.26, wpb=3534, bsz=131.3, num_updates=50800, lr=0.000140303, gnorm=1.161, train_wall=23, wall=0
2024-07-12 20:57:41 | INFO | train_inner | epoch 045:   1092 / 1132 loss=3.102, nll_loss=1.513, ppl=2.85, wps=15488.8, ups=4.44, wpb=3487.8, bsz=127.4, num_updates=50900, lr=0.000140165, gnorm=1.17, train_wall=22, wall=0
2024-07-12 20:57:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:57:55 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 3.964 | nll_loss 2.383 | ppl 5.22 | wps 44855.7 | wpb 2685.2 | bsz 107.1 | num_updates 50940 | best_loss 11.022
2024-07-12 20:57:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:58:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 45 @ 50940 updates, score 3.964) (writing took 5.111412914469838 seconds)
2024-07-12 20:58:00 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2024-07-12 20:58:00 | INFO | train | epoch 045 | loss 3.07 | nll_loss 1.476 | ppl 2.78 | wps 14509.2 | ups 4.08 | wpb 3556.4 | bsz 141.6 | num_updates 50940 | lr 0.00014011 | gnorm 1.13 | train_wall 256 | wall 0
2024-07-12 20:58:00 | INFO | fairseq.trainer | begin training epoch 46
2024-07-12 20:58:13 | INFO | train_inner | epoch 046:     60 / 1132 loss=3.058, nll_loss=1.462, ppl=2.76, wps=10849.1, ups=3.08, wpb=3520.5, bsz=127, num_updates=51000, lr=0.000140028, gnorm=1.141, train_wall=23, wall=0
2024-07-12 20:58:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 20:58:18 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 3.982 | nll_loss 2.397 | ppl 5.27 | wps 44873 | wpb 2685.2 | bsz 107.1 | num_updates 51000 | best_loss 11.022
2024-07-12 20:58:18 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 20:58:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_46_51000.pt (epoch 46 @ 51000 updates, score 3.982) (writing took 6.17712565138936 seconds)
2024-07-12 20:58:46 | INFO | train_inner | epoch 046:    160 / 1132 loss=3.018, nll_loss=1.415, ppl=2.67, wps=10911.3, ups=3.04, wpb=3594.2, bsz=151, num_updates=51100, lr=0.000139891, gnorm=1.112, train_wall=22, wall=0
2024-07-12 20:59:09 | INFO | train_inner | epoch 046:    260 / 1132 loss=3.039, nll_loss=1.441, ppl=2.71, wps=15803.2, ups=4.37, wpb=3614.3, bsz=139.6, num_updates=51200, lr=0.000139754, gnorm=1.13, train_wall=23, wall=0
2024-07-12 20:59:32 | INFO | train_inner | epoch 046:    360 / 1132 loss=3.051, nll_loss=1.452, ppl=2.74, wps=15674.8, ups=4.45, wpb=3523.8, bsz=129.8, num_updates=51300, lr=0.000139618, gnorm=1.164, train_wall=22, wall=0
2024-07-12 20:59:54 | INFO | train_inner | epoch 046:    460 / 1132 loss=3.049, nll_loss=1.453, ppl=2.74, wps=15827.4, ups=4.43, wpb=3573.2, bsz=135.1, num_updates=51400, lr=0.000139482, gnorm=1.128, train_wall=22, wall=0
2024-07-12 21:00:17 | INFO | train_inner | epoch 046:    560 / 1132 loss=3.057, nll_loss=1.459, ppl=2.75, wps=15802.2, ups=4.42, wpb=3578.1, bsz=139.5, num_updates=51500, lr=0.000139347, gnorm=1.122, train_wall=22, wall=0
2024-07-12 21:00:41 | INFO | train_inner | epoch 046:    660 / 1132 loss=3.066, nll_loss=1.472, ppl=2.77, wps=14939.6, ups=4.14, wpb=3604.4, bsz=153.2, num_updates=51600, lr=0.000139212, gnorm=1.128, train_wall=24, wall=0
2024-07-12 21:01:04 | INFO | train_inner | epoch 046:    760 / 1132 loss=3.066, nll_loss=1.473, ppl=2.78, wps=15400.4, ups=4.3, wpb=3577.4, bsz=146.8, num_updates=51700, lr=0.000139077, gnorm=1.112, train_wall=23, wall=0
2024-07-12 21:01:27 | INFO | train_inner | epoch 046:    860 / 1132 loss=3.087, nll_loss=1.493, ppl=2.82, wps=15524.3, ups=4.36, wpb=3561.5, bsz=140, num_updates=51800, lr=0.000138943, gnorm=1.16, train_wall=23, wall=0
2024-07-12 21:01:50 | INFO | train_inner | epoch 046:    960 / 1132 loss=3.047, nll_loss=1.455, ppl=2.74, wps=15658.8, ups=4.41, wpb=3553.3, bsz=168.6, num_updates=51900, lr=0.000138809, gnorm=1.117, train_wall=23, wall=0
2024-07-12 21:02:12 | INFO | train_inner | epoch 046:   1060 / 1132 loss=3.085, nll_loss=1.493, ppl=2.81, wps=15401.1, ups=4.43, wpb=3476.4, bsz=127.9, num_updates=52000, lr=0.000138675, gnorm=1.156, train_wall=22, wall=0
2024-07-12 21:02:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:02:17 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 3.959 | nll_loss 2.375 | ppl 5.19 | wps 44903.4 | wpb 2685.2 | bsz 107.1 | num_updates 52000 | best_loss 11.022
2024-07-12 21:02:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:02:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_46_52000.pt (epoch 46 @ 52000 updates, score 3.959) (writing took 5.54716123547405 seconds)
2024-07-12 21:02:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:02:43 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 3.969 | nll_loss 2.38 | ppl 5.21 | wps 45112.5 | wpb 2685.2 | bsz 107.1 | num_updates 52072 | best_loss 11.022
2024-07-12 21:02:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:02:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 46 @ 52072 updates, score 3.969) (writing took 9.414225379005075 seconds)
2024-07-12 21:02:52 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2024-07-12 21:02:52 | INFO | train | epoch 046 | loss 3.057 | nll_loss 1.461 | ppl 2.75 | wps 13767.1 | ups 3.87 | wpb 3556.4 | bsz 141.6 | num_updates 52072 | lr 0.000138579 | gnorm 1.135 | train_wall 257 | wall 0
2024-07-12 21:02:52 | INFO | fairseq.trainer | begin training epoch 47
2024-07-12 21:02:59 | INFO | train_inner | epoch 047:     28 / 1132 loss=3.063, nll_loss=1.466, ppl=2.76, wps=7488.1, ups=2.16, wpb=3465.9, bsz=138.6, num_updates=52100, lr=0.000138542, gnorm=1.168, train_wall=23, wall=0
2024-07-12 21:03:22 | INFO | train_inner | epoch 047:    128 / 1132 loss=2.996, nll_loss=1.391, ppl=2.62, wps=15564, ups=4.38, wpb=3553.1, bsz=138.5, num_updates=52200, lr=0.000138409, gnorm=1.118, train_wall=23, wall=0
2024-07-12 21:03:44 | INFO | train_inner | epoch 047:    228 / 1132 loss=3.029, nll_loss=1.427, ppl=2.69, wps=15494.4, ups=4.4, wpb=3523.9, bsz=132, num_updates=52300, lr=0.000138277, gnorm=1.162, train_wall=23, wall=0
2024-07-12 21:04:07 | INFO | train_inner | epoch 047:    328 / 1132 loss=3.026, nll_loss=1.424, ppl=2.68, wps=15625.5, ups=4.38, wpb=3570.2, bsz=143.7, num_updates=52400, lr=0.000138145, gnorm=1.12, train_wall=23, wall=0
2024-07-12 21:04:30 | INFO | train_inner | epoch 047:    428 / 1132 loss=3.015, nll_loss=1.416, ppl=2.67, wps=15657.9, ups=4.43, wpb=3535.4, bsz=154.5, num_updates=52500, lr=0.000138013, gnorm=1.145, train_wall=22, wall=0
2024-07-12 21:04:53 | INFO | train_inner | epoch 047:    528 / 1132 loss=3.044, nll_loss=1.445, ppl=2.72, wps=15359.5, ups=4.36, wpb=3520.3, bsz=138.5, num_updates=52600, lr=0.000137882, gnorm=1.162, train_wall=23, wall=0
2024-07-12 21:05:16 | INFO | train_inner | epoch 047:    628 / 1132 loss=3.073, nll_loss=1.478, ppl=2.79, wps=15499.2, ups=4.34, wpb=3573.9, bsz=131.8, num_updates=52700, lr=0.000137751, gnorm=1.146, train_wall=23, wall=0
2024-07-12 21:05:38 | INFO | train_inner | epoch 047:    728 / 1132 loss=3.047, nll_loss=1.451, ppl=2.73, wps=15968.8, ups=4.41, wpb=3624.9, bsz=152.7, num_updates=52800, lr=0.00013762, gnorm=1.127, train_wall=23, wall=0
2024-07-12 21:06:01 | INFO | train_inner | epoch 047:    828 / 1132 loss=3.068, nll_loss=1.473, ppl=2.78, wps=15553.7, ups=4.36, wpb=3567, bsz=141, num_updates=52900, lr=0.00013749, gnorm=1.149, train_wall=23, wall=0
2024-07-12 21:06:24 | INFO | train_inner | epoch 047:    928 / 1132 loss=3.06, nll_loss=1.465, ppl=2.76, wps=15626.5, ups=4.36, wpb=3581.8, bsz=143.5, num_updates=53000, lr=0.000137361, gnorm=1.14, train_wall=23, wall=0
2024-07-12 21:06:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:06:28 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 3.98 | nll_loss 2.396 | ppl 5.26 | wps 45039 | wpb 2685.2 | bsz 107.1 | num_updates 53000 | best_loss 11.022
2024-07-12 21:06:28 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:06:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_47_53000.pt (epoch 47 @ 53000 updates, score 3.98) (writing took 4.468939364887774 seconds)
2024-07-12 21:06:55 | INFO | train_inner | epoch 047:   1028 / 1132 loss=3.06, nll_loss=1.466, ppl=2.76, wps=11329.9, ups=3.24, wpb=3493.5, bsz=138.3, num_updates=53100, lr=0.000137231, gnorm=1.169, train_wall=22, wall=0
2024-07-12 21:07:18 | INFO | train_inner | epoch 047:   1128 / 1132 loss=3.087, nll_loss=1.496, ppl=2.82, wps=15926.1, ups=4.44, wpb=3589.7, bsz=140, num_updates=53200, lr=0.000137102, gnorm=1.127, train_wall=22, wall=0
2024-07-12 21:07:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:07:23 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 3.967 | nll_loss 2.386 | ppl 5.23 | wps 44959.8 | wpb 2685.2 | bsz 107.1 | num_updates 53204 | best_loss 11.022
2024-07-12 21:07:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:07:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 47 @ 53204 updates, score 3.967) (writing took 4.3622468346729875 seconds)
2024-07-12 21:07:27 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2024-07-12 21:07:27 | INFO | train | epoch 047 | loss 3.045 | nll_loss 1.447 | ppl 2.73 | wps 14640.4 | ups 4.12 | wpb 3556.4 | bsz 141.6 | num_updates 53204 | lr 0.000137097 | gnorm 1.142 | train_wall 256 | wall 0
2024-07-12 21:07:27 | INFO | fairseq.trainer | begin training epoch 48
2024-07-12 21:07:49 | INFO | train_inner | epoch 048:     96 / 1132 loss=2.998, nll_loss=1.393, ppl=2.63, wps=11248.2, ups=3.15, wpb=3571.2, bsz=131.5, num_updates=53300, lr=0.000136973, gnorm=1.108, train_wall=23, wall=0
2024-07-12 21:08:12 | INFO | train_inner | epoch 048:    196 / 1132 loss=3, nll_loss=1.394, ppl=2.63, wps=15717, ups=4.4, wpb=3574.9, bsz=153.4, num_updates=53400, lr=0.000136845, gnorm=1.124, train_wall=23, wall=0
2024-07-12 21:08:36 | INFO | train_inner | epoch 048:    296 / 1132 loss=3.03, nll_loss=1.429, ppl=2.69, wps=15375.1, ups=4.26, wpb=3606, bsz=137.4, num_updates=53500, lr=0.000136717, gnorm=1.122, train_wall=23, wall=0
2024-07-12 21:08:58 | INFO | train_inner | epoch 048:    396 / 1132 loss=3.028, nll_loss=1.427, ppl=2.69, wps=15692.3, ups=4.44, wpb=3534.4, bsz=138.6, num_updates=53600, lr=0.00013659, gnorm=1.143, train_wall=22, wall=0
2024-07-12 21:09:20 | INFO | train_inner | epoch 048:    496 / 1132 loss=3.025, nll_loss=1.423, ppl=2.68, wps=15468.7, ups=4.47, wpb=3459, bsz=131.3, num_updates=53700, lr=0.000136462, gnorm=1.176, train_wall=22, wall=0
2024-07-12 21:09:42 | INFO | train_inner | epoch 048:    596 / 1132 loss=3.041, nll_loss=1.443, ppl=2.72, wps=16287.9, ups=4.55, wpb=3578.6, bsz=138.9, num_updates=53800, lr=0.000136335, gnorm=1.153, train_wall=22, wall=0
2024-07-12 21:10:05 | INFO | train_inner | epoch 048:    696 / 1132 loss=3.036, nll_loss=1.438, ppl=2.71, wps=15681.4, ups=4.42, wpb=3551.6, bsz=140, num_updates=53900, lr=0.000136209, gnorm=1.153, train_wall=22, wall=0
2024-07-12 21:10:28 | INFO | train_inner | epoch 048:    796 / 1132 loss=3.063, nll_loss=1.467, ppl=2.77, wps=15680.8, ups=4.38, wpb=3583.1, bsz=131.5, num_updates=54000, lr=0.000136083, gnorm=1.16, train_wall=23, wall=0
2024-07-12 21:10:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:10:32 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 3.985 | nll_loss 2.401 | ppl 5.28 | wps 44920.8 | wpb 2685.2 | bsz 107.1 | num_updates 54000 | best_loss 11.022
2024-07-12 21:10:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:10:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_48_54000.pt (epoch 48 @ 54000 updates, score 3.985) (writing took 4.67549801338464 seconds)
2024-07-12 21:10:59 | INFO | train_inner | epoch 048:    896 / 1132 loss=3.053, nll_loss=1.458, ppl=2.75, wps=11216.8, ups=3.2, wpb=3505.7, bsz=132.6, num_updates=54100, lr=0.000135957, gnorm=1.182, train_wall=22, wall=0
2024-07-12 21:11:22 | INFO | train_inner | epoch 048:    996 / 1132 loss=3.036, nll_loss=1.44, ppl=2.71, wps=15756, ups=4.39, wpb=3587.6, bsz=161.1, num_updates=54200, lr=0.000135831, gnorm=1.122, train_wall=23, wall=0
2024-07-12 21:11:45 | INFO | train_inner | epoch 048:   1096 / 1132 loss=3.05, nll_loss=1.453, ppl=2.74, wps=15343.6, ups=4.33, wpb=3543.2, bsz=156.4, num_updates=54300, lr=0.000135706, gnorm=1.147, train_wall=23, wall=0
2024-07-12 21:11:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:11:58 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 3.97 | nll_loss 2.388 | ppl 5.23 | wps 44876.6 | wpb 2685.2 | bsz 107.1 | num_updates 54336 | best_loss 11.022
2024-07-12 21:11:58 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:12:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 48 @ 54336 updates, score 3.97) (writing took 3.4710404286161065 seconds)
2024-07-12 21:12:01 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2024-07-12 21:12:01 | INFO | train | epoch 048 | loss 3.034 | nll_loss 1.435 | ppl 2.7 | wps 14685.2 | ups 4.13 | wpb 3556.4 | bsz 141.6 | num_updates 54336 | lr 0.000135661 | gnorm 1.144 | train_wall 256 | wall 0
2024-07-12 21:12:01 | INFO | fairseq.trainer | begin training epoch 49
2024-07-12 21:12:16 | INFO | train_inner | epoch 049:     64 / 1132 loss=3.013, nll_loss=1.411, ppl=2.66, wps=11455.1, ups=3.23, wpb=3551.3, bsz=145.8, num_updates=54400, lr=0.000135582, gnorm=1.14, train_wall=23, wall=0
2024-07-12 21:12:39 | INFO | train_inner | epoch 049:    164 / 1132 loss=2.989, nll_loss=1.38, ppl=2.6, wps=15299.2, ups=4.34, wpb=3524, bsz=142.2, num_updates=54500, lr=0.000135457, gnorm=1.135, train_wall=23, wall=0
2024-07-12 21:13:02 | INFO | train_inner | epoch 049:    264 / 1132 loss=2.995, nll_loss=1.389, ppl=2.62, wps=15472, ups=4.39, wpb=3523.4, bsz=142.2, num_updates=54600, lr=0.000135333, gnorm=1.141, train_wall=23, wall=0
2024-07-12 21:13:25 | INFO | train_inner | epoch 049:    364 / 1132 loss=3.004, nll_loss=1.402, ppl=2.64, wps=15908.4, ups=4.36, wpb=3652.1, bsz=147, num_updates=54700, lr=0.000135209, gnorm=1.112, train_wall=23, wall=0
2024-07-12 21:13:48 | INFO | train_inner | epoch 049:    464 / 1132 loss=3.01, nll_loss=1.407, ppl=2.65, wps=15395.5, ups=4.3, wpb=3582.9, bsz=141.5, num_updates=54800, lr=0.000135086, gnorm=1.125, train_wall=23, wall=0
2024-07-12 21:14:11 | INFO | train_inner | epoch 049:    564 / 1132 loss=3.024, nll_loss=1.423, ppl=2.68, wps=15498.7, ups=4.33, wpb=3578.2, bsz=149, num_updates=54900, lr=0.000134963, gnorm=1.138, train_wall=23, wall=0
2024-07-12 21:14:34 | INFO | train_inner | epoch 049:    664 / 1132 loss=3.019, nll_loss=1.418, ppl=2.67, wps=15915.4, ups=4.48, wpb=3556.4, bsz=141.8, num_updates=55000, lr=0.00013484, gnorm=1.139, train_wall=22, wall=0
2024-07-12 21:14:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:14:38 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 3.985 | nll_loss 2.406 | ppl 5.3 | wps 45132.4 | wpb 2685.2 | bsz 107.1 | num_updates 55000 | best_loss 11.022
2024-07-12 21:14:38 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:14:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_49_55000.pt (epoch 49 @ 55000 updates, score 3.985) (writing took 4.937797727994621 seconds)
2024-07-12 21:15:06 | INFO | train_inner | epoch 049:    764 / 1132 loss=3.057, nll_loss=1.46, ppl=2.75, wps=11136.4, ups=3.12, wpb=3574.8, bsz=127.4, num_updates=55100, lr=0.000134718, gnorm=1.172, train_wall=23, wall=0
2024-07-12 21:15:29 | INFO | train_inner | epoch 049:    864 / 1132 loss=3.05, nll_loss=1.453, ppl=2.74, wps=15269.2, ups=4.37, wpb=3496.4, bsz=134.6, num_updates=55200, lr=0.000134595, gnorm=1.182, train_wall=23, wall=0
2024-07-12 21:15:51 | INFO | train_inner | epoch 049:    964 / 1132 loss=3.052, nll_loss=1.456, ppl=2.74, wps=15846.9, ups=4.38, wpb=3617, bsz=138.2, num_updates=55300, lr=0.000134474, gnorm=1.132, train_wall=23, wall=0
2024-07-12 21:16:14 | INFO | train_inner | epoch 049:   1064 / 1132 loss=3.049, nll_loss=1.454, ppl=2.74, wps=15486.8, ups=4.46, wpb=3475.7, bsz=135.1, num_updates=55400, lr=0.000134352, gnorm=1.204, train_wall=22, wall=0
2024-07-12 21:16:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:16:34 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 3.986 | nll_loss 2.4 | ppl 5.28 | wps 45023.3 | wpb 2685.2 | bsz 107.1 | num_updates 55468 | best_loss 11.022
2024-07-12 21:16:34 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:16:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 49 @ 55468 updates, score 3.986) (writing took 4.578838823363185 seconds)
2024-07-12 21:16:38 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2024-07-12 21:16:38 | INFO | train | epoch 049 | loss 3.022 | nll_loss 1.421 | ppl 2.68 | wps 14540.4 | ups 4.09 | wpb 3556.4 | bsz 141.6 | num_updates 55468 | lr 0.00013427 | gnorm 1.148 | train_wall 257 | wall 0
2024-07-12 21:16:38 | INFO | fairseq.trainer | begin training epoch 50
2024-07-12 21:16:45 | INFO | train_inner | epoch 050:     32 / 1132 loss=3.005, nll_loss=1.403, ppl=2.64, wps=11137.3, ups=3.17, wpb=3514.7, bsz=153.2, num_updates=55500, lr=0.000134231, gnorm=1.166, train_wall=22, wall=0
2024-07-12 21:17:08 | INFO | train_inner | epoch 050:    132 / 1132 loss=2.981, nll_loss=1.373, ppl=2.59, wps=15793.4, ups=4.47, wpb=3535.8, bsz=136.9, num_updates=55600, lr=0.00013411, gnorm=1.15, train_wall=22, wall=0
2024-07-12 21:17:31 | INFO | train_inner | epoch 050:    232 / 1132 loss=2.967, nll_loss=1.357, ppl=2.56, wps=15362.1, ups=4.39, wpb=3498.8, bsz=144, num_updates=55700, lr=0.00013399, gnorm=1.136, train_wall=23, wall=0
2024-07-12 21:17:53 | INFO | train_inner | epoch 050:    332 / 1132 loss=2.998, nll_loss=1.393, ppl=2.63, wps=15859.9, ups=4.45, wpb=3560.2, bsz=143.4, num_updates=55800, lr=0.00013387, gnorm=1.168, train_wall=22, wall=0
2024-07-12 21:18:15 | INFO | train_inner | epoch 050:    432 / 1132 loss=3.018, nll_loss=1.413, ppl=2.66, wps=15986.5, ups=4.44, wpb=3598.9, bsz=129.6, num_updates=55900, lr=0.00013375, gnorm=1.143, train_wall=22, wall=0
2024-07-12 21:18:38 | INFO | train_inner | epoch 050:    532 / 1132 loss=3.011, nll_loss=1.405, ppl=2.65, wps=15823.4, ups=4.52, wpb=3501.2, bsz=134.8, num_updates=56000, lr=0.000133631, gnorm=1.181, train_wall=22, wall=0
2024-07-12 21:18:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:18:42 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 4.003 | nll_loss 2.422 | ppl 5.36 | wps 45054.6 | wpb 2685.2 | bsz 107.1 | num_updates 56000 | best_loss 11.022
2024-07-12 21:18:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:18:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_50_56000.pt (epoch 50 @ 56000 updates, score 4.003) (writing took 4.585349317640066 seconds)
2024-07-12 21:19:09 | INFO | train_inner | epoch 050:    632 / 1132 loss=3.011, nll_loss=1.408, ppl=2.65, wps=11250.6, ups=3.14, wpb=3578.2, bsz=151.8, num_updates=56100, lr=0.000133511, gnorm=1.131, train_wall=23, wall=0
2024-07-12 21:19:32 | INFO | train_inner | epoch 050:    732 / 1132 loss=3.013, nll_loss=1.412, ppl=2.66, wps=16103, ups=4.47, wpb=3601.3, bsz=149.9, num_updates=56200, lr=0.000133393, gnorm=1.142, train_wall=22, wall=0
2024-07-12 21:19:54 | INFO | train_inner | epoch 050:    832 / 1132 loss=3.022, nll_loss=1.423, ppl=2.68, wps=16207.9, ups=4.49, wpb=3607.4, bsz=151.2, num_updates=56300, lr=0.000133274, gnorm=1.142, train_wall=22, wall=0
2024-07-12 21:20:17 | INFO | train_inner | epoch 050:    932 / 1132 loss=3.028, nll_loss=1.432, ppl=2.7, wps=15786.5, ups=4.35, wpb=3626.6, bsz=156.2, num_updates=56400, lr=0.000133156, gnorm=1.133, train_wall=23, wall=0
2024-07-12 21:20:39 | INFO | train_inner | epoch 050:   1032 / 1132 loss=3.042, nll_loss=1.444, ppl=2.72, wps=16041.3, ups=4.51, wpb=3553, bsz=134.1, num_updates=56500, lr=0.000133038, gnorm=1.153, train_wall=22, wall=0
2024-07-12 21:21:02 | INFO | train_inner | epoch 050:   1132 / 1132 loss=3.056, nll_loss=1.459, ppl=2.75, wps=15643.6, ups=4.44, wpb=3526.1, bsz=128.8, num_updates=56600, lr=0.00013292, gnorm=1.191, train_wall=22, wall=0
2024-07-12 21:21:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:21:06 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 3.98 | nll_loss 2.401 | ppl 5.28 | wps 44944.3 | wpb 2685.2 | bsz 107.1 | num_updates 56600 | best_loss 11.022
2024-07-12 21:21:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:21:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 50 @ 56600 updates, score 3.98) (writing took 3.3140067867934704 seconds)
2024-07-12 21:21:09 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2024-07-12 21:21:09 | INFO | train | epoch 050 | loss 3.012 | nll_loss 1.409 | ppl 2.66 | wps 14852.9 | ups 4.18 | wpb 3556.4 | bsz 141.6 | num_updates 56600 | lr 0.00013292 | gnorm 1.154 | train_wall 253 | wall 0
2024-07-12 21:21:09 | INFO | fairseq.trainer | begin training epoch 51
2024-07-12 21:21:31 | INFO | train_inner | epoch 051:    100 / 1132 loss=2.95, nll_loss=1.338, ppl=2.53, wps=11727.8, ups=3.35, wpb=3496.4, bsz=146.4, num_updates=56700, lr=0.000132803, gnorm=1.16, train_wall=22, wall=0
2024-07-12 21:21:54 | INFO | train_inner | epoch 051:    200 / 1132 loss=2.951, nll_loss=1.34, ppl=2.53, wps=15396, ups=4.4, wpb=3501.2, bsz=156.7, num_updates=56800, lr=0.000132686, gnorm=1.145, train_wall=23, wall=0
2024-07-12 21:22:17 | INFO | train_inner | epoch 051:    300 / 1132 loss=2.975, nll_loss=1.365, ppl=2.58, wps=15549.2, ups=4.35, wpb=3577.6, bsz=139.7, num_updates=56900, lr=0.00013257, gnorm=1.137, train_wall=23, wall=0
2024-07-12 21:22:40 | INFO | train_inner | epoch 051:    400 / 1132 loss=2.972, nll_loss=1.365, ppl=2.58, wps=15722.8, ups=4.43, wpb=3548.4, bsz=152.3, num_updates=57000, lr=0.000132453, gnorm=1.116, train_wall=22, wall=0
2024-07-12 21:22:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:22:44 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 3.998 | nll_loss 2.419 | ppl 5.35 | wps 44932.3 | wpb 2685.2 | bsz 107.1 | num_updates 57000 | best_loss 11.022
2024-07-12 21:22:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:22:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_51_57000.pt (epoch 51 @ 57000 updates, score 3.998) (writing took 5.042994638904929 seconds)
2024-07-12 21:23:12 | INFO | train_inner | epoch 051:    500 / 1132 loss=3.014, nll_loss=1.41, ppl=2.66, wps=10967.7, ups=3.1, wpb=3538.9, bsz=129.8, num_updates=57100, lr=0.000132337, gnorm=1.173, train_wall=23, wall=0
2024-07-12 21:23:35 | INFO | train_inner | epoch 051:    600 / 1132 loss=3.007, nll_loss=1.405, ppl=2.65, wps=15632.1, ups=4.35, wpb=3594.7, bsz=136.6, num_updates=57200, lr=0.000132221, gnorm=1.145, train_wall=23, wall=0
2024-07-12 21:23:57 | INFO | train_inner | epoch 051:    700 / 1132 loss=3.005, nll_loss=1.402, ppl=2.64, wps=16093.4, ups=4.48, wpb=3591.8, bsz=149.6, num_updates=57300, lr=0.000132106, gnorm=1.15, train_wall=22, wall=0
2024-07-12 21:24:20 | INFO | train_inner | epoch 051:    800 / 1132 loss=3.03, nll_loss=1.43, ppl=2.69, wps=15855.3, ups=4.45, wpb=3560.6, bsz=129.4, num_updates=57400, lr=0.000131991, gnorm=1.192, train_wall=22, wall=0
2024-07-12 21:24:43 | INFO | train_inner | epoch 051:    900 / 1132 loss=3.025, nll_loss=1.424, ppl=2.68, wps=15620.6, ups=4.37, wpb=3574.1, bsz=140.4, num_updates=57500, lr=0.000131876, gnorm=1.167, train_wall=23, wall=0
2024-07-12 21:25:05 | INFO | train_inner | epoch 051:   1000 / 1132 loss=3.025, nll_loss=1.424, ppl=2.68, wps=15808.6, ups=4.4, wpb=3592.9, bsz=152, num_updates=57600, lr=0.000131762, gnorm=1.155, train_wall=23, wall=0
2024-07-12 21:25:28 | INFO | train_inner | epoch 051:   1100 / 1132 loss=3.036, nll_loss=1.439, ppl=2.71, wps=15550, ups=4.4, wpb=3535.6, bsz=133.8, num_updates=57700, lr=0.000131647, gnorm=1.165, train_wall=23, wall=0
2024-07-12 21:25:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:25:40 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 3.982 | nll_loss 2.404 | ppl 5.29 | wps 44936.5 | wpb 2685.2 | bsz 107.1 | num_updates 57732 | best_loss 11.022
2024-07-12 21:25:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:25:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 51 @ 57732 updates, score 3.982) (writing took 3.2403433667495847 seconds)
2024-07-12 21:25:43 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2024-07-12 21:25:43 | INFO | train | epoch 051 | loss 3.001 | nll_loss 1.397 | ppl 2.63 | wps 14706.3 | ups 4.14 | wpb 3556.4 | bsz 141.6 | num_updates 57732 | lr 0.000131611 | gnorm 1.156 | train_wall 255 | wall 0
2024-07-12 21:25:43 | INFO | fairseq.trainer | begin training epoch 52
2024-07-12 21:25:58 | INFO | train_inner | epoch 052:     68 / 1132 loss=2.98, nll_loss=1.371, ppl=2.59, wps=11672.6, ups=3.31, wpb=3527.8, bsz=134.4, num_updates=57800, lr=0.000131533, gnorm=1.147, train_wall=22, wall=0
2024-07-12 21:26:21 | INFO | train_inner | epoch 052:    168 / 1132 loss=2.949, nll_loss=1.335, ppl=2.52, wps=15716.2, ups=4.36, wpb=3606.4, bsz=146.4, num_updates=57900, lr=0.00013142, gnorm=1.123, train_wall=23, wall=0
2024-07-12 21:26:44 | INFO | train_inner | epoch 052:    268 / 1132 loss=2.988, nll_loss=1.381, ppl=2.61, wps=16316.5, ups=4.44, wpb=3672.4, bsz=139.9, num_updates=58000, lr=0.000131306, gnorm=1.129, train_wall=22, wall=0
2024-07-12 21:26:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:26:48 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 3.998 | nll_loss 2.418 | ppl 5.34 | wps 45019.1 | wpb 2685.2 | bsz 107.1 | num_updates 58000 | best_loss 11.022
2024-07-12 21:26:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:26:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_52_58000.pt (epoch 52 @ 58000 updates, score 3.998) (writing took 5.207334507256746 seconds)
2024-07-12 21:27:16 | INFO | train_inner | epoch 052:    368 / 1132 loss=2.98, nll_loss=1.372, ppl=2.59, wps=10852, ups=3.09, wpb=3512.7, bsz=139.5, num_updates=58100, lr=0.000131193, gnorm=1.17, train_wall=23, wall=0
2024-07-12 21:27:39 | INFO | train_inner | epoch 052:    468 / 1132 loss=2.983, nll_loss=1.377, ppl=2.6, wps=15208.9, ups=4.36, wpb=3490.5, bsz=133, num_updates=58200, lr=0.000131081, gnorm=1.163, train_wall=23, wall=0
2024-07-12 21:28:02 | INFO | train_inner | epoch 052:    568 / 1132 loss=3.005, nll_loss=1.401, ppl=2.64, wps=15615, ups=4.4, wpb=3547.9, bsz=129.8, num_updates=58300, lr=0.000130968, gnorm=1.19, train_wall=23, wall=0
2024-07-12 21:28:25 | INFO | train_inner | epoch 052:    668 / 1132 loss=2.987, nll_loss=1.383, ppl=2.61, wps=15618.6, ups=4.36, wpb=3582, bsz=140.6, num_updates=58400, lr=0.000130856, gnorm=1.151, train_wall=23, wall=0
2024-07-12 21:28:48 | INFO | train_inner | epoch 052:    768 / 1132 loss=3.025, nll_loss=1.423, ppl=2.68, wps=15301.5, ups=4.28, wpb=3571.1, bsz=131.2, num_updates=58500, lr=0.000130744, gnorm=1.19, train_wall=23, wall=0
2024-07-12 21:29:11 | INFO | train_inner | epoch 052:    868 / 1132 loss=2.989, nll_loss=1.383, ppl=2.61, wps=15377.2, ups=4.44, wpb=3466, bsz=145.6, num_updates=58600, lr=0.000130632, gnorm=1.179, train_wall=22, wall=0
2024-07-12 21:29:33 | INFO | train_inner | epoch 052:    968 / 1132 loss=2.996, nll_loss=1.394, ppl=2.63, wps=15844.4, ups=4.5, wpb=3519.9, bsz=153.1, num_updates=58700, lr=0.000130521, gnorm=1.18, train_wall=22, wall=0
2024-07-12 21:29:56 | INFO | train_inner | epoch 052:   1068 / 1132 loss=3.016, nll_loss=1.415, ppl=2.67, wps=15846, ups=4.4, wpb=3599.9, bsz=149.5, num_updates=58800, lr=0.00013041, gnorm=1.158, train_wall=23, wall=0
2024-07-12 21:30:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:30:15 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 3.996 | nll_loss 2.413 | ppl 5.32 | wps 44753.6 | wpb 2685.2 | bsz 107.1 | num_updates 58864 | best_loss 11.022
2024-07-12 21:30:15 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:30:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 52 @ 58864 updates, score 3.996) (writing took 3.5977835692465305 seconds)
2024-07-12 21:30:18 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2024-07-12 21:30:18 | INFO | train | epoch 052 | loss 2.991 | nll_loss 1.386 | ppl 2.61 | wps 14623.9 | ups 4.11 | wpb 3556.4 | bsz 141.6 | num_updates 58864 | lr 0.000130339 | gnorm 1.161 | train_wall 256 | wall 0
2024-07-12 21:30:18 | INFO | fairseq.trainer | begin training epoch 53
2024-07-12 21:30:27 | INFO | train_inner | epoch 053:     36 / 1132 loss=3.007, nll_loss=1.404, ppl=2.65, wps=11603, ups=3.23, wpb=3595.7, bsz=145, num_updates=58900, lr=0.000130299, gnorm=1.155, train_wall=23, wall=0
2024-07-12 21:30:49 | INFO | train_inner | epoch 053:    136 / 1132 loss=2.954, nll_loss=1.343, ppl=2.54, wps=15850.1, ups=4.38, wpb=3617.5, bsz=133, num_updates=59000, lr=0.000130189, gnorm=1.118, train_wall=23, wall=0
2024-07-12 21:30:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:30:54 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 3.999 | nll_loss 2.418 | ppl 5.34 | wps 44884.6 | wpb 2685.2 | bsz 107.1 | num_updates 59000 | best_loss 11.022
2024-07-12 21:30:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:30:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_53_59000.pt (epoch 53 @ 59000 updates, score 3.999) (writing took 4.383209208957851 seconds)
2024-07-12 21:31:21 | INFO | train_inner | epoch 053:    236 / 1132 loss=2.953, nll_loss=1.342, ppl=2.54, wps=11534.4, ups=3.18, wpb=3630.9, bsz=145.4, num_updates=59100, lr=0.000130079, gnorm=1.142, train_wall=23, wall=0
2024-07-12 21:31:44 | INFO | train_inner | epoch 053:    336 / 1132 loss=2.955, nll_loss=1.343, ppl=2.54, wps=15742.9, ups=4.41, wpb=3567.8, bsz=145.5, num_updates=59200, lr=0.000129969, gnorm=1.145, train_wall=23, wall=0
2024-07-12 21:32:06 | INFO | train_inner | epoch 053:    436 / 1132 loss=2.98, nll_loss=1.371, ppl=2.59, wps=15561.9, ups=4.42, wpb=3520.5, bsz=127.5, num_updates=59300, lr=0.000129859, gnorm=1.214, train_wall=22, wall=0
2024-07-12 21:32:29 | INFO | train_inner | epoch 053:    536 / 1132 loss=2.971, nll_loss=1.363, ppl=2.57, wps=15581.9, ups=4.35, wpb=3582.5, bsz=154.2, num_updates=59400, lr=0.00012975, gnorm=1.153, train_wall=23, wall=0
2024-07-12 21:32:52 | INFO | train_inner | epoch 053:    636 / 1132 loss=2.975, nll_loss=1.367, ppl=2.58, wps=15202.1, ups=4.36, wpb=3484.5, bsz=147.8, num_updates=59500, lr=0.000129641, gnorm=1.171, train_wall=23, wall=0
2024-07-12 21:33:15 | INFO | train_inner | epoch 053:    736 / 1132 loss=3.01, nll_loss=1.409, ppl=2.65, wps=15736.1, ups=4.35, wpb=3615.7, bsz=139.5, num_updates=59600, lr=0.000129532, gnorm=1.164, train_wall=23, wall=0
2024-07-12 21:33:38 | INFO | train_inner | epoch 053:    836 / 1132 loss=2.993, nll_loss=1.387, ppl=2.62, wps=15612.1, ups=4.44, wpb=3513.5, bsz=144.9, num_updates=59700, lr=0.000129423, gnorm=1.191, train_wall=22, wall=0
2024-07-12 21:34:00 | INFO | train_inner | epoch 053:    936 / 1132 loss=2.995, nll_loss=1.389, ppl=2.62, wps=15528, ups=4.43, wpb=3501.5, bsz=136.1, num_updates=59800, lr=0.000129315, gnorm=1.183, train_wall=22, wall=0
2024-07-12 21:34:23 | INFO | train_inner | epoch 053:   1036 / 1132 loss=3.011, nll_loss=1.408, ppl=2.65, wps=15660.8, ups=4.42, wpb=3540.6, bsz=132.4, num_updates=59900, lr=0.000129207, gnorm=1.188, train_wall=22, wall=0
2024-07-12 21:34:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:34:49 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 4.004 | nll_loss 2.428 | ppl 5.38 | wps 44896.8 | wpb 2685.2 | bsz 107.1 | num_updates 59996 | best_loss 11.022
2024-07-12 21:34:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:34:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 53 @ 59996 updates, score 4.004) (writing took 3.840354056097567 seconds)
2024-07-12 21:34:53 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2024-07-12 21:34:53 | INFO | train | epoch 053 | loss 2.981 | nll_loss 1.374 | ppl 2.59 | wps 14654.6 | ups 4.12 | wpb 3556.4 | bsz 141.6 | num_updates 59996 | lr 0.000129104 | gnorm 1.167 | train_wall 256 | wall 0
2024-07-12 21:34:53 | INFO | fairseq.trainer | begin training epoch 54
2024-07-12 21:34:54 | INFO | train_inner | epoch 054:      4 / 1132 loss=3.001, nll_loss=1.397, ppl=2.63, wps=11285.3, ups=3.2, wpb=3529, bsz=149.8, num_updates=60000, lr=0.000129099, gnorm=1.186, train_wall=23, wall=0
2024-07-12 21:34:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:34:58 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 4.006 | nll_loss 2.424 | ppl 5.37 | wps 44997.6 | wpb 2685.2 | bsz 107.1 | num_updates 60000 | best_loss 11.022
2024-07-12 21:34:58 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:35:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_54_60000.pt (epoch 54 @ 60000 updates, score 4.006) (writing took 4.504412062466145 seconds)
2024-07-12 21:35:26 | INFO | train_inner | epoch 054:    104 / 1132 loss=2.923, nll_loss=1.305, ppl=2.47, wps=10885.8, ups=3.1, wpb=3513.2, bsz=138.2, num_updates=60100, lr=0.000128992, gnorm=1.149, train_wall=23, wall=0
2024-07-12 21:35:50 | INFO | train_inner | epoch 054:    204 / 1132 loss=2.944, nll_loss=1.328, ppl=2.51, wps=15376, ups=4.3, wpb=3571.8, bsz=133.9, num_updates=60200, lr=0.000128885, gnorm=1.152, train_wall=23, wall=0
2024-07-12 21:36:12 | INFO | train_inner | epoch 054:    304 / 1132 loss=2.917, nll_loss=1.302, ppl=2.47, wps=15715.1, ups=4.45, wpb=3528.3, bsz=157.4, num_updates=60300, lr=0.000128778, gnorm=1.142, train_wall=22, wall=0
2024-07-12 21:36:35 | INFO | train_inner | epoch 054:    404 / 1132 loss=2.968, nll_loss=1.36, ppl=2.57, wps=15382.8, ups=4.28, wpb=3594.6, bsz=146.2, num_updates=60400, lr=0.000128671, gnorm=1.149, train_wall=23, wall=0
2024-07-12 21:36:58 | INFO | train_inner | epoch 054:    504 / 1132 loss=2.971, nll_loss=1.36, ppl=2.57, wps=15469.2, ups=4.4, wpb=3517.9, bsz=141.6, num_updates=60500, lr=0.000128565, gnorm=1.179, train_wall=23, wall=0
2024-07-12 21:37:21 | INFO | train_inner | epoch 054:    604 / 1132 loss=2.961, nll_loss=1.352, ppl=2.55, wps=15783.3, ups=4.39, wpb=3596, bsz=150.3, num_updates=60600, lr=0.000128459, gnorm=1.138, train_wall=23, wall=0
2024-07-12 21:37:44 | INFO | train_inner | epoch 054:    704 / 1132 loss=2.989, nll_loss=1.382, ppl=2.61, wps=15679.8, ups=4.37, wpb=3584.6, bsz=142.8, num_updates=60700, lr=0.000128353, gnorm=1.19, train_wall=23, wall=0
2024-07-12 21:38:07 | INFO | train_inner | epoch 054:    804 / 1132 loss=2.995, nll_loss=1.39, ppl=2.62, wps=15660.2, ups=4.38, wpb=3576.7, bsz=139.4, num_updates=60800, lr=0.000128247, gnorm=1.169, train_wall=23, wall=0
2024-07-12 21:38:29 | INFO | train_inner | epoch 054:    904 / 1132 loss=2.986, nll_loss=1.379, ppl=2.6, wps=15450.1, ups=4.43, wpb=3484.9, bsz=130, num_updates=60900, lr=0.000128142, gnorm=1.192, train_wall=22, wall=0
2024-07-12 21:38:52 | INFO | train_inner | epoch 054:   1004 / 1132 loss=3.022, nll_loss=1.42, ppl=2.68, wps=15531.1, ups=4.38, wpb=3548, bsz=128.6, num_updates=61000, lr=0.000128037, gnorm=1.235, train_wall=23, wall=0
2024-07-12 21:38:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:38:56 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 4.003 | nll_loss 2.425 | ppl 5.37 | wps 44793.9 | wpb 2685.2 | bsz 107.1 | num_updates 61000 | best_loss 11.022
2024-07-12 21:38:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:39:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_54_61000.pt (epoch 54 @ 61000 updates, score 4.003) (writing took 4.107773273251951 seconds)
2024-07-12 21:39:23 | INFO | train_inner | epoch 054:   1104 / 1132 loss=2.991, nll_loss=1.389, ppl=2.62, wps=11586.4, ups=3.23, wpb=3592.2, bsz=151.1, num_updates=61100, lr=0.000127932, gnorm=1.155, train_wall=22, wall=0
2024-07-12 21:39:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:39:34 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 3.997 | nll_loss 2.419 | ppl 5.35 | wps 44865.4 | wpb 2685.2 | bsz 107.1 | num_updates 61128 | best_loss 11.022
2024-07-12 21:39:34 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:39:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 54 @ 61128 updates, score 3.997) (writing took 4.175076382234693 seconds)
2024-07-12 21:39:38 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2024-07-12 21:39:38 | INFO | train | epoch 054 | loss 2.971 | nll_loss 1.362 | ppl 2.57 | wps 14136.9 | ups 3.98 | wpb 3556.4 | bsz 141.6 | num_updates 61128 | lr 0.000127903 | gnorm 1.169 | train_wall 257 | wall 0
2024-07-12 21:39:38 | INFO | fairseq.trainer | begin training epoch 55
2024-07-12 21:39:54 | INFO | train_inner | epoch 055:     72 / 1132 loss=2.948, nll_loss=1.336, ppl=2.52, wps=11423.1, ups=3.19, wpb=3576.9, bsz=146.5, num_updates=61200, lr=0.000127827, gnorm=1.159, train_wall=23, wall=0
2024-07-12 21:40:17 | INFO | train_inner | epoch 055:    172 / 1132 loss=2.924, nll_loss=1.309, ppl=2.48, wps=15698.5, ups=4.38, wpb=3584.7, bsz=145.4, num_updates=61300, lr=0.000127723, gnorm=1.146, train_wall=23, wall=0
2024-07-12 21:40:40 | INFO | train_inner | epoch 055:    272 / 1132 loss=2.951, nll_loss=1.339, ppl=2.53, wps=15929, ups=4.44, wpb=3585.8, bsz=130.6, num_updates=61400, lr=0.000127619, gnorm=1.158, train_wall=22, wall=0
2024-07-12 21:41:03 | INFO | train_inner | epoch 055:    372 / 1132 loss=2.964, nll_loss=1.352, ppl=2.55, wps=15210.9, ups=4.35, wpb=3494.2, bsz=126.8, num_updates=61500, lr=0.000127515, gnorm=1.215, train_wall=23, wall=0
2024-07-12 21:41:25 | INFO | train_inner | epoch 055:    472 / 1132 loss=2.955, nll_loss=1.346, ppl=2.54, wps=16073.8, ups=4.47, wpb=3599.5, bsz=138.6, num_updates=61600, lr=0.000127412, gnorm=1.152, train_wall=22, wall=0
2024-07-12 21:41:47 | INFO | train_inner | epoch 055:    572 / 1132 loss=2.965, nll_loss=1.353, ppl=2.55, wps=15593.6, ups=4.5, wpb=3466, bsz=129.4, num_updates=61700, lr=0.000127309, gnorm=1.194, train_wall=22, wall=0
2024-07-12 21:42:10 | INFO | train_inner | epoch 055:    672 / 1132 loss=2.985, nll_loss=1.378, ppl=2.6, wps=15641.5, ups=4.37, wpb=3578.5, bsz=134.2, num_updates=61800, lr=0.000127205, gnorm=1.179, train_wall=23, wall=0
2024-07-12 21:42:33 | INFO | train_inner | epoch 055:    772 / 1132 loss=2.954, nll_loss=1.345, ppl=2.54, wps=15588.9, ups=4.35, wpb=3585.6, bsz=168.1, num_updates=61900, lr=0.000127103, gnorm=1.168, train_wall=23, wall=0
2024-07-12 21:42:57 | INFO | train_inner | epoch 055:    872 / 1132 loss=2.988, nll_loss=1.38, ppl=2.6, wps=15021, ups=4.21, wpb=3565.7, bsz=137.5, num_updates=62000, lr=0.000127, gnorm=1.208, train_wall=24, wall=0
2024-07-12 21:42:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:43:01 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 4.009 | nll_loss 2.435 | ppl 5.41 | wps 44821.3 | wpb 2685.2 | bsz 107.1 | num_updates 62000 | best_loss 11.022
2024-07-12 21:43:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:43:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_55_62000.pt (epoch 55 @ 62000 updates, score 4.009) (writing took 4.3934572748839855 seconds)
2024-07-12 21:43:28 | INFO | train_inner | epoch 055:    972 / 1132 loss=2.948, nll_loss=1.336, ppl=2.52, wps=11148, ups=3.18, wpb=3503.1, bsz=163.2, num_updates=62100, lr=0.000126898, gnorm=1.175, train_wall=23, wall=0
2024-07-12 21:43:51 | INFO | train_inner | epoch 055:   1072 / 1132 loss=3.008, nll_loss=1.407, ppl=2.65, wps=15819.1, ups=4.41, wpb=3588.6, bsz=133.1, num_updates=62200, lr=0.000126796, gnorm=1.189, train_wall=23, wall=0
2024-07-12 21:44:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:44:09 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 3.997 | nll_loss 2.42 | ppl 5.35 | wps 44885.6 | wpb 2685.2 | bsz 107.1 | num_updates 62260 | best_loss 11.022
2024-07-12 21:44:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:44:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 55 @ 62260 updates, score 3.997) (writing took 4.005048636347055 seconds)
2024-07-12 21:44:13 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2024-07-12 21:44:13 | INFO | train | epoch 055 | loss 2.962 | nll_loss 1.352 | ppl 2.55 | wps 14633.1 | ups 4.11 | wpb 3556.4 | bsz 141.6 | num_updates 62260 | lr 0.000126735 | gnorm 1.175 | train_wall 256 | wall 0
2024-07-12 21:44:13 | INFO | fairseq.trainer | begin training epoch 56
2024-07-12 21:44:22 | INFO | train_inner | epoch 056:     40 / 1132 loss=2.95, nll_loss=1.341, ppl=2.53, wps=11468.8, ups=3.22, wpb=3562.2, bsz=139.9, num_updates=62300, lr=0.000126694, gnorm=1.153, train_wall=23, wall=0
2024-07-12 21:44:45 | INFO | train_inner | epoch 056:    140 / 1132 loss=2.925, nll_loss=1.309, ppl=2.48, wps=15692.1, ups=4.41, wpb=3559.6, bsz=135.9, num_updates=62400, lr=0.000126592, gnorm=1.151, train_wall=23, wall=0
2024-07-12 21:45:08 | INFO | train_inner | epoch 056:    240 / 1132 loss=2.934, nll_loss=1.321, ppl=2.5, wps=15905.9, ups=4.34, wpb=3668.4, bsz=153.5, num_updates=62500, lr=0.000126491, gnorm=1.134, train_wall=23, wall=0
2024-07-12 21:45:31 | INFO | train_inner | epoch 056:    340 / 1132 loss=2.941, nll_loss=1.327, ppl=2.51, wps=15479.5, ups=4.31, wpb=3594.7, bsz=138.4, num_updates=62600, lr=0.00012639, gnorm=1.168, train_wall=23, wall=0
2024-07-12 21:45:54 | INFO | train_inner | epoch 056:    440 / 1132 loss=2.954, nll_loss=1.342, ppl=2.53, wps=15442.9, ups=4.28, wpb=3605.5, bsz=133.7, num_updates=62700, lr=0.000126289, gnorm=1.17, train_wall=23, wall=0
2024-07-12 21:46:18 | INFO | train_inner | epoch 056:    540 / 1132 loss=2.95, nll_loss=1.338, ppl=2.53, wps=15320.2, ups=4.32, wpb=3546.1, bsz=140, num_updates=62800, lr=0.000126189, gnorm=1.17, train_wall=23, wall=0
2024-07-12 21:46:40 | INFO | train_inner | epoch 056:    640 / 1132 loss=2.952, nll_loss=1.342, ppl=2.53, wps=15487.5, ups=4.36, wpb=3550.5, bsz=155.3, num_updates=62900, lr=0.000126088, gnorm=1.171, train_wall=23, wall=0
2024-07-12 21:47:03 | INFO | train_inner | epoch 056:    740 / 1132 loss=2.961, nll_loss=1.35, ppl=2.55, wps=15616.5, ups=4.42, wpb=3536.2, bsz=140.6, num_updates=63000, lr=0.000125988, gnorm=1.207, train_wall=22, wall=0
2024-07-12 21:47:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:47:07 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 4.002 | nll_loss 2.424 | ppl 5.37 | wps 44623.6 | wpb 2685.2 | bsz 107.1 | num_updates 63000 | best_loss 11.022
2024-07-12 21:47:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:47:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_56_63000.pt (epoch 56 @ 63000 updates, score 4.002) (writing took 4.643332999199629 seconds)
2024-07-12 21:47:35 | INFO | train_inner | epoch 056:    840 / 1132 loss=2.983, nll_loss=1.376, ppl=2.6, wps=11215.3, ups=3.17, wpb=3539.3, bsz=126, num_updates=63100, lr=0.000125888, gnorm=1.203, train_wall=22, wall=0
2024-07-12 21:47:57 | INFO | train_inner | epoch 056:    940 / 1132 loss=2.964, nll_loss=1.354, ppl=2.56, wps=15587.1, ups=4.46, wpb=3496.5, bsz=146.9, num_updates=63200, lr=0.000125789, gnorm=1.2, train_wall=22, wall=0
2024-07-12 21:48:19 | INFO | train_inner | epoch 056:   1040 / 1132 loss=2.971, nll_loss=1.362, ppl=2.57, wps=15994.8, ups=4.56, wpb=3503.9, bsz=147.7, num_updates=63300, lr=0.000125689, gnorm=1.203, train_wall=22, wall=0
2024-07-12 21:48:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:48:44 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 4.014 | nll_loss 2.435 | ppl 5.41 | wps 44831.8 | wpb 2685.2 | bsz 107.1 | num_updates 63392 | best_loss 11.022
2024-07-12 21:48:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:48:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 56 @ 63392 updates, score 4.014) (writing took 3.920112150721252 seconds)
2024-07-12 21:48:48 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2024-07-12 21:48:48 | INFO | train | epoch 056 | loss 2.953 | nll_loss 1.342 | ppl 2.53 | wps 14631.7 | ups 4.11 | wpb 3556.4 | bsz 141.6 | num_updates 63392 | lr 0.000125598 | gnorm 1.179 | train_wall 256 | wall 0
2024-07-12 21:48:48 | INFO | fairseq.trainer | begin training epoch 57
2024-07-12 21:48:50 | INFO | train_inner | epoch 057:      8 / 1132 loss=2.963, nll_loss=1.354, ppl=2.56, wps=11377.4, ups=3.22, wpb=3537.2, bsz=149.6, num_updates=63400, lr=0.00012559, gnorm=1.192, train_wall=23, wall=0
2024-07-12 21:49:13 | INFO | train_inner | epoch 057:    108 / 1132 loss=2.9, nll_loss=1.278, ppl=2.43, wps=15429.9, ups=4.46, wpb=3457.6, bsz=131.1, num_updates=63500, lr=0.000125491, gnorm=1.186, train_wall=22, wall=0
2024-07-12 21:49:35 | INFO | train_inner | epoch 057:    208 / 1132 loss=2.923, nll_loss=1.306, ppl=2.47, wps=15837.4, ups=4.41, wpb=3589.7, bsz=136.9, num_updates=63600, lr=0.000125392, gnorm=1.168, train_wall=23, wall=0
2024-07-12 21:49:59 | INFO | train_inner | epoch 057:    308 / 1132 loss=2.919, nll_loss=1.302, ppl=2.47, wps=15327.9, ups=4.29, wpb=3574.9, bsz=141.6, num_updates=63700, lr=0.000125294, gnorm=1.165, train_wall=23, wall=0
2024-07-12 21:50:21 | INFO | train_inner | epoch 057:    408 / 1132 loss=2.931, nll_loss=1.316, ppl=2.49, wps=15515.4, ups=4.38, wpb=3541, bsz=140.2, num_updates=63800, lr=0.000125196, gnorm=1.177, train_wall=23, wall=0
2024-07-12 21:50:44 | INFO | train_inner | epoch 057:    508 / 1132 loss=2.939, nll_loss=1.329, ppl=2.51, wps=15924.1, ups=4.42, wpb=3599.9, bsz=149.3, num_updates=63900, lr=0.000125098, gnorm=1.165, train_wall=22, wall=0
2024-07-12 21:51:07 | INFO | train_inner | epoch 057:    608 / 1132 loss=2.93, nll_loss=1.315, ppl=2.49, wps=15518.3, ups=4.42, wpb=3509.7, bsz=148.2, num_updates=64000, lr=0.000125, gnorm=1.182, train_wall=22, wall=0
2024-07-12 21:51:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:51:11 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 4.03 | nll_loss 2.453 | ppl 5.48 | wps 44832.4 | wpb 2685.2 | bsz 107.1 | num_updates 64000 | best_loss 11.022
2024-07-12 21:51:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:51:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_57_64000.pt (epoch 57 @ 64000 updates, score 4.03) (writing took 4.728611655533314 seconds)
2024-07-12 21:51:38 | INFO | train_inner | epoch 057:    708 / 1132 loss=2.949, nll_loss=1.334, ppl=2.52, wps=11128.9, ups=3.14, wpb=3542.2, bsz=143.6, num_updates=64100, lr=0.000124902, gnorm=1.202, train_wall=23, wall=0
2024-07-12 21:52:01 | INFO | train_inner | epoch 057:    808 / 1132 loss=2.961, nll_loss=1.351, ppl=2.55, wps=15689.8, ups=4.35, wpb=3604.1, bsz=148.2, num_updates=64200, lr=0.000124805, gnorm=1.192, train_wall=23, wall=0
2024-07-12 21:52:24 | INFO | train_inner | epoch 057:    908 / 1132 loss=2.968, nll_loss=1.361, ppl=2.57, wps=15904.9, ups=4.42, wpb=3601.7, bsz=137.2, num_updates=64300, lr=0.000124708, gnorm=1.176, train_wall=22, wall=0
2024-07-12 21:52:47 | INFO | train_inner | epoch 057:   1008 / 1132 loss=2.978, nll_loss=1.369, ppl=2.58, wps=15366.6, ups=4.39, wpb=3499.4, bsz=140.2, num_updates=64400, lr=0.000124611, gnorm=1.209, train_wall=23, wall=0
2024-07-12 21:53:10 | INFO | train_inner | epoch 057:   1108 / 1132 loss=2.989, nll_loss=1.385, ppl=2.61, wps=15793.3, ups=4.4, wpb=3593.3, bsz=135.4, num_updates=64500, lr=0.000124515, gnorm=1.184, train_wall=23, wall=0
2024-07-12 21:53:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:53:19 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 4.011 | nll_loss 2.433 | ppl 5.4 | wps 44947.4 | wpb 2685.2 | bsz 107.1 | num_updates 64524 | best_loss 11.022
2024-07-12 21:53:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:53:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 57 @ 64524 updates, score 4.011) (writing took 4.33767260145396 seconds)
2024-07-12 21:53:24 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2024-07-12 21:53:24 | INFO | train | epoch 057 | loss 2.944 | nll_loss 1.332 | ppl 2.52 | wps 14607.6 | ups 4.11 | wpb 3556.4 | bsz 141.6 | num_updates 64524 | lr 0.000124491 | gnorm 1.182 | train_wall 256 | wall 0
2024-07-12 21:53:24 | INFO | fairseq.trainer | begin training epoch 58
2024-07-12 21:53:41 | INFO | train_inner | epoch 058:     76 / 1132 loss=2.913, nll_loss=1.295, ppl=2.45, wps=11365.4, ups=3.16, wpb=3596.3, bsz=142.4, num_updates=64600, lr=0.000124418, gnorm=1.151, train_wall=23, wall=0
2024-07-12 21:54:04 | INFO | train_inner | epoch 058:    176 / 1132 loss=2.898, nll_loss=1.278, ppl=2.42, wps=15580.6, ups=4.37, wpb=3563.6, bsz=141, num_updates=64700, lr=0.000124322, gnorm=1.175, train_wall=23, wall=0
2024-07-12 21:54:27 | INFO | train_inner | epoch 058:    276 / 1132 loss=2.888, nll_loss=1.265, ppl=2.4, wps=15199.4, ups=4.4, wpb=3452.9, bsz=147.2, num_updates=64800, lr=0.000124226, gnorm=1.186, train_wall=23, wall=0
2024-07-12 21:54:50 | INFO | train_inner | epoch 058:    376 / 1132 loss=2.916, nll_loss=1.299, ppl=2.46, wps=15474.3, ups=4.35, wpb=3553.6, bsz=146.6, num_updates=64900, lr=0.00012413, gnorm=1.178, train_wall=23, wall=0
2024-07-12 21:55:13 | INFO | train_inner | epoch 058:    476 / 1132 loss=2.918, nll_loss=1.3, ppl=2.46, wps=15444.1, ups=4.33, wpb=3568.1, bsz=147.1, num_updates=65000, lr=0.000124035, gnorm=1.174, train_wall=23, wall=0
2024-07-12 21:55:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:55:17 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 4.024 | nll_loss 2.45 | ppl 5.46 | wps 44586.7 | wpb 2685.2 | bsz 107.1 | num_updates 65000 | best_loss 11.022
2024-07-12 21:55:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:55:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_58_65000.pt (epoch 58 @ 65000 updates, score 4.024) (writing took 4.9656242076307535 seconds)
2024-07-12 21:55:45 | INFO | train_inner | epoch 058:    576 / 1132 loss=2.956, nll_loss=1.344, ppl=2.54, wps=11238.8, ups=3.12, wpb=3603.3, bsz=134.3, num_updates=65100, lr=0.000123939, gnorm=1.183, train_wall=23, wall=0
2024-07-12 21:56:08 | INFO | train_inner | epoch 058:    676 / 1132 loss=2.938, nll_loss=1.324, ppl=2.5, wps=15545.9, ups=4.4, wpb=3531.4, bsz=140, num_updates=65200, lr=0.000123844, gnorm=1.193, train_wall=23, wall=0
2024-07-12 21:56:30 | INFO | train_inner | epoch 058:    776 / 1132 loss=2.954, nll_loss=1.343, ppl=2.54, wps=15672.5, ups=4.4, wpb=3563.7, bsz=141.8, num_updates=65300, lr=0.000123749, gnorm=1.209, train_wall=23, wall=0
2024-07-12 21:56:53 | INFO | train_inner | epoch 058:    876 / 1132 loss=2.961, nll_loss=1.351, ppl=2.55, wps=15640, ups=4.35, wpb=3597.8, bsz=134.9, num_updates=65400, lr=0.000123655, gnorm=1.194, train_wall=23, wall=0
2024-07-12 21:57:16 | INFO | train_inner | epoch 058:    976 / 1132 loss=2.964, nll_loss=1.355, ppl=2.56, wps=15577.6, ups=4.43, wpb=3517.3, bsz=132.2, num_updates=65500, lr=0.00012356, gnorm=1.234, train_wall=22, wall=0
2024-07-12 21:57:39 | INFO | train_inner | epoch 058:   1076 / 1132 loss=2.97, nll_loss=1.361, ppl=2.57, wps=15511.1, ups=4.39, wpb=3536.9, bsz=140.2, num_updates=65600, lr=0.000123466, gnorm=1.206, train_wall=23, wall=0
2024-07-12 21:57:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:57:56 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 4.015 | nll_loss 2.436 | ppl 5.41 | wps 44682.6 | wpb 2685.2 | bsz 107.1 | num_updates 65656 | best_loss 11.022
2024-07-12 21:57:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:57:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 58 @ 65656 updates, score 4.015) (writing took 3.6317111449316144 seconds)
2024-07-12 21:57:59 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2024-07-12 21:57:59 | INFO | train | epoch 058 | loss 2.934 | nll_loss 1.32 | ppl 2.5 | wps 14592.2 | ups 4.1 | wpb 3556.4 | bsz 141.6 | num_updates 65656 | lr 0.000123414 | gnorm 1.188 | train_wall 257 | wall 0
2024-07-12 21:58:00 | INFO | fairseq.trainer | begin training epoch 59
2024-07-12 21:58:09 | INFO | train_inner | epoch 059:     44 / 1132 loss=2.919, nll_loss=1.303, ppl=2.47, wps=11360.7, ups=3.25, wpb=3492.6, bsz=144.7, num_updates=65700, lr=0.000123372, gnorm=1.184, train_wall=23, wall=0
2024-07-12 21:58:32 | INFO | train_inner | epoch 059:    144 / 1132 loss=2.878, nll_loss=1.252, ppl=2.38, wps=15041.8, ups=4.38, wpb=3437.1, bsz=137.8, num_updates=65800, lr=0.000123278, gnorm=1.193, train_wall=23, wall=0
2024-07-12 21:58:55 | INFO | train_inner | epoch 059:    244 / 1132 loss=2.891, nll_loss=1.269, ppl=2.41, wps=15391.3, ups=4.36, wpb=3530.4, bsz=137.6, num_updates=65900, lr=0.000123185, gnorm=1.181, train_wall=23, wall=0
2024-07-12 21:59:18 | INFO | train_inner | epoch 059:    344 / 1132 loss=2.907, nll_loss=1.286, ppl=2.44, wps=15427, ups=4.41, wpb=3500.5, bsz=138.8, num_updates=66000, lr=0.000123091, gnorm=1.206, train_wall=23, wall=0
2024-07-12 21:59:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 21:59:22 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 4.033 | nll_loss 2.453 | ppl 5.48 | wps 44758.1 | wpb 2685.2 | bsz 107.1 | num_updates 66000 | best_loss 11.022
2024-07-12 21:59:22 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 21:59:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_59_66000.pt (epoch 59 @ 66000 updates, score 4.033) (writing took 4.760126982815564 seconds)
2024-07-12 21:59:50 | INFO | train_inner | epoch 059:    444 / 1132 loss=2.908, nll_loss=1.291, ppl=2.45, wps=11159, ups=3.13, wpb=3560.4, bsz=143, num_updates=66100, lr=0.000122998, gnorm=1.176, train_wall=23, wall=0
2024-07-12 22:00:13 | INFO | train_inner | epoch 059:    544 / 1132 loss=2.939, nll_loss=1.324, ppl=2.5, wps=15532.7, ups=4.31, wpb=3600.2, bsz=137.6, num_updates=66200, lr=0.000122905, gnorm=1.206, train_wall=23, wall=0
2024-07-12 22:00:36 | INFO | train_inner | epoch 059:    644 / 1132 loss=2.949, nll_loss=1.337, ppl=2.53, wps=15632.2, ups=4.29, wpb=3641.4, bsz=132.6, num_updates=66300, lr=0.000122813, gnorm=1.176, train_wall=23, wall=0
2024-07-12 22:00:59 | INFO | train_inner | epoch 059:    744 / 1132 loss=2.943, nll_loss=1.331, ppl=2.52, wps=15578.8, ups=4.33, wpb=3597.4, bsz=143, num_updates=66400, lr=0.00012272, gnorm=1.191, train_wall=23, wall=0
2024-07-12 22:01:22 | INFO | train_inner | epoch 059:    844 / 1132 loss=2.945, nll_loss=1.334, ppl=2.52, wps=15883.2, ups=4.39, wpb=3614.3, bsz=154.2, num_updates=66500, lr=0.000122628, gnorm=1.188, train_wall=23, wall=0
2024-07-12 22:01:46 | INFO | train_inner | epoch 059:    944 / 1132 loss=2.974, nll_loss=1.368, ppl=2.58, wps=15515.8, ups=4.29, wpb=3619.7, bsz=130.2, num_updates=66600, lr=0.000122536, gnorm=1.197, train_wall=23, wall=0
2024-07-12 22:02:08 | INFO | train_inner | epoch 059:   1044 / 1132 loss=2.935, nll_loss=1.323, ppl=2.5, wps=15820.6, ups=4.42, wpb=3579.1, bsz=159, num_updates=66700, lr=0.000122444, gnorm=1.181, train_wall=22, wall=0
2024-07-12 22:02:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:02:33 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 4.008 | nll_loss 2.432 | ppl 5.4 | wps 44897 | wpb 2685.2 | bsz 107.1 | num_updates 66788 | best_loss 11.022
2024-07-12 22:02:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:02:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 59 @ 66788 updates, score 4.008) (writing took 3.6565921641886234 seconds)
2024-07-12 22:02:36 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2024-07-12 22:02:36 | INFO | train | epoch 059 | loss 2.926 | nll_loss 1.311 | ppl 2.48 | wps 14549.9 | ups 4.09 | wpb 3556.4 | bsz 141.6 | num_updates 66788 | lr 0.000122363 | gnorm 1.191 | train_wall 258 | wall 0
2024-07-12 22:02:36 | INFO | fairseq.trainer | begin training epoch 60
2024-07-12 22:02:39 | INFO | train_inner | epoch 060:     12 / 1132 loss=2.936, nll_loss=1.323, ppl=2.5, wps=11454.8, ups=3.21, wpb=3563.4, bsz=151.4, num_updates=66800, lr=0.000122352, gnorm=1.184, train_wall=23, wall=0
2024-07-12 22:03:02 | INFO | train_inner | epoch 060:    112 / 1132 loss=2.857, nll_loss=1.234, ppl=2.35, wps=15758.6, ups=4.38, wpb=3598.1, bsz=153.1, num_updates=66900, lr=0.000122261, gnorm=1.16, train_wall=23, wall=0
2024-07-12 22:03:25 | INFO | train_inner | epoch 060:    212 / 1132 loss=2.88, nll_loss=1.256, ppl=2.39, wps=15273.1, ups=4.36, wpb=3500.3, bsz=146.6, num_updates=67000, lr=0.000122169, gnorm=1.179, train_wall=23, wall=0
2024-07-12 22:03:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:03:29 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 4.045 | nll_loss 2.466 | ppl 5.52 | wps 44926.2 | wpb 2685.2 | bsz 107.1 | num_updates 67000 | best_loss 11.022
2024-07-12 22:03:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:03:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_60_67000.pt (epoch 60 @ 67000 updates, score 4.045) (writing took 4.468285211361945 seconds)
2024-07-12 22:03:56 | INFO | train_inner | epoch 060:    312 / 1132 loss=2.902, nll_loss=1.284, ppl=2.44, wps=11487.3, ups=3.19, wpb=3604.4, bsz=145.2, num_updates=67100, lr=0.000122078, gnorm=1.178, train_wall=23, wall=0
2024-07-12 22:04:19 | INFO | train_inner | epoch 060:    412 / 1132 loss=2.919, nll_loss=1.3, ppl=2.46, wps=15313.5, ups=4.34, wpb=3527.1, bsz=128.9, num_updates=67200, lr=0.000121988, gnorm=1.22, train_wall=23, wall=0
2024-07-12 22:04:42 | INFO | train_inner | epoch 060:    512 / 1132 loss=2.92, nll_loss=1.304, ppl=2.47, wps=15863.6, ups=4.43, wpb=3578.3, bsz=134.6, num_updates=67300, lr=0.000121897, gnorm=1.183, train_wall=22, wall=0
2024-07-12 22:05:05 | INFO | train_inner | epoch 060:    612 / 1132 loss=2.91, nll_loss=1.292, ppl=2.45, wps=15421.8, ups=4.35, wpb=3548.4, bsz=156.2, num_updates=67400, lr=0.000121806, gnorm=1.189, train_wall=23, wall=0
2024-07-12 22:05:28 | INFO | train_inner | epoch 060:    712 / 1132 loss=2.942, nll_loss=1.328, ppl=2.51, wps=15546.1, ups=4.38, wpb=3549.7, bsz=130.2, num_updates=67500, lr=0.000121716, gnorm=1.218, train_wall=23, wall=0
2024-07-12 22:05:51 | INFO | train_inner | epoch 060:    812 / 1132 loss=2.939, nll_loss=1.325, ppl=2.51, wps=15358.9, ups=4.31, wpb=3563.6, bsz=139.4, num_updates=67600, lr=0.000121626, gnorm=1.206, train_wall=23, wall=0
2024-07-12 22:06:14 | INFO | train_inner | epoch 060:    912 / 1132 loss=2.939, nll_loss=1.327, ppl=2.51, wps=15664.5, ups=4.37, wpb=3585.3, bsz=148.6, num_updates=67700, lr=0.000121536, gnorm=1.2, train_wall=23, wall=0
2024-07-12 22:06:37 | INFO | train_inner | epoch 060:   1012 / 1132 loss=2.948, nll_loss=1.336, ppl=2.52, wps=15374.9, ups=4.35, wpb=3537.4, bsz=132.6, num_updates=67800, lr=0.000121447, gnorm=1.213, train_wall=23, wall=0
2024-07-12 22:06:59 | INFO | train_inner | epoch 060:   1112 / 1132 loss=2.935, nll_loss=1.321, ppl=2.5, wps=15453.2, ups=4.45, wpb=3472.9, bsz=138, num_updates=67900, lr=0.000121357, gnorm=1.227, train_wall=22, wall=0
2024-07-12 22:07:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:07:08 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 4.014 | nll_loss 2.437 | ppl 5.42 | wps 45011 | wpb 2685.2 | bsz 107.1 | num_updates 67920 | best_loss 11.022
2024-07-12 22:07:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:07:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 60 @ 67920 updates, score 4.014) (writing took 4.1471107099205256 seconds)
2024-07-12 22:07:12 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2024-07-12 22:07:12 | INFO | train | epoch 060 | loss 2.918 | nll_loss 1.301 | ppl 2.46 | wps 14579.3 | ups 4.1 | wpb 3556.4 | bsz 141.6 | num_updates 67920 | lr 0.000121339 | gnorm 1.196 | train_wall 257 | wall 0
2024-07-12 22:07:12 | INFO | fairseq.trainer | begin training epoch 61
2024-07-12 22:07:31 | INFO | train_inner | epoch 061:     80 / 1132 loss=2.88, nll_loss=1.258, ppl=2.39, wps=11269.2, ups=3.17, wpb=3551, bsz=137.3, num_updates=68000, lr=0.000121268, gnorm=1.174, train_wall=23, wall=0
2024-07-12 22:07:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:07:35 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 4.039 | nll_loss 2.458 | ppl 5.49 | wps 44601.6 | wpb 2685.2 | bsz 107.1 | num_updates 68000 | best_loss 11.022
2024-07-12 22:07:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:07:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_61_68000.pt (epoch 61 @ 68000 updates, score 4.039) (writing took 4.852189899422228 seconds)
2024-07-12 22:08:02 | INFO | train_inner | epoch 061:    180 / 1132 loss=2.86, nll_loss=1.235, ppl=2.35, wps=11113.8, ups=3.17, wpb=3511.3, bsz=145.8, num_updates=68100, lr=0.000121179, gnorm=1.17, train_wall=22, wall=0
2024-07-12 22:08:25 | INFO | train_inner | epoch 061:    280 / 1132 loss=2.887, nll_loss=1.264, ppl=2.4, wps=15412.3, ups=4.35, wpb=3543.4, bsz=140.6, num_updates=68200, lr=0.00012109, gnorm=1.201, train_wall=23, wall=0
2024-07-12 22:08:48 | INFO | train_inner | epoch 061:    380 / 1132 loss=2.892, nll_loss=1.269, ppl=2.41, wps=15466.1, ups=4.42, wpb=3500.5, bsz=139.3, num_updates=68300, lr=0.000121001, gnorm=1.201, train_wall=22, wall=0
2024-07-12 22:09:11 | INFO | train_inner | epoch 061:    480 / 1132 loss=2.903, nll_loss=1.286, ppl=2.44, wps=15758, ups=4.39, wpb=3588, bsz=144.2, num_updates=68400, lr=0.000120913, gnorm=1.179, train_wall=23, wall=0
2024-07-12 22:09:34 | INFO | train_inner | epoch 061:    580 / 1132 loss=2.915, nll_loss=1.298, ppl=2.46, wps=15725.1, ups=4.32, wpb=3636, bsz=149.8, num_updates=68500, lr=0.000120824, gnorm=1.184, train_wall=23, wall=0
2024-07-12 22:09:57 | INFO | train_inner | epoch 061:    680 / 1132 loss=2.93, nll_loss=1.313, ppl=2.48, wps=15190.6, ups=4.33, wpb=3508.8, bsz=129.4, num_updates=68600, lr=0.000120736, gnorm=1.246, train_wall=23, wall=0
2024-07-12 22:10:20 | INFO | train_inner | epoch 061:    780 / 1132 loss=2.918, nll_loss=1.302, ppl=2.47, wps=15321.1, ups=4.32, wpb=3547.7, bsz=142.8, num_updates=68700, lr=0.000120648, gnorm=1.205, train_wall=23, wall=0
2024-07-12 22:10:44 | INFO | train_inner | epoch 061:    880 / 1132 loss=2.927, nll_loss=1.314, ppl=2.49, wps=15548.2, ups=4.29, wpb=3628.4, bsz=149.8, num_updates=68800, lr=0.000120561, gnorm=1.176, train_wall=23, wall=0
2024-07-12 22:11:06 | INFO | train_inner | epoch 061:    980 / 1132 loss=2.943, nll_loss=1.332, ppl=2.52, wps=15823.4, ups=4.39, wpb=3606.2, bsz=140.7, num_updates=68900, lr=0.000120473, gnorm=1.198, train_wall=23, wall=0
2024-07-12 22:11:29 | INFO | train_inner | epoch 061:   1080 / 1132 loss=2.946, nll_loss=1.332, ppl=2.52, wps=15378.9, ups=4.38, wpb=3508.1, bsz=129.8, num_updates=69000, lr=0.000120386, gnorm=1.238, train_wall=23, wall=0
2024-07-12 22:11:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:11:33 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 4.026 | nll_loss 2.449 | ppl 5.46 | wps 44978.9 | wpb 2685.2 | bsz 107.1 | num_updates 69000 | best_loss 11.022
2024-07-12 22:11:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:11:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_61_69000.pt (epoch 61 @ 69000 updates, score 4.026) (writing took 4.476190290413797 seconds)
2024-07-12 22:11:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:11:54 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 4.04 | nll_loss 2.46 | ppl 5.5 | wps 44726.5 | wpb 2685.2 | bsz 107.1 | num_updates 69052 | best_loss 11.022
2024-07-12 22:11:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:11:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 61 @ 69052 updates, score 4.04) (writing took 3.510754874907434 seconds)
2024-07-12 22:11:58 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2024-07-12 22:11:58 | INFO | train | epoch 061 | loss 2.909 | nll_loss 1.291 | ppl 2.45 | wps 14103.9 | ups 3.97 | wpb 3556.4 | bsz 141.6 | num_updates 69052 | lr 0.000120341 | gnorm 1.197 | train_wall 258 | wall 0
2024-07-12 22:11:58 | INFO | fairseq.trainer | begin training epoch 62
2024-07-12 22:12:09 | INFO | train_inner | epoch 062:     48 / 1132 loss=2.883, nll_loss=1.264, ppl=2.4, wps=9080.2, ups=2.52, wpb=3606.7, bsz=157.9, num_updates=69100, lr=0.000120299, gnorm=1.156, train_wall=23, wall=0
2024-07-12 22:12:32 | INFO | train_inner | epoch 062:    148 / 1132 loss=2.847, nll_loss=1.221, ppl=2.33, wps=15675, ups=4.39, wpb=3569.7, bsz=152.9, num_updates=69200, lr=0.000120212, gnorm=1.146, train_wall=23, wall=0
2024-07-12 22:12:55 | INFO | train_inner | epoch 062:    248 / 1132 loss=2.877, nll_loss=1.254, ppl=2.39, wps=15778.2, ups=4.32, wpb=3653.1, bsz=153.5, num_updates=69300, lr=0.000120125, gnorm=1.161, train_wall=23, wall=0
2024-07-12 22:13:18 | INFO | train_inner | epoch 062:    348 / 1132 loss=2.883, nll_loss=1.262, ppl=2.4, wps=15515.1, ups=4.37, wpb=3553.5, bsz=153.2, num_updates=69400, lr=0.000120038, gnorm=1.176, train_wall=23, wall=0
2024-07-12 22:13:41 | INFO | train_inner | epoch 062:    448 / 1132 loss=2.912, nll_loss=1.292, ppl=2.45, wps=15730.6, ups=4.4, wpb=3577.9, bsz=127.8, num_updates=69500, lr=0.000119952, gnorm=1.231, train_wall=23, wall=0
2024-07-12 22:14:03 | INFO | train_inner | epoch 062:    548 / 1132 loss=2.894, nll_loss=1.273, ppl=2.42, wps=15632.3, ups=4.4, wpb=3552.6, bsz=140.6, num_updates=69600, lr=0.000119866, gnorm=1.194, train_wall=23, wall=0
2024-07-12 22:14:26 | INFO | train_inner | epoch 062:    648 / 1132 loss=2.917, nll_loss=1.301, ppl=2.46, wps=15803.8, ups=4.4, wpb=3590, bsz=128.6, num_updates=69700, lr=0.00011978, gnorm=1.205, train_wall=23, wall=0
2024-07-12 22:14:49 | INFO | train_inner | epoch 062:    748 / 1132 loss=2.929, nll_loss=1.312, ppl=2.48, wps=15442.5, ups=4.35, wpb=3549.7, bsz=135.2, num_updates=69800, lr=0.000119694, gnorm=1.23, train_wall=23, wall=0
2024-07-12 22:15:12 | INFO | train_inner | epoch 062:    848 / 1132 loss=2.905, nll_loss=1.288, ppl=2.44, wps=15329.6, ups=4.37, wpb=3505.9, bsz=137, num_updates=69900, lr=0.000119608, gnorm=1.237, train_wall=23, wall=0
2024-07-12 22:15:35 | INFO | train_inner | epoch 062:    948 / 1132 loss=2.918, nll_loss=1.298, ppl=2.46, wps=14854.2, ups=4.36, wpb=3408.8, bsz=127.6, num_updates=70000, lr=0.000119523, gnorm=1.247, train_wall=23, wall=0
2024-07-12 22:15:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:15:39 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 4.033 | nll_loss 2.459 | ppl 5.5 | wps 44442.6 | wpb 2685.2 | bsz 107.1 | num_updates 70000 | best_loss 11.022
2024-07-12 22:15:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:15:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_62_70000.pt (epoch 62 @ 70000 updates, score 4.033) (writing took 4.397070076316595 seconds)
2024-07-12 22:16:06 | INFO | train_inner | epoch 062:   1048 / 1132 loss=2.913, nll_loss=1.299, ppl=2.46, wps=11366.7, ups=3.17, wpb=3580.7, bsz=156.2, num_updates=70100, lr=0.000119438, gnorm=1.185, train_wall=23, wall=0
2024-07-12 22:16:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:16:30 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 4.034 | nll_loss 2.457 | ppl 5.49 | wps 44617.2 | wpb 2685.2 | bsz 107.1 | num_updates 70184 | best_loss 11.022
2024-07-12 22:16:30 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:16:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 62 @ 70184 updates, score 4.034) (writing took 4.021032756194472 seconds)
2024-07-12 22:16:34 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2024-07-12 22:16:34 | INFO | train | epoch 062 | loss 2.9 | nll_loss 1.281 | ppl 2.43 | wps 14595 | ups 4.1 | wpb 3556.4 | bsz 141.6 | num_updates 70184 | lr 0.000119366 | gnorm 1.2 | train_wall 257 | wall 0
2024-07-12 22:16:34 | INFO | fairseq.trainer | begin training epoch 63
2024-07-12 22:16:38 | INFO | train_inner | epoch 063:     16 / 1132 loss=2.931, nll_loss=1.317, ppl=2.49, wps=11394.3, ups=3.2, wpb=3562, bsz=135.4, num_updates=70200, lr=0.000119352, gnorm=1.216, train_wall=23, wall=0
2024-07-12 22:17:00 | INFO | train_inner | epoch 063:    116 / 1132 loss=2.859, nll_loss=1.231, ppl=2.35, wps=15463.6, ups=4.38, wpb=3529.3, bsz=124.6, num_updates=70300, lr=0.000119268, gnorm=1.191, train_wall=23, wall=0
2024-07-12 22:17:24 | INFO | train_inner | epoch 063:    216 / 1132 loss=2.859, nll_loss=1.235, ppl=2.35, wps=15092.1, ups=4.25, wpb=3548.6, bsz=131.3, num_updates=70400, lr=0.000119183, gnorm=1.205, train_wall=23, wall=0
2024-07-12 22:17:47 | INFO | train_inner | epoch 063:    316 / 1132 loss=2.864, nll_loss=1.24, ppl=2.36, wps=15713.5, ups=4.35, wpb=3615, bsz=162.6, num_updates=70500, lr=0.000119098, gnorm=1.163, train_wall=23, wall=0
2024-07-12 22:18:10 | INFO | train_inner | epoch 063:    416 / 1132 loss=2.886, nll_loss=1.266, ppl=2.4, wps=15727.9, ups=4.37, wpb=3596.7, bsz=140.9, num_updates=70600, lr=0.000119014, gnorm=1.196, train_wall=23, wall=0
2024-07-12 22:18:32 | INFO | train_inner | epoch 063:    516 / 1132 loss=2.9, nll_loss=1.28, ppl=2.43, wps=15985.2, ups=4.49, wpb=3559.4, bsz=134.4, num_updates=70700, lr=0.00011893, gnorm=1.206, train_wall=22, wall=0
2024-07-12 22:18:55 | INFO | train_inner | epoch 063:    616 / 1132 loss=2.886, nll_loss=1.265, ppl=2.4, wps=15539, ups=4.37, wpb=3559.5, bsz=153.3, num_updates=70800, lr=0.000118846, gnorm=1.21, train_wall=23, wall=0
2024-07-12 22:19:17 | INFO | train_inner | epoch 063:    716 / 1132 loss=2.906, nll_loss=1.286, ppl=2.44, wps=15516.4, ups=4.46, wpb=3478.9, bsz=132.6, num_updates=70900, lr=0.000118762, gnorm=1.235, train_wall=22, wall=0
2024-07-12 22:19:40 | INFO | train_inner | epoch 063:    816 / 1132 loss=2.902, nll_loss=1.284, ppl=2.44, wps=15796.4, ups=4.37, wpb=3612.6, bsz=155.9, num_updates=71000, lr=0.000118678, gnorm=1.193, train_wall=23, wall=0
2024-07-12 22:19:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:19:44 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 4.025 | nll_loss 2.451 | ppl 5.47 | wps 44886.7 | wpb 2685.2 | bsz 107.1 | num_updates 71000 | best_loss 11.022
2024-07-12 22:19:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:19:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_63_71000.pt (epoch 63 @ 71000 updates, score 4.025) (writing took 4.667503728531301 seconds)
2024-07-12 22:20:12 | INFO | train_inner | epoch 063:    916 / 1132 loss=2.917, nll_loss=1.302, ppl=2.47, wps=11352.8, ups=3.16, wpb=3595.5, bsz=147.8, num_updates=71100, lr=0.000118595, gnorm=1.195, train_wall=23, wall=0
2024-07-12 22:20:35 | INFO | train_inner | epoch 063:   1016 / 1132 loss=2.913, nll_loss=1.297, ppl=2.46, wps=15291.9, ups=4.39, wpb=3483.7, bsz=148.4, num_updates=71200, lr=0.000118511, gnorm=1.248, train_wall=23, wall=0
2024-07-12 22:20:57 | INFO | train_inner | epoch 063:   1116 / 1132 loss=2.932, nll_loss=1.316, ppl=2.49, wps=15598.1, ups=4.42, wpb=3529.1, bsz=128.2, num_updates=71300, lr=0.000118428, gnorm=1.238, train_wall=22, wall=0
2024-07-12 22:21:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:21:05 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 4.029 | nll_loss 2.455 | ppl 5.48 | wps 44752.1 | wpb 2685.2 | bsz 107.1 | num_updates 71316 | best_loss 11.022
2024-07-12 22:21:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:21:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 63 @ 71316 updates, score 4.029) (writing took 3.6929027596488595 seconds)
2024-07-12 22:21:09 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2024-07-12 22:21:09 | INFO | train | epoch 063 | loss 2.893 | nll_loss 1.273 | ppl 2.42 | wps 14626.4 | ups 4.11 | wpb 3556.4 | bsz 141.6 | num_updates 71316 | lr 0.000118415 | gnorm 1.207 | train_wall 256 | wall 0
2024-07-12 22:21:09 | INFO | fairseq.trainer | begin training epoch 64
2024-07-12 22:21:28 | INFO | train_inner | epoch 064:     84 / 1132 loss=2.86, nll_loss=1.232, ppl=2.35, wps=11412.1, ups=3.27, wpb=3491.5, bsz=131.4, num_updates=71400, lr=0.000118345, gnorm=1.202, train_wall=22, wall=0
2024-07-12 22:21:50 | INFO | train_inner | epoch 064:    184 / 1132 loss=2.842, nll_loss=1.216, ppl=2.32, wps=16437.9, ups=4.55, wpb=3616.5, bsz=154.7, num_updates=71500, lr=0.000118262, gnorm=1.145, train_wall=22, wall=0
2024-07-12 22:22:14 | INFO | train_inner | epoch 064:    284 / 1132 loss=2.869, nll_loss=1.245, ppl=2.37, wps=15240.4, ups=4.21, wpb=3616.5, bsz=141.4, num_updates=71600, lr=0.00011818, gnorm=1.193, train_wall=24, wall=0
2024-07-12 22:22:36 | INFO | train_inner | epoch 064:    384 / 1132 loss=2.865, nll_loss=1.242, ppl=2.37, wps=15722.6, ups=4.38, wpb=3587.2, bsz=146.5, num_updates=71700, lr=0.000118097, gnorm=1.186, train_wall=23, wall=0
2024-07-12 22:22:59 | INFO | train_inner | epoch 064:    484 / 1132 loss=2.872, nll_loss=1.247, ppl=2.37, wps=15674.5, ups=4.47, wpb=3507.3, bsz=143.4, num_updates=71800, lr=0.000118015, gnorm=1.218, train_wall=22, wall=0
2024-07-12 22:23:21 | INFO | train_inner | epoch 064:    584 / 1132 loss=2.881, nll_loss=1.258, ppl=2.39, wps=15854.7, ups=4.51, wpb=3513.5, bsz=138.8, num_updates=71900, lr=0.000117933, gnorm=1.222, train_wall=22, wall=0
2024-07-12 22:23:43 | INFO | train_inner | epoch 064:    684 / 1132 loss=2.889, nll_loss=1.269, ppl=2.41, wps=16013.4, ups=4.57, wpb=3507.2, bsz=145.8, num_updates=72000, lr=0.000117851, gnorm=1.236, train_wall=22, wall=0
2024-07-12 22:23:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:23:47 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 4.054 | nll_loss 2.479 | ppl 5.57 | wps 44978.6 | wpb 2685.2 | bsz 107.1 | num_updates 72000 | best_loss 11.022
2024-07-12 22:23:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:23:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_64_72000.pt (epoch 64 @ 72000 updates, score 4.054) (writing took 5.932106004096568 seconds)
2024-07-12 22:24:15 | INFO | train_inner | epoch 064:    784 / 1132 loss=2.911, nll_loss=1.292, ppl=2.45, wps=10892.7, ups=3.08, wpb=3531.9, bsz=132, num_updates=72100, lr=0.000117769, gnorm=1.276, train_wall=22, wall=0
2024-07-12 22:24:38 | INFO | train_inner | epoch 064:    884 / 1132 loss=2.912, nll_loss=1.296, ppl=2.46, wps=15770.4, ups=4.36, wpb=3616.7, bsz=139.2, num_updates=72200, lr=0.000117688, gnorm=1.198, train_wall=23, wall=0
2024-07-12 22:25:02 | INFO | train_inner | epoch 064:    984 / 1132 loss=2.909, nll_loss=1.291, ppl=2.45, wps=15014.1, ups=4.27, wpb=3517.2, bsz=137.9, num_updates=72300, lr=0.000117606, gnorm=1.242, train_wall=23, wall=0
2024-07-12 22:25:25 | INFO | train_inner | epoch 064:   1084 / 1132 loss=2.921, nll_loss=1.305, ppl=2.47, wps=15677.8, ups=4.35, wpb=3601.5, bsz=139.8, num_updates=72400, lr=0.000117525, gnorm=1.207, train_wall=23, wall=0
2024-07-12 22:25:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:25:40 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 4.025 | nll_loss 2.45 | ppl 5.46 | wps 44570.5 | wpb 2685.2 | bsz 107.1 | num_updates 72448 | best_loss 11.022
2024-07-12 22:25:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:25:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 64 @ 72448 updates, score 4.025) (writing took 4.882892905734479 seconds)
2024-07-12 22:25:45 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2024-07-12 22:25:45 | INFO | train | epoch 064 | loss 2.885 | nll_loss 1.263 | ppl 2.4 | wps 14563.6 | ups 4.1 | wpb 3556.4 | bsz 141.6 | num_updates 72448 | lr 0.000117486 | gnorm 1.21 | train_wall 255 | wall 0
2024-07-12 22:25:45 | INFO | fairseq.trainer | begin training epoch 65
2024-07-12 22:25:57 | INFO | train_inner | epoch 065:     52 / 1132 loss=2.882, nll_loss=1.26, ppl=2.4, wps=11007.5, ups=3.05, wpb=3614.4, bsz=144.1, num_updates=72500, lr=0.000117444, gnorm=1.184, train_wall=23, wall=0
2024-07-12 22:26:20 | INFO | train_inner | epoch 065:    152 / 1132 loss=2.825, nll_loss=1.193, ppl=2.29, wps=15234.2, ups=4.39, wpb=3469.7, bsz=139.3, num_updates=72600, lr=0.000117363, gnorm=1.196, train_wall=23, wall=0
2024-07-12 22:26:43 | INFO | train_inner | epoch 065:    252 / 1132 loss=2.852, nll_loss=1.223, ppl=2.34, wps=15628.5, ups=4.46, wpb=3503.3, bsz=130.5, num_updates=72700, lr=0.000117282, gnorm=1.227, train_wall=22, wall=0
2024-07-12 22:27:05 | INFO | train_inner | epoch 065:    352 / 1132 loss=2.871, nll_loss=1.246, ppl=2.37, wps=15486.5, ups=4.41, wpb=3508.5, bsz=135.5, num_updates=72800, lr=0.000117202, gnorm=1.253, train_wall=22, wall=0
2024-07-12 22:27:28 | INFO | train_inner | epoch 065:    452 / 1132 loss=2.864, nll_loss=1.24, ppl=2.36, wps=15771.2, ups=4.42, wpb=3564.1, bsz=143, num_updates=72900, lr=0.000117121, gnorm=1.184, train_wall=22, wall=0
2024-07-12 22:27:51 | INFO | train_inner | epoch 065:    552 / 1132 loss=2.882, nll_loss=1.262, ppl=2.4, wps=15968.7, ups=4.36, wpb=3659.5, bsz=153, num_updates=73000, lr=0.000117041, gnorm=1.177, train_wall=23, wall=0
2024-07-12 22:27:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:27:55 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 4.045 | nll_loss 2.472 | ppl 5.55 | wps 44936.6 | wpb 2685.2 | bsz 107.1 | num_updates 73000 | best_loss 11.022
2024-07-12 22:27:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:28:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_65_73000.pt (epoch 65 @ 73000 updates, score 4.045) (writing took 6.288945708423853 seconds)
2024-07-12 22:28:24 | INFO | train_inner | epoch 065:    652 / 1132 loss=2.893, nll_loss=1.272, ppl=2.42, wps=10758.9, ups=2.98, wpb=3607.3, bsz=142.2, num_updates=73100, lr=0.000116961, gnorm=1.223, train_wall=23, wall=0
2024-07-12 22:28:47 | INFO | train_inner | epoch 065:    752 / 1132 loss=2.87, nll_loss=1.248, ppl=2.38, wps=15530.3, ups=4.36, wpb=3562.7, bsz=157.4, num_updates=73200, lr=0.000116881, gnorm=1.194, train_wall=23, wall=0
2024-07-12 22:29:10 | INFO | train_inner | epoch 065:    852 / 1132 loss=2.906, nll_loss=1.286, ppl=2.44, wps=15630.2, ups=4.42, wpb=3533.6, bsz=129, num_updates=73300, lr=0.000116801, gnorm=1.249, train_wall=22, wall=0
2024-07-12 22:29:33 | INFO | train_inner | epoch 065:    952 / 1132 loss=2.896, nll_loss=1.276, ppl=2.42, wps=15594.7, ups=4.39, wpb=3555.6, bsz=146.2, num_updates=73400, lr=0.000116722, gnorm=1.217, train_wall=23, wall=0
2024-07-12 22:29:55 | INFO | train_inner | epoch 065:   1052 / 1132 loss=2.895, nll_loss=1.278, ppl=2.42, wps=15680.1, ups=4.42, wpb=3544.6, bsz=153, num_updates=73500, lr=0.000116642, gnorm=1.231, train_wall=22, wall=0
2024-07-12 22:30:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:30:18 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 4.039 | nll_loss 2.463 | ppl 5.51 | wps 44756.5 | wpb 2685.2 | bsz 107.1 | num_updates 73580 | best_loss 11.022
2024-07-12 22:30:18 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:30:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 65 @ 73580 updates, score 4.039) (writing took 4.973191540688276 seconds)
2024-07-12 22:30:23 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2024-07-12 22:30:23 | INFO | train | epoch 065 | loss 2.878 | nll_loss 1.255 | ppl 2.39 | wps 14515.6 | ups 4.08 | wpb 3556.4 | bsz 141.6 | num_updates 73580 | lr 0.000116579 | gnorm 1.213 | train_wall 256 | wall 0
2024-07-12 22:30:23 | INFO | fairseq.trainer | begin training epoch 66
2024-07-12 22:30:27 | INFO | train_inner | epoch 066:     20 / 1132 loss=2.902, nll_loss=1.285, ppl=2.44, wps=11187, ups=3.11, wpb=3596.8, bsz=128.6, num_updates=73600, lr=0.000116563, gnorm=1.197, train_wall=23, wall=0
2024-07-12 22:30:51 | INFO | train_inner | epoch 066:    120 / 1132 loss=2.812, nll_loss=1.182, ppl=2.27, wps=15685.3, ups=4.34, wpb=3613.6, bsz=171.1, num_updates=73700, lr=0.000116484, gnorm=1.158, train_wall=23, wall=0
2024-07-12 22:31:13 | INFO | train_inner | epoch 066:    220 / 1132 loss=2.846, nll_loss=1.219, ppl=2.33, wps=15630.7, ups=4.35, wpb=3592.6, bsz=145.5, num_updates=73800, lr=0.000116405, gnorm=1.19, train_wall=23, wall=0
2024-07-12 22:31:36 | INFO | train_inner | epoch 066:    320 / 1132 loss=2.847, nll_loss=1.221, ppl=2.33, wps=15806.7, ups=4.41, wpb=3585.4, bsz=150.4, num_updates=73900, lr=0.000116326, gnorm=1.19, train_wall=23, wall=0
2024-07-12 22:31:59 | INFO | train_inner | epoch 066:    420 / 1132 loss=2.856, nll_loss=1.228, ppl=2.34, wps=15278.6, ups=4.43, wpb=3448.5, bsz=123.6, num_updates=74000, lr=0.000116248, gnorm=1.243, train_wall=22, wall=0
2024-07-12 22:31:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:32:03 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 4.066 | nll_loss 2.49 | ppl 5.62 | wps 44630.9 | wpb 2685.2 | bsz 107.1 | num_updates 74000 | best_loss 11.022
2024-07-12 22:32:03 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:32:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_66_74000.pt (epoch 66 @ 74000 updates, score 4.066) (writing took 5.906245230697095 seconds)
2024-07-12 22:32:32 | INFO | train_inner | epoch 066:    520 / 1132 loss=2.874, nll_loss=1.25, ppl=2.38, wps=10739.5, ups=2.98, wpb=3606.1, bsz=131.8, num_updates=74100, lr=0.000116169, gnorm=1.214, train_wall=23, wall=0
2024-07-12 22:32:55 | INFO | train_inner | epoch 066:    620 / 1132 loss=2.89, nll_loss=1.268, ppl=2.41, wps=15700.1, ups=4.45, wpb=3529.8, bsz=123.1, num_updates=74200, lr=0.000116091, gnorm=1.251, train_wall=22, wall=0
2024-07-12 22:33:18 | INFO | train_inner | epoch 066:    720 / 1132 loss=2.879, nll_loss=1.253, ppl=2.38, wps=15286.8, ups=4.36, wpb=3505.3, bsz=140.4, num_updates=74300, lr=0.000116013, gnorm=1.249, train_wall=23, wall=0
2024-07-12 22:33:40 | INFO | train_inner | epoch 066:    820 / 1132 loss=2.884, nll_loss=1.263, ppl=2.4, wps=15504.1, ups=4.43, wpb=3499.3, bsz=142.3, num_updates=74400, lr=0.000115935, gnorm=1.26, train_wall=22, wall=0
2024-07-12 22:34:03 | INFO | train_inner | epoch 066:    920 / 1132 loss=2.888, nll_loss=1.267, ppl=2.41, wps=15610.5, ups=4.39, wpb=3558.3, bsz=145.5, num_updates=74500, lr=0.000115857, gnorm=1.211, train_wall=23, wall=0
2024-07-12 22:34:26 | INFO | train_inner | epoch 066:   1020 / 1132 loss=2.899, nll_loss=1.284, ppl=2.43, wps=15817, ups=4.4, wpb=3598.5, bsz=148.6, num_updates=74600, lr=0.000115779, gnorm=1.204, train_wall=23, wall=0
2024-07-12 22:34:49 | INFO | train_inner | epoch 066:   1120 / 1132 loss=2.899, nll_loss=1.279, ppl=2.43, wps=15500.6, ups=4.36, wpb=3552.9, bsz=139.9, num_updates=74700, lr=0.000115702, gnorm=1.229, train_wall=23, wall=0
2024-07-12 22:34:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:34:56 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 4.045 | nll_loss 2.475 | ppl 5.56 | wps 45031.3 | wpb 2685.2 | bsz 107.1 | num_updates 74712 | best_loss 11.022
2024-07-12 22:34:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:35:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 66 @ 74712 updates, score 4.045) (writing took 5.009802204556763 seconds)
2024-07-12 22:35:01 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2024-07-12 22:35:01 | INFO | train | epoch 066 | loss 2.871 | nll_loss 1.247 | ppl 2.37 | wps 14480.7 | ups 4.07 | wpb 3556.4 | bsz 141.6 | num_updates 74712 | lr 0.000115692 | gnorm 1.217 | train_wall 257 | wall 0
2024-07-12 22:35:01 | INFO | fairseq.trainer | begin training epoch 67
2024-07-12 22:35:21 | INFO | train_inner | epoch 067:     88 / 1132 loss=2.843, nll_loss=1.215, ppl=2.32, wps=11083.5, ups=3.11, wpb=3568.5, bsz=131.8, num_updates=74800, lr=0.000115624, gnorm=1.191, train_wall=23, wall=0
2024-07-12 22:35:44 | INFO | train_inner | epoch 067:    188 / 1132 loss=2.823, nll_loss=1.193, ppl=2.29, wps=15725.3, ups=4.36, wpb=3606.7, bsz=158.3, num_updates=74900, lr=0.000115547, gnorm=1.174, train_wall=23, wall=0
2024-07-12 22:36:07 | INFO | train_inner | epoch 067:    288 / 1132 loss=2.834, nll_loss=1.205, ppl=2.31, wps=15401, ups=4.27, wpb=3607.3, bsz=149.8, num_updates=75000, lr=0.00011547, gnorm=1.178, train_wall=23, wall=0
2024-07-12 22:36:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:36:12 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 4.049 | nll_loss 2.478 | ppl 5.57 | wps 44748.8 | wpb 2685.2 | bsz 107.1 | num_updates 75000 | best_loss 11.022
2024-07-12 22:36:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:36:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_67_75000.pt (epoch 67 @ 75000 updates, score 4.049) (writing took 6.3105861227959394 seconds)
2024-07-12 22:36:40 | INFO | train_inner | epoch 067:    388 / 1132 loss=2.846, nll_loss=1.217, ppl=2.32, wps=10521.4, ups=3.03, wpb=3474.9, bsz=130.7, num_updates=75100, lr=0.000115393, gnorm=1.254, train_wall=22, wall=0
2024-07-12 22:37:03 | INFO | train_inner | epoch 067:    488 / 1132 loss=2.852, nll_loss=1.227, ppl=2.34, wps=15585.5, ups=4.42, wpb=3523.5, bsz=141.3, num_updates=75200, lr=0.000115316, gnorm=1.215, train_wall=22, wall=0
2024-07-12 22:37:25 | INFO | train_inner | epoch 067:    588 / 1132 loss=2.861, nll_loss=1.234, ppl=2.35, wps=15972.5, ups=4.49, wpb=3555.7, bsz=139.9, num_updates=75300, lr=0.00011524, gnorm=1.23, train_wall=22, wall=0
2024-07-12 22:37:48 | INFO | train_inner | epoch 067:    688 / 1132 loss=2.87, nll_loss=1.246, ppl=2.37, wps=15672.7, ups=4.35, wpb=3600.2, bsz=154.9, num_updates=75400, lr=0.000115163, gnorm=1.222, train_wall=23, wall=0
2024-07-12 22:38:11 | INFO | train_inner | epoch 067:    788 / 1132 loss=2.879, nll_loss=1.26, ppl=2.39, wps=15824.2, ups=4.46, wpb=3549.4, bsz=142.2, num_updates=75500, lr=0.000115087, gnorm=1.233, train_wall=22, wall=0
2024-07-12 22:38:33 | INFO | train_inner | epoch 067:    888 / 1132 loss=2.885, nll_loss=1.266, ppl=2.41, wps=16080.2, ups=4.48, wpb=3593.2, bsz=139.6, num_updates=75600, lr=0.000115011, gnorm=1.231, train_wall=22, wall=0
2024-07-12 22:38:56 | INFO | train_inner | epoch 067:    988 / 1132 loss=2.893, nll_loss=1.27, ppl=2.41, wps=14971, ups=4.4, wpb=3401.4, bsz=122.2, num_updates=75700, lr=0.000114935, gnorm=1.282, train_wall=23, wall=0
2024-07-12 22:39:19 | INFO | train_inner | epoch 067:   1088 / 1132 loss=2.897, nll_loss=1.279, ppl=2.43, wps=15750.2, ups=4.34, wpb=3625.8, bsz=146.5, num_updates=75800, lr=0.000114859, gnorm=1.203, train_wall=23, wall=0
2024-07-12 22:39:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:39:33 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 4.036 | nll_loss 2.464 | ppl 5.52 | wps 44833.3 | wpb 2685.2 | bsz 107.1 | num_updates 75844 | best_loss 11.022
2024-07-12 22:39:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:39:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 67 @ 75844 updates, score 4.036) (writing took 5.04653216060251 seconds)
2024-07-12 22:39:38 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2024-07-12 22:39:38 | INFO | train | epoch 067 | loss 2.863 | nll_loss 1.239 | ppl 2.36 | wps 14519 | ups 4.08 | wpb 3556.4 | bsz 141.6 | num_updates 75844 | lr 0.000114826 | gnorm 1.22 | train_wall 255 | wall 0
2024-07-12 22:39:38 | INFO | fairseq.trainer | begin training epoch 68
2024-07-12 22:39:52 | INFO | train_inner | epoch 068:     56 / 1132 loss=2.851, nll_loss=1.224, ppl=2.34, wps=10714.9, ups=3.04, wpb=3530.1, bsz=136.6, num_updates=75900, lr=0.000114783, gnorm=1.214, train_wall=23, wall=0
2024-07-12 22:40:14 | INFO | train_inner | epoch 068:    156 / 1132 loss=2.815, nll_loss=1.185, ppl=2.27, wps=15821.9, ups=4.44, wpb=3561.1, bsz=147.3, num_updates=76000, lr=0.000114708, gnorm=1.194, train_wall=22, wall=0
2024-07-12 22:40:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:40:18 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 4.074 | nll_loss 2.497 | ppl 5.65 | wps 44738.8 | wpb 2685.2 | bsz 107.1 | num_updates 76000 | best_loss 11.022
2024-07-12 22:40:18 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:40:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_68_76000.pt (epoch 68 @ 76000 updates, score 4.074) (writing took 6.228885313495994 seconds)
2024-07-12 22:40:47 | INFO | train_inner | epoch 068:    256 / 1132 loss=2.833, nll_loss=1.205, ppl=2.3, wps=10965.3, ups=3, wpb=3654.8, bsz=151.1, num_updates=76100, lr=0.000114632, gnorm=1.181, train_wall=23, wall=0
2024-07-12 22:41:10 | INFO | train_inner | epoch 068:    356 / 1132 loss=2.832, nll_loss=1.2, ppl=2.3, wps=15618.7, ups=4.44, wpb=3519.8, bsz=138.2, num_updates=76200, lr=0.000114557, gnorm=1.224, train_wall=22, wall=0
2024-07-12 22:41:33 | INFO | train_inner | epoch 068:    456 / 1132 loss=2.851, nll_loss=1.224, ppl=2.34, wps=15754.2, ups=4.44, wpb=3551.9, bsz=131.4, num_updates=76300, lr=0.000114482, gnorm=1.209, train_wall=22, wall=0
2024-07-12 22:41:55 | INFO | train_inner | epoch 068:    556 / 1132 loss=2.854, nll_loss=1.229, ppl=2.34, wps=15714.6, ups=4.39, wpb=3582.2, bsz=153.5, num_updates=76400, lr=0.000114407, gnorm=1.238, train_wall=23, wall=0
2024-07-12 22:42:18 | INFO | train_inner | epoch 068:    656 / 1132 loss=2.849, nll_loss=1.22, ppl=2.33, wps=15194.5, ups=4.45, wpb=3418.2, bsz=133.1, num_updates=76500, lr=0.000114332, gnorm=1.263, train_wall=22, wall=0
2024-07-12 22:42:41 | INFO | train_inner | epoch 068:    756 / 1132 loss=2.856, nll_loss=1.232, ppl=2.35, wps=15295.4, ups=4.27, wpb=3580.5, bsz=157, num_updates=76600, lr=0.000114258, gnorm=1.233, train_wall=23, wall=0
2024-07-12 22:43:04 | INFO | train_inner | epoch 068:    856 / 1132 loss=2.878, nll_loss=1.257, ppl=2.39, wps=15748.6, ups=4.35, wpb=3617.4, bsz=151.5, num_updates=76700, lr=0.000114183, gnorm=1.195, train_wall=23, wall=0
2024-07-12 22:43:27 | INFO | train_inner | epoch 068:    956 / 1132 loss=2.903, nll_loss=1.284, ppl=2.44, wps=15858.2, ups=4.36, wpb=3634.3, bsz=128.6, num_updates=76800, lr=0.000114109, gnorm=1.225, train_wall=23, wall=0
2024-07-12 22:43:50 | INFO | train_inner | epoch 068:   1056 / 1132 loss=2.888, nll_loss=1.267, ppl=2.41, wps=15729, ups=4.47, wpb=3515.1, bsz=121.4, num_updates=76900, lr=0.000114035, gnorm=1.259, train_wall=22, wall=0
2024-07-12 22:44:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:44:12 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 4.057 | nll_loss 2.48 | ppl 5.58 | wps 44930.5 | wpb 2685.2 | bsz 107.1 | num_updates 76976 | best_loss 11.022
2024-07-12 22:44:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:44:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 68 @ 76976 updates, score 4.057) (writing took 5.038516887463629 seconds)
2024-07-12 22:44:17 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2024-07-12 22:44:17 | INFO | train | epoch 068 | loss 2.855 | nll_loss 1.23 | ppl 2.35 | wps 14436.1 | ups 4.06 | wpb 3556.4 | bsz 141.6 | num_updates 76976 | lr 0.000113978 | gnorm 1.223 | train_wall 257 | wall 0
2024-07-12 22:44:17 | INFO | fairseq.trainer | begin training epoch 69
2024-07-12 22:44:22 | INFO | train_inner | epoch 069:     24 / 1132 loss=2.874, nll_loss=1.25, ppl=2.38, wps=10717.5, ups=3.04, wpb=3527.1, bsz=134.2, num_updates=77000, lr=0.000113961, gnorm=1.244, train_wall=23, wall=0
2024-07-12 22:44:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:44:27 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 4.048 | nll_loss 2.474 | ppl 5.56 | wps 44911.1 | wpb 2685.2 | bsz 107.1 | num_updates 77000 | best_loss 11.022
2024-07-12 22:44:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:44:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_69_77000.pt (epoch 69 @ 77000 updates, score 4.048) (writing took 6.071142410859466 seconds)
2024-07-12 22:44:56 | INFO | train_inner | epoch 069:    124 / 1132 loss=2.81, nll_loss=1.175, ppl=2.26, wps=10956.4, ups=3.01, wpb=3639.1, bsz=137.8, num_updates=77100, lr=0.000113887, gnorm=1.167, train_wall=23, wall=0
2024-07-12 22:45:19 | INFO | train_inner | epoch 069:    224 / 1132 loss=2.808, nll_loss=1.174, ppl=2.26, wps=15272.4, ups=4.36, wpb=3501.9, bsz=158.7, num_updates=77200, lr=0.000113813, gnorm=1.226, train_wall=23, wall=0
2024-07-12 22:45:41 | INFO | train_inner | epoch 069:    324 / 1132 loss=2.846, nll_loss=1.22, ppl=2.33, wps=15957.9, ups=4.37, wpb=3648.7, bsz=139.9, num_updates=77300, lr=0.000113739, gnorm=1.189, train_wall=23, wall=0
2024-07-12 22:46:04 | INFO | train_inner | epoch 069:    424 / 1132 loss=2.844, nll_loss=1.217, ppl=2.32, wps=15725.2, ups=4.43, wpb=3549, bsz=128.4, num_updates=77400, lr=0.000113666, gnorm=1.241, train_wall=22, wall=0
2024-07-12 22:46:27 | INFO | train_inner | epoch 069:    524 / 1132 loss=2.829, nll_loss=1.201, ppl=2.3, wps=15689.9, ups=4.41, wpb=3558.4, bsz=145.4, num_updates=77500, lr=0.000113592, gnorm=1.198, train_wall=23, wall=0
2024-07-12 22:46:50 | INFO | train_inner | epoch 069:    624 / 1132 loss=2.847, nll_loss=1.219, ppl=2.33, wps=15552.8, ups=4.38, wpb=3549.7, bsz=145.6, num_updates=77600, lr=0.000113519, gnorm=1.241, train_wall=23, wall=0
2024-07-12 22:47:12 | INFO | train_inner | epoch 069:    724 / 1132 loss=2.865, nll_loss=1.238, ppl=2.36, wps=15565.4, ups=4.54, wpb=3430.9, bsz=129.9, num_updates=77700, lr=0.000113446, gnorm=1.27, train_wall=22, wall=0
2024-07-12 22:47:34 | INFO | train_inner | epoch 069:    824 / 1132 loss=2.861, nll_loss=1.237, ppl=2.36, wps=15632.3, ups=4.4, wpb=3555.7, bsz=141.9, num_updates=77800, lr=0.000113373, gnorm=1.223, train_wall=23, wall=0
2024-07-12 22:47:58 | INFO | train_inner | epoch 069:    924 / 1132 loss=2.866, nll_loss=1.243, ppl=2.37, wps=15275.7, ups=4.26, wpb=3588.9, bsz=143.8, num_updates=77900, lr=0.0001133, gnorm=1.226, train_wall=23, wall=0
2024-07-12 22:48:21 | INFO | train_inner | epoch 069:   1024 / 1132 loss=2.871, nll_loss=1.248, ppl=2.38, wps=15296.4, ups=4.37, wpb=3497.2, bsz=148.2, num_updates=78000, lr=0.000113228, gnorm=1.259, train_wall=23, wall=0
2024-07-12 22:48:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:48:25 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 4.064 | nll_loss 2.49 | ppl 5.62 | wps 44932.7 | wpb 2685.2 | bsz 107.1 | num_updates 78000 | best_loss 11.022
2024-07-12 22:48:25 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:48:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_69_78000.pt (epoch 69 @ 78000 updates, score 4.064) (writing took 6.0666702557355165 seconds)
2024-07-12 22:48:54 | INFO | train_inner | epoch 069:   1124 / 1132 loss=2.878, nll_loss=1.257, ppl=2.39, wps=10736.3, ups=2.99, wpb=3590.2, bsz=149.4, num_updates=78100, lr=0.000113155, gnorm=1.229, train_wall=23, wall=0
2024-07-12 22:48:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:49:00 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 4.046 | nll_loss 2.473 | ppl 5.55 | wps 44786.1 | wpb 2685.2 | bsz 107.1 | num_updates 78108 | best_loss 11.022
2024-07-12 22:49:00 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:49:07 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 69 @ 78108 updates, score 4.046) (writing took 7.256727559491992 seconds)
2024-07-12 22:49:07 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2024-07-12 22:49:07 | INFO | train | epoch 069 | loss 2.848 | nll_loss 1.221 | ppl 2.33 | wps 13852.8 | ups 3.9 | wpb 3556.4 | bsz 141.6 | num_updates 78108 | lr 0.000113149 | gnorm 1.225 | train_wall 257 | wall 0
2024-07-12 22:49:07 | INFO | fairseq.trainer | begin training epoch 70
2024-07-12 22:49:29 | INFO | train_inner | epoch 070:     92 / 1132 loss=2.826, nll_loss=1.194, ppl=2.29, wps=10454.7, ups=2.88, wpb=3625.7, bsz=131.6, num_updates=78200, lr=0.000113083, gnorm=1.197, train_wall=23, wall=0
2024-07-12 22:49:51 | INFO | train_inner | epoch 070:    192 / 1132 loss=2.801, nll_loss=1.168, ppl=2.25, wps=16076.8, ups=4.49, wpb=3580.9, bsz=161.4, num_updates=78300, lr=0.000113011, gnorm=1.2, train_wall=22, wall=0
2024-07-12 22:50:14 | INFO | train_inner | epoch 070:    292 / 1132 loss=2.825, nll_loss=1.191, ppl=2.28, wps=15689.3, ups=4.42, wpb=3545.9, bsz=140.3, num_updates=78400, lr=0.000112938, gnorm=1.224, train_wall=22, wall=0
2024-07-12 22:50:36 | INFO | train_inner | epoch 070:    392 / 1132 loss=2.836, nll_loss=1.207, ppl=2.31, wps=15524.9, ups=4.43, wpb=3501.5, bsz=134.6, num_updates=78500, lr=0.000112867, gnorm=1.266, train_wall=22, wall=0
2024-07-12 22:50:59 | INFO | train_inner | epoch 070:    492 / 1132 loss=2.856, nll_loss=1.23, ppl=2.35, wps=16064.5, ups=4.41, wpb=3643.2, bsz=134.3, num_updates=78600, lr=0.000112795, gnorm=1.218, train_wall=23, wall=0
2024-07-12 22:51:22 | INFO | train_inner | epoch 070:    592 / 1132 loss=2.847, nll_loss=1.222, ppl=2.33, wps=15933.3, ups=4.34, wpb=3674.8, bsz=138.7, num_updates=78700, lr=0.000112723, gnorm=1.184, train_wall=23, wall=0
2024-07-12 22:51:45 | INFO | train_inner | epoch 070:    692 / 1132 loss=2.849, nll_loss=1.224, ppl=2.34, wps=15369.7, ups=4.31, wpb=3562.3, bsz=147.6, num_updates=78800, lr=0.000112651, gnorm=1.233, train_wall=23, wall=0
2024-07-12 22:52:08 | INFO | train_inner | epoch 070:    792 / 1132 loss=2.835, nll_loss=1.204, ppl=2.3, wps=15176.3, ups=4.45, wpb=3410.2, bsz=139.1, num_updates=78900, lr=0.00011258, gnorm=1.27, train_wall=22, wall=0
2024-07-12 22:52:30 | INFO | train_inner | epoch 070:    892 / 1132 loss=2.855, nll_loss=1.231, ppl=2.35, wps=15726.8, ups=4.46, wpb=3528.8, bsz=138.6, num_updates=79000, lr=0.000112509, gnorm=1.233, train_wall=22, wall=0
2024-07-12 22:52:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:52:34 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 4.056 | nll_loss 2.482 | ppl 5.59 | wps 44899.2 | wpb 2685.2 | bsz 107.1 | num_updates 79000 | best_loss 11.022
2024-07-12 22:52:34 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:52:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_70_79000.pt (epoch 70 @ 79000 updates, score 4.056) (writing took 6.393422244116664 seconds)
2024-07-12 22:53:04 | INFO | train_inner | epoch 070:    992 / 1132 loss=2.856, nll_loss=1.233, ppl=2.35, wps=10603.6, ups=2.99, wpb=3550.1, bsz=149.8, num_updates=79100, lr=0.000112438, gnorm=1.227, train_wall=23, wall=0
2024-07-12 22:53:26 | INFO | train_inner | epoch 070:   1092 / 1132 loss=2.876, nll_loss=1.254, ppl=2.38, wps=15665.7, ups=4.41, wpb=3552.1, bsz=136.3, num_updates=79200, lr=0.000112367, gnorm=1.265, train_wall=22, wall=0
2024-07-12 22:53:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:53:39 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 4.054 | nll_loss 2.481 | ppl 5.58 | wps 44876.2 | wpb 2685.2 | bsz 107.1 | num_updates 79240 | best_loss 11.022
2024-07-12 22:53:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:53:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 70 @ 79240 updates, score 4.054) (writing took 5.3802728075534105 seconds)
2024-07-12 22:53:45 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2024-07-12 22:53:45 | INFO | train | epoch 070 | loss 2.842 | nll_loss 1.214 | ppl 2.32 | wps 14516.4 | ups 4.08 | wpb 3556.4 | bsz 141.6 | num_updates 79240 | lr 0.000112338 | gnorm 1.231 | train_wall 255 | wall 0
2024-07-12 22:53:45 | INFO | fairseq.trainer | begin training epoch 71
2024-07-12 22:53:59 | INFO | train_inner | epoch 071:     60 / 1132 loss=2.833, nll_loss=1.2, ppl=2.3, wps=10819, ups=3.08, wpb=3511.3, bsz=130.6, num_updates=79300, lr=0.000112296, gnorm=1.253, train_wall=23, wall=0
2024-07-12 22:54:21 | INFO | train_inner | epoch 071:    160 / 1132 loss=2.805, nll_loss=1.169, ppl=2.25, wps=15520.7, ups=4.46, wpb=3478.4, bsz=124.4, num_updates=79400, lr=0.000112225, gnorm=1.245, train_wall=22, wall=0
2024-07-12 22:54:44 | INFO | train_inner | epoch 071:    260 / 1132 loss=2.815, nll_loss=1.181, ppl=2.27, wps=15501.7, ups=4.35, wpb=3565.8, bsz=146.2, num_updates=79500, lr=0.000112154, gnorm=1.213, train_wall=23, wall=0
2024-07-12 22:55:07 | INFO | train_inner | epoch 071:    360 / 1132 loss=2.823, nll_loss=1.193, ppl=2.29, wps=15529.6, ups=4.4, wpb=3532.2, bsz=139.1, num_updates=79600, lr=0.000112084, gnorm=1.212, train_wall=23, wall=0
2024-07-12 22:55:30 | INFO | train_inner | epoch 071:    460 / 1132 loss=2.816, nll_loss=1.185, ppl=2.27, wps=15669.5, ups=4.4, wpb=3561.3, bsz=145.8, num_updates=79700, lr=0.000112014, gnorm=1.227, train_wall=23, wall=0
2024-07-12 22:55:52 | INFO | train_inner | epoch 071:    560 / 1132 loss=2.849, nll_loss=1.221, ppl=2.33, wps=15693, ups=4.41, wpb=3559.8, bsz=133.4, num_updates=79800, lr=0.000111943, gnorm=1.259, train_wall=23, wall=0
2024-07-12 22:56:15 | INFO | train_inner | epoch 071:    660 / 1132 loss=2.837, nll_loss=1.209, ppl=2.31, wps=15541.2, ups=4.43, wpb=3509.2, bsz=132.1, num_updates=79900, lr=0.000111873, gnorm=1.228, train_wall=22, wall=0
2024-07-12 22:56:37 | INFO | train_inner | epoch 071:    760 / 1132 loss=2.837, nll_loss=1.21, ppl=2.31, wps=15812.8, ups=4.43, wpb=3566, bsz=152.9, num_updates=80000, lr=0.000111803, gnorm=1.229, train_wall=22, wall=0
2024-07-12 22:56:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:56:42 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 4.077 | nll_loss 2.501 | ppl 5.66 | wps 44752.7 | wpb 2685.2 | bsz 107.1 | num_updates 80000 | best_loss 11.022
2024-07-12 22:56:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:56:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_71_80000.pt (epoch 71 @ 80000 updates, score 4.077) (writing took 6.846392393112183 seconds)
2024-07-12 22:57:11 | INFO | train_inner | epoch 071:    860 / 1132 loss=2.845, nll_loss=1.219, ppl=2.33, wps=10644.8, ups=2.94, wpb=3623.1, bsz=156.5, num_updates=80100, lr=0.000111734, gnorm=1.207, train_wall=23, wall=0
2024-07-12 22:57:34 | INFO | train_inner | epoch 071:    960 / 1132 loss=2.851, nll_loss=1.228, ppl=2.34, wps=15839.5, ups=4.38, wpb=3613.7, bsz=165.9, num_updates=80200, lr=0.000111664, gnorm=1.237, train_wall=23, wall=0
2024-07-12 22:57:57 | INFO | train_inner | epoch 071:   1060 / 1132 loss=2.862, nll_loss=1.239, ppl=2.36, wps=15992, ups=4.44, wpb=3603.2, bsz=145.8, num_updates=80300, lr=0.000111594, gnorm=1.239, train_wall=22, wall=0
2024-07-12 22:58:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 22:58:17 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 4.054 | nll_loss 2.483 | ppl 5.59 | wps 44792.5 | wpb 2685.2 | bsz 107.1 | num_updates 80372 | best_loss 11.022
2024-07-12 22:58:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 22:58:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 71 @ 80372 updates, score 4.054) (writing took 5.442212158814073 seconds)
2024-07-12 22:58:23 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2024-07-12 22:58:23 | INFO | train | epoch 071 | loss 2.835 | nll_loss 1.207 | ppl 2.31 | wps 14480.9 | ups 4.07 | wpb 3556.4 | bsz 141.6 | num_updates 80372 | lr 0.000111544 | gnorm 1.232 | train_wall 255 | wall 0
2024-07-12 22:58:23 | INFO | fairseq.trainer | begin training epoch 72
2024-07-12 22:58:29 | INFO | train_inner | epoch 072:     28 / 1132 loss=2.847, nll_loss=1.217, ppl=2.33, wps=10720.7, ups=3.08, wpb=3477.7, bsz=126, num_updates=80400, lr=0.000111525, gnorm=1.268, train_wall=22, wall=0
2024-07-12 22:58:52 | INFO | train_inner | epoch 072:    128 / 1132 loss=2.791, nll_loss=1.156, ppl=2.23, wps=15994, ups=4.45, wpb=3591.3, bsz=140.3, num_updates=80500, lr=0.000111456, gnorm=1.184, train_wall=22, wall=0
2024-07-12 22:59:14 | INFO | train_inner | epoch 072:    228 / 1132 loss=2.803, nll_loss=1.166, ppl=2.24, wps=15900.6, ups=4.49, wpb=3545, bsz=137.7, num_updates=80600, lr=0.000111386, gnorm=1.221, train_wall=22, wall=0
2024-07-12 22:59:37 | INFO | train_inner | epoch 072:    328 / 1132 loss=2.822, nll_loss=1.192, ppl=2.28, wps=15956.1, ups=4.37, wpb=3654.1, bsz=140.2, num_updates=80700, lr=0.000111317, gnorm=1.208, train_wall=23, wall=0
2024-07-12 22:59:59 | INFO | train_inner | epoch 072:    428 / 1132 loss=2.81, nll_loss=1.173, ppl=2.26, wps=15205.8, ups=4.41, wpb=3444.2, bsz=137.8, num_updates=80800, lr=0.000111249, gnorm=1.265, train_wall=22, wall=0
2024-07-12 23:00:23 | INFO | train_inner | epoch 072:    528 / 1132 loss=2.818, nll_loss=1.188, ppl=2.28, wps=15604.3, ups=4.34, wpb=3593.5, bsz=146.2, num_updates=80900, lr=0.00011118, gnorm=1.205, train_wall=23, wall=0
2024-07-12 23:00:45 | INFO | train_inner | epoch 072:    628 / 1132 loss=2.825, nll_loss=1.195, ppl=2.29, wps=15624.1, ups=4.38, wpb=3567.5, bsz=148.2, num_updates=81000, lr=0.000111111, gnorm=1.235, train_wall=23, wall=0
2024-07-12 23:00:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:00:50 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 4.068 | nll_loss 2.499 | ppl 5.65 | wps 45012.6 | wpb 2685.2 | bsz 107.1 | num_updates 81000 | best_loss 11.022
2024-07-12 23:00:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:00:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_72_81000.pt (epoch 72 @ 81000 updates, score 4.068) (writing took 6.321682522073388 seconds)
2024-07-12 23:01:18 | INFO | train_inner | epoch 072:    728 / 1132 loss=2.819, nll_loss=1.19, ppl=2.28, wps=10570.8, ups=3.02, wpb=3498.8, bsz=156.5, num_updates=81100, lr=0.000111043, gnorm=1.228, train_wall=22, wall=0
2024-07-12 23:01:41 | INFO | train_inner | epoch 072:    828 / 1132 loss=2.833, nll_loss=1.208, ppl=2.31, wps=15716.2, ups=4.45, wpb=3529.8, bsz=152.5, num_updates=81200, lr=0.000110974, gnorm=1.24, train_wall=22, wall=0
2024-07-12 23:02:04 | INFO | train_inner | epoch 072:    928 / 1132 loss=2.856, nll_loss=1.232, ppl=2.35, wps=15722.8, ups=4.41, wpb=3562.4, bsz=145.9, num_updates=81300, lr=0.000110906, gnorm=1.252, train_wall=22, wall=0
2024-07-12 23:02:26 | INFO | train_inner | epoch 072:   1028 / 1132 loss=2.869, nll_loss=1.246, ppl=2.37, wps=15707.9, ups=4.4, wpb=3571.9, bsz=127.2, num_updates=81400, lr=0.000110838, gnorm=1.268, train_wall=23, wall=0
2024-07-12 23:02:49 | INFO | train_inner | epoch 072:   1128 / 1132 loss=2.882, nll_loss=1.261, ppl=2.4, wps=15696.3, ups=4.39, wpb=3575.3, bsz=127.3, num_updates=81500, lr=0.00011077, gnorm=1.277, train_wall=23, wall=0
2024-07-12 23:02:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:02:54 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 4.072 | nll_loss 2.501 | ppl 5.66 | wps 44929.8 | wpb 2685.2 | bsz 107.1 | num_updates 81504 | best_loss 11.022
2024-07-12 23:02:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:02:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 72 @ 81504 updates, score 4.072) (writing took 4.515510494820774 seconds)
2024-07-12 23:02:59 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2024-07-12 23:02:59 | INFO | train | epoch 072 | loss 2.829 | nll_loss 1.2 | ppl 2.3 | wps 14585.7 | ups 4.1 | wpb 3556.4 | bsz 141.6 | num_updates 81504 | lr 0.000110767 | gnorm 1.235 | train_wall 255 | wall 0
2024-07-12 23:02:59 | INFO | fairseq.trainer | begin training epoch 73
2024-07-12 23:03:21 | INFO | train_inner | epoch 073:     96 / 1132 loss=2.792, nll_loss=1.155, ppl=2.23, wps=11095.6, ups=3.16, wpb=3508.6, bsz=128.2, num_updates=81600, lr=0.000110702, gnorm=1.226, train_wall=23, wall=0
2024-07-12 23:03:44 | INFO | train_inner | epoch 073:    196 / 1132 loss=2.797, nll_loss=1.161, ppl=2.24, wps=15430.7, ups=4.34, wpb=3552.7, bsz=130.1, num_updates=81700, lr=0.000110634, gnorm=1.211, train_wall=23, wall=0
2024-07-12 23:04:06 | INFO | train_inner | epoch 073:    296 / 1132 loss=2.791, nll_loss=1.154, ppl=2.23, wps=15484, ups=4.42, wpb=3506.9, bsz=147.7, num_updates=81800, lr=0.000110566, gnorm=1.242, train_wall=22, wall=0
2024-07-12 23:04:29 | INFO | train_inner | epoch 073:    396 / 1132 loss=2.815, nll_loss=1.182, ppl=2.27, wps=15579.4, ups=4.37, wpb=3568.7, bsz=142.3, num_updates=81900, lr=0.000110499, gnorm=1.225, train_wall=23, wall=0
2024-07-12 23:04:52 | INFO | train_inner | epoch 073:    496 / 1132 loss=2.812, nll_loss=1.182, ppl=2.27, wps=15649, ups=4.42, wpb=3539.2, bsz=137, num_updates=82000, lr=0.000110432, gnorm=1.235, train_wall=22, wall=0
2024-07-12 23:04:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:04:56 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 4.088 | nll_loss 2.516 | ppl 5.72 | wps 44942.6 | wpb 2685.2 | bsz 107.1 | num_updates 82000 | best_loss 11.022
2024-07-12 23:04:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:05:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_73_82000.pt (epoch 73 @ 82000 updates, score 4.088) (writing took 5.750428618863225 seconds)
2024-07-12 23:05:25 | INFO | train_inner | epoch 073:    596 / 1132 loss=2.821, nll_loss=1.19, ppl=2.28, wps=10696.6, ups=3.03, wpb=3526.6, bsz=141.4, num_updates=82100, lr=0.000110364, gnorm=1.247, train_wall=23, wall=0
2024-07-12 23:05:48 | INFO | train_inner | epoch 073:    696 / 1132 loss=2.818, nll_loss=1.188, ppl=2.28, wps=15636.8, ups=4.4, wpb=3556.7, bsz=150.7, num_updates=82200, lr=0.000110297, gnorm=1.23, train_wall=23, wall=0
2024-07-12 23:06:11 | INFO | train_inner | epoch 073:    796 / 1132 loss=2.836, nll_loss=1.214, ppl=2.32, wps=15791.7, ups=4.33, wpb=3650, bsz=155.5, num_updates=82300, lr=0.00011023, gnorm=1.215, train_wall=23, wall=0
2024-07-12 23:06:34 | INFO | train_inner | epoch 073:    896 / 1132 loss=2.837, nll_loss=1.211, ppl=2.32, wps=15652.3, ups=4.38, wpb=3575.9, bsz=146.9, num_updates=82400, lr=0.000110163, gnorm=1.244, train_wall=23, wall=0
2024-07-12 23:06:57 | INFO | train_inner | epoch 073:    996 / 1132 loss=2.868, nll_loss=1.244, ppl=2.37, wps=15916.3, ups=4.34, wpb=3670.3, bsz=141.6, num_updates=82500, lr=0.000110096, gnorm=1.237, train_wall=23, wall=0
2024-07-12 23:07:19 | INFO | train_inner | epoch 073:   1096 / 1132 loss=2.838, nll_loss=1.206, ppl=2.31, wps=15287, ups=4.42, wpb=3458, bsz=142.3, num_updates=82600, lr=0.00011003, gnorm=1.283, train_wall=22, wall=0
2024-07-12 23:07:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:07:32 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 4.067 | nll_loss 2.494 | ppl 5.64 | wps 44338.6 | wpb 2685.2 | bsz 107.1 | num_updates 82636 | best_loss 11.022
2024-07-12 23:07:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:07:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 73 @ 82636 updates, score 4.067) (writing took 3.8853975730016828 seconds)
2024-07-12 23:07:36 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2024-07-12 23:07:36 | INFO | train | epoch 073 | loss 2.823 | nll_loss 1.192 | ppl 2.29 | wps 14544.3 | ups 4.09 | wpb 3556.4 | bsz 141.6 | num_updates 82636 | lr 0.000110006 | gnorm 1.239 | train_wall 257 | wall 0
2024-07-12 23:07:36 | INFO | fairseq.trainer | begin training epoch 74
2024-07-12 23:07:50 | INFO | train_inner | epoch 074:     64 / 1132 loss=2.816, nll_loss=1.182, ppl=2.27, wps=11546.7, ups=3.24, wpb=3560.8, bsz=131.8, num_updates=82700, lr=0.000109963, gnorm=1.269, train_wall=22, wall=0
2024-07-12 23:08:13 | INFO | train_inner | epoch 074:    164 / 1132 loss=2.784, nll_loss=1.151, ppl=2.22, wps=15853.7, ups=4.37, wpb=3629.2, bsz=152.7, num_updates=82800, lr=0.000109897, gnorm=1.186, train_wall=23, wall=0
2024-07-12 23:08:36 | INFO | train_inner | epoch 074:    264 / 1132 loss=2.784, nll_loss=1.149, ppl=2.22, wps=15767.3, ups=4.41, wpb=3571.3, bsz=143.4, num_updates=82900, lr=0.00010983, gnorm=1.228, train_wall=22, wall=0
2024-07-12 23:08:59 | INFO | train_inner | epoch 074:    364 / 1132 loss=2.808, nll_loss=1.173, ppl=2.26, wps=15670, ups=4.37, wpb=3583.7, bsz=141.8, num_updates=83000, lr=0.000109764, gnorm=1.231, train_wall=23, wall=0
2024-07-12 23:08:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:09:03 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 4.083 | nll_loss 2.511 | ppl 5.7 | wps 44980.2 | wpb 2685.2 | bsz 107.1 | num_updates 83000 | best_loss 11.022
2024-07-12 23:09:03 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:09:07 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_74_83000.pt (epoch 74 @ 83000 updates, score 4.083) (writing took 4.21769281104207 seconds)
2024-07-12 23:09:30 | INFO | train_inner | epoch 074:    464 / 1132 loss=2.816, nll_loss=1.182, ppl=2.27, wps=11335.1, ups=3.19, wpb=3554.2, bsz=143, num_updates=83100, lr=0.000109698, gnorm=1.265, train_wall=23, wall=0
2024-07-12 23:09:53 | INFO | train_inner | epoch 074:    564 / 1132 loss=2.814, nll_loss=1.183, ppl=2.27, wps=15548.5, ups=4.37, wpb=3559.7, bsz=153.4, num_updates=83200, lr=0.000109632, gnorm=1.241, train_wall=23, wall=0
2024-07-12 23:10:15 | INFO | train_inner | epoch 074:    664 / 1132 loss=2.835, nll_loss=1.206, ppl=2.31, wps=15512.2, ups=4.4, wpb=3523.7, bsz=129.4, num_updates=83300, lr=0.000109566, gnorm=1.277, train_wall=23, wall=0
2024-07-12 23:10:38 | INFO | train_inner | epoch 074:    764 / 1132 loss=2.834, nll_loss=1.208, ppl=2.31, wps=16002.5, ups=4.44, wpb=3605.8, bsz=134.6, num_updates=83400, lr=0.000109501, gnorm=1.234, train_wall=22, wall=0
2024-07-12 23:11:01 | INFO | train_inner | epoch 074:    864 / 1132 loss=2.83, nll_loss=1.203, ppl=2.3, wps=15767.7, ups=4.43, wpb=3559.1, bsz=141.2, num_updates=83500, lr=0.000109435, gnorm=1.256, train_wall=22, wall=0
2024-07-12 23:11:23 | INFO | train_inner | epoch 074:    964 / 1132 loss=2.831, nll_loss=1.201, ppl=2.3, wps=15393.2, ups=4.41, wpb=3490.2, bsz=134, num_updates=83600, lr=0.00010937, gnorm=1.259, train_wall=23, wall=0
2024-07-12 23:11:46 | INFO | train_inner | epoch 074:   1064 / 1132 loss=2.85, nll_loss=1.225, ppl=2.34, wps=15776.8, ups=4.39, wpb=3596.8, bsz=141, num_updates=83700, lr=0.000109304, gnorm=1.242, train_wall=23, wall=0
2024-07-12 23:12:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:12:06 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 4.081 | nll_loss 2.51 | ppl 5.7 | wps 44668.5 | wpb 2685.2 | bsz 107.1 | num_updates 83768 | best_loss 11.022
2024-07-12 23:12:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:12:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 74 @ 83768 updates, score 4.081) (writing took 3.8560828287154436 seconds)
2024-07-12 23:12:10 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2024-07-12 23:12:10 | INFO | train | epoch 074 | loss 2.816 | nll_loss 1.185 | ppl 2.27 | wps 14678.3 | ups 4.13 | wpb 3556.4 | bsz 141.6 | num_updates 83768 | lr 0.00010926 | gnorm 1.245 | train_wall 256 | wall 0
2024-07-12 23:12:10 | INFO | fairseq.trainer | begin training epoch 75
2024-07-12 23:12:17 | INFO | train_inner | epoch 075:     32 / 1132 loss=2.802, nll_loss=1.17, ppl=2.25, wps=11079.8, ups=3.2, wpb=3465.8, bsz=146.2, num_updates=83800, lr=0.000109239, gnorm=1.255, train_wall=23, wall=0
2024-07-12 23:12:40 | INFO | train_inner | epoch 075:    132 / 1132 loss=2.761, nll_loss=1.119, ppl=2.17, wps=15193.9, ups=4.46, wpb=3408.3, bsz=140.1, num_updates=83900, lr=0.000109174, gnorm=1.255, train_wall=22, wall=0
2024-07-12 23:13:03 | INFO | train_inner | epoch 075:    232 / 1132 loss=2.809, nll_loss=1.173, ppl=2.25, wps=15712.6, ups=4.38, wpb=3585.2, bsz=128.1, num_updates=84000, lr=0.000109109, gnorm=1.245, train_wall=23, wall=0
2024-07-12 23:13:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:13:07 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 4.092 | nll_loss 2.521 | ppl 5.74 | wps 44745.1 | wpb 2685.2 | bsz 107.1 | num_updates 84000 | best_loss 11.022
2024-07-12 23:13:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:13:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_75_84000.pt (epoch 75 @ 84000 updates, score 4.092) (writing took 4.102651349268854 seconds)
2024-07-12 23:13:34 | INFO | train_inner | epoch 075:    332 / 1132 loss=2.788, nll_loss=1.153, ppl=2.22, wps=11676.3, ups=3.19, wpb=3655.1, bsz=157.8, num_updates=84100, lr=0.000109044, gnorm=1.196, train_wall=23, wall=0
2024-07-12 23:13:56 | INFO | train_inner | epoch 075:    432 / 1132 loss=2.801, nll_loss=1.167, ppl=2.25, wps=15820, ups=4.43, wpb=3571.9, bsz=135, num_updates=84200, lr=0.000108979, gnorm=1.246, train_wall=22, wall=0
2024-07-12 23:14:19 | INFO | train_inner | epoch 075:    532 / 1132 loss=2.793, nll_loss=1.159, ppl=2.23, wps=15899.8, ups=4.47, wpb=3556.7, bsz=146.8, num_updates=84300, lr=0.000108915, gnorm=1.249, train_wall=22, wall=0
2024-07-12 23:14:41 | INFO | train_inner | epoch 075:    632 / 1132 loss=2.798, nll_loss=1.168, ppl=2.25, wps=16343.8, ups=4.6, wpb=3555.4, bsz=143.7, num_updates=84400, lr=0.00010885, gnorm=1.22, train_wall=22, wall=0
2024-07-12 23:15:03 | INFO | train_inner | epoch 075:    732 / 1132 loss=2.802, nll_loss=1.169, ppl=2.25, wps=15943.1, ups=4.48, wpb=3560.8, bsz=164.2, num_updates=84500, lr=0.000108786, gnorm=1.225, train_wall=22, wall=0
2024-07-12 23:15:26 | INFO | train_inner | epoch 075:    832 / 1132 loss=2.834, nll_loss=1.206, ppl=2.31, wps=15535.9, ups=4.38, wpb=3548.4, bsz=133.9, num_updates=84600, lr=0.000108721, gnorm=1.264, train_wall=23, wall=0
2024-07-12 23:15:49 | INFO | train_inner | epoch 075:    932 / 1132 loss=2.844, nll_loss=1.216, ppl=2.32, wps=15585.8, ups=4.34, wpb=3589, bsz=139.6, num_updates=84700, lr=0.000108657, gnorm=1.256, train_wall=23, wall=0
2024-07-12 23:16:11 | INFO | train_inner | epoch 075:   1032 / 1132 loss=2.836, nll_loss=1.207, ppl=2.31, wps=15810.1, ups=4.53, wpb=3493.2, bsz=128.5, num_updates=84800, lr=0.000108593, gnorm=1.291, train_wall=22, wall=0
2024-07-12 23:16:33 | INFO | train_inner | epoch 075:   1132 / 1132 loss=2.839, nll_loss=1.213, ppl=2.32, wps=16146.6, ups=4.49, wpb=3594.3, bsz=139.8, num_updates=84900, lr=0.000108529, gnorm=1.252, train_wall=22, wall=0
2024-07-12 23:16:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:16:37 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 4.07 | nll_loss 2.5 | ppl 5.66 | wps 44750.3 | wpb 2685.2 | bsz 107.1 | num_updates 84900 | best_loss 11.022
2024-07-12 23:16:37 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:16:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 75 @ 84900 updates, score 4.07) (writing took 4.669052794575691 seconds)
2024-07-12 23:16:42 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2024-07-12 23:16:42 | INFO | train | epoch 075 | loss 2.809 | nll_loss 1.176 | ppl 2.26 | wps 14789.8 | ups 4.16 | wpb 3556.4 | bsz 141.6 | num_updates 84900 | lr 0.000108529 | gnorm 1.243 | train_wall 253 | wall 0
2024-07-12 23:16:42 | INFO | fairseq.trainer | begin training epoch 76
2024-07-12 23:17:05 | INFO | train_inner | epoch 076:    100 / 1132 loss=2.761, nll_loss=1.124, ppl=2.18, wps=11134.9, ups=3.11, wpb=3581.2, bsz=143, num_updates=85000, lr=0.000108465, gnorm=1.201, train_wall=23, wall=0
2024-07-12 23:17:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:17:10 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 4.08 | nll_loss 2.508 | ppl 5.69 | wps 44838.6 | wpb 2685.2 | bsz 107.1 | num_updates 85000 | best_loss 11.022
2024-07-12 23:17:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:17:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_76_85000.pt (epoch 76 @ 85000 updates, score 4.08) (writing took 4.72899329662323 seconds)
2024-07-12 23:17:37 | INFO | train_inner | epoch 076:    200 / 1132 loss=2.766, nll_loss=1.126, ppl=2.18, wps=11015.9, ups=3.13, wpb=3521.4, bsz=143.5, num_updates=85100, lr=0.000108401, gnorm=1.236, train_wall=23, wall=0
2024-07-12 23:18:00 | INFO | train_inner | epoch 076:    300 / 1132 loss=2.782, nll_loss=1.147, ppl=2.21, wps=15733.7, ups=4.4, wpb=3578.9, bsz=144.2, num_updates=85200, lr=0.000108338, gnorm=1.228, train_wall=23, wall=0
2024-07-12 23:18:23 | INFO | train_inner | epoch 076:    400 / 1132 loss=2.79, nll_loss=1.156, ppl=2.23, wps=15722.8, ups=4.38, wpb=3591.7, bsz=150.2, num_updates=85300, lr=0.000108274, gnorm=1.218, train_wall=23, wall=0
2024-07-12 23:18:46 | INFO | train_inner | epoch 076:    500 / 1132 loss=2.807, nll_loss=1.175, ppl=2.26, wps=15741.1, ups=4.39, wpb=3583.6, bsz=142.2, num_updates=85400, lr=0.000108211, gnorm=1.251, train_wall=23, wall=0
2024-07-12 23:19:08 | INFO | train_inner | epoch 076:    600 / 1132 loss=2.801, nll_loss=1.167, ppl=2.25, wps=15530.3, ups=4.47, wpb=3472.5, bsz=146.6, num_updates=85500, lr=0.000108148, gnorm=1.319, train_wall=22, wall=0
2024-07-12 23:19:31 | INFO | train_inner | epoch 076:    700 / 1132 loss=2.818, nll_loss=1.184, ppl=2.27, wps=15363.7, ups=4.39, wpb=3501.7, bsz=124.6, num_updates=85600, lr=0.000108084, gnorm=1.278, train_wall=23, wall=0
2024-07-12 23:19:54 | INFO | train_inner | epoch 076:    800 / 1132 loss=2.825, nll_loss=1.194, ppl=2.29, wps=15711.5, ups=4.33, wpb=3629.6, bsz=133.6, num_updates=85700, lr=0.000108021, gnorm=1.237, train_wall=23, wall=0
2024-07-12 23:20:18 | INFO | train_inner | epoch 076:    900 / 1132 loss=2.822, nll_loss=1.193, ppl=2.29, wps=15474.3, ups=4.24, wpb=3651.4, bsz=151.4, num_updates=85800, lr=0.000107958, gnorm=1.227, train_wall=23, wall=0
2024-07-12 23:20:40 | INFO | train_inner | epoch 076:   1000 / 1132 loss=2.826, nll_loss=1.197, ppl=2.29, wps=15698, ups=4.39, wpb=3576.3, bsz=139.8, num_updates=85900, lr=0.000107896, gnorm=1.25, train_wall=23, wall=0
2024-07-12 23:21:02 | INFO | train_inner | epoch 076:   1100 / 1132 loss=2.819, nll_loss=1.189, ppl=2.28, wps=15472.7, ups=4.51, wpb=3434, bsz=141, num_updates=86000, lr=0.000107833, gnorm=1.29, train_wall=22, wall=0
2024-07-12 23:21:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:21:07 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 4.086 | nll_loss 2.513 | ppl 5.71 | wps 44947.1 | wpb 2685.2 | bsz 107.1 | num_updates 86000 | best_loss 11.022
2024-07-12 23:21:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:21:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_76_86000.pt (epoch 76 @ 86000 updates, score 4.086) (writing took 3.7737188804894686 seconds)
2024-07-12 23:21:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:21:22 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 4.08 | nll_loss 2.509 | ppl 5.69 | wps 44869.4 | wpb 2685.2 | bsz 107.1 | num_updates 86032 | best_loss 11.022
2024-07-12 23:21:22 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:21:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 76 @ 86032 updates, score 4.08) (writing took 3.2073036646470428 seconds)
2024-07-12 23:21:25 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2024-07-12 23:21:25 | INFO | train | epoch 076 | loss 2.803 | nll_loss 1.17 | ppl 2.25 | wps 14215.7 | ups 4 | wpb 3556.4 | bsz 141.6 | num_updates 86032 | lr 0.000107813 | gnorm 1.249 | train_wall 257 | wall 0
2024-07-12 23:21:25 | INFO | fairseq.trainer | begin training epoch 77
2024-07-12 23:21:41 | INFO | train_inner | epoch 077:     68 / 1132 loss=2.795, nll_loss=1.155, ppl=2.23, wps=9255.2, ups=2.6, wpb=3561.7, bsz=130.2, num_updates=86100, lr=0.00010777, gnorm=1.241, train_wall=23, wall=0
2024-07-12 23:22:03 | INFO | train_inner | epoch 077:    168 / 1132 loss=2.756, nll_loss=1.117, ppl=2.17, wps=15940.6, ups=4.47, wpb=3569.7, bsz=137.4, num_updates=86200, lr=0.000107708, gnorm=1.208, train_wall=22, wall=0
2024-07-12 23:22:26 | INFO | train_inner | epoch 077:    268 / 1132 loss=2.77, nll_loss=1.133, ppl=2.19, wps=15746.3, ups=4.33, wpb=3640.1, bsz=156.1, num_updates=86300, lr=0.000107645, gnorm=1.209, train_wall=23, wall=0
2024-07-12 23:22:49 | INFO | train_inner | epoch 077:    368 / 1132 loss=2.776, nll_loss=1.137, ppl=2.2, wps=15487.6, ups=4.44, wpb=3491, bsz=147.2, num_updates=86400, lr=0.000107583, gnorm=1.271, train_wall=22, wall=0
2024-07-12 23:23:12 | INFO | train_inner | epoch 077:    468 / 1132 loss=2.789, nll_loss=1.15, ppl=2.22, wps=15308.1, ups=4.4, wpb=3481, bsz=138.2, num_updates=86500, lr=0.000107521, gnorm=1.288, train_wall=23, wall=0
2024-07-12 23:23:35 | INFO | train_inner | epoch 077:    568 / 1132 loss=2.803, nll_loss=1.167, ppl=2.25, wps=15438.7, ups=4.39, wpb=3514.6, bsz=137.4, num_updates=86600, lr=0.000107459, gnorm=1.277, train_wall=23, wall=0
2024-07-12 23:23:57 | INFO | train_inner | epoch 077:    668 / 1132 loss=2.817, nll_loss=1.184, ppl=2.27, wps=15763, ups=4.39, wpb=3594.2, bsz=132.9, num_updates=86700, lr=0.000107397, gnorm=1.258, train_wall=23, wall=0
2024-07-12 23:24:20 | INFO | train_inner | epoch 077:    768 / 1132 loss=2.811, nll_loss=1.18, ppl=2.27, wps=15843.8, ups=4.43, wpb=3576.2, bsz=141.6, num_updates=86800, lr=0.000107335, gnorm=1.246, train_wall=22, wall=0
2024-07-12 23:24:42 | INFO | train_inner | epoch 077:    868 / 1132 loss=2.803, nll_loss=1.172, ppl=2.25, wps=16232.2, ups=4.6, wpb=3529.3, bsz=149, num_updates=86900, lr=0.000107273, gnorm=1.261, train_wall=22, wall=0
2024-07-12 23:25:05 | INFO | train_inner | epoch 077:    968 / 1132 loss=2.826, nll_loss=1.2, ppl=2.3, wps=15649.9, ups=4.35, wpb=3599.2, bsz=144.4, num_updates=87000, lr=0.000107211, gnorm=1.244, train_wall=23, wall=0
2024-07-12 23:25:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:25:09 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 4.088 | nll_loss 2.518 | ppl 5.73 | wps 44839.9 | wpb 2685.2 | bsz 107.1 | num_updates 87000 | best_loss 11.022
2024-07-12 23:25:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:25:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_77_87000.pt (epoch 77 @ 87000 updates, score 4.088) (writing took 4.279756881296635 seconds)
2024-07-12 23:25:36 | INFO | train_inner | epoch 077:   1068 / 1132 loss=2.838, nll_loss=1.211, ppl=2.31, wps=11418.4, ups=3.19, wpb=3579.3, bsz=130.2, num_updates=87100, lr=0.00010715, gnorm=1.277, train_wall=23, wall=0
2024-07-12 23:25:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:25:55 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 4.083 | nll_loss 2.514 | ppl 5.71 | wps 45036.1 | wpb 2685.2 | bsz 107.1 | num_updates 87164 | best_loss 11.022
2024-07-12 23:25:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:25:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 77 @ 87164 updates, score 4.083) (writing took 3.3564566569402814 seconds)
2024-07-12 23:25:58 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2024-07-12 23:25:58 | INFO | train | epoch 077 | loss 2.797 | nll_loss 1.162 | ppl 2.24 | wps 14768 | ups 4.15 | wpb 3556.4 | bsz 141.6 | num_updates 87164 | lr 0.00010711 | gnorm 1.251 | train_wall 255 | wall 0
2024-07-12 23:25:58 | INFO | fairseq.trainer | begin training epoch 78
2024-07-12 23:26:06 | INFO | train_inner | epoch 078:     36 / 1132 loss=2.773, nll_loss=1.137, ppl=2.2, wps=11636.1, ups=3.32, wpb=3501.2, bsz=145.3, num_updates=87200, lr=0.000107088, gnorm=1.232, train_wall=22, wall=0
2024-07-12 23:26:29 | INFO | train_inner | epoch 078:    136 / 1132 loss=2.768, nll_loss=1.129, ppl=2.19, wps=15763.2, ups=4.41, wpb=3575.6, bsz=129.9, num_updates=87300, lr=0.000107027, gnorm=1.226, train_wall=23, wall=0
2024-07-12 23:26:51 | INFO | train_inner | epoch 078:    236 / 1132 loss=2.746, nll_loss=1.105, ppl=2.15, wps=15715.1, ups=4.47, wpb=3513.4, bsz=147.2, num_updates=87400, lr=0.000106966, gnorm=1.234, train_wall=22, wall=0
2024-07-12 23:27:14 | INFO | train_inner | epoch 078:    336 / 1132 loss=2.776, nll_loss=1.137, ppl=2.2, wps=15271.3, ups=4.4, wpb=3467.5, bsz=134.9, num_updates=87500, lr=0.000106904, gnorm=1.274, train_wall=23, wall=0
2024-07-12 23:27:36 | INFO | train_inner | epoch 078:    436 / 1132 loss=2.793, nll_loss=1.161, ppl=2.24, wps=15989.2, ups=4.41, wpb=3622.6, bsz=139.9, num_updates=87600, lr=0.000106843, gnorm=1.245, train_wall=22, wall=0
2024-07-12 23:27:59 | INFO | train_inner | epoch 078:    536 / 1132 loss=2.78, nll_loss=1.142, ppl=2.21, wps=15824.2, ups=4.51, wpb=3506.2, bsz=138, num_updates=87700, lr=0.000106783, gnorm=1.284, train_wall=22, wall=0
2024-07-12 23:28:22 | INFO | train_inner | epoch 078:    636 / 1132 loss=2.78, nll_loss=1.145, ppl=2.21, wps=15843.7, ups=4.37, wpb=3629.3, bsz=161.4, num_updates=87800, lr=0.000106722, gnorm=1.226, train_wall=23, wall=0
2024-07-12 23:28:44 | INFO | train_inner | epoch 078:    736 / 1132 loss=2.805, nll_loss=1.173, ppl=2.26, wps=15801.6, ups=4.38, wpb=3606.7, bsz=155.1, num_updates=87900, lr=0.000106661, gnorm=1.246, train_wall=23, wall=0
2024-07-12 23:29:07 | INFO | train_inner | epoch 078:    836 / 1132 loss=2.81, nll_loss=1.179, ppl=2.26, wps=15988.8, ups=4.5, wpb=3555.7, bsz=136.2, num_updates=88000, lr=0.0001066, gnorm=1.262, train_wall=22, wall=0
2024-07-12 23:29:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:29:11 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 4.086 | nll_loss 2.517 | ppl 5.73 | wps 44956.8 | wpb 2685.2 | bsz 107.1 | num_updates 88000 | best_loss 11.022
2024-07-12 23:29:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:29:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_78_88000.pt (epoch 78 @ 88000 updates, score 4.086) (writing took 4.41953947301954 seconds)
2024-07-12 23:29:38 | INFO | train_inner | epoch 078:    936 / 1132 loss=2.818, nll_loss=1.185, ppl=2.27, wps=11256.1, ups=3.17, wpb=3549.2, bsz=133, num_updates=88100, lr=0.00010654, gnorm=1.277, train_wall=23, wall=0
2024-07-12 23:30:01 | INFO | train_inner | epoch 078:   1036 / 1132 loss=2.817, nll_loss=1.187, ppl=2.28, wps=15852.6, ups=4.35, wpb=3643.4, bsz=147.7, num_updates=88200, lr=0.000106479, gnorm=1.245, train_wall=23, wall=0
2024-07-12 23:30:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:30:27 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 4.088 | nll_loss 2.519 | ppl 5.73 | wps 44953.3 | wpb 2685.2 | bsz 107.1 | num_updates 88296 | best_loss 11.022
2024-07-12 23:30:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:30:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 78 @ 88296 updates, score 4.088) (writing took 3.28890885040164 seconds)
2024-07-12 23:30:30 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2024-07-12 23:30:30 | INFO | train | epoch 078 | loss 2.791 | nll_loss 1.156 | ppl 2.23 | wps 14791 | ups 4.16 | wpb 3556.4 | bsz 141.6 | num_updates 88296 | lr 0.000106422 | gnorm 1.257 | train_wall 254 | wall 0
2024-07-12 23:30:30 | INFO | fairseq.trainer | begin training epoch 79
2024-07-12 23:30:31 | INFO | train_inner | epoch 079:      4 / 1132 loss=2.82, nll_loss=1.19, ppl=2.28, wps=11625.2, ups=3.33, wpb=3492.1, bsz=138.6, num_updates=88300, lr=0.000106419, gnorm=1.308, train_wall=22, wall=0
2024-07-12 23:30:54 | INFO | train_inner | epoch 079:    104 / 1132 loss=2.745, nll_loss=1.099, ppl=2.14, wps=15517.7, ups=4.41, wpb=3516.3, bsz=132.3, num_updates=88400, lr=0.000106359, gnorm=1.255, train_wall=22, wall=0
2024-07-12 23:31:17 | INFO | train_inner | epoch 079:    204 / 1132 loss=2.758, nll_loss=1.118, ppl=2.17, wps=15714, ups=4.34, wpb=3624.6, bsz=151.1, num_updates=88500, lr=0.000106299, gnorm=1.213, train_wall=23, wall=0
2024-07-12 23:31:40 | INFO | train_inner | epoch 079:    304 / 1132 loss=2.777, nll_loss=1.139, ppl=2.2, wps=15584.1, ups=4.41, wpb=3531.9, bsz=124.8, num_updates=88600, lr=0.000106239, gnorm=1.26, train_wall=22, wall=0
2024-07-12 23:32:02 | INFO | train_inner | epoch 079:    404 / 1132 loss=2.759, nll_loss=1.121, ppl=2.17, wps=15540.4, ups=4.41, wpb=3520.5, bsz=141.6, num_updates=88700, lr=0.000106179, gnorm=1.252, train_wall=22, wall=0
2024-07-12 23:32:25 | INFO | train_inner | epoch 079:    504 / 1132 loss=2.777, nll_loss=1.139, ppl=2.2, wps=15568.2, ups=4.45, wpb=3502.4, bsz=130, num_updates=88800, lr=0.000106119, gnorm=1.273, train_wall=22, wall=0
2024-07-12 23:32:47 | INFO | train_inner | epoch 079:    604 / 1132 loss=2.777, nll_loss=1.142, ppl=2.21, wps=15967.3, ups=4.5, wpb=3550.1, bsz=152.1, num_updates=88900, lr=0.000106059, gnorm=1.261, train_wall=22, wall=0
2024-07-12 23:33:10 | INFO | train_inner | epoch 079:    704 / 1132 loss=2.812, nll_loss=1.179, ppl=2.26, wps=15584.8, ups=4.41, wpb=3536.6, bsz=134.2, num_updates=89000, lr=0.000106, gnorm=1.262, train_wall=23, wall=0
2024-07-12 23:33:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:33:14 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 4.095 | nll_loss 2.528 | ppl 5.77 | wps 44921.5 | wpb 2685.2 | bsz 107.1 | num_updates 89000 | best_loss 11.022
2024-07-12 23:33:14 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:33:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_79_89000.pt (epoch 79 @ 89000 updates, score 4.095) (writing took 4.413568599149585 seconds)
2024-07-12 23:33:41 | INFO | train_inner | epoch 079:    804 / 1132 loss=2.802, nll_loss=1.167, ppl=2.25, wps=11347.9, ups=3.23, wpb=3508.4, bsz=127.5, num_updates=89100, lr=0.00010594, gnorm=1.303, train_wall=22, wall=0
2024-07-12 23:34:04 | INFO | train_inner | epoch 079:    904 / 1132 loss=2.808, nll_loss=1.176, ppl=2.26, wps=15540.6, ups=4.29, wpb=3623.4, bsz=142.9, num_updates=89200, lr=0.000105881, gnorm=1.249, train_wall=23, wall=0
2024-07-12 23:34:27 | INFO | train_inner | epoch 079:   1004 / 1132 loss=2.798, nll_loss=1.169, ppl=2.25, wps=15703.9, ups=4.38, wpb=3587.4, bsz=164.6, num_updates=89300, lr=0.000105822, gnorm=1.236, train_wall=23, wall=0
2024-07-12 23:34:50 | INFO | train_inner | epoch 079:   1104 / 1132 loss=2.817, nll_loss=1.187, ppl=2.28, wps=15591.5, ups=4.33, wpb=3597.5, bsz=153.1, num_updates=89400, lr=0.000105762, gnorm=1.272, train_wall=23, wall=0
2024-07-12 23:34:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:35:00 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 4.096 | nll_loss 2.522 | ppl 5.74 | wps 44685.9 | wpb 2685.2 | bsz 107.1 | num_updates 89428 | best_loss 11.022
2024-07-12 23:35:00 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:35:05 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 79 @ 89428 updates, score 4.096) (writing took 4.221200902014971 seconds)
2024-07-12 23:35:05 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2024-07-12 23:35:05 | INFO | train | epoch 079 | loss 2.785 | nll_loss 1.149 | ppl 2.22 | wps 14660.2 | ups 4.12 | wpb 3556.4 | bsz 141.6 | num_updates 89428 | lr 0.000105746 | gnorm 1.257 | train_wall 256 | wall 0
2024-07-12 23:35:05 | INFO | fairseq.trainer | begin training epoch 80
2024-07-12 23:35:21 | INFO | train_inner | epoch 080:     72 / 1132 loss=2.748, nll_loss=1.107, ppl=2.15, wps=11362.2, ups=3.18, wpb=3576.7, bsz=155.5, num_updates=89500, lr=0.000105703, gnorm=1.215, train_wall=23, wall=0
2024-07-12 23:35:44 | INFO | train_inner | epoch 080:    172 / 1132 loss=2.763, nll_loss=1.125, ppl=2.18, wps=16167.1, ups=4.45, wpb=3629.2, bsz=141.5, num_updates=89600, lr=0.000105644, gnorm=1.21, train_wall=22, wall=0
2024-07-12 23:36:07 | INFO | train_inner | epoch 080:    272 / 1132 loss=2.757, nll_loss=1.116, ppl=2.17, wps=15202.7, ups=4.31, wpb=3531.2, bsz=147.4, num_updates=89700, lr=0.000105585, gnorm=1.266, train_wall=23, wall=0
2024-07-12 23:36:30 | INFO | train_inner | epoch 080:    372 / 1132 loss=2.765, nll_loss=1.128, ppl=2.19, wps=15754.4, ups=4.4, wpb=3584.3, bsz=150.4, num_updates=89800, lr=0.000105527, gnorm=1.233, train_wall=23, wall=0
2024-07-12 23:36:52 | INFO | train_inner | epoch 080:    472 / 1132 loss=2.759, nll_loss=1.118, ppl=2.17, wps=15369.1, ups=4.43, wpb=3471, bsz=148.9, num_updates=89900, lr=0.000105468, gnorm=1.259, train_wall=22, wall=0
2024-07-12 23:37:15 | INFO | train_inner | epoch 080:    572 / 1132 loss=2.789, nll_loss=1.152, ppl=2.22, wps=15496.8, ups=4.39, wpb=3527.7, bsz=133.3, num_updates=90000, lr=0.000105409, gnorm=1.308, train_wall=23, wall=0
2024-07-12 23:37:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:37:19 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 4.103 | nll_loss 2.536 | ppl 5.8 | wps 44796.6 | wpb 2685.2 | bsz 107.1 | num_updates 90000 | best_loss 11.022
2024-07-12 23:37:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:37:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_80_90000.pt (epoch 80 @ 90000 updates, score 4.103) (writing took 4.427189596928656 seconds)
2024-07-12 23:37:46 | INFO | train_inner | epoch 080:    672 / 1132 loss=2.792, nll_loss=1.157, ppl=2.23, wps=11428.7, ups=3.2, wpb=3566.2, bsz=135.8, num_updates=90100, lr=0.000105351, gnorm=1.269, train_wall=22, wall=0
2024-07-12 23:38:09 | INFO | train_inner | epoch 080:    772 / 1132 loss=2.798, nll_loss=1.162, ppl=2.24, wps=15657.5, ups=4.4, wpb=3555.1, bsz=129, num_updates=90200, lr=0.000105292, gnorm=1.279, train_wall=23, wall=0
2024-07-12 23:38:32 | INFO | train_inner | epoch 080:    872 / 1132 loss=2.798, nll_loss=1.165, ppl=2.24, wps=15792.3, ups=4.41, wpb=3578.8, bsz=133.3, num_updates=90300, lr=0.000105234, gnorm=1.259, train_wall=22, wall=0
2024-07-12 23:38:54 | INFO | train_inner | epoch 080:    972 / 1132 loss=2.798, nll_loss=1.168, ppl=2.25, wps=15934.4, ups=4.4, wpb=3620.4, bsz=143, num_updates=90400, lr=0.000105176, gnorm=1.254, train_wall=23, wall=0
2024-07-12 23:39:17 | INFO | train_inner | epoch 080:   1072 / 1132 loss=2.802, nll_loss=1.169, ppl=2.25, wps=15482.2, ups=4.36, wpb=3548.4, bsz=146.1, num_updates=90500, lr=0.000105118, gnorm=1.264, train_wall=23, wall=0
2024-07-12 23:39:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:39:35 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 4.095 | nll_loss 2.528 | ppl 5.77 | wps 44927.2 | wpb 2685.2 | bsz 107.1 | num_updates 90560 | best_loss 11.022
2024-07-12 23:39:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:39:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 80 @ 90560 updates, score 4.095) (writing took 3.2881706077605486 seconds)
2024-07-12 23:39:38 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2024-07-12 23:39:38 | INFO | train | epoch 080 | loss 2.78 | nll_loss 1.144 | ppl 2.21 | wps 14716.6 | ups 4.14 | wpb 3556.4 | bsz 141.6 | num_updates 90560 | lr 0.000105083 | gnorm 1.26 | train_wall 255 | wall 0
2024-07-12 23:39:38 | INFO | fairseq.trainer | begin training epoch 81
2024-07-12 23:39:48 | INFO | train_inner | epoch 081:     40 / 1132 loss=2.777, nll_loss=1.14, ppl=2.2, wps=11671.9, ups=3.3, wpb=3535.9, bsz=144.2, num_updates=90600, lr=0.00010506, gnorm=1.277, train_wall=22, wall=0
2024-07-12 23:40:10 | INFO | train_inner | epoch 081:    140 / 1132 loss=2.737, nll_loss=1.092, ppl=2.13, wps=15518.5, ups=4.42, wpb=3511.7, bsz=128.7, num_updates=90700, lr=0.000105002, gnorm=1.237, train_wall=22, wall=0
2024-07-12 23:40:33 | INFO | train_inner | epoch 081:    240 / 1132 loss=2.74, nll_loss=1.1, ppl=2.14, wps=15666.6, ups=4.42, wpb=3547.9, bsz=149.8, num_updates=90800, lr=0.000104944, gnorm=1.226, train_wall=22, wall=0
2024-07-12 23:40:56 | INFO | train_inner | epoch 081:    340 / 1132 loss=2.773, nll_loss=1.136, ppl=2.2, wps=15258.3, ups=4.26, wpb=3583.1, bsz=144.5, num_updates=90900, lr=0.000104886, gnorm=1.271, train_wall=23, wall=0
2024-07-12 23:41:20 | INFO | train_inner | epoch 081:    440 / 1132 loss=2.766, nll_loss=1.128, ppl=2.19, wps=15378.8, ups=4.29, wpb=3584.7, bsz=139.7, num_updates=91000, lr=0.000104828, gnorm=1.259, train_wall=23, wall=0
2024-07-12 23:41:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:41:24 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 4.114 | nll_loss 2.545 | ppl 5.84 | wps 44831.9 | wpb 2685.2 | bsz 107.1 | num_updates 91000 | best_loss 11.022
2024-07-12 23:41:24 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:41:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_81_91000.pt (epoch 81 @ 91000 updates, score 4.114) (writing took 5.495735166594386 seconds)
2024-07-12 23:41:52 | INFO | train_inner | epoch 081:    540 / 1132 loss=2.768, nll_loss=1.13, ppl=2.19, wps=10898.4, ups=3.1, wpb=3510.6, bsz=135.3, num_updates=91100, lr=0.000104771, gnorm=1.263, train_wall=22, wall=0
2024-07-12 23:42:14 | INFO | train_inner | epoch 081:    640 / 1132 loss=2.78, nll_loss=1.145, ppl=2.21, wps=16062.4, ups=4.46, wpb=3604.8, bsz=149, num_updates=91200, lr=0.000104713, gnorm=1.254, train_wall=22, wall=0
2024-07-12 23:42:36 | INFO | train_inner | epoch 081:    740 / 1132 loss=2.764, nll_loss=1.125, ppl=2.18, wps=15868.9, ups=4.56, wpb=3481.4, bsz=143.8, num_updates=91300, lr=0.000104656, gnorm=1.266, train_wall=22, wall=0
2024-07-12 23:42:59 | INFO | train_inner | epoch 081:    840 / 1132 loss=2.792, nll_loss=1.158, ppl=2.23, wps=15962.6, ups=4.43, wpb=3602.8, bsz=152.6, num_updates=91400, lr=0.000104599, gnorm=1.269, train_wall=22, wall=0
2024-07-12 23:43:22 | INFO | train_inner | epoch 081:    940 / 1132 loss=2.809, nll_loss=1.177, ppl=2.26, wps=15913.1, ups=4.36, wpb=3649.4, bsz=138.4, num_updates=91500, lr=0.000104542, gnorm=1.264, train_wall=23, wall=0
2024-07-12 23:43:44 | INFO | train_inner | epoch 081:   1040 / 1132 loss=2.786, nll_loss=1.151, ppl=2.22, wps=15498.6, ups=4.42, wpb=3505.9, bsz=139.8, num_updates=91600, lr=0.000104485, gnorm=1.275, train_wall=22, wall=0
2024-07-12 23:44:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:44:09 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 4.098 | nll_loss 2.53 | ppl 5.78 | wps 44905.7 | wpb 2685.2 | bsz 107.1 | num_updates 91692 | best_loss 11.022
2024-07-12 23:44:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:44:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 81 @ 91692 updates, score 4.098) (writing took 3.380402489565313 seconds)
2024-07-12 23:44:13 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2024-07-12 23:44:13 | INFO | train | epoch 081 | loss 2.773 | nll_loss 1.136 | ppl 2.2 | wps 14666 | ups 4.12 | wpb 3556.4 | bsz 141.6 | num_updates 91692 | lr 0.000104432 | gnorm 1.263 | train_wall 255 | wall 0
2024-07-12 23:44:13 | INFO | fairseq.trainer | begin training epoch 82
2024-07-12 23:44:15 | INFO | train_inner | epoch 082:      8 / 1132 loss=2.803, nll_loss=1.167, ppl=2.24, wps=11439.6, ups=3.29, wpb=3472.5, bsz=127.4, num_updates=91700, lr=0.000104428, gnorm=1.334, train_wall=22, wall=0
2024-07-12 23:44:37 | INFO | train_inner | epoch 082:    108 / 1132 loss=2.736, nll_loss=1.094, ppl=2.13, wps=15757.1, ups=4.42, wpb=3561.4, bsz=144.8, num_updates=91800, lr=0.000104371, gnorm=1.238, train_wall=22, wall=0
2024-07-12 23:45:00 | INFO | train_inner | epoch 082:    208 / 1132 loss=2.735, nll_loss=1.092, ppl=2.13, wps=15540.6, ups=4.41, wpb=3520.3, bsz=144.4, num_updates=91900, lr=0.000104314, gnorm=1.256, train_wall=22, wall=0
2024-07-12 23:45:23 | INFO | train_inner | epoch 082:    308 / 1132 loss=2.752, nll_loss=1.109, ppl=2.16, wps=15745.1, ups=4.38, wpb=3591.5, bsz=132.2, num_updates=92000, lr=0.000104257, gnorm=1.259, train_wall=23, wall=0
2024-07-12 23:45:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:45:27 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 4.105 | nll_loss 2.537 | ppl 5.8 | wps 45045.9 | wpb 2685.2 | bsz 107.1 | num_updates 92000 | best_loss 11.022
2024-07-12 23:45:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:45:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_82_92000.pt (epoch 82 @ 92000 updates, score 4.105) (writing took 4.78023545909673 seconds)
2024-07-12 23:45:54 | INFO | train_inner | epoch 082:    408 / 1132 loss=2.767, nll_loss=1.127, ppl=2.18, wps=11423.9, ups=3.19, wpb=3579.5, bsz=133.4, num_updates=92100, lr=0.000104201, gnorm=1.255, train_wall=22, wall=0
2024-07-12 23:46:17 | INFO | train_inner | epoch 082:    508 / 1132 loss=2.757, nll_loss=1.115, ppl=2.17, wps=15452.1, ups=4.39, wpb=3523, bsz=138, num_updates=92200, lr=0.000104144, gnorm=1.265, train_wall=23, wall=0
2024-07-12 23:46:39 | INFO | train_inner | epoch 082:    608 / 1132 loss=2.759, nll_loss=1.12, ppl=2.17, wps=15591.3, ups=4.49, wpb=3470.9, bsz=149.9, num_updates=92300, lr=0.000104088, gnorm=1.277, train_wall=22, wall=0
2024-07-12 23:47:01 | INFO | train_inner | epoch 082:    708 / 1132 loss=2.786, nll_loss=1.151, ppl=2.22, wps=16004.7, ups=4.48, wpb=3570.6, bsz=147.2, num_updates=92400, lr=0.000104031, gnorm=1.31, train_wall=22, wall=0
2024-07-12 23:47:24 | INFO | train_inner | epoch 082:    808 / 1132 loss=2.781, nll_loss=1.146, ppl=2.21, wps=16005.2, ups=4.42, wpb=3617.6, bsz=139.6, num_updates=92500, lr=0.000103975, gnorm=1.239, train_wall=22, wall=0
2024-07-12 23:47:47 | INFO | train_inner | epoch 082:    908 / 1132 loss=2.769, nll_loss=1.133, ppl=2.19, wps=15648.2, ups=4.34, wpb=3608.3, bsz=158.2, num_updates=92600, lr=0.000103919, gnorm=1.236, train_wall=23, wall=0
2024-07-12 23:48:10 | INFO | train_inner | epoch 082:   1008 / 1132 loss=2.795, nll_loss=1.16, ppl=2.23, wps=15544.3, ups=4.39, wpb=3542.1, bsz=138.8, num_updates=92700, lr=0.000103863, gnorm=1.298, train_wall=23, wall=0
2024-07-12 23:48:33 | INFO | train_inner | epoch 082:   1108 / 1132 loss=2.808, nll_loss=1.177, ppl=2.26, wps=15197.7, ups=4.26, wpb=3565.2, bsz=133.6, num_updates=92800, lr=0.000103807, gnorm=1.278, train_wall=23, wall=0
2024-07-12 23:48:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:48:43 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 4.09 | nll_loss 2.524 | ppl 5.75 | wps 44805.9 | wpb 2685.2 | bsz 107.1 | num_updates 92824 | best_loss 11.022
2024-07-12 23:48:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:48:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 82 @ 92824 updates, score 4.09) (writing took 3.333048427477479 seconds)
2024-07-12 23:48:47 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2024-07-12 23:48:47 | INFO | train | epoch 082 | loss 2.768 | nll_loss 1.13 | ppl 2.19 | wps 14701.4 | ups 4.13 | wpb 3556.4 | bsz 141.6 | num_updates 92824 | lr 0.000103793 | gnorm 1.266 | train_wall 255 | wall 0
2024-07-12 23:48:47 | INFO | fairseq.trainer | begin training epoch 83
2024-07-12 23:49:04 | INFO | train_inner | epoch 083:     76 / 1132 loss=2.735, nll_loss=1.093, ppl=2.13, wps=11704.4, ups=3.27, wpb=3577.1, bsz=147.4, num_updates=92900, lr=0.000103751, gnorm=1.211, train_wall=23, wall=0
2024-07-12 23:49:27 | INFO | train_inner | epoch 083:    176 / 1132 loss=2.741, nll_loss=1.1, ppl=2.14, wps=15345.6, ups=4.29, wpb=3578.6, bsz=142.5, num_updates=93000, lr=0.000103695, gnorm=1.241, train_wall=23, wall=0
2024-07-12 23:49:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:49:32 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 4.11 | nll_loss 2.542 | ppl 5.82 | wps 45079.1 | wpb 2685.2 | bsz 107.1 | num_updates 93000 | best_loss 11.022
2024-07-12 23:49:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:49:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_83_93000.pt (epoch 83 @ 93000 updates, score 4.11) (writing took 4.17044638749212 seconds)
2024-07-12 23:49:59 | INFO | train_inner | epoch 083:    276 / 1132 loss=2.761, nll_loss=1.118, ppl=2.17, wps=11265.5, ups=3.15, wpb=3579.3, bsz=128.2, num_updates=93100, lr=0.000103639, gnorm=1.274, train_wall=23, wall=0
2024-07-12 23:50:23 | INFO | train_inner | epoch 083:    376 / 1132 loss=2.755, nll_loss=1.111, ppl=2.16, wps=15069.1, ups=4.26, wpb=3535.8, bsz=127.8, num_updates=93200, lr=0.000103584, gnorm=1.271, train_wall=23, wall=0
2024-07-12 23:50:45 | INFO | train_inner | epoch 083:    476 / 1132 loss=2.744, nll_loss=1.104, ppl=2.15, wps=15422.2, ups=4.42, wpb=3486.1, bsz=149.8, num_updates=93300, lr=0.000103528, gnorm=1.264, train_wall=22, wall=0
2024-07-12 23:51:07 | INFO | train_inner | epoch 083:    576 / 1132 loss=2.75, nll_loss=1.107, ppl=2.15, wps=15899.8, ups=4.54, wpb=3500.6, bsz=138.2, num_updates=93400, lr=0.000103473, gnorm=1.293, train_wall=22, wall=0
2024-07-12 23:51:29 | INFO | train_inner | epoch 083:    676 / 1132 loss=2.779, nll_loss=1.142, ppl=2.21, wps=16251.4, ups=4.53, wpb=3585.7, bsz=138, num_updates=93500, lr=0.000103418, gnorm=1.288, train_wall=22, wall=0
2024-07-12 23:51:52 | INFO | train_inner | epoch 083:    776 / 1132 loss=2.764, nll_loss=1.128, ppl=2.19, wps=15874.8, ups=4.45, wpb=3565.3, bsz=153.6, num_updates=93600, lr=0.000103362, gnorm=1.264, train_wall=22, wall=0
2024-07-12 23:52:14 | INFO | train_inner | epoch 083:    876 / 1132 loss=2.786, nll_loss=1.152, ppl=2.22, wps=15834.8, ups=4.4, wpb=3601.8, bsz=141.8, num_updates=93700, lr=0.000103307, gnorm=1.278, train_wall=23, wall=0
2024-07-12 23:52:37 | INFO | train_inner | epoch 083:    976 / 1132 loss=2.786, nll_loss=1.152, ppl=2.22, wps=15401.5, ups=4.37, wpb=3527.2, bsz=141.9, num_updates=93800, lr=0.000103252, gnorm=1.308, train_wall=23, wall=0
2024-07-12 23:53:01 | INFO | train_inner | epoch 083:   1076 / 1132 loss=2.79, nll_loss=1.157, ppl=2.23, wps=14900.3, ups=4.21, wpb=3538, bsz=138.6, num_updates=93900, lr=0.000103197, gnorm=1.289, train_wall=24, wall=0
2024-07-12 23:53:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:53:18 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 4.094 | nll_loss 2.531 | ppl 5.78 | wps 44831 | wpb 2685.2 | bsz 107.1 | num_updates 93956 | best_loss 11.022
2024-07-12 23:53:18 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:53:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 83 @ 93956 updates, score 4.094) (writing took 3.284731714054942 seconds)
2024-07-12 23:53:21 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2024-07-12 23:53:21 | INFO | train | epoch 083 | loss 2.764 | nll_loss 1.125 | ppl 2.18 | wps 14645.5 | ups 4.12 | wpb 3556.4 | bsz 141.6 | num_updates 93956 | lr 0.000103166 | gnorm 1.27 | train_wall 257 | wall 0
2024-07-12 23:53:22 | INFO | fairseq.trainer | begin training epoch 84
2024-07-12 23:53:32 | INFO | train_inner | epoch 084:     44 / 1132 loss=2.762, nll_loss=1.124, ppl=2.18, wps=11768.2, ups=3.25, wpb=3622, bsz=149.5, num_updates=94000, lr=0.000103142, gnorm=1.241, train_wall=23, wall=0
2024-07-12 23:53:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:53:36 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 4.108 | nll_loss 2.543 | ppl 5.83 | wps 44885.3 | wpb 2685.2 | bsz 107.1 | num_updates 94000 | best_loss 11.022
2024-07-12 23:53:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:53:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_84_94000.pt (epoch 84 @ 94000 updates, score 4.108) (writing took 4.131692507304251 seconds)
2024-07-12 23:54:03 | INFO | train_inner | epoch 084:    144 / 1132 loss=2.719, nll_loss=1.072, ppl=2.1, wps=11494.8, ups=3.22, wpb=3571.9, bsz=144.4, num_updates=94100, lr=0.000103087, gnorm=1.23, train_wall=23, wall=0
2024-07-12 23:54:25 | INFO | train_inner | epoch 084:    244 / 1132 loss=2.723, nll_loss=1.079, ppl=2.11, wps=15596.5, ups=4.43, wpb=3521, bsz=155.7, num_updates=94200, lr=0.000103033, gnorm=1.244, train_wall=22, wall=0
2024-07-12 23:54:48 | INFO | train_inner | epoch 084:    344 / 1132 loss=2.759, nll_loss=1.117, ppl=2.17, wps=15878.5, ups=4.43, wpb=3587.1, bsz=123.2, num_updates=94300, lr=0.000102978, gnorm=1.284, train_wall=22, wall=0
2024-07-12 23:55:11 | INFO | train_inner | epoch 084:    444 / 1132 loss=2.759, nll_loss=1.118, ppl=2.17, wps=15808.9, ups=4.42, wpb=3578.6, bsz=132.5, num_updates=94400, lr=0.000102923, gnorm=1.293, train_wall=22, wall=0
2024-07-12 23:55:34 | INFO | train_inner | epoch 084:    544 / 1132 loss=2.739, nll_loss=1.1, ppl=2.14, wps=15745.2, ups=4.38, wpb=3591.3, bsz=158.3, num_updates=94500, lr=0.000102869, gnorm=1.241, train_wall=23, wall=0
2024-07-12 23:55:56 | INFO | train_inner | epoch 084:    644 / 1132 loss=2.762, nll_loss=1.125, ppl=2.18, wps=16170.4, ups=4.51, wpb=3582.8, bsz=139.2, num_updates=94600, lr=0.000102815, gnorm=1.271, train_wall=22, wall=0
2024-07-12 23:56:18 | INFO | train_inner | epoch 084:    744 / 1132 loss=2.769, nll_loss=1.13, ppl=2.19, wps=15753.9, ups=4.43, wpb=3556.1, bsz=133.1, num_updates=94700, lr=0.00010276, gnorm=1.29, train_wall=22, wall=0
2024-07-12 23:56:41 | INFO | train_inner | epoch 084:    844 / 1132 loss=2.788, nll_loss=1.154, ppl=2.23, wps=15821.2, ups=4.36, wpb=3627.9, bsz=144.5, num_updates=94800, lr=0.000102706, gnorm=1.258, train_wall=23, wall=0
2024-07-12 23:57:04 | INFO | train_inner | epoch 084:    944 / 1132 loss=2.767, nll_loss=1.129, ppl=2.19, wps=14877.8, ups=4.32, wpb=3441.3, bsz=141.5, num_updates=94900, lr=0.000102652, gnorm=1.299, train_wall=23, wall=0
2024-07-12 23:57:27 | INFO | train_inner | epoch 084:   1044 / 1132 loss=2.777, nll_loss=1.141, ppl=2.21, wps=16237.1, ups=4.5, wpb=3607.1, bsz=155.9, num_updates=95000, lr=0.000102598, gnorm=1.266, train_wall=22, wall=0
2024-07-12 23:57:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:57:31 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 4.111 | nll_loss 2.547 | ppl 5.84 | wps 44820 | wpb 2685.2 | bsz 107.1 | num_updates 95000 | best_loss 11.022
2024-07-12 23:57:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:57:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_84_95000.pt (epoch 84 @ 95000 updates, score 4.111) (writing took 3.878842136822641 seconds)
2024-07-12 23:57:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-12 23:57:58 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 4.12 | nll_loss 2.55 | ppl 5.86 | wps 44941.5 | wpb 2685.2 | bsz 107.1 | num_updates 95088 | best_loss 11.022
2024-07-12 23:57:58 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-12 23:58:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 84 @ 95088 updates, score 4.12) (writing took 3.531109749339521 seconds)
2024-07-12 23:58:02 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2024-07-12 23:58:02 | INFO | train | epoch 084 | loss 2.757 | nll_loss 1.117 | ppl 2.17 | wps 14353.4 | ups 4.04 | wpb 3556.4 | bsz 141.6 | num_updates 95088 | lr 0.00010255 | gnorm 1.27 | train_wall 254 | wall 0
2024-07-12 23:58:02 | INFO | fairseq.trainer | begin training epoch 85
2024-07-12 23:58:05 | INFO | train_inner | epoch 085:     12 / 1132 loss=2.77, nll_loss=1.132, ppl=2.19, wps=8897.6, ups=2.61, wpb=3413.6, bsz=129.5, num_updates=95100, lr=0.000102544, gnorm=1.313, train_wall=22, wall=0
2024-07-12 23:58:28 | INFO | train_inner | epoch 085:    112 / 1132 loss=2.699, nll_loss=1.049, ppl=2.07, wps=15051.8, ups=4.29, wpb=3505.6, bsz=154.6, num_updates=95200, lr=0.00010249, gnorm=1.248, train_wall=23, wall=0
2024-07-12 23:58:51 | INFO | train_inner | epoch 085:    212 / 1132 loss=2.719, nll_loss=1.074, ppl=2.1, wps=15711.7, ups=4.38, wpb=3587.9, bsz=155.4, num_updates=95300, lr=0.000102436, gnorm=1.223, train_wall=23, wall=0
2024-07-12 23:59:13 | INFO | train_inner | epoch 085:    312 / 1132 loss=2.739, nll_loss=1.097, ppl=2.14, wps=15989.8, ups=4.49, wpb=3559.2, bsz=136.8, num_updates=95400, lr=0.000102383, gnorm=1.27, train_wall=22, wall=0
2024-07-12 23:59:36 | INFO | train_inner | epoch 085:    412 / 1132 loss=2.747, nll_loss=1.105, ppl=2.15, wps=15582.7, ups=4.31, wpb=3614.5, bsz=147.3, num_updates=95500, lr=0.000102329, gnorm=1.252, train_wall=23, wall=0
2024-07-13 00:00:00 | INFO | train_inner | epoch 085:    512 / 1132 loss=2.763, nll_loss=1.123, ppl=2.18, wps=15432, ups=4.29, wpb=3593.2, bsz=134.6, num_updates=95600, lr=0.000102275, gnorm=1.283, train_wall=23, wall=0
2024-07-13 00:00:22 | INFO | train_inner | epoch 085:    612 / 1132 loss=2.748, nll_loss=1.11, ppl=2.16, wps=15669, ups=4.41, wpb=3556.7, bsz=151.9, num_updates=95700, lr=0.000102222, gnorm=1.26, train_wall=23, wall=0
2024-07-13 00:00:45 | INFO | train_inner | epoch 085:    712 / 1132 loss=2.765, nll_loss=1.129, ppl=2.19, wps=16046.2, ups=4.45, wpb=3605.4, bsz=143.4, num_updates=95800, lr=0.000102169, gnorm=1.275, train_wall=22, wall=0
2024-07-13 00:01:07 | INFO | train_inner | epoch 085:    812 / 1132 loss=2.764, nll_loss=1.126, ppl=2.18, wps=16183.6, ups=4.51, wpb=3587.6, bsz=151.4, num_updates=95900, lr=0.000102115, gnorm=1.267, train_wall=22, wall=0
2024-07-13 00:01:29 | INFO | train_inner | epoch 085:    912 / 1132 loss=2.781, nll_loss=1.144, ppl=2.21, wps=16023.9, ups=4.53, wpb=3536.8, bsz=120.5, num_updates=96000, lr=0.000102062, gnorm=1.308, train_wall=22, wall=0
2024-07-13 00:01:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-13 00:01:33 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 4.112 | nll_loss 2.545 | ppl 5.84 | wps 45012.9 | wpb 2685.2 | bsz 107.1 | num_updates 96000 | best_loss 11.022
2024-07-13 00:01:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-13 00:01:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_85_96000.pt (epoch 85 @ 96000 updates, score 4.112) (writing took 5.124069705605507 seconds)
2024-07-13 00:02:01 | INFO | train_inner | epoch 085:   1012 / 1132 loss=2.775, nll_loss=1.137, ppl=2.2, wps=10928.7, ups=3.14, wpb=3478.7, bsz=123.6, num_updates=96100, lr=0.000102009, gnorm=1.322, train_wall=22, wall=0
2024-07-13 00:02:24 | INFO | train_inner | epoch 085:   1112 / 1132 loss=2.787, nll_loss=1.152, ppl=2.22, wps=15555.5, ups=4.39, wpb=3542.9, bsz=139.4, num_updates=96200, lr=0.000101956, gnorm=1.311, train_wall=23, wall=0
2024-07-13 00:02:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-13 00:02:32 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 4.113 | nll_loss 2.545 | ppl 5.84 | wps 44869.3 | wpb 2685.2 | bsz 107.1 | num_updates 96220 | best_loss 11.022
2024-07-13 00:02:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-13 00:02:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 85 @ 96220 updates, score 4.113) (writing took 3.384339719079435 seconds)
2024-07-13 00:02:36 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2024-07-13 00:02:36 | INFO | train | epoch 085 | loss 2.753 | nll_loss 1.113 | ppl 2.16 | wps 14695.3 | ups 4.13 | wpb 3556.4 | bsz 141.6 | num_updates 96220 | lr 0.000101945 | gnorm 1.275 | train_wall 255 | wall 0
2024-07-13 00:02:36 | INFO | fairseq.trainer | begin training epoch 86
2024-07-13 00:02:54 | INFO | train_inner | epoch 086:     80 / 1132 loss=2.721, nll_loss=1.076, ppl=2.11, wps=11552.2, ups=3.29, wpb=3507.2, bsz=135.3, num_updates=96300, lr=0.000101903, gnorm=1.28, train_wall=22, wall=0
2024-07-13 00:03:17 | INFO | train_inner | epoch 086:    180 / 1132 loss=2.721, nll_loss=1.077, ppl=2.11, wps=15893.5, ups=4.38, wpb=3629.3, bsz=145.5, num_updates=96400, lr=0.00010185, gnorm=1.24, train_wall=23, wall=0
2024-07-13 00:03:40 | INFO | train_inner | epoch 086:    280 / 1132 loss=2.722, nll_loss=1.078, ppl=2.11, wps=15723.9, ups=4.44, wpb=3542.5, bsz=149.4, num_updates=96500, lr=0.000101797, gnorm=1.273, train_wall=22, wall=0
2024-07-13 00:04:02 | INFO | train_inner | epoch 086:    380 / 1132 loss=2.739, nll_loss=1.096, ppl=2.14, wps=15602.3, ups=4.38, wpb=3561.8, bsz=128.9, num_updates=96600, lr=0.000101745, gnorm=1.27, train_wall=23, wall=0
2024-07-13 00:04:25 | INFO | train_inner | epoch 086:    480 / 1132 loss=2.745, nll_loss=1.105, ppl=2.15, wps=15760.6, ups=4.32, wpb=3644.8, bsz=158.2, num_updates=96700, lr=0.000101692, gnorm=1.246, train_wall=23, wall=0
2024-07-13 00:04:48 | INFO | train_inner | epoch 086:    580 / 1132 loss=2.752, nll_loss=1.111, ppl=2.16, wps=15660.4, ups=4.38, wpb=3575.6, bsz=140.1, num_updates=96800, lr=0.000101639, gnorm=1.284, train_wall=23, wall=0
2024-07-13 00:05:11 | INFO | train_inner | epoch 086:    680 / 1132 loss=2.762, nll_loss=1.122, ppl=2.18, wps=15412.3, ups=4.33, wpb=3558.4, bsz=128, num_updates=96900, lr=0.000101587, gnorm=1.288, train_wall=23, wall=0
2024-07-13 00:05:34 | INFO | train_inner | epoch 086:    780 / 1132 loss=2.76, nll_loss=1.119, ppl=2.17, wps=15236.9, ups=4.36, wpb=3495.8, bsz=133.8, num_updates=97000, lr=0.000101535, gnorm=1.297, train_wall=23, wall=0
2024-07-13 00:05:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-13 00:05:39 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 4.132 | nll_loss 2.571 | ppl 5.94 | wps 44500.6 | wpb 2685.2 | bsz 107.1 | num_updates 97000 | best_loss 11.022
2024-07-13 00:05:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-13 00:05:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_86_97000.pt (epoch 86 @ 97000 updates, score 4.132) (writing took 4.044483101926744 seconds)
2024-07-13 00:06:06 | INFO | train_inner | epoch 086:    880 / 1132 loss=2.766, nll_loss=1.129, ppl=2.19, wps=11361.7, ups=3.17, wpb=3583.1, bsz=150.6, num_updates=97100, lr=0.000101482, gnorm=1.281, train_wall=23, wall=0
2024-07-13 00:06:29 | INFO | train_inner | epoch 086:    980 / 1132 loss=2.756, nll_loss=1.115, ppl=2.17, wps=15177.1, ups=4.34, wpb=3494.1, bsz=139.8, num_updates=97200, lr=0.00010143, gnorm=1.29, train_wall=23, wall=0
2024-07-13 00:06:51 | INFO | train_inner | epoch 086:   1080 / 1132 loss=2.767, nll_loss=1.13, ppl=2.19, wps=15684, ups=4.48, wpb=3503.4, bsz=144.8, num_updates=97300, lr=0.000101378, gnorm=1.297, train_wall=22, wall=0
2024-07-13 00:07:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-13 00:07:07 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 4.113 | nll_loss 2.548 | ppl 5.85 | wps 44688.6 | wpb 2685.2 | bsz 107.1 | num_updates 97352 | best_loss 11.022
2024-07-13 00:07:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-13 00:07:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 86 @ 97352 updates, score 4.113) (writing took 3.495224834419787 seconds)
2024-07-13 00:07:11 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2024-07-13 00:07:11 | INFO | train | epoch 086 | loss 2.747 | nll_loss 1.106 | ppl 2.15 | wps 14644.3 | ups 4.12 | wpb 3556.4 | bsz 141.6 | num_updates 97352 | lr 0.000101351 | gnorm 1.278 | train_wall 257 | wall 0
2024-07-13 00:07:11 | INFO | fairseq.trainer | begin training epoch 87
2024-07-13 00:07:22 | INFO | train_inner | epoch 087:     48 / 1132 loss=2.74, nll_loss=1.099, ppl=2.14, wps=11653.2, ups=3.24, wpb=3599.6, bsz=151.6, num_updates=97400, lr=0.000101326, gnorm=1.271, train_wall=23, wall=0
2024-07-13 00:07:45 | INFO | train_inner | epoch 087:    148 / 1132 loss=2.715, nll_loss=1.07, ppl=2.1, wps=15556.3, ups=4.29, wpb=3622.4, bsz=145.9, num_updates=97500, lr=0.000101274, gnorm=1.234, train_wall=23, wall=0
2024-07-13 00:08:09 | INFO | train_inner | epoch 087:    248 / 1132 loss=2.731, nll_loss=1.086, ppl=2.12, wps=15507, ups=4.27, wpb=3634.7, bsz=141, num_updates=97600, lr=0.000101222, gnorm=1.262, train_wall=23, wall=0
2024-07-13 00:08:32 | INFO | train_inner | epoch 087:    348 / 1132 loss=2.72, nll_loss=1.074, ppl=2.11, wps=15522, ups=4.4, wpb=3525.1, bsz=141.8, num_updates=97700, lr=0.00010117, gnorm=1.262, train_wall=23, wall=0
2024-07-13 00:08:54 | INFO | train_inner | epoch 087:    448 / 1132 loss=2.743, nll_loss=1.097, ppl=2.14, wps=15393.1, ups=4.44, wpb=3466.5, bsz=120.7, num_updates=97800, lr=0.000101118, gnorm=1.343, train_wall=22, wall=0
2024-07-13 00:09:17 | INFO | train_inner | epoch 087:    548 / 1132 loss=2.732, nll_loss=1.089, ppl=2.13, wps=15509.2, ups=4.35, wpb=3565.7, bsz=150.2, num_updates=97900, lr=0.000101067, gnorm=1.265, train_wall=23, wall=0
2024-07-13 00:09:40 | INFO | train_inner | epoch 087:    648 / 1132 loss=2.742, nll_loss=1.101, ppl=2.14, wps=15514.4, ups=4.38, wpb=3542.4, bsz=137.8, num_updates=98000, lr=0.000101015, gnorm=1.281, train_wall=23, wall=0
2024-07-13 00:09:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-13 00:09:44 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 4.133 | nll_loss 2.565 | ppl 5.92 | wps 44726.6 | wpb 2685.2 | bsz 107.1 | num_updates 98000 | best_loss 11.022
2024-07-13 00:09:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-13 00:09:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_87_98000.pt (epoch 87 @ 98000 updates, score 4.133) (writing took 4.204052415676415 seconds)
2024-07-13 00:10:11 | INFO | train_inner | epoch 087:    748 / 1132 loss=2.742, nll_loss=1.1, ppl=2.14, wps=11159.2, ups=3.23, wpb=3450.5, bsz=134.8, num_updates=98100, lr=0.000100964, gnorm=1.306, train_wall=22, wall=0
2024-07-13 00:10:34 | INFO | train_inner | epoch 087:    848 / 1132 loss=2.745, nll_loss=1.107, ppl=2.15, wps=15899.3, ups=4.36, wpb=3644.4, bsz=172.5, num_updates=98200, lr=0.000100912, gnorm=1.239, train_wall=23, wall=0
2024-07-13 00:10:57 | INFO | train_inner | epoch 087:    948 / 1132 loss=2.78, nll_loss=1.144, ppl=2.21, wps=15743.5, ups=4.35, wpb=3617.2, bsz=131.9, num_updates=98300, lr=0.000100861, gnorm=1.304, train_wall=23, wall=0
2024-07-13 00:11:19 | INFO | train_inner | epoch 087:   1048 / 1132 loss=2.751, nll_loss=1.112, ppl=2.16, wps=15395.1, ups=4.43, wpb=3476.7, bsz=145.8, num_updates=98400, lr=0.00010081, gnorm=1.293, train_wall=22, wall=0
2024-07-13 00:11:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-13 00:11:42 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 4.12 | nll_loss 2.558 | ppl 5.89 | wps 44877.5 | wpb 2685.2 | bsz 107.1 | num_updates 98484 | best_loss 11.022
2024-07-13 00:11:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-13 00:11:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 87 @ 98484 updates, score 4.12) (writing took 3.429826687090099 seconds)
2024-07-13 00:11:46 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2024-07-13 00:11:46 | INFO | train | epoch 087 | loss 2.741 | nll_loss 1.099 | ppl 2.14 | wps 14635.2 | ups 4.12 | wpb 3556.4 | bsz 141.6 | num_updates 98484 | lr 0.000100767 | gnorm 1.278 | train_wall 257 | wall 0
2024-07-13 00:11:46 | INFO | fairseq.trainer | begin training epoch 88
2024-07-13 00:11:50 | INFO | train_inner | epoch 088:     16 / 1132 loss=2.762, nll_loss=1.123, ppl=2.18, wps=11639.9, ups=3.28, wpb=3549, bsz=124.3, num_updates=98500, lr=0.000100759, gnorm=1.286, train_wall=23, wall=0
2024-07-13 00:12:13 | INFO | train_inner | epoch 088:    116 / 1132 loss=2.696, nll_loss=1.047, ppl=2.07, wps=15506.9, ups=4.36, wpb=3556.2, bsz=148.2, num_updates=98600, lr=0.000100707, gnorm=1.246, train_wall=23, wall=0
2024-07-13 00:12:36 | INFO | train_inner | epoch 088:    216 / 1132 loss=2.716, nll_loss=1.069, ppl=2.1, wps=15561.4, ups=4.37, wpb=3561.7, bsz=140.9, num_updates=98700, lr=0.000100656, gnorm=1.293, train_wall=23, wall=0
2024-07-13 00:12:59 | INFO | train_inner | epoch 088:    316 / 1132 loss=2.736, nll_loss=1.091, ppl=2.13, wps=15703, ups=4.27, wpb=3677.2, bsz=142.8, num_updates=98800, lr=0.000100605, gnorm=1.239, train_wall=23, wall=0
2024-07-13 00:13:22 | INFO | train_inner | epoch 088:    416 / 1132 loss=2.727, nll_loss=1.084, ppl=2.12, wps=15884.8, ups=4.42, wpb=3591.2, bsz=130.7, num_updates=98900, lr=0.000100555, gnorm=1.257, train_wall=22, wall=0
2024-07-13 00:13:45 | INFO | train_inner | epoch 088:    516 / 1132 loss=2.725, nll_loss=1.082, ppl=2.12, wps=15561.7, ups=4.32, wpb=3599.1, bsz=172.2, num_updates=99000, lr=0.000100504, gnorm=1.258, train_wall=23, wall=0
2024-07-13 00:13:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-13 00:13:49 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 4.126 | nll_loss 2.566 | ppl 5.92 | wps 44761.2 | wpb 2685.2 | bsz 107.1 | num_updates 99000 | best_loss 11.022
2024-07-13 00:13:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-13 00:13:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_88_99000.pt (epoch 88 @ 99000 updates, score 4.126) (writing took 4.574582328088582 seconds)
2024-07-13 00:14:17 | INFO | train_inner | epoch 088:    616 / 1132 loss=2.735, nll_loss=1.093, ppl=2.13, wps=10937, ups=3.13, wpb=3492.3, bsz=131.4, num_updates=99100, lr=0.000100453, gnorm=1.289, train_wall=23, wall=0
2024-07-13 00:14:40 | INFO | train_inner | epoch 088:    716 / 1132 loss=2.741, nll_loss=1.099, ppl=2.14, wps=15484.3, ups=4.36, wpb=3549.6, bsz=140.6, num_updates=99200, lr=0.000100402, gnorm=1.286, train_wall=23, wall=0
2024-07-13 00:15:02 | INFO | train_inner | epoch 088:    816 / 1132 loss=2.745, nll_loss=1.105, ppl=2.15, wps=15555.8, ups=4.43, wpb=3508.4, bsz=139, num_updates=99300, lr=0.000100352, gnorm=1.315, train_wall=22, wall=0
2024-07-13 00:15:25 | INFO | train_inner | epoch 088:    916 / 1132 loss=2.756, nll_loss=1.117, ppl=2.17, wps=15389.1, ups=4.39, wpb=3505.1, bsz=132.6, num_updates=99400, lr=0.000100301, gnorm=1.307, train_wall=23, wall=0
2024-07-13 00:15:48 | INFO | train_inner | epoch 088:   1016 / 1132 loss=2.758, nll_loss=1.119, ppl=2.17, wps=15420.5, ups=4.4, wpb=3505.8, bsz=136.4, num_updates=99500, lr=0.000100251, gnorm=1.331, train_wall=23, wall=0
2024-07-13 00:16:10 | INFO | train_inner | epoch 088:   1116 / 1132 loss=2.762, nll_loss=1.124, ppl=2.18, wps=15654.6, ups=4.4, wpb=3555.3, bsz=145.8, num_updates=99600, lr=0.000100201, gnorm=1.286, train_wall=23, wall=0
2024-07-13 00:16:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-13 00:16:18 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 4.121 | nll_loss 2.558 | ppl 5.89 | wps 44854.9 | wpb 2685.2 | bsz 107.1 | num_updates 99616 | best_loss 11.022
2024-07-13 00:16:18 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-13 00:16:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 88 @ 99616 updates, score 4.121) (writing took 3.8311331160366535 seconds)
2024-07-13 00:16:22 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2024-07-13 00:16:22 | INFO | train | epoch 088 | loss 2.736 | nll_loss 1.094 | ppl 2.13 | wps 14574.8 | ups 4.1 | wpb 3556.4 | bsz 141.6 | num_updates 99616 | lr 0.000100193 | gnorm 1.282 | train_wall 257 | wall 0
2024-07-13 00:16:22 | INFO | fairseq.trainer | begin training epoch 89
2024-07-13 00:16:41 | INFO | train_inner | epoch 089:     84 / 1132 loss=2.692, nll_loss=1.042, ppl=2.06, wps=11237.2, ups=3.23, wpb=3476, bsz=142.1, num_updates=99700, lr=0.00010015, gnorm=1.264, train_wall=23, wall=0
2024-07-13 00:17:04 | INFO | train_inner | epoch 089:    184 / 1132 loss=2.721, nll_loss=1.075, ppl=2.11, wps=15846, ups=4.43, wpb=3575.3, bsz=130, num_updates=99800, lr=0.0001001, gnorm=1.285, train_wall=22, wall=0
2024-07-13 00:17:27 | INFO | train_inner | epoch 089:    284 / 1132 loss=2.71, nll_loss=1.065, ppl=2.09, wps=15718.5, ups=4.33, wpb=3634.3, bsz=152, num_updates=99900, lr=0.00010005, gnorm=1.248, train_wall=23, wall=0
2024-07-13 00:17:50 | INFO | train_inner | epoch 089:    384 / 1132 loss=2.717, nll_loss=1.072, ppl=2.1, wps=15638.4, ups=4.41, wpb=3548.8, bsz=144.6, num_updates=100000, lr=0.0001, gnorm=1.287, train_wall=23, wall=0
2024-07-13 00:17:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-13 00:17:54 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 4.128 | nll_loss 2.564 | ppl 5.91 | wps 44791.5 | wpb 2685.2 | bsz 107.1 | num_updates 100000 | best_loss 11.022
2024-07-13 00:17:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-13 00:17:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_89_100000.pt (epoch 89 @ 100000 updates, score 4.128) (writing took 4.178892311640084 seconds)
2024-07-13 00:17:58 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2024-07-13 00:17:58 | INFO | train | epoch 089 | loss 2.707 | nll_loss 1.06 | ppl 2.08 | wps 14224.9 | ups 4 | wpb 3557.4 | bsz 142.8 | num_updates 100000 | lr 0.0001 | gnorm 1.269 | train_wall 87 | wall 0
2024-07-13 00:17:58 | INFO | fairseq_cli.train | done training in 22276.9 seconds
