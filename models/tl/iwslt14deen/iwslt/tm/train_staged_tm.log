2024-05-30 16:58:30 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/iwslt14.sep.tokenized.de-en', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='de', srcdict=None, target_lang='en', task='translation', tensorboard_logdir=None, testpref='/local/home/ggabriel/ma/data/sentp/iwslt14.sep.tokenized.de-en/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/local/home/ggabriel/ma/data/sentp/iwslt14.sep.tokenized.de-en/train', user_dir=None, validpref='/local/home/ggabriel/ma/data/sentp/iwslt14.sep.tokenized.de-en/valid', workers=20)
2024-05-30 16:58:33 | INFO | fairseq_cli.preprocess | [de] Dictionary: 9952 types
2024-05-30 16:58:37 | INFO | fairseq_cli.preprocess | [de] /local/home/ggabriel/ma/data/sentp/iwslt14.sep.tokenized.de-en/train.de: 160239 sents, 3947193 tokens, 0.0% replaced by <unk>
2024-05-30 16:58:37 | INFO | fairseq_cli.preprocess | [de] Dictionary: 9952 types
2024-05-30 16:58:37 | INFO | fairseq_cli.preprocess | [de] /local/home/ggabriel/ma/data/sentp/iwslt14.sep.tokenized.de-en/valid.de: 7283 sents, 178832 tokens, 0.0% replaced by <unk>
2024-05-30 16:58:37 | INFO | fairseq_cli.preprocess | [de] Dictionary: 9952 types
2024-05-30 16:58:38 | INFO | fairseq_cli.preprocess | [de] /local/home/ggabriel/ma/data/sentp/iwslt14.sep.tokenized.de-en/test.de: 6750 sents, 158055 tokens, 0.0297% replaced by <unk>
2024-05-30 16:58:38 | INFO | fairseq_cli.preprocess | [en] Dictionary: 9840 types
2024-05-30 16:58:42 | INFO | fairseq_cli.preprocess | [en] /local/home/ggabriel/ma/data/sentp/iwslt14.sep.tokenized.de-en/train.en: 160239 sents, 4025857 tokens, 0.0% replaced by <unk>
2024-05-30 16:58:42 | INFO | fairseq_cli.preprocess | [en] Dictionary: 9840 types
2024-05-30 16:58:42 | INFO | fairseq_cli.preprocess | [en] /local/home/ggabriel/ma/data/sentp/iwslt14.sep.tokenized.de-en/valid.en: 7283 sents, 182594 tokens, 0.000548% replaced by <unk>
2024-05-30 16:58:42 | INFO | fairseq_cli.preprocess | [en] Dictionary: 9840 types
2024-05-30 16:58:43 | INFO | fairseq_cli.preprocess | [en] /local/home/ggabriel/ma/data/sentp/iwslt14.sep.tokenized.de-en/test.en: 6750 sents, 160684 tokens, 0.00622% replaced by <unk>
2024-05-30 16:58:43 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/iwslt14.sep.tokenized.de-en
2024-05-30 16:58:44 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.sep.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=1000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=100, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-05-30 16:58:44 | INFO | fairseq.tasks.translation | [de] dictionary: 9952 types
2024-05-30 16:58:44 | INFO | fairseq.tasks.translation | [en] dictionary: 9840 types
2024-05-30 16:58:44 | INFO | fairseq.data.data_utils | loaded 7283 examples from: data-bin/iwslt14.sep.tokenized.de-en/valid.de-en.de
2024-05-30 16:58:44 | INFO | fairseq.data.data_utils | loaded 7283 examples from: data-bin/iwslt14.sep.tokenized.de-en/valid.de-en.en
2024-05-30 16:58:44 | INFO | fairseq.tasks.translation | data-bin/iwslt14.sep.tokenized.de-en valid de-en 7283 examples
2024-05-30 16:58:45 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9952, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9840, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=9840, bias=False)
  )
)
2024-05-30 16:58:45 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-05-30 16:58:45 | INFO | fairseq_cli.train | model: transformer_iwslt_de_en (TransformerModel)
2024-05-30 16:58:45 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-05-30 16:58:45 | INFO | fairseq_cli.train | num. model params: 41676800 (num. trained: 41676800)
2024-05-30 16:58:49 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-05-30 16:58:49 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-05-30 16:58:49 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-05-30 16:58:49 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-05-30 16:58:49 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-05-30 16:58:49 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-05-30 16:58:49 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/checkpoint_last.pt
2024-05-30 16:58:49 | INFO | fairseq.trainer | loading train data for epoch 1
2024-05-30 16:58:49 | INFO | fairseq.data.data_utils | loaded 160239 examples from: data-bin/iwslt14.sep.tokenized.de-en/train.de-en.de
2024-05-30 16:58:49 | INFO | fairseq.data.data_utils | loaded 160239 examples from: data-bin/iwslt14.sep.tokenized.de-en/train.de-en.en
2024-05-30 16:58:49 | INFO | fairseq.tasks.translation | data-bin/iwslt14.sep.tokenized.de-en train de-en 160239 examples
2024-05-30 16:58:49 | INFO | fairseq.trainer | begin training epoch 1
2024-05-30 16:59:09 | INFO | train_inner | epoch 001:    100 / 1132 loss=12.426, nll_loss=12.248, ppl=4863.09, wps=18748.7, ups=5.27, wpb=3559.9, bsz=121.1, num_updates=100, lr=1.25e-05, gnorm=3.912, train_wall=19, wall=20
2024-05-30 16:59:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-05-30 16:59:12 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.059 | nll_loss 10.711 | ppl 1675.97 | wps 55605 | wpb 2685.2 | bsz 107.1 | num_updates 100
2024-05-30 16:59:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 16:59:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_100.pt (epoch 1 @ 100 updates, score 11.059) (writing took 2.283700677100569 seconds)
2024-05-30 16:59:34 | INFO | train_inner | epoch 001:    200 / 1132 loss=10.823, nll_loss=10.458, ppl=1406.34, wps=14343.4, ups=4.01, wpb=3580.7, bsz=147, num_updates=200, lr=2.5e-05, gnorm=2.041, train_wall=19, wall=44
2024-05-30 16:59:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 16:59:37 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.216 | nll_loss 9.766 | ppl 870.92 | wps 54474.4 | wpb 2685.2 | bsz 107.1 | num_updates 200 | best_loss 11.059
2024-05-30 16:59:37 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 16:59:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_200.pt (epoch 1 @ 200 updates, score 10.216) (writing took 3.6605020873248577 seconds)
2024-05-30 17:00:00 | INFO | train_inner | epoch 001:    300 / 1132 loss=9.89, nll_loss=9.394, ppl=672.87, wps=13292.9, ups=3.77, wpb=3521.9, bsz=131.7, num_updates=300, lr=3.75e-05, gnorm=1.916, train_wall=19, wall=71
2024-05-30 17:00:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:00:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.234 | nll_loss 8.586 | ppl 384.2 | wps 49425.6 | wpb 2685.2 | bsz 107.1 | num_updates 300 | best_loss 11.059
2024-05-30 17:00:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:00:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_300.pt (epoch 1 @ 300 updates, score 9.234) (writing took 4.259607602842152 seconds)
2024-05-30 17:00:28 | INFO | train_inner | epoch 001:    400 / 1132 loss=9.264, nll_loss=8.635, ppl=397.55, wps=12289.6, ups=3.56, wpb=3450.9, bsz=145.2, num_updates=400, lr=5e-05, gnorm=2.08, train_wall=20, wall=99
2024-05-30 17:00:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:00:32 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.964 | nll_loss 8.24 | ppl 302.25 | wps 51383.9 | wpb 2685.2 | bsz 107.1 | num_updates 400 | best_loss 11.059
2024-05-30 17:00:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:00:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_400.pt (epoch 1 @ 400 updates, score 8.964) (writing took 4.614321821834892 seconds)
2024-05-30 17:00:56 | INFO | train_inner | epoch 001:    500 / 1132 loss=8.852, nll_loss=8.146, ppl=283.2, wps=12763.8, ups=3.54, wpb=3609.1, bsz=165.4, num_updates=500, lr=6.25e-05, gnorm=1.793, train_wall=20, wall=127
2024-05-30 17:00:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:01:00 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.838 | nll_loss 8.082 | ppl 271.04 | wps 51068.5 | wpb 2685.2 | bsz 107.1 | num_updates 500 | best_loss 11.059
2024-05-30 17:01:00 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:01:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_500.pt (epoch 1 @ 500 updates, score 8.838) (writing took 4.211874598637223 seconds)
2024-05-30 17:01:24 | INFO | train_inner | epoch 001:    600 / 1132 loss=8.654, nll_loss=7.913, ppl=240.95, wps=12895, ups=3.62, wpb=3562.1, bsz=134.6, num_updates=600, lr=7.5e-05, gnorm=1.646, train_wall=19, wall=155
2024-05-30 17:01:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:01:28 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.604 | nll_loss 7.795 | ppl 222.14 | wps 52062.8 | wpb 2685.2 | bsz 107.1 | num_updates 600 | best_loss 11.059
2024-05-30 17:01:28 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:01:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_600.pt (epoch 1 @ 600 updates, score 8.604) (writing took 4.256395933683962 seconds)
2024-05-30 17:01:52 | INFO | train_inner | epoch 001:    700 / 1132 loss=8.528, nll_loss=7.77, ppl=218.27, wps=12767.6, ups=3.55, wpb=3597.5, bsz=159.4, num_updates=700, lr=8.75e-05, gnorm=1.693, train_wall=20, wall=183
2024-05-30 17:01:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:01:56 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.391 | nll_loss 7.566 | ppl 189.45 | wps 50524.9 | wpb 2685.2 | bsz 107.1 | num_updates 700 | best_loss 11.059
2024-05-30 17:01:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:02:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_700.pt (epoch 1 @ 700 updates, score 8.391) (writing took 6.926312671974301 seconds)
2024-05-30 17:02:23 | INFO | train_inner | epoch 001:    800 / 1132 loss=8.415, nll_loss=7.637, ppl=198.99, wps=11611.1, ups=3.24, wpb=3578.7, bsz=133.7, num_updates=800, lr=0.0001, gnorm=1.68, train_wall=20, wall=214
2024-05-30 17:02:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:02:27 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.284 | nll_loss 7.434 | ppl 172.94 | wps 50390.2 | wpb 2685.2 | bsz 107.1 | num_updates 800 | best_loss 11.059
2024-05-30 17:02:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:02:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_800.pt (epoch 1 @ 800 updates, score 8.284) (writing took 5.780059861950576 seconds)
2024-05-30 17:02:53 | INFO | train_inner | epoch 001:    900 / 1132 loss=8.282, nll_loss=7.484, ppl=179.01, wps=12023.1, ups=3.35, wpb=3590.2, bsz=147.1, num_updates=900, lr=0.0001125, gnorm=1.761, train_wall=20, wall=244
2024-05-30 17:02:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:02:57 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.192 | nll_loss 7.319 | ppl 159.7 | wps 50938.7 | wpb 2685.2 | bsz 107.1 | num_updates 900 | best_loss 11.059
2024-05-30 17:02:57 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:03:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_900.pt (epoch 1 @ 900 updates, score 8.192) (writing took 5.768332411069423 seconds)
2024-05-30 17:03:23 | INFO | train_inner | epoch 001:   1000 / 1132 loss=8.27, nll_loss=7.468, ppl=177.07, wps=11676.9, ups=3.35, wpb=3486.1, bsz=139.7, num_updates=1000, lr=0.000125, gnorm=1.543, train_wall=20, wall=274
2024-05-30 17:03:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:03:26 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.005 | nll_loss 7.128 | ppl 139.84 | wps 50915.3 | wpb 2685.2 | bsz 107.1 | num_updates 1000 | best_loss 11.059
2024-05-30 17:03:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:03:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 8.005) (writing took 6.901601407211274 seconds)
2024-05-30 17:03:33 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-05-30 17:03:33 | INFO | train | epoch 001 | loss 9.34 | nll_loss 8.715 | ppl 420.16 | wps 12519 | ups 3.52 | wpb 3553.7 | bsz 142.5 | num_updates 1000 | lr 0.000125 | gnorm 2.007 | train_wall 194 | wall 284
2024-05-30 17:03:33 | INFO | fairseq_cli.train | done training in 284.1 seconds
2024-05-30 17:03:35 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.sep.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=10000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=500, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-05-30 17:03:35 | INFO | fairseq.tasks.translation | [de] dictionary: 9952 types
2024-05-30 17:03:35 | INFO | fairseq.tasks.translation | [en] dictionary: 9840 types
2024-05-30 17:03:35 | INFO | fairseq.data.data_utils | loaded 7283 examples from: data-bin/iwslt14.sep.tokenized.de-en/valid.de-en.de
2024-05-30 17:03:35 | INFO | fairseq.data.data_utils | loaded 7283 examples from: data-bin/iwslt14.sep.tokenized.de-en/valid.de-en.en
2024-05-30 17:03:35 | INFO | fairseq.tasks.translation | data-bin/iwslt14.sep.tokenized.de-en valid de-en 7283 examples
2024-05-30 17:03:36 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9952, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9840, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=9840, bias=False)
  )
)
2024-05-30 17:03:36 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-05-30 17:03:36 | INFO | fairseq_cli.train | model: transformer_iwslt_de_en (TransformerModel)
2024-05-30 17:03:36 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-05-30 17:03:36 | INFO | fairseq_cli.train | num. model params: 41676800 (num. trained: 41676800)
2024-05-30 17:03:41 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-05-30 17:03:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-05-30 17:03:41 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-05-30 17:03:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-05-30 17:03:41 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-05-30 17:03:41 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-05-30 17:03:42 | INFO | fairseq.trainer | loaded checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 1000 updates)
2024-05-30 17:03:42 | INFO | fairseq.trainer | loading train data for epoch 1
2024-05-30 17:03:42 | INFO | fairseq.data.data_utils | loaded 160239 examples from: data-bin/iwslt14.sep.tokenized.de-en/train.de-en.de
2024-05-30 17:03:42 | INFO | fairseq.data.data_utils | loaded 160239 examples from: data-bin/iwslt14.sep.tokenized.de-en/train.de-en.en
2024-05-30 17:03:42 | INFO | fairseq.tasks.translation | data-bin/iwslt14.sep.tokenized.de-en train de-en 160239 examples
2024-05-30 17:03:42 | INFO | fairseq.trainer | begin training epoch 1
2024-05-30 17:04:03 | INFO | train_inner | epoch 001:   1100 / 1132 loss=8.13, nll_loss=7.307, ppl=158.35, wps=14348.6, ups=4.04, wpb=3551.7, bsz=135, num_updates=1100, lr=0.0001375, gnorm=1.515, train_wall=20, wall=0
2024-05-30 17:04:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-05-30 17:04:13 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.796 | nll_loss 6.884 | ppl 118.08 | wps 50921.8 | wpb 2685.2 | bsz 107.1 | num_updates 1132 | best_loss 11.059
2024-05-30 17:04:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:04:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 1132 updates, score 7.796) (writing took 3.3741951640695333 seconds)
2024-05-30 17:04:16 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-05-30 17:04:16 | INFO | train | epoch 001 | loss 9.194 | nll_loss 8.545 | ppl 373.39 | wps 12916.9 | ups 3.63 | wpb 3556.4 | bsz 141.6 | num_updates 1132 | lr 0.0001415 | gnorm 1.946 | train_wall 221 | wall 0
2024-05-30 17:04:16 | INFO | fairseq.trainer | begin training epoch 2
2024-05-30 17:04:30 | INFO | train_inner | epoch 002:     68 / 1132 loss=7.969, nll_loss=7.12, ppl=139.13, wps=12758.8, ups=3.59, wpb=3553.3, bsz=126.2, num_updates=1200, lr=0.00015, gnorm=1.535, train_wall=20, wall=0
2024-05-30 17:04:50 | INFO | train_inner | epoch 002:    168 / 1132 loss=7.742, nll_loss=6.858, ppl=115.98, wps=17479.7, ups=4.98, wpb=3508.3, bsz=159.3, num_updates=1300, lr=0.0001625, gnorm=1.555, train_wall=20, wall=0
2024-05-30 17:05:11 | INFO | train_inner | epoch 002:    268 / 1132 loss=7.736, nll_loss=6.849, ppl=115.27, wps=17623, ups=4.97, wpb=3545.4, bsz=136.7, num_updates=1400, lr=0.000175, gnorm=1.447, train_wall=20, wall=0
2024-05-30 17:05:31 | INFO | train_inner | epoch 002:    368 / 1132 loss=7.642, nll_loss=6.741, ppl=106.94, wps=17772.4, ups=4.96, wpb=3580.1, bsz=148, num_updates=1500, lr=0.0001875, gnorm=1.42, train_wall=20, wall=0
2024-05-30 17:05:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:05:35 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.547 | nll_loss 6.578 | ppl 95.55 | wps 49262.1 | wpb 2685.2 | bsz 107.1 | num_updates 1500 | best_loss 11.059
2024-05-30 17:05:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:05:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_1500.pt (epoch 2 @ 1500 updates, score 7.547) (writing took 4.504884397145361 seconds)
2024-05-30 17:05:59 | INFO | train_inner | epoch 002:    468 / 1132 loss=7.678, nll_loss=6.782, ppl=110.02, wps=12460.9, ups=3.49, wpb=3575.4, bsz=136.5, num_updates=1600, lr=0.0002, gnorm=1.325, train_wall=20, wall=0
2024-05-30 17:06:20 | INFO | train_inner | epoch 002:    568 / 1132 loss=7.611, nll_loss=6.705, ppl=104.33, wps=17393.7, ups=4.92, wpb=3532.1, bsz=146.7, num_updates=1700, lr=0.0002125, gnorm=1.309, train_wall=20, wall=0
2024-05-30 17:06:39 | INFO | train_inner | epoch 002:    668 / 1132 loss=7.385, nll_loss=6.444, ppl=87.04, wps=18354.5, ups=5.11, wpb=3595.3, bsz=153.3, num_updates=1800, lr=0.000225, gnorm=1.339, train_wall=19, wall=0
2024-05-30 17:06:58 | INFO | train_inner | epoch 002:    768 / 1132 loss=7.421, nll_loss=6.484, ppl=89.51, wps=18752.5, ups=5.23, wpb=3588.3, bsz=140.2, num_updates=1900, lr=0.0002375, gnorm=1.293, train_wall=19, wall=0
2024-05-30 17:07:18 | INFO | train_inner | epoch 002:    868 / 1132 loss=7.262, nll_loss=6.302, ppl=78.88, wps=18620.9, ups=5.2, wpb=3578.8, bsz=145.6, num_updates=2000, lr=0.00025, gnorm=1.301, train_wall=19, wall=0
2024-05-30 17:07:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:07:21 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.12 | nll_loss 6.097 | ppl 68.45 | wps 54340.2 | wpb 2685.2 | bsz 107.1 | num_updates 2000 | best_loss 11.059
2024-05-30 17:07:21 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:07:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 7.12) (writing took 3.7869412950240076 seconds)
2024-05-30 17:07:45 | INFO | train_inner | epoch 002:    968 / 1132 loss=7.331, nll_loss=6.381, ppl=83.32, wps=13319.2, ups=3.68, wpb=3623.2, bsz=130.5, num_updates=2100, lr=0.0002625, gnorm=1.183, train_wall=20, wall=0
2024-05-30 17:08:04 | INFO | train_inner | epoch 002:   1068 / 1132 loss=7.19, nll_loss=6.218, ppl=74.44, wps=18401.9, ups=5.27, wpb=3493.3, bsz=142.2, num_updates=2200, lr=0.000275, gnorm=1.322, train_wall=19, wall=0
2024-05-30 17:08:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:08:19 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 6.916 | nll_loss 5.846 | ppl 57.53 | wps 56386.6 | wpb 2685.2 | bsz 107.1 | num_updates 2264 | best_loss 11.059
2024-05-30 17:08:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:08:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 2 @ 2264 updates, score 6.916) (writing took 3.2689470248296857 seconds)
2024-05-30 17:08:23 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2024-05-30 17:08:23 | INFO | train | epoch 002 | loss 7.509 | nll_loss 6.586 | ppl 96.09 | wps 16338.9 | ups 4.59 | wpb 3556.4 | bsz 141.6 | num_updates 2264 | lr 0.000283 | gnorm 1.354 | train_wall 220 | wall 0
2024-05-30 17:08:23 | INFO | fairseq.trainer | begin training epoch 3
2024-05-30 17:08:30 | INFO | train_inner | epoch 003:     36 / 1132 loss=7.065, nll_loss=6.074, ppl=67.38, wps=13731.1, ups=3.85, wpb=3564.6, bsz=132.2, num_updates=2300, lr=0.0002875, gnorm=1.179, train_wall=19, wall=0
2024-05-30 17:08:49 | INFO | train_inner | epoch 003:    136 / 1132 loss=7.014, nll_loss=6.017, ppl=64.75, wps=18729.3, ups=5.2, wpb=3604.4, bsz=148.6, num_updates=2400, lr=0.0003, gnorm=1.272, train_wall=19, wall=0
2024-05-30 17:09:08 | INFO | train_inner | epoch 003:    236 / 1132 loss=7.093, nll_loss=6.106, ppl=68.87, wps=18137.7, ups=5.33, wpb=3400.3, bsz=120.2, num_updates=2500, lr=0.0003125, gnorm=1.25, train_wall=19, wall=0
2024-05-30 17:09:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:09:11 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 6.682 | nll_loss 5.571 | ppl 47.54 | wps 56363 | wpb 2685.2 | bsz 107.1 | num_updates 2500 | best_loss 11.059
2024-05-30 17:09:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:09:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_2500.pt (epoch 3 @ 2500 updates, score 6.682) (writing took 3.4489051583223045 seconds)
2024-05-30 17:09:34 | INFO | train_inner | epoch 003:    336 / 1132 loss=6.81, nll_loss=5.781, ppl=54.99, wps=13606.4, ups=3.87, wpb=3512.2, bsz=140.4, num_updates=2600, lr=0.000325, gnorm=1.208, train_wall=19, wall=0
2024-05-30 17:09:53 | INFO | train_inner | epoch 003:    436 / 1132 loss=6.756, nll_loss=5.719, ppl=52.66, wps=18253.9, ups=5.11, wpb=3569.5, bsz=142.8, num_updates=2700, lr=0.0003375, gnorm=1.258, train_wall=19, wall=0
2024-05-30 17:10:13 | INFO | train_inner | epoch 003:    536 / 1132 loss=6.739, nll_loss=5.698, ppl=51.9, wps=17791.7, ups=4.98, wpb=3572.9, bsz=133.8, num_updates=2800, lr=0.00035, gnorm=1.206, train_wall=20, wall=0
2024-05-30 17:10:33 | INFO | train_inner | epoch 003:    636 / 1132 loss=6.471, nll_loss=5.391, ppl=41.97, wps=18872.1, ups=5.19, wpb=3636.1, bsz=147.6, num_updates=2900, lr=0.0003625, gnorm=1.192, train_wall=19, wall=0
2024-05-30 17:10:52 | INFO | train_inner | epoch 003:    736 / 1132 loss=6.609, nll_loss=5.55, ppl=46.84, wps=18463.1, ups=5.23, wpb=3529.7, bsz=157.7, num_updates=3000, lr=0.000375, gnorm=1.305, train_wall=19, wall=0
2024-05-30 17:10:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:10:55 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 6.393 | nll_loss 5.225 | ppl 37.39 | wps 56227.2 | wpb 2685.2 | bsz 107.1 | num_updates 3000 | best_loss 11.059
2024-05-30 17:10:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:11:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_3000.pt (epoch 3 @ 3000 updates, score 6.393) (writing took 4.8018397386185825 seconds)
2024-05-30 17:11:19 | INFO | train_inner | epoch 003:    836 / 1132 loss=6.472, nll_loss=5.393, ppl=42.01, wps=13030.6, ups=3.69, wpb=3528.8, bsz=145.2, num_updates=3100, lr=0.0003875, gnorm=1.181, train_wall=19, wall=0
2024-05-30 17:11:38 | INFO | train_inner | epoch 003:    936 / 1132 loss=6.488, nll_loss=5.41, ppl=42.51, wps=18678.3, ups=5.22, wpb=3576.1, bsz=128.5, num_updates=3200, lr=0.0004, gnorm=1.141, train_wall=19, wall=0
2024-05-30 17:11:57 | INFO | train_inner | epoch 003:   1036 / 1132 loss=6.356, nll_loss=5.258, ppl=38.27, wps=18761.9, ups=5.21, wpb=3600.2, bsz=143.4, num_updates=3300, lr=0.0004125, gnorm=1.203, train_wall=19, wall=0
2024-05-30 17:12:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:12:20 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 6.141 | nll_loss 4.921 | ppl 30.3 | wps 56218.8 | wpb 2685.2 | bsz 107.1 | num_updates 3396 | best_loss 11.059
2024-05-30 17:12:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:12:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 3 @ 3396 updates, score 6.141) (writing took 2.9070651647634804 seconds)
2024-05-30 17:12:23 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2024-05-30 17:12:23 | INFO | train | epoch 003 | loss 6.649 | nll_loss 5.596 | ppl 48.37 | wps 16741.4 | ups 4.71 | wpb 3556.4 | bsz 141.6 | num_updates 3396 | lr 0.0004245 | gnorm 1.231 | train_wall 217 | wall 0
2024-05-30 17:12:23 | INFO | fairseq.trainer | begin training epoch 4
2024-05-30 17:12:24 | INFO | train_inner | epoch 004:      4 / 1132 loss=6.249, nll_loss=5.134, ppl=35.12, wps=13211.1, ups=3.7, wpb=3571.7, bsz=148, num_updates=3400, lr=0.000425, gnorm=1.34, train_wall=20, wall=0
2024-05-30 17:12:43 | INFO | train_inner | epoch 004:    104 / 1132 loss=6.171, nll_loss=5.046, ppl=33.05, wps=18308.1, ups=5.25, wpb=3489.2, bsz=146.2, num_updates=3500, lr=0.0004375, gnorm=1.172, train_wall=19, wall=0
2024-05-30 17:12:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:12:47 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 5.967 | nll_loss 4.711 | ppl 26.19 | wps 56215.4 | wpb 2685.2 | bsz 107.1 | num_updates 3500 | best_loss 11.059
2024-05-30 17:12:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:12:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_3500.pt (epoch 4 @ 3500 updates, score 5.967) (writing took 3.4608145589008927 seconds)
2024-05-30 17:13:11 | INFO | train_inner | epoch 004:    204 / 1132 loss=6.164, nll_loss=5.034, ppl=32.76, wps=13122.6, ups=3.63, wpb=3614.8, bsz=139.3, num_updates=3600, lr=0.00045, gnorm=1.174, train_wall=21, wall=0
2024-05-30 17:13:31 | INFO | train_inner | epoch 004:    304 / 1132 loss=6.068, nll_loss=4.923, ppl=30.34, wps=17846, ups=4.98, wpb=3585, bsz=127.4, num_updates=3700, lr=0.0004625, gnorm=1.129, train_wall=20, wall=0
2024-05-30 17:13:50 | INFO | train_inner | epoch 004:    404 / 1132 loss=6.129, nll_loss=4.993, ppl=31.84, wps=17968.4, ups=5.16, wpb=3484.7, bsz=130.6, num_updates=3800, lr=0.000475, gnorm=1.232, train_wall=19, wall=0
2024-05-30 17:14:09 | INFO | train_inner | epoch 004:    504 / 1132 loss=6.04, nll_loss=4.889, ppl=29.63, wps=18316.9, ups=5.28, wpb=3471.6, bsz=134, num_updates=3900, lr=0.0004875, gnorm=1.164, train_wall=19, wall=0
2024-05-30 17:14:28 | INFO | train_inner | epoch 004:    604 / 1132 loss=5.926, nll_loss=4.758, ppl=27.06, wps=18762.1, ups=5.25, wpb=3574.4, bsz=142.9, num_updates=4000, lr=0.0005, gnorm=1.159, train_wall=19, wall=0
2024-05-30 17:14:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:14:32 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 5.666 | nll_loss 4.349 | ppl 20.38 | wps 56273.9 | wpb 2685.2 | bsz 107.1 | num_updates 4000 | best_loss 11.059
2024-05-30 17:14:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:14:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_4000.pt (epoch 4 @ 4000 updates, score 5.666) (writing took 3.257597187999636 seconds)
2024-05-30 17:14:56 | INFO | train_inner | epoch 004:    704 / 1132 loss=5.846, nll_loss=4.664, ppl=25.35, wps=13234.7, ups=3.66, wpb=3619.5, bsz=151.3, num_updates=4100, lr=0.000493865, gnorm=1.182, train_wall=21, wall=0
2024-05-30 17:15:16 | INFO | train_inner | epoch 004:    804 / 1132 loss=5.769, nll_loss=4.575, ppl=23.84, wps=17372, ups=4.85, wpb=3582.1, bsz=142.2, num_updates=4200, lr=0.00048795, gnorm=1.17, train_wall=20, wall=0
2024-05-30 17:15:36 | INFO | train_inner | epoch 004:    904 / 1132 loss=5.72, nll_loss=4.519, ppl=22.93, wps=18175.8, ups=5.14, wpb=3533.6, bsz=146.6, num_updates=4300, lr=0.000482243, gnorm=1.131, train_wall=19, wall=0
2024-05-30 17:15:55 | INFO | train_inner | epoch 004:   1004 / 1132 loss=5.677, nll_loss=4.467, ppl=22.12, wps=18422.1, ups=5.17, wpb=3560.5, bsz=150, num_updates=4400, lr=0.000476731, gnorm=1.241, train_wall=19, wall=0
2024-05-30 17:16:14 | INFO | train_inner | epoch 004:   1104 / 1132 loss=5.566, nll_loss=4.34, ppl=20.25, wps=18813.5, ups=5.17, wpb=3641.5, bsz=143.9, num_updates=4500, lr=0.000471405, gnorm=1.103, train_wall=19, wall=0
2024-05-30 17:16:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:16:18 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 5.338 | nll_loss 3.959 | ppl 15.55 | wps 56015.8 | wpb 2685.2 | bsz 107.1 | num_updates 4500 | best_loss 11.059
2024-05-30 17:16:18 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:16:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_4500.pt (epoch 4 @ 4500 updates, score 5.338) (writing took 3.2843769378960133 seconds)
2024-05-30 17:16:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:16:30 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 5.346 | nll_loss 3.971 | ppl 15.69 | wps 56060.8 | wpb 2685.2 | bsz 107.1 | num_updates 4528 | best_loss 11.059
2024-05-30 17:16:30 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:16:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 4 @ 4528 updates, score 5.346) (writing took 2.8771838173270226 seconds)
2024-05-30 17:16:33 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2024-05-30 17:16:33 | INFO | train | epoch 004 | loss 5.908 | nll_loss 4.737 | ppl 26.67 | wps 16138.8 | ups 4.54 | wpb 3556.4 | bsz 141.6 | num_updates 4528 | lr 0.000469945 | gnorm 1.167 | train_wall 221 | wall 0
2024-05-30 17:16:33 | INFO | fairseq.trainer | begin training epoch 5
2024-05-30 17:16:46 | INFO | train_inner | epoch 005:     72 / 1132 loss=5.486, nll_loss=4.249, ppl=19.01, wps=10855.5, ups=3.11, wpb=3492.9, bsz=147.4, num_updates=4600, lr=0.000466252, gnorm=1.178, train_wall=19, wall=0
2024-05-30 17:17:05 | INFO | train_inner | epoch 005:    172 / 1132 loss=5.452, nll_loss=4.207, ppl=18.47, wps=19679.7, ups=5.52, wpb=3566.3, bsz=143.6, num_updates=4700, lr=0.000461266, gnorm=1.119, train_wall=18, wall=0
2024-05-30 17:17:23 | INFO | train_inner | epoch 005:    272 / 1132 loss=5.338, nll_loss=4.078, ppl=16.88, wps=18755.2, ups=5.3, wpb=3536.5, bsz=145.3, num_updates=4800, lr=0.000456435, gnorm=1.083, train_wall=19, wall=0
2024-05-30 17:17:42 | INFO | train_inner | epoch 005:    372 / 1132 loss=5.422, nll_loss=4.17, ppl=18.01, wps=18830, ups=5.3, wpb=3553.3, bsz=134.4, num_updates=4900, lr=0.000451754, gnorm=1.125, train_wall=19, wall=0
2024-05-30 17:18:02 | INFO | train_inner | epoch 005:    472 / 1132 loss=5.255, nll_loss=3.979, ppl=15.77, wps=18325.7, ups=5.12, wpb=3577.6, bsz=145.9, num_updates=5000, lr=0.000447214, gnorm=1.068, train_wall=19, wall=0
2024-05-30 17:18:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:18:05 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 5.144 | nll_loss 3.721 | ppl 13.18 | wps 55714 | wpb 2685.2 | bsz 107.1 | num_updates 5000 | best_loss 11.059
2024-05-30 17:18:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:18:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_5000.pt (epoch 5 @ 5000 updates, score 5.144) (writing took 3.425586658064276 seconds)
2024-05-30 17:18:29 | INFO | train_inner | epoch 005:    572 / 1132 loss=5.332, nll_loss=4.065, ppl=16.74, wps=13416.6, ups=3.73, wpb=3600.5, bsz=125.5, num_updates=5100, lr=0.000442807, gnorm=1.089, train_wall=20, wall=0
2024-05-30 17:18:48 | INFO | train_inner | epoch 005:    672 / 1132 loss=5.274, nll_loss=3.998, ppl=15.98, wps=18744.8, ups=5.25, wpb=3570.9, bsz=137.1, num_updates=5200, lr=0.000438529, gnorm=1.077, train_wall=19, wall=0
2024-05-30 17:19:07 | INFO | train_inner | epoch 005:    772 / 1132 loss=5.153, nll_loss=3.862, ppl=14.54, wps=18475.8, ups=5.2, wpb=3550.4, bsz=153.2, num_updates=5300, lr=0.000434372, gnorm=1.079, train_wall=19, wall=0
2024-05-30 17:19:26 | INFO | train_inner | epoch 005:    872 / 1132 loss=5.172, nll_loss=3.882, ppl=14.74, wps=18651.9, ups=5.23, wpb=3563.7, bsz=145, num_updates=5400, lr=0.000430331, gnorm=1.13, train_wall=19, wall=0
2024-05-30 17:19:45 | INFO | train_inner | epoch 005:    972 / 1132 loss=5.173, nll_loss=3.883, ppl=14.75, wps=18334.6, ups=5.26, wpb=3488.4, bsz=149.9, num_updates=5500, lr=0.000426401, gnorm=1.116, train_wall=19, wall=0
2024-05-30 17:19:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:19:48 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.944 | nll_loss 3.515 | ppl 11.43 | wps 56173.1 | wpb 2685.2 | bsz 107.1 | num_updates 5500 | best_loss 11.059
2024-05-30 17:19:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:19:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_5500.pt (epoch 5 @ 5500 updates, score 4.944) (writing took 3.3266056207939982 seconds)
2024-05-30 17:20:11 | INFO | train_inner | epoch 005:   1072 / 1132 loss=5.222, nll_loss=3.938, ppl=15.33, wps=13680, ups=3.85, wpb=3549.8, bsz=128.8, num_updates=5600, lr=0.000422577, gnorm=1.083, train_wall=19, wall=0
2024-05-30 17:20:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:20:26 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.929 | nll_loss 3.48 | ppl 11.15 | wps 55589.1 | wpb 2685.2 | bsz 107.1 | num_updates 5660 | best_loss 11.059
2024-05-30 17:20:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:20:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 5 @ 5660 updates, score 4.929) (writing took 2.9860443300567567 seconds)
2024-05-30 17:20:29 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2024-05-30 17:20:29 | INFO | train | epoch 005 | loss 5.278 | nll_loss 4.005 | ppl 16.05 | wps 17004.7 | ups 4.78 | wpb 3556.4 | bsz 141.6 | num_updates 5660 | lr 0.000420331 | gnorm 1.104 | train_wall 215 | wall 0
2024-05-30 17:20:29 | INFO | fairseq.trainer | begin training epoch 6
2024-05-30 17:20:37 | INFO | train_inner | epoch 006:     40 / 1132 loss=5.035, nll_loss=3.725, ppl=13.22, wps=13660, ups=3.84, wpb=3555.6, bsz=140.6, num_updates=5700, lr=0.000418854, gnorm=1.079, train_wall=19, wall=0
2024-05-30 17:20:56 | INFO | train_inner | epoch 006:    140 / 1132 loss=4.973, nll_loss=3.653, ppl=12.58, wps=18614.7, ups=5.17, wpb=3600.3, bsz=142.6, num_updates=5800, lr=0.000415227, gnorm=1.054, train_wall=19, wall=0
2024-05-30 17:21:16 | INFO | train_inner | epoch 006:    240 / 1132 loss=4.962, nll_loss=3.638, ppl=12.45, wps=18090.2, ups=5.15, wpb=3512.5, bsz=148, num_updates=5900, lr=0.000411693, gnorm=1.091, train_wall=19, wall=0
2024-05-30 17:21:35 | INFO | train_inner | epoch 006:    340 / 1132 loss=4.948, nll_loss=3.622, ppl=12.31, wps=18111.4, ups=5.1, wpb=3552.8, bsz=139.3, num_updates=6000, lr=0.000408248, gnorm=1.05, train_wall=19, wall=0
2024-05-30 17:21:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:21:39 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 4.824 | nll_loss 3.373 | ppl 10.36 | wps 55610.3 | wpb 2685.2 | bsz 107.1 | num_updates 6000 | best_loss 11.059
2024-05-30 17:21:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:21:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_6000.pt (epoch 6 @ 6000 updates, score 4.824) (writing took 3.5258110952563584 seconds)
2024-05-30 17:22:02 | INFO | train_inner | epoch 006:    440 / 1132 loss=4.895, nll_loss=3.561, ppl=11.8, wps=13587.3, ups=3.82, wpb=3560.5, bsz=144.2, num_updates=6100, lr=0.000404888, gnorm=1.056, train_wall=19, wall=0
2024-05-30 17:22:21 | INFO | train_inner | epoch 006:    540 / 1132 loss=4.887, nll_loss=3.551, ppl=11.72, wps=18449.6, ups=5.2, wpb=3545.2, bsz=129.8, num_updates=6200, lr=0.00040161, gnorm=1.036, train_wall=19, wall=0
2024-05-30 17:22:41 | INFO | train_inner | epoch 006:    640 / 1132 loss=4.964, nll_loss=3.64, ppl=12.47, wps=17756.2, ups=5.05, wpb=3515, bsz=134.6, num_updates=6300, lr=0.00039841, gnorm=1.092, train_wall=20, wall=0
2024-05-30 17:23:00 | INFO | train_inner | epoch 006:    740 / 1132 loss=4.748, nll_loss=3.394, ppl=10.51, wps=18754.8, ups=5.15, wpb=3642.3, bsz=166.2, num_updates=6400, lr=0.000395285, gnorm=1.009, train_wall=19, wall=0
2024-05-30 17:23:19 | INFO | train_inner | epoch 006:    840 / 1132 loss=4.722, nll_loss=3.364, ppl=10.3, wps=18896, ups=5.26, wpb=3594.6, bsz=152.2, num_updates=6500, lr=0.000392232, gnorm=1.002, train_wall=19, wall=0
2024-05-30 17:23:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:23:23 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 4.717 | nll_loss 3.235 | ppl 9.42 | wps 55916.9 | wpb 2685.2 | bsz 107.1 | num_updates 6500 | best_loss 11.059
2024-05-30 17:23:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:23:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_6500.pt (epoch 6 @ 6500 updates, score 4.717) (writing took 3.2133192690089345 seconds)
2024-05-30 17:23:45 | INFO | train_inner | epoch 006:    940 / 1132 loss=4.935, nll_loss=3.606, ppl=12.18, wps=13651.9, ups=3.84, wpb=3552.2, bsz=135.5, num_updates=6600, lr=0.000389249, gnorm=1.065, train_wall=19, wall=0
2024-05-30 17:24:04 | INFO | train_inner | epoch 006:   1040 / 1132 loss=4.899, nll_loss=3.563, ppl=11.82, wps=18371.9, ups=5.2, wpb=3532.4, bsz=130.7, num_updates=6700, lr=0.000386334, gnorm=1.053, train_wall=19, wall=0
2024-05-30 17:24:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:24:25 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 4.662 | nll_loss 3.179 | ppl 9.05 | wps 55974.9 | wpb 2685.2 | bsz 107.1 | num_updates 6792 | best_loss 11.059
2024-05-30 17:24:25 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:24:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 6 @ 6792 updates, score 4.662) (writing took 2.9680676800198853 seconds)
2024-05-30 17:24:28 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2024-05-30 17:24:28 | INFO | train | epoch 006 | loss 4.888 | nll_loss 3.553 | ppl 11.74 | wps 16846.5 | ups 4.74 | wpb 3556.4 | bsz 141.6 | num_updates 6792 | lr 0.000383708 | gnorm 1.05 | train_wall 217 | wall 0
2024-05-30 17:24:28 | INFO | fairseq.trainer | begin training epoch 7
2024-05-30 17:24:30 | INFO | train_inner | epoch 007:      8 / 1132 loss=4.777, nll_loss=3.427, ppl=10.75, wps=13745.1, ups=3.89, wpb=3535.9, bsz=141, num_updates=6800, lr=0.000383482, gnorm=1.042, train_wall=19, wall=0
2024-05-30 17:24:49 | INFO | train_inner | epoch 007:    108 / 1132 loss=4.601, nll_loss=3.223, ppl=9.34, wps=18959.2, ups=5.22, wpb=3628.7, bsz=146.5, num_updates=6900, lr=0.000380693, gnorm=0.981, train_wall=19, wall=0
2024-05-30 17:25:08 | INFO | train_inner | epoch 007:    208 / 1132 loss=4.677, nll_loss=3.31, ppl=9.92, wps=18227.2, ups=5.32, wpb=3429.3, bsz=131.1, num_updates=7000, lr=0.000377964, gnorm=1.054, train_wall=19, wall=0
2024-05-30 17:25:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:25:11 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 4.66 | nll_loss 3.179 | ppl 9.06 | wps 55885.1 | wpb 2685.2 | bsz 107.1 | num_updates 7000 | best_loss 11.059
2024-05-30 17:25:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:25:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_7_7000.pt (epoch 7 @ 7000 updates, score 4.66) (writing took 3.5126435779966414 seconds)
2024-05-30 17:25:34 | INFO | train_inner | epoch 007:    308 / 1132 loss=4.568, nll_loss=3.186, ppl=9.1, wps=13855.6, ups=3.79, wpb=3659.2, bsz=165, num_updates=7100, lr=0.000375293, gnorm=1.004, train_wall=19, wall=0
2024-05-30 17:25:54 | INFO | train_inner | epoch 007:    408 / 1132 loss=4.714, nll_loss=3.352, ppl=10.21, wps=17944, ups=5.1, wpb=3520.3, bsz=136, num_updates=7200, lr=0.000372678, gnorm=1.087, train_wall=19, wall=0
2024-05-30 17:26:14 | INFO | train_inner | epoch 007:    508 / 1132 loss=4.675, nll_loss=3.308, ppl=9.9, wps=17696.5, ups=4.97, wpb=3562.6, bsz=128.8, num_updates=7300, lr=0.000370117, gnorm=1.007, train_wall=20, wall=0
2024-05-30 17:26:33 | INFO | train_inner | epoch 007:    608 / 1132 loss=4.657, nll_loss=3.286, ppl=9.76, wps=18731.7, ups=5.26, wpb=3562.9, bsz=136.2, num_updates=7400, lr=0.000367607, gnorm=1.05, train_wall=19, wall=0
2024-05-30 17:26:52 | INFO | train_inner | epoch 007:    708 / 1132 loss=4.685, nll_loss=3.318, ppl=9.98, wps=18984.1, ups=5.32, wpb=3566.2, bsz=133.3, num_updates=7500, lr=0.000365148, gnorm=1.043, train_wall=19, wall=0
2024-05-30 17:26:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:26:55 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 4.552 | nll_loss 3.054 | ppl 8.31 | wps 55890.7 | wpb 2685.2 | bsz 107.1 | num_updates 7500 | best_loss 11.059
2024-05-30 17:26:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:26:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_7_7500.pt (epoch 7 @ 7500 updates, score 4.552) (writing took 3.576229539234191 seconds)
2024-05-30 17:27:18 | INFO | train_inner | epoch 007:    808 / 1132 loss=4.629, nll_loss=3.256, ppl=9.55, wps=13433.9, ups=3.81, wpb=3522.4, bsz=147.2, num_updates=7600, lr=0.000362738, gnorm=1.061, train_wall=19, wall=0
2024-05-30 17:27:37 | INFO | train_inner | epoch 007:    908 / 1132 loss=4.598, nll_loss=3.22, ppl=9.32, wps=18201.8, ups=5.27, wpb=3451.4, bsz=147.8, num_updates=7700, lr=0.000360375, gnorm=1.031, train_wall=19, wall=0
2024-05-30 17:27:57 | INFO | train_inner | epoch 007:   1008 / 1132 loss=4.611, nll_loss=3.235, ppl=9.41, wps=18685.1, ups=5.15, wpb=3625, bsz=139, num_updates=7800, lr=0.000358057, gnorm=1.007, train_wall=19, wall=0
2024-05-30 17:28:16 | INFO | train_inner | epoch 007:   1108 / 1132 loss=4.596, nll_loss=3.218, ppl=9.3, wps=18609.7, ups=5.22, wpb=3566.3, bsz=142.1, num_updates=7900, lr=0.000355784, gnorm=1.019, train_wall=19, wall=0
2024-05-30 17:28:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:28:24 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 4.495 | nll_loss 2.984 | ppl 7.91 | wps 55823.7 | wpb 2685.2 | bsz 107.1 | num_updates 7924 | best_loss 11.059
2024-05-30 17:28:24 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:28:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 7 @ 7924 updates, score 4.495) (writing took 3.122505603823811 seconds)
2024-05-30 17:28:27 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2024-05-30 17:28:27 | INFO | train | epoch 007 | loss 4.636 | nll_loss 3.264 | ppl 9.6 | wps 16864.4 | ups 4.74 | wpb 3556.4 | bsz 141.6 | num_updates 7924 | lr 0.000355245 | gnorm 1.03 | train_wall 216 | wall 0
2024-05-30 17:28:27 | INFO | fairseq.trainer | begin training epoch 8
2024-05-30 17:28:42 | INFO | train_inner | epoch 008:     76 / 1132 loss=4.435, nll_loss=3.034, ppl=8.19, wps=13997.9, ups=3.82, wpb=3662, bsz=152.7, num_updates=8000, lr=0.000353553, gnorm=0.974, train_wall=19, wall=0
2024-05-30 17:28:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:28:45 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 4.505 | nll_loss 2.987 | ppl 7.93 | wps 56072.3 | wpb 2685.2 | bsz 107.1 | num_updates 8000 | best_loss 11.059
2024-05-30 17:28:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:28:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_8000.pt (epoch 8 @ 8000 updates, score 4.505) (writing took 3.6836814926937222 seconds)
2024-05-30 17:29:08 | INFO | train_inner | epoch 008:    176 / 1132 loss=4.491, nll_loss=3.098, ppl=8.56, wps=13768.9, ups=3.89, wpb=3537.3, bsz=145.3, num_updates=8100, lr=0.000351364, gnorm=1.05, train_wall=18, wall=0
2024-05-30 17:29:27 | INFO | train_inner | epoch 008:    276 / 1132 loss=4.519, nll_loss=3.129, ppl=8.75, wps=18662.9, ups=5.23, wpb=3565.1, bsz=135.2, num_updates=8200, lr=0.000349215, gnorm=1.011, train_wall=19, wall=0
2024-05-30 17:29:46 | INFO | train_inner | epoch 008:    376 / 1132 loss=4.5, nll_loss=3.107, ppl=8.61, wps=18531.9, ups=5.26, wpb=3526.4, bsz=125, num_updates=8300, lr=0.000347105, gnorm=1.02, train_wall=19, wall=0
2024-05-30 17:30:05 | INFO | train_inner | epoch 008:    476 / 1132 loss=4.364, nll_loss=2.954, ppl=7.75, wps=18660.4, ups=5.21, wpb=3584.7, bsz=166.6, num_updates=8400, lr=0.000345033, gnorm=0.974, train_wall=19, wall=0
2024-05-30 17:30:24 | INFO | train_inner | epoch 008:    576 / 1132 loss=4.447, nll_loss=3.047, ppl=8.26, wps=18285.6, ups=5.25, wpb=3482.1, bsz=143.2, num_updates=8500, lr=0.000342997, gnorm=1.021, train_wall=19, wall=0
2024-05-30 17:30:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:30:27 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 4.442 | nll_loss 2.926 | ppl 7.6 | wps 55968.5 | wpb 2685.2 | bsz 107.1 | num_updates 8500 | best_loss 11.059
2024-05-30 17:30:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:30:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_8500.pt (epoch 8 @ 8500 updates, score 4.442) (writing took 3.5018236986361444 seconds)
2024-05-30 17:30:51 | INFO | train_inner | epoch 008:    676 / 1132 loss=4.426, nll_loss=3.024, ppl=8.13, wps=13561.1, ups=3.76, wpb=3611.2, bsz=147.9, num_updates=8600, lr=0.000340997, gnorm=0.994, train_wall=20, wall=0
2024-05-30 17:31:10 | INFO | train_inner | epoch 008:    776 / 1132 loss=4.47, nll_loss=3.074, ppl=8.42, wps=18468.3, ups=5.2, wpb=3551.3, bsz=139.8, num_updates=8700, lr=0.000339032, gnorm=1.049, train_wall=19, wall=0
2024-05-30 17:31:29 | INFO | train_inner | epoch 008:    876 / 1132 loss=4.487, nll_loss=3.092, ppl=8.52, wps=18367.4, ups=5.15, wpb=3568.9, bsz=132.3, num_updates=8800, lr=0.0003371, gnorm=0.998, train_wall=19, wall=0
2024-05-30 17:31:48 | INFO | train_inner | epoch 008:    976 / 1132 loss=4.438, nll_loss=3.038, ppl=8.21, wps=18624.9, ups=5.24, wpb=3555.7, bsz=135.8, num_updates=8900, lr=0.000335201, gnorm=0.984, train_wall=19, wall=0
2024-05-30 17:32:07 | INFO | train_inner | epoch 008:   1076 / 1132 loss=4.494, nll_loss=3.102, ppl=8.58, wps=18246.4, ups=5.28, wpb=3455.8, bsz=131, num_updates=9000, lr=0.000333333, gnorm=1.035, train_wall=19, wall=0
2024-05-30 17:32:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:32:11 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 4.379 | nll_loss 2.859 | ppl 7.25 | wps 56100.8 | wpb 2685.2 | bsz 107.1 | num_updates 9000 | best_loss 11.059
2024-05-30 17:32:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:32:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_8_9000.pt (epoch 8 @ 9000 updates, score 4.379) (writing took 3.7059553167782724 seconds)
2024-05-30 17:32:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:32:29 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 4.352 | nll_loss 2.83 | ppl 7.11 | wps 55943.8 | wpb 2685.2 | bsz 107.1 | num_updates 9056 | best_loss 11.059
2024-05-30 17:32:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:32:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 8 @ 9056 updates, score 4.352) (writing took 3.1995912147685885 seconds)
2024-05-30 17:32:32 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2024-05-30 17:32:32 | INFO | train | epoch 008 | loss 4.453 | nll_loss 3.055 | ppl 8.31 | wps 16437.8 | ups 4.62 | wpb 3556.4 | bsz 141.6 | num_updates 9056 | lr 0.000332301 | gnorm 1.008 | train_wall 215 | wall 0
2024-05-30 17:32:32 | INFO | fairseq.trainer | begin training epoch 9
2024-05-30 17:32:41 | INFO | train_inner | epoch 009:     44 / 1132 loss=4.312, nll_loss=2.894, ppl=7.43, wps=10980.1, ups=3.01, wpb=3650, bsz=146.2, num_updates=9100, lr=0.000331497, gnorm=0.948, train_wall=19, wall=0
2024-05-30 17:33:01 | INFO | train_inner | epoch 009:    144 / 1132 loss=4.273, nll_loss=2.849, ppl=7.2, wps=17512, ups=4.9, wpb=3575.4, bsz=140.3, num_updates=9200, lr=0.00032969, gnorm=0.98, train_wall=20, wall=0
2024-05-30 17:33:22 | INFO | train_inner | epoch 009:    244 / 1132 loss=4.348, nll_loss=2.934, ppl=7.64, wps=16887.6, ups=4.84, wpb=3485.7, bsz=132.5, num_updates=9300, lr=0.000327913, gnorm=1.036, train_wall=20, wall=0
2024-05-30 17:33:42 | INFO | train_inner | epoch 009:    344 / 1132 loss=4.323, nll_loss=2.905, ppl=7.49, wps=17410.4, ups=4.81, wpb=3620.1, bsz=141.8, num_updates=9400, lr=0.000326164, gnorm=1.002, train_wall=21, wall=0
2024-05-30 17:34:02 | INFO | train_inner | epoch 009:    444 / 1132 loss=4.28, nll_loss=2.857, ppl=7.25, wps=18878.6, ups=5.22, wpb=3614.7, bsz=147.8, num_updates=9500, lr=0.000324443, gnorm=0.964, train_wall=19, wall=0
2024-05-30 17:34:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:34:05 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 4.332 | nll_loss 2.8 | ppl 6.96 | wps 55725.2 | wpb 2685.2 | bsz 107.1 | num_updates 9500 | best_loss 11.059
2024-05-30 17:34:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:34:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_9_9500.pt (epoch 9 @ 9500 updates, score 4.332) (writing took 3.703885606955737 seconds)
2024-05-30 17:34:29 | INFO | train_inner | epoch 009:    544 / 1132 loss=4.296, nll_loss=2.876, ppl=7.34, wps=12733.4, ups=3.58, wpb=3552.4, bsz=147.1, num_updates=9600, lr=0.000322749, gnorm=1.044, train_wall=21, wall=0
2024-05-30 17:34:49 | INFO | train_inner | epoch 009:    644 / 1132 loss=4.341, nll_loss=2.926, ppl=7.6, wps=17801.4, ups=5.04, wpb=3528.6, bsz=138.2, num_updates=9700, lr=0.000321081, gnorm=1.002, train_wall=20, wall=0
2024-05-30 17:35:09 | INFO | train_inner | epoch 009:    744 / 1132 loss=4.312, nll_loss=2.893, ppl=7.43, wps=18263.5, ups=5.17, wpb=3534.8, bsz=135, num_updates=9800, lr=0.000319438, gnorm=1.002, train_wall=19, wall=0
2024-05-30 17:35:28 | INFO | train_inner | epoch 009:    844 / 1132 loss=4.329, nll_loss=2.914, ppl=7.54, wps=18746.2, ups=5.24, wpb=3580.6, bsz=150.1, num_updates=9900, lr=0.000317821, gnorm=1.016, train_wall=19, wall=0
2024-05-30 17:35:47 | INFO | train_inner | epoch 009:    944 / 1132 loss=4.335, nll_loss=2.92, ppl=7.57, wps=18483, ups=5.25, wpb=3523.7, bsz=139.5, num_updates=10000, lr=0.000316228, gnorm=0.997, train_wall=19, wall=0
2024-05-30 17:35:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:35:50 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 4.301 | nll_loss 2.776 | ppl 6.85 | wps 56117.1 | wpb 2685.2 | bsz 107.1 | num_updates 10000 | best_loss 11.059
2024-05-30 17:35:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:35:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_9_10000.pt (epoch 9 @ 10000 updates, score 4.301) (writing took 3.5964090758934617 seconds)
2024-05-30 17:35:54 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2024-05-30 17:35:54 | INFO | train | epoch 009 | loss 4.311 | nll_loss 2.892 | ppl 7.43 | wps 16656.9 | ups 4.68 | wpb 3562.2 | bsz 141.5 | num_updates 10000 | lr 0.000316228 | gnorm 1.002 | train_wall 186 | wall 0
2024-05-30 17:35:54 | INFO | fairseq_cli.train | done training in 1932.0 seconds
2024-05-30 17:35:56 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.sep.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=100000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=1000, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-05-30 17:35:56 | INFO | fairseq.tasks.translation | [de] dictionary: 9952 types
2024-05-30 17:35:56 | INFO | fairseq.tasks.translation | [en] dictionary: 9840 types
2024-05-30 17:35:56 | INFO | fairseq.data.data_utils | loaded 7283 examples from: data-bin/iwslt14.sep.tokenized.de-en/valid.de-en.de
2024-05-30 17:35:56 | INFO | fairseq.data.data_utils | loaded 7283 examples from: data-bin/iwslt14.sep.tokenized.de-en/valid.de-en.en
2024-05-30 17:35:56 | INFO | fairseq.tasks.translation | data-bin/iwslt14.sep.tokenized.de-en valid de-en 7283 examples
2024-05-30 17:35:56 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9952, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9840, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=9840, bias=False)
  )
)
2024-05-30 17:35:56 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-05-30 17:35:56 | INFO | fairseq_cli.train | model: transformer_iwslt_de_en (TransformerModel)
2024-05-30 17:35:56 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-05-30 17:35:56 | INFO | fairseq_cli.train | num. model params: 41676800 (num. trained: 41676800)
2024-05-30 17:35:59 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-05-30 17:35:59 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-05-30 17:35:59 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-05-30 17:35:59 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-05-30 17:35:59 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-05-30 17:35:59 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-05-30 17:36:00 | INFO | fairseq.trainer | loaded checkpoint checkpoints/checkpoint_last.pt (epoch 9 @ 10000 updates)
2024-05-30 17:36:00 | INFO | fairseq.trainer | loading train data for epoch 9
2024-05-30 17:36:00 | INFO | fairseq.data.data_utils | loaded 160239 examples from: data-bin/iwslt14.sep.tokenized.de-en/train.de-en.de
2024-05-30 17:36:00 | INFO | fairseq.data.data_utils | loaded 160239 examples from: data-bin/iwslt14.sep.tokenized.de-en/train.de-en.en
2024-05-30 17:36:00 | INFO | fairseq.tasks.translation | data-bin/iwslt14.sep.tokenized.de-en train de-en 160239 examples
2024-05-30 17:36:00 | INFO | fairseq.trainer | begin training epoch 9
2024-05-30 17:36:20 | INFO | train_inner | epoch 009:   1044 / 1132 loss=4.347, nll_loss=2.933, ppl=7.64, wps=15310.6, ups=4.33, wpb=3532.7, bsz=140.4, num_updates=10100, lr=0.000314658, gnorm=1.009, train_wall=19, wall=0
2024-05-30 17:36:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-05-30 17:36:40 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 4.289 | nll_loss 2.765 | ppl 6.8 | wps 56492.2 | wpb 2685.2 | bsz 107.1 | num_updates 10188 | best_loss 11.059
2024-05-30 17:36:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:36:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 9 @ 10188 updates, score 4.289) (writing took 2.7670059939846396 seconds)
2024-05-30 17:36:43 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2024-05-30 17:36:43 | INFO | train | epoch 009 | loss 4.313 | nll_loss 2.895 | ppl 7.44 | wps 16681.8 | ups 4.69 | wpb 3556.4 | bsz 141.6 | num_updates 10188 | lr 0.000313296 | gnorm 1.001 | train_wall 222 | wall 0
2024-05-30 17:36:43 | INFO | fairseq.trainer | begin training epoch 10
2024-05-30 17:36:46 | INFO | train_inner | epoch 010:     12 / 1132 loss=4.282, nll_loss=2.861, ppl=7.27, wps=13641.6, ups=3.86, wpb=3534.3, bsz=143, num_updates=10200, lr=0.000313112, gnorm=0.994, train_wall=19, wall=0
2024-05-30 17:37:05 | INFO | train_inner | epoch 010:    112 / 1132 loss=4.157, nll_loss=2.716, ppl=6.57, wps=18744.3, ups=5.25, wpb=3572.9, bsz=147.4, num_updates=10300, lr=0.000311588, gnorm=0.975, train_wall=19, wall=0
2024-05-30 17:37:24 | INFO | train_inner | epoch 010:    212 / 1132 loss=4.223, nll_loss=2.792, ppl=6.93, wps=18529.3, ups=5.27, wpb=3514.7, bsz=131, num_updates=10400, lr=0.000310087, gnorm=1.017, train_wall=19, wall=0
2024-05-30 17:37:43 | INFO | train_inner | epoch 010:    312 / 1132 loss=4.183, nll_loss=2.745, ppl=6.7, wps=18757.2, ups=5.21, wpb=3601, bsz=143.2, num_updates=10500, lr=0.000308607, gnorm=0.966, train_wall=19, wall=0
2024-05-30 17:38:02 | INFO | train_inner | epoch 010:    412 / 1132 loss=4.155, nll_loss=2.715, ppl=6.57, wps=18976.5, ups=5.2, wpb=3651.6, bsz=150.5, num_updates=10600, lr=0.000307148, gnorm=0.965, train_wall=19, wall=0
2024-05-30 17:38:21 | INFO | train_inner | epoch 010:    512 / 1132 loss=4.232, nll_loss=2.801, ppl=6.97, wps=18207.5, ups=5.25, wpb=3465.6, bsz=137.4, num_updates=10700, lr=0.000305709, gnorm=1.068, train_wall=19, wall=0
2024-05-30 17:38:41 | INFO | train_inner | epoch 010:    612 / 1132 loss=4.215, nll_loss=2.782, ppl=6.88, wps=17820.8, ups=5.03, wpb=3539.9, bsz=140, num_updates=10800, lr=0.00030429, gnorm=0.98, train_wall=20, wall=0
2024-05-30 17:39:01 | INFO | train_inner | epoch 010:    712 / 1132 loss=4.187, nll_loss=2.753, ppl=6.74, wps=18456.2, ups=5.14, wpb=3588.7, bsz=138.2, num_updates=10900, lr=0.000302891, gnorm=0.969, train_wall=19, wall=0
2024-05-30 17:39:20 | INFO | train_inner | epoch 010:    812 / 1132 loss=4.192, nll_loss=2.757, ppl=6.76, wps=18790.5, ups=5.2, wpb=3612.7, bsz=143.8, num_updates=11000, lr=0.000301511, gnorm=0.966, train_wall=19, wall=0
2024-05-30 17:39:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:39:23 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.249 | nll_loss 2.703 | ppl 6.51 | wps 55843.6 | wpb 2685.2 | bsz 107.1 | num_updates 11000 | best_loss 11.059
2024-05-30 17:39:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:39:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_10_11000.pt (epoch 10 @ 11000 updates, score 4.249) (writing took 3.475750066805631 seconds)
2024-05-30 17:39:46 | INFO | train_inner | epoch 010:    912 / 1132 loss=4.273, nll_loss=2.85, ppl=7.21, wps=13559.6, ups=3.87, wpb=3505.6, bsz=129, num_updates=11100, lr=0.00030015, gnorm=1.024, train_wall=19, wall=0
2024-05-30 17:40:05 | INFO | train_inner | epoch 010:   1012 / 1132 loss=4.197, nll_loss=2.764, ppl=6.79, wps=18549.6, ups=5.2, wpb=3569.3, bsz=149.9, num_updates=11200, lr=0.000298807, gnorm=1.01, train_wall=19, wall=0
2024-05-30 17:40:24 | INFO | train_inner | epoch 010:   1112 / 1132 loss=4.159, nll_loss=2.721, ppl=6.59, wps=18484.2, ups=5.25, wpb=3521.6, bsz=156.1, num_updates=11300, lr=0.000297482, gnorm=0.985, train_wall=19, wall=0
2024-05-30 17:40:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:40:31 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.224 | nll_loss 2.686 | ppl 6.43 | wps 56351.6 | wpb 2685.2 | bsz 107.1 | num_updates 11320 | best_loss 11.059
2024-05-30 17:40:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:40:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 10 @ 11320 updates, score 4.224) (writing took 3.1420925119891763 seconds)
2024-05-30 17:40:34 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2024-05-30 17:40:34 | INFO | train | epoch 010 | loss 4.201 | nll_loss 2.767 | ppl 6.81 | wps 17434.8 | ups 4.9 | wpb 3556.4 | bsz 141.6 | num_updates 11320 | lr 0.000297219 | gnorm 0.997 | train_wall 215 | wall 0
2024-05-30 17:40:34 | INFO | fairseq.trainer | begin training epoch 11
2024-05-30 17:40:50 | INFO | train_inner | epoch 011:     80 / 1132 loss=4.193, nll_loss=2.758, ppl=6.76, wps=13628.3, ups=3.89, wpb=3505, bsz=124.5, num_updates=11400, lr=0.000296174, gnorm=1.035, train_wall=19, wall=0
2024-05-30 17:41:09 | INFO | train_inner | epoch 011:    180 / 1132 loss=4.105, nll_loss=2.657, ppl=6.31, wps=18747, ups=5.26, wpb=3563.1, bsz=140.6, num_updates=11500, lr=0.000294884, gnorm=0.992, train_wall=19, wall=0
2024-05-30 17:41:28 | INFO | train_inner | epoch 011:    280 / 1132 loss=4.111, nll_loss=2.664, ppl=6.34, wps=18850.7, ups=5.27, wpb=3576.6, bsz=132.6, num_updates=11600, lr=0.00029361, gnorm=0.981, train_wall=19, wall=0
2024-05-30 17:41:47 | INFO | train_inner | epoch 011:    380 / 1132 loss=4.108, nll_loss=2.66, ppl=6.32, wps=18765, ups=5.27, wpb=3562.7, bsz=144.6, num_updates=11700, lr=0.000292353, gnorm=0.988, train_wall=19, wall=0
2024-05-30 17:42:05 | INFO | train_inner | epoch 011:    480 / 1132 loss=4.064, nll_loss=2.614, ppl=6.12, wps=19114.8, ups=5.3, wpb=3606.3, bsz=152.1, num_updates=11800, lr=0.000291111, gnorm=0.957, train_wall=19, wall=0
2024-05-30 17:42:24 | INFO | train_inner | epoch 011:    580 / 1132 loss=4.088, nll_loss=2.639, ppl=6.23, wps=19270.9, ups=5.38, wpb=3582.6, bsz=145.3, num_updates=11900, lr=0.000289886, gnorm=0.984, train_wall=18, wall=0
2024-05-30 17:42:43 | INFO | train_inner | epoch 011:    680 / 1132 loss=4.06, nll_loss=2.608, ppl=6.1, wps=18704.2, ups=5.29, wpb=3537.9, bsz=154.9, num_updates=12000, lr=0.000288675, gnorm=0.992, train_wall=19, wall=0
2024-05-30 17:42:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:42:46 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.189 | nll_loss 2.647 | ppl 6.26 | wps 56289.4 | wpb 2685.2 | bsz 107.1 | num_updates 12000 | best_loss 11.059
2024-05-30 17:42:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:42:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_11_12000.pt (epoch 11 @ 12000 updates, score 4.189) (writing took 3.393188406713307 seconds)
2024-05-30 17:43:09 | INFO | train_inner | epoch 011:    780 / 1132 loss=4.098, nll_loss=2.65, ppl=6.28, wps=13685.5, ups=3.9, wpb=3507.6, bsz=150.6, num_updates=12100, lr=0.00028748, gnorm=1.011, train_wall=19, wall=0
2024-05-30 17:43:28 | INFO | train_inner | epoch 011:    880 / 1132 loss=4.149, nll_loss=2.709, ppl=6.54, wps=18543.9, ups=5.22, wpb=3555.6, bsz=139.7, num_updates=12200, lr=0.000286299, gnorm=1.019, train_wall=19, wall=0
2024-05-30 17:43:48 | INFO | train_inner | epoch 011:    980 / 1132 loss=4.165, nll_loss=2.726, ppl=6.61, wps=18031.9, ups=5.05, wpb=3572.8, bsz=128, num_updates=12300, lr=0.000285133, gnorm=0.998, train_wall=20, wall=0
2024-05-30 17:44:07 | INFO | train_inner | epoch 011:   1080 / 1132 loss=4.154, nll_loss=2.715, ppl=6.56, wps=18042, ups=5.12, wpb=3522.4, bsz=134.7, num_updates=12400, lr=0.000283981, gnorm=1.067, train_wall=19, wall=0
2024-05-30 17:44:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:44:20 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.157 | nll_loss 2.615 | ppl 6.13 | wps 56379.1 | wpb 2685.2 | bsz 107.1 | num_updates 12452 | best_loss 11.059
2024-05-30 17:44:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:44:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 11 @ 12452 updates, score 4.157) (writing took 2.917427252046764 seconds)
2024-05-30 17:44:23 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2024-05-30 17:44:23 | INFO | train | epoch 011 | loss 4.111 | nll_loss 2.666 | ppl 6.35 | wps 17561.8 | ups 4.94 | wpb 3556.4 | bsz 141.6 | num_updates 12452 | lr 0.000283387 | gnorm 0.999 | train_wall 214 | wall 0
2024-05-30 17:44:23 | INFO | fairseq.trainer | begin training epoch 12
2024-05-30 17:44:33 | INFO | train_inner | epoch 012:     48 / 1132 loss=4.038, nll_loss=2.583, ppl=5.99, wps=13986.1, ups=3.92, wpb=3570.3, bsz=150.9, num_updates=12500, lr=0.000282843, gnorm=0.988, train_wall=19, wall=0
2024-05-30 17:44:51 | INFO | train_inner | epoch 012:    148 / 1132 loss=4.033, nll_loss=2.575, ppl=5.96, wps=19447.4, ups=5.37, wpb=3622.5, bsz=143.3, num_updates=12600, lr=0.000281718, gnorm=0.977, train_wall=18, wall=0
2024-05-30 17:45:10 | INFO | train_inner | epoch 012:    248 / 1132 loss=4.044, nll_loss=2.586, ppl=6.01, wps=18229.6, ups=5.2, wpb=3502.5, bsz=132.3, num_updates=12700, lr=0.000280607, gnorm=0.998, train_wall=19, wall=0
2024-05-30 17:45:30 | INFO | train_inner | epoch 012:    348 / 1132 loss=3.947, nll_loss=2.479, ppl=5.57, wps=18396.3, ups=5.06, wpb=3634.4, bsz=160.2, num_updates=12800, lr=0.000279508, gnorm=0.946, train_wall=20, wall=0
2024-05-30 17:45:49 | INFO | train_inner | epoch 012:    448 / 1132 loss=4.028, nll_loss=2.57, ppl=5.94, wps=18565.6, ups=5.28, wpb=3517.8, bsz=135.3, num_updates=12900, lr=0.000278423, gnorm=0.99, train_wall=19, wall=0
2024-05-30 17:46:08 | INFO | train_inner | epoch 012:    548 / 1132 loss=4.034, nll_loss=2.579, ppl=5.97, wps=18630.7, ups=5.31, wpb=3506.8, bsz=143.4, num_updates=13000, lr=0.00027735, gnorm=1.003, train_wall=19, wall=0
2024-05-30 17:46:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:46:11 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.154 | nll_loss 2.598 | ppl 6.05 | wps 56235 | wpb 2685.2 | bsz 107.1 | num_updates 13000 | best_loss 11.059
2024-05-30 17:46:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:46:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_12_13000.pt (epoch 12 @ 13000 updates, score 4.154) (writing took 3.4334989190101624 seconds)
2024-05-30 17:46:34 | INFO | train_inner | epoch 012:    648 / 1132 loss=4.059, nll_loss=2.607, ppl=6.09, wps=13743.3, ups=3.86, wpb=3558.4, bsz=131.5, num_updates=13100, lr=0.000276289, gnorm=0.998, train_wall=19, wall=0
2024-05-30 17:46:53 | INFO | train_inner | epoch 012:    748 / 1132 loss=4.048, nll_loss=2.594, ppl=6.04, wps=18746.3, ups=5.27, wpb=3560.4, bsz=136.6, num_updates=13200, lr=0.000275241, gnorm=0.984, train_wall=19, wall=0
2024-05-30 17:47:12 | INFO | train_inner | epoch 012:    848 / 1132 loss=4.074, nll_loss=2.624, ppl=6.16, wps=18413.2, ups=5.31, wpb=3470.6, bsz=143.3, num_updates=13300, lr=0.000274204, gnorm=1.041, train_wall=19, wall=0
2024-05-30 17:47:31 | INFO | train_inner | epoch 012:    948 / 1132 loss=4.036, nll_loss=2.582, ppl=5.99, wps=18773.2, ups=5.28, wpb=3554.3, bsz=135.6, num_updates=13400, lr=0.000273179, gnorm=0.973, train_wall=19, wall=0
2024-05-30 17:47:50 | INFO | train_inner | epoch 012:   1048 / 1132 loss=4.022, nll_loss=2.567, ppl=5.92, wps=19118.9, ups=5.3, wpb=3610.5, bsz=140.2, num_updates=13500, lr=0.000272166, gnorm=0.984, train_wall=19, wall=0
2024-05-30 17:48:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:48:09 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.124 | nll_loss 2.573 | ppl 5.95 | wps 56210.9 | wpb 2685.2 | bsz 107.1 | num_updates 13584 | best_loss 11.059
2024-05-30 17:48:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:48:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 12 @ 13584 updates, score 4.124) (writing took 2.8702322617173195 seconds)
2024-05-30 17:48:12 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2024-05-30 17:48:12 | INFO | train | epoch 012 | loss 4.03 | nll_loss 2.574 | ppl 5.95 | wps 17608.9 | ups 4.95 | wpb 3556.4 | bsz 141.6 | num_updates 13584 | lr 0.000271323 | gnorm 0.989 | train_wall 214 | wall 0
2024-05-30 17:48:12 | INFO | fairseq.trainer | begin training epoch 13
2024-05-30 17:48:15 | INFO | train_inner | epoch 013:     16 / 1132 loss=4.038, nll_loss=2.584, ppl=6, wps=13856.2, ups=3.91, wpb=3544.4, bsz=143, num_updates=13600, lr=0.000271163, gnorm=1.001, train_wall=19, wall=0
2024-05-30 17:48:34 | INFO | train_inner | epoch 013:    116 / 1132 loss=3.94, nll_loss=2.47, ppl=5.54, wps=18891.4, ups=5.27, wpb=3582.2, bsz=133.4, num_updates=13700, lr=0.000270172, gnorm=0.947, train_wall=19, wall=0
2024-05-30 17:48:53 | INFO | train_inner | epoch 013:    216 / 1132 loss=3.897, nll_loss=2.421, ppl=5.36, wps=18777.8, ups=5.26, wpb=3572.4, bsz=153, num_updates=13800, lr=0.000269191, gnorm=0.96, train_wall=19, wall=0
2024-05-30 17:49:12 | INFO | train_inner | epoch 013:    316 / 1132 loss=3.959, nll_loss=2.492, ppl=5.63, wps=18728.7, ups=5.3, wpb=3536.8, bsz=139.3, num_updates=13900, lr=0.000268221, gnorm=1.014, train_wall=19, wall=0
2024-05-30 17:49:31 | INFO | train_inner | epoch 013:    416 / 1132 loss=3.969, nll_loss=2.504, ppl=5.67, wps=18413.8, ups=5.24, wpb=3513.1, bsz=144.6, num_updates=14000, lr=0.000267261, gnorm=1.011, train_wall=19, wall=0
2024-05-30 17:49:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:49:34 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.139 | nll_loss 2.578 | ppl 5.97 | wps 56253 | wpb 2685.2 | bsz 107.1 | num_updates 14000 | best_loss 11.059
2024-05-30 17:49:34 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:49:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_13_14000.pt (epoch 13 @ 14000 updates, score 4.139) (writing took 3.424990946892649 seconds)
2024-05-30 17:49:57 | INFO | train_inner | epoch 013:    516 / 1132 loss=3.97, nll_loss=2.505, ppl=5.68, wps=13793.9, ups=3.87, wpb=3561.1, bsz=139.6, num_updates=14100, lr=0.000266312, gnorm=0.995, train_wall=19, wall=0
2024-05-30 17:50:17 | INFO | train_inner | epoch 013:    616 / 1132 loss=3.952, nll_loss=2.484, ppl=5.59, wps=17956.4, ups=4.92, wpb=3646.9, bsz=154.1, num_updates=14200, lr=0.000265372, gnorm=0.958, train_wall=20, wall=0
2024-05-30 17:50:37 | INFO | train_inner | epoch 013:    716 / 1132 loss=3.977, nll_loss=2.514, ppl=5.71, wps=18088.2, ups=5.13, wpb=3528.1, bsz=144.6, num_updates=14300, lr=0.000264443, gnorm=0.995, train_wall=19, wall=0
2024-05-30 17:50:57 | INFO | train_inner | epoch 013:    816 / 1132 loss=4.009, nll_loss=2.549, ppl=5.85, wps=17548.9, ups=5.03, wpb=3492.1, bsz=129.3, num_updates=14400, lr=0.000263523, gnorm=1.025, train_wall=20, wall=0
2024-05-30 17:51:17 | INFO | train_inner | epoch 013:    916 / 1132 loss=3.993, nll_loss=2.534, ppl=5.79, wps=18184.9, ups=4.98, wpb=3648.9, bsz=135.8, num_updates=14500, lr=0.000262613, gnorm=0.965, train_wall=20, wall=0
2024-05-30 17:51:36 | INFO | train_inner | epoch 013:   1016 / 1132 loss=3.954, nll_loss=2.489, ppl=5.61, wps=18718.6, ups=5.31, wpb=3526.8, bsz=137.8, num_updates=14600, lr=0.000261712, gnorm=0.998, train_wall=19, wall=0
2024-05-30 17:51:55 | INFO | train_inner | epoch 013:   1116 / 1132 loss=3.985, nll_loss=2.525, ppl=5.76, wps=18459.2, ups=5.25, wpb=3517.3, bsz=151, num_updates=14700, lr=0.00026082, gnorm=1.046, train_wall=19, wall=0
2024-05-30 17:51:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:52:01 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.092 | nll_loss 2.535 | ppl 5.8 | wps 56153.8 | wpb 2685.2 | bsz 107.1 | num_updates 14716 | best_loss 11.059
2024-05-30 17:52:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:52:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 13 @ 14716 updates, score 4.092) (writing took 2.906847890932113 seconds)
2024-05-30 17:52:04 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2024-05-30 17:52:04 | INFO | train | epoch 013 | loss 3.965 | nll_loss 2.5 | ppl 5.66 | wps 17350.6 | ups 4.88 | wpb 3556.4 | bsz 141.6 | num_updates 14716 | lr 0.000260678 | gnorm 0.993 | train_wall 217 | wall 0
2024-05-30 17:52:04 | INFO | fairseq.trainer | begin training epoch 14
2024-05-30 17:52:20 | INFO | train_inner | epoch 014:     84 / 1132 loss=3.858, nll_loss=2.379, ppl=5.2, wps=13833.8, ups=3.92, wpb=3525.2, bsz=143.1, num_updates=14800, lr=0.000259938, gnorm=0.976, train_wall=19, wall=0
2024-05-30 17:52:39 | INFO | train_inner | epoch 014:    184 / 1132 loss=3.877, nll_loss=2.399, ppl=5.28, wps=18803, ups=5.25, wpb=3579.2, bsz=136.2, num_updates=14900, lr=0.000259064, gnorm=0.953, train_wall=19, wall=0
2024-05-30 17:52:58 | INFO | train_inner | epoch 014:    284 / 1132 loss=3.905, nll_loss=2.432, ppl=5.4, wps=18639.3, ups=5.35, wpb=3481, bsz=128.2, num_updates=15000, lr=0.000258199, gnorm=0.994, train_wall=19, wall=0
2024-05-30 17:52:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:53:01 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.086 | nll_loss 2.527 | ppl 5.76 | wps 56327.4 | wpb 2685.2 | bsz 107.1 | num_updates 15000 | best_loss 11.059
2024-05-30 17:53:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:53:05 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_14_15000.pt (epoch 14 @ 15000 updates, score 4.086) (writing took 3.3981481748633087 seconds)
2024-05-30 17:53:24 | INFO | train_inner | epoch 014:    384 / 1132 loss=3.913, nll_loss=2.441, ppl=5.43, wps=13765.1, ups=3.87, wpb=3559.1, bsz=136.7, num_updates=15100, lr=0.000257343, gnorm=1.004, train_wall=19, wall=0
2024-05-30 17:53:43 | INFO | train_inner | epoch 014:    484 / 1132 loss=3.909, nll_loss=2.436, ppl=5.41, wps=19037.2, ups=5.15, wpb=3694, bsz=142, num_updates=15200, lr=0.000256495, gnorm=0.953, train_wall=19, wall=0
2024-05-30 17:54:02 | INFO | train_inner | epoch 014:    584 / 1132 loss=3.921, nll_loss=2.45, ppl=5.46, wps=18658.6, ups=5.19, wpb=3597.1, bsz=137.4, num_updates=15300, lr=0.000255655, gnorm=1.012, train_wall=19, wall=0
2024-05-30 17:54:22 | INFO | train_inner | epoch 014:    684 / 1132 loss=3.888, nll_loss=2.412, ppl=5.32, wps=18563, ups=5.2, wpb=3572.6, bsz=157.7, num_updates=15400, lr=0.000254824, gnorm=0.986, train_wall=19, wall=0
2024-05-30 17:54:41 | INFO | train_inner | epoch 014:    784 / 1132 loss=3.909, nll_loss=2.436, ppl=5.41, wps=18849.6, ups=5.23, wpb=3604.2, bsz=145.7, num_updates=15500, lr=0.000254, gnorm=0.975, train_wall=19, wall=0
2024-05-30 17:55:00 | INFO | train_inner | epoch 014:    884 / 1132 loss=3.92, nll_loss=2.45, ppl=5.47, wps=18558.4, ups=5.26, wpb=3528.9, bsz=149.8, num_updates=15600, lr=0.000253185, gnorm=1.017, train_wall=19, wall=0
2024-05-30 17:55:19 | INFO | train_inner | epoch 014:    984 / 1132 loss=3.929, nll_loss=2.459, ppl=5.5, wps=18304.5, ups=5.18, wpb=3531.3, bsz=140.3, num_updates=15700, lr=0.000252377, gnorm=1.017, train_wall=19, wall=0
2024-05-30 17:55:38 | INFO | train_inner | epoch 014:   1084 / 1132 loss=3.933, nll_loss=2.464, ppl=5.52, wps=18690.6, ups=5.26, wpb=3552.1, bsz=133, num_updates=15800, lr=0.000251577, gnorm=0.988, train_wall=19, wall=0
2024-05-30 17:55:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:55:50 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.059 | nll_loss 2.502 | ppl 5.66 | wps 56236.8 | wpb 2685.2 | bsz 107.1 | num_updates 15848 | best_loss 11.059
2024-05-30 17:55:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:55:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 14 @ 15848 updates, score 4.059) (writing took 2.9402828980237246 seconds)
2024-05-30 17:55:53 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2024-05-30 17:55:53 | INFO | train | epoch 014 | loss 3.905 | nll_loss 2.431 | ppl 5.39 | wps 17563.2 | ups 4.94 | wpb 3556.4 | bsz 141.6 | num_updates 15848 | lr 0.000251196 | gnorm 0.991 | train_wall 214 | wall 0
2024-05-30 17:55:53 | INFO | fairseq.trainer | begin training epoch 15
2024-05-30 17:56:03 | INFO | train_inner | epoch 015:     52 / 1132 loss=3.857, nll_loss=2.379, ppl=5.2, wps=13631.8, ups=3.96, wpb=3439.1, bsz=140.5, num_updates=15900, lr=0.000250785, gnorm=1.008, train_wall=19, wall=0
2024-05-30 17:56:22 | INFO | train_inner | epoch 015:    152 / 1132 loss=3.828, nll_loss=2.342, ppl=5.07, wps=18495.3, ups=5.21, wpb=3550, bsz=138.1, num_updates=16000, lr=0.00025, gnorm=0.972, train_wall=19, wall=0
2024-05-30 17:56:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:56:26 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.059 | nll_loss 2.496 | ppl 5.64 | wps 56386.5 | wpb 2685.2 | bsz 107.1 | num_updates 16000 | best_loss 11.059
2024-05-30 17:56:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:56:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_15_16000.pt (epoch 15 @ 16000 updates, score 4.059) (writing took 3.455695828422904 seconds)
2024-05-30 17:56:48 | INFO | train_inner | epoch 015:    252 / 1132 loss=3.814, nll_loss=2.329, ppl=5.02, wps=13908.9, ups=3.84, wpb=3620.3, bsz=145.4, num_updates=16100, lr=0.000249222, gnorm=0.965, train_wall=19, wall=0
2024-05-30 17:57:07 | INFO | train_inner | epoch 015:    352 / 1132 loss=3.874, nll_loss=2.395, ppl=5.26, wps=18583.5, ups=5.26, wpb=3533.9, bsz=125.8, num_updates=16200, lr=0.000248452, gnorm=1.001, train_wall=19, wall=0
2024-05-30 17:57:27 | INFO | train_inner | epoch 015:    452 / 1132 loss=3.803, nll_loss=2.317, ppl=4.98, wps=18405.9, ups=5.25, wpb=3504.3, bsz=159.4, num_updates=16300, lr=0.000247689, gnorm=0.983, train_wall=19, wall=0
2024-05-30 17:57:46 | INFO | train_inner | epoch 015:    552 / 1132 loss=3.865, nll_loss=2.385, ppl=5.22, wps=18569.9, ups=5.21, wpb=3564.4, bsz=145.4, num_updates=16400, lr=0.000246932, gnorm=0.998, train_wall=19, wall=0
2024-05-30 17:58:05 | INFO | train_inner | epoch 015:    652 / 1132 loss=3.806, nll_loss=2.32, ppl=4.99, wps=18704.4, ups=5.18, wpb=3608.3, bsz=163.3, num_updates=16500, lr=0.000246183, gnorm=0.961, train_wall=19, wall=0
2024-05-30 17:58:24 | INFO | train_inner | epoch 015:    752 / 1132 loss=3.899, nll_loss=2.425, ppl=5.37, wps=18593.2, ups=5.26, wpb=3535, bsz=122.6, num_updates=16600, lr=0.00024544, gnorm=1.018, train_wall=19, wall=0
2024-05-30 17:58:43 | INFO | train_inner | epoch 015:    852 / 1132 loss=3.886, nll_loss=2.411, ppl=5.32, wps=18799.3, ups=5.25, wpb=3582, bsz=128.6, num_updates=16700, lr=0.000244704, gnorm=0.988, train_wall=19, wall=0
2024-05-30 17:59:02 | INFO | train_inner | epoch 015:    952 / 1132 loss=3.858, nll_loss=2.38, ppl=5.21, wps=18850.6, ups=5.25, wpb=3588.9, bsz=147.7, num_updates=16800, lr=0.000243975, gnorm=0.991, train_wall=19, wall=0
2024-05-30 17:59:21 | INFO | train_inner | epoch 015:   1052 / 1132 loss=3.887, nll_loss=2.414, ppl=5.33, wps=18607, ups=5.3, wpb=3511.7, bsz=148.2, num_updates=16900, lr=0.000243252, gnorm=1.098, train_wall=19, wall=0
2024-05-30 17:59:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:59:40 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.033 | nll_loss 2.464 | ppl 5.52 | wps 56086 | wpb 2685.2 | bsz 107.1 | num_updates 16980 | best_loss 11.059
2024-05-30 17:59:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:59:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 15 @ 16980 updates, score 4.033) (writing took 2.944877743255347 seconds)
2024-05-30 17:59:43 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2024-05-30 17:59:43 | INFO | train | epoch 015 | loss 3.851 | nll_loss 2.371 | ppl 5.17 | wps 17556.4 | ups 4.94 | wpb 3556.4 | bsz 141.6 | num_updates 16980 | lr 0.000242678 | gnorm 0.995 | train_wall 214 | wall 0
2024-05-30 17:59:43 | INFO | fairseq.trainer | begin training epoch 16
2024-05-30 17:59:47 | INFO | train_inner | epoch 016:     20 / 1132 loss=3.851, nll_loss=2.372, ppl=5.18, wps=13842.4, ups=3.91, wpb=3540.2, bsz=138.4, num_updates=17000, lr=0.000242536, gnorm=0.979, train_wall=19, wall=0
2024-05-30 17:59:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 17:59:50 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.052 | nll_loss 2.489 | ppl 5.61 | wps 56013.3 | wpb 2685.2 | bsz 107.1 | num_updates 17000 | best_loss 11.059
2024-05-30 17:59:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 17:59:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_16_17000.pt (epoch 16 @ 17000 updates, score 4.052) (writing took 3.439158549066633 seconds)
2024-05-30 18:00:13 | INFO | train_inner | epoch 016:    120 / 1132 loss=3.739, nll_loss=2.243, ppl=4.73, wps=13692.5, ups=3.83, wpb=3576.5, bsz=142, num_updates=17100, lr=0.000241825, gnorm=0.969, train_wall=19, wall=0
2024-05-30 18:00:31 | INFO | train_inner | epoch 016:    220 / 1132 loss=3.783, nll_loss=2.292, ppl=4.9, wps=18888.8, ups=5.37, wpb=3519.1, bsz=135.5, num_updates=17200, lr=0.000241121, gnorm=1, train_wall=18, wall=0
2024-05-30 18:00:50 | INFO | train_inner | epoch 016:    320 / 1132 loss=3.806, nll_loss=2.319, ppl=4.99, wps=19641.1, ups=5.46, wpb=3595.5, bsz=139.7, num_updates=17300, lr=0.000240424, gnorm=0.986, train_wall=18, wall=0
2024-05-30 18:01:08 | INFO | train_inner | epoch 016:    420 / 1132 loss=3.78, nll_loss=2.289, ppl=4.89, wps=19273, ups=5.54, wpb=3480.3, bsz=143.8, num_updates=17400, lr=0.000239732, gnorm=1.011, train_wall=18, wall=0
2024-05-30 18:01:27 | INFO | train_inner | epoch 016:    520 / 1132 loss=3.855, nll_loss=2.373, ppl=5.18, wps=18377.2, ups=5.29, wpb=3472.3, bsz=130.4, num_updates=17500, lr=0.000239046, gnorm=1.04, train_wall=19, wall=0
2024-05-30 18:01:46 | INFO | train_inner | epoch 016:    620 / 1132 loss=3.784, nll_loss=2.295, ppl=4.91, wps=18951.7, ups=5.27, wpb=3597.1, bsz=144.5, num_updates=17600, lr=0.000238366, gnorm=0.98, train_wall=19, wall=0
2024-05-30 18:02:05 | INFO | train_inner | epoch 016:    720 / 1132 loss=3.79, nll_loss=2.303, ppl=4.93, wps=18985.5, ups=5.24, wpb=3621.8, bsz=154.6, num_updates=17700, lr=0.000237691, gnorm=0.988, train_wall=19, wall=0
2024-05-30 18:02:24 | INFO | train_inner | epoch 016:    820 / 1132 loss=3.83, nll_loss=2.347, ppl=5.09, wps=18990.2, ups=5.22, wpb=3635.6, bsz=137.3, num_updates=17800, lr=0.000237023, gnorm=0.98, train_wall=19, wall=0
2024-05-30 18:02:43 | INFO | train_inner | epoch 016:    920 / 1132 loss=3.839, nll_loss=2.357, ppl=5.12, wps=18585.4, ups=5.22, wpb=3560.4, bsz=153.6, num_updates=17900, lr=0.00023636, gnorm=1.075, train_wall=19, wall=0
2024-05-30 18:03:02 | INFO | train_inner | epoch 016:   1020 / 1132 loss=3.81, nll_loss=2.326, ppl=5.01, wps=18716.5, ups=5.26, wpb=3555.4, bsz=144, num_updates=18000, lr=0.000235702, gnorm=1.007, train_wall=19, wall=0
2024-05-30 18:03:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:03:05 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.022 | nll_loss 2.466 | ppl 5.53 | wps 56076.4 | wpb 2685.2 | bsz 107.1 | num_updates 18000 | best_loss 11.059
2024-05-30 18:03:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:03:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_16_18000.pt (epoch 16 @ 18000 updates, score 4.022) (writing took 3.354122501797974 seconds)
2024-05-30 18:03:27 | INFO | train_inner | epoch 016:   1120 / 1132 loss=3.831, nll_loss=2.35, ppl=5.1, wps=13928.3, ups=3.95, wpb=3527.1, bsz=135.9, num_updates=18100, lr=0.00023505, gnorm=0.997, train_wall=18, wall=0
2024-05-30 18:03:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:03:33 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.016 | nll_loss 2.454 | ppl 5.48 | wps 55591.4 | wpb 2685.2 | bsz 107.1 | num_updates 18112 | best_loss 11.059
2024-05-30 18:03:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:03:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 16 @ 18112 updates, score 4.016) (writing took 3.6870630527846515 seconds)
2024-05-30 18:03:37 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2024-05-30 18:03:37 | INFO | train | epoch 016 | loss 3.805 | nll_loss 2.318 | ppl 4.99 | wps 17194.1 | ups 4.83 | wpb 3556.4 | bsz 141.6 | num_updates 18112 | lr 0.000234972 | gnorm 1.003 | train_wall 212 | wall 0
2024-05-30 18:03:37 | INFO | fairseq.trainer | begin training epoch 17
2024-05-30 18:03:54 | INFO | train_inner | epoch 017:     88 / 1132 loss=3.773, nll_loss=2.28, ppl=4.86, wps=13350, ups=3.81, wpb=3503.9, bsz=130.6, num_updates=18200, lr=0.000234404, gnorm=1.014, train_wall=19, wall=0
2024-05-30 18:04:12 | INFO | train_inner | epoch 017:    188 / 1132 loss=3.702, nll_loss=2.2, ppl=4.6, wps=19720.9, ups=5.41, wpb=3644.5, bsz=151, num_updates=18300, lr=0.000233762, gnorm=0.976, train_wall=18, wall=0
2024-05-30 18:04:31 | INFO | train_inner | epoch 017:    288 / 1132 loss=3.745, nll_loss=2.249, ppl=4.76, wps=18925, ups=5.22, wpb=3625.3, bsz=140.3, num_updates=18400, lr=0.000233126, gnorm=0.966, train_wall=19, wall=0
2024-05-30 18:04:50 | INFO | train_inner | epoch 017:    388 / 1132 loss=3.741, nll_loss=2.245, ppl=4.74, wps=18637.6, ups=5.23, wpb=3560.7, bsz=146.7, num_updates=18500, lr=0.000232495, gnorm=0.987, train_wall=19, wall=0
2024-05-30 18:05:09 | INFO | train_inner | epoch 017:    488 / 1132 loss=3.743, nll_loss=2.249, ppl=4.75, wps=18578.7, ups=5.28, wpb=3521.2, bsz=137.9, num_updates=18600, lr=0.000231869, gnorm=0.995, train_wall=19, wall=0
2024-05-30 18:05:28 | INFO | train_inner | epoch 017:    588 / 1132 loss=3.781, nll_loss=2.29, ppl=4.89, wps=18479.5, ups=5.25, wpb=3520.3, bsz=135.2, num_updates=18700, lr=0.000231249, gnorm=1.023, train_wall=19, wall=0
2024-05-30 18:05:47 | INFO | train_inner | epoch 017:    688 / 1132 loss=3.764, nll_loss=2.273, ppl=4.83, wps=18563.8, ups=5.25, wpb=3537.3, bsz=148.1, num_updates=18800, lr=0.000230633, gnorm=1.012, train_wall=19, wall=0
2024-05-30 18:06:07 | INFO | train_inner | epoch 017:    788 / 1132 loss=3.779, nll_loss=2.288, ppl=4.88, wps=18849.3, ups=5.19, wpb=3632.9, bsz=145.2, num_updates=18900, lr=0.000230022, gnorm=0.993, train_wall=19, wall=0
2024-05-30 18:06:27 | INFO | train_inner | epoch 017:    888 / 1132 loss=3.75, nll_loss=2.257, ppl=4.78, wps=17806, ups=4.97, wpb=3582, bsz=151, num_updates=19000, lr=0.000229416, gnorm=0.983, train_wall=20, wall=0
2024-05-30 18:06:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:06:30 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 4.006 | nll_loss 2.439 | ppl 5.42 | wps 55777.2 | wpb 2685.2 | bsz 107.1 | num_updates 19000 | best_loss 11.059
2024-05-30 18:06:30 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:06:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_17_19000.pt (epoch 17 @ 19000 updates, score 4.006) (writing took 3.4916458702646196 seconds)
2024-05-30 18:06:53 | INFO | train_inner | epoch 017:    988 / 1132 loss=3.811, nll_loss=2.325, ppl=5.01, wps=13598.6, ups=3.86, wpb=3525, bsz=127.2, num_updates=19100, lr=0.000228814, gnorm=1.012, train_wall=19, wall=0
2024-05-30 18:07:11 | INFO | train_inner | epoch 017:   1088 / 1132 loss=3.79, nll_loss=2.303, ppl=4.93, wps=18497.2, ups=5.33, wpb=3473, bsz=151.9, num_updates=19200, lr=0.000228218, gnorm=1.065, train_wall=19, wall=0
2024-05-30 18:07:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:07:23 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 3.992 | nll_loss 2.429 | ppl 5.39 | wps 56209.1 | wpb 2685.2 | bsz 107.1 | num_updates 19244 | best_loss 11.059
2024-05-30 18:07:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:07:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 17 @ 19244 updates, score 3.992) (writing took 3.0176386260427535 seconds)
2024-05-30 18:07:26 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2024-05-30 18:07:26 | INFO | train | epoch 017 | loss 3.763 | nll_loss 2.271 | ppl 4.83 | wps 17552.8 | ups 4.94 | wpb 3556.4 | bsz 141.6 | num_updates 19244 | lr 0.000227957 | gnorm 1.002 | train_wall 214 | wall 0
2024-05-30 18:07:26 | INFO | fairseq.trainer | begin training epoch 18
2024-05-30 18:07:37 | INFO | train_inner | epoch 018:     56 / 1132 loss=3.752, nll_loss=2.257, ppl=4.78, wps=13896.7, ups=3.91, wpb=3554.2, bsz=119.9, num_updates=19300, lr=0.000227626, gnorm=0.974, train_wall=19, wall=0
2024-05-30 18:07:57 | INFO | train_inner | epoch 018:    156 / 1132 loss=3.718, nll_loss=2.217, ppl=4.65, wps=17933, ups=5.11, wpb=3509.2, bsz=126.8, num_updates=19400, lr=0.000227038, gnorm=1.008, train_wall=19, wall=0
2024-05-30 18:08:15 | INFO | train_inner | epoch 018:    256 / 1132 loss=3.709, nll_loss=2.209, ppl=4.62, wps=18625.5, ups=5.29, wpb=3518.5, bsz=136.9, num_updates=19500, lr=0.000226455, gnorm=1.004, train_wall=19, wall=0
2024-05-30 18:08:34 | INFO | train_inner | epoch 018:    356 / 1132 loss=3.719, nll_loss=2.22, ppl=4.66, wps=18959.9, ups=5.28, wpb=3588.6, bsz=135, num_updates=19600, lr=0.000225877, gnorm=1.003, train_wall=19, wall=0
2024-05-30 18:08:53 | INFO | train_inner | epoch 018:    456 / 1132 loss=3.795, nll_loss=2.304, ppl=4.94, wps=18533.8, ups=5.27, wpb=3514.8, bsz=115.6, num_updates=19700, lr=0.000225303, gnorm=1.042, train_wall=19, wall=0
2024-05-30 18:09:12 | INFO | train_inner | epoch 018:    556 / 1132 loss=3.685, nll_loss=2.182, ppl=4.54, wps=18787.5, ups=5.36, wpb=3507.8, bsz=156.9, num_updates=19800, lr=0.000224733, gnorm=1.001, train_wall=19, wall=0
2024-05-30 18:09:30 | INFO | train_inner | epoch 018:    656 / 1132 loss=3.708, nll_loss=2.209, ppl=4.62, wps=19630.8, ups=5.41, wpb=3627.5, bsz=150.9, num_updates=19900, lr=0.000224168, gnorm=0.983, train_wall=18, wall=0
2024-05-30 18:09:49 | INFO | train_inner | epoch 018:    756 / 1132 loss=3.683, nll_loss=2.182, ppl=4.54, wps=19648.7, ups=5.43, wpb=3620.2, bsz=165, num_updates=20000, lr=0.000223607, gnorm=0.974, train_wall=18, wall=0
2024-05-30 18:09:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:09:52 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.987 | nll_loss 2.418 | ppl 5.34 | wps 56214.3 | wpb 2685.2 | bsz 107.1 | num_updates 20000 | best_loss 11.059
2024-05-30 18:09:52 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:09:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_18_20000.pt (epoch 18 @ 20000 updates, score 3.987) (writing took 3.9189237100072205 seconds)
2024-05-30 18:10:15 | INFO | train_inner | epoch 018:    856 / 1132 loss=3.719, nll_loss=2.22, ppl=4.66, wps=13600.9, ups=3.76, wpb=3617.6, bsz=151.4, num_updates=20100, lr=0.00022305, gnorm=0.986, train_wall=19, wall=0
2024-05-30 18:10:34 | INFO | train_inner | epoch 018:    956 / 1132 loss=3.756, nll_loss=2.263, ppl=4.8, wps=18665.9, ups=5.33, wpb=3500.7, bsz=137.4, num_updates=20200, lr=0.000222497, gnorm=1.046, train_wall=19, wall=0
2024-05-30 18:10:53 | INFO | train_inner | epoch 018:   1056 / 1132 loss=3.756, nll_loss=2.264, ppl=4.8, wps=18229.6, ups=5.21, wpb=3500.3, bsz=156.7, num_updates=20300, lr=0.000221948, gnorm=1.039, train_wall=19, wall=0
2024-05-30 18:11:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:11:11 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.978 | nll_loss 2.41 | ppl 5.31 | wps 55974.2 | wpb 2685.2 | bsz 107.1 | num_updates 20376 | best_loss 11.059
2024-05-30 18:11:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:11:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 18 @ 20376 updates, score 3.978) (writing took 3.443169957958162 seconds)
2024-05-30 18:11:14 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2024-05-30 18:11:14 | INFO | train | epoch 018 | loss 3.724 | nll_loss 2.226 | ppl 4.68 | wps 17629.6 | ups 4.96 | wpb 3556.4 | bsz 141.6 | num_updates 20376 | lr 0.000221534 | gnorm 1.003 | train_wall 212 | wall 0
2024-05-30 18:11:14 | INFO | fairseq.trainer | begin training epoch 19
2024-05-30 18:11:19 | INFO | train_inner | epoch 019:     24 / 1132 loss=3.729, nll_loss=2.234, ppl=4.7, wps=13875.6, ups=3.9, wpb=3558.8, bsz=129.8, num_updates=20400, lr=0.000221404, gnorm=0.985, train_wall=18, wall=0
2024-05-30 18:11:38 | INFO | train_inner | epoch 019:    124 / 1132 loss=3.668, nll_loss=2.159, ppl=4.47, wps=18472.3, ups=5.24, wpb=3525.1, bsz=128.4, num_updates=20500, lr=0.000220863, gnorm=1.007, train_wall=19, wall=0
2024-05-30 18:11:57 | INFO | train_inner | epoch 019:    224 / 1132 loss=3.65, nll_loss=2.141, ppl=4.41, wps=18473.3, ups=5.21, wpb=3544.5, bsz=153.6, num_updates=20600, lr=0.000220326, gnorm=0.991, train_wall=19, wall=0
2024-05-30 18:12:16 | INFO | train_inner | epoch 019:    324 / 1132 loss=3.667, nll_loss=2.161, ppl=4.47, wps=18468.8, ups=5.25, wpb=3518.3, bsz=134, num_updates=20700, lr=0.000219793, gnorm=1.012, train_wall=19, wall=0
2024-05-30 18:12:35 | INFO | train_inner | epoch 019:    424 / 1132 loss=3.666, nll_loss=2.16, ppl=4.47, wps=18658.6, ups=5.25, wpb=3550.8, bsz=138.4, num_updates=20800, lr=0.000219265, gnorm=0.992, train_wall=19, wall=0
2024-05-30 18:12:55 | INFO | train_inner | epoch 019:    524 / 1132 loss=3.718, nll_loss=2.219, ppl=4.65, wps=18366.1, ups=5.19, wpb=3540.9, bsz=143, num_updates=20900, lr=0.000218739, gnorm=1.022, train_wall=19, wall=0
2024-05-30 18:13:14 | INFO | train_inner | epoch 019:    624 / 1132 loss=3.69, nll_loss=2.187, ppl=4.55, wps=18831.6, ups=5.22, wpb=3604.6, bsz=136.9, num_updates=21000, lr=0.000218218, gnorm=0.997, train_wall=19, wall=0
2024-05-30 18:13:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:13:17 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 3.983 | nll_loss 2.412 | ppl 5.32 | wps 56011 | wpb 2685.2 | bsz 107.1 | num_updates 21000 | best_loss 11.059
2024-05-30 18:13:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:13:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_19_21000.pt (epoch 19 @ 21000 updates, score 3.983) (writing took 3.800605983939022 seconds)
2024-05-30 18:13:40 | INFO | train_inner | epoch 019:    724 / 1132 loss=3.677, nll_loss=2.172, ppl=4.51, wps=13240.7, ups=3.81, wpb=3475.3, bsz=158, num_updates=21100, lr=0.0002177, gnorm=1.037, train_wall=19, wall=0
2024-05-30 18:13:59 | INFO | train_inner | epoch 019:    824 / 1132 loss=3.72, nll_loss=2.222, ppl=4.67, wps=18592.6, ups=5.31, wpb=3500.9, bsz=132.2, num_updates=21200, lr=0.000217186, gnorm=1.024, train_wall=19, wall=0
2024-05-30 18:14:18 | INFO | train_inner | epoch 019:    924 / 1132 loss=3.728, nll_loss=2.232, ppl=4.7, wps=19168.2, ups=5.24, wpb=3657, bsz=129.1, num_updates=21300, lr=0.000216676, gnorm=0.988, train_wall=19, wall=0
2024-05-30 18:14:39 | INFO | train_inner | epoch 019:   1024 / 1132 loss=3.653, nll_loss=2.148, ppl=4.43, wps=17462.3, ups=4.83, wpb=3612.8, bsz=165.4, num_updates=21400, lr=0.000216169, gnorm=0.97, train_wall=21, wall=0
2024-05-30 18:14:59 | INFO | train_inner | epoch 019:   1124 / 1132 loss=3.695, nll_loss=2.195, ppl=4.58, wps=18263.9, ups=5.02, wpb=3637.2, bsz=145.9, num_updates=21500, lr=0.000215666, gnorm=0.985, train_wall=20, wall=0
2024-05-30 18:15:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:15:04 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 3.972 | nll_loss 2.404 | ppl 5.29 | wps 55201.8 | wpb 2685.2 | bsz 107.1 | num_updates 21508 | best_loss 11.059
2024-05-30 18:15:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:15:07 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 19 @ 21508 updates, score 3.972) (writing took 3.1106671588495374 seconds)
2024-05-30 18:15:07 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2024-05-30 18:15:07 | INFO | train | epoch 019 | loss 3.686 | nll_loss 2.183 | ppl 4.54 | wps 17323.6 | ups 4.87 | wpb 3556.4 | bsz 141.6 | num_updates 21508 | lr 0.000215625 | gnorm 1.004 | train_wall 217 | wall 0
2024-05-30 18:15:07 | INFO | fairseq.trainer | begin training epoch 20
2024-05-30 18:15:24 | INFO | train_inner | epoch 020:     92 / 1132 loss=3.64, nll_loss=2.131, ppl=4.38, wps=13512.8, ups=3.88, wpb=3485.4, bsz=135.7, num_updates=21600, lr=0.000215166, gnorm=1.02, train_wall=19, wall=0
2024-05-30 18:15:44 | INFO | train_inner | epoch 020:    192 / 1132 loss=3.633, nll_loss=2.122, ppl=4.35, wps=18849.4, ups=5.2, wpb=3622.3, bsz=132.1, num_updates=21700, lr=0.000214669, gnorm=0.975, train_wall=19, wall=0
2024-05-30 18:16:03 | INFO | train_inner | epoch 020:    292 / 1132 loss=3.651, nll_loss=2.141, ppl=4.41, wps=18682, ups=5.28, wpb=3540.5, bsz=137.6, num_updates=21800, lr=0.000214176, gnorm=1.036, train_wall=19, wall=0
2024-05-30 18:16:22 | INFO | train_inner | epoch 020:    392 / 1132 loss=3.623, nll_loss=2.111, ppl=4.32, wps=18377.2, ups=5.24, wpb=3510.3, bsz=147.9, num_updates=21900, lr=0.000213687, gnorm=1.031, train_wall=19, wall=0
2024-05-30 18:16:41 | INFO | train_inner | epoch 020:    492 / 1132 loss=3.66, nll_loss=2.153, ppl=4.45, wps=17743.6, ups=5.08, wpb=3492.3, bsz=137.4, num_updates=22000, lr=0.000213201, gnorm=1.044, train_wall=20, wall=0
2024-05-30 18:16:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:16:45 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.965 | nll_loss 2.394 | ppl 5.25 | wps 55812.9 | wpb 2685.2 | bsz 107.1 | num_updates 22000 | best_loss 11.059
2024-05-30 18:16:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:16:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_20_22000.pt (epoch 20 @ 22000 updates, score 3.965) (writing took 3.6862359228543937 seconds)
2024-05-30 18:17:08 | INFO | train_inner | epoch 020:    592 / 1132 loss=3.629, nll_loss=2.119, ppl=4.34, wps=13644.5, ups=3.79, wpb=3598.1, bsz=163.8, num_updates=22100, lr=0.000212718, gnorm=1.009, train_wall=19, wall=0
2024-05-30 18:17:27 | INFO | train_inner | epoch 020:    692 / 1132 loss=3.674, nll_loss=2.17, ppl=4.5, wps=18790.1, ups=5.21, wpb=3603.5, bsz=139.4, num_updates=22200, lr=0.000212238, gnorm=0.996, train_wall=19, wall=0
2024-05-30 18:17:46 | INFO | train_inner | epoch 020:    792 / 1132 loss=3.667, nll_loss=2.161, ppl=4.47, wps=18319.8, ups=5.25, wpb=3491.8, bsz=135.5, num_updates=22300, lr=0.000211762, gnorm=1.03, train_wall=19, wall=0
2024-05-30 18:18:05 | INFO | train_inner | epoch 020:    892 / 1132 loss=3.686, nll_loss=2.182, ppl=4.54, wps=18640.4, ups=5.22, wpb=3570.5, bsz=136.4, num_updates=22400, lr=0.000211289, gnorm=1.017, train_wall=19, wall=0
2024-05-30 18:18:24 | INFO | train_inner | epoch 020:    992 / 1132 loss=3.651, nll_loss=2.145, ppl=4.42, wps=18817, ups=5.22, wpb=3606.7, bsz=145.8, num_updates=22500, lr=0.000210819, gnorm=0.988, train_wall=19, wall=0
2024-05-30 18:18:43 | INFO | train_inner | epoch 020:   1092 / 1132 loss=3.662, nll_loss=2.156, ppl=4.46, wps=18711.5, ups=5.22, wpb=3587, bsz=148, num_updates=22600, lr=0.000210352, gnorm=1.014, train_wall=19, wall=0
2024-05-30 18:18:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:18:55 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.972 | nll_loss 2.404 | ppl 5.29 | wps 55831.7 | wpb 2685.2 | bsz 107.1 | num_updates 22640 | best_loss 11.059
2024-05-30 18:18:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:18:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 20 @ 22640 updates, score 3.972) (writing took 2.888878915924579 seconds)
2024-05-30 18:18:57 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2024-05-30 18:18:57 | INFO | train | epoch 020 | loss 3.654 | nll_loss 2.146 | ppl 4.43 | wps 17451.1 | ups 4.91 | wpb 3556.4 | bsz 141.6 | num_updates 22640 | lr 0.000210166 | gnorm 1.015 | train_wall 215 | wall 0
2024-05-30 18:18:58 | INFO | fairseq.trainer | begin training epoch 21
2024-05-30 18:19:09 | INFO | train_inner | epoch 021:     60 / 1132 loss=3.657, nll_loss=2.15, ppl=4.44, wps=13762.8, ups=3.91, wpb=3521, bsz=132.6, num_updates=22700, lr=0.000209888, gnorm=1.051, train_wall=19, wall=0
2024-05-30 18:19:29 | INFO | train_inner | epoch 021:    160 / 1132 loss=3.568, nll_loss=2.048, ppl=4.13, wps=17399.7, ups=5, wpb=3478.3, bsz=142.2, num_updates=22800, lr=0.000209427, gnorm=1.011, train_wall=20, wall=0
2024-05-30 18:19:49 | INFO | train_inner | epoch 021:    260 / 1132 loss=3.556, nll_loss=2.035, ppl=4.1, wps=18102.5, ups=5.03, wpb=3598.5, bsz=157.2, num_updates=22900, lr=0.000208969, gnorm=0.989, train_wall=20, wall=0
2024-05-30 18:20:08 | INFO | train_inner | epoch 021:    360 / 1132 loss=3.633, nll_loss=2.122, ppl=4.35, wps=18212.2, ups=5.15, wpb=3534.5, bsz=129.1, num_updates=23000, lr=0.000208514, gnorm=1.033, train_wall=19, wall=0
2024-05-30 18:20:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:20:12 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 3.958 | nll_loss 2.388 | ppl 5.23 | wps 55805.5 | wpb 2685.2 | bsz 107.1 | num_updates 23000 | best_loss 11.059
2024-05-30 18:20:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:20:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_21_23000.pt (epoch 21 @ 23000 updates, score 3.958) (writing took 3.585666741710156 seconds)
2024-05-30 18:20:35 | INFO | train_inner | epoch 021:    460 / 1132 loss=3.641, nll_loss=2.131, ppl=4.38, wps=13428.9, ups=3.81, wpb=3523.9, bsz=126.1, num_updates=23100, lr=0.000208063, gnorm=1.024, train_wall=19, wall=0
2024-05-30 18:20:54 | INFO | train_inner | epoch 021:    560 / 1132 loss=3.605, nll_loss=2.091, ppl=4.26, wps=18932.6, ups=5.16, wpb=3668.3, bsz=148.5, num_updates=23200, lr=0.000207614, gnorm=0.978, train_wall=19, wall=0
2024-05-30 18:21:13 | INFO | train_inner | epoch 021:    660 / 1132 loss=3.648, nll_loss=2.139, ppl=4.4, wps=18660.2, ups=5.15, wpb=3621, bsz=142.7, num_updates=23300, lr=0.000207168, gnorm=1.004, train_wall=19, wall=0
2024-05-30 18:21:32 | INFO | train_inner | epoch 021:    760 / 1132 loss=3.636, nll_loss=2.128, ppl=4.37, wps=18626.4, ups=5.26, wpb=3543.1, bsz=146.6, num_updates=23400, lr=0.000206725, gnorm=1.027, train_wall=19, wall=0
2024-05-30 18:21:51 | INFO | train_inner | epoch 021:    860 / 1132 loss=3.618, nll_loss=2.106, ppl=4.31, wps=18842, ups=5.29, wpb=3563, bsz=154.1, num_updates=23500, lr=0.000206284, gnorm=1.014, train_wall=19, wall=0
2024-05-30 18:22:10 | INFO | train_inner | epoch 021:    960 / 1132 loss=3.646, nll_loss=2.138, ppl=4.4, wps=19045.2, ups=5.36, wpb=3551.1, bsz=136.2, num_updates=23600, lr=0.000205847, gnorm=1.015, train_wall=19, wall=0
2024-05-30 18:22:29 | INFO | train_inner | epoch 021:   1060 / 1132 loss=3.604, nll_loss=2.091, ppl=4.26, wps=18951.9, ups=5.34, wpb=3548.4, bsz=159.2, num_updates=23700, lr=0.000205412, gnorm=1.003, train_wall=19, wall=0
2024-05-30 18:22:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:22:45 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 3.939 | nll_loss 2.368 | ppl 5.16 | wps 55930 | wpb 2685.2 | bsz 107.1 | num_updates 23772 | best_loss 11.059
2024-05-30 18:22:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:22:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 21 @ 23772 updates, score 3.939) (writing took 3.1723309229128063 seconds)
2024-05-30 18:22:49 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2024-05-30 18:22:49 | INFO | train | epoch 021 | loss 3.623 | nll_loss 2.111 | ppl 4.32 | wps 17414.7 | ups 4.9 | wpb 3556.4 | bsz 141.6 | num_updates 23772 | lr 0.000205101 | gnorm 1.015 | train_wall 216 | wall 0
2024-05-30 18:22:49 | INFO | fairseq.trainer | begin training epoch 22
2024-05-30 18:22:54 | INFO | train_inner | epoch 022:     28 / 1132 loss=3.7, nll_loss=2.196, ppl=4.58, wps=13821, ups=3.91, wpb=3533, bsz=114, num_updates=23800, lr=0.00020498, gnorm=1.045, train_wall=19, wall=0
2024-05-30 18:23:13 | INFO | train_inner | epoch 022:    128 / 1132 loss=3.551, nll_loss=2.029, ppl=4.08, wps=18814.9, ups=5.24, wpb=3587.4, bsz=137, num_updates=23900, lr=0.000204551, gnorm=0.975, train_wall=19, wall=0
2024-05-30 18:23:33 | INFO | train_inner | epoch 022:    228 / 1132 loss=3.543, nll_loss=2.021, ppl=4.06, wps=18947.3, ups=5.19, wpb=3648.2, bsz=152.8, num_updates=24000, lr=0.000204124, gnorm=0.969, train_wall=19, wall=0
2024-05-30 18:23:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:23:36 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 3.951 | nll_loss 2.374 | ppl 5.19 | wps 56196.2 | wpb 2685.2 | bsz 107.1 | num_updates 24000 | best_loss 11.059
2024-05-30 18:23:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:23:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_22_24000.pt (epoch 22 @ 24000 updates, score 3.951) (writing took 4.024034942034632 seconds)
2024-05-30 18:23:59 | INFO | train_inner | epoch 022:    328 / 1132 loss=3.561, nll_loss=2.038, ppl=4.11, wps=13331.9, ups=3.75, wpb=3558.4, bsz=151.5, num_updates=24100, lr=0.0002037, gnorm=1.004, train_wall=19, wall=0
2024-05-30 18:24:18 | INFO | train_inner | epoch 022:    428 / 1132 loss=3.574, nll_loss=2.056, ppl=4.16, wps=18615.8, ups=5.23, wpb=3559.3, bsz=154, num_updates=24200, lr=0.000203279, gnorm=1.033, train_wall=19, wall=0
2024-05-30 18:24:37 | INFO | train_inner | epoch 022:    528 / 1132 loss=3.586, nll_loss=2.068, ppl=4.19, wps=18638.6, ups=5.24, wpb=3556.9, bsz=150, num_updates=24300, lr=0.00020286, gnorm=1.002, train_wall=19, wall=0
2024-05-30 18:24:56 | INFO | train_inner | epoch 022:    628 / 1132 loss=3.632, nll_loss=2.121, ppl=4.35, wps=18651.2, ups=5.35, wpb=3488.3, bsz=125, num_updates=24400, lr=0.000202444, gnorm=1.055, train_wall=19, wall=0
2024-05-30 18:25:15 | INFO | train_inner | epoch 022:    728 / 1132 loss=3.592, nll_loss=2.076, ppl=4.22, wps=18723.2, ups=5.2, wpb=3600.7, bsz=138.8, num_updates=24500, lr=0.000202031, gnorm=1.005, train_wall=19, wall=0
2024-05-30 18:25:34 | INFO | train_inner | epoch 022:    828 / 1132 loss=3.592, nll_loss=2.077, ppl=4.22, wps=18256.6, ups=5.24, wpb=3483.3, bsz=148.4, num_updates=24600, lr=0.000201619, gnorm=1.04, train_wall=19, wall=0
2024-05-30 18:25:54 | INFO | train_inner | epoch 022:    928 / 1132 loss=3.631, nll_loss=2.12, ppl=4.35, wps=18536.1, ups=5.15, wpb=3601.6, bsz=132.8, num_updates=24700, lr=0.000201211, gnorm=1.024, train_wall=19, wall=0
2024-05-30 18:26:14 | INFO | train_inner | epoch 022:   1028 / 1132 loss=3.658, nll_loss=2.15, ppl=4.44, wps=17268.8, ups=4.96, wpb=3484.9, bsz=123.6, num_updates=24800, lr=0.000200805, gnorm=1.068, train_wall=20, wall=0
2024-05-30 18:26:33 | INFO | train_inner | epoch 022:   1128 / 1132 loss=3.596, nll_loss=2.084, ppl=4.24, wps=18270, ups=5.16, wpb=3542.3, bsz=150.5, num_updates=24900, lr=0.000200401, gnorm=1.017, train_wall=19, wall=0
2024-05-30 18:26:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:26:38 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 3.945 | nll_loss 2.369 | ppl 5.17 | wps 55894 | wpb 2685.2 | bsz 107.1 | num_updates 24904 | best_loss 11.059
2024-05-30 18:26:38 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:26:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 22 @ 24904 updates, score 3.945) (writing took 3.2310184901580215 seconds)
2024-05-30 18:26:41 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2024-05-30 18:26:41 | INFO | train | epoch 022 | loss 3.593 | nll_loss 2.077 | ppl 4.22 | wps 17332.1 | ups 4.87 | wpb 3556.4 | bsz 141.6 | num_updates 24904 | lr 0.000200385 | gnorm 1.017 | train_wall 216 | wall 0
2024-05-30 18:26:41 | INFO | fairseq.trainer | begin training epoch 23
2024-05-30 18:26:59 | INFO | train_inner | epoch 023:     96 / 1132 loss=3.515, nll_loss=1.988, ppl=3.97, wps=13657.3, ups=3.87, wpb=3526.2, bsz=143.4, num_updates=25000, lr=0.0002, gnorm=1.011, train_wall=19, wall=0
2024-05-30 18:26:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:27:03 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.951 | nll_loss 2.375 | ppl 5.19 | wps 55760.9 | wpb 2685.2 | bsz 107.1 | num_updates 25000 | best_loss 11.059
2024-05-30 18:27:03 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:27:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_23_25000.pt (epoch 23 @ 25000 updates, score 3.951) (writing took 3.384557773824781 seconds)
2024-05-30 18:27:26 | INFO | train_inner | epoch 023:    196 / 1132 loss=3.547, nll_loss=2.023, ppl=4.06, wps=13191.1, ups=3.71, wpb=3553.1, bsz=134.4, num_updates=25100, lr=0.000199601, gnorm=1.001, train_wall=20, wall=0
2024-05-30 18:27:46 | INFO | train_inner | epoch 023:    296 / 1132 loss=3.563, nll_loss=2.041, ppl=4.11, wps=17586, ups=4.95, wpb=3551.6, bsz=130, num_updates=25200, lr=0.000199205, gnorm=1.015, train_wall=20, wall=0
2024-05-30 18:28:06 | INFO | train_inner | epoch 023:    396 / 1132 loss=3.543, nll_loss=2.019, ppl=4.05, wps=18485.3, ups=5.08, wpb=3636.1, bsz=155.8, num_updates=25300, lr=0.000198811, gnorm=1.002, train_wall=20, wall=0
2024-05-30 18:28:25 | INFO | train_inner | epoch 023:    496 / 1132 loss=3.568, nll_loss=2.048, ppl=4.14, wps=18610, ups=5.29, wpb=3518.5, bsz=144.4, num_updates=25400, lr=0.000198419, gnorm=1.026, train_wall=19, wall=0
2024-05-30 18:28:44 | INFO | train_inner | epoch 023:    596 / 1132 loss=3.596, nll_loss=2.078, ppl=4.22, wps=18860.7, ups=5.37, wpb=3515.2, bsz=124, num_updates=25500, lr=0.00019803, gnorm=1.054, train_wall=18, wall=0
2024-05-30 18:29:02 | INFO | train_inner | epoch 023:    696 / 1132 loss=3.611, nll_loss=2.097, ppl=4.28, wps=19394.4, ups=5.48, wpb=3540.9, bsz=129.2, num_updates=25600, lr=0.000197642, gnorm=1.059, train_wall=18, wall=0
2024-05-30 18:29:20 | INFO | train_inner | epoch 023:    796 / 1132 loss=3.553, nll_loss=2.032, ppl=4.09, wps=19680.4, ups=5.46, wpb=3603.9, bsz=152.2, num_updates=25700, lr=0.000197257, gnorm=1.011, train_wall=18, wall=0
2024-05-30 18:29:38 | INFO | train_inner | epoch 023:    896 / 1132 loss=3.58, nll_loss=2.063, ppl=4.18, wps=19425.3, ups=5.48, wpb=3543.9, bsz=146.7, num_updates=25800, lr=0.000196875, gnorm=1.046, train_wall=18, wall=0
2024-05-30 18:29:57 | INFO | train_inner | epoch 023:    996 / 1132 loss=3.581, nll_loss=2.063, ppl=4.18, wps=19613.7, ups=5.48, wpb=3579.1, bsz=144.1, num_updates=25900, lr=0.000196494, gnorm=1.024, train_wall=18, wall=0
2024-05-30 18:30:16 | INFO | train_inner | epoch 023:   1096 / 1132 loss=3.568, nll_loss=2.05, ppl=4.14, wps=18712, ups=5.31, wpb=3525.2, bsz=151.3, num_updates=26000, lr=0.000196116, gnorm=1.041, train_wall=19, wall=0
2024-05-30 18:30:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:30:19 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.931 | nll_loss 2.361 | ppl 5.14 | wps 56259.7 | wpb 2685.2 | bsz 107.1 | num_updates 26000 | best_loss 11.059
2024-05-30 18:30:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:30:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_23_26000.pt (epoch 23 @ 26000 updates, score 3.931) (writing took 3.2734261150471866 seconds)
2024-05-30 18:30:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:30:33 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.936 | nll_loss 2.357 | ppl 5.12 | wps 56228.2 | wpb 2685.2 | bsz 107.1 | num_updates 26036 | best_loss 11.059
2024-05-30 18:30:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:30:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 23 @ 26036 updates, score 3.936) (writing took 2.9392820349894464 seconds)
2024-05-30 18:30:36 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2024-05-30 18:30:36 | INFO | train | epoch 023 | loss 3.567 | nll_loss 2.047 | ppl 4.13 | wps 17161 | ups 4.83 | wpb 3556.4 | bsz 141.6 | num_updates 26036 | lr 0.000195981 | gnorm 1.026 | train_wall 213 | wall 0
2024-05-30 18:30:36 | INFO | fairseq.trainer | begin training epoch 24
2024-05-30 18:30:48 | INFO | train_inner | epoch 024:     64 / 1132 loss=3.53, nll_loss=2.007, ppl=4.02, wps=11076.3, ups=3.1, wpb=3572.7, bsz=137, num_updates=26100, lr=0.00019574, gnorm=1.005, train_wall=19, wall=0
2024-05-30 18:31:07 | INFO | train_inner | epoch 024:    164 / 1132 loss=3.479, nll_loss=1.947, ppl=3.86, wps=19234.4, ups=5.16, wpb=3724.7, bsz=154.6, num_updates=26200, lr=0.000195366, gnorm=0.945, train_wall=19, wall=0
2024-05-30 18:31:26 | INFO | train_inner | epoch 024:    264 / 1132 loss=3.559, nll_loss=2.036, ppl=4.1, wps=18500.7, ups=5.22, wpb=3546.9, bsz=132.3, num_updates=26300, lr=0.000194994, gnorm=1.029, train_wall=19, wall=0
2024-05-30 18:31:45 | INFO | train_inner | epoch 024:    364 / 1132 loss=3.542, nll_loss=2.016, ppl=4.05, wps=18679.6, ups=5.22, wpb=3577.1, bsz=136.7, num_updates=26400, lr=0.000194625, gnorm=1.035, train_wall=19, wall=0
2024-05-30 18:32:05 | INFO | train_inner | epoch 024:    464 / 1132 loss=3.553, nll_loss=2.03, ppl=4.08, wps=18042.5, ups=5.03, wpb=3587.2, bsz=142.6, num_updates=26500, lr=0.000194257, gnorm=1.048, train_wall=20, wall=0
2024-05-30 18:32:27 | INFO | train_inner | epoch 024:    564 / 1132 loss=3.518, nll_loss=1.992, ppl=3.98, wps=16693.5, ups=4.7, wpb=3550.3, bsz=150.1, num_updates=26600, lr=0.000193892, gnorm=1.014, train_wall=21, wall=0
2024-05-30 18:32:48 | INFO | train_inner | epoch 024:    664 / 1132 loss=3.561, nll_loss=2.039, ppl=4.11, wps=16804.8, ups=4.71, wpb=3569.6, bsz=133.8, num_updates=26700, lr=0.000193528, gnorm=1.023, train_wall=21, wall=0
2024-05-30 18:33:09 | INFO | train_inner | epoch 024:    764 / 1132 loss=3.566, nll_loss=2.045, ppl=4.13, wps=16310.9, ups=4.77, wpb=3416, bsz=139.4, num_updates=26800, lr=0.000193167, gnorm=1.068, train_wall=21, wall=0
2024-05-30 18:33:28 | INFO | train_inner | epoch 024:    864 / 1132 loss=3.539, nll_loss=2.017, ppl=4.05, wps=18246.1, ups=5.12, wpb=3564.5, bsz=147.2, num_updates=26900, lr=0.000192807, gnorm=1.011, train_wall=19, wall=0
2024-05-30 18:33:47 | INFO | train_inner | epoch 024:    964 / 1132 loss=3.548, nll_loss=2.026, ppl=4.07, wps=18262.2, ups=5.29, wpb=3454.7, bsz=140.6, num_updates=27000, lr=0.00019245, gnorm=1.052, train_wall=19, wall=0
2024-05-30 18:33:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:33:51 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 3.926 | nll_loss 2.346 | ppl 5.08 | wps 55878.8 | wpb 2685.2 | bsz 107.1 | num_updates 27000 | best_loss 11.059
2024-05-30 18:33:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:33:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_24_27000.pt (epoch 24 @ 27000 updates, score 3.926) (writing took 3.532212772872299 seconds)
2024-05-30 18:34:13 | INFO | train_inner | epoch 024:   1064 / 1132 loss=3.555, nll_loss=2.034, ppl=4.1, wps=13672.6, ups=3.82, wpb=3577.8, bsz=146.7, num_updates=27100, lr=0.000192095, gnorm=1.048, train_wall=19, wall=0
2024-05-30 18:34:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:34:30 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 3.919 | nll_loss 2.344 | ppl 5.08 | wps 55317.4 | wpb 2685.2 | bsz 107.1 | num_updates 27168 | best_loss 11.059
2024-05-30 18:34:30 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:34:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 24 @ 27168 updates, score 3.919) (writing took 3.3264147816225886 seconds)
2024-05-30 18:34:33 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2024-05-30 18:34:33 | INFO | train | epoch 024 | loss 3.541 | nll_loss 2.017 | ppl 4.05 | wps 16937.8 | ups 4.76 | wpb 3556.4 | bsz 141.6 | num_updates 27168 | lr 0.000191854 | gnorm 1.027 | train_wall 222 | wall 0
2024-05-30 18:34:33 | INFO | fairseq.trainer | begin training epoch 25
2024-05-30 18:34:39 | INFO | train_inner | epoch 025:     32 / 1132 loss=3.567, nll_loss=2.046, ppl=4.13, wps=13659.9, ups=3.84, wpb=3553.8, bsz=131.8, num_updates=27200, lr=0.000191741, gnorm=1.044, train_wall=19, wall=0
2024-05-30 18:34:59 | INFO | train_inner | epoch 025:    132 / 1132 loss=3.477, nll_loss=1.943, ppl=3.84, wps=18524.3, ups=5.18, wpb=3576.4, bsz=143.6, num_updates=27300, lr=0.00019139, gnorm=1.003, train_wall=19, wall=0
2024-05-30 18:35:18 | INFO | train_inner | epoch 025:    232 / 1132 loss=3.477, nll_loss=1.94, ppl=3.84, wps=18205.4, ups=5.22, wpb=3484.8, bsz=151, num_updates=27400, lr=0.00019104, gnorm=1.036, train_wall=19, wall=0
2024-05-30 18:35:38 | INFO | train_inner | epoch 025:    332 / 1132 loss=3.481, nll_loss=1.948, ppl=3.86, wps=17960.6, ups=4.96, wpb=3618.7, bsz=156.1, num_updates=27500, lr=0.000190693, gnorm=1.001, train_wall=20, wall=0
2024-05-30 18:35:57 | INFO | train_inner | epoch 025:    432 / 1132 loss=3.544, nll_loss=2.019, ppl=4.05, wps=18889.4, ups=5.31, wpb=3559.8, bsz=134.1, num_updates=27600, lr=0.000190347, gnorm=1.072, train_wall=19, wall=0
2024-05-30 18:36:18 | INFO | train_inner | epoch 025:    532 / 1132 loss=3.529, nll_loss=2.004, ppl=4.01, wps=17228.8, ups=4.84, wpb=3562.3, bsz=124.8, num_updates=27700, lr=0.000190003, gnorm=1.018, train_wall=21, wall=0
2024-05-30 18:36:38 | INFO | train_inner | epoch 025:    632 / 1132 loss=3.515, nll_loss=1.988, ppl=3.97, wps=17921.7, ups=5.01, wpb=3579.8, bsz=140.6, num_updates=27800, lr=0.000189661, gnorm=1.024, train_wall=20, wall=0
2024-05-30 18:36:57 | INFO | train_inner | epoch 025:    732 / 1132 loss=3.567, nll_loss=2.046, ppl=4.13, wps=18468.4, ups=5.23, wpb=3530.6, bsz=132.9, num_updates=27900, lr=0.000189321, gnorm=1.059, train_wall=19, wall=0
2024-05-30 18:37:16 | INFO | train_inner | epoch 025:    832 / 1132 loss=3.536, nll_loss=2.012, ppl=4.03, wps=18633.2, ups=5.3, wpb=3514.6, bsz=133.2, num_updates=28000, lr=0.000188982, gnorm=1.044, train_wall=19, wall=0
2024-05-30 18:37:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:37:19 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 3.928 | nll_loss 2.352 | ppl 5.1 | wps 56012.8 | wpb 2685.2 | bsz 107.1 | num_updates 28000 | best_loss 11.059
2024-05-30 18:37:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:37:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_25_28000.pt (epoch 25 @ 28000 updates, score 3.928) (writing took 3.5223308159038424 seconds)
2024-05-30 18:37:42 | INFO | train_inner | epoch 025:    932 / 1132 loss=3.518, nll_loss=1.993, ppl=3.98, wps=13917.2, ups=3.82, wpb=3639.3, bsz=152.4, num_updates=28100, lr=0.000188646, gnorm=1.003, train_wall=19, wall=0
2024-05-30 18:38:01 | INFO | train_inner | epoch 025:   1032 / 1132 loss=3.5, nll_loss=1.973, ppl=3.93, wps=18350.9, ups=5.31, wpb=3457.8, bsz=149.4, num_updates=28200, lr=0.000188311, gnorm=1.048, train_wall=19, wall=0
2024-05-30 18:38:20 | INFO | train_inner | epoch 025:   1132 / 1132 loss=3.549, nll_loss=2.03, ppl=4.08, wps=18863, ups=5.22, wpb=3614, bsz=144.1, num_updates=28300, lr=0.000187978, gnorm=1.027, train_wall=19, wall=0
2024-05-30 18:38:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:38:23 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 3.926 | nll_loss 2.35 | ppl 5.1 | wps 55806.4 | wpb 2685.2 | bsz 107.1 | num_updates 28300 | best_loss 11.059
2024-05-30 18:38:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:38:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 25 @ 28300 updates, score 3.926) (writing took 3.080544208176434 seconds)
2024-05-30 18:38:26 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2024-05-30 18:38:26 | INFO | train | epoch 025 | loss 3.517 | nll_loss 1.99 | ppl 3.97 | wps 17278.4 | ups 4.86 | wpb 3556.4 | bsz 141.6 | num_updates 28300 | lr 0.000187978 | gnorm 1.031 | train_wall 218 | wall 0
2024-05-30 18:38:26 | INFO | fairseq.trainer | begin training epoch 26
2024-05-30 18:38:46 | INFO | train_inner | epoch 026:    100 / 1132 loss=3.402, nll_loss=1.86, ppl=3.63, wps=13908.2, ups=3.85, wpb=3609.5, bsz=163.9, num_updates=28400, lr=0.000187647, gnorm=0.998, train_wall=19, wall=0
2024-05-30 18:39:04 | INFO | train_inner | epoch 026:    200 / 1132 loss=3.469, nll_loss=1.936, ppl=3.83, wps=18471.7, ups=5.33, wpb=3464.7, bsz=131.5, num_updates=28500, lr=0.000187317, gnorm=1.058, train_wall=19, wall=0
2024-05-30 18:39:24 | INFO | train_inner | epoch 026:    300 / 1132 loss=3.473, nll_loss=1.94, ppl=3.84, wps=18719.4, ups=5.17, wpb=3618.6, bsz=149.2, num_updates=28600, lr=0.000186989, gnorm=1.005, train_wall=19, wall=0
2024-05-30 18:39:43 | INFO | train_inner | epoch 026:    400 / 1132 loss=3.515, nll_loss=1.986, ppl=3.96, wps=18652, ups=5.25, wpb=3555.5, bsz=126.5, num_updates=28700, lr=0.000186663, gnorm=1.039, train_wall=19, wall=0
2024-05-30 18:40:02 | INFO | train_inner | epoch 026:    500 / 1132 loss=3.487, nll_loss=1.956, ppl=3.88, wps=18673, ups=5.23, wpb=3570.7, bsz=140.2, num_updates=28800, lr=0.000186339, gnorm=1.019, train_wall=19, wall=0
2024-05-30 18:40:21 | INFO | train_inner | epoch 026:    600 / 1132 loss=3.522, nll_loss=1.994, ppl=3.98, wps=18532.1, ups=5.24, wpb=3534.6, bsz=130.9, num_updates=28900, lr=0.000186016, gnorm=1.078, train_wall=19, wall=0
2024-05-30 18:40:40 | INFO | train_inner | epoch 026:    700 / 1132 loss=3.497, nll_loss=1.967, ppl=3.91, wps=18507.8, ups=5.24, wpb=3534.1, bsz=140.5, num_updates=29000, lr=0.000185695, gnorm=1.028, train_wall=19, wall=0
2024-05-30 18:40:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:40:44 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 3.925 | nll_loss 2.347 | ppl 5.09 | wps 55809.4 | wpb 2685.2 | bsz 107.1 | num_updates 29000 | best_loss 11.059
2024-05-30 18:40:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:40:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_26_29000.pt (epoch 26 @ 29000 updates, score 3.925) (writing took 3.5954487901180983 seconds)
2024-05-30 18:41:06 | INFO | train_inner | epoch 026:    800 / 1132 loss=3.526, nll_loss=1.999, ppl=4, wps=13599.8, ups=3.81, wpb=3564.9, bsz=140.2, num_updates=29100, lr=0.000185376, gnorm=1.05, train_wall=19, wall=0
2024-05-30 18:41:25 | INFO | train_inner | epoch 026:    900 / 1132 loss=3.511, nll_loss=1.985, ppl=3.96, wps=19072.2, ups=5.31, wpb=3588.6, bsz=144.9, num_updates=29200, lr=0.000185058, gnorm=1.032, train_wall=19, wall=0
2024-05-30 18:41:45 | INFO | train_inner | epoch 026:   1000 / 1132 loss=3.512, nll_loss=1.987, ppl=3.97, wps=18077.1, ups=5.06, wpb=3574.2, bsz=152.1, num_updates=29300, lr=0.000184742, gnorm=1.035, train_wall=20, wall=0
2024-05-30 18:42:04 | INFO | train_inner | epoch 026:   1100 / 1132 loss=3.511, nll_loss=1.983, ppl=3.95, wps=18420.1, ups=5.2, wpb=3540.1, bsz=145.3, num_updates=29400, lr=0.000184428, gnorm=1.043, train_wall=19, wall=0
2024-05-30 18:42:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:42:14 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 3.918 | nll_loss 2.34 | ppl 5.06 | wps 55802.5 | wpb 2685.2 | bsz 107.1 | num_updates 29432 | best_loss 11.059
2024-05-30 18:42:14 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:42:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 26 @ 29432 updates, score 3.918) (writing took 3.009713025763631 seconds)
2024-05-30 18:42:17 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2024-05-30 18:42:17 | INFO | train | epoch 026 | loss 3.495 | nll_loss 1.965 | ppl 3.9 | wps 17472.4 | ups 4.91 | wpb 3556.4 | bsz 141.6 | num_updates 29432 | lr 0.000184327 | gnorm 1.037 | train_wall 215 | wall 0
2024-05-30 18:42:17 | INFO | fairseq.trainer | begin training epoch 27
2024-05-30 18:42:30 | INFO | train_inner | epoch 027:     68 / 1132 loss=3.467, nll_loss=1.931, ppl=3.81, wps=13521.1, ups=3.87, wpb=3497.3, bsz=134.9, num_updates=29500, lr=0.000184115, gnorm=1.048, train_wall=19, wall=0
2024-05-30 18:42:49 | INFO | train_inner | epoch 027:    168 / 1132 loss=3.417, nll_loss=1.875, ppl=3.67, wps=18479, ups=5.23, wpb=3530.9, bsz=153.1, num_updates=29600, lr=0.000183804, gnorm=1.01, train_wall=19, wall=0
2024-05-30 18:43:08 | INFO | train_inner | epoch 027:    268 / 1132 loss=3.458, nll_loss=1.922, ppl=3.79, wps=18851.6, ups=5.24, wpb=3599.9, bsz=141.5, num_updates=29700, lr=0.000183494, gnorm=1.043, train_wall=19, wall=0
2024-05-30 18:43:27 | INFO | train_inner | epoch 027:    368 / 1132 loss=3.468, nll_loss=1.932, ppl=3.82, wps=18777.7, ups=5.21, wpb=3603.9, bsz=137.8, num_updates=29800, lr=0.000183186, gnorm=1.021, train_wall=19, wall=0
2024-05-30 18:43:46 | INFO | train_inner | epoch 027:    468 / 1132 loss=3.46, nll_loss=1.925, ppl=3.8, wps=18649, ups=5.27, wpb=3540.6, bsz=140.8, num_updates=29900, lr=0.000182879, gnorm=1.042, train_wall=19, wall=0
2024-05-30 18:44:06 | INFO | train_inner | epoch 027:    568 / 1132 loss=3.452, nll_loss=1.917, ppl=3.78, wps=18968.4, ups=5.2, wpb=3646.5, bsz=148.6, num_updates=30000, lr=0.000182574, gnorm=1.005, train_wall=19, wall=0
2024-05-30 18:44:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:44:09 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 3.922 | nll_loss 2.34 | ppl 5.06 | wps 56088.8 | wpb 2685.2 | bsz 107.1 | num_updates 30000 | best_loss 11.059
2024-05-30 18:44:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:44:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_27_30000.pt (epoch 27 @ 30000 updates, score 3.922) (writing took 3.4836673932150006 seconds)
2024-05-30 18:44:31 | INFO | train_inner | epoch 027:    668 / 1132 loss=3.471, nll_loss=1.938, ppl=3.83, wps=13562.8, ups=3.87, wpb=3503.9, bsz=141.3, num_updates=30100, lr=0.000182271, gnorm=1.048, train_wall=19, wall=0
2024-05-30 18:44:50 | INFO | train_inner | epoch 027:    768 / 1132 loss=3.491, nll_loss=1.96, ppl=3.89, wps=18915.7, ups=5.38, wpb=3517.7, bsz=137.3, num_updates=30200, lr=0.000181969, gnorm=1.056, train_wall=18, wall=0
2024-05-30 18:45:09 | INFO | train_inner | epoch 027:    868 / 1132 loss=3.481, nll_loss=1.952, ppl=3.87, wps=18586, ups=5.24, wpb=3549.7, bsz=142.6, num_updates=30300, lr=0.000181668, gnorm=1.057, train_wall=19, wall=0
2024-05-30 18:45:28 | INFO | train_inner | epoch 027:    968 / 1132 loss=3.527, nll_loss=2, ppl=4, wps=18728.3, ups=5.22, wpb=3584.5, bsz=128, num_updates=30400, lr=0.000181369, gnorm=1.058, train_wall=19, wall=0
2024-05-30 18:45:47 | INFO | train_inner | epoch 027:   1068 / 1132 loss=3.513, nll_loss=1.986, ppl=3.96, wps=18470.1, ups=5.3, wpb=3487.1, bsz=142.5, num_updates=30500, lr=0.000181071, gnorm=1.083, train_wall=19, wall=0
2024-05-30 18:45:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:46:03 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 3.918 | nll_loss 2.34 | ppl 5.06 | wps 55953 | wpb 2685.2 | bsz 107.1 | num_updates 30564 | best_loss 11.059
2024-05-30 18:46:03 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:46:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 27 @ 30564 updates, score 3.918) (writing took 3.0747958198189735 seconds)
2024-05-30 18:46:06 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2024-05-30 18:46:06 | INFO | train | epoch 027 | loss 3.473 | nll_loss 1.94 | ppl 3.84 | wps 17568.6 | ups 4.94 | wpb 3556.4 | bsz 141.6 | num_updates 30564 | lr 0.000180882 | gnorm 1.041 | train_wall 214 | wall 0
2024-05-30 18:46:06 | INFO | fairseq.trainer | begin training epoch 28
2024-05-30 18:46:13 | INFO | train_inner | epoch 028:     36 / 1132 loss=3.49, nll_loss=1.957, ppl=3.88, wps=13940.6, ups=3.89, wpb=3583.5, bsz=135.9, num_updates=30600, lr=0.000180775, gnorm=1.024, train_wall=19, wall=0
2024-05-30 18:46:31 | INFO | train_inner | epoch 028:    136 / 1132 loss=3.417, nll_loss=1.873, ppl=3.66, wps=19097.7, ups=5.42, wpb=3523.7, bsz=138.2, num_updates=30700, lr=0.000180481, gnorm=1.041, train_wall=18, wall=0
2024-05-30 18:46:50 | INFO | train_inner | epoch 028:    236 / 1132 loss=3.412, nll_loss=1.87, ppl=3.66, wps=19349.5, ups=5.33, wpb=3628.1, bsz=153.3, num_updates=30800, lr=0.000180187, gnorm=1.011, train_wall=19, wall=0
2024-05-30 18:47:09 | INFO | train_inner | epoch 028:    336 / 1132 loss=3.429, nll_loss=1.888, ppl=3.7, wps=17996.9, ups=5.3, wpb=3395.7, bsz=131.4, num_updates=30900, lr=0.000179896, gnorm=1.09, train_wall=19, wall=0
2024-05-30 18:47:28 | INFO | train_inner | epoch 028:    436 / 1132 loss=3.443, nll_loss=1.904, ppl=3.74, wps=17914.9, ups=5.13, wpb=3493.7, bsz=149.5, num_updates=31000, lr=0.000179605, gnorm=1.093, train_wall=19, wall=0
2024-05-30 18:47:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:47:32 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 3.933 | nll_loss 2.35 | ppl 5.1 | wps 56058 | wpb 2685.2 | bsz 107.1 | num_updates 31000 | best_loss 11.059
2024-05-30 18:47:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:47:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_28_31000.pt (epoch 28 @ 31000 updates, score 3.933) (writing took 3.434045022819191 seconds)
2024-05-30 18:47:55 | INFO | train_inner | epoch 028:    536 / 1132 loss=3.467, nll_loss=1.931, ppl=3.81, wps=13235.9, ups=3.7, wpb=3575.2, bsz=132.4, num_updates=31100, lr=0.000179316, gnorm=1.041, train_wall=20, wall=0
2024-05-30 18:48:16 | INFO | train_inner | epoch 028:    636 / 1132 loss=3.454, nll_loss=1.917, ppl=3.78, wps=17396.5, ups=4.81, wpb=3613.7, bsz=143.2, num_updates=31200, lr=0.000179029, gnorm=1.032, train_wall=21, wall=0
2024-05-30 18:48:36 | INFO | train_inner | epoch 028:    736 / 1132 loss=3.44, nll_loss=1.905, ppl=3.75, wps=18295.3, ups=5.02, wpb=3644.1, bsz=148, num_updates=31300, lr=0.000178743, gnorm=1.022, train_wall=20, wall=0
2024-05-30 18:48:55 | INFO | train_inner | epoch 028:    836 / 1132 loss=3.51, nll_loss=1.98, ppl=3.94, wps=18120.6, ups=5.25, wpb=3448.6, bsz=128.8, num_updates=31400, lr=0.000178458, gnorm=1.111, train_wall=19, wall=0
2024-05-30 18:49:14 | INFO | train_inner | epoch 028:    936 / 1132 loss=3.475, nll_loss=1.943, ppl=3.85, wps=18766.8, ups=5.22, wpb=3592.1, bsz=140.5, num_updates=31500, lr=0.000178174, gnorm=1.035, train_wall=19, wall=0
2024-05-30 18:49:34 | INFO | train_inner | epoch 028:   1036 / 1132 loss=3.449, nll_loss=1.914, ppl=3.77, wps=18806.9, ups=5.21, wpb=3612.4, bsz=151.4, num_updates=31600, lr=0.000177892, gnorm=1.006, train_wall=19, wall=0
2024-05-30 18:49:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:49:55 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 3.905 | nll_loss 2.323 | ppl 5 | wps 55920.2 | wpb 2685.2 | bsz 107.1 | num_updates 31696 | best_loss 11.059
2024-05-30 18:49:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:49:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 28 @ 31696 updates, score 3.905) (writing took 2.8244753959588706 seconds)
2024-05-30 18:49:58 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2024-05-30 18:49:58 | INFO | train | epoch 028 | loss 3.452 | nll_loss 1.915 | ppl 3.77 | wps 17324.8 | ups 4.87 | wpb 3556.4 | bsz 141.6 | num_updates 31696 | lr 0.000177622 | gnorm 1.047 | train_wall 217 | wall 0
2024-05-30 18:49:58 | INFO | fairseq.trainer | begin training epoch 29
2024-05-30 18:49:59 | INFO | train_inner | epoch 029:      4 / 1132 loss=3.478, nll_loss=1.947, ppl=3.86, wps=14031.5, ups=3.9, wpb=3602.3, bsz=148.8, num_updates=31700, lr=0.000177611, gnorm=1.041, train_wall=19, wall=0
2024-05-30 18:50:19 | INFO | train_inner | epoch 029:    104 / 1132 loss=3.384, nll_loss=1.837, ppl=3.57, wps=18082.6, ups=5.17, wpb=3499.6, bsz=141.4, num_updates=31800, lr=0.000177332, gnorm=1.036, train_wall=19, wall=0
2024-05-30 18:50:38 | INFO | train_inner | epoch 029:    204 / 1132 loss=3.414, nll_loss=1.867, ppl=3.65, wps=18327.7, ups=5.27, wpb=3478.5, bsz=129.9, num_updates=31900, lr=0.000177054, gnorm=1.063, train_wall=19, wall=0
2024-05-30 18:50:57 | INFO | train_inner | epoch 029:    304 / 1132 loss=3.394, nll_loss=1.85, ppl=3.61, wps=19002, ups=5.19, wpb=3662.8, bsz=150.3, num_updates=32000, lr=0.000176777, gnorm=0.985, train_wall=19, wall=0
2024-05-30 18:50:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:51:00 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 3.92 | nll_loss 2.338 | ppl 5.05 | wps 56148.8 | wpb 2685.2 | bsz 107.1 | num_updates 32000 | best_loss 11.059
2024-05-30 18:51:00 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:51:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_29_32000.pt (epoch 29 @ 32000 updates, score 3.92) (writing took 3.350092437583953 seconds)
2024-05-30 18:51:23 | INFO | train_inner | epoch 029:    404 / 1132 loss=3.447, nll_loss=1.908, ppl=3.75, wps=13592.4, ups=3.86, wpb=3518.2, bsz=135.3, num_updates=32100, lr=0.000176501, gnorm=1.07, train_wall=19, wall=0
2024-05-30 18:51:42 | INFO | train_inner | epoch 029:    504 / 1132 loss=3.413, nll_loss=1.874, ppl=3.66, wps=18709.8, ups=5.18, wpb=3612.5, bsz=142.8, num_updates=32200, lr=0.000176227, gnorm=1.012, train_wall=19, wall=0
2024-05-30 18:52:02 | INFO | train_inner | epoch 029:    604 / 1132 loss=3.428, nll_loss=1.89, ppl=3.71, wps=18317.8, ups=5, wpb=3662, bsz=148.3, num_updates=32300, lr=0.000175954, gnorm=1.031, train_wall=20, wall=0
2024-05-30 18:52:21 | INFO | train_inner | epoch 029:    704 / 1132 loss=3.445, nll_loss=1.909, ppl=3.76, wps=18903.8, ups=5.22, wpb=3623.1, bsz=143.4, num_updates=32400, lr=0.000175682, gnorm=1.042, train_wall=19, wall=0
2024-05-30 18:52:40 | INFO | train_inner | epoch 029:    804 / 1132 loss=3.468, nll_loss=1.933, ppl=3.82, wps=18335.5, ups=5.3, wpb=3459.3, bsz=130.2, num_updates=32500, lr=0.000175412, gnorm=1.106, train_wall=19, wall=0
2024-05-30 18:52:59 | INFO | train_inner | epoch 029:    904 / 1132 loss=3.462, nll_loss=1.926, ppl=3.8, wps=18380.8, ups=5.27, wpb=3485.4, bsz=136.2, num_updates=32600, lr=0.000175142, gnorm=1.107, train_wall=19, wall=0
2024-05-30 18:53:18 | INFO | train_inner | epoch 029:   1004 / 1132 loss=3.436, nll_loss=1.899, ppl=3.73, wps=18601.8, ups=5.24, wpb=3548.7, bsz=161.3, num_updates=32700, lr=0.000174874, gnorm=1.05, train_wall=19, wall=0
2024-05-30 18:53:37 | INFO | train_inner | epoch 029:   1104 / 1132 loss=3.478, nll_loss=1.945, ppl=3.85, wps=18713, ups=5.25, wpb=3566, bsz=135.3, num_updates=32800, lr=0.000174608, gnorm=1.068, train_wall=19, wall=0
2024-05-30 18:53:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:53:46 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 3.911 | nll_loss 2.331 | ppl 5.03 | wps 55979.9 | wpb 2685.2 | bsz 107.1 | num_updates 32828 | best_loss 11.059
2024-05-30 18:53:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:53:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 29 @ 32828 updates, score 3.911) (writing took 2.8504585321061313 seconds)
2024-05-30 18:53:49 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2024-05-30 18:53:49 | INFO | train | epoch 029 | loss 3.434 | nll_loss 1.895 | ppl 3.72 | wps 17458.8 | ups 4.91 | wpb 3556.4 | bsz 141.6 | num_updates 32828 | lr 0.000174533 | gnorm 1.052 | train_wall 216 | wall 0
2024-05-30 18:53:49 | INFO | fairseq.trainer | begin training epoch 30
2024-05-30 18:54:03 | INFO | train_inner | epoch 030:     72 / 1132 loss=3.393, nll_loss=1.847, ppl=3.6, wps=13917.2, ups=3.89, wpb=3575, bsz=143, num_updates=32900, lr=0.000174342, gnorm=1.05, train_wall=19, wall=0
2024-05-30 18:54:22 | INFO | train_inner | epoch 030:    172 / 1132 loss=3.4, nll_loss=1.854, ppl=3.61, wps=18639.8, ups=5.26, wpb=3542.5, bsz=131, num_updates=33000, lr=0.000174078, gnorm=1.063, train_wall=19, wall=0
2024-05-30 18:54:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:54:25 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 3.92 | nll_loss 2.334 | ppl 5.04 | wps 55971.1 | wpb 2685.2 | bsz 107.1 | num_updates 33000 | best_loss 11.059
2024-05-30 18:54:25 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:54:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_30_33000.pt (epoch 30 @ 33000 updates, score 3.92) (writing took 3.3751785634085536 seconds)
2024-05-30 18:54:48 | INFO | train_inner | epoch 030:    272 / 1132 loss=3.421, nll_loss=1.877, ppl=3.67, wps=13759.1, ups=3.87, wpb=3557.6, bsz=131.4, num_updates=33100, lr=0.000173814, gnorm=1.075, train_wall=19, wall=0
2024-05-30 18:55:07 | INFO | train_inner | epoch 030:    372 / 1132 loss=3.357, nll_loss=1.808, ppl=3.5, wps=18519.9, ups=5.06, wpb=3660.4, bsz=177.7, num_updates=33200, lr=0.000173553, gnorm=0.989, train_wall=20, wall=0
2024-05-30 18:55:27 | INFO | train_inner | epoch 030:    472 / 1132 loss=3.407, nll_loss=1.865, ppl=3.64, wps=17812.5, ups=5.06, wpb=3519.4, bsz=134.6, num_updates=33300, lr=0.000173292, gnorm=1.065, train_wall=20, wall=0
2024-05-30 18:55:47 | INFO | train_inner | epoch 030:    572 / 1132 loss=3.407, nll_loss=1.863, ppl=3.64, wps=17949.9, ups=5.04, wpb=3562.2, bsz=140, num_updates=33400, lr=0.000173032, gnorm=1.049, train_wall=20, wall=0
2024-05-30 18:56:07 | INFO | train_inner | epoch 030:    672 / 1132 loss=3.42, nll_loss=1.879, ppl=3.68, wps=17591.2, ups=5.03, wpb=3496.2, bsz=140.2, num_updates=33500, lr=0.000172774, gnorm=1.072, train_wall=20, wall=0
2024-05-30 18:56:26 | INFO | train_inner | epoch 030:    772 / 1132 loss=3.462, nll_loss=1.925, ppl=3.8, wps=18513.3, ups=5.28, wpb=3506.2, bsz=123, num_updates=33600, lr=0.000172516, gnorm=1.079, train_wall=19, wall=0
2024-05-30 18:56:45 | INFO | train_inner | epoch 030:    872 / 1132 loss=3.411, nll_loss=1.87, ppl=3.66, wps=18563.2, ups=5.26, wpb=3530.5, bsz=156.2, num_updates=33700, lr=0.00017226, gnorm=1.051, train_wall=19, wall=0
2024-05-30 18:57:04 | INFO | train_inner | epoch 030:    972 / 1132 loss=3.459, nll_loss=1.921, ppl=3.79, wps=18704.9, ups=5.2, wpb=3596, bsz=132.9, num_updates=33800, lr=0.000172005, gnorm=1.062, train_wall=19, wall=0
2024-05-30 18:57:23 | INFO | train_inner | epoch 030:   1072 / 1132 loss=3.426, nll_loss=1.888, ppl=3.7, wps=18864.5, ups=5.24, wpb=3600.5, bsz=151.8, num_updates=33900, lr=0.000171751, gnorm=1.023, train_wall=19, wall=0
2024-05-30 18:57:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:57:38 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 3.915 | nll_loss 2.336 | ppl 5.05 | wps 56034.8 | wpb 2685.2 | bsz 107.1 | num_updates 33960 | best_loss 11.059
2024-05-30 18:57:38 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:57:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 30 @ 33960 updates, score 3.915) (writing took 2.487496556248516 seconds)
2024-05-30 18:57:40 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2024-05-30 18:57:40 | INFO | train | epoch 030 | loss 3.415 | nll_loss 1.873 | ppl 3.66 | wps 17386.8 | ups 4.89 | wpb 3556.4 | bsz 141.6 | num_updates 33960 | lr 0.0001716 | gnorm 1.054 | train_wall 217 | wall 0
2024-05-30 18:57:40 | INFO | fairseq.trainer | begin training epoch 31
2024-05-30 18:57:48 | INFO | train_inner | epoch 031:     40 / 1132 loss=3.41, nll_loss=1.867, ppl=3.65, wps=13843.4, ups=4.03, wpb=3438.4, bsz=136.2, num_updates=34000, lr=0.000171499, gnorm=1.091, train_wall=19, wall=0
2024-05-30 18:57:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 18:57:51 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 3.925 | nll_loss 2.339 | ppl 5.06 | wps 55561.4 | wpb 2685.2 | bsz 107.1 | num_updates 34000 | best_loss 11.059
2024-05-30 18:57:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 18:57:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_31_34000.pt (epoch 31 @ 34000 updates, score 3.925) (writing took 3.3436332349665463 seconds)
2024-05-30 18:58:14 | INFO | train_inner | epoch 031:    140 / 1132 loss=3.307, nll_loss=1.751, ppl=3.37, wps=13838.7, ups=3.87, wpb=3579.8, bsz=158.2, num_updates=34100, lr=0.000171247, gnorm=1.012, train_wall=19, wall=0
2024-05-30 18:58:33 | INFO | train_inner | epoch 031:    240 / 1132 loss=3.369, nll_loss=1.82, ppl=3.53, wps=18941.1, ups=5.26, wpb=3601.7, bsz=146.5, num_updates=34200, lr=0.000170996, gnorm=1.026, train_wall=19, wall=0
2024-05-30 18:58:52 | INFO | train_inner | epoch 031:    340 / 1132 loss=3.372, nll_loss=1.825, ppl=3.54, wps=18851.6, ups=5.25, wpb=3591.1, bsz=152.2, num_updates=34300, lr=0.000170747, gnorm=1.048, train_wall=19, wall=0
2024-05-30 18:59:11 | INFO | train_inner | epoch 031:    440 / 1132 loss=3.433, nll_loss=1.89, ppl=3.71, wps=18685.2, ups=5.22, wpb=3578.1, bsz=124.3, num_updates=34400, lr=0.000170499, gnorm=1.06, train_wall=19, wall=0
2024-05-30 18:59:30 | INFO | train_inner | epoch 031:    540 / 1132 loss=3.429, nll_loss=1.886, ppl=3.7, wps=18755.2, ups=5.22, wpb=3591.7, bsz=122.6, num_updates=34500, lr=0.000170251, gnorm=1.059, train_wall=19, wall=0
2024-05-30 18:59:48 | INFO | train_inner | epoch 031:    640 / 1132 loss=3.38, nll_loss=1.834, ppl=3.57, wps=19411.3, ups=5.5, wpb=3528.8, bsz=155.2, num_updates=34600, lr=0.000170005, gnorm=1.058, train_wall=18, wall=0
2024-05-30 19:00:07 | INFO | train_inner | epoch 031:    740 / 1132 loss=3.397, nll_loss=1.854, ppl=3.62, wps=19260.8, ups=5.49, wpb=3506.2, bsz=142.5, num_updates=34700, lr=0.00016976, gnorm=1.086, train_wall=18, wall=0
2024-05-30 19:00:26 | INFO | train_inner | epoch 031:    840 / 1132 loss=3.422, nll_loss=1.88, ppl=3.68, wps=18914.3, ups=5.28, wpb=3580.6, bsz=138.6, num_updates=34800, lr=0.000169516, gnorm=1.062, train_wall=19, wall=0
2024-05-30 19:00:45 | INFO | train_inner | epoch 031:    940 / 1132 loss=3.439, nll_loss=1.899, ppl=3.73, wps=18023.5, ups=5.12, wpb=3518.7, bsz=130.9, num_updates=34900, lr=0.000169273, gnorm=1.086, train_wall=19, wall=0
2024-05-30 19:01:05 | INFO | train_inner | epoch 031:   1040 / 1132 loss=3.445, nll_loss=1.907, ppl=3.75, wps=18063.7, ups=5.02, wpb=3596.8, bsz=134.4, num_updates=35000, lr=0.000169031, gnorm=1.053, train_wall=20, wall=0
2024-05-30 19:01:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:01:08 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 3.904 | nll_loss 2.328 | ppl 5.02 | wps 55758.5 | wpb 2685.2 | bsz 107.1 | num_updates 35000 | best_loss 11.059
2024-05-30 19:01:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:01:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_31_35000.pt (epoch 31 @ 35000 updates, score 3.904) (writing took 3.2775304010137916 seconds)
2024-05-30 19:01:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:01:32 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 3.901 | nll_loss 2.325 | ppl 5.01 | wps 56059 | wpb 2685.2 | bsz 107.1 | num_updates 35092 | best_loss 11.059
2024-05-30 19:01:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:01:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 31 @ 35092 updates, score 3.901) (writing took 2.8300147280097008 seconds)
2024-05-30 19:01:35 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2024-05-30 19:01:35 | INFO | train | epoch 031 | loss 3.397 | nll_loss 1.852 | ppl 3.61 | wps 17128.6 | ups 4.82 | wpb 3556.4 | bsz 141.6 | num_updates 35092 | lr 0.000168809 | gnorm 1.056 | train_wall 214 | wall 0
2024-05-30 19:01:35 | INFO | fairseq.trainer | begin training epoch 32
2024-05-30 19:01:37 | INFO | train_inner | epoch 032:      8 / 1132 loss=3.391, nll_loss=1.849, ppl=3.6, wps=11028.8, ups=3.12, wpb=3529.3, bsz=152.1, num_updates=35100, lr=0.00016879, gnorm=1.053, train_wall=19, wall=0
2024-05-30 19:01:56 | INFO | train_inner | epoch 032:    108 / 1132 loss=3.352, nll_loss=1.798, ppl=3.48, wps=18739.9, ups=5.22, wpb=3590.7, bsz=136.9, num_updates=35200, lr=0.00016855, gnorm=1.055, train_wall=19, wall=0
2024-05-30 19:02:15 | INFO | train_inner | epoch 032:    208 / 1132 loss=3.351, nll_loss=1.8, ppl=3.48, wps=18807.6, ups=5.28, wpb=3562.6, bsz=136.3, num_updates=35300, lr=0.000168311, gnorm=1.056, train_wall=19, wall=0
2024-05-30 19:02:34 | INFO | train_inner | epoch 032:    308 / 1132 loss=3.358, nll_loss=1.808, ppl=3.5, wps=18900, ups=5.22, wpb=3619.8, bsz=143, num_updates=35400, lr=0.000168073, gnorm=1.05, train_wall=19, wall=0
2024-05-30 19:02:53 | INFO | train_inner | epoch 032:    408 / 1132 loss=3.35, nll_loss=1.798, ppl=3.48, wps=18667.5, ups=5.3, wpb=3521.9, bsz=146.2, num_updates=35500, lr=0.000167836, gnorm=1.05, train_wall=19, wall=0
2024-05-30 19:03:12 | INFO | train_inner | epoch 032:    508 / 1132 loss=3.369, nll_loss=1.821, ppl=3.53, wps=18789.1, ups=5.31, wpb=3538.7, bsz=142.6, num_updates=35600, lr=0.0001676, gnorm=1.078, train_wall=19, wall=0
2024-05-30 19:03:31 | INFO | train_inner | epoch 032:    608 / 1132 loss=3.421, nll_loss=1.877, ppl=3.67, wps=18713.2, ups=5.26, wpb=3555, bsz=125.9, num_updates=35700, lr=0.000167365, gnorm=1.073, train_wall=19, wall=0
2024-05-30 19:03:50 | INFO | train_inner | epoch 032:    708 / 1132 loss=3.373, nll_loss=1.823, ppl=3.54, wps=18417.1, ups=5.24, wpb=3516.2, bsz=148.6, num_updates=35800, lr=0.000167132, gnorm=1.061, train_wall=19, wall=0
2024-05-30 19:04:09 | INFO | train_inner | epoch 032:    808 / 1132 loss=3.406, nll_loss=1.863, ppl=3.64, wps=18727.9, ups=5.3, wpb=3534.8, bsz=136.2, num_updates=35900, lr=0.000166899, gnorm=1.085, train_wall=19, wall=0
2024-05-30 19:04:27 | INFO | train_inner | epoch 032:    908 / 1132 loss=3.424, nll_loss=1.882, ppl=3.69, wps=19666.6, ups=5.48, wpb=3589.5, bsz=136.6, num_updates=36000, lr=0.000166667, gnorm=1.062, train_wall=18, wall=0
2024-05-30 19:04:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:04:31 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 3.906 | nll_loss 2.326 | ppl 5.02 | wps 56084.7 | wpb 2685.2 | bsz 107.1 | num_updates 36000 | best_loss 11.059
2024-05-30 19:04:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:04:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_32_36000.pt (epoch 32 @ 36000 updates, score 3.906) (writing took 3.522650274913758 seconds)
2024-05-30 19:04:55 | INFO | train_inner | epoch 032:   1008 / 1132 loss=3.4, nll_loss=1.858, ppl=3.62, wps=12541.1, ups=3.58, wpb=3500.1, bsz=146.2, num_updates=36100, lr=0.000166436, gnorm=1.095, train_wall=21, wall=0
2024-05-30 19:05:15 | INFO | train_inner | epoch 032:   1108 / 1132 loss=3.374, nll_loss=1.83, ppl=3.55, wps=18019, ups=5.01, wpb=3597.5, bsz=160, num_updates=36200, lr=0.000166206, gnorm=1.044, train_wall=20, wall=0
2024-05-30 19:05:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:05:23 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 3.893 | nll_loss 2.314 | ppl 4.97 | wps 56057.4 | wpb 2685.2 | bsz 107.1 | num_updates 36224 | best_loss 11.059
2024-05-30 19:05:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:05:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 32 @ 36224 updates, score 3.893) (writing took 2.739897376857698 seconds)
2024-05-30 19:05:26 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2024-05-30 19:05:26 | INFO | train | epoch 032 | loss 3.38 | nll_loss 1.833 | ppl 3.56 | wps 17472.2 | ups 4.91 | wpb 3556.4 | bsz 141.6 | num_updates 36224 | lr 0.000166151 | gnorm 1.064 | train_wall 215 | wall 0
2024-05-30 19:05:26 | INFO | fairseq.trainer | begin training epoch 33
2024-05-30 19:05:40 | INFO | train_inner | epoch 033:     76 / 1132 loss=3.345, nll_loss=1.793, ppl=3.46, wps=14215.2, ups=3.93, wpb=3613, bsz=133.9, num_updates=36300, lr=0.000165977, gnorm=1.017, train_wall=19, wall=0
2024-05-30 19:05:59 | INFO | train_inner | epoch 033:    176 / 1132 loss=3.323, nll_loss=1.769, ppl=3.41, wps=18912.9, ups=5.25, wpb=3599.2, bsz=145, num_updates=36400, lr=0.000165748, gnorm=1.044, train_wall=19, wall=0
2024-05-30 19:06:18 | INFO | train_inner | epoch 033:    276 / 1132 loss=3.322, nll_loss=1.766, ppl=3.4, wps=18626.9, ups=5.31, wpb=3508.7, bsz=145, num_updates=36500, lr=0.000165521, gnorm=1.061, train_wall=19, wall=0
2024-05-30 19:06:37 | INFO | train_inner | epoch 033:    376 / 1132 loss=3.384, nll_loss=1.836, ppl=3.57, wps=18850.8, ups=5.25, wpb=3588.6, bsz=129.3, num_updates=36600, lr=0.000165295, gnorm=1.063, train_wall=19, wall=0
2024-05-30 19:06:56 | INFO | train_inner | epoch 033:    476 / 1132 loss=3.356, nll_loss=1.803, ppl=3.49, wps=18375.4, ups=5.3, wpb=3465.2, bsz=140.2, num_updates=36700, lr=0.00016507, gnorm=1.103, train_wall=19, wall=0
2024-05-30 19:07:15 | INFO | train_inner | epoch 033:    576 / 1132 loss=3.375, nll_loss=1.826, ppl=3.54, wps=18551.8, ups=5.29, wpb=3509.7, bsz=128.5, num_updates=36800, lr=0.000164845, gnorm=1.069, train_wall=19, wall=0
2024-05-30 19:07:34 | INFO | train_inner | epoch 033:    676 / 1132 loss=3.373, nll_loss=1.826, ppl=3.54, wps=18721.6, ups=5.3, wpb=3531, bsz=139.8, num_updates=36900, lr=0.000164622, gnorm=1.101, train_wall=19, wall=0
2024-05-30 19:07:53 | INFO | train_inner | epoch 033:    776 / 1132 loss=3.359, nll_loss=1.81, ppl=3.51, wps=18801.8, ups=5.22, wpb=3602.7, bsz=157.7, num_updates=37000, lr=0.000164399, gnorm=1.057, train_wall=19, wall=0
2024-05-30 19:07:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:07:57 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 3.919 | nll_loss 2.329 | ppl 5.03 | wps 56055.9 | wpb 2685.2 | bsz 107.1 | num_updates 37000 | best_loss 11.059
2024-05-30 19:07:57 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:08:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_33_37000.pt (epoch 33 @ 37000 updates, score 3.919) (writing took 3.4352659373544157 seconds)
2024-05-30 19:08:19 | INFO | train_inner | epoch 033:    876 / 1132 loss=3.393, nll_loss=1.846, ppl=3.6, wps=13576.9, ups=3.84, wpb=3533.9, bsz=145.7, num_updates=37100, lr=0.000164177, gnorm=1.095, train_wall=19, wall=0
2024-05-30 19:08:38 | INFO | train_inner | epoch 033:    976 / 1132 loss=3.383, nll_loss=1.838, ppl=3.58, wps=19045.6, ups=5.2, wpb=3662.7, bsz=156.3, num_updates=37200, lr=0.000163956, gnorm=1.053, train_wall=19, wall=0
2024-05-30 19:08:57 | INFO | train_inner | epoch 033:   1076 / 1132 loss=3.399, nll_loss=1.856, ppl=3.62, wps=18800.5, ups=5.34, wpb=3523.3, bsz=131, num_updates=37300, lr=0.000163737, gnorm=1.082, train_wall=19, wall=0
2024-05-30 19:09:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:09:11 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 3.902 | nll_loss 2.319 | ppl 4.99 | wps 56218.4 | wpb 2685.2 | bsz 107.1 | num_updates 37356 | best_loss 11.059
2024-05-30 19:09:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:09:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 33 @ 37356 updates, score 3.902) (writing took 3.2450188673101366 seconds)
2024-05-30 19:09:14 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2024-05-30 19:09:14 | INFO | train | epoch 033 | loss 3.364 | nll_loss 1.815 | ppl 3.52 | wps 17598.5 | ups 4.95 | wpb 3556.4 | bsz 141.6 | num_updates 37356 | lr 0.000163614 | gnorm 1.069 | train_wall 213 | wall 0
2024-05-30 19:09:15 | INFO | fairseq.trainer | begin training epoch 34
2024-05-30 19:09:23 | INFO | train_inner | epoch 034:     44 / 1132 loss=3.337, nll_loss=1.784, ppl=3.44, wps=13560.8, ups=3.85, wpb=3526.6, bsz=151.2, num_updates=37400, lr=0.000163517, gnorm=1.067, train_wall=19, wall=0
2024-05-30 19:09:42 | INFO | train_inner | epoch 034:    144 / 1132 loss=3.306, nll_loss=1.748, ppl=3.36, wps=19069.7, ups=5.25, wpb=3632.6, bsz=144.9, num_updates=37500, lr=0.000163299, gnorm=1.036, train_wall=19, wall=0
2024-05-30 19:10:01 | INFO | train_inner | epoch 034:    244 / 1132 loss=3.309, nll_loss=1.754, ppl=3.37, wps=19195, ups=5.23, wpb=3670.8, bsz=155.5, num_updates=37600, lr=0.000163082, gnorm=1.035, train_wall=19, wall=0
2024-05-30 19:10:22 | INFO | train_inner | epoch 034:    344 / 1132 loss=3.328, nll_loss=1.772, ppl=3.42, wps=16676.7, ups=4.73, wpb=3522.4, bsz=145.5, num_updates=37700, lr=0.000162866, gnorm=1.066, train_wall=21, wall=0
2024-05-30 19:10:44 | INFO | train_inner | epoch 034:    444 / 1132 loss=3.336, nll_loss=1.781, ppl=3.44, wps=16629, ups=4.71, wpb=3530.9, bsz=138.5, num_updates=37800, lr=0.00016265, gnorm=1.071, train_wall=21, wall=0
2024-05-30 19:11:03 | INFO | train_inner | epoch 034:    544 / 1132 loss=3.399, nll_loss=1.851, ppl=3.61, wps=18144.9, ups=5.21, wpb=3481.9, bsz=114, num_updates=37900, lr=0.000162435, gnorm=1.111, train_wall=19, wall=0
2024-05-30 19:11:22 | INFO | train_inner | epoch 034:    644 / 1132 loss=3.328, nll_loss=1.774, ppl=3.42, wps=18619.3, ups=5.23, wpb=3560.8, bsz=153.5, num_updates=38000, lr=0.000162221, gnorm=1.058, train_wall=19, wall=0
2024-05-30 19:11:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:11:25 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 3.901 | nll_loss 2.322 | ppl 5 | wps 55860.4 | wpb 2685.2 | bsz 107.1 | num_updates 38000 | best_loss 11.059
2024-05-30 19:11:25 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:11:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_34_38000.pt (epoch 34 @ 38000 updates, score 3.901) (writing took 3.5687783281318843 seconds)
2024-05-30 19:11:50 | INFO | train_inner | epoch 034:    744 / 1132 loss=3.349, nll_loss=1.798, ppl=3.48, wps=12831.9, ups=3.57, wpb=3597.6, bsz=152.4, num_updates=38100, lr=0.000162008, gnorm=1.055, train_wall=21, wall=0
2024-05-30 19:12:11 | INFO | train_inner | epoch 034:    844 / 1132 loss=3.359, nll_loss=1.809, ppl=3.5, wps=16880, ups=4.74, wpb=3560, bsz=145, num_updates=38200, lr=0.000161796, gnorm=1.086, train_wall=21, wall=0
2024-05-30 19:12:30 | INFO | train_inner | epoch 034:    944 / 1132 loss=3.362, nll_loss=1.813, ppl=3.51, wps=18340, ups=5.27, wpb=3483.1, bsz=139.4, num_updates=38300, lr=0.000161585, gnorm=1.092, train_wall=19, wall=0
2024-05-30 19:12:49 | INFO | train_inner | epoch 034:   1044 / 1132 loss=3.385, nll_loss=1.839, ppl=3.58, wps=18787.9, ups=5.26, wpb=3570.2, bsz=134.5, num_updates=38400, lr=0.000161374, gnorm=1.062, train_wall=19, wall=0
2024-05-30 19:13:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:13:09 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 3.903 | nll_loss 2.325 | ppl 5.01 | wps 55948.7 | wpb 2685.2 | bsz 107.1 | num_updates 38488 | best_loss 11.059
2024-05-30 19:13:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:13:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 34 @ 38488 updates, score 3.903) (writing took 3.065299596171826 seconds)
2024-05-30 19:13:12 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2024-05-30 19:13:12 | INFO | train | epoch 034 | loss 3.348 | nll_loss 1.796 | ppl 3.47 | wps 16929.8 | ups 4.76 | wpb 3556.4 | bsz 141.6 | num_updates 38488 | lr 0.00016119 | gnorm 1.07 | train_wall 222 | wall 0
2024-05-30 19:13:12 | INFO | fairseq.trainer | begin training epoch 35
2024-05-30 19:13:15 | INFO | train_inner | epoch 035:     12 / 1132 loss=3.372, nll_loss=1.824, ppl=3.54, wps=13724.1, ups=3.9, wpb=3520.3, bsz=135, num_updates=38500, lr=0.000161165, gnorm=1.1, train_wall=19, wall=0
2024-05-30 19:13:36 | INFO | train_inner | epoch 035:    112 / 1132 loss=3.279, nll_loss=1.717, ppl=3.29, wps=17160.1, ups=4.83, wpb=3556.1, bsz=143.9, num_updates=38600, lr=0.000160956, gnorm=1.045, train_wall=21, wall=0
2024-05-30 19:13:55 | INFO | train_inner | epoch 035:    212 / 1132 loss=3.301, nll_loss=1.741, ppl=3.34, wps=18466.3, ups=5.25, wpb=3520.2, bsz=132.2, num_updates=38700, lr=0.000160748, gnorm=1.077, train_wall=19, wall=0
2024-05-30 19:14:14 | INFO | train_inner | epoch 035:    312 / 1132 loss=3.31, nll_loss=1.751, ppl=3.37, wps=18311, ups=5.24, wpb=3492.7, bsz=134, num_updates=38800, lr=0.00016054, gnorm=1.08, train_wall=19, wall=0
2024-05-30 19:14:33 | INFO | train_inner | epoch 035:    412 / 1132 loss=3.305, nll_loss=1.748, ppl=3.36, wps=18821.9, ups=5.2, wpb=3622.7, bsz=154.1, num_updates=38900, lr=0.000160334, gnorm=1.044, train_wall=19, wall=0
2024-05-30 19:14:52 | INFO | train_inner | epoch 035:    512 / 1132 loss=3.35, nll_loss=1.796, ppl=3.47, wps=18759.8, ups=5.27, wpb=3559.8, bsz=131.8, num_updates=39000, lr=0.000160128, gnorm=1.081, train_wall=19, wall=0
2024-05-30 19:14:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:14:55 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 3.908 | nll_loss 2.33 | ppl 5.03 | wps 55981.5 | wpb 2685.2 | bsz 107.1 | num_updates 39000 | best_loss 11.059
2024-05-30 19:14:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:14:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_35_39000.pt (epoch 35 @ 39000 updates, score 3.908) (writing took 3.5794952590949833 seconds)
2024-05-30 19:15:18 | INFO | train_inner | epoch 035:    612 / 1132 loss=3.358, nll_loss=1.809, ppl=3.5, wps=13833.4, ups=3.76, wpb=3681.6, bsz=149, num_updates=39100, lr=0.000159923, gnorm=1.052, train_wall=19, wall=0
2024-05-30 19:15:38 | INFO | train_inner | epoch 035:    712 / 1132 loss=3.328, nll_loss=1.774, ppl=3.42, wps=18535.3, ups=5.22, wpb=3549.6, bsz=149.2, num_updates=39200, lr=0.000159719, gnorm=1.06, train_wall=19, wall=0
2024-05-30 19:15:57 | INFO | train_inner | epoch 035:    812 / 1132 loss=3.322, nll_loss=1.767, ppl=3.4, wps=18500.5, ups=5.25, wpb=3524.2, bsz=164.7, num_updates=39300, lr=0.000159516, gnorm=1.088, train_wall=19, wall=0
2024-05-30 19:16:16 | INFO | train_inner | epoch 035:    912 / 1132 loss=3.35, nll_loss=1.798, ppl=3.48, wps=18605.7, ups=5.29, wpb=3518.2, bsz=136.6, num_updates=39400, lr=0.000159313, gnorm=1.109, train_wall=19, wall=0
2024-05-30 19:16:35 | INFO | train_inner | epoch 035:   1012 / 1132 loss=3.393, nll_loss=1.848, ppl=3.6, wps=19013.2, ups=5.22, wpb=3642.4, bsz=128.2, num_updates=39500, lr=0.000159111, gnorm=1.079, train_wall=19, wall=0
2024-05-30 19:16:53 | INFO | train_inner | epoch 035:   1112 / 1132 loss=3.367, nll_loss=1.818, ppl=3.53, wps=18522.1, ups=5.36, wpb=3456.6, bsz=131.8, num_updates=39600, lr=0.00015891, gnorm=1.118, train_wall=19, wall=0
2024-05-30 19:16:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:17:01 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 3.911 | nll_loss 2.327 | ppl 5.02 | wps 56162.7 | wpb 2685.2 | bsz 107.1 | num_updates 39620 | best_loss 11.059
2024-05-30 19:17:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:17:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 35 @ 39620 updates, score 3.911) (writing took 3.3916906933300197 seconds)
2024-05-30 19:17:04 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2024-05-30 19:17:04 | INFO | train | epoch 035 | loss 3.333 | nll_loss 1.779 | ppl 3.43 | wps 17368.9 | ups 4.88 | wpb 3556.4 | bsz 141.6 | num_updates 39620 | lr 0.00015887 | gnorm 1.077 | train_wall 216 | wall 0
2024-05-30 19:17:04 | INFO | fairseq.trainer | begin training epoch 36
2024-05-30 19:17:20 | INFO | train_inner | epoch 036:     80 / 1132 loss=3.321, nll_loss=1.762, ppl=3.39, wps=13705.3, ups=3.8, wpb=3606.4, bsz=136.3, num_updates=39700, lr=0.00015871, gnorm=1.052, train_wall=19, wall=0
2024-05-30 19:17:39 | INFO | train_inner | epoch 036:    180 / 1132 loss=3.281, nll_loss=1.717, ppl=3.29, wps=18502.9, ups=5.24, wpb=3530.2, bsz=145.8, num_updates=39800, lr=0.000158511, gnorm=1.077, train_wall=19, wall=0
2024-05-30 19:17:58 | INFO | train_inner | epoch 036:    280 / 1132 loss=3.259, nll_loss=1.695, ppl=3.24, wps=18794.3, ups=5.26, wpb=3570, bsz=158.4, num_updates=39900, lr=0.000158312, gnorm=1.05, train_wall=19, wall=0
2024-05-30 19:18:17 | INFO | train_inner | epoch 036:    380 / 1132 loss=3.303, nll_loss=1.745, ppl=3.35, wps=18745, ups=5.27, wpb=3559.4, bsz=142.6, num_updates=40000, lr=0.000158114, gnorm=1.084, train_wall=19, wall=0
2024-05-30 19:18:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:18:20 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 3.918 | nll_loss 2.332 | ppl 5.03 | wps 56199.4 | wpb 2685.2 | bsz 107.1 | num_updates 40000 | best_loss 11.059
2024-05-30 19:18:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:18:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_36_40000.pt (epoch 36 @ 40000 updates, score 3.918) (writing took 3.3630761709064245 seconds)
2024-05-30 19:18:42 | INFO | train_inner | epoch 036:    480 / 1132 loss=3.307, nll_loss=1.751, ppl=3.37, wps=13831.9, ups=3.9, wpb=3551.2, bsz=143.2, num_updates=40100, lr=0.000157917, gnorm=1.07, train_wall=19, wall=0
2024-05-30 19:19:01 | INFO | train_inner | epoch 036:    580 / 1132 loss=3.322, nll_loss=1.766, ppl=3.4, wps=18590.1, ups=5.28, wpb=3522.7, bsz=136.3, num_updates=40200, lr=0.00015772, gnorm=1.097, train_wall=19, wall=0
2024-05-30 19:19:21 | INFO | train_inner | epoch 036:    680 / 1132 loss=3.327, nll_loss=1.771, ppl=3.41, wps=18851.7, ups=5.23, wpb=3602.6, bsz=143.2, num_updates=40300, lr=0.000157524, gnorm=1.068, train_wall=19, wall=0
2024-05-30 19:19:39 | INFO | train_inner | epoch 036:    780 / 1132 loss=3.331, nll_loss=1.777, ppl=3.43, wps=18680.8, ups=5.3, wpb=3525.9, bsz=129.5, num_updates=40400, lr=0.000157329, gnorm=1.087, train_wall=19, wall=0
2024-05-30 19:19:59 | INFO | train_inner | epoch 036:    880 / 1132 loss=3.314, nll_loss=1.758, ppl=3.38, wps=18899.8, ups=5.22, wpb=3619.5, bsz=153.2, num_updates=40500, lr=0.000157135, gnorm=1.047, train_wall=19, wall=0
2024-05-30 19:20:18 | INFO | train_inner | epoch 036:    980 / 1132 loss=3.37, nll_loss=1.82, ppl=3.53, wps=18464.8, ups=5.25, wpb=3519.5, bsz=131.6, num_updates=40600, lr=0.000156941, gnorm=1.1, train_wall=19, wall=0
2024-05-30 19:20:37 | INFO | train_inner | epoch 036:   1080 / 1132 loss=3.366, nll_loss=1.817, ppl=3.52, wps=18488.9, ups=5.22, wpb=3543.1, bsz=139, num_updates=40700, lr=0.000156748, gnorm=1.116, train_wall=19, wall=0
2024-05-30 19:20:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:20:50 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 3.902 | nll_loss 2.322 | ppl 5 | wps 55976.4 | wpb 2685.2 | bsz 107.1 | num_updates 40752 | best_loss 11.059
2024-05-30 19:20:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:20:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 36 @ 40752 updates, score 3.902) (writing took 2.9000690006650984 seconds)
2024-05-30 19:20:53 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2024-05-30 19:20:53 | INFO | train | epoch 036 | loss 3.318 | nll_loss 1.762 | ppl 3.39 | wps 17593.7 | ups 4.95 | wpb 3556.4 | bsz 141.6 | num_updates 40752 | lr 0.000156648 | gnorm 1.078 | train_wall 214 | wall 0
2024-05-30 19:20:53 | INFO | fairseq.trainer | begin training epoch 37
2024-05-30 19:21:02 | INFO | train_inner | epoch 037:     48 / 1132 loss=3.319, nll_loss=1.761, ppl=3.39, wps=13816.5, ups=3.92, wpb=3528.8, bsz=137, num_updates=40800, lr=0.000156556, gnorm=1.099, train_wall=19, wall=0
2024-05-30 19:21:22 | INFO | train_inner | epoch 037:    148 / 1132 loss=3.243, nll_loss=1.677, ppl=3.2, wps=18656.4, ups=5.22, wpb=3576.3, bsz=150.6, num_updates=40900, lr=0.000156365, gnorm=1.064, train_wall=19, wall=0
2024-05-30 19:21:41 | INFO | train_inner | epoch 037:    248 / 1132 loss=3.26, nll_loss=1.697, ppl=3.24, wps=18935.1, ups=5.23, wpb=3617.3, bsz=154.9, num_updates=41000, lr=0.000156174, gnorm=1.055, train_wall=19, wall=0
2024-05-30 19:21:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:21:44 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 3.919 | nll_loss 2.338 | ppl 5.06 | wps 56012.6 | wpb 2685.2 | bsz 107.1 | num_updates 41000 | best_loss 11.059
2024-05-30 19:21:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:21:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_37_41000.pt (epoch 37 @ 41000 updates, score 3.919) (writing took 3.3998506041243672 seconds)
2024-05-30 19:22:07 | INFO | train_inner | epoch 037:    348 / 1132 loss=3.293, nll_loss=1.732, ppl=3.32, wps=13692.6, ups=3.84, wpb=3563.8, bsz=138.6, num_updates=41100, lr=0.000155984, gnorm=1.076, train_wall=19, wall=0
2024-05-30 19:22:26 | INFO | train_inner | epoch 037:    448 / 1132 loss=3.294, nll_loss=1.734, ppl=3.33, wps=18624.5, ups=5.25, wpb=3547.3, bsz=138.4, num_updates=41200, lr=0.000155794, gnorm=1.081, train_wall=19, wall=0
2024-05-30 19:22:45 | INFO | train_inner | epoch 037:    548 / 1132 loss=3.309, nll_loss=1.75, ppl=3.36, wps=18722, ups=5.21, wpb=3590.9, bsz=137.9, num_updates=41300, lr=0.000155606, gnorm=1.063, train_wall=19, wall=0
2024-05-30 19:23:04 | INFO | train_inner | epoch 037:    648 / 1132 loss=3.335, nll_loss=1.779, ppl=3.43, wps=18438.5, ups=5.25, wpb=3512.3, bsz=129.9, num_updates=41400, lr=0.000155417, gnorm=1.104, train_wall=19, wall=0
2024-05-30 19:23:23 | INFO | train_inner | epoch 037:    748 / 1132 loss=3.316, nll_loss=1.759, ppl=3.38, wps=18809.8, ups=5.31, wpb=3544.2, bsz=135, num_updates=41500, lr=0.00015523, gnorm=1.097, train_wall=19, wall=0
2024-05-30 19:23:42 | INFO | train_inner | epoch 037:    848 / 1132 loss=3.316, nll_loss=1.759, ppl=3.38, wps=18415.4, ups=5.22, wpb=3527.4, bsz=154.2, num_updates=41600, lr=0.000155043, gnorm=1.083, train_wall=19, wall=0
2024-05-30 19:24:01 | INFO | train_inner | epoch 037:    948 / 1132 loss=3.339, nll_loss=1.787, ppl=3.45, wps=18803.2, ups=5.29, wpb=3556.4, bsz=128.3, num_updates=41700, lr=0.000154857, gnorm=1.107, train_wall=19, wall=0
2024-05-30 19:24:20 | INFO | train_inner | epoch 037:   1048 / 1132 loss=3.345, nll_loss=1.79, ppl=3.46, wps=18417, ups=5.2, wpb=3544.9, bsz=140.7, num_updates=41800, lr=0.000154672, gnorm=1.112, train_wall=19, wall=0
2024-05-30 19:24:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:24:39 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 3.906 | nll_loss 2.327 | ppl 5.02 | wps 56218 | wpb 2685.2 | bsz 107.1 | num_updates 41884 | best_loss 11.059
2024-05-30 19:24:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:24:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 37 @ 41884 updates, score 3.906) (writing took 2.9307348849251866 seconds)
2024-05-30 19:24:42 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2024-05-30 19:24:42 | INFO | train | epoch 037 | loss 3.304 | nll_loss 1.746 | ppl 3.35 | wps 17562.9 | ups 4.94 | wpb 3556.4 | bsz 141.6 | num_updates 41884 | lr 0.000154517 | gnorm 1.085 | train_wall 214 | wall 0
2024-05-30 19:24:42 | INFO | fairseq.trainer | begin training epoch 38
2024-05-30 19:24:45 | INFO | train_inner | epoch 038:     16 / 1132 loss=3.311, nll_loss=1.757, ppl=3.38, wps=13986.1, ups=3.96, wpb=3535, bsz=143.2, num_updates=41900, lr=0.000154487, gnorm=1.101, train_wall=19, wall=0
2024-05-30 19:25:05 | INFO | train_inner | epoch 038:    116 / 1132 loss=3.232, nll_loss=1.662, ppl=3.16, wps=18283, ups=5.14, wpb=3557.7, bsz=149.2, num_updates=42000, lr=0.000154303, gnorm=1.07, train_wall=19, wall=0
2024-05-30 19:25:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:25:08 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 3.914 | nll_loss 2.328 | ppl 5.02 | wps 55961.5 | wpb 2685.2 | bsz 107.1 | num_updates 42000 | best_loss 11.059
2024-05-30 19:25:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:25:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_38_42000.pt (epoch 38 @ 42000 updates, score 3.914) (writing took 3.4293814380653203 seconds)
2024-05-30 19:25:31 | INFO | train_inner | epoch 038:    216 / 1132 loss=3.267, nll_loss=1.703, ppl=3.26, wps=13805.9, ups=3.86, wpb=3574.9, bsz=147.8, num_updates=42100, lr=0.00015412, gnorm=1.081, train_wall=19, wall=0
2024-05-30 19:25:50 | INFO | train_inner | epoch 038:    316 / 1132 loss=3.262, nll_loss=1.697, ppl=3.24, wps=18614.8, ups=5.31, wpb=3504.9, bsz=143.5, num_updates=42200, lr=0.000153937, gnorm=1.097, train_wall=19, wall=0
2024-05-30 19:26:08 | INFO | train_inner | epoch 038:    416 / 1132 loss=3.281, nll_loss=1.717, ppl=3.29, wps=18351.2, ups=5.33, wpb=3442.5, bsz=135.6, num_updates=42300, lr=0.000153755, gnorm=1.098, train_wall=19, wall=0
2024-05-30 19:26:27 | INFO | train_inner | epoch 038:    516 / 1132 loss=3.291, nll_loss=1.73, ppl=3.32, wps=18808.1, ups=5.22, wpb=3601.3, bsz=141, num_updates=42400, lr=0.000153574, gnorm=1.083, train_wall=19, wall=0
2024-05-30 19:26:47 | INFO | train_inner | epoch 038:    616 / 1132 loss=3.299, nll_loss=1.741, ppl=3.34, wps=19071.3, ups=5.2, wpb=3667.1, bsz=143.4, num_updates=42500, lr=0.000153393, gnorm=1.064, train_wall=19, wall=0
2024-05-30 19:27:06 | INFO | train_inner | epoch 038:    716 / 1132 loss=3.329, nll_loss=1.773, ppl=3.42, wps=18716, ups=5.2, wpb=3600.7, bsz=137, num_updates=42600, lr=0.000153213, gnorm=1.112, train_wall=19, wall=0
2024-05-30 19:27:25 | INFO | train_inner | epoch 038:    816 / 1132 loss=3.278, nll_loss=1.717, ppl=3.29, wps=18873.1, ups=5.22, wpb=3617, bsz=151.7, num_updates=42700, lr=0.000153033, gnorm=1.073, train_wall=19, wall=0
2024-05-30 19:27:44 | INFO | train_inner | epoch 038:    916 / 1132 loss=3.317, nll_loss=1.762, ppl=3.39, wps=18698.1, ups=5.3, wpb=3528, bsz=139.2, num_updates=42800, lr=0.000152854, gnorm=1.112, train_wall=19, wall=0
2024-05-30 19:28:03 | INFO | train_inner | epoch 038:   1016 / 1132 loss=3.325, nll_loss=1.77, ppl=3.41, wps=19108.5, ups=5.38, wpb=3550.7, bsz=137.2, num_updates=42900, lr=0.000152676, gnorm=1.103, train_wall=18, wall=0
2024-05-30 19:28:22 | INFO | train_inner | epoch 038:   1116 / 1132 loss=3.325, nll_loss=1.77, ppl=3.41, wps=17818.5, ups=5.12, wpb=3478.6, bsz=134.7, num_updates=43000, lr=0.000152499, gnorm=1.142, train_wall=19, wall=0
2024-05-30 19:28:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:28:25 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 3.905 | nll_loss 2.32 | ppl 4.99 | wps 55684.5 | wpb 2685.2 | bsz 107.1 | num_updates 43000 | best_loss 11.059
2024-05-30 19:28:25 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:28:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_38_43000.pt (epoch 38 @ 43000 updates, score 3.905) (writing took 3.330827913247049 seconds)
2024-05-30 19:28:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:28:35 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 3.908 | nll_loss 2.331 | ppl 5.03 | wps 55614.2 | wpb 2685.2 | bsz 107.1 | num_updates 43016 | best_loss 11.059
2024-05-30 19:28:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:28:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 38 @ 43016 updates, score 3.908) (writing took 2.828474707901478 seconds)
2024-05-30 19:28:38 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2024-05-30 19:28:38 | INFO | train | epoch 038 | loss 3.292 | nll_loss 1.731 | ppl 3.32 | wps 17054.3 | ups 4.8 | wpb 3556.4 | bsz 141.6 | num_updates 43016 | lr 0.00015247 | gnorm 1.094 | train_wall 214 | wall 0
2024-05-30 19:28:38 | INFO | fairseq.trainer | begin training epoch 39
2024-05-30 19:28:55 | INFO | train_inner | epoch 039:     84 / 1132 loss=3.269, nll_loss=1.702, ppl=3.25, wps=11006.9, ups=3.08, wpb=3576.5, bsz=139.8, num_updates=43100, lr=0.000152322, gnorm=1.102, train_wall=19, wall=0
2024-05-30 19:29:14 | INFO | train_inner | epoch 039:    184 / 1132 loss=3.218, nll_loss=1.648, ppl=3.13, wps=18698.1, ups=5.27, wpb=3547.8, bsz=156, num_updates=43200, lr=0.000152145, gnorm=1.051, train_wall=19, wall=0
2024-05-30 19:29:32 | INFO | train_inner | epoch 039:    284 / 1132 loss=3.247, nll_loss=1.679, ppl=3.2, wps=18716.9, ups=5.28, wpb=3542, bsz=140.9, num_updates=43300, lr=0.000151969, gnorm=1.082, train_wall=19, wall=0
2024-05-30 19:29:51 | INFO | train_inner | epoch 039:    384 / 1132 loss=3.254, nll_loss=1.69, ppl=3.23, wps=18754, ups=5.27, wpb=3559.4, bsz=147.7, num_updates=43400, lr=0.000151794, gnorm=1.078, train_wall=19, wall=0
2024-05-30 19:30:10 | INFO | train_inner | epoch 039:    484 / 1132 loss=3.267, nll_loss=1.705, ppl=3.26, wps=18850.9, ups=5.27, wpb=3578.5, bsz=142.1, num_updates=43500, lr=0.00015162, gnorm=1.077, train_wall=19, wall=0
2024-05-30 19:30:29 | INFO | train_inner | epoch 039:    584 / 1132 loss=3.264, nll_loss=1.7, ppl=3.25, wps=18792.1, ups=5.24, wpb=3584.6, bsz=144.6, num_updates=43600, lr=0.000151446, gnorm=1.081, train_wall=19, wall=0
2024-05-30 19:30:48 | INFO | train_inner | epoch 039:    684 / 1132 loss=3.286, nll_loss=1.725, ppl=3.31, wps=18731.5, ups=5.27, wpb=3557.3, bsz=140.2, num_updates=43700, lr=0.000151272, gnorm=1.094, train_wall=19, wall=0
2024-05-30 19:31:08 | INFO | train_inner | epoch 039:    784 / 1132 loss=3.297, nll_loss=1.737, ppl=3.33, wps=18558.6, ups=5.25, wpb=3532.8, bsz=136.5, num_updates=43800, lr=0.000151099, gnorm=1.107, train_wall=19, wall=0
2024-05-30 19:31:27 | INFO | train_inner | epoch 039:    884 / 1132 loss=3.313, nll_loss=1.756, ppl=3.38, wps=18623.6, ups=5.26, wpb=3539.7, bsz=136.2, num_updates=43900, lr=0.000150927, gnorm=1.107, train_wall=19, wall=0
2024-05-30 19:31:46 | INFO | train_inner | epoch 039:    984 / 1132 loss=3.315, nll_loss=1.757, ppl=3.38, wps=18559.1, ups=5.25, wpb=3536.7, bsz=136, num_updates=44000, lr=0.000150756, gnorm=1.122, train_wall=19, wall=0
2024-05-30 19:31:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:31:49 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 3.907 | nll_loss 2.323 | ppl 5 | wps 55977.5 | wpb 2685.2 | bsz 107.1 | num_updates 44000 | best_loss 11.059
2024-05-30 19:31:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:31:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_39_44000.pt (epoch 39 @ 44000 updates, score 3.907) (writing took 3.395302307792008 seconds)
2024-05-30 19:32:14 | INFO | train_inner | epoch 039:   1084 / 1132 loss=3.333, nll_loss=1.777, ppl=3.43, wps=12528, ups=3.55, wpb=3531.6, bsz=136.2, num_updates=44100, lr=0.000150585, gnorm=1.131, train_wall=21, wall=0
2024-05-30 19:32:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:32:26 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 3.901 | nll_loss 2.319 | ppl 4.99 | wps 55933.7 | wpb 2685.2 | bsz 107.1 | num_updates 44148 | best_loss 11.059
2024-05-30 19:32:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:32:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 39 @ 44148 updates, score 3.901) (writing took 2.8452307721599936 seconds)
2024-05-30 19:32:29 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2024-05-30 19:32:29 | INFO | train | epoch 039 | loss 3.279 | nll_loss 1.716 | ppl 3.29 | wps 17427.3 | ups 4.9 | wpb 3556.4 | bsz 141.6 | num_updates 44148 | lr 0.000150503 | gnorm 1.093 | train_wall 216 | wall 0
2024-05-30 19:32:29 | INFO | fairseq.trainer | begin training epoch 40
2024-05-30 19:32:39 | INFO | train_inner | epoch 040:     52 / 1132 loss=3.26, nll_loss=1.695, ppl=3.24, wps=14038, ups=3.89, wpb=3609.2, bsz=143.5, num_updates=44200, lr=0.000150414, gnorm=1.069, train_wall=19, wall=0
2024-05-30 19:32:58 | INFO | train_inner | epoch 040:    152 / 1132 loss=3.235, nll_loss=1.664, ppl=3.17, wps=19531.7, ups=5.51, wpb=3544.4, bsz=128.6, num_updates=44300, lr=0.000150244, gnorm=1.089, train_wall=18, wall=0
2024-05-30 19:33:16 | INFO | train_inner | epoch 040:    252 / 1132 loss=3.258, nll_loss=1.691, ppl=3.23, wps=20095.8, ups=5.51, wpb=3645.3, bsz=133.2, num_updates=44400, lr=0.000150075, gnorm=1.072, train_wall=18, wall=0
2024-05-30 19:33:34 | INFO | train_inner | epoch 040:    352 / 1132 loss=3.254, nll_loss=1.685, ppl=3.22, wps=18657.4, ups=5.4, wpb=3452.4, bsz=133.6, num_updates=44500, lr=0.000149906, gnorm=1.122, train_wall=18, wall=0
2024-05-30 19:33:55 | INFO | train_inner | epoch 040:    452 / 1132 loss=3.284, nll_loss=1.721, ppl=3.3, wps=17060.9, ups=4.75, wpb=3592.8, bsz=135.7, num_updates=44600, lr=0.000149738, gnorm=1.114, train_wall=21, wall=0
2024-05-30 19:34:15 | INFO | train_inner | epoch 040:    552 / 1132 loss=3.252, nll_loss=1.685, ppl=3.22, wps=17808.4, ups=5.08, wpb=3502.3, bsz=148.6, num_updates=44700, lr=0.000149571, gnorm=1.095, train_wall=20, wall=0
2024-05-30 19:34:34 | INFO | train_inner | epoch 040:    652 / 1132 loss=3.259, nll_loss=1.693, ppl=3.23, wps=18640.3, ups=5.3, wpb=3514.3, bsz=148.1, num_updates=44800, lr=0.000149404, gnorm=1.111, train_wall=19, wall=0
2024-05-30 19:34:53 | INFO | train_inner | epoch 040:    752 / 1132 loss=3.275, nll_loss=1.714, ppl=3.28, wps=18980.9, ups=5.2, wpb=3650.2, bsz=147.3, num_updates=44900, lr=0.000149237, gnorm=1.081, train_wall=19, wall=0
2024-05-30 19:35:13 | INFO | train_inner | epoch 040:    852 / 1132 loss=3.296, nll_loss=1.736, ppl=3.33, wps=17509, ups=5.01, wpb=3495, bsz=132.6, num_updates=45000, lr=0.000149071, gnorm=1.147, train_wall=20, wall=0
2024-05-30 19:35:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:35:16 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 3.904 | nll_loss 2.326 | ppl 5.01 | wps 55704.5 | wpb 2685.2 | bsz 107.1 | num_updates 45000 | best_loss 11.059
2024-05-30 19:35:16 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:35:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_40_45000.pt (epoch 40 @ 45000 updates, score 3.904) (writing took 3.3886839081533253 seconds)
2024-05-30 19:35:39 | INFO | train_inner | epoch 040:    952 / 1132 loss=3.282, nll_loss=1.721, ppl=3.3, wps=13838.7, ups=3.87, wpb=3578.9, bsz=146.4, num_updates=45100, lr=0.000148906, gnorm=1.08, train_wall=19, wall=0
2024-05-30 19:35:58 | INFO | train_inner | epoch 040:   1052 / 1132 loss=3.255, nll_loss=1.693, ppl=3.23, wps=18729.4, ups=5.28, wpb=3550.3, bsz=161.2, num_updates=45200, lr=0.000148741, gnorm=1.079, train_wall=19, wall=0
2024-05-30 19:36:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:36:17 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 3.909 | nll_loss 2.324 | ppl 5.01 | wps 55322.1 | wpb 2685.2 | bsz 107.1 | num_updates 45280 | best_loss 11.059
2024-05-30 19:36:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:36:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 40 @ 45280 updates, score 3.909) (writing took 3.1256526936776936 seconds)
2024-05-30 19:36:20 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2024-05-30 19:36:20 | INFO | train | epoch 040 | loss 3.265 | nll_loss 1.701 | ppl 3.25 | wps 17465.9 | ups 4.91 | wpb 3556.4 | bsz 141.6 | num_updates 45280 | lr 0.00014861 | gnorm 1.097 | train_wall 215 | wall 0
2024-05-30 19:36:20 | INFO | fairseq.trainer | begin training epoch 41
2024-05-30 19:36:24 | INFO | train_inner | epoch 041:     20 / 1132 loss=3.284, nll_loss=1.723, ppl=3.3, wps=13727.5, ups=3.86, wpb=3556.3, bsz=137.5, num_updates=45300, lr=0.000148577, gnorm=1.109, train_wall=19, wall=0
2024-05-30 19:36:43 | INFO | train_inner | epoch 041:    120 / 1132 loss=3.192, nll_loss=1.617, ppl=3.07, wps=18723.4, ups=5.17, wpb=3618.8, bsz=155.4, num_updates=45400, lr=0.000148413, gnorm=1.054, train_wall=19, wall=0
2024-05-30 19:37:02 | INFO | train_inner | epoch 041:    220 / 1132 loss=3.22, nll_loss=1.65, ppl=3.14, wps=18999.5, ups=5.21, wpb=3649.8, bsz=148.6, num_updates=45500, lr=0.00014825, gnorm=1.044, train_wall=19, wall=0
2024-05-30 19:37:22 | INFO | train_inner | epoch 041:    320 / 1132 loss=3.249, nll_loss=1.682, ppl=3.21, wps=18910.6, ups=5.21, wpb=3630.1, bsz=145.3, num_updates=45600, lr=0.000148087, gnorm=1.089, train_wall=19, wall=0
2024-05-30 19:37:40 | INFO | train_inner | epoch 041:    420 / 1132 loss=3.232, nll_loss=1.662, ppl=3.17, wps=18241, ups=5.27, wpb=3462.1, bsz=143.5, num_updates=45700, lr=0.000147925, gnorm=1.111, train_wall=19, wall=0
2024-05-30 19:38:00 | INFO | train_inner | epoch 041:    520 / 1132 loss=3.262, nll_loss=1.696, ppl=3.24, wps=18906.8, ups=5.24, wpb=3605, bsz=134.2, num_updates=45800, lr=0.000147764, gnorm=1.101, train_wall=19, wall=0
2024-05-30 19:38:19 | INFO | train_inner | epoch 041:    620 / 1132 loss=3.249, nll_loss=1.683, ppl=3.21, wps=18896.4, ups=5.25, wpb=3600.3, bsz=146.6, num_updates=45900, lr=0.000147602, gnorm=1.093, train_wall=19, wall=0
2024-05-30 19:38:38 | INFO | train_inner | epoch 041:    720 / 1132 loss=3.229, nll_loss=1.66, ppl=3.16, wps=18523.8, ups=5.24, wpb=3537.8, bsz=153.2, num_updates=46000, lr=0.000147442, gnorm=1.091, train_wall=19, wall=0
2024-05-30 19:38:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:38:41 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 3.915 | nll_loss 2.333 | ppl 5.04 | wps 55826.5 | wpb 2685.2 | bsz 107.1 | num_updates 46000 | best_loss 11.059
2024-05-30 19:38:41 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:38:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_41_46000.pt (epoch 41 @ 46000 updates, score 3.915) (writing took 3.421640877146274 seconds)
2024-05-30 19:39:04 | INFO | train_inner | epoch 041:    820 / 1132 loss=3.264, nll_loss=1.699, ppl=3.25, wps=13360.1, ups=3.87, wpb=3447.9, bsz=139.4, num_updates=46100, lr=0.000147282, gnorm=1.148, train_wall=19, wall=0
2024-05-30 19:39:22 | INFO | train_inner | epoch 041:    920 / 1132 loss=3.291, nll_loss=1.731, ppl=3.32, wps=18439.5, ups=5.31, wpb=3471.3, bsz=125, num_updates=46200, lr=0.000147122, gnorm=1.127, train_wall=19, wall=0
2024-05-30 19:39:41 | INFO | train_inner | epoch 041:   1020 / 1132 loss=3.301, nll_loss=1.74, ppl=3.34, wps=18662.5, ups=5.29, wpb=3527.6, bsz=127.2, num_updates=46300, lr=0.000146964, gnorm=1.127, train_wall=19, wall=0
2024-05-30 19:40:00 | INFO | train_inner | epoch 041:   1120 / 1132 loss=3.285, nll_loss=1.725, ppl=3.31, wps=18909.1, ups=5.24, wpb=3607.4, bsz=144.3, num_updates=46400, lr=0.000146805, gnorm=1.087, train_wall=19, wall=0
2024-05-30 19:40:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:40:06 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 3.916 | nll_loss 2.331 | ppl 5.03 | wps 55200.1 | wpb 2685.2 | bsz 107.1 | num_updates 46412 | best_loss 11.059
2024-05-30 19:40:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:40:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 41 @ 46412 updates, score 3.916) (writing took 3.0366949350573123 seconds)
2024-05-30 19:40:09 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2024-05-30 19:40:09 | INFO | train | epoch 041 | loss 3.252 | nll_loss 1.686 | ppl 3.22 | wps 17555.7 | ups 4.94 | wpb 3556.4 | bsz 141.6 | num_updates 46412 | lr 0.000146786 | gnorm 1.099 | train_wall 214 | wall 0
2024-05-30 19:40:09 | INFO | fairseq.trainer | begin training epoch 42
2024-05-30 19:40:26 | INFO | train_inner | epoch 042:     88 / 1132 loss=3.205, nll_loss=1.629, ppl=3.09, wps=13472.7, ups=3.87, wpb=3481.2, bsz=136.4, num_updates=46500, lr=0.000146647, gnorm=1.103, train_wall=19, wall=0
2024-05-30 19:40:46 | INFO | train_inner | epoch 042:    188 / 1132 loss=3.22, nll_loss=1.646, ppl=3.13, wps=17958.7, ups=5.03, wpb=3571, bsz=135.4, num_updates=46600, lr=0.00014649, gnorm=1.086, train_wall=20, wall=0
2024-05-30 19:41:06 | INFO | train_inner | epoch 042:    288 / 1132 loss=3.208, nll_loss=1.635, ppl=3.11, wps=17562.9, ups=4.9, wpb=3581.6, bsz=148.5, num_updates=46700, lr=0.000146333, gnorm=1.084, train_wall=20, wall=0
2024-05-30 19:41:26 | INFO | train_inner | epoch 042:    388 / 1132 loss=3.243, nll_loss=1.675, ppl=3.19, wps=17950.2, ups=5.11, wpb=3513.2, bsz=129.1, num_updates=46800, lr=0.000146176, gnorm=1.118, train_wall=19, wall=0
2024-05-30 19:41:45 | INFO | train_inner | epoch 042:    488 / 1132 loss=3.254, nll_loss=1.685, ppl=3.22, wps=18277.2, ups=5.21, wpb=3507.9, bsz=132.2, num_updates=46900, lr=0.00014602, gnorm=1.141, train_wall=19, wall=0
2024-05-30 19:42:04 | INFO | train_inner | epoch 042:    588 / 1132 loss=3.249, nll_loss=1.681, ppl=3.21, wps=18503.6, ups=5.22, wpb=3545.7, bsz=134.3, num_updates=47000, lr=0.000145865, gnorm=1.104, train_wall=19, wall=0
2024-05-30 19:42:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:42:08 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 3.924 | nll_loss 2.339 | ppl 5.06 | wps 55953.3 | wpb 2685.2 | bsz 107.1 | num_updates 47000 | best_loss 11.059
2024-05-30 19:42:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:42:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_42_47000.pt (epoch 42 @ 47000 updates, score 3.924) (writing took 3.6935340142808855 seconds)
2024-05-30 19:42:31 | INFO | train_inner | epoch 042:    688 / 1132 loss=3.249, nll_loss=1.682, ppl=3.21, wps=13397.3, ups=3.82, wpb=3505, bsz=137.4, num_updates=47100, lr=0.00014571, gnorm=1.122, train_wall=19, wall=0
2024-05-30 19:42:50 | INFO | train_inner | epoch 042:    788 / 1132 loss=3.238, nll_loss=1.671, ppl=3.18, wps=18644.1, ups=5.26, wpb=3546.7, bsz=152.3, num_updates=47200, lr=0.000145556, gnorm=1.095, train_wall=19, wall=0
2024-05-30 19:43:09 | INFO | train_inner | epoch 042:    888 / 1132 loss=3.254, nll_loss=1.69, ppl=3.23, wps=18906.6, ups=5.18, wpb=3650.2, bsz=154.4, num_updates=47300, lr=0.000145402, gnorm=1.083, train_wall=19, wall=0
2024-05-30 19:43:28 | INFO | train_inner | epoch 042:    988 / 1132 loss=3.25, nll_loss=1.685, ppl=3.22, wps=18774.6, ups=5.24, wpb=3580.6, bsz=153.1, num_updates=47400, lr=0.000145248, gnorm=1.093, train_wall=19, wall=0
2024-05-30 19:43:47 | INFO | train_inner | epoch 042:   1088 / 1132 loss=3.284, nll_loss=1.724, ppl=3.3, wps=18731.4, ups=5.26, wpb=3559.8, bsz=135.2, num_updates=47500, lr=0.000145095, gnorm=1.142, train_wall=19, wall=0
2024-05-30 19:43:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:43:59 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 3.903 | nll_loss 2.322 | ppl 5 | wps 56014.3 | wpb 2685.2 | bsz 107.1 | num_updates 47544 | best_loss 11.059
2024-05-30 19:43:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:44:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 42 @ 47544 updates, score 3.903) (writing took 3.0882378979586065 seconds)
2024-05-30 19:44:02 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2024-05-30 19:44:02 | INFO | train | epoch 042 | loss 3.241 | nll_loss 1.672 | ppl 3.19 | wps 17288.8 | ups 4.86 | wpb 3556.4 | bsz 141.6 | num_updates 47544 | lr 0.000145028 | gnorm 1.103 | train_wall 217 | wall 0
2024-05-30 19:44:02 | INFO | fairseq.trainer | begin training epoch 43
2024-05-30 19:44:13 | INFO | train_inner | epoch 043:     56 / 1132 loss=3.213, nll_loss=1.643, ppl=3.12, wps=14187.6, ups=3.86, wpb=3677.9, bsz=150.8, num_updates=47600, lr=0.000144943, gnorm=1.055, train_wall=19, wall=0
2024-05-30 19:44:32 | INFO | train_inner | epoch 043:    156 / 1132 loss=3.164, nll_loss=1.587, ppl=3, wps=18741.6, ups=5.22, wpb=3592.9, bsz=167.8, num_updates=47700, lr=0.000144791, gnorm=1.062, train_wall=19, wall=0
2024-05-30 19:44:51 | INFO | train_inner | epoch 043:    256 / 1132 loss=3.214, nll_loss=1.641, ppl=3.12, wps=18804.7, ups=5.27, wpb=3570.7, bsz=147.8, num_updates=47800, lr=0.000144639, gnorm=1.098, train_wall=19, wall=0
2024-05-30 19:45:10 | INFO | train_inner | epoch 043:    356 / 1132 loss=3.208, nll_loss=1.634, ppl=3.1, wps=18295.7, ups=5.27, wpb=3469, bsz=135.7, num_updates=47900, lr=0.000144488, gnorm=1.125, train_wall=19, wall=0
2024-05-30 19:45:30 | INFO | train_inner | epoch 043:    456 / 1132 loss=3.25, nll_loss=1.681, ppl=3.21, wps=17841.9, ups=5.01, wpb=3562.9, bsz=124.3, num_updates=48000, lr=0.000144338, gnorm=1.118, train_wall=20, wall=0
2024-05-30 19:45:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:45:33 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 3.922 | nll_loss 2.337 | ppl 5.05 | wps 55363.9 | wpb 2685.2 | bsz 107.1 | num_updates 48000 | best_loss 11.059
2024-05-30 19:45:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:45:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_43_48000.pt (epoch 43 @ 48000 updates, score 3.922) (writing took 3.469560951925814 seconds)
2024-05-30 19:45:56 | INFO | train_inner | epoch 043:    556 / 1132 loss=3.239, nll_loss=1.67, ppl=3.18, wps=13762, ups=3.82, wpb=3605.1, bsz=132.3, num_updates=48100, lr=0.000144187, gnorm=1.097, train_wall=19, wall=0
2024-05-30 19:46:15 | INFO | train_inner | epoch 043:    656 / 1132 loss=3.229, nll_loss=1.66, ppl=3.16, wps=18696, ups=5.17, wpb=3614.2, bsz=147.6, num_updates=48200, lr=0.000144038, gnorm=1.094, train_wall=19, wall=0
2024-05-30 19:46:34 | INFO | train_inner | epoch 043:    756 / 1132 loss=3.234, nll_loss=1.667, ppl=3.18, wps=18494.9, ups=5.31, wpb=3484.6, bsz=141.4, num_updates=48300, lr=0.000143889, gnorm=1.172, train_wall=19, wall=0
2024-05-30 19:46:53 | INFO | train_inner | epoch 043:    856 / 1132 loss=3.25, nll_loss=1.682, ppl=3.21, wps=18593, ups=5.28, wpb=3521.2, bsz=129.6, num_updates=48400, lr=0.00014374, gnorm=1.135, train_wall=19, wall=0
2024-05-30 19:47:12 | INFO | train_inner | epoch 043:    956 / 1132 loss=3.24, nll_loss=1.673, ppl=3.19, wps=18810.7, ups=5.26, wpb=3573.6, bsz=147.4, num_updates=48500, lr=0.000143592, gnorm=1.091, train_wall=19, wall=0
2024-05-30 19:47:30 | INFO | train_inner | epoch 043:   1056 / 1132 loss=3.272, nll_loss=1.706, ppl=3.26, wps=19177.6, ups=5.53, wpb=3467.5, bsz=130.2, num_updates=48600, lr=0.000143444, gnorm=1.155, train_wall=18, wall=0
2024-05-30 19:47:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:47:48 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 3.927 | nll_loss 2.35 | ppl 5.1 | wps 56016.7 | wpb 2685.2 | bsz 107.1 | num_updates 48676 | best_loss 11.059
2024-05-30 19:47:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:47:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 43 @ 48676 updates, score 3.927) (writing took 2.8724396019242704 seconds)
2024-05-30 19:47:50 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2024-05-30 19:47:50 | INFO | train | epoch 043 | loss 3.23 | nll_loss 1.66 | ppl 3.16 | wps 17613.6 | ups 4.95 | wpb 3556.4 | bsz 141.6 | num_updates 48676 | lr 0.000143332 | gnorm 1.111 | train_wall 214 | wall 0
2024-05-30 19:47:51 | INFO | fairseq.trainer | begin training epoch 44
2024-05-30 19:47:55 | INFO | train_inner | epoch 044:     24 / 1132 loss=3.237, nll_loss=1.669, ppl=3.18, wps=14268.1, ups=4.03, wpb=3543, bsz=141.8, num_updates=48700, lr=0.000143296, gnorm=1.119, train_wall=18, wall=0
2024-05-30 19:48:14 | INFO | train_inner | epoch 044:    124 / 1132 loss=3.189, nll_loss=1.61, ppl=3.05, wps=18683.8, ups=5.27, wpb=3547.8, bsz=141.9, num_updates=48800, lr=0.00014315, gnorm=1.112, train_wall=19, wall=0
2024-05-30 19:48:33 | INFO | train_inner | epoch 044:    224 / 1132 loss=3.201, nll_loss=1.625, ppl=3.08, wps=18582.1, ups=5.28, wpb=3519.9, bsz=137.5, num_updates=48900, lr=0.000143003, gnorm=1.1, train_wall=19, wall=0
2024-05-30 19:48:52 | INFO | train_inner | epoch 044:    324 / 1132 loss=3.168, nll_loss=1.593, ppl=3.02, wps=18954.1, ups=5.31, wpb=3572.5, bsz=156.6, num_updates=49000, lr=0.000142857, gnorm=1.073, train_wall=19, wall=0
2024-05-30 19:48:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:48:55 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 3.932 | nll_loss 2.35 | ppl 5.1 | wps 56033.9 | wpb 2685.2 | bsz 107.1 | num_updates 49000 | best_loss 11.059
2024-05-30 19:48:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:48:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_44_49000.pt (epoch 44 @ 49000 updates, score 3.932) (writing took 3.4111334499903023 seconds)
2024-05-30 19:49:18 | INFO | train_inner | epoch 044:    424 / 1132 loss=3.177, nll_loss=1.601, ppl=3.03, wps=13563.6, ups=3.87, wpb=3508.1, bsz=164.4, num_updates=49100, lr=0.000142712, gnorm=1.104, train_wall=19, wall=0
2024-05-30 19:49:37 | INFO | train_inner | epoch 044:    524 / 1132 loss=3.224, nll_loss=1.652, ppl=3.14, wps=18260.2, ups=5.11, wpb=3571.8, bsz=134.7, num_updates=49200, lr=0.000142566, gnorm=1.101, train_wall=19, wall=0
2024-05-30 19:49:57 | INFO | train_inner | epoch 044:    624 / 1132 loss=3.244, nll_loss=1.677, ppl=3.2, wps=18668.8, ups=5.16, wpb=3620.5, bsz=143.9, num_updates=49300, lr=0.000142422, gnorm=1.12, train_wall=19, wall=0
2024-05-30 19:50:16 | INFO | train_inner | epoch 044:    724 / 1132 loss=3.222, nll_loss=1.651, ppl=3.14, wps=18642.6, ups=5.14, wpb=3623.5, bsz=140.6, num_updates=49400, lr=0.000142278, gnorm=1.09, train_wall=19, wall=0
2024-05-30 19:50:35 | INFO | train_inner | epoch 044:    824 / 1132 loss=3.242, nll_loss=1.674, ppl=3.19, wps=18507.6, ups=5.23, wpb=3539.3, bsz=140.6, num_updates=49500, lr=0.000142134, gnorm=1.141, train_wall=19, wall=0
2024-05-30 19:50:54 | INFO | train_inner | epoch 044:    924 / 1132 loss=3.233, nll_loss=1.664, ppl=3.17, wps=18641.7, ups=5.29, wpb=3521.3, bsz=137.4, num_updates=49600, lr=0.00014199, gnorm=1.132, train_wall=19, wall=0
2024-05-30 19:51:14 | INFO | train_inner | epoch 044:   1024 / 1132 loss=3.263, nll_loss=1.697, ppl=3.24, wps=17725.1, ups=5, wpb=3545.1, bsz=135.3, num_updates=49700, lr=0.000141848, gnorm=1.149, train_wall=20, wall=0
2024-05-30 19:51:34 | INFO | train_inner | epoch 044:   1124 / 1132 loss=3.265, nll_loss=1.7, ppl=3.25, wps=18169.3, ups=5.06, wpb=3593.3, bsz=130.7, num_updates=49800, lr=0.000141705, gnorm=1.13, train_wall=20, wall=0
2024-05-30 19:51:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:51:39 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 3.908 | nll_loss 2.333 | ppl 5.04 | wps 55289.9 | wpb 2685.2 | bsz 107.1 | num_updates 49808 | best_loss 11.059
2024-05-30 19:51:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:51:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 44 @ 49808 updates, score 3.908) (writing took 2.9066401082091033 seconds)
2024-05-30 19:51:42 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2024-05-30 19:51:42 | INFO | train | epoch 044 | loss 3.22 | nll_loss 1.648 | ppl 3.13 | wps 17391.8 | ups 4.89 | wpb 3556.4 | bsz 141.6 | num_updates 49808 | lr 0.000141694 | gnorm 1.114 | train_wall 216 | wall 0
2024-05-30 19:51:42 | INFO | fairseq.trainer | begin training epoch 45
2024-05-30 19:52:00 | INFO | train_inner | epoch 045:     92 / 1132 loss=3.166, nll_loss=1.585, ppl=3, wps=13738.4, ups=3.85, wpb=3565.7, bsz=147.9, num_updates=49900, lr=0.000141563, gnorm=1.089, train_wall=19, wall=0
2024-05-30 19:52:19 | INFO | train_inner | epoch 045:    192 / 1132 loss=3.142, nll_loss=1.559, ppl=2.95, wps=18330.9, ups=5.22, wpb=3510.9, bsz=162.6, num_updates=50000, lr=0.000141421, gnorm=1.086, train_wall=19, wall=0
2024-05-30 19:52:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:52:23 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 3.933 | nll_loss 2.341 | ppl 5.07 | wps 56049 | wpb 2685.2 | bsz 107.1 | num_updates 50000 | best_loss 11.059
2024-05-30 19:52:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:52:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_45_50000.pt (epoch 45 @ 50000 updates, score 3.933) (writing took 3.4497490311041474 seconds)
2024-05-30 19:52:45 | INFO | train_inner | epoch 045:    292 / 1132 loss=3.18, nll_loss=1.603, ppl=3.04, wps=13836.3, ups=3.84, wpb=3605.4, bsz=151.2, num_updates=50100, lr=0.00014128, gnorm=1.086, train_wall=19, wall=0
2024-05-30 19:53:04 | INFO | train_inner | epoch 045:    392 / 1132 loss=3.207, nll_loss=1.633, ppl=3.1, wps=18855.2, ups=5.3, wpb=3558.4, bsz=124.5, num_updates=50200, lr=0.000141139, gnorm=1.117, train_wall=19, wall=0
2024-05-30 19:53:23 | INFO | train_inner | epoch 045:    492 / 1132 loss=3.2, nll_loss=1.626, ppl=3.09, wps=18986.2, ups=5.19, wpb=3654.8, bsz=154.2, num_updates=50300, lr=0.000140999, gnorm=1.074, train_wall=19, wall=0
2024-05-30 19:53:42 | INFO | train_inner | epoch 045:    592 / 1132 loss=3.199, nll_loss=1.625, ppl=3.08, wps=18735.2, ups=5.22, wpb=3585.7, bsz=153.9, num_updates=50400, lr=0.000140859, gnorm=1.113, train_wall=19, wall=0
2024-05-30 19:54:01 | INFO | train_inner | epoch 045:    692 / 1132 loss=3.204, nll_loss=1.631, ppl=3.1, wps=18697.9, ups=5.31, wpb=3522.4, bsz=139.3, num_updates=50500, lr=0.00014072, gnorm=1.115, train_wall=19, wall=0
2024-05-30 19:54:20 | INFO | train_inner | epoch 045:    792 / 1132 loss=3.223, nll_loss=1.653, ppl=3.15, wps=18633.7, ups=5.29, wpb=3524.1, bsz=139.9, num_updates=50600, lr=0.00014058, gnorm=1.149, train_wall=19, wall=0
2024-05-30 19:54:39 | INFO | train_inner | epoch 045:    892 / 1132 loss=3.244, nll_loss=1.676, ppl=3.2, wps=18907.8, ups=5.27, wpb=3584.5, bsz=132.2, num_updates=50700, lr=0.000140442, gnorm=1.122, train_wall=19, wall=0
2024-05-30 19:54:58 | INFO | train_inner | epoch 045:    992 / 1132 loss=3.252, nll_loss=1.684, ppl=3.21, wps=18494.6, ups=5.23, wpb=3534, bsz=131.3, num_updates=50800, lr=0.000140303, gnorm=1.155, train_wall=19, wall=0
2024-05-30 19:55:18 | INFO | train_inner | epoch 045:   1092 / 1132 loss=3.245, nll_loss=1.677, ppl=3.2, wps=17694.6, ups=5.07, wpb=3487.8, bsz=127.4, num_updates=50900, lr=0.000140165, gnorm=1.155, train_wall=20, wall=0
2024-05-30 19:55:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:55:29 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 3.908 | nll_loss 2.329 | ppl 5.02 | wps 55703 | wpb 2685.2 | bsz 107.1 | num_updates 50940 | best_loss 11.059
2024-05-30 19:55:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:55:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 45 @ 50940 updates, score 3.908) (writing took 2.8797563477419317 seconds)
2024-05-30 19:55:32 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2024-05-30 19:55:32 | INFO | train | epoch 045 | loss 3.208 | nll_loss 1.635 | ppl 3.11 | wps 17498.1 | ups 4.92 | wpb 3556.4 | bsz 141.6 | num_updates 50940 | lr 0.00014011 | gnorm 1.117 | train_wall 215 | wall 0
2024-05-30 19:55:32 | INFO | fairseq.trainer | begin training epoch 46
2024-05-30 19:55:44 | INFO | train_inner | epoch 046:     60 / 1132 loss=3.209, nll_loss=1.636, ppl=3.11, wps=13749.6, ups=3.91, wpb=3520.5, bsz=127, num_updates=51000, lr=0.000140028, gnorm=1.14, train_wall=19, wall=0
2024-05-30 19:55:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:55:47 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 3.93 | nll_loss 2.347 | ppl 5.09 | wps 55698.5 | wpb 2685.2 | bsz 107.1 | num_updates 51000 | best_loss 11.059
2024-05-30 19:55:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:55:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_46_51000.pt (epoch 46 @ 51000 updates, score 3.93) (writing took 3.3677065572701395 seconds)
2024-05-30 19:56:10 | INFO | train_inner | epoch 046:    160 / 1132 loss=3.158, nll_loss=1.576, ppl=2.98, wps=13791.4, ups=3.84, wpb=3594.2, bsz=151, num_updates=51100, lr=0.000139891, gnorm=1.097, train_wall=19, wall=0
2024-05-30 19:56:29 | INFO | train_inner | epoch 046:    260 / 1132 loss=3.178, nll_loss=1.6, ppl=3.03, wps=18815.3, ups=5.21, wpb=3614.3, bsz=139.6, num_updates=51200, lr=0.000139754, gnorm=1.117, train_wall=19, wall=0
2024-05-30 19:56:48 | INFO | train_inner | epoch 046:    360 / 1132 loss=3.194, nll_loss=1.618, ppl=3.07, wps=18672.8, ups=5.3, wpb=3523.8, bsz=129.8, num_updates=51300, lr=0.000139618, gnorm=1.133, train_wall=19, wall=0
2024-05-30 19:57:07 | INFO | train_inner | epoch 046:    460 / 1132 loss=3.188, nll_loss=1.613, ppl=3.06, wps=18772, ups=5.25, wpb=3573.2, bsz=135.1, num_updates=51400, lr=0.000139482, gnorm=1.108, train_wall=19, wall=0
2024-05-30 19:57:26 | INFO | train_inner | epoch 046:    560 / 1132 loss=3.199, nll_loss=1.622, ppl=3.08, wps=18615.2, ups=5.2, wpb=3578.1, bsz=139.5, num_updates=51500, lr=0.000139347, gnorm=1.105, train_wall=19, wall=0
2024-05-30 19:57:45 | INFO | train_inner | epoch 046:    660 / 1132 loss=3.206, nll_loss=1.633, ppl=3.1, wps=18777.8, ups=5.21, wpb=3604.4, bsz=153.2, num_updates=51600, lr=0.000139212, gnorm=1.114, train_wall=19, wall=0
2024-05-30 19:58:04 | INFO | train_inner | epoch 046:    760 / 1132 loss=3.208, nll_loss=1.636, ppl=3.11, wps=18691, ups=5.22, wpb=3577.4, bsz=146.8, num_updates=51700, lr=0.000139077, gnorm=1.096, train_wall=19, wall=0
2024-05-30 19:58:24 | INFO | train_inner | epoch 046:    860 / 1132 loss=3.223, nll_loss=1.65, ppl=3.14, wps=18490.2, ups=5.19, wpb=3561.5, bsz=140, num_updates=51800, lr=0.000138943, gnorm=1.142, train_wall=19, wall=0
2024-05-30 19:58:43 | INFO | train_inner | epoch 046:    960 / 1132 loss=3.181, nll_loss=1.609, ppl=3.05, wps=18621.7, ups=5.24, wpb=3553.3, bsz=168.6, num_updates=51900, lr=0.000138809, gnorm=1.114, train_wall=19, wall=0
2024-05-30 19:59:02 | INFO | train_inner | epoch 046:   1060 / 1132 loss=3.229, nll_loss=1.66, ppl=3.16, wps=18301.5, ups=5.26, wpb=3476.4, bsz=127.9, num_updates=52000, lr=0.000138675, gnorm=1.151, train_wall=19, wall=0
2024-05-30 19:59:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:59:05 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 3.912 | nll_loss 2.33 | ppl 5.03 | wps 55860.7 | wpb 2685.2 | bsz 107.1 | num_updates 52000 | best_loss 11.059
2024-05-30 19:59:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:59:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_46_52000.pt (epoch 46 @ 52000 updates, score 3.912) (writing took 3.252075908705592 seconds)
2024-05-30 19:59:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 19:59:26 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 3.911 | nll_loss 2.326 | ppl 5.01 | wps 55982.2 | wpb 2685.2 | bsz 107.1 | num_updates 52072 | best_loss 11.059
2024-05-30 19:59:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 19:59:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 46 @ 52072 updates, score 3.911) (writing took 2.714401374105364 seconds)
2024-05-30 19:59:28 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2024-05-30 19:59:28 | INFO | train | epoch 046 | loss 3.197 | nll_loss 1.622 | ppl 3.08 | wps 17041.5 | ups 4.79 | wpb 3556.4 | bsz 141.6 | num_updates 52072 | lr 0.000138579 | gnorm 1.12 | train_wall 215 | wall 0
2024-05-30 19:59:28 | INFO | fairseq.trainer | begin training epoch 47
2024-05-30 19:59:34 | INFO | train_inner | epoch 047:     28 / 1132 loss=3.204, nll_loss=1.628, ppl=3.09, wps=10568.6, ups=3.05, wpb=3465.9, bsz=138.6, num_updates=52100, lr=0.000138542, gnorm=1.148, train_wall=20, wall=0
2024-05-30 19:59:55 | INFO | train_inner | epoch 047:    128 / 1132 loss=3.14, nll_loss=1.556, ppl=2.94, wps=16891.2, ups=4.75, wpb=3553.1, bsz=138.5, num_updates=52200, lr=0.000138409, gnorm=1.106, train_wall=21, wall=0
2024-05-30 20:00:15 | INFO | train_inner | epoch 047:    228 / 1132 loss=3.178, nll_loss=1.598, ppl=3.03, wps=18253.2, ups=5.18, wpb=3523.9, bsz=132, num_updates=52300, lr=0.000138277, gnorm=1.137, train_wall=19, wall=0
2024-05-30 20:00:35 | INFO | train_inner | epoch 047:    328 / 1132 loss=3.169, nll_loss=1.589, ppl=3.01, wps=17381.6, ups=4.87, wpb=3570.2, bsz=143.7, num_updates=52400, lr=0.000138145, gnorm=1.114, train_wall=20, wall=0
2024-05-30 20:00:54 | INFO | train_inner | epoch 047:    428 / 1132 loss=3.156, nll_loss=1.577, ppl=2.98, wps=18682.1, ups=5.28, wpb=3535.4, bsz=154.5, num_updates=52500, lr=0.000138013, gnorm=1.124, train_wall=19, wall=0
2024-05-30 20:01:13 | INFO | train_inner | epoch 047:    528 / 1132 loss=3.188, nll_loss=1.611, ppl=3.06, wps=18593.8, ups=5.28, wpb=3520.3, bsz=138.5, num_updates=52600, lr=0.000137882, gnorm=1.152, train_wall=19, wall=0
2024-05-30 20:01:33 | INFO | train_inner | epoch 047:    628 / 1132 loss=3.216, nll_loss=1.643, ppl=3.12, wps=18472.1, ups=5.17, wpb=3573.9, bsz=131.8, num_updates=52700, lr=0.000137751, gnorm=1.137, train_wall=19, wall=0
2024-05-30 20:01:52 | INFO | train_inner | epoch 047:    728 / 1132 loss=3.183, nll_loss=1.607, ppl=3.05, wps=18988.6, ups=5.24, wpb=3624.9, bsz=152.7, num_updates=52800, lr=0.00013762, gnorm=1.114, train_wall=19, wall=0
2024-05-30 20:02:11 | INFO | train_inner | epoch 047:    828 / 1132 loss=3.21, nll_loss=1.636, ppl=3.11, wps=18638.7, ups=5.23, wpb=3567, bsz=141, num_updates=52900, lr=0.00013749, gnorm=1.142, train_wall=19, wall=0
2024-05-30 20:02:30 | INFO | train_inner | epoch 047:    928 / 1132 loss=3.2, nll_loss=1.626, ppl=3.09, wps=18696.2, ups=5.22, wpb=3581.8, bsz=143.5, num_updates=53000, lr=0.000137361, gnorm=1.122, train_wall=19, wall=0
2024-05-30 20:02:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:02:33 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 3.934 | nll_loss 2.351 | ppl 5.1 | wps 55489.1 | wpb 2685.2 | bsz 107.1 | num_updates 53000 | best_loss 11.059
2024-05-30 20:02:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:02:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_47_53000.pt (epoch 47 @ 53000 updates, score 3.934) (writing took 3.61517053283751 seconds)
2024-05-30 20:02:56 | INFO | train_inner | epoch 047:   1028 / 1132 loss=3.203, nll_loss=1.63, ppl=3.1, wps=13441.5, ups=3.85, wpb=3493.5, bsz=138.3, num_updates=53100, lr=0.000137231, gnorm=1.159, train_wall=19, wall=0
2024-05-30 20:03:15 | INFO | train_inner | epoch 047:   1128 / 1132 loss=3.23, nll_loss=1.66, ppl=3.16, wps=18901.2, ups=5.27, wpb=3589.7, bsz=140, num_updates=53200, lr=0.000137102, gnorm=1.116, train_wall=19, wall=0
2024-05-30 20:03:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:03:19 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 3.915 | nll_loss 2.339 | ppl 5.06 | wps 55828.5 | wpb 2685.2 | bsz 107.1 | num_updates 53204 | best_loss 11.059
2024-05-30 20:03:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:03:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 47 @ 53204 updates, score 3.915) (writing took 2.974190582986921 seconds)
2024-05-30 20:03:22 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2024-05-30 20:03:22 | INFO | train | epoch 047 | loss 3.188 | nll_loss 1.611 | ppl 3.06 | wps 17215.4 | ups 4.84 | wpb 3556.4 | bsz 141.6 | num_updates 53204 | lr 0.000137097 | gnorm 1.129 | train_wall 218 | wall 0
2024-05-30 20:03:22 | INFO | fairseq.trainer | begin training epoch 48
2024-05-30 20:03:41 | INFO | train_inner | epoch 048:     96 / 1132 loss=3.148, nll_loss=1.564, ppl=2.96, wps=13842.7, ups=3.88, wpb=3571.2, bsz=131.5, num_updates=53300, lr=0.000136973, gnorm=1.096, train_wall=19, wall=0
2024-05-30 20:03:59 | INFO | train_inner | epoch 048:    196 / 1132 loss=3.144, nll_loss=1.561, ppl=2.95, wps=19512.3, ups=5.46, wpb=3574.9, bsz=153.4, num_updates=53400, lr=0.000136845, gnorm=1.112, train_wall=18, wall=0
2024-05-30 20:04:17 | INFO | train_inner | epoch 048:    296 / 1132 loss=3.173, nll_loss=1.594, ppl=3.02, wps=19763.1, ups=5.48, wpb=3606, bsz=137.4, num_updates=53500, lr=0.000136717, gnorm=1.115, train_wall=18, wall=0
2024-05-30 20:04:37 | INFO | train_inner | epoch 048:    396 / 1132 loss=3.174, nll_loss=1.595, ppl=3.02, wps=18221, ups=5.16, wpb=3534.4, bsz=138.6, num_updates=53600, lr=0.00013659, gnorm=1.128, train_wall=19, wall=0
2024-05-30 20:04:56 | INFO | train_inner | epoch 048:    496 / 1132 loss=3.173, nll_loss=1.593, ppl=3.02, wps=18263, ups=5.28, wpb=3459, bsz=131.3, num_updates=53700, lr=0.000136462, gnorm=1.162, train_wall=19, wall=0
2024-05-30 20:05:15 | INFO | train_inner | epoch 048:    596 / 1132 loss=3.185, nll_loss=1.608, ppl=3.05, wps=18666.2, ups=5.22, wpb=3578.6, bsz=138.9, num_updates=53800, lr=0.000136335, gnorm=1.14, train_wall=19, wall=0
2024-05-30 20:05:35 | INFO | train_inner | epoch 048:    696 / 1132 loss=3.177, nll_loss=1.599, ppl=3.03, wps=17930.1, ups=5.05, wpb=3551.6, bsz=140, num_updates=53900, lr=0.000136209, gnorm=1.135, train_wall=20, wall=0
2024-05-30 20:05:54 | INFO | train_inner | epoch 048:    796 / 1132 loss=3.215, nll_loss=1.642, ppl=3.12, wps=18774, ups=5.24, wpb=3583.1, bsz=131.5, num_updates=54000, lr=0.000136083, gnorm=1.146, train_wall=19, wall=0
2024-05-30 20:05:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:05:57 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 3.931 | nll_loss 2.346 | ppl 5.08 | wps 55802.9 | wpb 2685.2 | bsz 107.1 | num_updates 54000 | best_loss 11.059
2024-05-30 20:05:57 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:06:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_48_54000.pt (epoch 48 @ 54000 updates, score 3.931) (writing took 3.5556007870472968 seconds)
2024-05-30 20:06:20 | INFO | train_inner | epoch 048:    896 / 1132 loss=3.196, nll_loss=1.623, ppl=3.08, wps=13527.1, ups=3.86, wpb=3505.7, bsz=132.6, num_updates=54100, lr=0.000135957, gnorm=1.161, train_wall=19, wall=0
2024-05-30 20:06:39 | INFO | train_inner | epoch 048:    996 / 1132 loss=3.171, nll_loss=1.595, ppl=3.02, wps=18675.6, ups=5.21, wpb=3587.6, bsz=161.1, num_updates=54200, lr=0.000135831, gnorm=1.11, train_wall=19, wall=0
2024-05-30 20:06:58 | INFO | train_inner | epoch 048:   1096 / 1132 loss=3.19, nll_loss=1.614, ppl=3.06, wps=18495.6, ups=5.22, wpb=3543.2, bsz=156.4, num_updates=54300, lr=0.000135706, gnorm=1.129, train_wall=19, wall=0
2024-05-30 20:07:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:07:08 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 3.917 | nll_loss 2.336 | ppl 5.05 | wps 55873.3 | wpb 2685.2 | bsz 107.1 | num_updates 54336 | best_loss 11.059
2024-05-30 20:07:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:07:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 48 @ 54336 updates, score 3.917) (writing took 2.8984180432744324 seconds)
2024-05-30 20:07:11 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2024-05-30 20:07:11 | INFO | train | epoch 048 | loss 3.178 | nll_loss 1.6 | ppl 3.03 | wps 17566.1 | ups 4.94 | wpb 3556.4 | bsz 141.6 | num_updates 54336 | lr 0.000135661 | gnorm 1.129 | train_wall 214 | wall 0
2024-05-30 20:07:11 | INFO | fairseq.trainer | begin training epoch 49
2024-05-30 20:07:24 | INFO | train_inner | epoch 049:     64 / 1132 loss=3.159, nll_loss=1.579, ppl=2.99, wps=13791.4, ups=3.88, wpb=3551.3, bsz=145.8, num_updates=54400, lr=0.000135582, gnorm=1.133, train_wall=19, wall=0
2024-05-30 20:07:43 | INFO | train_inner | epoch 049:    164 / 1132 loss=3.133, nll_loss=1.546, ppl=2.92, wps=18328.8, ups=5.2, wpb=3524, bsz=142.2, num_updates=54500, lr=0.000135457, gnorm=1.117, train_wall=19, wall=0
2024-05-30 20:08:02 | INFO | train_inner | epoch 049:    264 / 1132 loss=3.141, nll_loss=1.557, ppl=2.94, wps=18483.5, ups=5.25, wpb=3523.4, bsz=142.2, num_updates=54600, lr=0.000135333, gnorm=1.128, train_wall=19, wall=0
2024-05-30 20:08:21 | INFO | train_inner | epoch 049:    364 / 1132 loss=3.149, nll_loss=1.568, ppl=2.96, wps=19082.1, ups=5.22, wpb=3652.1, bsz=147, num_updates=54700, lr=0.000135209, gnorm=1.088, train_wall=19, wall=0
2024-05-30 20:08:40 | INFO | train_inner | epoch 049:    464 / 1132 loss=3.159, nll_loss=1.578, ppl=2.99, wps=18684.6, ups=5.21, wpb=3582.9, bsz=141.5, num_updates=54800, lr=0.000135086, gnorm=1.108, train_wall=19, wall=0
2024-05-30 20:08:59 | INFO | train_inner | epoch 049:    564 / 1132 loss=3.17, nll_loss=1.591, ppl=3.01, wps=18702.4, ups=5.23, wpb=3578.2, bsz=149, num_updates=54900, lr=0.000134963, gnorm=1.122, train_wall=19, wall=0
2024-05-30 20:09:18 | INFO | train_inner | epoch 049:    664 / 1132 loss=3.157, nll_loss=1.577, ppl=2.98, wps=18701.8, ups=5.26, wpb=3556.4, bsz=141.8, num_updates=55000, lr=0.00013484, gnorm=1.126, train_wall=19, wall=0
2024-05-30 20:09:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:09:22 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 3.923 | nll_loss 2.343 | ppl 5.07 | wps 55871.8 | wpb 2685.2 | bsz 107.1 | num_updates 55000 | best_loss 11.059
2024-05-30 20:09:22 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:09:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_49_55000.pt (epoch 49 @ 55000 updates, score 3.923) (writing took 3.4154258482158184 seconds)
2024-05-30 20:09:44 | INFO | train_inner | epoch 049:    764 / 1132 loss=3.209, nll_loss=1.635, ppl=3.11, wps=13822.4, ups=3.87, wpb=3574.8, bsz=127.4, num_updates=55100, lr=0.000134718, gnorm=1.167, train_wall=19, wall=0
2024-05-30 20:10:03 | INFO | train_inner | epoch 049:    864 / 1132 loss=3.198, nll_loss=1.623, ppl=3.08, wps=18460.6, ups=5.28, wpb=3496.4, bsz=134.6, num_updates=55200, lr=0.000134595, gnorm=1.159, train_wall=19, wall=0
2024-05-30 20:10:23 | INFO | train_inner | epoch 049:    964 / 1132 loss=3.187, nll_loss=1.612, ppl=3.06, wps=18741.6, ups=5.18, wpb=3617, bsz=138.2, num_updates=55300, lr=0.000134474, gnorm=1.114, train_wall=19, wall=0
2024-05-30 20:10:42 | INFO | train_inner | epoch 049:   1064 / 1132 loss=3.199, nll_loss=1.625, ppl=3.08, wps=18311.8, ups=5.27, wpb=3475.7, bsz=135.1, num_updates=55400, lr=0.000134352, gnorm=1.203, train_wall=19, wall=0
2024-05-30 20:10:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:10:58 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 3.928 | nll_loss 2.341 | ppl 5.06 | wps 55707.9 | wpb 2685.2 | bsz 107.1 | num_updates 55468 | best_loss 11.059
2024-05-30 20:10:58 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:11:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 49 @ 55468 updates, score 3.928) (writing took 2.9114237902686 seconds)
2024-05-30 20:11:01 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2024-05-30 20:11:01 | INFO | train | epoch 049 | loss 3.167 | nll_loss 1.588 | ppl 3.01 | wps 17522.3 | ups 4.93 | wpb 3556.4 | bsz 141.6 | num_updates 55468 | lr 0.00013427 | gnorm 1.134 | train_wall 215 | wall 0
2024-05-30 20:11:01 | INFO | fairseq.trainer | begin training epoch 50
2024-05-30 20:11:07 | INFO | train_inner | epoch 050:     32 / 1132 loss=3.152, nll_loss=1.571, ppl=2.97, wps=13699.3, ups=3.9, wpb=3514.7, bsz=153.2, num_updates=55500, lr=0.000134231, gnorm=1.186, train_wall=19, wall=0
2024-05-30 20:11:26 | INFO | train_inner | epoch 050:    132 / 1132 loss=3.134, nll_loss=1.549, ppl=2.93, wps=18386, ups=5.2, wpb=3535.8, bsz=136.9, num_updates=55600, lr=0.00013411, gnorm=1.124, train_wall=19, wall=0
2024-05-30 20:11:45 | INFO | train_inner | epoch 050:    232 / 1132 loss=3.115, nll_loss=1.529, ppl=2.89, wps=18459.8, ups=5.28, wpb=3498.8, bsz=144, num_updates=55700, lr=0.00013399, gnorm=1.133, train_wall=19, wall=0
2024-05-30 20:12:04 | INFO | train_inner | epoch 050:    332 / 1132 loss=3.149, nll_loss=1.566, ppl=2.96, wps=18740.8, ups=5.26, wpb=3560.2, bsz=143.4, num_updates=55800, lr=0.00013387, gnorm=1.158, train_wall=19, wall=0
2024-05-30 20:12:24 | INFO | train_inner | epoch 050:    432 / 1132 loss=3.168, nll_loss=1.587, ppl=3, wps=18616.3, ups=5.17, wpb=3598.9, bsz=129.6, num_updates=55900, lr=0.00013375, gnorm=1.136, train_wall=19, wall=0
2024-05-30 20:12:43 | INFO | train_inner | epoch 050:    532 / 1132 loss=3.167, nll_loss=1.584, ppl=3, wps=18393.9, ups=5.25, wpb=3501.2, bsz=134.8, num_updates=56000, lr=0.000133631, gnorm=1.18, train_wall=19, wall=0
2024-05-30 20:12:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:12:46 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 3.933 | nll_loss 2.357 | ppl 5.12 | wps 55737.9 | wpb 2685.2 | bsz 107.1 | num_updates 56000 | best_loss 11.059
2024-05-30 20:12:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:12:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_50_56000.pt (epoch 50 @ 56000 updates, score 3.933) (writing took 3.7585439272224903 seconds)
2024-05-30 20:13:10 | INFO | train_inner | epoch 050:    632 / 1132 loss=3.155, nll_loss=1.573, ppl=2.98, wps=13076.3, ups=3.65, wpb=3578.2, bsz=151.8, num_updates=56100, lr=0.000133511, gnorm=1.114, train_wall=20, wall=0
2024-05-30 20:13:29 | INFO | train_inner | epoch 050:    732 / 1132 loss=3.161, nll_loss=1.581, ppl=2.99, wps=18777.7, ups=5.21, wpb=3601.3, bsz=149.9, num_updates=56200, lr=0.000133393, gnorm=1.129, train_wall=19, wall=0
2024-05-30 20:13:48 | INFO | train_inner | epoch 050:    832 / 1132 loss=3.165, nll_loss=1.587, ppl=3, wps=19810.2, ups=5.49, wpb=3607.4, bsz=151.2, num_updates=56300, lr=0.000133274, gnorm=1.12, train_wall=18, wall=0
2024-05-30 20:14:06 | INFO | train_inner | epoch 050:    932 / 1132 loss=3.166, nll_loss=1.59, ppl=3.01, wps=19781.9, ups=5.45, wpb=3626.6, bsz=156.2, num_updates=56400, lr=0.000133156, gnorm=1.11, train_wall=18, wall=0
2024-05-30 20:14:24 | INFO | train_inner | epoch 050:   1032 / 1132 loss=3.185, nll_loss=1.609, ppl=3.05, wps=19600.3, ups=5.52, wpb=3553, bsz=134.1, num_updates=56500, lr=0.000133038, gnorm=1.134, train_wall=18, wall=0
2024-05-30 20:14:42 | INFO | train_inner | epoch 050:   1132 / 1132 loss=3.208, nll_loss=1.634, ppl=3.1, wps=19472.6, ups=5.52, wpb=3526.1, bsz=128.8, num_updates=56600, lr=0.00013292, gnorm=1.169, train_wall=18, wall=0
2024-05-30 20:14:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:14:45 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 3.91 | nll_loss 2.334 | ppl 5.04 | wps 55954.8 | wpb 2685.2 | bsz 107.1 | num_updates 56600 | best_loss 11.059
2024-05-30 20:14:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:14:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 50 @ 56600 updates, score 3.91) (writing took 3.2013453720137477 seconds)
2024-05-30 20:14:49 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2024-05-30 20:14:49 | INFO | train | epoch 050 | loss 3.16 | nll_loss 1.579 | ppl 2.99 | wps 17683.6 | ups 4.97 | wpb 3556.4 | bsz 141.6 | num_updates 56600 | lr 0.00013292 | gnorm 1.142 | train_wall 212 | wall 0
2024-05-30 20:14:49 | INFO | fairseq.trainer | begin training epoch 51
2024-05-30 20:15:08 | INFO | train_inner | epoch 051:    100 / 1132 loss=3.101, nll_loss=1.512, ppl=2.85, wps=13346.9, ups=3.82, wpb=3496.4, bsz=146.4, num_updates=56700, lr=0.000132803, gnorm=1.152, train_wall=19, wall=0
2024-05-30 20:15:27 | INFO | train_inner | epoch 051:    200 / 1132 loss=3.097, nll_loss=1.507, ppl=2.84, wps=18216.7, ups=5.2, wpb=3501.2, bsz=156.7, num_updates=56800, lr=0.000132686, gnorm=1.131, train_wall=19, wall=0
2024-05-30 20:15:47 | INFO | train_inner | epoch 051:    300 / 1132 loss=3.124, nll_loss=1.536, ppl=2.9, wps=18605.3, ups=5.2, wpb=3577.6, bsz=139.7, num_updates=56900, lr=0.00013257, gnorm=1.124, train_wall=19, wall=0
2024-05-30 20:16:06 | INFO | train_inner | epoch 051:    400 / 1132 loss=3.119, nll_loss=1.534, ppl=2.9, wps=18751.9, ups=5.28, wpb=3548.4, bsz=152.3, num_updates=57000, lr=0.000132453, gnorm=1.115, train_wall=19, wall=0
2024-05-30 20:16:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:16:09 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 3.935 | nll_loss 2.356 | ppl 5.12 | wps 55940 | wpb 2685.2 | bsz 107.1 | num_updates 57000 | best_loss 11.059
2024-05-30 20:16:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:16:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_51_57000.pt (epoch 51 @ 57000 updates, score 3.935) (writing took 3.64793011918664 seconds)
2024-05-30 20:16:32 | INFO | train_inner | epoch 051:    500 / 1132 loss=3.167, nll_loss=1.586, ppl=3, wps=13519.9, ups=3.82, wpb=3538.9, bsz=129.8, num_updates=57100, lr=0.000132337, gnorm=1.159, train_wall=19, wall=0
2024-05-30 20:16:51 | INFO | train_inner | epoch 051:    600 / 1132 loss=3.156, nll_loss=1.576, ppl=2.98, wps=18810.2, ups=5.23, wpb=3594.7, bsz=136.6, num_updates=57200, lr=0.000132221, gnorm=1.125, train_wall=19, wall=0
2024-05-30 20:17:10 | INFO | train_inner | epoch 051:    700 / 1132 loss=3.15, nll_loss=1.569, ppl=2.97, wps=18800.1, ups=5.23, wpb=3591.8, bsz=149.6, num_updates=57300, lr=0.000132106, gnorm=1.139, train_wall=19, wall=0
2024-05-30 20:17:29 | INFO | train_inner | epoch 051:    800 / 1132 loss=3.181, nll_loss=1.603, ppl=3.04, wps=18719.1, ups=5.26, wpb=3560.6, bsz=129.4, num_updates=57400, lr=0.000131991, gnorm=1.159, train_wall=19, wall=0
2024-05-30 20:17:48 | INFO | train_inner | epoch 051:    900 / 1132 loss=3.177, nll_loss=1.599, ppl=3.03, wps=18733.9, ups=5.24, wpb=3574.1, bsz=140.4, num_updates=57500, lr=0.000131876, gnorm=1.156, train_wall=19, wall=0
2024-05-30 20:18:07 | INFO | train_inner | epoch 051:   1000 / 1132 loss=3.169, nll_loss=1.589, ppl=3.01, wps=18686.8, ups=5.2, wpb=3592.9, bsz=152, num_updates=57600, lr=0.000131762, gnorm=1.134, train_wall=19, wall=0
2024-05-30 20:18:26 | INFO | train_inner | epoch 051:   1100 / 1132 loss=3.183, nll_loss=1.607, ppl=3.05, wps=18716.3, ups=5.29, wpb=3535.6, bsz=133.8, num_updates=57700, lr=0.000131647, gnorm=1.154, train_wall=19, wall=0
2024-05-30 20:18:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:18:36 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 3.927 | nll_loss 2.343 | ppl 5.07 | wps 55831.7 | wpb 2685.2 | bsz 107.1 | num_updates 57732 | best_loss 11.059
2024-05-30 20:18:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:18:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 51 @ 57732 updates, score 3.927) (writing took 3.328796974848956 seconds)
2024-05-30 20:18:39 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2024-05-30 20:18:39 | INFO | train | epoch 051 | loss 3.15 | nll_loss 1.568 | ppl 2.97 | wps 17470.9 | ups 4.91 | wpb 3556.4 | bsz 141.6 | num_updates 57732 | lr 0.000131611 | gnorm 1.142 | train_wall 215 | wall 0
2024-05-30 20:18:39 | INFO | fairseq.trainer | begin training epoch 52
2024-05-30 20:18:53 | INFO | train_inner | epoch 052:     68 / 1132 loss=3.133, nll_loss=1.547, ppl=2.92, wps=13144.9, ups=3.73, wpb=3527.8, bsz=134.4, num_updates=57800, lr=0.000131533, gnorm=1.132, train_wall=20, wall=0
2024-05-30 20:19:12 | INFO | train_inner | epoch 052:    168 / 1132 loss=3.096, nll_loss=1.504, ppl=2.84, wps=18618.4, ups=5.16, wpb=3606.4, bsz=146.4, num_updates=57900, lr=0.00013142, gnorm=1.099, train_wall=19, wall=0
2024-05-30 20:19:32 | INFO | train_inner | epoch 052:    268 / 1132 loss=3.141, nll_loss=1.557, ppl=2.94, wps=18983.3, ups=5.17, wpb=3672.4, bsz=139.9, num_updates=58000, lr=0.000131306, gnorm=1.112, train_wall=19, wall=0
2024-05-30 20:19:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:19:35 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 3.926 | nll_loss 2.349 | ppl 5.1 | wps 56018.6 | wpb 2685.2 | bsz 107.1 | num_updates 58000 | best_loss 11.059
2024-05-30 20:19:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:19:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_52_58000.pt (epoch 52 @ 58000 updates, score 3.926) (writing took 3.7036544890142977 seconds)
2024-05-30 20:19:58 | INFO | train_inner | epoch 052:    368 / 1132 loss=3.132, nll_loss=1.547, ppl=2.92, wps=13365.4, ups=3.8, wpb=3512.7, bsz=139.5, num_updates=58100, lr=0.000131193, gnorm=1.157, train_wall=19, wall=0
2024-05-30 20:20:17 | INFO | train_inner | epoch 052:    468 / 1132 loss=3.135, nll_loss=1.551, ppl=2.93, wps=18437.3, ups=5.28, wpb=3490.5, bsz=133, num_updates=58200, lr=0.000131081, gnorm=1.15, train_wall=19, wall=0
2024-05-30 20:20:36 | INFO | train_inner | epoch 052:    568 / 1132 loss=3.159, nll_loss=1.578, ppl=2.99, wps=18601.2, ups=5.24, wpb=3547.9, bsz=129.8, num_updates=58300, lr=0.000130968, gnorm=1.167, train_wall=19, wall=0
2024-05-30 20:20:55 | INFO | train_inner | epoch 052:    668 / 1132 loss=3.135, nll_loss=1.553, ppl=2.93, wps=18916.5, ups=5.28, wpb=3582, bsz=140.6, num_updates=58400, lr=0.000130856, gnorm=1.143, train_wall=19, wall=0
2024-05-30 20:21:14 | INFO | train_inner | epoch 052:    768 / 1132 loss=3.174, nll_loss=1.594, ppl=3.02, wps=18652.5, ups=5.22, wpb=3571.1, bsz=131.2, num_updates=58500, lr=0.000130744, gnorm=1.17, train_wall=19, wall=0
2024-05-30 20:21:33 | INFO | train_inner | epoch 052:    868 / 1132 loss=3.139, nll_loss=1.556, ppl=2.94, wps=17978.9, ups=5.19, wpb=3466, bsz=145.6, num_updates=58600, lr=0.000130632, gnorm=1.169, train_wall=19, wall=0
2024-05-30 20:21:53 | INFO | train_inner | epoch 052:    968 / 1132 loss=3.143, nll_loss=1.563, ppl=2.95, wps=17880.6, ups=5.08, wpb=3519.9, bsz=153.1, num_updates=58700, lr=0.000130521, gnorm=1.156, train_wall=20, wall=0
2024-05-30 20:22:13 | INFO | train_inner | epoch 052:   1068 / 1132 loss=3.164, nll_loss=1.585, ppl=3, wps=18258.2, ups=5.07, wpb=3599.9, bsz=149.5, num_updates=58800, lr=0.00013041, gnorm=1.13, train_wall=20, wall=0
2024-05-30 20:22:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:22:28 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 3.93 | nll_loss 2.346 | ppl 5.08 | wps 55843.9 | wpb 2685.2 | bsz 107.1 | num_updates 58864 | best_loss 11.059
2024-05-30 20:22:28 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:22:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 52 @ 58864 updates, score 3.93) (writing took 2.852217325940728 seconds)
2024-05-30 20:22:31 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2024-05-30 20:22:31 | INFO | train | epoch 052 | loss 3.141 | nll_loss 1.558 | ppl 2.94 | wps 17367.1 | ups 4.88 | wpb 3556.4 | bsz 141.6 | num_updates 58864 | lr 0.000130339 | gnorm 1.143 | train_wall 217 | wall 0
2024-05-30 20:22:31 | INFO | fairseq.trainer | begin training epoch 53
2024-05-30 20:22:38 | INFO | train_inner | epoch 053:     36 / 1132 loss=3.157, nll_loss=1.576, ppl=2.98, wps=14268, ups=3.97, wpb=3595.7, bsz=145, num_updates=58900, lr=0.000130299, gnorm=1.128, train_wall=19, wall=0
2024-05-30 20:22:57 | INFO | train_inner | epoch 053:    136 / 1132 loss=3.104, nll_loss=1.515, ppl=2.86, wps=18921.4, ups=5.23, wpb=3617.5, bsz=133, num_updates=59000, lr=0.000130189, gnorm=1.099, train_wall=19, wall=0
2024-05-30 20:22:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:23:01 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 3.929 | nll_loss 2.35 | ppl 5.1 | wps 55879 | wpb 2685.2 | bsz 107.1 | num_updates 59000 | best_loss 11.059
2024-05-30 20:23:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:23:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_53_59000.pt (epoch 53 @ 59000 updates, score 3.929) (writing took 3.568111966829747 seconds)
2024-05-30 20:23:23 | INFO | train_inner | epoch 053:    236 / 1132 loss=3.109, nll_loss=1.521, ppl=2.87, wps=13875.9, ups=3.82, wpb=3630.9, bsz=145.4, num_updates=59100, lr=0.000130079, gnorm=1.136, train_wall=19, wall=0
2024-05-30 20:23:42 | INFO | train_inner | epoch 053:    336 / 1132 loss=3.11, nll_loss=1.522, ppl=2.87, wps=18706.5, ups=5.24, wpb=3567.8, bsz=145.5, num_updates=59200, lr=0.000129969, gnorm=1.124, train_wall=19, wall=0
2024-05-30 20:24:01 | INFO | train_inner | epoch 053:    436 / 1132 loss=3.137, nll_loss=1.553, ppl=2.93, wps=18530.9, ups=5.26, wpb=3520.5, bsz=127.5, num_updates=59300, lr=0.000129859, gnorm=1.203, train_wall=19, wall=0
2024-05-30 20:24:21 | INFO | train_inner | epoch 053:    536 / 1132 loss=3.119, nll_loss=1.533, ppl=2.89, wps=18664.3, ups=5.21, wpb=3582.5, bsz=154.2, num_updates=59400, lr=0.00012975, gnorm=1.138, train_wall=19, wall=0
2024-05-30 20:24:40 | INFO | train_inner | epoch 053:    636 / 1132 loss=3.126, nll_loss=1.542, ppl=2.91, wps=18364.6, ups=5.27, wpb=3484.5, bsz=147.8, num_updates=59500, lr=0.000129641, gnorm=1.155, train_wall=19, wall=0
2024-05-30 20:24:59 | INFO | train_inner | epoch 053:    736 / 1132 loss=3.161, nll_loss=1.581, ppl=2.99, wps=18843.5, ups=5.21, wpb=3615.7, bsz=139.5, num_updates=59600, lr=0.000129532, gnorm=1.143, train_wall=19, wall=0
2024-05-30 20:25:18 | INFO | train_inner | epoch 053:    836 / 1132 loss=3.147, nll_loss=1.563, ppl=2.96, wps=18252.6, ups=5.2, wpb=3513.5, bsz=144.9, num_updates=59700, lr=0.000129423, gnorm=1.178, train_wall=19, wall=0
2024-05-30 20:25:37 | INFO | train_inner | epoch 053:    936 / 1132 loss=3.144, nll_loss=1.56, ppl=2.95, wps=18504.5, ups=5.28, wpb=3501.5, bsz=136.1, num_updates=59800, lr=0.000129315, gnorm=1.166, train_wall=19, wall=0
2024-05-30 20:25:56 | INFO | train_inner | epoch 053:   1036 / 1132 loss=3.159, nll_loss=1.579, ppl=2.99, wps=18635.2, ups=5.26, wpb=3540.6, bsz=132.4, num_updates=59900, lr=0.000129207, gnorm=1.166, train_wall=19, wall=0
2024-05-30 20:26:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:26:18 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 3.939 | nll_loss 2.364 | ppl 5.15 | wps 55895.5 | wpb 2685.2 | bsz 107.1 | num_updates 59996 | best_loss 11.059
2024-05-30 20:26:18 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:26:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 53 @ 59996 updates, score 3.939) (writing took 2.8218655860982835 seconds)
2024-05-30 20:26:20 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2024-05-30 20:26:20 | INFO | train | epoch 053 | loss 3.132 | nll_loss 1.548 | ppl 2.92 | wps 17543.5 | ups 4.93 | wpb 3556.4 | bsz 141.6 | num_updates 59996 | lr 0.000129104 | gnorm 1.151 | train_wall 214 | wall 0
2024-05-30 20:26:20 | INFO | fairseq.trainer | begin training epoch 54
2024-05-30 20:26:21 | INFO | train_inner | epoch 054:      4 / 1132 loss=3.148, nll_loss=1.568, ppl=2.96, wps=13877.6, ups=3.93, wpb=3529, bsz=149.8, num_updates=60000, lr=0.000129099, gnorm=1.168, train_wall=19, wall=0
2024-05-30 20:26:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:26:25 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 3.945 | nll_loss 2.363 | ppl 5.15 | wps 55971.1 | wpb 2685.2 | bsz 107.1 | num_updates 60000 | best_loss 11.059
2024-05-30 20:26:25 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:26:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_54_60000.pt (epoch 54 @ 60000 updates, score 3.945) (writing took 3.5950507181696594 seconds)
2024-05-30 20:26:47 | INFO | train_inner | epoch 054:    104 / 1132 loss=3.078, nll_loss=1.484, ppl=2.8, wps=13493.1, ups=3.84, wpb=3513.2, bsz=138.2, num_updates=60100, lr=0.000128992, gnorm=1.135, train_wall=19, wall=0
2024-05-30 20:27:07 | INFO | train_inner | epoch 054:    204 / 1132 loss=3.095, nll_loss=1.503, ppl=2.83, wps=18711.4, ups=5.24, wpb=3571.8, bsz=133.9, num_updates=60200, lr=0.000128885, gnorm=1.121, train_wall=19, wall=0
2024-05-30 20:27:25 | INFO | train_inner | epoch 054:    304 / 1132 loss=3.066, nll_loss=1.475, ppl=2.78, wps=18792.4, ups=5.33, wpb=3528.3, bsz=157.4, num_updates=60300, lr=0.000128778, gnorm=1.127, train_wall=19, wall=0
2024-05-30 20:27:44 | INFO | train_inner | epoch 054:    404 / 1132 loss=3.118, nll_loss=1.532, ppl=2.89, wps=18847.4, ups=5.24, wpb=3594.6, bsz=146.2, num_updates=60400, lr=0.000128671, gnorm=1.132, train_wall=19, wall=0
2024-05-30 20:28:03 | INFO | train_inner | epoch 054:    504 / 1132 loss=3.123, nll_loss=1.534, ppl=2.9, wps=18489.9, ups=5.26, wpb=3517.9, bsz=141.6, num_updates=60500, lr=0.000128565, gnorm=1.166, train_wall=19, wall=0
2024-05-30 20:28:22 | INFO | train_inner | epoch 054:    604 / 1132 loss=3.113, nll_loss=1.526, ppl=2.88, wps=18860.5, ups=5.24, wpb=3596, bsz=150.3, num_updates=60600, lr=0.000128459, gnorm=1.126, train_wall=19, wall=0
2024-05-30 20:28:42 | INFO | train_inner | epoch 054:    704 / 1132 loss=3.142, nll_loss=1.558, ppl=2.94, wps=18803.5, ups=5.25, wpb=3584.6, bsz=142.8, num_updates=60700, lr=0.000128353, gnorm=1.17, train_wall=19, wall=0
2024-05-30 20:29:01 | INFO | train_inner | epoch 054:    804 / 1132 loss=3.153, nll_loss=1.572, ppl=2.97, wps=18679.8, ups=5.22, wpb=3576.7, bsz=139.4, num_updates=60800, lr=0.000128247, gnorm=1.157, train_wall=19, wall=0
2024-05-30 20:29:20 | INFO | train_inner | epoch 054:    904 / 1132 loss=3.139, nll_loss=1.554, ppl=2.94, wps=18412, ups=5.28, wpb=3484.9, bsz=130, num_updates=60900, lr=0.000128142, gnorm=1.176, train_wall=19, wall=0
2024-05-30 20:29:38 | INFO | train_inner | epoch 054:   1004 / 1132 loss=3.18, nll_loss=1.602, ppl=3.04, wps=18778.9, ups=5.29, wpb=3548, bsz=128.6, num_updates=61000, lr=0.000128037, gnorm=1.209, train_wall=19, wall=0
2024-05-30 20:29:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:29:42 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 3.937 | nll_loss 2.354 | ppl 5.11 | wps 55558.2 | wpb 2685.2 | bsz 107.1 | num_updates 61000 | best_loss 11.059
2024-05-30 20:29:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:29:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_54_61000.pt (epoch 54 @ 61000 updates, score 3.937) (writing took 3.1730969231575727 seconds)
2024-05-30 20:30:05 | INFO | train_inner | epoch 054:   1104 / 1132 loss=3.143, nll_loss=1.563, ppl=2.96, wps=13748.5, ups=3.83, wpb=3592.2, bsz=151.1, num_updates=61100, lr=0.000127932, gnorm=1.14, train_wall=19, wall=0
2024-05-30 20:30:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:30:14 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 3.928 | nll_loss 2.35 | ppl 5.1 | wps 55494.1 | wpb 2685.2 | bsz 107.1 | num_updates 61128 | best_loss 11.059
2024-05-30 20:30:14 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:30:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 54 @ 61128 updates, score 3.928) (writing took 3.0354793681763113 seconds)
2024-05-30 20:30:17 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2024-05-30 20:30:17 | INFO | train | epoch 054 | loss 3.124 | nll_loss 1.538 | ppl 2.9 | wps 17015.5 | ups 4.78 | wpb 3556.4 | bsz 141.6 | num_updates 61128 | lr 0.000127903 | gnorm 1.152 | train_wall 215 | wall 0
2024-05-30 20:30:17 | INFO | fairseq.trainer | begin training epoch 55
2024-05-30 20:30:31 | INFO | train_inner | epoch 055:     72 / 1132 loss=3.098, nll_loss=1.508, ppl=2.84, wps=13564, ups=3.79, wpb=3576.9, bsz=146.5, num_updates=61200, lr=0.000127827, gnorm=1.138, train_wall=20, wall=0
2024-05-30 20:30:51 | INFO | train_inner | epoch 055:    172 / 1132 loss=3.077, nll_loss=1.484, ppl=2.8, wps=17712.4, ups=4.94, wpb=3584.7, bsz=145.4, num_updates=61300, lr=0.000127723, gnorm=1.133, train_wall=20, wall=0
2024-05-30 20:31:12 | INFO | train_inner | epoch 055:    272 / 1132 loss=3.109, nll_loss=1.521, ppl=2.87, wps=17206.5, ups=4.8, wpb=3585.8, bsz=130.6, num_updates=61400, lr=0.000127619, gnorm=1.136, train_wall=21, wall=0
2024-05-30 20:31:32 | INFO | train_inner | epoch 055:    372 / 1132 loss=3.123, nll_loss=1.535, ppl=2.9, wps=17820.7, ups=5.1, wpb=3494.2, bsz=126.8, num_updates=61500, lr=0.000127515, gnorm=1.187, train_wall=19, wall=0
2024-05-30 20:31:51 | INFO | train_inner | epoch 055:    472 / 1132 loss=3.108, nll_loss=1.521, ppl=2.87, wps=18222, ups=5.06, wpb=3599.5, bsz=138.6, num_updates=61600, lr=0.000127412, gnorm=1.137, train_wall=20, wall=0
2024-05-30 20:32:11 | INFO | train_inner | epoch 055:    572 / 1132 loss=3.12, nll_loss=1.531, ppl=2.89, wps=17984.5, ups=5.19, wpb=3466, bsz=129.4, num_updates=61700, lr=0.000127309, gnorm=1.175, train_wall=19, wall=0
2024-05-30 20:32:30 | INFO | train_inner | epoch 055:    672 / 1132 loss=3.143, nll_loss=1.559, ppl=2.95, wps=18704.1, ups=5.23, wpb=3578.5, bsz=134.2, num_updates=61800, lr=0.000127205, gnorm=1.162, train_wall=19, wall=0
2024-05-30 20:32:49 | INFO | train_inner | epoch 055:    772 / 1132 loss=3.101, nll_loss=1.513, ppl=2.85, wps=18717.6, ups=5.22, wpb=3585.6, bsz=168.1, num_updates=61900, lr=0.000127103, gnorm=1.148, train_wall=19, wall=0
2024-05-30 20:33:08 | INFO | train_inner | epoch 055:    872 / 1132 loss=3.138, nll_loss=1.553, ppl=2.94, wps=18580.4, ups=5.21, wpb=3565.7, bsz=137.5, num_updates=62000, lr=0.000127, gnorm=1.175, train_wall=19, wall=0
2024-05-30 20:33:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:33:12 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 3.933 | nll_loss 2.356 | ppl 5.12 | wps 55839.8 | wpb 2685.2 | bsz 107.1 | num_updates 62000 | best_loss 11.059
2024-05-30 20:33:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:33:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_55_62000.pt (epoch 55 @ 62000 updates, score 3.933) (writing took 3.3909474099054933 seconds)
2024-05-30 20:33:34 | INFO | train_inner | epoch 055:    972 / 1132 loss=3.095, nll_loss=1.505, ppl=2.84, wps=13709.7, ups=3.91, wpb=3503.1, bsz=163.2, num_updates=62100, lr=0.000126898, gnorm=1.159, train_wall=19, wall=0
2024-05-30 20:33:52 | INFO | train_inner | epoch 055:   1072 / 1132 loss=3.159, nll_loss=1.58, ppl=2.99, wps=19716.3, ups=5.49, wpb=3588.6, bsz=133.1, num_updates=62200, lr=0.000126796, gnorm=1.163, train_wall=18, wall=0
2024-05-30 20:34:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:34:06 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 3.927 | nll_loss 2.35 | ppl 5.1 | wps 56061.1 | wpb 2685.2 | bsz 107.1 | num_updates 62260 | best_loss 11.059
2024-05-30 20:34:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:34:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 55 @ 62260 updates, score 3.927) (writing took 2.851644883863628 seconds)
2024-05-30 20:34:09 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2024-05-30 20:34:09 | INFO | train | epoch 055 | loss 3.115 | nll_loss 1.528 | ppl 2.88 | wps 17345.2 | ups 4.88 | wpb 3556.4 | bsz 141.6 | num_updates 62260 | lr 0.000126735 | gnorm 1.155 | train_wall 217 | wall 0
2024-05-30 20:34:09 | INFO | fairseq.trainer | begin training epoch 56
2024-05-30 20:34:17 | INFO | train_inner | epoch 056:     40 / 1132 loss=3.104, nll_loss=1.517, ppl=2.86, wps=14288.1, ups=4.01, wpb=3562.2, bsz=139.9, num_updates=62300, lr=0.000126694, gnorm=1.144, train_wall=18, wall=0
2024-05-30 20:34:36 | INFO | train_inner | epoch 056:    140 / 1132 loss=3.081, nll_loss=1.488, ppl=2.81, wps=18677.7, ups=5.25, wpb=3559.6, bsz=135.9, num_updates=62400, lr=0.000126592, gnorm=1.137, train_wall=19, wall=0
2024-05-30 20:34:55 | INFO | train_inner | epoch 056:    240 / 1132 loss=3.082, nll_loss=1.492, ppl=2.81, wps=19028.5, ups=5.19, wpb=3668.4, bsz=153.5, num_updates=62500, lr=0.000126491, gnorm=1.12, train_wall=19, wall=0
2024-05-30 20:35:14 | INFO | train_inner | epoch 056:    340 / 1132 loss=3.1, nll_loss=1.51, ppl=2.85, wps=18696.9, ups=5.2, wpb=3594.7, bsz=138.4, num_updates=62600, lr=0.00012639, gnorm=1.151, train_wall=19, wall=0
2024-05-30 20:35:34 | INFO | train_inner | epoch 056:    440 / 1132 loss=3.114, nll_loss=1.526, ppl=2.88, wps=18624.1, ups=5.17, wpb=3605.5, bsz=133.7, num_updates=62700, lr=0.000126289, gnorm=1.153, train_wall=19, wall=0
2024-05-30 20:35:53 | INFO | train_inner | epoch 056:    540 / 1132 loss=3.104, nll_loss=1.516, ppl=2.86, wps=18673.2, ups=5.27, wpb=3546.1, bsz=140, num_updates=62800, lr=0.000126189, gnorm=1.16, train_wall=19, wall=0
2024-05-30 20:36:11 | INFO | train_inner | epoch 056:    640 / 1132 loss=3.104, nll_loss=1.515, ppl=2.86, wps=19428.9, ups=5.47, wpb=3550.5, bsz=155.3, num_updates=62900, lr=0.000126088, gnorm=1.16, train_wall=18, wall=0
2024-05-30 20:36:30 | INFO | train_inner | epoch 056:    740 / 1132 loss=3.115, nll_loss=1.528, ppl=2.88, wps=18716.9, ups=5.29, wpb=3536.2, bsz=140.6, num_updates=63000, lr=0.000125988, gnorm=1.19, train_wall=19, wall=0
2024-05-30 20:36:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:36:33 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 3.931 | nll_loss 2.351 | ppl 5.1 | wps 55954.4 | wpb 2685.2 | bsz 107.1 | num_updates 63000 | best_loss 11.059
2024-05-30 20:36:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:36:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_56_63000.pt (epoch 56 @ 63000 updates, score 3.931) (writing took 3.409777933731675 seconds)
2024-05-30 20:36:56 | INFO | train_inner | epoch 056:    840 / 1132 loss=3.139, nll_loss=1.555, ppl=2.94, wps=13714.7, ups=3.87, wpb=3539.3, bsz=126, num_updates=63100, lr=0.000125888, gnorm=1.174, train_wall=19, wall=0
2024-05-30 20:37:15 | INFO | train_inner | epoch 056:    940 / 1132 loss=3.125, nll_loss=1.539, ppl=2.91, wps=18467.8, ups=5.28, wpb=3496.5, bsz=146.9, num_updates=63200, lr=0.000125789, gnorm=1.192, train_wall=19, wall=0
2024-05-30 20:37:34 | INFO | train_inner | epoch 056:   1040 / 1132 loss=3.126, nll_loss=1.541, ppl=2.91, wps=18518.8, ups=5.29, wpb=3503.9, bsz=147.7, num_updates=63300, lr=0.000125689, gnorm=1.195, train_wall=19, wall=0
2024-05-30 20:37:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:37:54 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 3.939 | nll_loss 2.363 | ppl 5.14 | wps 56167.4 | wpb 2685.2 | bsz 107.1 | num_updates 63392 | best_loss 11.059
2024-05-30 20:37:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:37:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 56 @ 63392 updates, score 3.939) (writing took 2.9014234710484743 seconds)
2024-05-30 20:37:57 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2024-05-30 20:37:57 | INFO | train | epoch 056 | loss 3.109 | nll_loss 1.52 | ppl 2.87 | wps 17639.6 | ups 4.96 | wpb 3556.4 | bsz 141.6 | num_updates 63392 | lr 0.000125598 | gnorm 1.163 | train_wall 213 | wall 0
2024-05-30 20:37:57 | INFO | fairseq.trainer | begin training epoch 57
2024-05-30 20:37:59 | INFO | train_inner | epoch 057:      8 / 1132 loss=3.115, nll_loss=1.529, ppl=2.89, wps=13855.2, ups=3.92, wpb=3537.2, bsz=149.6, num_updates=63400, lr=0.00012559, gnorm=1.172, train_wall=19, wall=0
2024-05-30 20:38:18 | INFO | train_inner | epoch 057:    108 / 1132 loss=3.061, nll_loss=1.464, ppl=2.76, wps=18292.2, ups=5.29, wpb=3457.6, bsz=131.1, num_updates=63500, lr=0.000125491, gnorm=1.173, train_wall=19, wall=0
2024-05-30 20:38:37 | INFO | train_inner | epoch 057:    208 / 1132 loss=3.084, nll_loss=1.49, ppl=2.81, wps=18754.7, ups=5.22, wpb=3589.7, bsz=136.9, num_updates=63600, lr=0.000125392, gnorm=1.15, train_wall=19, wall=0
2024-05-30 20:38:57 | INFO | train_inner | epoch 057:    308 / 1132 loss=3.072, nll_loss=1.477, ppl=2.78, wps=18429.5, ups=5.16, wpb=3574.9, bsz=141.6, num_updates=63700, lr=0.000125294, gnorm=1.145, train_wall=19, wall=0
2024-05-30 20:39:16 | INFO | train_inner | epoch 057:    408 / 1132 loss=3.089, nll_loss=1.498, ppl=2.83, wps=18444.3, ups=5.21, wpb=3541, bsz=140.2, num_updates=63800, lr=0.000125196, gnorm=1.16, train_wall=19, wall=0
2024-05-30 20:39:35 | INFO | train_inner | epoch 057:    508 / 1132 loss=3.09, nll_loss=1.502, ppl=2.83, wps=18865, ups=5.24, wpb=3599.9, bsz=149.3, num_updates=63900, lr=0.000125098, gnorm=1.143, train_wall=19, wall=0
2024-05-30 20:39:54 | INFO | train_inner | epoch 057:    608 / 1132 loss=3.082, nll_loss=1.491, ppl=2.81, wps=18429.7, ups=5.25, wpb=3509.7, bsz=148.2, num_updates=64000, lr=0.000125, gnorm=1.165, train_wall=19, wall=0
2024-05-30 20:39:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:39:57 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 3.963 | nll_loss 2.384 | ppl 5.22 | wps 56026.3 | wpb 2685.2 | bsz 107.1 | num_updates 64000 | best_loss 11.059
2024-05-30 20:39:57 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:40:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_57_64000.pt (epoch 57 @ 64000 updates, score 3.963) (writing took 3.4871089858934283 seconds)
2024-05-30 20:40:20 | INFO | train_inner | epoch 057:    708 / 1132 loss=3.111, nll_loss=1.521, ppl=2.87, wps=13528.7, ups=3.82, wpb=3542.2, bsz=143.6, num_updates=64100, lr=0.000124902, gnorm=1.179, train_wall=19, wall=0
2024-05-30 20:40:39 | INFO | train_inner | epoch 057:    808 / 1132 loss=3.113, nll_loss=1.526, ppl=2.88, wps=18736.7, ups=5.2, wpb=3604.1, bsz=148.2, num_updates=64200, lr=0.000124805, gnorm=1.163, train_wall=19, wall=0
2024-05-30 20:40:58 | INFO | train_inner | epoch 057:    908 / 1132 loss=3.128, nll_loss=1.545, ppl=2.92, wps=18839.5, ups=5.23, wpb=3601.7, bsz=137.2, num_updates=64300, lr=0.000124708, gnorm=1.156, train_wall=19, wall=0
2024-05-30 20:41:18 | INFO | train_inner | epoch 057:   1008 / 1132 loss=3.133, nll_loss=1.548, ppl=2.92, wps=18293.8, ups=5.23, wpb=3499.4, bsz=140.2, num_updates=64400, lr=0.000124611, gnorm=1.192, train_wall=19, wall=0
2024-05-30 20:41:37 | INFO | train_inner | epoch 057:   1108 / 1132 loss=3.144, nll_loss=1.563, ppl=2.95, wps=18773.6, ups=5.22, wpb=3593.3, bsz=135.4, num_updates=64500, lr=0.000124515, gnorm=1.152, train_wall=19, wall=0
2024-05-30 20:41:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:41:45 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 3.941 | nll_loss 2.357 | ppl 5.12 | wps 55852.9 | wpb 2685.2 | bsz 107.1 | num_updates 64524 | best_loss 11.059
2024-05-30 20:41:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:41:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 57 @ 64524 updates, score 3.941) (writing took 2.9318936527706683 seconds)
2024-05-30 20:41:48 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2024-05-30 20:41:48 | INFO | train | epoch 057 | loss 3.1 | nll_loss 1.511 | ppl 2.85 | wps 17473.6 | ups 4.91 | wpb 3556.4 | bsz 141.6 | num_updates 64524 | lr 0.000124491 | gnorm 1.162 | train_wall 215 | wall 0
2024-05-30 20:41:48 | INFO | fairseq.trainer | begin training epoch 58
2024-05-30 20:42:02 | INFO | train_inner | epoch 058:     76 / 1132 loss=3.073, nll_loss=1.479, ppl=2.79, wps=13969.4, ups=3.88, wpb=3596.3, bsz=142.4, num_updates=64600, lr=0.000124418, gnorm=1.136, train_wall=19, wall=0
2024-05-30 20:42:21 | INFO | train_inner | epoch 058:    176 / 1132 loss=3.059, nll_loss=1.463, ppl=2.76, wps=18806.1, ups=5.28, wpb=3563.6, bsz=141, num_updates=64700, lr=0.000124322, gnorm=1.158, train_wall=19, wall=0
2024-05-30 20:42:40 | INFO | train_inner | epoch 058:    276 / 1132 loss=3.043, nll_loss=1.443, ppl=2.72, wps=18255, ups=5.29, wpb=3452.9, bsz=147.2, num_updates=64800, lr=0.000124226, gnorm=1.169, train_wall=19, wall=0
2024-05-30 20:42:59 | INFO | train_inner | epoch 058:    376 / 1132 loss=3.07, nll_loss=1.477, ppl=2.78, wps=18683.3, ups=5.26, wpb=3553.6, bsz=146.6, num_updates=64900, lr=0.00012413, gnorm=1.165, train_wall=19, wall=0
2024-05-30 20:43:19 | INFO | train_inner | epoch 058:    476 / 1132 loss=3.076, nll_loss=1.483, ppl=2.79, wps=17970, ups=5.04, wpb=3568.1, bsz=147.1, num_updates=65000, lr=0.000124035, gnorm=1.158, train_wall=20, wall=0
2024-05-30 20:43:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:43:23 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 3.949 | nll_loss 2.373 | ppl 5.18 | wps 55487.6 | wpb 2685.2 | bsz 107.1 | num_updates 65000 | best_loss 11.059
2024-05-30 20:43:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:43:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_58_65000.pt (epoch 58 @ 65000 updates, score 3.949) (writing took 3.7192712370306253 seconds)
2024-05-30 20:43:46 | INFO | train_inner | epoch 058:    576 / 1132 loss=3.116, nll_loss=1.527, ppl=2.88, wps=13257.2, ups=3.68, wpb=3603.3, bsz=134.3, num_updates=65100, lr=0.000123939, gnorm=1.155, train_wall=20, wall=0
2024-05-30 20:44:05 | INFO | train_inner | epoch 058:    676 / 1132 loss=3.096, nll_loss=1.507, ppl=2.84, wps=18601.4, ups=5.27, wpb=3531.4, bsz=140, num_updates=65200, lr=0.000123844, gnorm=1.176, train_wall=19, wall=0
2024-05-30 20:44:24 | INFO | train_inner | epoch 058:    776 / 1132 loss=3.114, nll_loss=1.527, ppl=2.88, wps=18649.4, ups=5.23, wpb=3563.7, bsz=141.8, num_updates=65300, lr=0.000123749, gnorm=1.182, train_wall=19, wall=0
2024-05-30 20:44:43 | INFO | train_inner | epoch 058:    876 / 1132 loss=3.12, nll_loss=1.534, ppl=2.9, wps=19105.1, ups=5.31, wpb=3597.8, bsz=134.9, num_updates=65400, lr=0.000123655, gnorm=1.171, train_wall=19, wall=0
2024-05-30 20:45:01 | INFO | train_inner | epoch 058:    976 / 1132 loss=3.125, nll_loss=1.54, ppl=2.91, wps=19582.5, ups=5.57, wpb=3517.3, bsz=132.2, num_updates=65500, lr=0.00012356, gnorm=1.231, train_wall=18, wall=0
2024-05-30 20:45:21 | INFO | train_inner | epoch 058:   1076 / 1132 loss=3.13, nll_loss=1.545, ppl=2.92, wps=18220.1, ups=5.15, wpb=3536.9, bsz=140.2, num_updates=65600, lr=0.000123466, gnorm=1.19, train_wall=19, wall=0
2024-05-30 20:45:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:45:35 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 3.935 | nll_loss 2.351 | ppl 5.1 | wps 55792.9 | wpb 2685.2 | bsz 107.1 | num_updates 65656 | best_loss 11.059
2024-05-30 20:45:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:45:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 58 @ 65656 updates, score 3.935) (writing took 3.0434949472546577 seconds)
2024-05-30 20:45:38 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2024-05-30 20:45:38 | INFO | train | epoch 058 | loss 3.093 | nll_loss 1.503 | ppl 2.83 | wps 17481.8 | ups 4.92 | wpb 3556.4 | bsz 141.6 | num_updates 65656 | lr 0.000123414 | gnorm 1.17 | train_wall 215 | wall 0
2024-05-30 20:45:38 | INFO | fairseq.trainer | begin training epoch 59
2024-05-30 20:45:46 | INFO | train_inner | epoch 059:     44 / 1132 loss=3.076, nll_loss=1.484, ppl=2.8, wps=13546.2, ups=3.88, wpb=3492.6, bsz=144.7, num_updates=65700, lr=0.000123372, gnorm=1.176, train_wall=19, wall=0
2024-05-30 20:46:06 | INFO | train_inner | epoch 059:    144 / 1132 loss=3.042, nll_loss=1.441, ppl=2.71, wps=17906.1, ups=5.21, wpb=3437.1, bsz=137.8, num_updates=65800, lr=0.000123278, gnorm=1.185, train_wall=19, wall=0
2024-05-30 20:46:25 | INFO | train_inner | epoch 059:    244 / 1132 loss=3.051, nll_loss=1.454, ppl=2.74, wps=18578.1, ups=5.26, wpb=3530.4, bsz=137.6, num_updates=65900, lr=0.000123185, gnorm=1.177, train_wall=19, wall=0
2024-05-30 20:46:44 | INFO | train_inner | epoch 059:    344 / 1132 loss=3.067, nll_loss=1.47, ppl=2.77, wps=18366.7, ups=5.25, wpb=3500.5, bsz=138.8, num_updates=66000, lr=0.000123091, gnorm=1.185, train_wall=19, wall=0
2024-05-30 20:46:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:46:47 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 3.954 | nll_loss 2.371 | ppl 5.17 | wps 55900 | wpb 2685.2 | bsz 107.1 | num_updates 66000 | best_loss 11.059
2024-05-30 20:46:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:46:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_59_66000.pt (epoch 59 @ 66000 updates, score 3.954) (writing took 3.396859945729375 seconds)
2024-05-30 20:47:10 | INFO | train_inner | epoch 059:    444 / 1132 loss=3.069, nll_loss=1.475, ppl=2.78, wps=13691.4, ups=3.85, wpb=3560.4, bsz=143, num_updates=66100, lr=0.000122998, gnorm=1.169, train_wall=19, wall=0
2024-05-30 20:47:29 | INFO | train_inner | epoch 059:    544 / 1132 loss=3.101, nll_loss=1.51, ppl=2.85, wps=18704.6, ups=5.2, wpb=3600.2, bsz=137.6, num_updates=66200, lr=0.000122905, gnorm=1.183, train_wall=19, wall=0
2024-05-30 20:47:48 | INFO | train_inner | epoch 059:    644 / 1132 loss=3.108, nll_loss=1.521, ppl=2.87, wps=18967.2, ups=5.21, wpb=3641.4, bsz=132.6, num_updates=66300, lr=0.000122813, gnorm=1.155, train_wall=19, wall=0
2024-05-30 20:48:07 | INFO | train_inner | epoch 059:    744 / 1132 loss=3.103, nll_loss=1.516, ppl=2.86, wps=18961.1, ups=5.27, wpb=3597.4, bsz=143, num_updates=66400, lr=0.00012272, gnorm=1.16, train_wall=19, wall=0
2024-05-30 20:48:26 | INFO | train_inner | epoch 059:    844 / 1132 loss=3.101, nll_loss=1.513, ppl=2.85, wps=18927.4, ups=5.24, wpb=3614.3, bsz=154.2, num_updates=66500, lr=0.000122628, gnorm=1.17, train_wall=19, wall=0
2024-05-30 20:48:45 | INFO | train_inner | epoch 059:    944 / 1132 loss=3.137, nll_loss=1.555, ppl=2.94, wps=19269.7, ups=5.32, wpb=3619.7, bsz=130.2, num_updates=66600, lr=0.000122536, gnorm=1.163, train_wall=19, wall=0
2024-05-30 20:49:03 | INFO | train_inner | epoch 059:   1044 / 1132 loss=3.093, nll_loss=1.504, ppl=2.84, wps=19543.7, ups=5.46, wpb=3579.1, bsz=159, num_updates=66700, lr=0.000122444, gnorm=1.163, train_wall=18, wall=0
2024-05-30 20:49:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:49:23 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 3.928 | nll_loss 2.35 | ppl 5.1 | wps 55834.1 | wpb 2685.2 | bsz 107.1 | num_updates 66788 | best_loss 11.059
2024-05-30 20:49:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:49:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 59 @ 66788 updates, score 3.928) (writing took 2.8338146740570664 seconds)
2024-05-30 20:49:26 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2024-05-30 20:49:26 | INFO | train | epoch 059 | loss 3.086 | nll_loss 1.495 | ppl 2.82 | wps 17687.5 | ups 4.97 | wpb 3556.4 | bsz 141.6 | num_updates 66788 | lr 0.000122363 | gnorm 1.174 | train_wall 213 | wall 0
2024-05-30 20:49:26 | INFO | fairseq.trainer | begin training epoch 60
2024-05-30 20:49:28 | INFO | train_inner | epoch 060:     12 / 1132 loss=3.092, nll_loss=1.503, ppl=2.83, wps=14317.5, ups=4.02, wpb=3563.4, bsz=151.4, num_updates=66800, lr=0.000122352, gnorm=1.168, train_wall=18, wall=0
2024-05-30 20:49:47 | INFO | train_inner | epoch 060:    112 / 1132 loss=3.012, nll_loss=1.411, ppl=2.66, wps=18889.3, ups=5.25, wpb=3598.1, bsz=153.1, num_updates=66900, lr=0.000122261, gnorm=1.128, train_wall=19, wall=0
2024-05-30 20:50:07 | INFO | train_inner | epoch 060:    212 / 1132 loss=3.042, nll_loss=1.442, ppl=2.72, wps=18219.8, ups=5.21, wpb=3500.3, bsz=146.6, num_updates=67000, lr=0.000122169, gnorm=1.168, train_wall=19, wall=0
2024-05-30 20:50:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:50:10 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 3.967 | nll_loss 2.386 | ppl 5.23 | wps 55747.9 | wpb 2685.2 | bsz 107.1 | num_updates 67000 | best_loss 11.059
2024-05-30 20:50:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:50:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_60_67000.pt (epoch 60 @ 67000 updates, score 3.967) (writing took 3.4044410190545022 seconds)
2024-05-30 20:50:32 | INFO | train_inner | epoch 060:    312 / 1132 loss=3.06, nll_loss=1.466, ppl=2.76, wps=13878.9, ups=3.85, wpb=3604.4, bsz=145.2, num_updates=67100, lr=0.000122078, gnorm=1.154, train_wall=19, wall=0
2024-05-30 20:50:52 | INFO | train_inner | epoch 060:    412 / 1132 loss=3.082, nll_loss=1.488, ppl=2.81, wps=18534, ups=5.25, wpb=3527.1, bsz=128.9, num_updates=67200, lr=0.000121988, gnorm=1.203, train_wall=19, wall=0
2024-05-30 20:51:10 | INFO | train_inner | epoch 060:    512 / 1132 loss=3.083, nll_loss=1.492, ppl=2.81, wps=18926.9, ups=5.29, wpb=3578.3, bsz=134.6, num_updates=67300, lr=0.000121897, gnorm=1.155, train_wall=19, wall=0
2024-05-30 20:51:29 | INFO | train_inner | epoch 060:    612 / 1132 loss=3.067, nll_loss=1.472, ppl=2.77, wps=19395.6, ups=5.47, wpb=3548.4, bsz=156.2, num_updates=67400, lr=0.000121806, gnorm=1.17, train_wall=18, wall=0
2024-05-30 20:51:47 | INFO | train_inner | epoch 060:    712 / 1132 loss=3.104, nll_loss=1.514, ppl=2.86, wps=19610.7, ups=5.52, wpb=3549.7, bsz=130.2, num_updates=67500, lr=0.000121716, gnorm=1.198, train_wall=18, wall=0
2024-05-30 20:52:05 | INFO | train_inner | epoch 060:    812 / 1132 loss=3.102, nll_loss=1.513, ppl=2.85, wps=19560, ups=5.49, wpb=3563.6, bsz=139.4, num_updates=67600, lr=0.000121626, gnorm=1.189, train_wall=18, wall=0
2024-05-30 20:52:23 | INFO | train_inner | epoch 060:    912 / 1132 loss=3.094, nll_loss=1.505, ppl=2.84, wps=19611, ups=5.47, wpb=3585.3, bsz=148.6, num_updates=67700, lr=0.000121536, gnorm=1.176, train_wall=18, wall=0
2024-05-30 20:52:41 | INFO | train_inner | epoch 060:   1012 / 1132 loss=3.109, nll_loss=1.52, ppl=2.87, wps=19490.7, ups=5.51, wpb=3537.4, bsz=132.6, num_updates=67800, lr=0.000121447, gnorm=1.194, train_wall=18, wall=0
2024-05-30 20:53:00 | INFO | train_inner | epoch 060:   1112 / 1132 loss=3.094, nll_loss=1.504, ppl=2.84, wps=18818.6, ups=5.42, wpb=3472.9, bsz=138, num_updates=67900, lr=0.000121357, gnorm=1.208, train_wall=18, wall=0
2024-05-30 20:53:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:53:07 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 3.94 | nll_loss 2.36 | ppl 5.13 | wps 55838.1 | wpb 2685.2 | bsz 107.1 | num_updates 67920 | best_loss 11.059
2024-05-30 20:53:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:53:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 60 @ 67920 updates, score 3.94) (writing took 2.8742950409650803 seconds)
2024-05-30 20:53:10 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2024-05-30 20:53:10 | INFO | train | epoch 060 | loss 3.077 | nll_loss 1.484 | ppl 2.8 | wps 17941.6 | ups 5.04 | wpb 3556.4 | bsz 141.6 | num_updates 67920 | lr 0.000121339 | gnorm 1.175 | train_wall 210 | wall 0
2024-05-30 20:53:10 | INFO | fairseq.trainer | begin training epoch 61
2024-05-30 20:53:26 | INFO | train_inner | epoch 061:     80 / 1132 loss=3.041, nll_loss=1.443, ppl=2.72, wps=13522.9, ups=3.81, wpb=3551, bsz=137.3, num_updates=68000, lr=0.000121268, gnorm=1.158, train_wall=19, wall=0
2024-05-30 20:53:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:53:30 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 3.958 | nll_loss 2.376 | ppl 5.19 | wps 56150.1 | wpb 2685.2 | bsz 107.1 | num_updates 68000 | best_loss 11.059
2024-05-30 20:53:30 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:53:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_61_68000.pt (epoch 61 @ 68000 updates, score 3.958) (writing took 3.411128747742623 seconds)
2024-05-30 20:53:52 | INFO | train_inner | epoch 061:    180 / 1132 loss=3.019, nll_loss=1.418, ppl=2.67, wps=13601.2, ups=3.87, wpb=3511.3, bsz=145.8, num_updates=68100, lr=0.000121179, gnorm=1.158, train_wall=19, wall=0
2024-05-30 20:54:11 | INFO | train_inner | epoch 061:    280 / 1132 loss=3.049, nll_loss=1.449, ppl=2.73, wps=18370.8, ups=5.18, wpb=3543.4, bsz=140.6, num_updates=68200, lr=0.00012109, gnorm=1.193, train_wall=19, wall=0
2024-05-30 20:54:30 | INFO | train_inner | epoch 061:    380 / 1132 loss=3.055, nll_loss=1.456, ppl=2.74, wps=18345.1, ups=5.24, wpb=3500.5, bsz=139.3, num_updates=68300, lr=0.000121001, gnorm=1.184, train_wall=19, wall=0
2024-05-30 20:54:49 | INFO | train_inner | epoch 061:    480 / 1132 loss=3.065, nll_loss=1.471, ppl=2.77, wps=18852.4, ups=5.25, wpb=3588, bsz=144.2, num_updates=68400, lr=0.000120913, gnorm=1.158, train_wall=19, wall=0
2024-05-30 20:55:09 | INFO | train_inner | epoch 061:    580 / 1132 loss=3.072, nll_loss=1.478, ppl=2.79, wps=18711, ups=5.15, wpb=3636, bsz=149.8, num_updates=68500, lr=0.000120824, gnorm=1.154, train_wall=19, wall=0
2024-05-30 20:55:28 | INFO | train_inner | epoch 061:    680 / 1132 loss=3.096, nll_loss=1.503, ppl=2.83, wps=18445.7, ups=5.26, wpb=3508.8, bsz=129.4, num_updates=68600, lr=0.000120736, gnorm=1.222, train_wall=19, wall=0
2024-05-30 20:55:47 | INFO | train_inner | epoch 061:    780 / 1132 loss=3.082, nll_loss=1.492, ppl=2.81, wps=18670.4, ups=5.26, wpb=3547.7, bsz=142.8, num_updates=68700, lr=0.000120648, gnorm=1.19, train_wall=19, wall=0
2024-05-30 20:56:06 | INFO | train_inner | epoch 061:    880 / 1132 loss=3.083, nll_loss=1.493, ppl=2.81, wps=18843, ups=5.19, wpb=3628.4, bsz=149.8, num_updates=68800, lr=0.000120561, gnorm=1.155, train_wall=19, wall=0
2024-05-30 20:56:25 | INFO | train_inner | epoch 061:    980 / 1132 loss=3.103, nll_loss=1.517, ppl=2.86, wps=19024.4, ups=5.28, wpb=3606.2, bsz=140.7, num_updates=68900, lr=0.000120473, gnorm=1.19, train_wall=19, wall=0
2024-05-30 20:56:44 | INFO | train_inner | epoch 061:   1080 / 1132 loss=3.112, nll_loss=1.524, ppl=2.88, wps=18585.7, ups=5.3, wpb=3508.1, bsz=129.8, num_updates=69000, lr=0.000120386, gnorm=1.219, train_wall=19, wall=0
2024-05-30 20:56:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:56:47 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 3.942 | nll_loss 2.36 | ppl 5.13 | wps 56055.2 | wpb 2685.2 | bsz 107.1 | num_updates 69000 | best_loss 11.059
2024-05-30 20:56:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:56:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_61_69000.pt (epoch 61 @ 69000 updates, score 3.942) (writing took 3.221711441874504 seconds)
2024-05-30 20:57:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 20:57:05 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 3.951 | nll_loss 2.374 | ppl 5.18 | wps 55543.2 | wpb 2685.2 | bsz 107.1 | num_updates 69052 | best_loss 11.059
2024-05-30 20:57:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 20:57:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 61 @ 69052 updates, score 3.951) (writing took 2.826577281113714 seconds)
2024-05-30 20:57:08 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2024-05-30 20:57:08 | INFO | train | epoch 061 | loss 3.071 | nll_loss 1.477 | ppl 2.78 | wps 16915.2 | ups 4.76 | wpb 3556.4 | bsz 141.6 | num_updates 69052 | lr 0.000120341 | gnorm 1.18 | train_wall 216 | wall 0
2024-05-30 20:57:08 | INFO | fairseq.trainer | begin training epoch 62
2024-05-30 20:57:17 | INFO | train_inner | epoch 062:     48 / 1132 loss=3.042, nll_loss=1.448, ppl=2.73, wps=10766.9, ups=2.99, wpb=3606.7, bsz=157.9, num_updates=69100, lr=0.000120299, gnorm=1.139, train_wall=20, wall=0
2024-05-30 20:57:37 | INFO | train_inner | epoch 062:    148 / 1132 loss=3.009, nll_loss=1.408, ppl=2.65, wps=18654.1, ups=5.23, wpb=3569.7, bsz=152.9, num_updates=69200, lr=0.000120212, gnorm=1.135, train_wall=19, wall=0
2024-05-30 20:57:56 | INFO | train_inner | epoch 062:    248 / 1132 loss=3.034, nll_loss=1.434, ppl=2.7, wps=18918.1, ups=5.18, wpb=3653.1, bsz=153.5, num_updates=69300, lr=0.000120125, gnorm=1.146, train_wall=19, wall=0
2024-05-30 20:58:15 | INFO | train_inner | epoch 062:    348 / 1132 loss=3.042, nll_loss=1.444, ppl=2.72, wps=18595.9, ups=5.23, wpb=3553.5, bsz=153.2, num_updates=69400, lr=0.000120038, gnorm=1.158, train_wall=19, wall=0
2024-05-30 20:58:34 | INFO | train_inner | epoch 062:    448 / 1132 loss=3.08, nll_loss=1.485, ppl=2.8, wps=18786.9, ups=5.25, wpb=3577.9, bsz=127.8, num_updates=69500, lr=0.000119952, gnorm=1.214, train_wall=19, wall=0
2024-05-30 20:58:53 | INFO | train_inner | epoch 062:    548 / 1132 loss=3.057, nll_loss=1.461, ppl=2.75, wps=18745.5, ups=5.28, wpb=3552.6, bsz=140.6, num_updates=69600, lr=0.000119866, gnorm=1.177, train_wall=19, wall=0
2024-05-30 20:59:12 | INFO | train_inner | epoch 062:    648 / 1132 loss=3.08, nll_loss=1.487, ppl=2.8, wps=18959.9, ups=5.28, wpb=3590, bsz=128.6, num_updates=69700, lr=0.00011978, gnorm=1.182, train_wall=19, wall=0
2024-05-30 20:59:31 | INFO | train_inner | epoch 062:    748 / 1132 loss=3.094, nll_loss=1.503, ppl=2.83, wps=18569.4, ups=5.23, wpb=3549.7, bsz=135.2, num_updates=69800, lr=0.000119694, gnorm=1.196, train_wall=19, wall=0
2024-05-30 20:59:50 | INFO | train_inner | epoch 062:    848 / 1132 loss=3.069, nll_loss=1.476, ppl=2.78, wps=18671.5, ups=5.33, wpb=3505.9, bsz=137, num_updates=69900, lr=0.000119608, gnorm=1.203, train_wall=19, wall=0
2024-05-30 21:00:09 | INFO | train_inner | epoch 062:    948 / 1132 loss=3.084, nll_loss=1.49, ppl=2.81, wps=18140.3, ups=5.32, wpb=3408.8, bsz=127.6, num_updates=70000, lr=0.000119523, gnorm=1.231, train_wall=19, wall=0
2024-05-30 21:00:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:00:12 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 3.949 | nll_loss 2.373 | ppl 5.18 | wps 55971.8 | wpb 2685.2 | bsz 107.1 | num_updates 70000 | best_loss 11.059
2024-05-30 21:00:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:00:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_62_70000.pt (epoch 62 @ 70000 updates, score 3.949) (writing took 3.4296553819440305 seconds)
2024-05-30 21:00:36 | INFO | train_inner | epoch 062:   1048 / 1132 loss=3.069, nll_loss=1.479, ppl=2.79, wps=13233.4, ups=3.7, wpb=3580.7, bsz=156.2, num_updates=70100, lr=0.000119438, gnorm=1.16, train_wall=20, wall=0
2024-05-30 21:00:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:00:56 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 3.954 | nll_loss 2.373 | ppl 5.18 | wps 55778.7 | wpb 2685.2 | bsz 107.1 | num_updates 70184 | best_loss 11.059
2024-05-30 21:00:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:00:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 62 @ 70184 updates, score 3.954) (writing took 2.948200055398047 seconds)
2024-05-30 21:00:59 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2024-05-30 21:00:59 | INFO | train | epoch 062 | loss 3.063 | nll_loss 1.468 | ppl 2.77 | wps 17461.8 | ups 4.91 | wpb 3556.4 | bsz 141.6 | num_updates 70184 | lr 0.000119366 | gnorm 1.179 | train_wall 215 | wall 0
2024-05-30 21:00:59 | INFO | fairseq.trainer | begin training epoch 63
2024-05-30 21:01:02 | INFO | train_inner | epoch 063:     16 / 1132 loss=3.094, nll_loss=1.504, ppl=2.84, wps=13616.9, ups=3.82, wpb=3562, bsz=135.4, num_updates=70200, lr=0.000119352, gnorm=1.187, train_wall=19, wall=0
2024-05-30 21:01:22 | INFO | train_inner | epoch 063:    116 / 1132 loss=3.023, nll_loss=1.419, ppl=2.67, wps=17679.7, ups=5.01, wpb=3529.3, bsz=124.6, num_updates=70300, lr=0.000119268, gnorm=1.17, train_wall=20, wall=0
2024-05-30 21:01:41 | INFO | train_inner | epoch 063:    216 / 1132 loss=3.023, nll_loss=1.423, ppl=2.68, wps=18157.6, ups=5.12, wpb=3548.6, bsz=131.3, num_updates=70400, lr=0.000119183, gnorm=1.173, train_wall=19, wall=0
2024-05-30 21:02:01 | INFO | train_inner | epoch 063:    316 / 1132 loss=3.022, nll_loss=1.422, ppl=2.68, wps=18429.2, ups=5.1, wpb=3615, bsz=162.6, num_updates=70500, lr=0.000119098, gnorm=1.143, train_wall=19, wall=0
2024-05-30 21:02:20 | INFO | train_inner | epoch 063:    416 / 1132 loss=3.048, nll_loss=1.452, ppl=2.74, wps=18755.1, ups=5.21, wpb=3596.7, bsz=140.9, num_updates=70600, lr=0.000119014, gnorm=1.174, train_wall=19, wall=0
2024-05-30 21:02:39 | INFO | train_inner | epoch 063:    516 / 1132 loss=3.066, nll_loss=1.471, ppl=2.77, wps=18702.5, ups=5.25, wpb=3559.4, bsz=134.4, num_updates=70700, lr=0.00011893, gnorm=1.193, train_wall=19, wall=0
2024-05-30 21:02:58 | INFO | train_inner | epoch 063:    616 / 1132 loss=3.047, nll_loss=1.45, ppl=2.73, wps=18472.6, ups=5.19, wpb=3559.5, bsz=153.3, num_updates=70800, lr=0.000118846, gnorm=1.176, train_wall=19, wall=0
2024-05-30 21:03:17 | INFO | train_inner | epoch 063:    716 / 1132 loss=3.072, nll_loss=1.478, ppl=2.79, wps=18434.1, ups=5.3, wpb=3478.9, bsz=132.6, num_updates=70900, lr=0.000118762, gnorm=1.217, train_wall=19, wall=0
2024-05-30 21:03:36 | INFO | train_inner | epoch 063:    816 / 1132 loss=3.059, nll_loss=1.466, ppl=2.76, wps=18840.7, ups=5.22, wpb=3612.6, bsz=155.9, num_updates=71000, lr=0.000118678, gnorm=1.184, train_wall=19, wall=0
2024-05-30 21:03:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:03:40 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 3.938 | nll_loss 2.365 | ppl 5.15 | wps 55892.8 | wpb 2685.2 | bsz 107.1 | num_updates 71000 | best_loss 11.059
2024-05-30 21:03:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:03:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_63_71000.pt (epoch 63 @ 71000 updates, score 3.938) (writing took 3.4342068289406598 seconds)
2024-05-30 21:04:03 | INFO | train_inner | epoch 063:    916 / 1132 loss=3.077, nll_loss=1.485, ppl=2.8, wps=13754.8, ups=3.83, wpb=3595.5, bsz=147.8, num_updates=71100, lr=0.000118595, gnorm=1.174, train_wall=19, wall=0
2024-05-30 21:04:21 | INFO | train_inner | epoch 063:   1016 / 1132 loss=3.081, nll_loss=1.491, ppl=2.81, wps=18562.5, ups=5.33, wpb=3483.7, bsz=148.4, num_updates=71200, lr=0.000118511, gnorm=1.236, train_wall=19, wall=0
2024-05-30 21:04:41 | INFO | train_inner | epoch 063:   1116 / 1132 loss=3.102, nll_loss=1.511, ppl=2.85, wps=18462.9, ups=5.23, wpb=3529.1, bsz=128.2, num_updates=71300, lr=0.000118428, gnorm=1.215, train_wall=19, wall=0
2024-05-30 21:04:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:04:47 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 3.946 | nll_loss 2.367 | ppl 5.16 | wps 55746 | wpb 2685.2 | bsz 107.1 | num_updates 71316 | best_loss 11.059
2024-05-30 21:04:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:04:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 63 @ 71316 updates, score 3.946) (writing took 2.8295252206735313 seconds)
2024-05-30 21:04:50 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2024-05-30 21:04:50 | INFO | train | epoch 063 | loss 3.057 | nll_loss 1.461 | ppl 2.75 | wps 17409.2 | ups 4.9 | wpb 3556.4 | bsz 141.6 | num_updates 71316 | lr 0.000118415 | gnorm 1.186 | train_wall 216 | wall 0
2024-05-30 21:04:50 | INFO | fairseq.trainer | begin training epoch 64
2024-05-30 21:05:06 | INFO | train_inner | epoch 064:     84 / 1132 loss=3.029, nll_loss=1.427, ppl=2.69, wps=13734.1, ups=3.93, wpb=3491.5, bsz=131.4, num_updates=71400, lr=0.000118345, gnorm=1.196, train_wall=19, wall=0
2024-05-30 21:05:25 | INFO | train_inner | epoch 064:    184 / 1132 loss=3.003, nll_loss=1.401, ppl=2.64, wps=18869.6, ups=5.22, wpb=3616.5, bsz=154.7, num_updates=71500, lr=0.000118262, gnorm=1.13, train_wall=19, wall=0
2024-05-30 21:05:44 | INFO | train_inner | epoch 064:    284 / 1132 loss=3.033, nll_loss=1.433, ppl=2.7, wps=18912, ups=5.23, wpb=3616.5, bsz=141.4, num_updates=71600, lr=0.00011818, gnorm=1.153, train_wall=19, wall=0
2024-05-30 21:06:03 | INFO | train_inner | epoch 064:    384 / 1132 loss=3.031, nll_loss=1.432, ppl=2.7, wps=18917.8, ups=5.27, wpb=3587.2, bsz=146.5, num_updates=71700, lr=0.000118097, gnorm=1.17, train_wall=19, wall=0
2024-05-30 21:06:22 | INFO | train_inner | epoch 064:    484 / 1132 loss=3.038, nll_loss=1.437, ppl=2.71, wps=18436.4, ups=5.26, wpb=3507.3, bsz=143.4, num_updates=71800, lr=0.000118015, gnorm=1.203, train_wall=19, wall=0
2024-05-30 21:06:41 | INFO | train_inner | epoch 064:    584 / 1132 loss=3.053, nll_loss=1.455, ppl=2.74, wps=18501.8, ups=5.27, wpb=3513.5, bsz=138.8, num_updates=71900, lr=0.000117933, gnorm=1.206, train_wall=19, wall=0
2024-05-30 21:07:00 | INFO | train_inner | epoch 064:    684 / 1132 loss=3.052, nll_loss=1.457, ppl=2.74, wps=18571.4, ups=5.3, wpb=3507.2, bsz=145.8, num_updates=72000, lr=0.000117851, gnorm=1.209, train_wall=19, wall=0
2024-05-30 21:07:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:07:04 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 3.965 | nll_loss 2.383 | ppl 5.22 | wps 55767.5 | wpb 2685.2 | bsz 107.1 | num_updates 72000 | best_loss 11.059
2024-05-30 21:07:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:07:07 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_64_72000.pt (epoch 64 @ 72000 updates, score 3.965) (writing took 3.4465154949575663 seconds)
2024-05-30 21:07:26 | INFO | train_inner | epoch 064:    784 / 1132 loss=3.078, nll_loss=1.485, ppl=2.8, wps=13608.9, ups=3.85, wpb=3531.9, bsz=132, num_updates=72100, lr=0.000117769, gnorm=1.245, train_wall=19, wall=0
2024-05-30 21:07:45 | INFO | train_inner | epoch 064:    884 / 1132 loss=3.075, nll_loss=1.483, ppl=2.8, wps=18959.3, ups=5.24, wpb=3616.7, bsz=139.2, num_updates=72200, lr=0.000117688, gnorm=1.165, train_wall=19, wall=0
2024-05-30 21:08:04 | INFO | train_inner | epoch 064:    984 / 1132 loss=3.071, nll_loss=1.477, ppl=2.78, wps=18412.1, ups=5.23, wpb=3517.2, bsz=137.9, num_updates=72300, lr=0.000117606, gnorm=1.22, train_wall=19, wall=0
2024-05-30 21:08:23 | INFO | train_inner | epoch 064:   1084 / 1132 loss=3.088, nll_loss=1.498, ppl=2.82, wps=18774.2, ups=5.21, wpb=3601.5, bsz=139.8, num_updates=72400, lr=0.000117525, gnorm=1.197, train_wall=19, wall=0
2024-05-30 21:08:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:08:36 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 3.946 | nll_loss 2.362 | ppl 5.14 | wps 55796 | wpb 2685.2 | bsz 107.1 | num_updates 72448 | best_loss 11.059
2024-05-30 21:08:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:08:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 64 @ 72448 updates, score 3.946) (writing took 2.8925341367721558 seconds)
2024-05-30 21:08:39 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2024-05-30 21:08:39 | INFO | train | epoch 064 | loss 3.05 | nll_loss 1.453 | ppl 2.74 | wps 17581.6 | ups 4.94 | wpb 3556.4 | bsz 141.6 | num_updates 72448 | lr 0.000117486 | gnorm 1.189 | train_wall 214 | wall 0
2024-05-30 21:08:39 | INFO | fairseq.trainer | begin training epoch 65
2024-05-30 21:08:49 | INFO | train_inner | epoch 065:     52 / 1132 loss=3.046, nll_loss=1.448, ppl=2.73, wps=14083.9, ups=3.9, wpb=3614.4, bsz=144.1, num_updates=72500, lr=0.000117444, gnorm=1.161, train_wall=19, wall=0
2024-05-30 21:09:08 | INFO | train_inner | epoch 065:    152 / 1132 loss=2.99, nll_loss=1.382, ppl=2.61, wps=18210.6, ups=5.25, wpb=3469.7, bsz=139.3, num_updates=72600, lr=0.000117363, gnorm=1.182, train_wall=19, wall=0
2024-05-30 21:09:27 | INFO | train_inner | epoch 065:    252 / 1132 loss=3.027, nll_loss=1.423, ppl=2.68, wps=18515.5, ups=5.29, wpb=3503.3, bsz=130.5, num_updates=72700, lr=0.000117282, gnorm=1.203, train_wall=19, wall=0
2024-05-30 21:09:46 | INFO | train_inner | epoch 065:    352 / 1132 loss=3.041, nll_loss=1.441, ppl=2.71, wps=18363.1, ups=5.23, wpb=3508.5, bsz=135.5, num_updates=72800, lr=0.000117202, gnorm=1.221, train_wall=19, wall=0
2024-05-30 21:10:05 | INFO | train_inner | epoch 065:    452 / 1132 loss=3.027, nll_loss=1.427, ppl=2.69, wps=18743.5, ups=5.26, wpb=3564.1, bsz=143, num_updates=72900, lr=0.000117121, gnorm=1.168, train_wall=19, wall=0
2024-05-30 21:10:24 | INFO | train_inner | epoch 065:    552 / 1132 loss=3.041, nll_loss=1.446, ppl=2.72, wps=18969.6, ups=5.18, wpb=3659.5, bsz=153, num_updates=73000, lr=0.000117041, gnorm=1.15, train_wall=19, wall=0
2024-05-30 21:10:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:10:28 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 3.971 | nll_loss 2.392 | ppl 5.25 | wps 56025.5 | wpb 2685.2 | bsz 107.1 | num_updates 73000 | best_loss 11.059
2024-05-30 21:10:28 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:10:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_65_73000.pt (epoch 65 @ 73000 updates, score 3.971) (writing took 3.3634035931900144 seconds)
2024-05-30 21:10:50 | INFO | train_inner | epoch 065:    652 / 1132 loss=3.066, nll_loss=1.471, ppl=2.77, wps=13883.2, ups=3.85, wpb=3607.3, bsz=142.2, num_updates=73100, lr=0.000116961, gnorm=1.221, train_wall=19, wall=0
2024-05-30 21:11:10 | INFO | train_inner | epoch 065:    752 / 1132 loss=3.034, nll_loss=1.436, ppl=2.71, wps=18667.8, ups=5.24, wpb=3562.7, bsz=157.4, num_updates=73200, lr=0.000116881, gnorm=1.18, train_wall=19, wall=0
2024-05-30 21:11:29 | INFO | train_inner | epoch 065:    852 / 1132 loss=3.071, nll_loss=1.476, ppl=2.78, wps=18234.3, ups=5.16, wpb=3533.6, bsz=129, num_updates=73300, lr=0.000116801, gnorm=1.211, train_wall=19, wall=0
2024-05-30 21:11:48 | INFO | train_inner | epoch 065:    952 / 1132 loss=3.059, nll_loss=1.464, ppl=2.76, wps=18453.3, ups=5.19, wpb=3555.6, bsz=146.2, num_updates=73400, lr=0.000116722, gnorm=1.195, train_wall=19, wall=0
2024-05-30 21:12:07 | INFO | train_inner | epoch 065:   1052 / 1132 loss=3.056, nll_loss=1.463, ppl=2.76, wps=18626, ups=5.25, wpb=3544.6, bsz=153, num_updates=73500, lr=0.000116642, gnorm=1.191, train_wall=19, wall=0
2024-05-30 21:12:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:12:26 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 3.946 | nll_loss 2.364 | ppl 5.15 | wps 55789 | wpb 2685.2 | bsz 107.1 | num_updates 73580 | best_loss 11.059
2024-05-30 21:12:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:12:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 65 @ 73580 updates, score 3.946) (writing took 2.9075813060626388 seconds)
2024-05-30 21:12:29 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2024-05-30 21:12:29 | INFO | train | epoch 065 | loss 3.043 | nll_loss 1.445 | ppl 2.72 | wps 17517 | ups 4.93 | wpb 3556.4 | bsz 141.6 | num_updates 73580 | lr 0.000116579 | gnorm 1.19 | train_wall 215 | wall 0
2024-05-30 21:12:29 | INFO | fairseq.trainer | begin training epoch 66
2024-05-30 21:12:33 | INFO | train_inner | epoch 066:     20 / 1132 loss=3.068, nll_loss=1.476, ppl=2.78, wps=13837.4, ups=3.85, wpb=3596.8, bsz=128.6, num_updates=73600, lr=0.000116563, gnorm=1.178, train_wall=19, wall=0
2024-05-30 21:12:54 | INFO | train_inner | epoch 066:    120 / 1132 loss=2.969, nll_loss=1.363, ppl=2.57, wps=17086, ups=4.73, wpb=3613.6, bsz=171.1, num_updates=73700, lr=0.000116484, gnorm=1.142, train_wall=21, wall=0
2024-05-30 21:13:14 | INFO | train_inner | epoch 066:    220 / 1132 loss=3.01, nll_loss=1.407, ppl=2.65, wps=18586.8, ups=5.17, wpb=3592.6, bsz=145.5, num_updates=73800, lr=0.000116405, gnorm=1.173, train_wall=19, wall=0
2024-05-30 21:13:33 | INFO | train_inner | epoch 066:    320 / 1132 loss=3.012, nll_loss=1.41, ppl=2.66, wps=18862.5, ups=5.26, wpb=3585.4, bsz=150.4, num_updates=73900, lr=0.000116326, gnorm=1.172, train_wall=19, wall=0
2024-05-30 21:13:51 | INFO | train_inner | epoch 066:    420 / 1132 loss=3.026, nll_loss=1.423, ppl=2.68, wps=18356.5, ups=5.32, wpb=3448.5, bsz=123.6, num_updates=74000, lr=0.000116248, gnorm=1.222, train_wall=19, wall=0
2024-05-30 21:13:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:13:55 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 3.968 | nll_loss 2.39 | ppl 5.24 | wps 55795.2 | wpb 2685.2 | bsz 107.1 | num_updates 74000 | best_loss 11.059
2024-05-30 21:13:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:13:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_66_74000.pt (epoch 66 @ 74000 updates, score 3.968) (writing took 3.4005510238930583 seconds)
2024-05-30 21:14:18 | INFO | train_inner | epoch 066:    520 / 1132 loss=3.043, nll_loss=1.444, ppl=2.72, wps=13748.8, ups=3.81, wpb=3606.1, bsz=131.8, num_updates=74100, lr=0.000116169, gnorm=1.188, train_wall=19, wall=0
2024-05-30 21:14:37 | INFO | train_inner | epoch 066:    620 / 1132 loss=3.062, nll_loss=1.465, ppl=2.76, wps=18728.5, ups=5.31, wpb=3529.8, bsz=123.1, num_updates=74200, lr=0.000116091, gnorm=1.22, train_wall=19, wall=0
2024-05-30 21:14:56 | INFO | train_inner | epoch 066:    720 / 1132 loss=3.046, nll_loss=1.446, ppl=2.72, wps=18325.2, ups=5.23, wpb=3505.3, bsz=140.4, num_updates=74300, lr=0.000116013, gnorm=1.228, train_wall=19, wall=0
2024-05-30 21:15:15 | INFO | train_inner | epoch 066:    820 / 1132 loss=3.05, nll_loss=1.453, ppl=2.74, wps=18342.4, ups=5.24, wpb=3499.3, bsz=142.3, num_updates=74400, lr=0.000115935, gnorm=1.229, train_wall=19, wall=0
2024-05-30 21:15:34 | INFO | train_inner | epoch 066:    920 / 1132 loss=3.053, nll_loss=1.457, ppl=2.75, wps=18486, ups=5.2, wpb=3558.3, bsz=145.5, num_updates=74500, lr=0.000115857, gnorm=1.193, train_wall=19, wall=0
2024-05-30 21:15:53 | INFO | train_inner | epoch 066:   1020 / 1132 loss=3.06, nll_loss=1.469, ppl=2.77, wps=18863.3, ups=5.24, wpb=3598.5, bsz=148.6, num_updates=74600, lr=0.000115779, gnorm=1.179, train_wall=19, wall=0
2024-05-30 21:16:12 | INFO | train_inner | epoch 066:   1120 / 1132 loss=3.066, nll_loss=1.472, ppl=2.77, wps=18585.9, ups=5.23, wpb=3552.9, bsz=139.9, num_updates=74700, lr=0.000115702, gnorm=1.218, train_wall=19, wall=0
2024-05-30 21:16:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:16:18 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 3.949 | nll_loss 2.378 | ppl 5.2 | wps 55846.6 | wpb 2685.2 | bsz 107.1 | num_updates 74712 | best_loss 11.059
2024-05-30 21:16:18 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:16:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 66 @ 74712 updates, score 3.949) (writing took 2.9197157346643507 seconds)
2024-05-30 21:16:21 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2024-05-30 21:16:21 | INFO | train | epoch 066 | loss 3.037 | nll_loss 1.438 | ppl 2.71 | wps 17343.7 | ups 4.88 | wpb 3556.4 | bsz 141.6 | num_updates 74712 | lr 0.000115692 | gnorm 1.195 | train_wall 217 | wall 0
2024-05-30 21:16:21 | INFO | fairseq.trainer | begin training epoch 67
2024-05-30 21:16:38 | INFO | train_inner | epoch 067:     88 / 1132 loss=3.018, nll_loss=1.416, ppl=2.67, wps=13932.7, ups=3.9, wpb=3568.5, bsz=131.8, num_updates=74800, lr=0.000115624, gnorm=1.174, train_wall=19, wall=0
2024-05-30 21:16:57 | INFO | train_inner | epoch 067:    188 / 1132 loss=2.983, nll_loss=1.377, ppl=2.6, wps=18865.1, ups=5.23, wpb=3606.7, bsz=158.3, num_updates=74900, lr=0.000115547, gnorm=1.152, train_wall=19, wall=0
2024-05-30 21:17:16 | INFO | train_inner | epoch 067:    288 / 1132 loss=2.999, nll_loss=1.395, ppl=2.63, wps=18821.9, ups=5.22, wpb=3607.3, bsz=149.8, num_updates=75000, lr=0.00011547, gnorm=1.159, train_wall=19, wall=0
2024-05-30 21:17:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:17:20 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 3.954 | nll_loss 2.379 | ppl 5.2 | wps 56003.7 | wpb 2685.2 | bsz 107.1 | num_updates 75000 | best_loss 11.059
2024-05-30 21:17:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:17:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_67_75000.pt (epoch 67 @ 75000 updates, score 3.954) (writing took 3.4959737230092287 seconds)
2024-05-30 21:17:42 | INFO | train_inner | epoch 067:    388 / 1132 loss=3.013, nll_loss=1.409, ppl=2.66, wps=13450.7, ups=3.87, wpb=3474.9, bsz=130.7, num_updates=75100, lr=0.000115393, gnorm=1.222, train_wall=19, wall=0
2024-05-30 21:18:01 | INFO | train_inner | epoch 067:    488 / 1132 loss=3.023, nll_loss=1.424, ppl=2.68, wps=18628.1, ups=5.29, wpb=3523.5, bsz=141.3, num_updates=75200, lr=0.000115316, gnorm=1.203, train_wall=19, wall=0
2024-05-30 21:18:20 | INFO | train_inner | epoch 067:    588 / 1132 loss=3.028, nll_loss=1.425, ppl=2.69, wps=18600.2, ups=5.23, wpb=3555.7, bsz=139.9, num_updates=75300, lr=0.00011524, gnorm=1.206, train_wall=19, wall=0
2024-05-30 21:18:39 | INFO | train_inner | epoch 067:    688 / 1132 loss=3.038, nll_loss=1.44, ppl=2.71, wps=18720.6, ups=5.2, wpb=3600.2, bsz=154.9, num_updates=75400, lr=0.000115163, gnorm=1.193, train_wall=19, wall=0
2024-05-30 21:18:58 | INFO | train_inner | epoch 067:    788 / 1132 loss=3.049, nll_loss=1.455, ppl=2.74, wps=18814.3, ups=5.3, wpb=3549.4, bsz=142.2, num_updates=75500, lr=0.000115087, gnorm=1.208, train_wall=19, wall=0
2024-05-30 21:19:17 | INFO | train_inner | epoch 067:    888 / 1132 loss=3.049, nll_loss=1.455, ppl=2.74, wps=19121.1, ups=5.32, wpb=3593.2, bsz=139.6, num_updates=75600, lr=0.000115011, gnorm=1.201, train_wall=19, wall=0
2024-05-30 21:19:36 | INFO | train_inner | epoch 067:    988 / 1132 loss=3.071, nll_loss=1.474, ppl=2.78, wps=17983.4, ups=5.29, wpb=3401.4, bsz=122.2, num_updates=75700, lr=0.000114935, gnorm=1.268, train_wall=19, wall=0
2024-05-30 21:19:55 | INFO | train_inner | epoch 067:   1088 / 1132 loss=3.06, nll_loss=1.466, ppl=2.76, wps=18901.9, ups=5.21, wpb=3625.8, bsz=146.5, num_updates=75800, lr=0.000114859, gnorm=1.178, train_wall=19, wall=0
2024-05-30 21:20:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:20:07 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 3.949 | nll_loss 2.373 | ppl 5.18 | wps 55748.8 | wpb 2685.2 | bsz 107.1 | num_updates 75844 | best_loss 11.059
2024-05-30 21:20:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:20:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 67 @ 75844 updates, score 3.949) (writing took 2.9412644980475307 seconds)
2024-05-30 21:20:10 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2024-05-30 21:20:10 | INFO | train | epoch 067 | loss 3.031 | nll_loss 1.431 | ppl 2.7 | wps 17578.7 | ups 4.94 | wpb 3556.4 | bsz 141.6 | num_updates 75844 | lr 0.000114826 | gnorm 1.197 | train_wall 214 | wall 0
2024-05-30 21:20:10 | INFO | fairseq.trainer | begin training epoch 68
2024-05-30 21:20:21 | INFO | train_inner | epoch 068:     56 / 1132 loss=3.018, nll_loss=1.415, ppl=2.67, wps=13620.2, ups=3.86, wpb=3530.1, bsz=136.6, num_updates=75900, lr=0.000114783, gnorm=1.189, train_wall=19, wall=0
2024-05-30 21:20:40 | INFO | train_inner | epoch 068:    156 / 1132 loss=2.98, nll_loss=1.375, ppl=2.59, wps=18872, ups=5.3, wpb=3561.1, bsz=147.3, num_updates=76000, lr=0.000114708, gnorm=1.166, train_wall=19, wall=0
2024-05-30 21:20:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:20:43 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 3.979 | nll_loss 2.403 | ppl 5.29 | wps 55927.2 | wpb 2685.2 | bsz 107.1 | num_updates 76000 | best_loss 11.059
2024-05-30 21:20:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:20:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_68_76000.pt (epoch 68 @ 76000 updates, score 3.979) (writing took 5.441121960990131 seconds)
2024-05-30 21:21:08 | INFO | train_inner | epoch 068:    256 / 1132 loss=2.994, nll_loss=1.39, ppl=2.62, wps=12972.1, ups=3.55, wpb=3654.8, bsz=151.1, num_updates=76100, lr=0.000114632, gnorm=1.158, train_wall=19, wall=0
2024-05-30 21:21:27 | INFO | train_inner | epoch 068:    356 / 1132 loss=3.002, nll_loss=1.396, ppl=2.63, wps=18498.5, ups=5.26, wpb=3519.8, bsz=138.2, num_updates=76200, lr=0.000114557, gnorm=1.215, train_wall=19, wall=0
2024-05-30 21:21:46 | INFO | train_inner | epoch 068:    456 / 1132 loss=3.024, nll_loss=1.423, ppl=2.68, wps=18752.2, ups=5.28, wpb=3551.9, bsz=131.4, num_updates=76300, lr=0.000114482, gnorm=1.192, train_wall=19, wall=0
2024-05-30 21:22:05 | INFO | train_inner | epoch 068:    556 / 1132 loss=3.021, nll_loss=1.42, ppl=2.68, wps=18706.4, ups=5.22, wpb=3582.2, bsz=153.5, num_updates=76400, lr=0.000114407, gnorm=1.213, train_wall=19, wall=0
2024-05-30 21:22:24 | INFO | train_inner | epoch 068:    656 / 1132 loss=3.022, nll_loss=1.419, ppl=2.67, wps=18076.4, ups=5.29, wpb=3418.2, bsz=133.1, num_updates=76500, lr=0.000114332, gnorm=1.253, train_wall=19, wall=0
2024-05-30 21:22:43 | INFO | train_inner | epoch 068:    756 / 1132 loss=3.023, nll_loss=1.425, ppl=2.68, wps=18746.9, ups=5.24, wpb=3580.5, bsz=157, num_updates=76600, lr=0.000114258, gnorm=1.216, train_wall=19, wall=0
2024-05-30 21:23:02 | INFO | train_inner | epoch 068:    856 / 1132 loss=3.042, nll_loss=1.446, ppl=2.72, wps=18651.6, ups=5.16, wpb=3617.4, bsz=151.5, num_updates=76700, lr=0.000114183, gnorm=1.18, train_wall=19, wall=0
2024-05-30 21:23:22 | INFO | train_inner | epoch 068:    956 / 1132 loss=3.076, nll_loss=1.482, ppl=2.79, wps=18946.7, ups=5.21, wpb=3634.3, bsz=128.6, num_updates=76800, lr=0.000114109, gnorm=1.19, train_wall=19, wall=0
2024-05-30 21:23:40 | INFO | train_inner | epoch 068:   1056 / 1132 loss=3.066, nll_loss=1.472, ppl=2.77, wps=18717.5, ups=5.32, wpb=3515.1, bsz=121.4, num_updates=76900, lr=0.000114035, gnorm=1.228, train_wall=19, wall=0
2024-05-30 21:23:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:23:58 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 3.967 | nll_loss 2.388 | ppl 5.24 | wps 56128.1 | wpb 2685.2 | bsz 107.1 | num_updates 76976 | best_loss 11.059
2024-05-30 21:23:58 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:24:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 68 @ 76976 updates, score 3.967) (writing took 3.1366039840504527 seconds)
2024-05-30 21:24:01 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2024-05-30 21:24:01 | INFO | train | epoch 068 | loss 3.024 | nll_loss 1.424 | ppl 2.68 | wps 17381.7 | ups 4.89 | wpb 3556.4 | bsz 141.6 | num_updates 76976 | lr 0.000113978 | gnorm 1.201 | train_wall 214 | wall 0
2024-05-30 21:24:01 | INFO | fairseq.trainer | begin training epoch 69
2024-05-30 21:24:06 | INFO | train_inner | epoch 069:     24 / 1132 loss=3.044, nll_loss=1.445, ppl=2.72, wps=13681, ups=3.88, wpb=3527.1, bsz=134.2, num_updates=77000, lr=0.000113961, gnorm=1.222, train_wall=19, wall=0
2024-05-30 21:24:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:24:10 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 3.963 | nll_loss 2.383 | ppl 5.22 | wps 55883.6 | wpb 2685.2 | bsz 107.1 | num_updates 77000 | best_loss 11.059
2024-05-30 21:24:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:24:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_69_77000.pt (epoch 69 @ 77000 updates, score 3.963) (writing took 3.7354977992363274 seconds)
2024-05-30 21:24:34 | INFO | train_inner | epoch 069:    124 / 1132 loss=2.98, nll_loss=1.371, ppl=2.59, wps=13258.9, ups=3.64, wpb=3639.1, bsz=137.8, num_updates=77100, lr=0.000113887, gnorm=1.153, train_wall=20, wall=0
2024-05-30 21:24:53 | INFO | train_inner | epoch 069:    224 / 1132 loss=2.977, nll_loss=1.368, ppl=2.58, wps=17714.2, ups=5.06, wpb=3501.9, bsz=158.7, num_updates=77200, lr=0.000113813, gnorm=1.208, train_wall=20, wall=0
2024-05-30 21:25:13 | INFO | train_inner | epoch 069:    324 / 1132 loss=3.013, nll_loss=1.412, ppl=2.66, wps=18623.5, ups=5.1, wpb=3648.7, bsz=139.9, num_updates=77300, lr=0.000113739, gnorm=1.175, train_wall=19, wall=0
2024-05-30 21:25:32 | INFO | train_inner | epoch 069:    424 / 1132 loss=3.016, nll_loss=1.413, ppl=2.66, wps=18727.8, ups=5.28, wpb=3549, bsz=128.4, num_updates=77400, lr=0.000113666, gnorm=1.221, train_wall=19, wall=0
2024-05-30 21:25:51 | INFO | train_inner | epoch 069:    524 / 1132 loss=2.998, nll_loss=1.395, ppl=2.63, wps=18774.9, ups=5.28, wpb=3558.4, bsz=145.4, num_updates=77500, lr=0.000113592, gnorm=1.183, train_wall=19, wall=0
2024-05-30 21:26:10 | INFO | train_inner | epoch 069:    624 / 1132 loss=3.013, nll_loss=1.41, ppl=2.66, wps=18421.1, ups=5.19, wpb=3549.7, bsz=145.6, num_updates=77600, lr=0.000113519, gnorm=1.217, train_wall=19, wall=0
2024-05-30 21:26:29 | INFO | train_inner | epoch 069:    724 / 1132 loss=3.04, nll_loss=1.439, ppl=2.71, wps=18262.5, ups=5.32, wpb=3430.9, bsz=129.9, num_updates=77700, lr=0.000113446, gnorm=1.255, train_wall=19, wall=0
2024-05-30 21:26:48 | INFO | train_inner | epoch 069:    824 / 1132 loss=3.035, nll_loss=1.436, ppl=2.71, wps=18696.1, ups=5.26, wpb=3555.7, bsz=141.9, num_updates=77800, lr=0.000113373, gnorm=1.203, train_wall=19, wall=0
2024-05-30 21:27:07 | INFO | train_inner | epoch 069:    924 / 1132 loss=3.037, nll_loss=1.439, ppl=2.71, wps=19248, ups=5.36, wpb=3588.9, bsz=143.8, num_updates=77900, lr=0.0001133, gnorm=1.203, train_wall=19, wall=0
2024-05-30 21:27:26 | INFO | train_inner | epoch 069:   1024 / 1132 loss=3.038, nll_loss=1.44, ppl=2.71, wps=18460.9, ups=5.28, wpb=3497.2, bsz=148.2, num_updates=78000, lr=0.000113228, gnorm=1.247, train_wall=19, wall=0
2024-05-30 21:27:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:27:29 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 3.968 | nll_loss 2.387 | ppl 5.23 | wps 56037.9 | wpb 2685.2 | bsz 107.1 | num_updates 78000 | best_loss 11.059
2024-05-30 21:27:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:27:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_69_78000.pt (epoch 69 @ 78000 updates, score 3.968) (writing took 3.2785518299788237 seconds)
2024-05-30 21:27:53 | INFO | train_inner | epoch 069:   1124 / 1132 loss=3.044, nll_loss=1.448, ppl=2.73, wps=13209.7, ups=3.68, wpb=3590.2, bsz=149.4, num_updates=78100, lr=0.000113155, gnorm=1.201, train_wall=20, wall=0
2024-05-30 21:27:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:27:58 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 3.949 | nll_loss 2.373 | ppl 5.18 | wps 55587.1 | wpb 2685.2 | bsz 107.1 | num_updates 78108 | best_loss 11.059
2024-05-30 21:27:58 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:28:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 69 @ 78108 updates, score 3.949) (writing took 2.7925429069437087 seconds)
2024-05-30 21:28:01 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2024-05-30 21:28:01 | INFO | train | epoch 069 | loss 3.018 | nll_loss 1.416 | ppl 2.67 | wps 16832.4 | ups 4.73 | wpb 3556.4 | bsz 141.6 | num_updates 78108 | lr 0.000113149 | gnorm 1.206 | train_wall 217 | wall 0
2024-05-30 21:28:01 | INFO | fairseq.trainer | begin training epoch 70
2024-05-30 21:28:19 | INFO | train_inner | epoch 070:     92 / 1132 loss=2.996, nll_loss=1.39, ppl=2.62, wps=14067.3, ups=3.88, wpb=3625.7, bsz=131.6, num_updates=78200, lr=0.000113083, gnorm=1.175, train_wall=19, wall=0
2024-05-30 21:28:38 | INFO | train_inner | epoch 070:    192 / 1132 loss=2.969, nll_loss=1.36, ppl=2.57, wps=18816, ups=5.25, wpb=3580.9, bsz=161.4, num_updates=78300, lr=0.000113011, gnorm=1.186, train_wall=19, wall=0
2024-05-30 21:28:57 | INFO | train_inner | epoch 070:    292 / 1132 loss=2.998, nll_loss=1.39, ppl=2.62, wps=18504.5, ups=5.22, wpb=3545.9, bsz=140.3, num_updates=78400, lr=0.000112938, gnorm=1.201, train_wall=19, wall=0
2024-05-30 21:29:16 | INFO | train_inner | epoch 070:    392 / 1132 loss=3.011, nll_loss=1.408, ppl=2.65, wps=18574.3, ups=5.3, wpb=3501.5, bsz=134.6, num_updates=78500, lr=0.000112867, gnorm=1.244, train_wall=19, wall=0
2024-05-30 21:29:35 | INFO | train_inner | epoch 070:    492 / 1132 loss=3.026, nll_loss=1.425, ppl=2.69, wps=18940.3, ups=5.2, wpb=3643.2, bsz=134.3, num_updates=78600, lr=0.000112795, gnorm=1.194, train_wall=19, wall=0
2024-05-30 21:29:54 | INFO | train_inner | epoch 070:    592 / 1132 loss=3.021, nll_loss=1.422, ppl=2.68, wps=19029.4, ups=5.18, wpb=3674.8, bsz=138.7, num_updates=78700, lr=0.000112723, gnorm=1.163, train_wall=19, wall=0
2024-05-30 21:30:13 | INFO | train_inner | epoch 070:    692 / 1132 loss=3.015, nll_loss=1.415, ppl=2.67, wps=18702.2, ups=5.25, wpb=3562.3, bsz=147.6, num_updates=78800, lr=0.000112651, gnorm=1.201, train_wall=19, wall=0
2024-05-30 21:30:32 | INFO | train_inner | epoch 070:    792 / 1132 loss=3.007, nll_loss=1.403, ppl=2.64, wps=18064.5, ups=5.3, wpb=3410.2, bsz=139.1, num_updates=78900, lr=0.00011258, gnorm=1.248, train_wall=19, wall=0
2024-05-30 21:30:52 | INFO | train_inner | epoch 070:    892 / 1132 loss=3.022, nll_loss=1.424, ppl=2.68, wps=17867.4, ups=5.06, wpb=3528.8, bsz=138.6, num_updates=79000, lr=0.000112509, gnorm=1.209, train_wall=20, wall=0
2024-05-30 21:30:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:30:55 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 3.96 | nll_loss 2.384 | ppl 5.22 | wps 55582.7 | wpb 2685.2 | bsz 107.1 | num_updates 79000 | best_loss 11.059
2024-05-30 21:30:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:30:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_70_79000.pt (epoch 70 @ 79000 updates, score 3.96) (writing took 3.464270898140967 seconds)
2024-05-30 21:31:18 | INFO | train_inner | epoch 070:    992 / 1132 loss=3.021, nll_loss=1.422, ppl=2.68, wps=13607.6, ups=3.83, wpb=3550.1, bsz=149.8, num_updates=79100, lr=0.000112438, gnorm=1.205, train_wall=19, wall=0
2024-05-30 21:31:36 | INFO | train_inner | epoch 070:   1092 / 1132 loss=3.051, nll_loss=1.455, ppl=2.74, wps=19129.1, ups=5.39, wpb=3552.1, bsz=136.3, num_updates=79200, lr=0.000112367, gnorm=1.234, train_wall=18, wall=0
2024-05-30 21:31:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:31:47 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 3.963 | nll_loss 2.387 | ppl 5.23 | wps 56036.4 | wpb 2685.2 | bsz 107.1 | num_updates 79240 | best_loss 11.059
2024-05-30 21:31:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:31:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 70 @ 79240 updates, score 3.963) (writing took 2.913846192881465 seconds)
2024-05-30 21:31:50 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2024-05-30 21:31:50 | INFO | train | epoch 070 | loss 3.012 | nll_loss 1.41 | ppl 2.66 | wps 17556.6 | ups 4.94 | wpb 3556.4 | bsz 141.6 | num_updates 79240 | lr 0.000112338 | gnorm 1.208 | train_wall 214 | wall 0
2024-05-30 21:31:50 | INFO | fairseq.trainer | begin training epoch 71
2024-05-30 21:32:03 | INFO | train_inner | epoch 071:     60 / 1132 loss=3.005, nll_loss=1.398, ppl=2.64, wps=13368, ups=3.81, wpb=3511.3, bsz=130.6, num_updates=79300, lr=0.000112296, gnorm=1.234, train_wall=20, wall=0
2024-05-30 21:32:22 | INFO | train_inner | epoch 071:    160 / 1132 loss=2.98, nll_loss=1.37, ppl=2.59, wps=18190.1, ups=5.23, wpb=3478.4, bsz=124.4, num_updates=79400, lr=0.000112225, gnorm=1.244, train_wall=19, wall=0
2024-05-30 21:32:41 | INFO | train_inner | epoch 071:    260 / 1132 loss=2.983, nll_loss=1.375, ppl=2.59, wps=18515.2, ups=5.19, wpb=3565.8, bsz=146.2, num_updates=79500, lr=0.000112154, gnorm=1.196, train_wall=19, wall=0
2024-05-30 21:33:00 | INFO | train_inner | epoch 071:    360 / 1132 loss=3, nll_loss=1.396, ppl=2.63, wps=18567.5, ups=5.26, wpb=3532.2, bsz=139.1, num_updates=79600, lr=0.000112084, gnorm=1.206, train_wall=19, wall=0
2024-05-30 21:33:20 | INFO | train_inner | epoch 071:    460 / 1132 loss=2.984, nll_loss=1.378, ppl=2.6, wps=17715.7, ups=4.97, wpb=3561.3, bsz=145.8, num_updates=79700, lr=0.000112014, gnorm=1.201, train_wall=20, wall=0
2024-05-30 21:33:40 | INFO | train_inner | epoch 071:    560 / 1132 loss=3.022, nll_loss=1.419, ppl=2.67, wps=18207.6, ups=5.11, wpb=3559.8, bsz=133.4, num_updates=79800, lr=0.000111943, gnorm=1.233, train_wall=19, wall=0
2024-05-30 21:33:59 | INFO | train_inner | epoch 071:    660 / 1132 loss=3.006, nll_loss=1.403, ppl=2.65, wps=18588.1, ups=5.3, wpb=3509.2, bsz=132.1, num_updates=79900, lr=0.000111873, gnorm=1.204, train_wall=19, wall=0
2024-05-30 21:34:18 | INFO | train_inner | epoch 071:    760 / 1132 loss=3.008, nll_loss=1.407, ppl=2.65, wps=18713.6, ups=5.25, wpb=3566, bsz=152.9, num_updates=80000, lr=0.000111803, gnorm=1.216, train_wall=19, wall=0
2024-05-30 21:34:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:34:21 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 3.971 | nll_loss 2.39 | ppl 5.24 | wps 55830.7 | wpb 2685.2 | bsz 107.1 | num_updates 80000 | best_loss 11.059
2024-05-30 21:34:21 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:34:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_71_80000.pt (epoch 71 @ 80000 updates, score 3.971) (writing took 3.386710229795426 seconds)
2024-05-30 21:34:44 | INFO | train_inner | epoch 071:    860 / 1132 loss=3.01, nll_loss=1.408, ppl=2.65, wps=13810, ups=3.81, wpb=3623.1, bsz=156.5, num_updates=80100, lr=0.000111734, gnorm=1.182, train_wall=19, wall=0
2024-05-30 21:35:03 | INFO | train_inner | epoch 071:    960 / 1132 loss=3.013, nll_loss=1.415, ppl=2.67, wps=18704.1, ups=5.18, wpb=3613.7, bsz=165.9, num_updates=80200, lr=0.000111664, gnorm=1.213, train_wall=19, wall=0
2024-05-30 21:35:22 | INFO | train_inner | epoch 071:   1060 / 1132 loss=3.035, nll_loss=1.438, ppl=2.71, wps=18774.2, ups=5.21, wpb=3603.2, bsz=145.8, num_updates=80300, lr=0.000111594, gnorm=1.223, train_wall=19, wall=0
2024-05-30 21:35:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:35:40 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 3.953 | nll_loss 2.378 | ppl 5.2 | wps 55790.4 | wpb 2685.2 | bsz 107.1 | num_updates 80372 | best_loss 11.059
2024-05-30 21:35:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:35:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 71 @ 80372 updates, score 3.953) (writing took 2.909877578727901 seconds)
2024-05-30 21:35:42 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2024-05-30 21:35:42 | INFO | train | epoch 071 | loss 3.006 | nll_loss 1.403 | ppl 2.64 | wps 17311.2 | ups 4.87 | wpb 3556.4 | bsz 141.6 | num_updates 80372 | lr 0.000111544 | gnorm 1.213 | train_wall 217 | wall 0
2024-05-30 21:35:43 | INFO | fairseq.trainer | begin training epoch 72
2024-05-30 21:35:48 | INFO | train_inner | epoch 072:     28 / 1132 loss=3.019, nll_loss=1.415, ppl=2.67, wps=13624.3, ups=3.92, wpb=3477.7, bsz=126, num_updates=80400, lr=0.000111525, gnorm=1.232, train_wall=19, wall=0
2024-05-30 21:36:07 | INFO | train_inner | epoch 072:    128 / 1132 loss=2.964, nll_loss=1.356, ppl=2.56, wps=18728.2, ups=5.21, wpb=3591.3, bsz=140.3, num_updates=80500, lr=0.000111456, gnorm=1.17, train_wall=19, wall=0
2024-05-30 21:36:26 | INFO | train_inner | epoch 072:    228 / 1132 loss=2.975, nll_loss=1.364, ppl=2.57, wps=18397.9, ups=5.19, wpb=3545, bsz=137.7, num_updates=80600, lr=0.000111386, gnorm=1.204, train_wall=19, wall=0
2024-05-30 21:36:46 | INFO | train_inner | epoch 072:    328 / 1132 loss=2.994, nll_loss=1.39, ppl=2.62, wps=19000.8, ups=5.2, wpb=3654.1, bsz=140.2, num_updates=80700, lr=0.000111317, gnorm=1.18, train_wall=19, wall=0
2024-05-30 21:37:05 | INFO | train_inner | epoch 072:    428 / 1132 loss=2.99, nll_loss=1.379, ppl=2.6, wps=18055, ups=5.24, wpb=3444.2, bsz=137.8, num_updates=80800, lr=0.000111249, gnorm=1.254, train_wall=19, wall=0
2024-05-30 21:37:24 | INFO | train_inner | epoch 072:    528 / 1132 loss=2.991, nll_loss=1.388, ppl=2.62, wps=18798.9, ups=5.23, wpb=3593.5, bsz=146.2, num_updates=80900, lr=0.00011118, gnorm=1.184, train_wall=19, wall=0
2024-05-30 21:37:43 | INFO | train_inner | epoch 072:    628 / 1132 loss=2.994, nll_loss=1.389, ppl=2.62, wps=18655.8, ups=5.23, wpb=3567.5, bsz=148.2, num_updates=81000, lr=0.000111111, gnorm=1.214, train_wall=19, wall=0
2024-05-30 21:37:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:37:46 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 3.971 | nll_loss 2.395 | ppl 5.26 | wps 55938.9 | wpb 2685.2 | bsz 107.1 | num_updates 81000 | best_loss 11.059
2024-05-30 21:37:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:37:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_72_81000.pt (epoch 72 @ 81000 updates, score 3.971) (writing took 3.381106197834015 seconds)
2024-05-30 21:38:09 | INFO | train_inner | epoch 072:    728 / 1132 loss=2.985, nll_loss=1.38, ppl=2.6, wps=13477.4, ups=3.85, wpb=3498.8, bsz=156.5, num_updates=81100, lr=0.000111043, gnorm=1.217, train_wall=19, wall=0
2024-05-30 21:38:28 | INFO | train_inner | epoch 072:    828 / 1132 loss=3.001, nll_loss=1.4, ppl=2.64, wps=18593.5, ups=5.27, wpb=3529.8, bsz=152.5, num_updates=81200, lr=0.000110974, gnorm=1.221, train_wall=19, wall=0
2024-05-30 21:38:47 | INFO | train_inner | epoch 072:    928 / 1132 loss=3.027, nll_loss=1.428, ppl=2.69, wps=18601.8, ups=5.22, wpb=3562.4, bsz=145.9, num_updates=81300, lr=0.000110906, gnorm=1.236, train_wall=19, wall=0
2024-05-30 21:39:06 | INFO | train_inner | epoch 072:   1028 / 1132 loss=3.042, nll_loss=1.444, ppl=2.72, wps=18865.1, ups=5.28, wpb=3571.9, bsz=127.2, num_updates=81400, lr=0.000110838, gnorm=1.241, train_wall=19, wall=0
2024-05-30 21:39:25 | INFO | train_inner | epoch 072:   1128 / 1132 loss=3.057, nll_loss=1.462, ppl=2.75, wps=18772.7, ups=5.25, wpb=3575.3, bsz=127.3, num_updates=81500, lr=0.00011077, gnorm=1.259, train_wall=19, wall=0
2024-05-30 21:39:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:39:29 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 3.971 | nll_loss 2.392 | ppl 5.25 | wps 55895.8 | wpb 2685.2 | bsz 107.1 | num_updates 81504 | best_loss 11.059
2024-05-30 21:39:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:39:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 72 @ 81504 updates, score 3.971) (writing took 3.3002118980512023 seconds)
2024-05-30 21:39:33 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2024-05-30 21:39:33 | INFO | train | epoch 072 | loss 3.001 | nll_loss 1.397 | ppl 2.63 | wps 17492.2 | ups 4.92 | wpb 3556.4 | bsz 141.6 | num_updates 81504 | lr 0.000110767 | gnorm 1.216 | train_wall 215 | wall 0
2024-05-30 21:39:33 | INFO | fairseq.trainer | begin training epoch 73
2024-05-30 21:39:51 | INFO | train_inner | epoch 073:     96 / 1132 loss=2.968, nll_loss=1.357, ppl=2.56, wps=13542.7, ups=3.86, wpb=3508.6, bsz=128.2, num_updates=81600, lr=0.000110702, gnorm=1.218, train_wall=19, wall=0
2024-05-30 21:40:10 | INFO | train_inner | epoch 073:    196 / 1132 loss=2.969, nll_loss=1.359, ppl=2.57, wps=18514.2, ups=5.21, wpb=3552.7, bsz=130.1, num_updates=81700, lr=0.000110634, gnorm=1.191, train_wall=19, wall=0
2024-05-30 21:40:29 | INFO | train_inner | epoch 073:    296 / 1132 loss=2.964, nll_loss=1.353, ppl=2.55, wps=18247.6, ups=5.2, wpb=3506.9, bsz=147.7, num_updates=81800, lr=0.000110566, gnorm=1.236, train_wall=19, wall=0
2024-05-30 21:40:49 | INFO | train_inner | epoch 073:    396 / 1132 loss=2.989, nll_loss=1.382, ppl=2.61, wps=18510.6, ups=5.19, wpb=3568.7, bsz=142.3, num_updates=81900, lr=0.000110499, gnorm=1.204, train_wall=19, wall=0
2024-05-30 21:41:08 | INFO | train_inner | epoch 073:    496 / 1132 loss=2.983, nll_loss=1.378, ppl=2.6, wps=18672.7, ups=5.28, wpb=3539.2, bsz=137, num_updates=82000, lr=0.000110432, gnorm=1.226, train_wall=19, wall=0
2024-05-30 21:41:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:41:11 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 3.991 | nll_loss 2.414 | ppl 5.33 | wps 55678 | wpb 2685.2 | bsz 107.1 | num_updates 82000 | best_loss 11.059
2024-05-30 21:41:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:41:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_73_82000.pt (epoch 73 @ 82000 updates, score 3.991) (writing took 3.396438397001475 seconds)
2024-05-30 21:41:33 | INFO | train_inner | epoch 073:    596 / 1132 loss=2.997, nll_loss=1.391, ppl=2.62, wps=13627.4, ups=3.86, wpb=3526.6, bsz=141.4, num_updates=82100, lr=0.000110364, gnorm=1.231, train_wall=19, wall=0
2024-05-30 21:41:52 | INFO | train_inner | epoch 073:    696 / 1132 loss=2.988, nll_loss=1.383, ppl=2.61, wps=18779.5, ups=5.28, wpb=3556.7, bsz=150.7, num_updates=82200, lr=0.000110297, gnorm=1.199, train_wall=19, wall=0
2024-05-30 21:42:11 | INFO | train_inner | epoch 073:    796 / 1132 loss=3.006, nll_loss=1.408, ppl=2.65, wps=19152.6, ups=5.25, wpb=3650, bsz=155.5, num_updates=82300, lr=0.00011023, gnorm=1.193, train_wall=19, wall=0
2024-05-30 21:42:31 | INFO | train_inner | epoch 073:    896 / 1132 loss=3.008, nll_loss=1.408, ppl=2.65, wps=18705.5, ups=5.23, wpb=3575.9, bsz=146.9, num_updates=82400, lr=0.000110163, gnorm=1.21, train_wall=19, wall=0
2024-05-30 21:42:50 | INFO | train_inner | epoch 073:    996 / 1132 loss=3.041, nll_loss=1.443, ppl=2.72, wps=18987.4, ups=5.17, wpb=3670.3, bsz=141.6, num_updates=82500, lr=0.000110096, gnorm=1.204, train_wall=19, wall=0
2024-05-30 21:43:09 | INFO | train_inner | epoch 073:   1096 / 1132 loss=3.011, nll_loss=1.405, ppl=2.65, wps=18128.9, ups=5.24, wpb=3458, bsz=142.3, num_updates=82600, lr=0.00011003, gnorm=1.27, train_wall=19, wall=0
2024-05-30 21:43:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:43:19 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 3.974 | nll_loss 2.398 | ppl 5.27 | wps 55770.5 | wpb 2685.2 | bsz 107.1 | num_updates 82636 | best_loss 11.059
2024-05-30 21:43:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:43:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 73 @ 82636 updates, score 3.974) (writing took 2.898613940924406 seconds)
2024-05-30 21:43:22 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2024-05-30 21:43:22 | INFO | train | epoch 073 | loss 2.995 | nll_loss 1.391 | ppl 2.62 | wps 17528.9 | ups 4.93 | wpb 3556.4 | bsz 141.6 | num_updates 82636 | lr 0.000110006 | gnorm 1.218 | train_wall 215 | wall 0
2024-05-30 21:43:22 | INFO | fairseq.trainer | begin training epoch 74
2024-05-30 21:43:35 | INFO | train_inner | epoch 074:     64 / 1132 loss=2.992, nll_loss=1.385, ppl=2.61, wps=13854.2, ups=3.89, wpb=3560.8, bsz=131.8, num_updates=82700, lr=0.000109963, gnorm=1.236, train_wall=19, wall=0
2024-05-30 21:43:54 | INFO | train_inner | epoch 074:    164 / 1132 loss=2.957, nll_loss=1.349, ppl=2.55, wps=18899, ups=5.21, wpb=3629.2, bsz=152.7, num_updates=82800, lr=0.000109897, gnorm=1.166, train_wall=19, wall=0
2024-05-30 21:44:13 | INFO | train_inner | epoch 074:    264 / 1132 loss=2.957, nll_loss=1.347, ppl=2.54, wps=18611.4, ups=5.21, wpb=3571.3, bsz=143.4, num_updates=82900, lr=0.00010983, gnorm=1.203, train_wall=19, wall=0
2024-05-30 21:44:32 | INFO | train_inner | epoch 074:    364 / 1132 loss=2.983, nll_loss=1.375, ppl=2.59, wps=18642.5, ups=5.2, wpb=3583.7, bsz=141.8, num_updates=83000, lr=0.000109764, gnorm=1.204, train_wall=19, wall=0
2024-05-30 21:44:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:44:36 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 3.986 | nll_loss 2.405 | ppl 5.3 | wps 55747.4 | wpb 2685.2 | bsz 107.1 | num_updates 83000 | best_loss 11.059
2024-05-30 21:44:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:44:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_74_83000.pt (epoch 74 @ 83000 updates, score 3.986) (writing took 3.4204214462079108 seconds)
2024-05-30 21:44:59 | INFO | train_inner | epoch 074:    464 / 1132 loss=2.99, nll_loss=1.381, ppl=2.6, wps=13558.1, ups=3.81, wpb=3554.2, bsz=143, num_updates=83100, lr=0.000109698, gnorm=1.241, train_wall=19, wall=0
2024-05-30 21:45:18 | INFO | train_inner | epoch 074:    564 / 1132 loss=2.981, nll_loss=1.374, ppl=2.59, wps=18522.9, ups=5.2, wpb=3559.7, bsz=153.4, num_updates=83200, lr=0.000109632, gnorm=1.211, train_wall=19, wall=0
2024-05-30 21:45:36 | INFO | train_inner | epoch 074:    664 / 1132 loss=3.009, nll_loss=1.406, ppl=2.65, wps=19487, ups=5.53, wpb=3523.7, bsz=129.4, num_updates=83300, lr=0.000109566, gnorm=1.251, train_wall=18, wall=0
2024-05-30 21:45:54 | INFO | train_inner | epoch 074:    764 / 1132 loss=3.007, nll_loss=1.406, ppl=2.65, wps=19878, ups=5.51, wpb=3605.8, bsz=134.6, num_updates=83400, lr=0.000109501, gnorm=1.211, train_wall=18, wall=0
2024-05-30 21:46:12 | INFO | train_inner | epoch 074:    864 / 1132 loss=3.005, nll_loss=1.403, ppl=2.64, wps=19548.8, ups=5.49, wpb=3559.1, bsz=141.2, num_updates=83500, lr=0.000109435, gnorm=1.235, train_wall=18, wall=0
2024-05-30 21:46:30 | INFO | train_inner | epoch 074:    964 / 1132 loss=3.006, nll_loss=1.402, ppl=2.64, wps=19236.5, ups=5.51, wpb=3490.2, bsz=134, num_updates=83600, lr=0.00010937, gnorm=1.239, train_wall=18, wall=0
2024-05-30 21:46:49 | INFO | train_inner | epoch 074:   1064 / 1132 loss=3.023, nll_loss=1.424, ppl=2.68, wps=19568.6, ups=5.44, wpb=3596.8, bsz=141, num_updates=83700, lr=0.000109304, gnorm=1.226, train_wall=18, wall=0
2024-05-30 21:47:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:47:05 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 3.977 | nll_loss 2.398 | ppl 5.27 | wps 55965.3 | wpb 2685.2 | bsz 107.1 | num_updates 83768 | best_loss 11.059
2024-05-30 21:47:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:47:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 74 @ 83768 updates, score 3.977) (writing took 2.876174361910671 seconds)
2024-05-30 21:47:08 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2024-05-30 21:47:08 | INFO | train | epoch 074 | loss 2.989 | nll_loss 1.383 | ppl 2.61 | wps 17848.8 | ups 5.02 | wpb 3556.4 | bsz 141.6 | num_updates 83768 | lr 0.00010926 | gnorm 1.221 | train_wall 211 | wall 0
2024-05-30 21:47:08 | INFO | fairseq.trainer | begin training epoch 75
2024-05-30 21:47:14 | INFO | train_inner | epoch 075:     32 / 1132 loss=2.973, nll_loss=1.366, ppl=2.58, wps=13650.4, ups=3.94, wpb=3465.8, bsz=146.2, num_updates=83800, lr=0.000109239, gnorm=1.231, train_wall=19, wall=0
2024-05-30 21:47:33 | INFO | train_inner | epoch 075:    132 / 1132 loss=2.936, nll_loss=1.32, ppl=2.5, wps=18071.6, ups=5.3, wpb=3408.3, bsz=140.1, num_updates=83900, lr=0.000109174, gnorm=1.238, train_wall=19, wall=0
2024-05-30 21:47:52 | INFO | train_inner | epoch 075:    232 / 1132 loss=2.986, nll_loss=1.375, ppl=2.59, wps=18712.4, ups=5.22, wpb=3585.2, bsz=128.1, num_updates=84000, lr=0.000109109, gnorm=1.221, train_wall=19, wall=0
2024-05-30 21:47:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:47:56 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 3.991 | nll_loss 2.412 | ppl 5.32 | wps 55781.8 | wpb 2685.2 | bsz 107.1 | num_updates 84000 | best_loss 11.059
2024-05-30 21:47:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:47:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_75_84000.pt (epoch 75 @ 84000 updates, score 3.991) (writing took 3.402467232197523 seconds)
2024-05-30 21:48:18 | INFO | train_inner | epoch 075:    332 / 1132 loss=2.962, nll_loss=1.354, ppl=2.56, wps=13989.2, ups=3.83, wpb=3655.1, bsz=157.8, num_updates=84100, lr=0.000109044, gnorm=1.187, train_wall=19, wall=0
2024-05-30 21:48:37 | INFO | train_inner | epoch 075:    432 / 1132 loss=2.978, nll_loss=1.37, ppl=2.59, wps=18832, ups=5.27, wpb=3571.9, bsz=135, num_updates=84200, lr=0.000108979, gnorm=1.226, train_wall=19, wall=0
2024-05-30 21:48:56 | INFO | train_inner | epoch 075:    532 / 1132 loss=2.971, nll_loss=1.364, ppl=2.57, wps=18776.7, ups=5.28, wpb=3556.7, bsz=146.8, num_updates=84300, lr=0.000108915, gnorm=1.226, train_wall=19, wall=0
2024-05-30 21:49:15 | INFO | train_inner | epoch 075:    632 / 1132 loss=2.975, nll_loss=1.371, ppl=2.59, wps=18913.5, ups=5.32, wpb=3555.4, bsz=143.7, num_updates=84400, lr=0.00010885, gnorm=1.201, train_wall=19, wall=0
2024-05-30 21:49:34 | INFO | train_inner | epoch 075:    732 / 1132 loss=2.968, nll_loss=1.36, ppl=2.57, wps=18502.1, ups=5.2, wpb=3560.8, bsz=164.2, num_updates=84500, lr=0.000108786, gnorm=1.201, train_wall=19, wall=0
2024-05-30 21:49:53 | INFO | train_inner | epoch 075:    832 / 1132 loss=3.009, nll_loss=1.406, ppl=2.65, wps=18458.2, ups=5.2, wpb=3548.4, bsz=133.9, num_updates=84600, lr=0.000108721, gnorm=1.246, train_wall=19, wall=0
2024-05-30 21:50:13 | INFO | train_inner | epoch 075:    932 / 1132 loss=3.022, nll_loss=1.419, ppl=2.67, wps=18464.7, ups=5.14, wpb=3589, bsz=139.6, num_updates=84700, lr=0.000108657, gnorm=1.253, train_wall=19, wall=0
2024-05-30 21:50:32 | INFO | train_inner | epoch 075:   1032 / 1132 loss=3.017, nll_loss=1.415, ppl=2.67, wps=18616.9, ups=5.33, wpb=3493.2, bsz=128.5, num_updates=84800, lr=0.000108593, gnorm=1.266, train_wall=19, wall=0
2024-05-30 21:50:51 | INFO | train_inner | epoch 075:   1132 / 1132 loss=3.015, nll_loss=1.414, ppl=2.66, wps=18884.4, ups=5.25, wpb=3594.3, bsz=139.8, num_updates=84900, lr=0.000108529, gnorm=1.232, train_wall=19, wall=0
2024-05-30 21:50:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:50:54 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 3.973 | nll_loss 2.398 | ppl 5.27 | wps 55764.5 | wpb 2685.2 | bsz 107.1 | num_updates 84900 | best_loss 11.059
2024-05-30 21:50:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:50:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 75 @ 84900 updates, score 3.973) (writing took 2.935584686230868 seconds)
2024-05-30 21:50:57 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2024-05-30 21:50:57 | INFO | train | epoch 075 | loss 2.984 | nll_loss 1.378 | ppl 2.6 | wps 17562 | ups 4.94 | wpb 3556.4 | bsz 141.6 | num_updates 84900 | lr 0.000108529 | gnorm 1.226 | train_wall 214 | wall 0
2024-05-30 21:50:57 | INFO | fairseq.trainer | begin training epoch 76
2024-05-30 21:51:18 | INFO | train_inner | epoch 076:    100 / 1132 loss=2.936, nll_loss=1.325, ppl=2.51, wps=13193.9, ups=3.68, wpb=3581.2, bsz=143, num_updates=85000, lr=0.000108465, gnorm=1.185, train_wall=20, wall=0
2024-05-30 21:51:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:51:21 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 3.981 | nll_loss 2.403 | ppl 5.29 | wps 55711.9 | wpb 2685.2 | bsz 107.1 | num_updates 85000 | best_loss 11.059
2024-05-30 21:51:21 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:51:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_76_85000.pt (epoch 76 @ 85000 updates, score 3.981) (writing took 3.646940232720226 seconds)
2024-05-30 21:51:44 | INFO | train_inner | epoch 076:    200 / 1132 loss=2.942, nll_loss=1.328, ppl=2.51, wps=13466.9, ups=3.82, wpb=3521.4, bsz=143.5, num_updates=85100, lr=0.000108401, gnorm=1.223, train_wall=19, wall=0
2024-05-30 21:52:03 | INFO | train_inner | epoch 076:    300 / 1132 loss=2.959, nll_loss=1.349, ppl=2.55, wps=18825.7, ups=5.26, wpb=3578.9, bsz=144.2, num_updates=85200, lr=0.000108338, gnorm=1.203, train_wall=19, wall=0
2024-05-30 21:52:22 | INFO | train_inner | epoch 076:    400 / 1132 loss=2.958, nll_loss=1.348, ppl=2.55, wps=18749.9, ups=5.22, wpb=3591.7, bsz=150.2, num_updates=85300, lr=0.000108274, gnorm=1.2, train_wall=19, wall=0
2024-05-30 21:52:43 | INFO | train_inner | epoch 076:    500 / 1132 loss=2.985, nll_loss=1.379, ppl=2.6, wps=17577.9, ups=4.91, wpb=3583.6, bsz=142.2, num_updates=85400, lr=0.000108211, gnorm=1.223, train_wall=20, wall=0
2024-05-30 21:53:02 | INFO | train_inner | epoch 076:    600 / 1132 loss=2.98, nll_loss=1.372, ppl=2.59, wps=17662.6, ups=5.09, wpb=3472.5, bsz=146.6, num_updates=85500, lr=0.000108148, gnorm=1.296, train_wall=20, wall=0
2024-05-30 21:53:21 | INFO | train_inner | epoch 076:    700 / 1132 loss=2.998, nll_loss=1.39, ppl=2.62, wps=18264, ups=5.22, wpb=3501.7, bsz=124.6, num_updates=85600, lr=0.000108084, gnorm=1.264, train_wall=19, wall=0
2024-05-30 21:53:41 | INFO | train_inner | epoch 076:    800 / 1132 loss=3.002, nll_loss=1.398, ppl=2.64, wps=18861.3, ups=5.2, wpb=3629.6, bsz=133.6, num_updates=85700, lr=0.000108021, gnorm=1.218, train_wall=19, wall=0
2024-05-30 21:54:00 | INFO | train_inner | epoch 076:    900 / 1132 loss=2.995, nll_loss=1.392, ppl=2.62, wps=18866.1, ups=5.17, wpb=3651.4, bsz=151.4, num_updates=85800, lr=0.000107958, gnorm=1.198, train_wall=19, wall=0
2024-05-30 21:54:19 | INFO | train_inner | epoch 076:   1000 / 1132 loss=3.004, nll_loss=1.401, ppl=2.64, wps=18737.3, ups=5.24, wpb=3576.3, bsz=139.8, num_updates=85900, lr=0.000107896, gnorm=1.226, train_wall=19, wall=0
2024-05-30 21:54:38 | INFO | train_inner | epoch 076:   1100 / 1132 loss=2.991, nll_loss=1.386, ppl=2.61, wps=18395.7, ups=5.36, wpb=3434, bsz=141, num_updates=86000, lr=0.000107833, gnorm=1.272, train_wall=19, wall=0
2024-05-30 21:54:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:54:41 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 3.981 | nll_loss 2.403 | ppl 5.29 | wps 55745.2 | wpb 2685.2 | bsz 107.1 | num_updates 86000 | best_loss 11.059
2024-05-30 21:54:41 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:54:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_76_86000.pt (epoch 76 @ 86000 updates, score 3.981) (writing took 4.0526448069140315 seconds)
2024-05-30 21:54:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:54:55 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 3.981 | nll_loss 2.404 | ppl 5.29 | wps 55652.1 | wpb 2685.2 | bsz 107.1 | num_updates 86032 | best_loss 11.059
2024-05-30 21:54:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:54:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 76 @ 86032 updates, score 3.981) (writing took 2.9315545549616218 seconds)
2024-05-30 21:54:58 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2024-05-30 21:54:58 | INFO | train | epoch 076 | loss 2.978 | nll_loss 1.371 | ppl 2.59 | wps 16722.5 | ups 4.7 | wpb 3556.4 | bsz 141.6 | num_updates 86032 | lr 0.000107813 | gnorm 1.228 | train_wall 218 | wall 0
2024-05-30 21:54:58 | INFO | fairseq.trainer | begin training epoch 77
2024-05-30 21:55:11 | INFO | train_inner | epoch 077:     68 / 1132 loss=2.972, nll_loss=1.359, ppl=2.57, wps=10621.6, ups=2.98, wpb=3561.7, bsz=130.2, num_updates=86100, lr=0.00010777, gnorm=1.212, train_wall=19, wall=0
2024-05-30 21:55:30 | INFO | train_inner | epoch 077:    168 / 1132 loss=2.927, nll_loss=1.314, ppl=2.49, wps=18830.2, ups=5.28, wpb=3569.7, bsz=137.4, num_updates=86200, lr=0.000107708, gnorm=1.184, train_wall=19, wall=0
2024-05-30 21:55:49 | INFO | train_inner | epoch 077:    268 / 1132 loss=2.944, nll_loss=1.333, ppl=2.52, wps=18916.7, ups=5.2, wpb=3640.1, bsz=156.1, num_updates=86300, lr=0.000107645, gnorm=1.197, train_wall=19, wall=0
2024-05-30 21:56:08 | INFO | train_inner | epoch 077:    368 / 1132 loss=2.948, nll_loss=1.335, ppl=2.52, wps=18404.1, ups=5.27, wpb=3491, bsz=147.2, num_updates=86400, lr=0.000107583, gnorm=1.245, train_wall=19, wall=0
2024-05-30 21:56:27 | INFO | train_inner | epoch 077:    468 / 1132 loss=2.966, nll_loss=1.354, ppl=2.56, wps=18262.8, ups=5.25, wpb=3481, bsz=138.2, num_updates=86500, lr=0.000107521, gnorm=1.262, train_wall=19, wall=0
2024-05-30 21:56:47 | INFO | train_inner | epoch 077:    568 / 1132 loss=2.986, nll_loss=1.376, ppl=2.6, wps=18311.7, ups=5.21, wpb=3514.6, bsz=137.4, num_updates=86600, lr=0.000107459, gnorm=1.261, train_wall=19, wall=0
2024-05-30 21:57:06 | INFO | train_inner | epoch 077:    668 / 1132 loss=2.996, nll_loss=1.389, ppl=2.62, wps=18642.6, ups=5.19, wpb=3594.2, bsz=132.9, num_updates=86700, lr=0.000107397, gnorm=1.228, train_wall=19, wall=0
2024-05-30 21:57:25 | INFO | train_inner | epoch 077:    768 / 1132 loss=2.986, nll_loss=1.381, ppl=2.6, wps=18873.5, ups=5.28, wpb=3576.2, bsz=141.6, num_updates=86800, lr=0.000107335, gnorm=1.224, train_wall=19, wall=0
2024-05-30 21:57:44 | INFO | train_inner | epoch 077:    868 / 1132 loss=2.979, nll_loss=1.374, ppl=2.59, wps=18723.7, ups=5.31, wpb=3529.3, bsz=149, num_updates=86900, lr=0.000107273, gnorm=1.243, train_wall=19, wall=0
2024-05-30 21:58:04 | INFO | train_inner | epoch 077:    968 / 1132 loss=3, nll_loss=1.399, ppl=2.64, wps=17862.6, ups=4.96, wpb=3599.2, bsz=144.4, num_updates=87000, lr=0.000107211, gnorm=1.221, train_wall=20, wall=0
2024-05-30 21:58:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:58:07 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 3.982 | nll_loss 2.403 | ppl 5.29 | wps 55745.8 | wpb 2685.2 | bsz 107.1 | num_updates 87000 | best_loss 11.059
2024-05-30 21:58:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:58:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_77_87000.pt (epoch 77 @ 87000 updates, score 3.982) (writing took 3.391077463980764 seconds)
2024-05-30 21:58:30 | INFO | train_inner | epoch 077:   1068 / 1132 loss=3.017, nll_loss=1.416, ppl=2.67, wps=13802.3, ups=3.86, wpb=3579.3, bsz=130.2, num_updates=87100, lr=0.00010715, gnorm=1.256, train_wall=19, wall=0
2024-05-30 21:58:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 21:58:45 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 3.982 | nll_loss 2.406 | ppl 5.3 | wps 55326.3 | wpb 2685.2 | bsz 107.1 | num_updates 87164 | best_loss 11.059
2024-05-30 21:58:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 21:58:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 77 @ 87164 updates, score 3.982) (writing took 3.014243167825043 seconds)
2024-05-30 21:58:48 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2024-05-30 21:58:48 | INFO | train | epoch 077 | loss 2.973 | nll_loss 1.364 | ppl 2.57 | wps 17463.2 | ups 4.91 | wpb 3556.4 | bsz 141.6 | num_updates 87164 | lr 0.00010711 | gnorm 1.229 | train_wall 215 | wall 0
2024-05-30 21:58:48 | INFO | fairseq.trainer | begin training epoch 78
2024-05-30 21:58:55 | INFO | train_inner | epoch 078:     36 / 1132 loss=2.944, nll_loss=1.334, ppl=2.52, wps=13755.2, ups=3.93, wpb=3501.2, bsz=145.3, num_updates=87200, lr=0.000107088, gnorm=1.216, train_wall=19, wall=0
2024-05-30 21:59:14 | INFO | train_inner | epoch 078:    136 / 1132 loss=2.948, nll_loss=1.336, ppl=2.52, wps=18797.4, ups=5.26, wpb=3575.6, bsz=129.9, num_updates=87300, lr=0.000107027, gnorm=1.203, train_wall=19, wall=0
2024-05-30 21:59:33 | INFO | train_inner | epoch 078:    236 / 1132 loss=2.919, nll_loss=1.303, ppl=2.47, wps=18586.8, ups=5.29, wpb=3513.4, bsz=147.2, num_updates=87400, lr=0.000106966, gnorm=1.222, train_wall=19, wall=0
2024-05-30 21:59:52 | INFO | train_inner | epoch 078:    336 / 1132 loss=2.955, nll_loss=1.342, ppl=2.53, wps=18198.3, ups=5.25, wpb=3467.5, bsz=134.9, num_updates=87500, lr=0.000106904, gnorm=1.262, train_wall=19, wall=0
2024-05-30 22:00:12 | INFO | train_inner | epoch 078:    436 / 1132 loss=2.972, nll_loss=1.365, ppl=2.58, wps=18811.4, ups=5.19, wpb=3622.6, bsz=139.9, num_updates=87600, lr=0.000106843, gnorm=1.21, train_wall=19, wall=0
2024-05-30 22:00:30 | INFO | train_inner | epoch 078:    536 / 1132 loss=2.954, nll_loss=1.342, ppl=2.54, wps=19258.5, ups=5.49, wpb=3506.2, bsz=138, num_updates=87700, lr=0.000106783, gnorm=1.264, train_wall=18, wall=0
2024-05-30 22:00:48 | INFO | train_inner | epoch 078:    636 / 1132 loss=2.957, nll_loss=1.347, ppl=2.54, wps=19638.7, ups=5.41, wpb=3629.3, bsz=161.4, num_updates=87800, lr=0.000106722, gnorm=1.198, train_wall=18, wall=0
2024-05-30 22:01:07 | INFO | train_inner | epoch 078:    736 / 1132 loss=2.978, nll_loss=1.372, ppl=2.59, wps=19692.8, ups=5.46, wpb=3606.7, bsz=155.1, num_updates=87900, lr=0.000106661, gnorm=1.214, train_wall=18, wall=0
2024-05-30 22:01:26 | INFO | train_inner | epoch 078:    836 / 1132 loss=2.991, nll_loss=1.386, ppl=2.61, wps=18038.2, ups=5.07, wpb=3555.7, bsz=136.2, num_updates=88000, lr=0.0001066, gnorm=1.261, train_wall=20, wall=0
2024-05-30 22:01:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:01:30 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 3.988 | nll_loss 2.411 | ppl 5.32 | wps 54980.8 | wpb 2685.2 | bsz 107.1 | num_updates 88000 | best_loss 11.059
2024-05-30 22:01:30 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:01:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_78_88000.pt (epoch 78 @ 88000 updates, score 3.988) (writing took 3.8710766257718205 seconds)
2024-05-30 22:01:53 | INFO | train_inner | epoch 078:    936 / 1132 loss=3, nll_loss=1.394, ppl=2.63, wps=13080.4, ups=3.69, wpb=3549.2, bsz=133, num_updates=88100, lr=0.00010654, gnorm=1.244, train_wall=20, wall=0
2024-05-30 22:02:13 | INFO | train_inner | epoch 078:   1036 / 1132 loss=2.99, nll_loss=1.385, ppl=2.61, wps=18526.9, ups=5.09, wpb=3643.4, bsz=147.7, num_updates=88200, lr=0.000106479, gnorm=1.213, train_wall=19, wall=0
2024-05-30 22:02:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:02:35 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 3.982 | nll_loss 2.406 | ppl 5.3 | wps 54695.9 | wpb 2685.2 | bsz 107.1 | num_updates 88296 | best_loss 11.059
2024-05-30 22:02:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:02:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 78 @ 88296 updates, score 3.982) (writing took 2.737041383050382 seconds)
2024-05-30 22:02:38 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2024-05-30 22:02:38 | INFO | train | epoch 078 | loss 2.968 | nll_loss 1.359 | ppl 2.57 | wps 17547.4 | ups 4.93 | wpb 3556.4 | bsz 141.6 | num_updates 88296 | lr 0.000106422 | gnorm 1.234 | train_wall 214 | wall 0
2024-05-30 22:02:38 | INFO | fairseq.trainer | begin training epoch 79
2024-05-30 22:02:39 | INFO | train_inner | epoch 079:      4 / 1132 loss=3, nll_loss=1.397, ppl=2.63, wps=13594.4, ups=3.89, wpb=3492.1, bsz=138.6, num_updates=88300, lr=0.000106419, gnorm=1.286, train_wall=19, wall=0
2024-05-30 22:02:58 | INFO | train_inner | epoch 079:    104 / 1132 loss=2.925, nll_loss=1.306, ppl=2.47, wps=18138.6, ups=5.16, wpb=3516.3, bsz=132.3, num_updates=88400, lr=0.000106359, gnorm=1.23, train_wall=19, wall=0
2024-05-30 22:03:18 | INFO | train_inner | epoch 079:    204 / 1132 loss=2.931, nll_loss=1.316, ppl=2.49, wps=18509.9, ups=5.11, wpb=3624.6, bsz=151.1, num_updates=88500, lr=0.000106299, gnorm=1.2, train_wall=19, wall=0
2024-05-30 22:03:37 | INFO | train_inner | epoch 079:    304 / 1132 loss=2.956, nll_loss=1.344, ppl=2.54, wps=18410.9, ups=5.21, wpb=3531.9, bsz=124.8, num_updates=88600, lr=0.000106239, gnorm=1.241, train_wall=19, wall=0
2024-05-30 22:03:56 | INFO | train_inner | epoch 079:    404 / 1132 loss=2.935, nll_loss=1.322, ppl=2.5, wps=18486.6, ups=5.25, wpb=3520.5, bsz=141.6, num_updates=88700, lr=0.000106179, gnorm=1.235, train_wall=19, wall=0
2024-05-30 22:04:15 | INFO | train_inner | epoch 079:    504 / 1132 loss=2.957, nll_loss=1.345, ppl=2.54, wps=18285.3, ups=5.22, wpb=3502.4, bsz=130, num_updates=88800, lr=0.000106119, gnorm=1.255, train_wall=19, wall=0
2024-05-30 22:04:34 | INFO | train_inner | epoch 079:    604 / 1132 loss=2.958, nll_loss=1.349, ppl=2.55, wps=18440.4, ups=5.19, wpb=3550.1, bsz=152.1, num_updates=88900, lr=0.000106059, gnorm=1.239, train_wall=19, wall=0
2024-05-30 22:04:54 | INFO | train_inner | epoch 079:    704 / 1132 loss=2.99, nll_loss=1.383, ppl=2.61, wps=18071.5, ups=5.11, wpb=3536.6, bsz=134.2, num_updates=89000, lr=0.000106, gnorm=1.233, train_wall=19, wall=0
2024-05-30 22:04:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:04:58 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 3.986 | nll_loss 2.41 | ppl 5.32 | wps 52909.2 | wpb 2685.2 | bsz 107.1 | num_updates 89000 | best_loss 11.059
2024-05-30 22:04:58 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:05:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_79_89000.pt (epoch 79 @ 89000 updates, score 3.986) (writing took 4.057754877023399 seconds)
2024-05-30 22:05:21 | INFO | train_inner | epoch 079:    804 / 1132 loss=2.985, nll_loss=1.377, ppl=2.6, wps=12902, ups=3.68, wpb=3508.4, bsz=127.5, num_updates=89100, lr=0.00010594, gnorm=1.281, train_wall=19, wall=0
2024-05-30 22:05:42 | INFO | train_inner | epoch 079:    904 / 1132 loss=2.988, nll_loss=1.382, ppl=2.61, wps=17756.4, ups=4.9, wpb=3623.4, bsz=142.9, num_updates=89200, lr=0.000105881, gnorm=1.218, train_wall=20, wall=0
2024-05-30 22:06:02 | INFO | train_inner | epoch 079:   1004 / 1132 loss=2.963, nll_loss=1.357, ppl=2.56, wps=17487.9, ups=4.87, wpb=3587.4, bsz=164.6, num_updates=89300, lr=0.000105822, gnorm=1.202, train_wall=20, wall=0
2024-05-30 22:06:23 | INFO | train_inner | epoch 079:   1104 / 1132 loss=2.991, nll_loss=1.386, ppl=2.61, wps=17469.8, ups=4.86, wpb=3597.5, bsz=153.1, num_updates=89400, lr=0.000105762, gnorm=1.247, train_wall=20, wall=0
2024-05-30 22:06:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:06:32 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 3.988 | nll_loss 2.411 | ppl 5.32 | wps 49473.9 | wpb 2685.2 | bsz 107.1 | num_updates 89428 | best_loss 11.059
2024-05-30 22:06:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:06:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 79 @ 89428 updates, score 3.988) (writing took 3.196651495061815 seconds)
2024-05-30 22:06:35 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2024-05-30 22:06:35 | INFO | train | epoch 079 | loss 2.962 | nll_loss 1.352 | ppl 2.55 | wps 16940.1 | ups 4.76 | wpb 3556.4 | bsz 141.6 | num_updates 89428 | lr 0.000105746 | gnorm 1.234 | train_wall 219 | wall 0
2024-05-30 22:06:35 | INFO | fairseq.trainer | begin training epoch 80
2024-05-30 22:06:50 | INFO | train_inner | epoch 080:     72 / 1132 loss=2.919, nll_loss=1.304, ppl=2.47, wps=12927.6, ups=3.61, wpb=3576.7, bsz=155.5, num_updates=89500, lr=0.000105703, gnorm=1.202, train_wall=20, wall=0
2024-05-30 22:07:11 | INFO | train_inner | epoch 080:    172 / 1132 loss=2.943, nll_loss=1.332, ppl=2.52, wps=17941.3, ups=4.94, wpb=3629.2, bsz=141.5, num_updates=89600, lr=0.000105644, gnorm=1.186, train_wall=20, wall=0
2024-05-30 22:07:31 | INFO | train_inner | epoch 080:    272 / 1132 loss=2.935, nll_loss=1.319, ppl=2.5, wps=17609.2, ups=4.99, wpb=3531.2, bsz=147.4, num_updates=89700, lr=0.000105585, gnorm=1.242, train_wall=20, wall=0
2024-05-30 22:07:51 | INFO | train_inner | epoch 080:    372 / 1132 loss=2.942, nll_loss=1.331, ppl=2.52, wps=17688, ups=4.93, wpb=3584.3, bsz=150.4, num_updates=89800, lr=0.000105527, gnorm=1.213, train_wall=20, wall=0
2024-05-30 22:08:11 | INFO | train_inner | epoch 080:    472 / 1132 loss=2.935, nll_loss=1.32, ppl=2.5, wps=17306.8, ups=4.99, wpb=3471, bsz=148.9, num_updates=89900, lr=0.000105468, gnorm=1.236, train_wall=20, wall=0
2024-05-30 22:08:31 | INFO | train_inner | epoch 080:    572 / 1132 loss=2.967, nll_loss=1.357, ppl=2.56, wps=17593, ups=4.99, wpb=3527.7, bsz=133.3, num_updates=90000, lr=0.000105409, gnorm=1.284, train_wall=20, wall=0
2024-05-30 22:08:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:08:35 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 3.998 | nll_loss 2.422 | ppl 5.36 | wps 49412.1 | wpb 2685.2 | bsz 107.1 | num_updates 90000 | best_loss 11.059
2024-05-30 22:08:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:08:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_80_90000.pt (epoch 80 @ 90000 updates, score 3.998) (writing took 4.312924669124186 seconds)
2024-05-30 22:08:59 | INFO | train_inner | epoch 080:    672 / 1132 loss=2.974, nll_loss=1.366, ppl=2.58, wps=12653.4, ups=3.55, wpb=3566.2, bsz=135.8, num_updates=90100, lr=0.000105351, gnorm=1.244, train_wall=20, wall=0
2024-05-30 22:09:19 | INFO | train_inner | epoch 080:    772 / 1132 loss=2.982, nll_loss=1.373, ppl=2.59, wps=18101.6, ups=5.09, wpb=3555.1, bsz=129, num_updates=90200, lr=0.000105292, gnorm=1.261, train_wall=19, wall=0
2024-05-30 22:09:38 | INFO | train_inner | epoch 080:    872 / 1132 loss=2.976, nll_loss=1.369, ppl=2.58, wps=18523, ups=5.18, wpb=3578.8, bsz=133.3, num_updates=90300, lr=0.000105234, gnorm=1.23, train_wall=19, wall=0
2024-05-30 22:09:58 | INFO | train_inner | epoch 080:    972 / 1132 loss=2.967, nll_loss=1.361, ppl=2.57, wps=18191.1, ups=5.02, wpb=3620.4, bsz=143, num_updates=90400, lr=0.000105176, gnorm=1.215, train_wall=20, wall=0
2024-05-30 22:10:18 | INFO | train_inner | epoch 080:   1072 / 1132 loss=2.974, nll_loss=1.366, ppl=2.58, wps=17796.2, ups=5.02, wpb=3548.4, bsz=146.1, num_updates=90500, lr=0.000105118, gnorm=1.242, train_wall=20, wall=0
2024-05-30 22:10:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:10:33 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 3.988 | nll_loss 2.414 | ppl 5.33 | wps 52859.6 | wpb 2685.2 | bsz 107.1 | num_updates 90560 | best_loss 11.059
2024-05-30 22:10:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:10:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 80 @ 90560 updates, score 3.988) (writing took 3.3377837180159986 seconds)
2024-05-30 22:10:36 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2024-05-30 22:10:36 | INFO | train | epoch 080 | loss 2.957 | nll_loss 1.347 | ppl 2.54 | wps 16711.2 | ups 4.7 | wpb 3556.4 | bsz 141.6 | num_updates 90560 | lr 0.000105083 | gnorm 1.236 | train_wall 221 | wall 0
2024-05-30 22:10:36 | INFO | fairseq.trainer | begin training epoch 81
2024-05-30 22:10:44 | INFO | train_inner | epoch 081:     40 / 1132 loss=2.954, nll_loss=1.343, ppl=2.54, wps=13420.3, ups=3.8, wpb=3535.9, bsz=144.2, num_updates=90600, lr=0.00010506, gnorm=1.248, train_wall=19, wall=0
2024-05-30 22:11:04 | INFO | train_inner | epoch 081:    140 / 1132 loss=2.915, nll_loss=1.297, ppl=2.46, wps=17893, ups=5.1, wpb=3511.7, bsz=128.7, num_updates=90700, lr=0.000105002, gnorm=1.219, train_wall=19, wall=0
2024-05-30 22:11:23 | INFO | train_inner | epoch 081:    240 / 1132 loss=2.919, nll_loss=1.305, ppl=2.47, wps=18556, ups=5.23, wpb=3547.9, bsz=149.8, num_updates=90800, lr=0.000104944, gnorm=1.232, train_wall=19, wall=0
2024-05-30 22:11:43 | INFO | train_inner | epoch 081:    340 / 1132 loss=2.951, nll_loss=1.341, ppl=2.53, wps=18336.6, ups=5.12, wpb=3583.1, bsz=144.5, num_updates=90900, lr=0.000104886, gnorm=1.247, train_wall=19, wall=0
2024-05-30 22:12:03 | INFO | train_inner | epoch 081:    440 / 1132 loss=2.947, nll_loss=1.336, ppl=2.52, wps=17814.7, ups=4.97, wpb=3584.7, bsz=139.7, num_updates=91000, lr=0.000104828, gnorm=1.241, train_wall=20, wall=0
2024-05-30 22:12:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:12:06 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 4.002 | nll_loss 2.425 | ppl 5.37 | wps 52361.5 | wpb 2685.2 | bsz 107.1 | num_updates 91000 | best_loss 11.059
2024-05-30 22:12:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:12:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_81_91000.pt (epoch 81 @ 91000 updates, score 4.002) (writing took 4.019362816121429 seconds)
2024-05-30 22:12:30 | INFO | train_inner | epoch 081:    540 / 1132 loss=2.945, nll_loss=1.333, ppl=2.52, wps=12833.9, ups=3.66, wpb=3510.6, bsz=135.3, num_updates=91100, lr=0.000104771, gnorm=1.238, train_wall=19, wall=0
2024-05-30 22:12:50 | INFO | train_inner | epoch 081:    640 / 1132 loss=2.955, nll_loss=1.346, ppl=2.54, wps=18079.1, ups=5.02, wpb=3604.8, bsz=149, num_updates=91200, lr=0.000104713, gnorm=1.233, train_wall=20, wall=0
2024-05-30 22:13:10 | INFO | train_inner | epoch 081:    740 / 1132 loss=2.945, nll_loss=1.333, ppl=2.52, wps=17810.5, ups=5.12, wpb=3481.4, bsz=143.8, num_updates=91300, lr=0.000104656, gnorm=1.255, train_wall=19, wall=0
2024-05-30 22:13:29 | INFO | train_inner | epoch 081:    840 / 1132 loss=2.97, nll_loss=1.361, ppl=2.57, wps=18379.3, ups=5.1, wpb=3602.8, bsz=152.6, num_updates=91400, lr=0.000104599, gnorm=1.243, train_wall=19, wall=0
2024-05-30 22:13:49 | INFO | train_inner | epoch 081:    940 / 1132 loss=2.988, nll_loss=1.382, ppl=2.61, wps=18236.9, ups=5, wpb=3649.4, bsz=138.4, num_updates=91500, lr=0.000104542, gnorm=1.241, train_wall=20, wall=0
2024-05-30 22:14:09 | INFO | train_inner | epoch 081:   1040 / 1132 loss=2.966, nll_loss=1.356, ppl=2.56, wps=17677.6, ups=5.04, wpb=3505.9, bsz=139.8, num_updates=91600, lr=0.000104485, gnorm=1.254, train_wall=19, wall=0
2024-05-30 22:14:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:14:31 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 3.988 | nll_loss 2.412 | ppl 5.32 | wps 51993.4 | wpb 2685.2 | bsz 107.1 | num_updates 91692 | best_loss 11.059
2024-05-30 22:14:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:14:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 81 @ 91692 updates, score 3.988) (writing took 3.576372985728085 seconds)
2024-05-30 22:14:35 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2024-05-30 22:14:35 | INFO | train | epoch 081 | loss 2.952 | nll_loss 1.341 | ppl 2.53 | wps 16902 | ups 4.75 | wpb 3556.4 | bsz 141.6 | num_updates 91692 | lr 0.000104432 | gnorm 1.243 | train_wall 219 | wall 0
2024-05-30 22:14:35 | INFO | fairseq.trainer | begin training epoch 82
2024-05-30 22:14:36 | INFO | train_inner | epoch 082:      8 / 1132 loss=2.985, nll_loss=1.375, ppl=2.59, wps=12714.2, ups=3.66, wpb=3472.5, bsz=127.4, num_updates=91700, lr=0.000104428, gnorm=1.307, train_wall=19, wall=0
2024-05-30 22:14:56 | INFO | train_inner | epoch 082:    108 / 1132 loss=2.911, nll_loss=1.295, ppl=2.45, wps=17946.7, ups=5.04, wpb=3561.4, bsz=144.8, num_updates=91800, lr=0.000104371, gnorm=1.22, train_wall=19, wall=0
2024-05-30 22:15:16 | INFO | train_inner | epoch 082:    208 / 1132 loss=2.916, nll_loss=1.299, ppl=2.46, wps=17782.9, ups=5.05, wpb=3520.3, bsz=144.4, num_updates=91900, lr=0.000104314, gnorm=1.25, train_wall=19, wall=0
2024-05-30 22:15:36 | INFO | train_inner | epoch 082:    308 / 1132 loss=2.933, nll_loss=1.317, ppl=2.49, wps=17837.8, ups=4.97, wpb=3591.5, bsz=132.2, num_updates=92000, lr=0.000104257, gnorm=1.238, train_wall=20, wall=0
2024-05-30 22:15:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:15:40 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 3.995 | nll_loss 2.417 | ppl 5.34 | wps 51340.4 | wpb 2685.2 | bsz 107.1 | num_updates 92000 | best_loss 11.059
2024-05-30 22:15:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:15:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_82_92000.pt (epoch 82 @ 92000 updates, score 3.995) (writing took 4.024037709925324 seconds)
2024-05-30 22:16:04 | INFO | train_inner | epoch 082:    408 / 1132 loss=2.95, nll_loss=1.337, ppl=2.53, wps=13015.8, ups=3.64, wpb=3579.5, bsz=133.4, num_updates=92100, lr=0.000104201, gnorm=1.242, train_wall=19, wall=0
2024-05-30 22:16:23 | INFO | train_inner | epoch 082:    508 / 1132 loss=2.939, nll_loss=1.324, ppl=2.5, wps=17885.7, ups=5.08, wpb=3523, bsz=138, num_updates=92200, lr=0.000104144, gnorm=1.247, train_wall=19, wall=0
2024-05-30 22:16:43 | INFO | train_inner | epoch 082:    608 / 1132 loss=2.936, nll_loss=1.324, ppl=2.5, wps=17823.1, ups=5.13, wpb=3470.9, bsz=149.9, num_updates=92300, lr=0.000104088, gnorm=1.258, train_wall=19, wall=0
2024-05-30 22:17:02 | INFO | train_inner | epoch 082:    708 / 1132 loss=2.967, nll_loss=1.359, ppl=2.57, wps=18191.5, ups=5.09, wpb=3570.6, bsz=147.2, num_updates=92400, lr=0.000104031, gnorm=1.279, train_wall=19, wall=0
2024-05-30 22:17:22 | INFO | train_inner | epoch 082:    808 / 1132 loss=2.959, nll_loss=1.351, ppl=2.55, wps=18315.8, ups=5.06, wpb=3617.6, bsz=139.6, num_updates=92500, lr=0.000103975, gnorm=1.214, train_wall=19, wall=0
2024-05-30 22:17:42 | INFO | train_inner | epoch 082:    908 / 1132 loss=2.943, nll_loss=1.333, ppl=2.52, wps=18227.6, ups=5.05, wpb=3608.3, bsz=158.2, num_updates=92600, lr=0.000103919, gnorm=1.215, train_wall=19, wall=0
2024-05-30 22:18:01 | INFO | train_inner | epoch 082:   1008 / 1132 loss=2.974, nll_loss=1.365, ppl=2.58, wps=18253.2, ups=5.15, wpb=3542.1, bsz=138.8, num_updates=92700, lr=0.000103863, gnorm=1.278, train_wall=19, wall=0
2024-05-30 22:18:21 | INFO | train_inner | epoch 082:   1108 / 1132 loss=2.992, nll_loss=1.387, ppl=2.62, wps=17938.2, ups=5.03, wpb=3565.2, bsz=133.6, num_updates=92800, lr=0.000103807, gnorm=1.257, train_wall=19, wall=0
2024-05-30 22:18:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:18:30 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 3.982 | nll_loss 2.411 | ppl 5.32 | wps 52558.2 | wpb 2685.2 | bsz 107.1 | num_updates 92824 | best_loss 11.059
2024-05-30 22:18:30 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:18:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 82 @ 92824 updates, score 3.982) (writing took 3.4319077283143997 seconds)
2024-05-30 22:18:33 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2024-05-30 22:18:33 | INFO | train | epoch 082 | loss 2.948 | nll_loss 1.336 | ppl 2.52 | wps 16876.5 | ups 4.75 | wpb 3556.4 | bsz 141.6 | num_updates 92824 | lr 0.000103793 | gnorm 1.246 | train_wall 219 | wall 0
2024-05-30 22:18:33 | INFO | fairseq.trainer | begin training epoch 83
2024-05-30 22:18:48 | INFO | train_inner | epoch 083:     76 / 1132 loss=2.911, nll_loss=1.295, ppl=2.45, wps=13398.5, ups=3.75, wpb=3577.1, bsz=147.4, num_updates=92900, lr=0.000103751, gnorm=1.197, train_wall=19, wall=0
2024-05-30 22:19:07 | INFO | train_inner | epoch 083:    176 / 1132 loss=2.917, nll_loss=1.301, ppl=2.46, wps=18380.6, ups=5.14, wpb=3578.6, bsz=142.5, num_updates=93000, lr=0.000103695, gnorm=1.224, train_wall=19, wall=0
2024-05-30 22:19:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:19:11 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 4.001 | nll_loss 2.422 | ppl 5.36 | wps 51991.2 | wpb 2685.2 | bsz 107.1 | num_updates 93000 | best_loss 11.059
2024-05-30 22:19:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:19:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_83_93000.pt (epoch 83 @ 93000 updates, score 4.001) (writing took 4.11871641036123 seconds)
2024-05-30 22:19:35 | INFO | train_inner | epoch 083:    276 / 1132 loss=2.94, nll_loss=1.322, ppl=2.5, wps=12964, ups=3.62, wpb=3579.3, bsz=128.2, num_updates=93100, lr=0.000103639, gnorm=1.256, train_wall=19, wall=0
2024-05-30 22:19:54 | INFO | train_inner | epoch 083:    376 / 1132 loss=2.937, nll_loss=1.32, ppl=2.5, wps=18460, ups=5.22, wpb=3535.8, bsz=127.8, num_updates=93200, lr=0.000103584, gnorm=1.251, train_wall=19, wall=0
2024-05-30 22:20:14 | INFO | train_inner | epoch 083:    476 / 1132 loss=2.918, nll_loss=1.303, ppl=2.47, wps=17662.7, ups=5.07, wpb=3486.1, bsz=149.8, num_updates=93300, lr=0.000103528, gnorm=1.252, train_wall=19, wall=0
2024-05-30 22:20:33 | INFO | train_inner | epoch 083:    576 / 1132 loss=2.928, nll_loss=1.311, ppl=2.48, wps=17834.5, ups=5.09, wpb=3500.6, bsz=138.2, num_updates=93400, lr=0.000103473, gnorm=1.274, train_wall=19, wall=0
2024-05-30 22:20:53 | INFO | train_inner | epoch 083:    676 / 1132 loss=2.962, nll_loss=1.351, ppl=2.55, wps=18386.4, ups=5.13, wpb=3585.7, bsz=138, num_updates=93500, lr=0.000103418, gnorm=1.262, train_wall=19, wall=0
2024-05-30 22:21:13 | INFO | train_inner | epoch 083:    776 / 1132 loss=2.941, nll_loss=1.332, ppl=2.52, wps=18214.9, ups=5.11, wpb=3565.3, bsz=153.6, num_updates=93600, lr=0.000103362, gnorm=1.244, train_wall=19, wall=0
2024-05-30 22:21:32 | INFO | train_inner | epoch 083:    876 / 1132 loss=2.969, nll_loss=1.362, ppl=2.57, wps=18604.1, ups=5.17, wpb=3601.8, bsz=141.8, num_updates=93700, lr=0.000103307, gnorm=1.246, train_wall=19, wall=0
2024-05-30 22:21:52 | INFO | train_inner | epoch 083:    976 / 1132 loss=2.967, nll_loss=1.359, ppl=2.57, wps=17535.8, ups=4.97, wpb=3527.2, bsz=141.9, num_updates=93800, lr=0.000103252, gnorm=1.294, train_wall=20, wall=0
2024-05-30 22:22:12 | INFO | train_inner | epoch 083:   1076 / 1132 loss=2.97, nll_loss=1.363, ppl=2.57, wps=17460.9, ups=4.94, wpb=3538, bsz=138.6, num_updates=93900, lr=0.000103197, gnorm=1.269, train_wall=20, wall=0
2024-05-30 22:22:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:22:27 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 3.987 | nll_loss 2.418 | ppl 5.34 | wps 51943.2 | wpb 2685.2 | bsz 107.1 | num_updates 93956 | best_loss 11.059
2024-05-30 22:22:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:22:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 83 @ 93956 updates, score 3.987) (writing took 3.186825953889638 seconds)
2024-05-30 22:22:31 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2024-05-30 22:22:31 | INFO | train | epoch 083 | loss 2.942 | nll_loss 1.33 | ppl 2.51 | wps 16950.7 | ups 4.77 | wpb 3556.4 | bsz 141.6 | num_updates 93956 | lr 0.000103166 | gnorm 1.251 | train_wall 218 | wall 0
2024-05-30 22:22:31 | INFO | fairseq.trainer | begin training epoch 84
2024-05-30 22:22:39 | INFO | train_inner | epoch 084:     44 / 1132 loss=2.94, nll_loss=1.328, ppl=2.51, wps=13392.6, ups=3.7, wpb=3622, bsz=149.5, num_updates=94000, lr=0.000103142, gnorm=1.21, train_wall=20, wall=0
2024-05-30 22:22:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:22:43 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 4.004 | nll_loss 2.428 | ppl 5.38 | wps 52626.2 | wpb 2685.2 | bsz 107.1 | num_updates 94000 | best_loss 11.059
2024-05-30 22:22:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:22:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_84_94000.pt (epoch 84 @ 94000 updates, score 4.004) (writing took 3.7670213067904115 seconds)
2024-05-30 22:23:07 | INFO | train_inner | epoch 084:    144 / 1132 loss=2.899, nll_loss=1.28, ppl=2.43, wps=13082.4, ups=3.66, wpb=3571.9, bsz=144.4, num_updates=94100, lr=0.000103087, gnorm=1.219, train_wall=20, wall=0
2024-05-30 22:23:26 | INFO | train_inner | epoch 084:    244 / 1132 loss=2.899, nll_loss=1.28, ppl=2.43, wps=17762.7, ups=5.04, wpb=3521, bsz=155.7, num_updates=94200, lr=0.000103033, gnorm=1.224, train_wall=19, wall=0
2024-05-30 22:23:46 | INFO | train_inner | epoch 084:    344 / 1132 loss=2.943, nll_loss=1.328, ppl=2.51, wps=18120.7, ups=5.05, wpb=3587.1, bsz=123.2, num_updates=94300, lr=0.000102978, gnorm=1.26, train_wall=19, wall=0
2024-05-30 22:24:06 | INFO | train_inner | epoch 084:    444 / 1132 loss=2.945, nll_loss=1.332, ppl=2.52, wps=17980.9, ups=5.02, wpb=3578.6, bsz=132.5, num_updates=94400, lr=0.000102923, gnorm=1.283, train_wall=19, wall=0
2024-05-30 22:24:26 | INFO | train_inner | epoch 084:    544 / 1132 loss=2.913, nll_loss=1.298, ppl=2.46, wps=18146.2, ups=5.05, wpb=3591.3, bsz=158.3, num_updates=94500, lr=0.000102869, gnorm=1.223, train_wall=19, wall=0
2024-05-30 22:24:46 | INFO | train_inner | epoch 084:    644 / 1132 loss=2.94, nll_loss=1.328, ppl=2.51, wps=18120.5, ups=5.06, wpb=3582.8, bsz=139.2, num_updates=94600, lr=0.000102815, gnorm=1.24, train_wall=19, wall=0
2024-05-30 22:25:06 | INFO | train_inner | epoch 084:    744 / 1132 loss=2.956, nll_loss=1.345, ppl=2.54, wps=17925.1, ups=5.04, wpb=3556.1, bsz=133.1, num_updates=94700, lr=0.00010276, gnorm=1.277, train_wall=19, wall=0
2024-05-30 22:25:26 | INFO | train_inner | epoch 084:    844 / 1132 loss=2.966, nll_loss=1.358, ppl=2.56, wps=18072.6, ups=4.98, wpb=3627.9, bsz=144.5, num_updates=94800, lr=0.000102706, gnorm=1.224, train_wall=20, wall=0
2024-05-30 22:25:45 | INFO | train_inner | epoch 084:    944 / 1132 loss=2.945, nll_loss=1.332, ppl=2.52, wps=17492.6, ups=5.08, wpb=3441.3, bsz=141.5, num_updates=94900, lr=0.000102652, gnorm=1.273, train_wall=19, wall=0
2024-05-30 22:26:05 | INFO | train_inner | epoch 084:   1044 / 1132 loss=2.953, nll_loss=1.344, ppl=2.54, wps=18552.7, ups=5.14, wpb=3607.1, bsz=155.9, num_updates=95000, lr=0.000102598, gnorm=1.241, train_wall=19, wall=0
2024-05-30 22:26:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:26:08 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 3.999 | nll_loss 2.424 | ppl 5.37 | wps 53915.6 | wpb 2685.2 | bsz 107.1 | num_updates 95000 | best_loss 11.059
2024-05-30 22:26:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:26:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_84_95000.pt (epoch 84 @ 95000 updates, score 3.999) (writing took 3.8850270598195493 seconds)
2024-05-30 22:26:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:26:33 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 4.004 | nll_loss 2.426 | ppl 5.37 | wps 52025.9 | wpb 2685.2 | bsz 107.1 | num_updates 95088 | best_loss 11.059
2024-05-30 22:26:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:26:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 84 @ 95088 updates, score 4.004) (writing took 3.4526318409480155 seconds)
2024-05-30 22:26:36 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2024-05-30 22:26:36 | INFO | train | epoch 084 | loss 2.936 | nll_loss 1.323 | ppl 2.5 | wps 16381.8 | ups 4.61 | wpb 3556.4 | bsz 141.6 | num_updates 95088 | lr 0.00010255 | gnorm 1.248 | train_wall 219 | wall 0
2024-05-30 22:26:36 | INFO | fairseq.trainer | begin training epoch 85
2024-05-30 22:26:39 | INFO | train_inner | epoch 085:     12 / 1132 loss=2.953, nll_loss=1.34, ppl=2.53, wps=10003.8, ups=2.93, wpb=3413.6, bsz=129.5, num_updates=95100, lr=0.000102544, gnorm=1.291, train_wall=19, wall=0
2024-05-30 22:26:59 | INFO | train_inner | epoch 085:    112 / 1132 loss=2.871, nll_loss=1.246, ppl=2.37, wps=17871.8, ups=5.1, wpb=3505.6, bsz=154.6, num_updates=95200, lr=0.00010249, gnorm=1.227, train_wall=19, wall=0
2024-05-30 22:27:18 | INFO | train_inner | epoch 085:    212 / 1132 loss=2.9, nll_loss=1.28, ppl=2.43, wps=18294.6, ups=5.1, wpb=3587.9, bsz=155.4, num_updates=95300, lr=0.000102436, gnorm=1.204, train_wall=19, wall=0
2024-05-30 22:27:38 | INFO | train_inner | epoch 085:    312 / 1132 loss=2.92, nll_loss=1.304, ppl=2.47, wps=18055.8, ups=5.07, wpb=3559.2, bsz=136.8, num_updates=95400, lr=0.000102383, gnorm=1.243, train_wall=19, wall=0
2024-05-30 22:27:58 | INFO | train_inner | epoch 085:    412 / 1132 loss=2.926, nll_loss=1.311, ppl=2.48, wps=17998.8, ups=4.98, wpb=3614.5, bsz=147.3, num_updates=95500, lr=0.000102329, gnorm=1.232, train_wall=20, wall=0
2024-05-30 22:28:17 | INFO | train_inner | epoch 085:    512 / 1132 loss=2.946, nll_loss=1.333, ppl=2.52, wps=18517.1, ups=5.15, wpb=3593.2, bsz=134.6, num_updates=95600, lr=0.000102275, gnorm=1.254, train_wall=19, wall=0
2024-05-30 22:28:37 | INFO | train_inner | epoch 085:    612 / 1132 loss=2.924, nll_loss=1.312, ppl=2.48, wps=18142.3, ups=5.1, wpb=3556.7, bsz=151.9, num_updates=95700, lr=0.000102222, gnorm=1.239, train_wall=19, wall=0
2024-05-30 22:28:57 | INFO | train_inner | epoch 085:    712 / 1132 loss=2.946, nll_loss=1.336, ppl=2.52, wps=18278.8, ups=5.07, wpb=3605.4, bsz=143.4, num_updates=95800, lr=0.000102169, gnorm=1.258, train_wall=19, wall=0
2024-05-30 22:29:17 | INFO | train_inner | epoch 085:    812 / 1132 loss=2.94, nll_loss=1.327, ppl=2.51, wps=17950.3, ups=5, wpb=3587.6, bsz=151.4, num_updates=95900, lr=0.000102115, gnorm=1.252, train_wall=20, wall=0
2024-05-30 22:29:36 | INFO | train_inner | epoch 085:    912 / 1132 loss=2.967, nll_loss=1.357, ppl=2.56, wps=17978.1, ups=5.08, wpb=3536.8, bsz=120.5, num_updates=96000, lr=0.000102062, gnorm=1.287, train_wall=19, wall=0
2024-05-30 22:29:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:29:40 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 3.999 | nll_loss 2.423 | ppl 5.36 | wps 51242.4 | wpb 2685.2 | bsz 107.1 | num_updates 96000 | best_loss 11.059
2024-05-30 22:29:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:29:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_85_96000.pt (epoch 85 @ 96000 updates, score 3.999) (writing took 4.110641228035092 seconds)
2024-05-30 22:30:04 | INFO | train_inner | epoch 085:   1012 / 1132 loss=2.961, nll_loss=1.351, ppl=2.55, wps=12653.8, ups=3.64, wpb=3478.7, bsz=123.6, num_updates=96100, lr=0.000102009, gnorm=1.295, train_wall=19, wall=0
2024-05-30 22:30:24 | INFO | train_inner | epoch 085:   1112 / 1132 loss=2.969, nll_loss=1.36, ppl=2.57, wps=17855.4, ups=5.04, wpb=3542.9, bsz=139.4, num_updates=96200, lr=0.000101956, gnorm=1.278, train_wall=19, wall=0
2024-05-30 22:30:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:30:31 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 4 | nll_loss 2.422 | ppl 5.36 | wps 51209.3 | wpb 2685.2 | bsz 107.1 | num_updates 96220 | best_loss 11.059
2024-05-30 22:30:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:30:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 85 @ 96220 updates, score 4.0) (writing took 3.4061956820078194 seconds)
2024-05-30 22:30:35 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2024-05-30 22:30:35 | INFO | train | epoch 085 | loss 2.934 | nll_loss 1.32 | ppl 2.5 | wps 16884.8 | ups 4.75 | wpb 3556.4 | bsz 141.6 | num_updates 96220 | lr 0.000101945 | gnorm 1.253 | train_wall 219 | wall 0
2024-05-30 22:30:35 | INFO | fairseq.trainer | begin training epoch 86
2024-05-30 22:30:50 | INFO | train_inner | epoch 086:     80 / 1132 loss=2.899, nll_loss=1.28, ppl=2.43, wps=13187.3, ups=3.76, wpb=3507.2, bsz=135.3, num_updates=96300, lr=0.000101903, gnorm=1.254, train_wall=19, wall=0
2024-05-30 22:31:10 | INFO | train_inner | epoch 086:    180 / 1132 loss=2.9, nll_loss=1.282, ppl=2.43, wps=18582.9, ups=5.12, wpb=3629.3, bsz=145.5, num_updates=96400, lr=0.00010185, gnorm=1.226, train_wall=19, wall=0
2024-05-30 22:31:29 | INFO | train_inner | epoch 086:    280 / 1132 loss=2.902, nll_loss=1.285, ppl=2.44, wps=18130.2, ups=5.12, wpb=3542.5, bsz=149.4, num_updates=96500, lr=0.000101797, gnorm=1.24, train_wall=19, wall=0
2024-05-30 22:31:49 | INFO | train_inner | epoch 086:    380 / 1132 loss=2.924, nll_loss=1.308, ppl=2.48, wps=17922.7, ups=5.03, wpb=3561.8, bsz=128.9, num_updates=96600, lr=0.000101745, gnorm=1.262, train_wall=20, wall=0
2024-05-30 22:32:09 | INFO | train_inner | epoch 086:    480 / 1132 loss=2.922, nll_loss=1.308, ppl=2.48, wps=18309.3, ups=5.02, wpb=3644.8, bsz=158.2, num_updates=96700, lr=0.000101692, gnorm=1.22, train_wall=20, wall=0
2024-05-30 22:32:29 | INFO | train_inner | epoch 086:    580 / 1132 loss=2.938, nll_loss=1.324, ppl=2.5, wps=18067.4, ups=5.05, wpb=3575.6, bsz=140.1, num_updates=96800, lr=0.000101639, gnorm=1.264, train_wall=19, wall=0
2024-05-30 22:32:49 | INFO | train_inner | epoch 086:    680 / 1132 loss=2.949, nll_loss=1.337, ppl=2.53, wps=17872.1, ups=5.02, wpb=3558.4, bsz=128, num_updates=96900, lr=0.000101587, gnorm=1.271, train_wall=20, wall=0
2024-05-30 22:33:09 | INFO | train_inner | epoch 086:    780 / 1132 loss=2.943, nll_loss=1.33, ppl=2.51, wps=17695.7, ups=5.06, wpb=3495.8, bsz=133.8, num_updates=97000, lr=0.000101535, gnorm=1.272, train_wall=19, wall=0
2024-05-30 22:33:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:33:12 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 4.009 | nll_loss 2.44 | ppl 5.43 | wps 51423.2 | wpb 2685.2 | bsz 107.1 | num_updates 97000 | best_loss 11.059
2024-05-30 22:33:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:33:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_86_97000.pt (epoch 86 @ 97000 updates, score 4.009) (writing took 4.3244015499949455 seconds)
2024-05-30 22:33:37 | INFO | train_inner | epoch 086:    880 / 1132 loss=2.944, nll_loss=1.332, ppl=2.52, wps=12817.9, ups=3.58, wpb=3583.1, bsz=150.6, num_updates=97100, lr=0.000101482, gnorm=1.258, train_wall=20, wall=0
2024-05-30 22:33:56 | INFO | train_inner | epoch 086:    980 / 1132 loss=2.938, nll_loss=1.324, ppl=2.5, wps=17500.2, ups=5.01, wpb=3494.1, bsz=139.8, num_updates=97200, lr=0.00010143, gnorm=1.259, train_wall=20, wall=0
2024-05-30 22:34:16 | INFO | train_inner | epoch 086:   1080 / 1132 loss=2.945, nll_loss=1.335, ppl=2.52, wps=18145.9, ups=5.18, wpb=3503.4, bsz=144.8, num_updates=97300, lr=0.000101378, gnorm=1.273, train_wall=19, wall=0
2024-05-30 22:34:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:34:29 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 3.988 | nll_loss 2.415 | ppl 5.33 | wps 53644 | wpb 2685.2 | bsz 107.1 | num_updates 97352 | best_loss 11.059
2024-05-30 22:34:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:34:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 86 @ 97352 updates, score 3.988) (writing took 3.632672163192183 seconds)
2024-05-30 22:34:33 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2024-05-30 22:34:33 | INFO | train | epoch 086 | loss 2.929 | nll_loss 1.314 | ppl 2.49 | wps 16896.9 | ups 4.75 | wpb 3556.4 | bsz 141.6 | num_updates 97352 | lr 0.000101351 | gnorm 1.254 | train_wall 219 | wall 0
2024-05-30 22:34:33 | INFO | fairseq.trainer | begin training epoch 87
2024-05-30 22:34:43 | INFO | train_inner | epoch 087:     48 / 1132 loss=2.919, nll_loss=1.305, ppl=2.47, wps=13459.5, ups=3.74, wpb=3599.6, bsz=151.6, num_updates=97400, lr=0.000101326, gnorm=1.234, train_wall=19, wall=0
2024-05-30 22:35:03 | INFO | train_inner | epoch 087:    148 / 1132 loss=2.904, nll_loss=1.286, ppl=2.44, wps=18063.5, ups=4.99, wpb=3622.4, bsz=145.9, num_updates=97500, lr=0.000101274, gnorm=1.218, train_wall=20, wall=0
2024-05-30 22:35:23 | INFO | train_inner | epoch 087:    248 / 1132 loss=2.915, nll_loss=1.296, ppl=2.45, wps=18113.8, ups=4.98, wpb=3634.7, bsz=141, num_updates=97600, lr=0.000101222, gnorm=1.24, train_wall=20, wall=0
2024-05-30 22:35:42 | INFO | train_inner | epoch 087:    348 / 1132 loss=2.897, nll_loss=1.276, ppl=2.42, wps=18253.5, ups=5.18, wpb=3525.1, bsz=141.8, num_updates=97700, lr=0.00010117, gnorm=1.249, train_wall=19, wall=0
2024-05-30 22:36:01 | INFO | train_inner | epoch 087:    448 / 1132 loss=2.935, nll_loss=1.317, ppl=2.49, wps=17918.4, ups=5.17, wpb=3466.5, bsz=120.7, num_updates=97800, lr=0.000101118, gnorm=1.325, train_wall=19, wall=0
2024-05-30 22:36:21 | INFO | train_inner | epoch 087:    548 / 1132 loss=2.908, nll_loss=1.29, ppl=2.44, wps=18178.2, ups=5.1, wpb=3565.7, bsz=150.2, num_updates=97900, lr=0.000101067, gnorm=1.237, train_wall=19, wall=0
2024-05-30 22:36:40 | INFO | train_inner | epoch 087:    648 / 1132 loss=2.929, nll_loss=1.315, ppl=2.49, wps=18499.7, ups=5.22, wpb=3542.4, bsz=137.8, num_updates=98000, lr=0.000101015, gnorm=1.264, train_wall=19, wall=0
2024-05-30 22:36:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:36:44 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 4.005 | nll_loss 2.432 | ppl 5.4 | wps 51711.2 | wpb 2685.2 | bsz 107.1 | num_updates 98000 | best_loss 11.059
2024-05-30 22:36:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:36:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_87_98000.pt (epoch 87 @ 98000 updates, score 4.005) (writing took 4.1834617499262094 seconds)
2024-05-30 22:37:08 | INFO | train_inner | epoch 087:    748 / 1132 loss=2.93, nll_loss=1.315, ppl=2.49, wps=12485.2, ups=3.62, wpb=3450.5, bsz=134.8, num_updates=98100, lr=0.000100964, gnorm=1.291, train_wall=19, wall=0
2024-05-30 22:37:28 | INFO | train_inner | epoch 087:    848 / 1132 loss=2.92, nll_loss=1.309, ppl=2.48, wps=18164, ups=4.98, wpb=3644.4, bsz=172.5, num_updates=98200, lr=0.000100912, gnorm=1.222, train_wall=20, wall=0
2024-05-30 22:37:48 | INFO | train_inner | epoch 087:    948 / 1132 loss=2.967, nll_loss=1.359, ppl=2.56, wps=18169.6, ups=5.02, wpb=3617.2, bsz=131.9, num_updates=98300, lr=0.000100861, gnorm=1.27, train_wall=20, wall=0
2024-05-30 22:38:07 | INFO | train_inner | epoch 087:   1048 / 1132 loss=2.933, nll_loss=1.319, ppl=2.49, wps=17709.3, ups=5.09, wpb=3476.7, bsz=145.8, num_updates=98400, lr=0.00010081, gnorm=1.276, train_wall=19, wall=0
2024-05-30 22:38:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:38:28 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 4.002 | nll_loss 2.429 | ppl 5.38 | wps 50997.3 | wpb 2685.2 | bsz 107.1 | num_updates 98484 | best_loss 11.059
2024-05-30 22:38:28 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:38:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 87 @ 98484 updates, score 4.002) (writing took 3.507465207017958 seconds)
2024-05-30 22:38:31 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2024-05-30 22:38:31 | INFO | train | epoch 087 | loss 2.925 | nll_loss 1.31 | ppl 2.48 | wps 16912.5 | ups 4.76 | wpb 3556.4 | bsz 141.6 | num_updates 98484 | lr 0.000100767 | gnorm 1.258 | train_wall 219 | wall 0
2024-05-30 22:38:31 | INFO | fairseq.trainer | begin training epoch 88
2024-05-30 22:38:34 | INFO | train_inner | epoch 088:     16 / 1132 loss=2.953, nll_loss=1.342, ppl=2.54, wps=13073.1, ups=3.68, wpb=3549, bsz=124.3, num_updates=98500, lr=0.000100759, gnorm=1.261, train_wall=19, wall=0
2024-05-30 22:38:54 | INFO | train_inner | epoch 088:    116 / 1132 loss=2.878, nll_loss=1.256, ppl=2.39, wps=17962.1, ups=5.05, wpb=3556.2, bsz=148.2, num_updates=98600, lr=0.000100707, gnorm=1.225, train_wall=19, wall=0
2024-05-30 22:39:13 | INFO | train_inner | epoch 088:    216 / 1132 loss=2.904, nll_loss=1.284, ppl=2.44, wps=18646.1, ups=5.24, wpb=3561.7, bsz=140.9, num_updates=98700, lr=0.000100656, gnorm=1.268, train_wall=19, wall=0
2024-05-30 22:39:33 | INFO | train_inner | epoch 088:    316 / 1132 loss=2.919, nll_loss=1.302, ppl=2.47, wps=18384.4, ups=5, wpb=3677.2, bsz=142.8, num_updates=98800, lr=0.000100605, gnorm=1.213, train_wall=20, wall=0
2024-05-30 22:39:53 | INFO | train_inner | epoch 088:    416 / 1132 loss=2.917, nll_loss=1.302, ppl=2.47, wps=18206.1, ups=5.07, wpb=3591.2, bsz=130.7, num_updates=98900, lr=0.000100555, gnorm=1.247, train_wall=19, wall=0
2024-05-30 22:40:13 | INFO | train_inner | epoch 088:    516 / 1132 loss=2.896, nll_loss=1.28, ppl=2.43, wps=17813, ups=4.95, wpb=3599.1, bsz=172.2, num_updates=99000, lr=0.000100504, gnorm=1.23, train_wall=20, wall=0
2024-05-30 22:40:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:40:17 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 4.014 | nll_loss 2.441 | ppl 5.43 | wps 51476.5 | wpb 2685.2 | bsz 107.1 | num_updates 99000 | best_loss 11.059
2024-05-30 22:40:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:40:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_88_99000.pt (epoch 88 @ 99000 updates, score 4.014) (writing took 4.2192255249246955 seconds)
2024-05-30 22:40:41 | INFO | train_inner | epoch 088:    616 / 1132 loss=2.919, nll_loss=1.302, ppl=2.47, wps=12677.9, ups=3.63, wpb=3492.3, bsz=131.4, num_updates=99100, lr=0.000100453, gnorm=1.277, train_wall=19, wall=0
2024-05-30 22:41:01 | INFO | train_inner | epoch 088:    716 / 1132 loss=2.924, nll_loss=1.308, ppl=2.48, wps=17893.4, ups=5.04, wpb=3549.6, bsz=140.6, num_updates=99200, lr=0.000100402, gnorm=1.262, train_wall=19, wall=0
2024-05-30 22:41:20 | INFO | train_inner | epoch 088:    816 / 1132 loss=2.928, nll_loss=1.314, ppl=2.49, wps=18019.2, ups=5.14, wpb=3508.4, bsz=139, num_updates=99300, lr=0.000100352, gnorm=1.294, train_wall=19, wall=0
2024-05-30 22:41:40 | INFO | train_inner | epoch 088:    916 / 1132 loss=2.941, nll_loss=1.329, ppl=2.51, wps=17817.7, ups=5.08, wpb=3505.1, bsz=132.6, num_updates=99400, lr=0.000100301, gnorm=1.285, train_wall=19, wall=0
2024-05-30 22:42:00 | INFO | train_inner | epoch 088:   1016 / 1132 loss=2.941, nll_loss=1.328, ppl=2.51, wps=17707.2, ups=5.05, wpb=3505.8, bsz=136.4, num_updates=99500, lr=0.000100251, gnorm=1.305, train_wall=19, wall=0
2024-05-30 22:42:20 | INFO | train_inner | epoch 088:   1116 / 1132 loss=2.944, nll_loss=1.332, ppl=2.52, wps=17845.6, ups=5.02, wpb=3555.3, bsz=145.8, num_updates=99600, lr=0.000100201, gnorm=1.266, train_wall=20, wall=0
2024-05-30 22:42:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:42:26 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 4.002 | nll_loss 2.432 | ppl 5.4 | wps 53463.9 | wpb 2685.2 | bsz 107.1 | num_updates 99616 | best_loss 11.059
2024-05-30 22:42:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:42:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 88 @ 99616 updates, score 4.002) (writing took 3.288922310806811 seconds)
2024-05-30 22:42:30 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2024-05-30 22:42:30 | INFO | train | epoch 088 | loss 2.919 | nll_loss 1.303 | ppl 2.47 | wps 16874.3 | ups 4.74 | wpb 3556.4 | bsz 141.6 | num_updates 99616 | lr 0.000100193 | gnorm 1.26 | train_wall 219 | wall 0
2024-05-30 22:42:30 | INFO | fairseq.trainer | begin training epoch 89
2024-05-30 22:42:46 | INFO | train_inner | epoch 089:     84 / 1132 loss=2.873, nll_loss=1.249, ppl=2.38, wps=13241.7, ups=3.81, wpb=3476, bsz=142.1, num_updates=99700, lr=0.00010015, gnorm=1.248, train_wall=19, wall=0
2024-05-30 22:43:05 | INFO | train_inner | epoch 089:    184 / 1132 loss=2.91, nll_loss=1.292, ppl=2.45, wps=18362.5, ups=5.14, wpb=3575.3, bsz=130, num_updates=99800, lr=0.0001001, gnorm=1.265, train_wall=19, wall=0
2024-05-30 22:43:25 | INFO | train_inner | epoch 089:    284 / 1132 loss=2.887, nll_loss=1.267, ppl=2.41, wps=18314.8, ups=5.04, wpb=3634.3, bsz=152, num_updates=99900, lr=0.00010005, gnorm=1.223, train_wall=19, wall=0
2024-05-30 22:43:45 | INFO | train_inner | epoch 089:    384 / 1132 loss=2.902, nll_loss=1.283, ppl=2.43, wps=18285.4, ups=5.15, wpb=3548.8, bsz=144.6, num_updates=100000, lr=0.0001, gnorm=1.27, train_wall=19, wall=0
2024-05-30 22:43:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-05-30 22:43:48 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 4.006 | nll_loss 2.434 | ppl 5.4 | wps 53625.6 | wpb 2685.2 | bsz 107.1 | num_updates 100000 | best_loss 11.059
2024-05-30 22:43:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-05-30 22:43:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_89_100000.pt (epoch 89 @ 100000 updates, score 4.006) (writing took 4.100312924012542 seconds)
2024-05-30 22:43:52 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2024-05-30 22:43:52 | INFO | train | epoch 089 | loss 2.889 | nll_loss 1.269 | ppl 2.41 | wps 16533.8 | ups 4.65 | wpb 3557.4 | bsz 142.8 | num_updates 100000 | lr 0.0001 | gnorm 1.25 | train_wall 73 | wall 0
2024-05-30 22:43:52 | INFO | fairseq_cli.train | done training in 18471.9 seconds
