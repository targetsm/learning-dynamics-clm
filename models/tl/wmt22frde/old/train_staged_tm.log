2024-07-07 18:38:17 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt22.sep.tokenized.fr-de', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=1000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=100, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-07 18:38:17 | INFO | fairseq.tasks.translation | [fr] dictionary: 10016 types
2024-07-07 18:38:17 | INFO | fairseq.tasks.translation | [de] dictionary: 10032 types
2024-07-07 18:38:17 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.fr
2024-07-07 18:38:17 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.de
2024-07-07 18:38:17 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de valid fr-de 3238 examples
2024-07-07 18:38:18 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10016, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10032, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=10032, bias=False)
  )
)
2024-07-07 18:38:18 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-07 18:38:18 | INFO | fairseq_cli.train | model: transformer_iwslt_de_en (TransformerModel)
2024-07-07 18:38:18 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-07 18:38:18 | INFO | fairseq_cli.train | num. model params: 41807872 (num. trained: 41807872)
2024-07-07 18:38:41 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-07 18:38:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-07 18:38:41 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-07 18:38:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-07 18:38:41 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-07 18:38:41 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-07 18:38:41 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/checkpoint_last.pt
2024-07-07 18:38:41 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-07 18:38:42 | INFO | fairseq.data.data_utils | loaded 15571322 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.fr
2024-07-07 18:38:42 | INFO | fairseq.data.data_utils | loaded 15571322 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.de
2024-07-07 18:38:42 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de train fr-de 15571322 examples
2024-07-07 18:39:00 | INFO | fairseq.trainer | begin training epoch 1
2024-07-07 18:39:25 | INFO | train_inner | epoch 001:    100 / 150053 loss=13.089, nll_loss=12.984, ppl=8102.45, wps=17077.2, ups=4.92, wpb=3474.8, bsz=91.2, num_updates=100, lr=1.25e-05, gnorm=2.694, train_wall=25, wall=45
2024-07-07 18:39:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-07 18:39:27 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.211 | nll_loss 11.998 | ppl 4089.24 | wps 54073.1 | wpb 2588.8 | bsz 75.3 | num_updates 100
2024-07-07 18:39:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 18:39:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_100.pt (epoch 1 @ 100 updates, score 12.211) (writing took 2.035707900300622 seconds)
2024-07-07 18:39:48 | INFO | train_inner | epoch 001:    200 / 150053 loss=11.849, nll_loss=11.599, ppl=3101.49, wps=15290.4, ups=4.28, wpb=3570.1, bsz=80.2, num_updates=200, lr=2.5e-05, gnorm=1.23, train_wall=19, wall=68
2024-07-07 18:39:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 18:39:51 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.24 | nll_loss 10.904 | ppl 1916.45 | wps 54049.3 | wpb 2588.8 | bsz 75.3 | num_updates 200 | best_loss 12.211
2024-07-07 18:39:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 18:39:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_200.pt (epoch 1 @ 200 updates, score 11.24) (writing took 3.293338260613382 seconds)
2024-07-07 18:40:13 | INFO | train_inner | epoch 001:    300 / 150053 loss=10.957, nll_loss=10.565, ppl=1514.99, wps=14459.9, ups=4.04, wpb=3574.9, bsz=95.8, num_updates=300, lr=3.75e-05, gnorm=1.192, train_wall=19, wall=93
2024-07-07 18:40:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 18:40:15 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.648 | nll_loss 10.17 | ppl 1152.11 | wps 53902.3 | wpb 2588.8 | bsz 75.3 | num_updates 300 | best_loss 12.211
2024-07-07 18:40:15 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 18:40:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_300.pt (epoch 1 @ 300 updates, score 10.648) (writing took 3.328063230961561 seconds)
2024-07-07 18:40:38 | INFO | train_inner | epoch 001:    400 / 150053 loss=10.541, nll_loss=10.034, ppl=1048.56, wps=14325, ups=4, wpb=3576.8, bsz=110.7, num_updates=400, lr=5e-05, gnorm=1.429, train_wall=19, wall=118
2024-07-07 18:40:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 18:40:40 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.449 | nll_loss 9.876 | ppl 939.57 | wps 53848.1 | wpb 2588.8 | bsz 75.3 | num_updates 400 | best_loss 12.211
2024-07-07 18:40:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 18:40:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_400.pt (epoch 1 @ 400 updates, score 10.449) (writing took 4.145437627099454 seconds)
2024-07-07 18:41:04 | INFO | train_inner | epoch 001:    500 / 150053 loss=10.389, nll_loss=9.829, ppl=909.41, wps=13783.9, ups=3.89, wpb=3545.1, bsz=106.6, num_updates=500, lr=6.25e-05, gnorm=1.171, train_wall=19, wall=143
2024-07-07 18:41:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 18:41:06 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.364 | nll_loss 9.765 | ppl 870.19 | wps 54125.2 | wpb 2588.8 | bsz 75.3 | num_updates 500 | best_loss 12.211
2024-07-07 18:41:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 18:41:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_500.pt (epoch 1 @ 500 updates, score 10.364) (writing took 3.5784697718918324 seconds)
2024-07-07 18:41:29 | INFO | train_inner | epoch 001:    600 / 150053 loss=10.329, nll_loss=9.752, ppl=862.27, wps=14258.3, ups=3.96, wpb=3598.9, bsz=98.6, num_updates=600, lr=7.5e-05, gnorm=1.197, train_wall=19, wall=169
2024-07-07 18:41:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 18:41:31 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.379 | nll_loss 9.782 | ppl 880.6 | wps 52720.7 | wpb 2588.8 | bsz 75.3 | num_updates 600 | best_loss 12.211
2024-07-07 18:41:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 18:41:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_600.pt (epoch 1 @ 600 updates, score 10.379) (writing took 3.4237064607441425 seconds)
2024-07-07 18:41:54 | INFO | train_inner | epoch 001:    700 / 150053 loss=10.27, nll_loss=9.684, ppl=822.4, wps=14187.8, ups=3.99, wpb=3559.1, bsz=89.2, num_updates=700, lr=8.75e-05, gnorm=1.277, train_wall=19, wall=194
2024-07-07 18:41:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 18:41:56 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.307 | nll_loss 9.709 | ppl 836.88 | wps 53807.9 | wpb 2588.8 | bsz 75.3 | num_updates 700 | best_loss 12.211
2024-07-07 18:41:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 18:42:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_700.pt (epoch 1 @ 700 updates, score 10.307) (writing took 3.4761299891397357 seconds)
2024-07-07 18:42:19 | INFO | train_inner | epoch 001:    800 / 150053 loss=10.12, nll_loss=9.515, ppl=731.39, wps=13957.2, ups=3.97, wpb=3517, bsz=99.8, num_updates=800, lr=0.0001, gnorm=1.297, train_wall=19, wall=219
2024-07-07 18:42:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 18:42:22 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.113 | nll_loss 9.486 | ppl 716.96 | wps 53616.2 | wpb 2588.8 | bsz 75.3 | num_updates 800 | best_loss 12.211
2024-07-07 18:42:22 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 18:42:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_800.pt (epoch 1 @ 800 updates, score 10.113) (writing took 3.6388842333108187 seconds)
2024-07-07 18:42:44 | INFO | train_inner | epoch 001:    900 / 150053 loss=9.955, nll_loss=9.327, ppl=642.43, wps=13892.5, ups=3.98, wpb=3486.5, bsz=101.7, num_updates=900, lr=0.0001125, gnorm=1.339, train_wall=19, wall=244
2024-07-07 18:42:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 18:42:47 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.856 | nll_loss 9.18 | ppl 580 | wps 53439.5 | wpb 2588.8 | bsz 75.3 | num_updates 900 | best_loss 12.211
2024-07-07 18:42:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 18:42:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_900.pt (epoch 1 @ 900 updates, score 9.856) (writing took 3.449888058938086 seconds)
2024-07-07 18:43:10 | INFO | train_inner | epoch 001:   1000 / 150053 loss=9.756, nll_loss=9.098, ppl=547.95, wps=14329.6, ups=3.99, wpb=3589.7, bsz=108.6, num_updates=1000, lr=0.000125, gnorm=1.43, train_wall=19, wall=269
2024-07-07 18:43:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 18:43:12 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.711 | nll_loss 9.025 | ppl 520.89 | wps 53941.7 | wpb 2588.8 | bsz 75.3 | num_updates 1000 | best_loss 12.211
2024-07-07 18:43:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 18:43:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 9.711) (writing took 3.8092708121985197 seconds)
2024-07-07 18:43:16 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-07 18:43:16 | INFO | train | epoch 001 | loss 10.721 | nll_loss 10.234 | ppl 1204.27 | wps 14150.7 | ups 3.99 | wpb 3549.3 | bsz 98.3 | num_updates 1000 | lr 0.000125 | gnorm 1.426 | train_wall 198 | wall 275
2024-07-07 18:43:16 | INFO | fairseq_cli.train | done training in 256.0 seconds
2024-07-07 18:43:26 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt22.sep.tokenized.fr-de', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=10000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=500, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-07 18:43:26 | INFO | fairseq.tasks.translation | [fr] dictionary: 10016 types
2024-07-07 18:43:26 | INFO | fairseq.tasks.translation | [de] dictionary: 10032 types
2024-07-07 18:43:26 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.fr
2024-07-07 18:43:26 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.de
2024-07-07 18:43:26 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de valid fr-de 3238 examples
2024-07-07 18:43:27 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10016, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10032, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=10032, bias=False)
  )
)
2024-07-07 18:43:27 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-07 18:43:27 | INFO | fairseq_cli.train | model: transformer_iwslt_de_en (TransformerModel)
2024-07-07 18:43:27 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-07 18:43:27 | INFO | fairseq_cli.train | num. model params: 41807872 (num. trained: 41807872)
2024-07-07 18:43:41 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-07 18:43:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-07 18:43:41 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-07 18:43:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-07 18:43:41 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-07 18:43:41 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-07 18:43:43 | INFO | fairseq.trainer | loaded checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 1000 updates)
2024-07-07 18:43:43 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-07 18:43:44 | INFO | fairseq.data.data_utils | loaded 15571322 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.fr
2024-07-07 18:43:45 | INFO | fairseq.data.data_utils | loaded 15571322 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.de
2024-07-07 18:43:45 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de train fr-de 15571322 examples
2024-07-07 18:44:02 | INFO | fairseq.trainer | begin training epoch 1
2024-07-07 18:44:24 | INFO | train_inner | epoch 001:   1100 / 150053 loss=9.598, nll_loss=8.917, ppl=483.29, wps=8426.3, ups=2.34, wpb=3597.6, bsz=98.8, num_updates=1100, lr=0.0001375, gnorm=1.365, train_wall=21, wall=0
2024-07-07 18:44:43 | INFO | train_inner | epoch 001:   1200 / 150053 loss=9.415, nll_loss=8.708, ppl=418.17, wps=18470.2, ups=5.17, wpb=3573.8, bsz=106.6, num_updates=1200, lr=0.00015, gnorm=1.402, train_wall=19, wall=0
2024-07-07 18:45:02 | INFO | train_inner | epoch 001:   1300 / 150053 loss=9.267, nll_loss=8.536, ppl=371.15, wps=18491.5, ups=5.23, wpb=3536, bsz=107.9, num_updates=1300, lr=0.0001625, gnorm=1.39, train_wall=19, wall=0
2024-07-07 18:45:22 | INFO | train_inner | epoch 001:   1400 / 150053 loss=9.147, nll_loss=8.398, ppl=337.31, wps=17978.6, ups=5.19, wpb=3462.6, bsz=101.4, num_updates=1400, lr=0.000175, gnorm=1.344, train_wall=19, wall=0
2024-07-07 18:45:40 | INFO | train_inner | epoch 001:   1500 / 150053 loss=9.038, nll_loss=8.272, ppl=309.22, wps=18611.7, ups=5.28, wpb=3522.5, bsz=93.2, num_updates=1500, lr=0.0001875, gnorm=1.491, train_wall=19, wall=0
2024-07-07 18:45:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-07 18:45:43 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.281 | nll_loss 8.526 | ppl 368.65 | wps 53696.5 | wpb 2588.8 | bsz 75.3 | num_updates 1500 | best_loss 12.211
2024-07-07 18:45:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 18:45:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_1500.pt (epoch 1 @ 1500 updates, score 9.281) (writing took 3.4658751264214516 seconds)
2024-07-07 18:46:05 | INFO | train_inner | epoch 001:   1600 / 150053 loss=8.922, nll_loss=8.139, ppl=281.9, wps=14406.5, ups=4.03, wpb=3577.1, bsz=112, num_updates=1600, lr=0.0002, gnorm=1.358, train_wall=19, wall=0
2024-07-07 18:46:24 | INFO | train_inner | epoch 001:   1700 / 150053 loss=8.811, nll_loss=8.014, ppl=258.44, wps=18329.2, ups=5.24, wpb=3495.3, bsz=96.6, num_updates=1700, lr=0.0002125, gnorm=1.356, train_wall=19, wall=0
2024-07-07 18:46:44 | INFO | train_inner | epoch 001:   1800 / 150053 loss=8.698, nll_loss=7.886, ppl=236.54, wps=18484.7, ups=5.2, wpb=3552.6, bsz=99.4, num_updates=1800, lr=0.000225, gnorm=1.435, train_wall=19, wall=0
2024-07-07 18:47:03 | INFO | train_inner | epoch 001:   1900 / 150053 loss=8.587, nll_loss=7.759, ppl=216.6, wps=18091.6, ups=5.21, wpb=3474.4, bsz=124, num_updates=1900, lr=0.0002375, gnorm=1.747, train_wall=19, wall=0
2024-07-07 18:47:22 | INFO | train_inner | epoch 001:   2000 / 150053 loss=8.472, nll_loss=7.629, ppl=197.94, wps=18056.9, ups=5.18, wpb=3484.9, bsz=102.2, num_updates=2000, lr=0.00025, gnorm=1.67, train_wall=19, wall=0
2024-07-07 18:47:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 18:47:24 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.502 | nll_loss 7.625 | ppl 197.39 | wps 53979.6 | wpb 2588.8 | bsz 75.3 | num_updates 2000 | best_loss 12.211
2024-07-07 18:47:24 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 18:47:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 8.502) (writing took 3.739560306072235 seconds)
2024-07-07 18:47:47 | INFO | train_inner | epoch 001:   2100 / 150053 loss=8.343, nll_loss=7.481, ppl=178.61, wps=14283.3, ups=4.01, wpb=3564.7, bsz=123.1, num_updates=2100, lr=0.0002625, gnorm=1.687, train_wall=19, wall=0
2024-07-07 18:48:07 | INFO | train_inner | epoch 001:   2200 / 150053 loss=8.319, nll_loss=7.455, ppl=175.5, wps=18206.3, ups=5.08, wpb=3582.8, bsz=101.4, num_updates=2200, lr=0.000275, gnorm=1.473, train_wall=20, wall=0
2024-07-07 18:48:26 | INFO | train_inner | epoch 001:   2300 / 150053 loss=8.162, nll_loss=7.277, ppl=155.1, wps=18215.9, ups=5.25, wpb=3471.3, bsz=97.7, num_updates=2300, lr=0.0002875, gnorm=1.348, train_wall=19, wall=0
2024-07-07 18:48:45 | INFO | train_inner | epoch 001:   2400 / 150053 loss=8.039, nll_loss=7.137, ppl=140.77, wps=18301.1, ups=5.16, wpb=3545.5, bsz=92.4, num_updates=2400, lr=0.0003, gnorm=1.346, train_wall=19, wall=0
2024-07-07 18:49:04 | INFO | train_inner | epoch 001:   2500 / 150053 loss=7.953, nll_loss=7.039, ppl=131.52, wps=18486.3, ups=5.24, wpb=3526.7, bsz=93.9, num_updates=2500, lr=0.0003125, gnorm=1.362, train_wall=19, wall=0
2024-07-07 18:49:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 18:49:06 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.051 | nll_loss 7.09 | ppl 136.25 | wps 53736.8 | wpb 2588.8 | bsz 75.3 | num_updates 2500 | best_loss 12.211
2024-07-07 18:49:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 18:49:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_2500.pt (epoch 1 @ 2500 updates, score 8.051) (writing took 3.7263035997748375 seconds)
2024-07-07 18:49:30 | INFO | train_inner | epoch 001:   2600 / 150053 loss=7.896, nll_loss=6.973, ppl=125.63, wps=13859.3, ups=3.92, wpb=3532.1, bsz=97.6, num_updates=2600, lr=0.000325, gnorm=1.413, train_wall=19, wall=0
2024-07-07 18:49:49 | INFO | train_inner | epoch 001:   2700 / 150053 loss=7.836, nll_loss=6.905, ppl=119.85, wps=18415, ups=5.18, wpb=3552.8, bsz=91, num_updates=2700, lr=0.0003375, gnorm=1.277, train_wall=19, wall=0
2024-07-07 18:50:08 | INFO | train_inner | epoch 001:   2800 / 150053 loss=7.855, nll_loss=6.926, ppl=121.58, wps=18608.2, ups=5.14, wpb=3618.3, bsz=127.4, num_updates=2800, lr=0.00035, gnorm=1.592, train_wall=19, wall=0
2024-07-07 18:50:28 | INFO | train_inner | epoch 001:   2900 / 150053 loss=7.66, nll_loss=6.705, ppl=104.35, wps=18005.1, ups=5.1, wpb=3531.4, bsz=106.8, num_updates=2900, lr=0.0003625, gnorm=1.24, train_wall=19, wall=0
2024-07-07 18:50:48 | INFO | train_inner | epoch 001:   3000 / 150053 loss=7.592, nll_loss=6.627, ppl=98.84, wps=18286.3, ups=5.04, wpb=3627.2, bsz=122.6, num_updates=3000, lr=0.000375, gnorm=1.323, train_wall=20, wall=0
2024-07-07 18:50:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 18:50:50 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.758 | nll_loss 6.735 | ppl 106.54 | wps 53997.9 | wpb 2588.8 | bsz 75.3 | num_updates 3000 | best_loss 12.211
2024-07-07 18:50:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 18:50:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_3000.pt (epoch 1 @ 3000 updates, score 7.758) (writing took 3.1538097048178315 seconds)
2024-07-07 18:51:13 | INFO | train_inner | epoch 001:   3100 / 150053 loss=7.583, nll_loss=6.616, ppl=98.09, wps=14315.8, ups=4.05, wpb=3538.4, bsz=95.5, num_updates=3100, lr=0.0003875, gnorm=1.244, train_wall=19, wall=0
2024-07-07 18:51:32 | INFO | train_inner | epoch 001:   3200 / 150053 loss=7.573, nll_loss=6.604, ppl=97.25, wps=18341.6, ups=5.17, wpb=3550.8, bsz=120.2, num_updates=3200, lr=0.0004, gnorm=1.473, train_wall=19, wall=0
2024-07-07 18:51:51 | INFO | train_inner | epoch 001:   3300 / 150053 loss=7.491, nll_loss=6.512, ppl=91.26, wps=18143.7, ups=5.17, wpb=3507, bsz=103.1, num_updates=3300, lr=0.0004125, gnorm=1.221, train_wall=19, wall=0
2024-07-07 18:52:11 | INFO | train_inner | epoch 001:   3400 / 150053 loss=7.412, nll_loss=6.421, ppl=85.7, wps=18346.7, ups=5.13, wpb=3574.5, bsz=110.2, num_updates=3400, lr=0.000425, gnorm=1.189, train_wall=19, wall=0
2024-07-07 18:52:30 | INFO | train_inner | epoch 001:   3500 / 150053 loss=7.447, nll_loss=6.46, ppl=88.05, wps=18241.1, ups=5.16, wpb=3537.1, bsz=97.6, num_updates=3500, lr=0.0004375, gnorm=1.164, train_wall=19, wall=0
2024-07-07 18:52:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 18:52:32 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.627 | nll_loss 6.581 | ppl 95.72 | wps 53897.6 | wpb 2588.8 | bsz 75.3 | num_updates 3500 | best_loss 12.211
2024-07-07 18:52:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 18:52:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_3500.pt (epoch 1 @ 3500 updates, score 7.627) (writing took 3.389905177988112 seconds)
2024-07-07 18:52:55 | INFO | train_inner | epoch 001:   3600 / 150053 loss=7.317, nll_loss=6.313, ppl=79.5, wps=14341.8, ups=4, wpb=3583.8, bsz=111.4, num_updates=3600, lr=0.00045, gnorm=1.152, train_wall=19, wall=0
2024-07-07 18:53:15 | INFO | train_inner | epoch 001:   3700 / 150053 loss=7.375, nll_loss=6.379, ppl=83.21, wps=18313.8, ups=5.13, wpb=3573.2, bsz=110.3, num_updates=3700, lr=0.0004625, gnorm=1.222, train_wall=19, wall=0
2024-07-07 18:53:35 | INFO | train_inner | epoch 001:   3800 / 150053 loss=7.243, nll_loss=6.227, ppl=74.92, wps=17663.9, ups=4.97, wpb=3555.6, bsz=114.6, num_updates=3800, lr=0.000475, gnorm=1.12, train_wall=20, wall=0
2024-07-07 18:53:55 | INFO | train_inner | epoch 001:   3900 / 150053 loss=7.289, nll_loss=6.28, ppl=77.7, wps=17787.7, ups=5.04, wpb=3528.4, bsz=111.5, num_updates=3900, lr=0.0004875, gnorm=1.191, train_wall=20, wall=0
2024-07-07 18:54:14 | INFO | train_inner | epoch 001:   4000 / 150053 loss=7.34, nll_loss=6.337, ppl=80.82, wps=18606.2, ups=5.17, wpb=3601.8, bsz=101.4, num_updates=4000, lr=0.0005, gnorm=1.137, train_wall=19, wall=0
2024-07-07 18:54:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 18:54:16 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.415 | nll_loss 6.354 | ppl 81.8 | wps 53740.9 | wpb 2588.8 | bsz 75.3 | num_updates 4000 | best_loss 12.211
2024-07-07 18:54:16 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 18:54:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 7.415) (writing took 3.477171367034316 seconds)
2024-07-07 18:54:39 | INFO | train_inner | epoch 001:   4100 / 150053 loss=7.315, nll_loss=6.31, ppl=79.35, wps=13847, ups=4.02, wpb=3440.3, bsz=107.4, num_updates=4100, lr=0.000493865, gnorm=1.234, train_wall=19, wall=0
2024-07-07 18:54:58 | INFO | train_inner | epoch 001:   4200 / 150053 loss=7.232, nll_loss=6.215, ppl=74.3, wps=18145.5, ups=5.24, wpb=3464.4, bsz=96.7, num_updates=4200, lr=0.00048795, gnorm=1.105, train_wall=19, wall=0
2024-07-07 18:55:17 | INFO | train_inner | epoch 001:   4300 / 150053 loss=7.202, nll_loss=6.18, ppl=72.53, wps=18477.7, ups=5.24, wpb=3524.1, bsz=93.2, num_updates=4300, lr=0.000482243, gnorm=1.016, train_wall=19, wall=0
2024-07-07 18:55:37 | INFO | train_inner | epoch 001:   4400 / 150053 loss=7.127, nll_loss=6.097, ppl=68.45, wps=17888.8, ups=5.04, wpb=3552.5, bsz=117.7, num_updates=4400, lr=0.000476731, gnorm=1.052, train_wall=20, wall=0
2024-07-07 18:55:56 | INFO | train_inner | epoch 001:   4500 / 150053 loss=7.165, nll_loss=6.14, ppl=70.51, wps=18378.9, ups=5.28, wpb=3480.3, bsz=119.7, num_updates=4500, lr=0.000471405, gnorm=1.224, train_wall=19, wall=0
2024-07-07 18:55:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 18:55:58 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.377 | nll_loss 6.299 | ppl 78.76 | wps 53873.6 | wpb 2588.8 | bsz 75.3 | num_updates 4500 | best_loss 12.211
2024-07-07 18:55:58 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 18:56:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_4500.pt (epoch 1 @ 4500 updates, score 7.377) (writing took 3.481574301607907 seconds)
2024-07-07 18:56:21 | INFO | train_inner | epoch 001:   4600 / 150053 loss=7.105, nll_loss=6.071, ppl=67.23, wps=13945.9, ups=4.01, wpb=3474.9, bsz=99.1, num_updates=4600, lr=0.000466252, gnorm=1.016, train_wall=19, wall=0
2024-07-07 18:56:40 | INFO | train_inner | epoch 001:   4700 / 150053 loss=7.05, nll_loss=6.009, ppl=64.41, wps=18118.2, ups=5.11, wpb=3542.3, bsz=104.3, num_updates=4700, lr=0.000461266, gnorm=0.997, train_wall=19, wall=0
2024-07-07 18:57:00 | INFO | train_inner | epoch 001:   4800 / 150053 loss=6.994, nll_loss=5.945, ppl=61.59, wps=18285.7, ups=5.14, wpb=3559, bsz=101, num_updates=4800, lr=0.000456435, gnorm=0.986, train_wall=19, wall=0
2024-07-07 18:57:19 | INFO | train_inner | epoch 001:   4900 / 150053 loss=6.871, nll_loss=5.805, ppl=55.92, wps=18657.4, ups=5.14, wpb=3628.7, bsz=120.2, num_updates=4900, lr=0.000451754, gnorm=0.982, train_wall=19, wall=0
2024-07-07 18:57:39 | INFO | train_inner | epoch 001:   5000 / 150053 loss=6.924, nll_loss=5.865, ppl=58.3, wps=18542.4, ups=5.17, wpb=3587.5, bsz=100.1, num_updates=5000, lr=0.000447214, gnorm=0.921, train_wall=19, wall=0
2024-07-07 18:57:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 18:57:41 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.178 | nll_loss 6.068 | ppl 67.1 | wps 53660.5 | wpb 2588.8 | bsz 75.3 | num_updates 5000 | best_loss 12.211
2024-07-07 18:57:41 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 18:57:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_5000.pt (epoch 1 @ 5000 updates, score 7.178) (writing took 3.516997321508825 seconds)
2024-07-07 18:58:04 | INFO | train_inner | epoch 001:   5100 / 150053 loss=6.972, nll_loss=5.92, ppl=60.53, wps=14168, ups=4.01, wpb=3531.2, bsz=87, num_updates=5100, lr=0.000442807, gnorm=0.944, train_wall=19, wall=0
2024-07-07 18:58:23 | INFO | train_inner | epoch 001:   5200 / 150053 loss=6.822, nll_loss=5.751, ppl=53.84, wps=17703.3, ups=5.07, wpb=3490.8, bsz=103.4, num_updates=5200, lr=0.000438529, gnorm=0.937, train_wall=20, wall=0
2024-07-07 18:58:43 | INFO | train_inner | epoch 001:   5300 / 150053 loss=6.87, nll_loss=5.804, ppl=55.87, wps=17736.7, ups=5.07, wpb=3500.6, bsz=93.7, num_updates=5300, lr=0.000434372, gnorm=0.953, train_wall=20, wall=0
2024-07-07 18:59:02 | INFO | train_inner | epoch 001:   5400 / 150053 loss=6.898, nll_loss=5.836, ppl=57.13, wps=18502, ups=5.24, wpb=3533.6, bsz=94.8, num_updates=5400, lr=0.000430331, gnorm=0.941, train_wall=19, wall=0
2024-07-07 18:59:21 | INFO | train_inner | epoch 001:   5500 / 150053 loss=6.868, nll_loss=5.802, ppl=55.8, wps=18299.8, ups=5.18, wpb=3533, bsz=100.2, num_updates=5500, lr=0.000426401, gnorm=0.937, train_wall=19, wall=0
2024-07-07 18:59:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 18:59:24 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.12 | nll_loss 6.007 | ppl 64.33 | wps 53999 | wpb 2588.8 | bsz 75.3 | num_updates 5500 | best_loss 12.211
2024-07-07 18:59:24 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 18:59:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_5500.pt (epoch 1 @ 5500 updates, score 7.12) (writing took 3.6187800485640764 seconds)
2024-07-07 18:59:47 | INFO | train_inner | epoch 001:   5600 / 150053 loss=6.856, nll_loss=5.789, ppl=55.28, wps=13987.4, ups=3.93, wpb=3556.5, bsz=111.6, num_updates=5600, lr=0.000422577, gnorm=0.971, train_wall=19, wall=0
2024-07-07 19:00:06 | INFO | train_inner | epoch 001:   5700 / 150053 loss=6.813, nll_loss=5.739, ppl=53.41, wps=17988.4, ups=5.13, wpb=3507.4, bsz=97.7, num_updates=5700, lr=0.000418854, gnorm=0.944, train_wall=19, wall=0
2024-07-07 19:00:26 | INFO | train_inner | epoch 001:   5800 / 150053 loss=6.713, nll_loss=5.626, ppl=49.39, wps=18218, ups=5.17, wpb=3520.8, bsz=125, num_updates=5800, lr=0.000415227, gnorm=0.949, train_wall=19, wall=0
2024-07-07 19:00:45 | INFO | train_inner | epoch 001:   5900 / 150053 loss=6.723, nll_loss=5.636, ppl=49.74, wps=18424.3, ups=5.1, wpb=3610.4, bsz=129.4, num_updates=5900, lr=0.000411693, gnorm=0.969, train_wall=19, wall=0
2024-07-07 19:01:05 | INFO | train_inner | epoch 001:   6000 / 150053 loss=6.797, nll_loss=5.72, ppl=52.71, wps=18018.2, ups=5.1, wpb=3533.7, bsz=85, num_updates=6000, lr=0.000408248, gnorm=0.885, train_wall=19, wall=0
2024-07-07 19:01:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:01:07 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.982 | nll_loss 5.85 | ppl 57.67 | wps 53771.7 | wpb 2588.8 | bsz 75.3 | num_updates 6000 | best_loss 12.211
2024-07-07 19:01:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:01:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 6.982) (writing took 3.590985110029578 seconds)
2024-07-07 19:01:30 | INFO | train_inner | epoch 001:   6100 / 150053 loss=6.733, nll_loss=5.649, ppl=50.17, wps=14198, ups=3.99, wpb=3562.8, bsz=105.6, num_updates=6100, lr=0.000404888, gnorm=0.961, train_wall=19, wall=0
2024-07-07 19:01:49 | INFO | train_inner | epoch 001:   6200 / 150053 loss=6.686, nll_loss=5.594, ppl=48.32, wps=18751.1, ups=5.17, wpb=3626.9, bsz=108.6, num_updates=6200, lr=0.00040161, gnorm=0.947, train_wall=19, wall=0
2024-07-07 19:02:09 | INFO | train_inner | epoch 001:   6300 / 150053 loss=6.701, nll_loss=5.612, ppl=48.92, wps=18237.6, ups=5.19, wpb=3511.1, bsz=98.6, num_updates=6300, lr=0.00039841, gnorm=0.898, train_wall=19, wall=0
2024-07-07 19:02:28 | INFO | train_inner | epoch 001:   6400 / 150053 loss=6.625, nll_loss=5.525, ppl=46.05, wps=17901.3, ups=5.01, wpb=3571.2, bsz=117.7, num_updates=6400, lr=0.000395285, gnorm=0.929, train_wall=20, wall=0
2024-07-07 19:02:48 | INFO | train_inner | epoch 001:   6500 / 150053 loss=6.666, nll_loss=5.571, ppl=47.55, wps=18661.6, ups=5.16, wpb=3613.8, bsz=94.4, num_updates=6500, lr=0.000392232, gnorm=0.905, train_wall=19, wall=0
2024-07-07 19:02:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:02:50 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.926 | nll_loss 5.783 | ppl 55.05 | wps 53980.8 | wpb 2588.8 | bsz 75.3 | num_updates 6500 | best_loss 12.211
2024-07-07 19:02:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:02:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_6500.pt (epoch 1 @ 6500 updates, score 6.926) (writing took 3.41083019785583 seconds)
2024-07-07 19:03:13 | INFO | train_inner | epoch 001:   6600 / 150053 loss=6.652, nll_loss=5.555, ppl=47.01, wps=14007.5, ups=4, wpb=3500.1, bsz=98.1, num_updates=6600, lr=0.000389249, gnorm=0.905, train_wall=19, wall=0
2024-07-07 19:03:32 | INFO | train_inner | epoch 001:   6700 / 150053 loss=6.673, nll_loss=5.58, ppl=47.83, wps=18013.8, ups=5.2, wpb=3467.1, bsz=87.9, num_updates=6700, lr=0.000386334, gnorm=0.915, train_wall=19, wall=0
2024-07-07 19:03:52 | INFO | train_inner | epoch 001:   6800 / 150053 loss=6.615, nll_loss=5.513, ppl=45.67, wps=18042.5, ups=5.08, wpb=3548.9, bsz=106.6, num_updates=6800, lr=0.000383482, gnorm=0.913, train_wall=19, wall=0
2024-07-07 19:04:11 | INFO | train_inner | epoch 001:   6900 / 150053 loss=6.565, nll_loss=5.457, ppl=43.94, wps=18325.4, ups=5.13, wpb=3574, bsz=97.1, num_updates=6900, lr=0.000380693, gnorm=0.862, train_wall=19, wall=0
2024-07-07 19:04:31 | INFO | train_inner | epoch 001:   7000 / 150053 loss=6.485, nll_loss=5.367, ppl=41.26, wps=17927.9, ups=5.17, wpb=3467, bsz=120.3, num_updates=7000, lr=0.000377964, gnorm=0.92, train_wall=19, wall=0
2024-07-07 19:04:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:04:33 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.878 | nll_loss 5.728 | ppl 53.01 | wps 53596.6 | wpb 2588.8 | bsz 75.3 | num_updates 7000 | best_loss 12.211
2024-07-07 19:04:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:04:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_7000.pt (epoch 1 @ 7000 updates, score 6.878) (writing took 3.343399823643267 seconds)
2024-07-07 19:04:56 | INFO | train_inner | epoch 001:   7100 / 150053 loss=6.524, nll_loss=5.41, ppl=42.52, wps=14242.7, ups=3.99, wpb=3565.4, bsz=98.9, num_updates=7100, lr=0.000375293, gnorm=0.874, train_wall=19, wall=0
2024-07-07 19:05:15 | INFO | train_inner | epoch 001:   7200 / 150053 loss=6.543, nll_loss=5.431, ppl=43.15, wps=17998.5, ups=5.14, wpb=3500, bsz=103, num_updates=7200, lr=0.000372678, gnorm=0.91, train_wall=19, wall=0
2024-07-07 19:05:35 | INFO | train_inner | epoch 001:   7300 / 150053 loss=6.514, nll_loss=5.398, ppl=42.18, wps=18319.8, ups=5.13, wpb=3572.2, bsz=103.3, num_updates=7300, lr=0.000370117, gnorm=0.872, train_wall=19, wall=0
2024-07-07 19:05:54 | INFO | train_inner | epoch 001:   7400 / 150053 loss=6.567, nll_loss=5.458, ppl=43.97, wps=17645.5, ups=5.09, wpb=3466.7, bsz=101, num_updates=7400, lr=0.000367607, gnorm=0.981, train_wall=19, wall=0
2024-07-07 19:06:14 | INFO | train_inner | epoch 001:   7500 / 150053 loss=6.546, nll_loss=5.435, ppl=43.27, wps=18254.1, ups=5.13, wpb=3557, bsz=101.4, num_updates=7500, lr=0.000365148, gnorm=0.942, train_wall=19, wall=0
2024-07-07 19:06:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:06:16 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.908 | nll_loss 5.755 | ppl 54.01 | wps 54011.4 | wpb 2588.8 | bsz 75.3 | num_updates 7500 | best_loss 12.211
2024-07-07 19:06:16 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:06:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_7500.pt (epoch 1 @ 7500 updates, score 6.908) (writing took 3.414029087871313 seconds)
2024-07-07 19:06:39 | INFO | train_inner | epoch 001:   7600 / 150053 loss=6.485, nll_loss=5.365, ppl=41.23, wps=14080.5, ups=3.95, wpb=3561.3, bsz=101.6, num_updates=7600, lr=0.000362738, gnorm=0.89, train_wall=20, wall=0
2024-07-07 19:06:59 | INFO | train_inner | epoch 001:   7700 / 150053 loss=6.509, nll_loss=5.393, ppl=42.02, wps=18191, ups=5.11, wpb=3560.4, bsz=107.1, num_updates=7700, lr=0.000360375, gnorm=0.903, train_wall=19, wall=0
2024-07-07 19:07:18 | INFO | train_inner | epoch 001:   7800 / 150053 loss=6.482, nll_loss=5.362, ppl=41.13, wps=18193.6, ups=5.16, wpb=3525.8, bsz=105.8, num_updates=7800, lr=0.000358057, gnorm=0.889, train_wall=19, wall=0
2024-07-07 19:07:37 | INFO | train_inner | epoch 001:   7900 / 150053 loss=6.399, nll_loss=5.267, ppl=38.52, wps=18407.2, ups=5.19, wpb=3544.1, bsz=112.8, num_updates=7900, lr=0.000355784, gnorm=0.89, train_wall=19, wall=0
2024-07-07 19:07:57 | INFO | train_inner | epoch 001:   8000 / 150053 loss=6.42, nll_loss=5.291, ppl=39.15, wps=18654.9, ups=5.12, wpb=3640.9, bsz=102.1, num_updates=8000, lr=0.000353553, gnorm=0.857, train_wall=19, wall=0
2024-07-07 19:07:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:07:59 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.787 | nll_loss 5.619 | ppl 49.16 | wps 53667.7 | wpb 2588.8 | bsz 75.3 | num_updates 8000 | best_loss 12.211
2024-07-07 19:07:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:08:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 6.787) (writing took 3.578251091763377 seconds)
2024-07-07 19:08:22 | INFO | train_inner | epoch 001:   8100 / 150053 loss=6.445, nll_loss=5.32, ppl=39.95, wps=14156.6, ups=3.96, wpb=3578.7, bsz=97.4, num_updates=8100, lr=0.000351364, gnorm=0.862, train_wall=19, wall=0
2024-07-07 19:08:41 | INFO | train_inner | epoch 001:   8200 / 150053 loss=6.407, nll_loss=5.277, ppl=38.78, wps=18002.8, ups=5.14, wpb=3504.3, bsz=110.1, num_updates=8200, lr=0.000349215, gnorm=0.92, train_wall=19, wall=0
2024-07-07 19:09:01 | INFO | train_inner | epoch 001:   8300 / 150053 loss=6.399, nll_loss=5.268, ppl=38.54, wps=18177.4, ups=5.12, wpb=3546.8, bsz=107.2, num_updates=8300, lr=0.000347105, gnorm=0.891, train_wall=19, wall=0
2024-07-07 19:09:20 | INFO | train_inner | epoch 001:   8400 / 150053 loss=6.351, nll_loss=5.213, ppl=37.1, wps=18412.3, ups=5.15, wpb=3577, bsz=106.9, num_updates=8400, lr=0.000345033, gnorm=0.894, train_wall=19, wall=0
2024-07-07 19:09:40 | INFO | train_inner | epoch 001:   8500 / 150053 loss=6.354, nll_loss=5.216, ppl=37.17, wps=18008.1, ups=5.11, wpb=3527.2, bsz=99.2, num_updates=8500, lr=0.000342997, gnorm=0.9, train_wall=19, wall=0
2024-07-07 19:09:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:09:42 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.768 | nll_loss 5.603 | ppl 48.61 | wps 54010.4 | wpb 2588.8 | bsz 75.3 | num_updates 8500 | best_loss 12.211
2024-07-07 19:09:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:09:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_8500.pt (epoch 1 @ 8500 updates, score 6.768) (writing took 3.5042275562882423 seconds)
2024-07-07 19:10:05 | INFO | train_inner | epoch 001:   8600 / 150053 loss=6.363, nll_loss=5.227, ppl=37.46, wps=14298.7, ups=4, wpb=3575, bsz=103, num_updates=8600, lr=0.000340997, gnorm=0.892, train_wall=19, wall=0
2024-07-07 19:10:24 | INFO | train_inner | epoch 001:   8700 / 150053 loss=6.421, nll_loss=5.293, ppl=39.2, wps=18488.2, ups=5.2, wpb=3555.3, bsz=101.6, num_updates=8700, lr=0.000339032, gnorm=0.974, train_wall=19, wall=0
2024-07-07 19:10:44 | INFO | train_inner | epoch 001:   8800 / 150053 loss=6.407, nll_loss=5.277, ppl=38.78, wps=18253, ups=5.05, wpb=3613.8, bsz=103.5, num_updates=8800, lr=0.0003371, gnorm=0.9, train_wall=20, wall=0
2024-07-07 19:11:04 | INFO | train_inner | epoch 001:   8900 / 150053 loss=6.424, nll_loss=5.297, ppl=39.31, wps=18044.5, ups=5.11, wpb=3534.4, bsz=106.6, num_updates=8900, lr=0.000335201, gnorm=0.934, train_wall=19, wall=0
2024-07-07 19:11:23 | INFO | train_inner | epoch 001:   9000 / 150053 loss=6.349, nll_loss=5.21, ppl=37.03, wps=18659.3, ups=5.12, wpb=3641.8, bsz=98.7, num_updates=9000, lr=0.000333333, gnorm=0.862, train_wall=19, wall=0
2024-07-07 19:11:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:11:25 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.739 | nll_loss 5.572 | ppl 47.56 | wps 53880.6 | wpb 2588.8 | bsz 75.3 | num_updates 9000 | best_loss 12.211
2024-07-07 19:11:25 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:11:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_9000.pt (epoch 1 @ 9000 updates, score 6.739) (writing took 3.542508418671787 seconds)
2024-07-07 19:11:48 | INFO | train_inner | epoch 001:   9100 / 150053 loss=6.33, nll_loss=5.189, ppl=36.49, wps=13765.6, ups=3.96, wpb=3478.3, bsz=92.1, num_updates=9100, lr=0.000331497, gnorm=0.876, train_wall=19, wall=0
2024-07-07 19:12:08 | INFO | train_inner | epoch 001:   9200 / 150053 loss=6.39, nll_loss=5.258, ppl=38.27, wps=18363.7, ups=5.23, wpb=3508.7, bsz=101.1, num_updates=9200, lr=0.00032969, gnorm=0.921, train_wall=19, wall=0
2024-07-07 19:12:27 | INFO | train_inner | epoch 001:   9300 / 150053 loss=6.31, nll_loss=5.167, ppl=35.92, wps=18535.9, ups=5.12, wpb=3618.6, bsz=100.7, num_updates=9300, lr=0.000327913, gnorm=0.855, train_wall=19, wall=0
2024-07-07 19:12:46 | INFO | train_inner | epoch 001:   9400 / 150053 loss=6.332, nll_loss=5.19, ppl=36.52, wps=18334.8, ups=5.25, wpb=3495.1, bsz=95.6, num_updates=9400, lr=0.000326164, gnorm=0.904, train_wall=19, wall=0
2024-07-07 19:13:05 | INFO | train_inner | epoch 001:   9500 / 150053 loss=6.313, nll_loss=5.171, ppl=36.02, wps=18275.6, ups=5.21, wpb=3507.6, bsz=91.5, num_updates=9500, lr=0.000324443, gnorm=0.868, train_wall=19, wall=0
2024-07-07 19:13:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:13:07 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.728 | nll_loss 5.555 | ppl 47.01 | wps 53784.1 | wpb 2588.8 | bsz 75.3 | num_updates 9500 | best_loss 12.211
2024-07-07 19:13:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:13:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_9500.pt (epoch 1 @ 9500 updates, score 6.728) (writing took 3.292885299772024 seconds)
2024-07-07 19:13:30 | INFO | train_inner | epoch 001:   9600 / 150053 loss=6.223, nll_loss=5.068, ppl=33.54, wps=14551.6, ups=4.01, wpb=3630.1, bsz=122.1, num_updates=9600, lr=0.000322749, gnorm=0.894, train_wall=19, wall=0
2024-07-07 19:13:49 | INFO | train_inner | epoch 001:   9700 / 150053 loss=6.291, nll_loss=5.145, ppl=35.38, wps=18208.6, ups=5.22, wpb=3491.1, bsz=95.9, num_updates=9700, lr=0.000321081, gnorm=0.891, train_wall=19, wall=0
2024-07-07 19:14:09 | INFO | train_inner | epoch 001:   9800 / 150053 loss=6.229, nll_loss=5.075, ppl=33.7, wps=18346.9, ups=5.17, wpb=3545.5, bsz=112.2, num_updates=9800, lr=0.000319438, gnorm=0.905, train_wall=19, wall=0
2024-07-07 19:14:28 | INFO | train_inner | epoch 001:   9900 / 150053 loss=6.284, nll_loss=5.137, ppl=35.19, wps=18441.7, ups=5.17, wpb=3565.9, bsz=103.8, num_updates=9900, lr=0.000317821, gnorm=0.91, train_wall=19, wall=0
2024-07-07 19:14:48 | INFO | train_inner | epoch 001:  10000 / 150053 loss=6.205, nll_loss=5.046, ppl=33.04, wps=18364.7, ups=5.14, wpb=3574.7, bsz=107.8, num_updates=10000, lr=0.000316228, gnorm=0.9, train_wall=19, wall=0
2024-07-07 19:14:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:14:50 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.675 | nll_loss 5.494 | ppl 45.06 | wps 53955.4 | wpb 2588.8 | bsz 75.3 | num_updates 10000 | best_loss 12.211
2024-07-07 19:14:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:14:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score 6.675) (writing took 3.439735818654299 seconds)
2024-07-07 19:14:53 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-07 19:14:53 | INFO | train | epoch 001 | loss 7.484 | nll_loss 6.508 | ppl 90.99 | wps 16744.5 | ups 4.72 | wpb 3544.5 | bsz 103.7 | num_updates 10000 | lr 0.000316228 | gnorm 1.111 | train_wall 1931 | wall 0
2024-07-07 19:14:53 | INFO | fairseq_cli.train | done training in 1850.8 seconds
2024-07-07 19:15:01 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt22.sep.tokenized.fr-de', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=100000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=1000, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-07 19:15:01 | INFO | fairseq.tasks.translation | [fr] dictionary: 10016 types
2024-07-07 19:15:01 | INFO | fairseq.tasks.translation | [de] dictionary: 10032 types
2024-07-07 19:15:01 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.fr
2024-07-07 19:15:01 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.de
2024-07-07 19:15:01 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de valid fr-de 3238 examples
2024-07-07 19:15:02 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10016, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10032, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=10032, bias=False)
  )
)
2024-07-07 19:15:02 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-07 19:15:02 | INFO | fairseq_cli.train | model: transformer_iwslt_de_en (TransformerModel)
2024-07-07 19:15:02 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-07 19:15:02 | INFO | fairseq_cli.train | num. model params: 41807872 (num. trained: 41807872)
2024-07-07 19:15:13 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-07 19:15:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-07 19:15:13 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-07 19:15:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-07 19:15:13 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-07 19:15:13 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-07 19:15:14 | INFO | fairseq.trainer | loaded checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 10000 updates)
2024-07-07 19:15:14 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-07 19:15:15 | INFO | fairseq.data.data_utils | loaded 15571322 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.fr
2024-07-07 19:15:15 | INFO | fairseq.data.data_utils | loaded 15571322 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.de
2024-07-07 19:15:15 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de train fr-de 15571322 examples
2024-07-07 19:15:34 | INFO | fairseq.trainer | begin training epoch 1
2024-07-07 19:15:55 | INFO | train_inner | epoch 001:  10100 / 150053 loss=6.218, nll_loss=5.062, ppl=33.4, wps=8144.2, ups=2.31, wpb=3518.4, bsz=94.2, num_updates=10100, lr=0.000314658, gnorm=0.868, train_wall=21, wall=0
2024-07-07 19:16:15 | INFO | train_inner | epoch 001:  10200 / 150053 loss=6.216, nll_loss=5.059, ppl=33.34, wps=18362.6, ups=5.12, wpb=3584.4, bsz=123.5, num_updates=10200, lr=0.000313112, gnorm=0.932, train_wall=19, wall=0
2024-07-07 19:16:34 | INFO | train_inner | epoch 001:  10300 / 150053 loss=6.259, nll_loss=5.108, ppl=34.48, wps=18480.3, ups=5.16, wpb=3584.2, bsz=106.1, num_updates=10300, lr=0.000311588, gnorm=0.947, train_wall=19, wall=0
2024-07-07 19:16:54 | INFO | train_inner | epoch 001:  10400 / 150053 loss=6.263, nll_loss=5.112, ppl=34.59, wps=18280.2, ups=5.17, wpb=3538.3, bsz=101.8, num_updates=10400, lr=0.000310087, gnorm=0.898, train_wall=19, wall=0
2024-07-07 19:17:13 | INFO | train_inner | epoch 001:  10500 / 150053 loss=6.132, nll_loss=4.964, ppl=31.21, wps=18683.2, ups=5.16, wpb=3623.7, bsz=117, num_updates=10500, lr=0.000308607, gnorm=0.892, train_wall=19, wall=0
2024-07-07 19:17:32 | INFO | train_inner | epoch 001:  10600 / 150053 loss=6.224, nll_loss=5.068, ppl=33.54, wps=18409.1, ups=5.24, wpb=3512.3, bsz=92.6, num_updates=10600, lr=0.000307148, gnorm=0.898, train_wall=19, wall=0
2024-07-07 19:17:51 | INFO | train_inner | epoch 001:  10700 / 150053 loss=6.235, nll_loss=5.081, ppl=33.86, wps=18110.7, ups=5.15, wpb=3513.3, bsz=112.2, num_updates=10700, lr=0.000305709, gnorm=0.926, train_wall=19, wall=0
2024-07-07 19:18:11 | INFO | train_inner | epoch 001:  10800 / 150053 loss=6.288, nll_loss=5.141, ppl=35.29, wps=18332, ups=5.21, wpb=3521.7, bsz=97.4, num_updates=10800, lr=0.00030429, gnorm=0.927, train_wall=19, wall=0
2024-07-07 19:18:30 | INFO | train_inner | epoch 001:  10900 / 150053 loss=6.181, nll_loss=5.02, ppl=32.44, wps=18405.9, ups=5.2, wpb=3538.2, bsz=104.9, num_updates=10900, lr=0.000302891, gnorm=0.871, train_wall=19, wall=0
2024-07-07 19:18:49 | INFO | train_inner | epoch 001:  11000 / 150053 loss=6.227, nll_loss=5.072, ppl=33.64, wps=18252.9, ups=5.22, wpb=3500, bsz=99.6, num_updates=11000, lr=0.000301511, gnorm=0.909, train_wall=19, wall=0
2024-07-07 19:18:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-07 19:18:51 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.638 | nll_loss 5.449 | ppl 43.69 | wps 54009 | wpb 2588.8 | bsz 75.3 | num_updates 11000 | best_loss 12.211
2024-07-07 19:18:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:18:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_11000.pt (epoch 1 @ 11000 updates, score 6.638) (writing took 3.591152506880462 seconds)
2024-07-07 19:19:14 | INFO | train_inner | epoch 001:  11100 / 150053 loss=6.187, nll_loss=5.027, ppl=32.6, wps=14112.4, ups=3.99, wpb=3533.3, bsz=98.6, num_updates=11100, lr=0.00030015, gnorm=0.883, train_wall=19, wall=0
2024-07-07 19:19:33 | INFO | train_inner | epoch 001:  11200 / 150053 loss=6.167, nll_loss=5.004, ppl=32.09, wps=18327.5, ups=5.16, wpb=3551.9, bsz=99, num_updates=11200, lr=0.000298807, gnorm=0.908, train_wall=19, wall=0
2024-07-07 19:19:53 | INFO | train_inner | epoch 001:  11300 / 150053 loss=6.182, nll_loss=5.02, ppl=32.46, wps=18513.6, ups=5.17, wpb=3583.8, bsz=111.2, num_updates=11300, lr=0.000297482, gnorm=0.935, train_wall=19, wall=0
2024-07-07 19:20:12 | INFO | train_inner | epoch 001:  11400 / 150053 loss=6.131, nll_loss=4.963, ppl=31.19, wps=18456.9, ups=5.16, wpb=3576, bsz=112.7, num_updates=11400, lr=0.000296174, gnorm=0.907, train_wall=19, wall=0
2024-07-07 19:20:31 | INFO | train_inner | epoch 001:  11500 / 150053 loss=6.208, nll_loss=5.05, ppl=33.12, wps=18389.2, ups=5.21, wpb=3528.1, bsz=97.8, num_updates=11500, lr=0.000294884, gnorm=0.889, train_wall=19, wall=0
2024-07-07 19:20:51 | INFO | train_inner | epoch 001:  11600 / 150053 loss=6.165, nll_loss=5.002, ppl=32.05, wps=18039.2, ups=5.19, wpb=3475, bsz=101.4, num_updates=11600, lr=0.00029361, gnorm=0.939, train_wall=19, wall=0
2024-07-07 19:21:10 | INFO | train_inner | epoch 001:  11700 / 150053 loss=6.25, nll_loss=5.098, ppl=34.25, wps=18392.4, ups=5.25, wpb=3500.3, bsz=112.6, num_updates=11700, lr=0.000292353, gnorm=0.959, train_wall=19, wall=0
2024-07-07 19:21:29 | INFO | train_inner | epoch 001:  11800 / 150053 loss=6.266, nll_loss=5.116, ppl=34.67, wps=18015.6, ups=5.23, wpb=3442.9, bsz=92.8, num_updates=11800, lr=0.000291111, gnorm=0.971, train_wall=19, wall=0
2024-07-07 19:21:48 | INFO | train_inner | epoch 001:  11900 / 150053 loss=6.194, nll_loss=5.035, ppl=32.78, wps=18302.7, ups=5.19, wpb=3525.3, bsz=95.3, num_updates=11900, lr=0.000289886, gnorm=0.911, train_wall=19, wall=0
2024-07-07 19:22:07 | INFO | train_inner | epoch 001:  12000 / 150053 loss=6.119, nll_loss=4.95, ppl=30.91, wps=18368, ups=5.22, wpb=3517.7, bsz=114.8, num_updates=12000, lr=0.000288675, gnorm=0.918, train_wall=19, wall=0
2024-07-07 19:22:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:22:09 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.594 | nll_loss 5.396 | ppl 42.09 | wps 53865.7 | wpb 2588.8 | bsz 75.3 | num_updates 12000 | best_loss 12.211
2024-07-07 19:22:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:22:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_12000.pt (epoch 1 @ 12000 updates, score 6.594) (writing took 3.382479735650122 seconds)
2024-07-07 19:22:32 | INFO | train_inner | epoch 001:  12100 / 150053 loss=6.156, nll_loss=4.991, ppl=31.8, wps=14079.1, ups=4.02, wpb=3505.8, bsz=91.4, num_updates=12100, lr=0.00028748, gnorm=0.867, train_wall=19, wall=0
2024-07-07 19:22:51 | INFO | train_inner | epoch 001:  12200 / 150053 loss=6.152, nll_loss=4.987, ppl=31.7, wps=18454, ups=5.21, wpb=3539.1, bsz=98.1, num_updates=12200, lr=0.000286299, gnorm=0.887, train_wall=19, wall=0
2024-07-07 19:23:11 | INFO | train_inner | epoch 001:  12300 / 150053 loss=6.186, nll_loss=5.025, ppl=32.57, wps=18418.8, ups=5.19, wpb=3550.9, bsz=102.6, num_updates=12300, lr=0.000285133, gnorm=0.928, train_wall=19, wall=0
2024-07-07 19:23:30 | INFO | train_inner | epoch 001:  12400 / 150053 loss=6.163, nll_loss=4.999, ppl=31.98, wps=18270.9, ups=5.14, wpb=3553.6, bsz=101.6, num_updates=12400, lr=0.000283981, gnorm=0.911, train_wall=19, wall=0
2024-07-07 19:23:49 | INFO | train_inner | epoch 001:  12500 / 150053 loss=6.119, nll_loss=4.949, ppl=30.9, wps=18544, ups=5.19, wpb=3575.1, bsz=107.4, num_updates=12500, lr=0.000282843, gnorm=0.885, train_wall=19, wall=0
2024-07-07 19:24:09 | INFO | train_inner | epoch 001:  12600 / 150053 loss=6.087, nll_loss=4.912, ppl=30.11, wps=18218.6, ups=5.14, wpb=3541.7, bsz=120.1, num_updates=12600, lr=0.000281718, gnorm=0.95, train_wall=19, wall=0
2024-07-07 19:24:28 | INFO | train_inner | epoch 001:  12700 / 150053 loss=6.134, nll_loss=4.967, ppl=31.27, wps=18224.5, ups=5.15, wpb=3537.9, bsz=109.3, num_updates=12700, lr=0.000280607, gnorm=0.912, train_wall=19, wall=0
2024-07-07 19:24:48 | INFO | train_inner | epoch 001:  12800 / 150053 loss=6.149, nll_loss=4.983, ppl=31.62, wps=18091, ups=5.15, wpb=3515.1, bsz=92.3, num_updates=12800, lr=0.000279508, gnorm=0.916, train_wall=19, wall=0
2024-07-07 19:25:07 | INFO | train_inner | epoch 001:  12900 / 150053 loss=6.054, nll_loss=4.875, ppl=29.34, wps=18375.2, ups=5.13, wpb=3581.4, bsz=112.2, num_updates=12900, lr=0.000278423, gnorm=0.884, train_wall=19, wall=0
2024-07-07 19:25:26 | INFO | train_inner | epoch 001:  13000 / 150053 loss=6.079, nll_loss=4.903, ppl=29.92, wps=18505.6, ups=5.2, wpb=3560.9, bsz=101.3, num_updates=13000, lr=0.00027735, gnorm=0.881, train_wall=19, wall=0
2024-07-07 19:25:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:25:29 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.563 | nll_loss 5.362 | ppl 41.14 | wps 53981.4 | wpb 2588.8 | bsz 75.3 | num_updates 13000 | best_loss 12.211
2024-07-07 19:25:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:25:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_13000.pt (epoch 1 @ 13000 updates, score 6.563) (writing took 3.183636713773012 seconds)
2024-07-07 19:25:51 | INFO | train_inner | epoch 001:  13100 / 150053 loss=6.063, nll_loss=4.886, ppl=29.56, wps=14360.9, ups=3.99, wpb=3601.3, bsz=115, num_updates=13100, lr=0.000276289, gnorm=0.91, train_wall=20, wall=0
2024-07-07 19:26:11 | INFO | train_inner | epoch 001:  13200 / 150053 loss=6.118, nll_loss=4.947, ppl=30.85, wps=18503.7, ups=5.22, wpb=3548.1, bsz=86.9, num_updates=13200, lr=0.000275241, gnorm=0.881, train_wall=19, wall=0
2024-07-07 19:26:30 | INFO | train_inner | epoch 001:  13300 / 150053 loss=6.005, nll_loss=4.819, ppl=28.24, wps=18451, ups=5.16, wpb=3578.7, bsz=124.6, num_updates=13300, lr=0.000274204, gnorm=0.939, train_wall=19, wall=0
2024-07-07 19:26:49 | INFO | train_inner | epoch 001:  13400 / 150053 loss=6.105, nll_loss=4.933, ppl=30.54, wps=18613.9, ups=5.19, wpb=3583.2, bsz=103.8, num_updates=13400, lr=0.000273179, gnorm=0.911, train_wall=19, wall=0
2024-07-07 19:27:09 | INFO | train_inner | epoch 001:  13500 / 150053 loss=6.054, nll_loss=4.876, ppl=29.36, wps=18193.1, ups=5.15, wpb=3529.4, bsz=100.4, num_updates=13500, lr=0.000272166, gnorm=0.889, train_wall=19, wall=0
2024-07-07 19:27:28 | INFO | train_inner | epoch 001:  13600 / 150053 loss=6.08, nll_loss=4.904, ppl=29.95, wps=18449.5, ups=5.16, wpb=3572.3, bsz=101.9, num_updates=13600, lr=0.000271163, gnorm=0.899, train_wall=19, wall=0
2024-07-07 19:27:47 | INFO | train_inner | epoch 001:  13700 / 150053 loss=6.107, nll_loss=4.936, ppl=30.6, wps=18006.1, ups=5.17, wpb=3486.1, bsz=90.5, num_updates=13700, lr=0.000270172, gnorm=0.897, train_wall=19, wall=0
2024-07-07 19:28:07 | INFO | train_inner | epoch 001:  13800 / 150053 loss=6.043, nll_loss=4.864, ppl=29.11, wps=18229.3, ups=5.19, wpb=3510.7, bsz=102.9, num_updates=13800, lr=0.000269191, gnorm=0.905, train_wall=19, wall=0
2024-07-07 19:28:26 | INFO | train_inner | epoch 001:  13900 / 150053 loss=6.037, nll_loss=4.856, ppl=28.95, wps=18467.3, ups=5.13, wpb=3601, bsz=110.6, num_updates=13900, lr=0.000268221, gnorm=0.912, train_wall=19, wall=0
2024-07-07 19:28:45 | INFO | train_inner | epoch 001:  14000 / 150053 loss=6.056, nll_loss=4.878, ppl=29.4, wps=18566.5, ups=5.18, wpb=3587.7, bsz=103.8, num_updates=14000, lr=0.000267261, gnorm=0.906, train_wall=19, wall=0
2024-07-07 19:28:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:28:48 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.557 | nll_loss 5.359 | ppl 41.04 | wps 53814.5 | wpb 2588.8 | bsz 75.3 | num_updates 14000 | best_loss 12.211
2024-07-07 19:28:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:28:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_14000.pt (epoch 1 @ 14000 updates, score 6.557) (writing took 3.2335385885089636 seconds)
2024-07-07 19:29:10 | INFO | train_inner | epoch 001:  14100 / 150053 loss=6.119, nll_loss=4.949, ppl=30.89, wps=14323, ups=4.05, wpb=3540.6, bsz=97.8, num_updates=14100, lr=0.000266312, gnorm=0.971, train_wall=19, wall=0
2024-07-07 19:29:30 | INFO | train_inner | epoch 001:  14200 / 150053 loss=6.079, nll_loss=4.903, ppl=29.93, wps=18593.6, ups=5.11, wpb=3635.4, bsz=112.6, num_updates=14200, lr=0.000265372, gnorm=0.919, train_wall=19, wall=0
2024-07-07 19:29:49 | INFO | train_inner | epoch 001:  14300 / 150053 loss=5.98, nll_loss=4.791, ppl=27.69, wps=18149.1, ups=5.13, wpb=3539.2, bsz=116.7, num_updates=14300, lr=0.000264443, gnorm=0.934, train_wall=19, wall=0
2024-07-07 19:30:09 | INFO | train_inner | epoch 001:  14400 / 150053 loss=6.018, nll_loss=4.835, ppl=28.54, wps=17986.2, ups=5.15, wpb=3490.8, bsz=101.3, num_updates=14400, lr=0.000263523, gnorm=0.923, train_wall=19, wall=0
2024-07-07 19:30:28 | INFO | train_inner | epoch 001:  14500 / 150053 loss=6.049, nll_loss=4.869, ppl=29.22, wps=18507.2, ups=5.2, wpb=3562.2, bsz=110.7, num_updates=14500, lr=0.000262613, gnorm=0.909, train_wall=19, wall=0
2024-07-07 19:30:47 | INFO | train_inner | epoch 001:  14600 / 150053 loss=6.039, nll_loss=4.858, ppl=28.99, wps=18319.6, ups=5.15, wpb=3554.2, bsz=104.8, num_updates=14600, lr=0.000261712, gnorm=0.918, train_wall=19, wall=0
2024-07-07 19:31:07 | INFO | train_inner | epoch 001:  14700 / 150053 loss=6.001, nll_loss=4.815, ppl=28.14, wps=18376.8, ups=5.14, wpb=3577.3, bsz=109, num_updates=14700, lr=0.00026082, gnorm=0.906, train_wall=19, wall=0
2024-07-07 19:31:26 | INFO | train_inner | epoch 001:  14800 / 150053 loss=6.035, nll_loss=4.854, ppl=28.92, wps=18376.7, ups=5.24, wpb=3509.9, bsz=92.8, num_updates=14800, lr=0.000259938, gnorm=0.912, train_wall=19, wall=0
2024-07-07 19:31:45 | INFO | train_inner | epoch 001:  14900 / 150053 loss=5.981, nll_loss=4.793, ppl=27.71, wps=18697.3, ups=5.13, wpb=3644.3, bsz=102.9, num_updates=14900, lr=0.000259064, gnorm=0.9, train_wall=19, wall=0
2024-07-07 19:32:05 | INFO | train_inner | epoch 001:  15000 / 150053 loss=5.947, nll_loss=4.754, ppl=26.98, wps=18233.4, ups=5.18, wpb=3522.3, bsz=105, num_updates=15000, lr=0.000258199, gnorm=0.908, train_wall=19, wall=0
2024-07-07 19:32:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:32:07 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.49 | nll_loss 5.284 | ppl 38.96 | wps 53827.6 | wpb 2588.8 | bsz 75.3 | num_updates 15000 | best_loss 12.211
2024-07-07 19:32:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:32:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_15000.pt (epoch 1 @ 15000 updates, score 6.49) (writing took 3.668788759969175 seconds)
2024-07-07 19:32:30 | INFO | train_inner | epoch 001:  15100 / 150053 loss=5.999, nll_loss=4.813, ppl=28.11, wps=14027.1, ups=4, wpb=3505.5, bsz=99.8, num_updates=15100, lr=0.000257343, gnorm=0.92, train_wall=19, wall=0
2024-07-07 19:32:49 | INFO | train_inner | epoch 001:  15200 / 150053 loss=6.128, nll_loss=4.959, ppl=31.11, wps=18437.6, ups=5.23, wpb=3528.6, bsz=92.9, num_updates=15200, lr=0.000256495, gnorm=0.936, train_wall=19, wall=0
2024-07-07 19:33:08 | INFO | train_inner | epoch 001:  15300 / 150053 loss=6.043, nll_loss=4.863, ppl=29.11, wps=18351.8, ups=5.21, wpb=3520.5, bsz=96.7, num_updates=15300, lr=0.000255655, gnorm=0.916, train_wall=19, wall=0
2024-07-07 19:33:27 | INFO | train_inner | epoch 001:  15400 / 150053 loss=6.062, nll_loss=4.885, ppl=29.54, wps=18606.4, ups=5.23, wpb=3555.6, bsz=93.8, num_updates=15400, lr=0.000254824, gnorm=0.908, train_wall=19, wall=0
2024-07-07 19:33:47 | INFO | train_inner | epoch 001:  15500 / 150053 loss=6.018, nll_loss=4.835, ppl=28.54, wps=18254.9, ups=5.15, wpb=3545, bsz=95.5, num_updates=15500, lr=0.000254, gnorm=0.898, train_wall=19, wall=0
2024-07-07 19:34:06 | INFO | train_inner | epoch 001:  15600 / 150053 loss=5.968, nll_loss=4.777, ppl=27.42, wps=18131.8, ups=5.2, wpb=3488.3, bsz=115.1, num_updates=15600, lr=0.000253185, gnorm=0.915, train_wall=19, wall=0
2024-07-07 19:34:25 | INFO | train_inner | epoch 001:  15700 / 150053 loss=5.971, nll_loss=4.781, ppl=27.5, wps=18118.6, ups=5.2, wpb=3482.6, bsz=100.7, num_updates=15700, lr=0.000252377, gnorm=0.927, train_wall=19, wall=0
2024-07-07 19:34:45 | INFO | train_inner | epoch 001:  15800 / 150053 loss=6.007, nll_loss=4.821, ppl=28.28, wps=18412.5, ups=5.09, wpb=3614.9, bsz=103.3, num_updates=15800, lr=0.000251577, gnorm=0.889, train_wall=19, wall=0
2024-07-07 19:35:04 | INFO | train_inner | epoch 001:  15900 / 150053 loss=5.937, nll_loss=4.742, ppl=26.76, wps=18161.5, ups=5.1, wpb=3560.9, bsz=102.1, num_updates=15900, lr=0.000250785, gnorm=0.899, train_wall=19, wall=0
2024-07-07 19:35:24 | INFO | train_inner | epoch 001:  16000 / 150053 loss=5.906, nll_loss=4.707, ppl=26.11, wps=18554.3, ups=5.17, wpb=3587.4, bsz=108.7, num_updates=16000, lr=0.00025, gnorm=0.895, train_wall=19, wall=0
2024-07-07 19:35:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:35:26 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.45 | nll_loss 5.232 | ppl 37.57 | wps 53554.6 | wpb 2588.8 | bsz 75.3 | num_updates 16000 | best_loss 12.211
2024-07-07 19:35:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:35:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_16000.pt (epoch 1 @ 16000 updates, score 6.45) (writing took 3.106413137167692 seconds)
2024-07-07 19:35:48 | INFO | train_inner | epoch 001:  16100 / 150053 loss=5.993, nll_loss=4.806, ppl=27.97, wps=14311.8, ups=4.08, wpb=3507.6, bsz=104.5, num_updates=16100, lr=0.000249222, gnorm=0.95, train_wall=19, wall=0
2024-07-07 19:36:07 | INFO | train_inner | epoch 001:  16200 / 150053 loss=6.059, nll_loss=4.881, ppl=29.46, wps=18290.9, ups=5.17, wpb=3534.7, bsz=95.8, num_updates=16200, lr=0.000248452, gnorm=0.935, train_wall=19, wall=0
2024-07-07 19:36:27 | INFO | train_inner | epoch 001:  16300 / 150053 loss=5.902, nll_loss=4.702, ppl=26.03, wps=18645, ups=5.16, wpb=3611.1, bsz=115.8, num_updates=16300, lr=0.000247689, gnorm=0.907, train_wall=19, wall=0
2024-07-07 19:36:46 | INFO | train_inner | epoch 001:  16400 / 150053 loss=6.017, nll_loss=4.833, ppl=28.5, wps=18267.1, ups=5.12, wpb=3569.5, bsz=99.4, num_updates=16400, lr=0.000246932, gnorm=0.955, train_wall=19, wall=0
2024-07-07 19:37:06 | INFO | train_inner | epoch 001:  16500 / 150053 loss=5.985, nll_loss=4.796, ppl=27.79, wps=18355.7, ups=5.2, wpb=3528.3, bsz=90.3, num_updates=16500, lr=0.000246183, gnorm=0.909, train_wall=19, wall=0
2024-07-07 19:37:25 | INFO | train_inner | epoch 001:  16600 / 150053 loss=5.925, nll_loss=4.728, ppl=26.51, wps=18459.7, ups=5.24, wpb=3521.1, bsz=113.3, num_updates=16600, lr=0.00024544, gnorm=0.919, train_wall=19, wall=0
2024-07-07 19:37:44 | INFO | train_inner | epoch 001:  16700 / 150053 loss=5.947, nll_loss=4.754, ppl=26.98, wps=18284.3, ups=5.14, wpb=3555.6, bsz=119.6, num_updates=16700, lr=0.000244704, gnorm=0.977, train_wall=19, wall=0
2024-07-07 19:38:03 | INFO | train_inner | epoch 001:  16800 / 150053 loss=5.928, nll_loss=4.731, ppl=26.55, wps=18437.3, ups=5.21, wpb=3541.1, bsz=99.9, num_updates=16800, lr=0.000243975, gnorm=0.939, train_wall=19, wall=0
2024-07-07 19:38:23 | INFO | train_inner | epoch 001:  16900 / 150053 loss=5.885, nll_loss=4.683, ppl=25.7, wps=18287.1, ups=5.15, wpb=3547.8, bsz=120.5, num_updates=16900, lr=0.000243252, gnorm=0.931, train_wall=19, wall=0
2024-07-07 19:38:42 | INFO | train_inner | epoch 001:  17000 / 150053 loss=5.937, nll_loss=4.742, ppl=26.76, wps=18530.1, ups=5.16, wpb=3594.3, bsz=110.6, num_updates=17000, lr=0.000242536, gnorm=0.921, train_wall=19, wall=0
2024-07-07 19:38:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:38:44 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.457 | nll_loss 5.245 | ppl 37.91 | wps 54000.1 | wpb 2588.8 | bsz 75.3 | num_updates 17000 | best_loss 12.211
2024-07-07 19:38:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:38:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_17000.pt (epoch 1 @ 17000 updates, score 6.457) (writing took 3.2882775673642755 seconds)
2024-07-07 19:39:07 | INFO | train_inner | epoch 001:  17100 / 150053 loss=5.953, nll_loss=4.76, ppl=27.1, wps=14427.8, ups=4, wpb=3605.4, bsz=101.4, num_updates=17100, lr=0.000241825, gnorm=0.925, train_wall=19, wall=0
2024-07-07 19:39:26 | INFO | train_inner | epoch 001:  17200 / 150053 loss=6.006, nll_loss=4.821, ppl=28.27, wps=18512.3, ups=5.21, wpb=3555.4, bsz=96.1, num_updates=17200, lr=0.000241121, gnorm=0.899, train_wall=19, wall=0
2024-07-07 19:39:46 | INFO | train_inner | epoch 001:  17300 / 150053 loss=5.892, nll_loss=4.692, ppl=25.85, wps=18408.5, ups=5.14, wpb=3578.7, bsz=110.5, num_updates=17300, lr=0.000240424, gnorm=0.902, train_wall=19, wall=0
2024-07-07 19:40:05 | INFO | train_inner | epoch 001:  17400 / 150053 loss=5.855, nll_loss=4.649, ppl=25.09, wps=18099.4, ups=5.13, wpb=3530.8, bsz=112.6, num_updates=17400, lr=0.000239732, gnorm=0.912, train_wall=19, wall=0
2024-07-07 19:40:24 | INFO | train_inner | epoch 001:  17500 / 150053 loss=5.896, nll_loss=4.696, ppl=25.92, wps=18318.2, ups=5.23, wpb=3501.3, bsz=104.2, num_updates=17500, lr=0.000239046, gnorm=0.924, train_wall=19, wall=0
2024-07-07 19:40:44 | INFO | train_inner | epoch 001:  17600 / 150053 loss=5.888, nll_loss=4.687, ppl=25.76, wps=18126.4, ups=5.16, wpb=3513.8, bsz=96.9, num_updates=17600, lr=0.000238366, gnorm=0.893, train_wall=19, wall=0
2024-07-07 19:41:03 | INFO | train_inner | epoch 001:  17700 / 150053 loss=5.953, nll_loss=4.76, ppl=27.09, wps=18499.9, ups=5.2, wpb=3556.3, bsz=99.7, num_updates=17700, lr=0.000237691, gnorm=0.925, train_wall=19, wall=0
2024-07-07 19:41:22 | INFO | train_inner | epoch 001:  17800 / 150053 loss=5.962, nll_loss=4.77, ppl=27.28, wps=18622.5, ups=5.14, wpb=3624, bsz=103.9, num_updates=17800, lr=0.000237023, gnorm=0.94, train_wall=19, wall=0
2024-07-07 19:41:42 | INFO | train_inner | epoch 001:  17900 / 150053 loss=5.958, nll_loss=4.767, ppl=27.23, wps=18185.5, ups=5.2, wpb=3499.6, bsz=100.5, num_updates=17900, lr=0.00023636, gnorm=0.948, train_wall=19, wall=0
2024-07-07 19:42:01 | INFO | train_inner | epoch 001:  18000 / 150053 loss=5.885, nll_loss=4.683, ppl=25.69, wps=18428, ups=5.16, wpb=3572.1, bsz=104.4, num_updates=18000, lr=0.000235702, gnorm=0.89, train_wall=19, wall=0
2024-07-07 19:42:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:42:03 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.415 | nll_loss 5.197 | ppl 36.68 | wps 53986.4 | wpb 2588.8 | bsz 75.3 | num_updates 18000 | best_loss 12.211
2024-07-07 19:42:03 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:42:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_18000.pt (epoch 1 @ 18000 updates, score 6.415) (writing took 3.089552568271756 seconds)
2024-07-07 19:42:26 | INFO | train_inner | epoch 001:  18100 / 150053 loss=5.921, nll_loss=4.724, ppl=26.43, wps=14355, ups=4.05, wpb=3543.6, bsz=98.8, num_updates=18100, lr=0.00023505, gnorm=0.91, train_wall=19, wall=0
2024-07-07 19:42:45 | INFO | train_inner | epoch 001:  18200 / 150053 loss=5.912, nll_loss=4.714, ppl=26.24, wps=18407.7, ups=5.18, wpb=3551.5, bsz=116.9, num_updates=18200, lr=0.000234404, gnorm=0.942, train_wall=19, wall=0
2024-07-07 19:43:04 | INFO | train_inner | epoch 001:  18300 / 150053 loss=5.862, nll_loss=4.657, ppl=25.22, wps=18484.4, ups=5.17, wpb=3576.7, bsz=106.4, num_updates=18300, lr=0.000233762, gnorm=0.908, train_wall=19, wall=0
2024-07-07 19:43:24 | INFO | train_inner | epoch 001:  18400 / 150053 loss=5.926, nll_loss=4.731, ppl=26.55, wps=17976.6, ups=5.19, wpb=3462.3, bsz=96, num_updates=18400, lr=0.000233126, gnorm=0.94, train_wall=19, wall=0
2024-07-07 19:43:43 | INFO | train_inner | epoch 001:  18500 / 150053 loss=5.971, nll_loss=4.781, ppl=27.49, wps=18138.6, ups=5.23, wpb=3470.5, bsz=83.8, num_updates=18500, lr=0.000232495, gnorm=0.941, train_wall=19, wall=0
2024-07-07 19:44:02 | INFO | train_inner | epoch 001:  18600 / 150053 loss=5.799, nll_loss=4.586, ppl=24.01, wps=18361, ups=5.18, wpb=3547, bsz=115.9, num_updates=18600, lr=0.000231869, gnorm=0.914, train_wall=19, wall=0
2024-07-07 19:44:21 | INFO | train_inner | epoch 001:  18700 / 150053 loss=5.936, nll_loss=4.741, ppl=26.75, wps=17757.2, ups=5.17, wpb=3436.4, bsz=105, num_updates=18700, lr=0.000231249, gnorm=0.966, train_wall=19, wall=0
2024-07-07 19:44:40 | INFO | train_inner | epoch 001:  18800 / 150053 loss=5.934, nll_loss=4.739, ppl=26.7, wps=18364.8, ups=5.25, wpb=3495.2, bsz=99.4, num_updates=18800, lr=0.000230633, gnorm=0.937, train_wall=19, wall=0
2024-07-07 19:45:00 | INFO | train_inner | epoch 001:  18900 / 150053 loss=5.905, nll_loss=4.706, ppl=26.1, wps=18139.8, ups=5.17, wpb=3506.7, bsz=97, num_updates=18900, lr=0.000230022, gnorm=0.921, train_wall=19, wall=0
2024-07-07 19:45:19 | INFO | train_inner | epoch 001:  19000 / 150053 loss=5.878, nll_loss=4.675, ppl=25.55, wps=18500.1, ups=5.19, wpb=3562.7, bsz=101.2, num_updates=19000, lr=0.000229416, gnorm=0.936, train_wall=19, wall=0
2024-07-07 19:45:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:45:21 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.434 | nll_loss 5.215 | ppl 37.15 | wps 53808.9 | wpb 2588.8 | bsz 75.3 | num_updates 19000 | best_loss 12.211
2024-07-07 19:45:21 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:45:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_19000.pt (epoch 1 @ 19000 updates, score 6.434) (writing took 3.194477348588407 seconds)
2024-07-07 19:45:44 | INFO | train_inner | epoch 001:  19100 / 150053 loss=5.939, nll_loss=4.745, ppl=26.82, wps=14471.5, ups=4.04, wpb=3580.9, bsz=85.3, num_updates=19100, lr=0.000228814, gnorm=0.903, train_wall=19, wall=0
2024-07-07 19:46:03 | INFO | train_inner | epoch 001:  19200 / 150053 loss=5.863, nll_loss=4.658, ppl=25.25, wps=18280, ups=5.11, wpb=3575.5, bsz=98.9, num_updates=19200, lr=0.000228218, gnorm=0.897, train_wall=19, wall=0
2024-07-07 19:46:23 | INFO | train_inner | epoch 001:  19300 / 150053 loss=5.855, nll_loss=4.65, ppl=25.1, wps=18320.2, ups=5.19, wpb=3529.3, bsz=101.8, num_updates=19300, lr=0.000227626, gnorm=0.921, train_wall=19, wall=0
2024-07-07 19:46:42 | INFO | train_inner | epoch 001:  19400 / 150053 loss=5.835, nll_loss=4.627, ppl=24.7, wps=18389.4, ups=5.15, wpb=3572.4, bsz=110.4, num_updates=19400, lr=0.000227038, gnorm=0.947, train_wall=19, wall=0
2024-07-07 19:47:01 | INFO | train_inner | epoch 001:  19500 / 150053 loss=5.838, nll_loss=4.63, ppl=24.76, wps=18199.8, ups=5.16, wpb=3528.5, bsz=111.6, num_updates=19500, lr=0.000226455, gnorm=0.949, train_wall=19, wall=0
2024-07-07 19:47:21 | INFO | train_inner | epoch 001:  19600 / 150053 loss=5.831, nll_loss=4.622, ppl=24.63, wps=18465.3, ups=5.19, wpb=3558.9, bsz=106.9, num_updates=19600, lr=0.000225877, gnorm=0.937, train_wall=19, wall=0
2024-07-07 19:47:40 | INFO | train_inner | epoch 001:  19700 / 150053 loss=5.897, nll_loss=4.697, ppl=25.93, wps=18427.7, ups=5.16, wpb=3569.5, bsz=105.5, num_updates=19700, lr=0.000225303, gnorm=0.919, train_wall=19, wall=0
2024-07-07 19:47:59 | INFO | train_inner | epoch 001:  19800 / 150053 loss=5.915, nll_loss=4.717, ppl=26.31, wps=17825.2, ups=5.19, wpb=3437.3, bsz=97.2, num_updates=19800, lr=0.000224733, gnorm=0.956, train_wall=19, wall=0
2024-07-07 19:48:19 | INFO | train_inner | epoch 001:  19900 / 150053 loss=5.822, nll_loss=4.612, ppl=24.45, wps=18066.6, ups=5.16, wpb=3499.4, bsz=115.4, num_updates=19900, lr=0.000224168, gnorm=0.941, train_wall=19, wall=0
2024-07-07 19:48:38 | INFO | train_inner | epoch 001:  20000 / 150053 loss=5.863, nll_loss=4.658, ppl=25.24, wps=18337.5, ups=5.22, wpb=3515.1, bsz=92.5, num_updates=20000, lr=0.000223607, gnorm=0.928, train_wall=19, wall=0
2024-07-07 19:48:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:48:40 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.416 | nll_loss 5.198 | ppl 36.72 | wps 53929.7 | wpb 2588.8 | bsz 75.3 | num_updates 20000 | best_loss 12.211
2024-07-07 19:48:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:48:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_20000.pt (epoch 1 @ 20000 updates, score 6.416) (writing took 3.4904401376843452 seconds)
2024-07-07 19:49:03 | INFO | train_inner | epoch 001:  20100 / 150053 loss=5.771, nll_loss=4.553, ppl=23.48, wps=14177.6, ups=3.98, wpb=3564.3, bsz=112.7, num_updates=20100, lr=0.00022305, gnorm=0.899, train_wall=19, wall=0
2024-07-07 19:49:22 | INFO | train_inner | epoch 001:  20200 / 150053 loss=5.842, nll_loss=4.634, ppl=24.83, wps=18473, ups=5.18, wpb=3566.9, bsz=96.2, num_updates=20200, lr=0.000222497, gnorm=0.91, train_wall=19, wall=0
2024-07-07 19:49:42 | INFO | train_inner | epoch 001:  20300 / 150053 loss=5.834, nll_loss=4.626, ppl=24.69, wps=18103.9, ups=5.16, wpb=3508.2, bsz=105.4, num_updates=20300, lr=0.000221948, gnorm=0.916, train_wall=19, wall=0
2024-07-07 19:50:01 | INFO | train_inner | epoch 001:  20400 / 150053 loss=5.86, nll_loss=4.656, ppl=25.21, wps=18271.4, ups=5.17, wpb=3530.7, bsz=99.2, num_updates=20400, lr=0.000221404, gnorm=0.933, train_wall=19, wall=0
2024-07-07 19:50:20 | INFO | train_inner | epoch 001:  20500 / 150053 loss=5.822, nll_loss=4.611, ppl=24.43, wps=18632.2, ups=5.18, wpb=3595.7, bsz=107.8, num_updates=20500, lr=0.000220863, gnorm=0.936, train_wall=19, wall=0
2024-07-07 19:50:40 | INFO | train_inner | epoch 001:  20600 / 150053 loss=5.869, nll_loss=4.665, ppl=25.37, wps=18151.7, ups=5.18, wpb=3505.8, bsz=102.6, num_updates=20600, lr=0.000220326, gnorm=0.974, train_wall=19, wall=0
2024-07-07 19:50:59 | INFO | train_inner | epoch 001:  20700 / 150053 loss=5.939, nll_loss=4.744, ppl=26.8, wps=18474.6, ups=5.21, wpb=3543.4, bsz=96.1, num_updates=20700, lr=0.000219793, gnorm=0.938, train_wall=19, wall=0
2024-07-07 19:51:18 | INFO | train_inner | epoch 001:  20800 / 150053 loss=5.818, nll_loss=4.608, ppl=24.38, wps=18253.9, ups=5.21, wpb=3504, bsz=99.7, num_updates=20800, lr=0.000219265, gnorm=0.928, train_wall=19, wall=0
2024-07-07 19:51:38 | INFO | train_inner | epoch 001:  20900 / 150053 loss=5.803, nll_loss=4.591, ppl=24.1, wps=18330.2, ups=5.12, wpb=3580.9, bsz=116, num_updates=20900, lr=0.000218739, gnorm=0.933, train_wall=19, wall=0
2024-07-07 19:51:57 | INFO | train_inner | epoch 001:  21000 / 150053 loss=5.826, nll_loss=4.617, ppl=24.53, wps=18245.1, ups=5.12, wpb=3565.4, bsz=100.6, num_updates=21000, lr=0.000218218, gnorm=0.918, train_wall=19, wall=0
2024-07-07 19:51:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:51:59 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.377 | nll_loss 5.157 | ppl 35.67 | wps 53701.7 | wpb 2588.8 | bsz 75.3 | num_updates 21000 | best_loss 12.211
2024-07-07 19:51:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:52:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_21000.pt (epoch 1 @ 21000 updates, score 6.377) (writing took 3.3493198193609715 seconds)
2024-07-07 19:52:22 | INFO | train_inner | epoch 001:  21100 / 150053 loss=5.811, nll_loss=4.6, ppl=24.25, wps=14114.8, ups=4.02, wpb=3507.2, bsz=108.6, num_updates=21100, lr=0.0002177, gnorm=0.941, train_wall=19, wall=0
2024-07-07 19:52:41 | INFO | train_inner | epoch 001:  21200 / 150053 loss=5.871, nll_loss=4.668, ppl=25.42, wps=18301, ups=5.22, wpb=3503.1, bsz=93.4, num_updates=21200, lr=0.000217186, gnorm=0.941, train_wall=19, wall=0
2024-07-07 19:53:01 | INFO | train_inner | epoch 001:  21300 / 150053 loss=5.791, nll_loss=4.577, ppl=23.87, wps=18719.4, ups=5.14, wpb=3643.3, bsz=98.2, num_updates=21300, lr=0.000216676, gnorm=0.885, train_wall=19, wall=0
2024-07-07 19:53:20 | INFO | train_inner | epoch 001:  21400 / 150053 loss=5.795, nll_loss=4.581, ppl=23.93, wps=18239.3, ups=5.21, wpb=3498.7, bsz=103.8, num_updates=21400, lr=0.000216169, gnorm=0.957, train_wall=19, wall=0
2024-07-07 19:53:39 | INFO | train_inner | epoch 001:  21500 / 150053 loss=5.905, nll_loss=4.705, ppl=26.09, wps=18243.3, ups=5.26, wpb=3465.2, bsz=91, num_updates=21500, lr=0.000215666, gnorm=0.971, train_wall=19, wall=0
2024-07-07 19:53:58 | INFO | train_inner | epoch 001:  21600 / 150053 loss=5.869, nll_loss=4.666, ppl=25.38, wps=18167.2, ups=5.17, wpb=3511.7, bsz=103.8, num_updates=21600, lr=0.000215166, gnorm=0.957, train_wall=19, wall=0
2024-07-07 19:54:17 | INFO | train_inner | epoch 001:  21700 / 150053 loss=5.84, nll_loss=4.632, ppl=24.8, wps=18102.7, ups=5.16, wpb=3508.9, bsz=97.7, num_updates=21700, lr=0.000214669, gnorm=0.916, train_wall=19, wall=0
2024-07-07 19:54:37 | INFO | train_inner | epoch 001:  21800 / 150053 loss=5.791, nll_loss=4.576, ppl=23.85, wps=18261.5, ups=5.13, wpb=3557.4, bsz=97.2, num_updates=21800, lr=0.000214176, gnorm=0.914, train_wall=19, wall=0
2024-07-07 19:54:56 | INFO | train_inner | epoch 001:  21900 / 150053 loss=5.846, nll_loss=4.64, ppl=24.93, wps=18297.2, ups=5.19, wpb=3522.7, bsz=96.9, num_updates=21900, lr=0.000213687, gnorm=0.922, train_wall=19, wall=0
2024-07-07 19:55:15 | INFO | train_inner | epoch 001:  22000 / 150053 loss=5.807, nll_loss=4.595, ppl=24.16, wps=18666.2, ups=5.26, wpb=3548.5, bsz=106.9, num_updates=22000, lr=0.000213201, gnorm=0.934, train_wall=19, wall=0
2024-07-07 19:55:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:55:17 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.362 | nll_loss 5.137 | ppl 35.18 | wps 53234 | wpb 2588.8 | bsz 75.3 | num_updates 22000 | best_loss 12.211
2024-07-07 19:55:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:55:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_22000.pt (epoch 1 @ 22000 updates, score 6.362) (writing took 3.8935430673882365 seconds)
2024-07-07 19:55:41 | INFO | train_inner | epoch 001:  22100 / 150053 loss=5.799, nll_loss=4.585, ppl=24, wps=14101, ups=3.92, wpb=3599.2, bsz=105.1, num_updates=22100, lr=0.000212718, gnorm=0.911, train_wall=19, wall=0
2024-07-07 19:56:00 | INFO | train_inner | epoch 001:  22200 / 150053 loss=5.866, nll_loss=4.662, ppl=25.32, wps=18331, ups=5.17, wpb=3546.4, bsz=98.9, num_updates=22200, lr=0.000212238, gnorm=0.934, train_wall=19, wall=0
2024-07-07 19:56:19 | INFO | train_inner | epoch 001:  22300 / 150053 loss=5.779, nll_loss=4.563, ppl=23.63, wps=18242.8, ups=5.15, wpb=3541.5, bsz=95.4, num_updates=22300, lr=0.000211762, gnorm=0.91, train_wall=19, wall=0
2024-07-07 19:56:39 | INFO | train_inner | epoch 001:  22400 / 150053 loss=5.8, nll_loss=4.586, ppl=24.01, wps=18472.8, ups=5.2, wpb=3551.5, bsz=97, num_updates=22400, lr=0.000211289, gnorm=0.946, train_wall=19, wall=0
2024-07-07 19:56:58 | INFO | train_inner | epoch 001:  22500 / 150053 loss=5.881, nll_loss=4.679, ppl=25.62, wps=18060.9, ups=5.24, wpb=3443.6, bsz=103.8, num_updates=22500, lr=0.000210819, gnorm=0.967, train_wall=19, wall=0
2024-07-07 19:57:17 | INFO | train_inner | epoch 001:  22600 / 150053 loss=5.777, nll_loss=4.561, ppl=23.6, wps=18525.6, ups=5.12, wpb=3615.6, bsz=100.8, num_updates=22600, lr=0.000210352, gnorm=0.91, train_wall=19, wall=0
2024-07-07 19:57:37 | INFO | train_inner | epoch 001:  22700 / 150053 loss=5.797, nll_loss=4.584, ppl=23.98, wps=18034.5, ups=5.2, wpb=3468.2, bsz=103.8, num_updates=22700, lr=0.000209888, gnorm=0.933, train_wall=19, wall=0
2024-07-07 19:57:56 | INFO | train_inner | epoch 001:  22800 / 150053 loss=5.843, nll_loss=4.636, ppl=24.86, wps=18231.8, ups=5.23, wpb=3486.4, bsz=96.3, num_updates=22800, lr=0.000209427, gnorm=0.929, train_wall=19, wall=0
2024-07-07 19:58:15 | INFO | train_inner | epoch 001:  22900 / 150053 loss=5.866, nll_loss=4.662, ppl=25.31, wps=18161.8, ups=5.22, wpb=3476.6, bsz=88.3, num_updates=22900, lr=0.000208969, gnorm=1.009, train_wall=19, wall=0
2024-07-07 19:58:34 | INFO | train_inner | epoch 001:  23000 / 150053 loss=5.791, nll_loss=4.577, ppl=23.87, wps=18280.1, ups=5.14, wpb=3554.6, bsz=108.9, num_updates=23000, lr=0.000208514, gnorm=0.961, train_wall=19, wall=0
2024-07-07 19:58:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 19:58:36 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.37 | nll_loss 5.147 | ppl 35.43 | wps 53622.2 | wpb 2588.8 | bsz 75.3 | num_updates 23000 | best_loss 12.211
2024-07-07 19:58:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 19:58:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_23000.pt (epoch 1 @ 23000 updates, score 6.37) (writing took 4.09949912969023 seconds)
2024-07-07 19:59:00 | INFO | train_inner | epoch 001:  23100 / 150053 loss=5.82, nll_loss=4.609, ppl=24.4, wps=13906, ups=3.9, wpb=3567.8, bsz=100.2, num_updates=23100, lr=0.000208063, gnorm=0.968, train_wall=19, wall=0
2024-07-07 19:59:19 | INFO | train_inner | epoch 001:  23200 / 150053 loss=5.796, nll_loss=4.583, ppl=23.96, wps=18212.1, ups=5.21, wpb=3494.4, bsz=103.4, num_updates=23200, lr=0.000207614, gnorm=0.987, train_wall=19, wall=0
2024-07-07 19:59:39 | INFO | train_inner | epoch 001:  23300 / 150053 loss=5.706, nll_loss=4.48, ppl=22.32, wps=18349.2, ups=5.13, wpb=3580.2, bsz=112.8, num_updates=23300, lr=0.000207168, gnorm=0.918, train_wall=19, wall=0
2024-07-07 19:59:58 | INFO | train_inner | epoch 001:  23400 / 150053 loss=5.72, nll_loss=4.496, ppl=22.57, wps=18432.8, ups=5.13, wpb=3592.6, bsz=108.7, num_updates=23400, lr=0.000206725, gnorm=0.926, train_wall=19, wall=0
2024-07-07 20:00:17 | INFO | train_inner | epoch 001:  23500 / 150053 loss=5.785, nll_loss=4.57, ppl=23.75, wps=18462.5, ups=5.2, wpb=3553.8, bsz=95, num_updates=23500, lr=0.000206284, gnorm=0.917, train_wall=19, wall=0
2024-07-07 20:00:37 | INFO | train_inner | epoch 001:  23600 / 150053 loss=5.81, nll_loss=4.598, ppl=24.22, wps=18359.8, ups=5.19, wpb=3536.4, bsz=91.5, num_updates=23600, lr=0.000205847, gnorm=0.923, train_wall=19, wall=0
2024-07-07 20:00:56 | INFO | train_inner | epoch 001:  23700 / 150053 loss=5.749, nll_loss=4.528, ppl=23.08, wps=18104.7, ups=5.12, wpb=3537.2, bsz=104.3, num_updates=23700, lr=0.000205412, gnorm=0.918, train_wall=19, wall=0
2024-07-07 20:01:15 | INFO | train_inner | epoch 001:  23800 / 150053 loss=5.846, nll_loss=4.639, ppl=24.91, wps=18292.4, ups=5.22, wpb=3506.4, bsz=104.6, num_updates=23800, lr=0.00020498, gnorm=0.958, train_wall=19, wall=0
2024-07-07 20:01:35 | INFO | train_inner | epoch 001:  23900 / 150053 loss=5.816, nll_loss=4.605, ppl=24.34, wps=18310.8, ups=5.18, wpb=3531.8, bsz=93.6, num_updates=23900, lr=0.000204551, gnorm=0.927, train_wall=19, wall=0
2024-07-07 20:01:54 | INFO | train_inner | epoch 001:  24000 / 150053 loss=5.756, nll_loss=4.537, ppl=23.22, wps=18324.2, ups=5.15, wpb=3560.4, bsz=100.8, num_updates=24000, lr=0.000204124, gnorm=0.93, train_wall=19, wall=0
2024-07-07 20:01:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 20:01:56 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.294 | nll_loss 5.066 | ppl 33.51 | wps 53272 | wpb 2588.8 | bsz 75.3 | num_updates 24000 | best_loss 12.211
2024-07-07 20:01:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 20:02:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_24000.pt (epoch 1 @ 24000 updates, score 6.294) (writing took 3.4772022059187293 seconds)
2024-07-07 20:02:19 | INFO | train_inner | epoch 001:  24100 / 150053 loss=5.822, nll_loss=4.612, ppl=24.45, wps=14185.9, ups=3.99, wpb=3551.2, bsz=96.4, num_updates=24100, lr=0.0002037, gnorm=0.962, train_wall=19, wall=0
2024-07-07 20:02:38 | INFO | train_inner | epoch 001:  24200 / 150053 loss=5.823, nll_loss=4.613, ppl=24.48, wps=17856.6, ups=5.19, wpb=3443.1, bsz=88.2, num_updates=24200, lr=0.000203279, gnorm=0.941, train_wall=19, wall=0
2024-07-07 20:02:58 | INFO | train_inner | epoch 001:  24300 / 150053 loss=5.698, nll_loss=4.471, ppl=22.17, wps=18270.1, ups=5.18, wpb=3528.9, bsz=127.1, num_updates=24300, lr=0.00020286, gnorm=0.951, train_wall=19, wall=0
2024-07-07 20:03:17 | INFO | train_inner | epoch 001:  24400 / 150053 loss=5.721, nll_loss=4.497, ppl=22.59, wps=18207, ups=5.17, wpb=3519.1, bsz=104.6, num_updates=24400, lr=0.000202444, gnorm=0.926, train_wall=19, wall=0
2024-07-07 20:03:36 | INFO | train_inner | epoch 001:  24500 / 150053 loss=5.746, nll_loss=4.525, ppl=23.03, wps=18810, ups=5.17, wpb=3639.6, bsz=116.6, num_updates=24500, lr=0.000202031, gnorm=0.926, train_wall=19, wall=0
2024-07-07 20:03:56 | INFO | train_inner | epoch 001:  24600 / 150053 loss=5.765, nll_loss=4.546, ppl=23.36, wps=18232.7, ups=5.19, wpb=3512.4, bsz=94.5, num_updates=24600, lr=0.000201619, gnorm=0.948, train_wall=19, wall=0
2024-07-07 20:04:15 | INFO | train_inner | epoch 001:  24700 / 150053 loss=5.794, nll_loss=4.58, ppl=23.92, wps=18316.8, ups=5.22, wpb=3508.1, bsz=97.2, num_updates=24700, lr=0.000201211, gnorm=0.954, train_wall=19, wall=0
2024-07-07 20:04:34 | INFO | train_inner | epoch 001:  24800 / 150053 loss=5.747, nll_loss=4.527, ppl=23.05, wps=18410.5, ups=5.11, wpb=3599.7, bsz=107.7, num_updates=24800, lr=0.000200805, gnorm=0.927, train_wall=19, wall=0
2024-07-07 20:04:54 | INFO | train_inner | epoch 001:  24900 / 150053 loss=5.721, nll_loss=4.496, ppl=22.57, wps=18224, ups=5.14, wpb=3543.9, bsz=116.7, num_updates=24900, lr=0.000200401, gnorm=0.986, train_wall=19, wall=0
2024-07-07 20:05:13 | INFO | train_inner | epoch 001:  25000 / 150053 loss=5.726, nll_loss=4.502, ppl=22.65, wps=18641.5, ups=5.17, wpb=3606.2, bsz=109.4, num_updates=25000, lr=0.0002, gnorm=0.954, train_wall=19, wall=0
2024-07-07 20:05:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 20:05:15 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.301 | nll_loss 5.077 | ppl 33.76 | wps 53334 | wpb 2588.8 | bsz 75.3 | num_updates 25000 | best_loss 12.211
2024-07-07 20:05:15 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 20:05:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_25000.pt (epoch 1 @ 25000 updates, score 6.301) (writing took 3.3962756106629968 seconds)
2024-07-07 20:05:38 | INFO | train_inner | epoch 001:  25100 / 150053 loss=5.776, nll_loss=4.56, ppl=23.59, wps=13990.4, ups=3.99, wpb=3502.9, bsz=103.6, num_updates=25100, lr=0.000199601, gnorm=0.943, train_wall=19, wall=0
2024-07-07 20:05:57 | INFO | train_inner | epoch 001:  25200 / 150053 loss=5.795, nll_loss=4.582, ppl=23.95, wps=18409.5, ups=5.18, wpb=3557.4, bsz=100.1, num_updates=25200, lr=0.000199205, gnorm=1.019, train_wall=19, wall=0
2024-07-07 20:06:17 | INFO | train_inner | epoch 001:  25300 / 150053 loss=5.689, nll_loss=4.461, ppl=22.02, wps=18323.9, ups=5.17, wpb=3546, bsz=115.2, num_updates=25300, lr=0.000198811, gnorm=0.933, train_wall=19, wall=0
2024-07-07 20:06:36 | INFO | train_inner | epoch 001:  25400 / 150053 loss=5.765, nll_loss=4.547, ppl=23.38, wps=18004.8, ups=5.22, wpb=3448.4, bsz=96.2, num_updates=25400, lr=0.000198419, gnorm=0.952, train_wall=19, wall=0
2024-07-07 20:06:55 | INFO | train_inner | epoch 001:  25500 / 150053 loss=5.696, nll_loss=4.468, ppl=22.12, wps=18406, ups=5.15, wpb=3574.3, bsz=116.3, num_updates=25500, lr=0.00019803, gnorm=0.938, train_wall=19, wall=0
2024-07-07 20:07:15 | INFO | train_inner | epoch 001:  25600 / 150053 loss=5.746, nll_loss=4.525, ppl=23.03, wps=18362.9, ups=5.17, wpb=3551.9, bsz=98.6, num_updates=25600, lr=0.000197642, gnorm=0.971, train_wall=19, wall=0
2024-07-07 20:07:34 | INFO | train_inner | epoch 001:  25700 / 150053 loss=5.712, nll_loss=4.486, ppl=22.42, wps=18343.6, ups=5.21, wpb=3518.7, bsz=113.8, num_updates=25700, lr=0.000197257, gnorm=0.935, train_wall=19, wall=0
2024-07-07 20:07:53 | INFO | train_inner | epoch 001:  25800 / 150053 loss=5.726, nll_loss=4.503, ppl=22.67, wps=18347.9, ups=5.16, wpb=3559.2, bsz=109, num_updates=25800, lr=0.000196875, gnorm=0.945, train_wall=19, wall=0
2024-07-07 20:08:13 | INFO | train_inner | epoch 001:  25900 / 150053 loss=5.768, nll_loss=4.55, ppl=23.43, wps=18437.7, ups=5.19, wpb=3555.2, bsz=93.4, num_updates=25900, lr=0.000196494, gnorm=0.932, train_wall=19, wall=0
2024-07-07 20:08:32 | INFO | train_inner | epoch 001:  26000 / 150053 loss=5.762, nll_loss=4.545, ppl=23.34, wps=18325.9, ups=5.2, wpb=3527, bsz=92.6, num_updates=26000, lr=0.000196116, gnorm=0.94, train_wall=19, wall=0
2024-07-07 20:08:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 20:08:34 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.32 | nll_loss 5.092 | ppl 34.11 | wps 53440.2 | wpb 2588.8 | bsz 75.3 | num_updates 26000 | best_loss 12.211
2024-07-07 20:08:34 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 20:08:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_26000.pt (epoch 1 @ 26000 updates, score 6.32) (writing took 3.0222387854009867 seconds)
2024-07-07 20:08:57 | INFO | train_inner | epoch 001:  26100 / 150053 loss=5.692, nll_loss=4.464, ppl=22.07, wps=14495, ups=4.04, wpb=3590.7, bsz=102.6, num_updates=26100, lr=0.00019574, gnorm=0.928, train_wall=19, wall=0
2024-07-07 20:09:16 | INFO | train_inner | epoch 001:  26200 / 150053 loss=5.728, nll_loss=4.505, ppl=22.71, wps=18509.7, ups=5.22, wpb=3548.4, bsz=103.6, num_updates=26200, lr=0.000195366, gnorm=0.963, train_wall=19, wall=0
2024-07-07 20:09:35 | INFO | train_inner | epoch 001:  26300 / 150053 loss=5.74, nll_loss=4.518, ppl=22.92, wps=18466.7, ups=5.19, wpb=3560.2, bsz=106.5, num_updates=26300, lr=0.000194994, gnorm=0.96, train_wall=19, wall=0
2024-07-07 20:09:54 | INFO | train_inner | epoch 001:  26400 / 150053 loss=5.751, nll_loss=4.532, ppl=23.13, wps=18491.2, ups=5.21, wpb=3548.7, bsz=106.1, num_updates=26400, lr=0.000194625, gnorm=0.95, train_wall=19, wall=0
2024-07-07 20:10:14 | INFO | train_inner | epoch 001:  26500 / 150053 loss=5.68, nll_loss=4.451, ppl=21.88, wps=18079, ups=5.18, wpb=3491.3, bsz=113.6, num_updates=26500, lr=0.000194257, gnorm=0.959, train_wall=19, wall=0
2024-07-07 20:10:33 | INFO | train_inner | epoch 001:  26600 / 150053 loss=5.754, nll_loss=4.535, ppl=23.18, wps=18358.7, ups=5.2, wpb=3529.3, bsz=100.5, num_updates=26600, lr=0.000193892, gnorm=0.956, train_wall=19, wall=0
2024-07-07 20:10:52 | INFO | train_inner | epoch 001:  26700 / 150053 loss=5.673, nll_loss=4.443, ppl=21.75, wps=18457.6, ups=5.18, wpb=3565.4, bsz=108.1, num_updates=26700, lr=0.000193528, gnorm=0.956, train_wall=19, wall=0
2024-07-07 20:11:11 | INFO | train_inner | epoch 001:  26800 / 150053 loss=5.722, nll_loss=4.498, ppl=22.59, wps=18516.3, ups=5.2, wpb=3557.8, bsz=94.2, num_updates=26800, lr=0.000193167, gnorm=0.943, train_wall=19, wall=0
2024-07-07 20:11:31 | INFO | train_inner | epoch 001:  26900 / 150053 loss=5.735, nll_loss=4.513, ppl=22.83, wps=18052.6, ups=5.19, wpb=3479.7, bsz=93.8, num_updates=26900, lr=0.000192807, gnorm=0.936, train_wall=19, wall=0
2024-07-07 20:11:50 | INFO | train_inner | epoch 001:  27000 / 150053 loss=5.706, nll_loss=4.48, ppl=22.32, wps=18531.3, ups=5.24, wpb=3538.3, bsz=103.4, num_updates=27000, lr=0.00019245, gnorm=0.954, train_wall=19, wall=0
2024-07-07 20:11:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 20:11:52 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.319 | nll_loss 5.097 | ppl 34.22 | wps 53949.7 | wpb 2588.8 | bsz 75.3 | num_updates 27000 | best_loss 12.211
2024-07-07 20:11:52 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 20:11:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_27000.pt (epoch 1 @ 27000 updates, score 6.319) (writing took 3.3805268052965403 seconds)
2024-07-07 20:12:15 | INFO | train_inner | epoch 001:  27100 / 150053 loss=5.708, nll_loss=4.482, ppl=22.35, wps=14172.2, ups=4.01, wpb=3531.3, bsz=105, num_updates=27100, lr=0.000192095, gnorm=0.97, train_wall=19, wall=0
2024-07-07 20:12:34 | INFO | train_inner | epoch 001:  27200 / 150053 loss=5.735, nll_loss=4.514, ppl=22.85, wps=18675, ups=5.27, wpb=3541.8, bsz=103, num_updates=27200, lr=0.000191741, gnorm=0.957, train_wall=19, wall=0
2024-07-07 20:12:53 | INFO | train_inner | epoch 001:  27300 / 150053 loss=5.67, nll_loss=4.439, ppl=21.69, wps=18250.2, ups=5.13, wpb=3555.1, bsz=106.7, num_updates=27300, lr=0.00019139, gnorm=0.916, train_wall=19, wall=0
2024-07-07 20:13:12 | INFO | train_inner | epoch 001:  27400 / 150053 loss=5.786, nll_loss=4.572, ppl=23.78, wps=18145.9, ups=5.22, wpb=3478.2, bsz=89.7, num_updates=27400, lr=0.00019104, gnorm=0.953, train_wall=19, wall=0
2024-07-07 20:13:31 | INFO | train_inner | epoch 001:  27500 / 150053 loss=5.692, nll_loss=4.464, ppl=22.07, wps=18355.7, ups=5.2, wpb=3529.5, bsz=104.2, num_updates=27500, lr=0.000190693, gnorm=0.972, train_wall=19, wall=0
2024-07-07 20:13:51 | INFO | train_inner | epoch 001:  27600 / 150053 loss=5.704, nll_loss=4.478, ppl=22.28, wps=18460.6, ups=5.17, wpb=3569.9, bsz=107.4, num_updates=27600, lr=0.000190347, gnorm=0.965, train_wall=19, wall=0
2024-07-07 20:14:10 | INFO | train_inner | epoch 001:  27700 / 150053 loss=5.694, nll_loss=4.467, ppl=22.12, wps=18321.5, ups=5.16, wpb=3548.6, bsz=102.2, num_updates=27700, lr=0.000190003, gnorm=0.95, train_wall=19, wall=0
2024-07-07 20:14:29 | INFO | train_inner | epoch 001:  27800 / 150053 loss=5.73, nll_loss=4.507, ppl=22.73, wps=18333.5, ups=5.2, wpb=3528.5, bsz=93.8, num_updates=27800, lr=0.000189661, gnorm=0.966, train_wall=19, wall=0
2024-07-07 20:14:49 | INFO | train_inner | epoch 001:  27900 / 150053 loss=5.638, nll_loss=4.403, ppl=21.16, wps=18597.5, ups=5.16, wpb=3606.3, bsz=105.4, num_updates=27900, lr=0.000189321, gnorm=0.931, train_wall=19, wall=0
2024-07-07 20:15:08 | INFO | train_inner | epoch 001:  28000 / 150053 loss=5.632, nll_loss=4.396, ppl=21.05, wps=18616.8, ups=5.16, wpb=3609.7, bsz=118.2, num_updates=28000, lr=0.000188982, gnorm=0.942, train_wall=19, wall=0
2024-07-07 20:15:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 20:15:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.287 | nll_loss 5.055 | ppl 33.25 | wps 53408.1 | wpb 2588.8 | bsz 75.3 | num_updates 28000 | best_loss 12.211
2024-07-07 20:15:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 20:15:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_28000.pt (epoch 1 @ 28000 updates, score 6.287) (writing took 3.383832085877657 seconds)
2024-07-07 20:15:33 | INFO | train_inner | epoch 001:  28100 / 150053 loss=5.709, nll_loss=4.484, ppl=22.38, wps=14063, ups=4.04, wpb=3478.8, bsz=94.4, num_updates=28100, lr=0.000188646, gnorm=0.954, train_wall=19, wall=0
2024-07-07 20:15:52 | INFO | train_inner | epoch 001:  28200 / 150053 loss=5.71, nll_loss=4.485, ppl=22.4, wps=18009.5, ups=5.2, wpb=3466.6, bsz=108.4, num_updates=28200, lr=0.000188311, gnorm=0.949, train_wall=19, wall=0
2024-07-07 20:16:11 | INFO | train_inner | epoch 001:  28300 / 150053 loss=5.725, nll_loss=4.501, ppl=22.65, wps=18404.9, ups=5.21, wpb=3530.2, bsz=89.1, num_updates=28300, lr=0.000187978, gnorm=0.941, train_wall=19, wall=0
2024-07-07 20:16:31 | INFO | train_inner | epoch 001:  28400 / 150053 loss=5.627, nll_loss=4.39, ppl=20.96, wps=18393.3, ups=5.14, wpb=3575, bsz=111, num_updates=28400, lr=0.000187647, gnorm=0.949, train_wall=19, wall=0
2024-07-07 20:16:50 | INFO | train_inner | epoch 001:  28500 / 150053 loss=5.755, nll_loss=4.536, ppl=23.2, wps=18359.2, ups=5.21, wpb=3523.4, bsz=89.7, num_updates=28500, lr=0.000187317, gnorm=0.949, train_wall=19, wall=0
2024-07-07 20:17:09 | INFO | train_inner | epoch 001:  28600 / 150053 loss=5.67, nll_loss=4.44, ppl=21.7, wps=18273, ups=5.14, wpb=3553.5, bsz=102.3, num_updates=28600, lr=0.000186989, gnorm=0.952, train_wall=19, wall=0
2024-07-07 20:17:29 | INFO | train_inner | epoch 001:  28700 / 150053 loss=5.678, nll_loss=4.448, ppl=21.83, wps=18232, ups=5.18, wpb=3520.6, bsz=113.4, num_updates=28700, lr=0.000186663, gnorm=0.978, train_wall=19, wall=0
2024-07-07 20:17:48 | INFO | train_inner | epoch 001:  28800 / 150053 loss=5.749, nll_loss=4.529, ppl=23.09, wps=18447.5, ups=5.18, wpb=3559.9, bsz=90.2, num_updates=28800, lr=0.000186339, gnorm=0.955, train_wall=19, wall=0
2024-07-07 20:18:07 | INFO | train_inner | epoch 001:  28900 / 150053 loss=5.718, nll_loss=4.494, ppl=22.54, wps=18245.4, ups=5.23, wpb=3490.8, bsz=101.4, num_updates=28900, lr=0.000186016, gnorm=0.991, train_wall=19, wall=0
2024-07-07 20:18:26 | INFO | train_inner | epoch 001:  29000 / 150053 loss=5.628, nll_loss=4.392, ppl=20.99, wps=18299.8, ups=5.22, wpb=3507.6, bsz=118.6, num_updates=29000, lr=0.000185695, gnorm=1.005, train_wall=19, wall=0
2024-07-07 20:18:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 20:18:29 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.291 | nll_loss 5.062 | ppl 33.42 | wps 53706.1 | wpb 2588.8 | bsz 75.3 | num_updates 29000 | best_loss 12.211
2024-07-07 20:18:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 20:18:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_29000.pt (epoch 1 @ 29000 updates, score 6.291) (writing took 3.220665176399052 seconds)
2024-07-07 20:18:51 | INFO | train_inner | epoch 001:  29100 / 150053 loss=5.707, nll_loss=4.481, ppl=22.33, wps=14370.1, ups=4.06, wpb=3542.7, bsz=88.4, num_updates=29100, lr=0.000185376, gnorm=0.956, train_wall=19, wall=0
2024-07-07 20:19:10 | INFO | train_inner | epoch 001:  29200 / 150053 loss=5.701, nll_loss=4.475, ppl=22.24, wps=18623.9, ups=5.17, wpb=3599.5, bsz=101.8, num_updates=29200, lr=0.000185058, gnorm=0.956, train_wall=19, wall=0
2024-07-07 20:19:30 | INFO | train_inner | epoch 001:  29300 / 150053 loss=5.656, nll_loss=4.423, ppl=21.45, wps=18492.5, ups=5.17, wpb=3574.5, bsz=101.8, num_updates=29300, lr=0.000184742, gnorm=0.939, train_wall=19, wall=0
2024-07-07 20:19:49 | INFO | train_inner | epoch 001:  29400 / 150053 loss=5.69, nll_loss=4.462, ppl=22.04, wps=18349.3, ups=5.15, wpb=3561.1, bsz=102.1, num_updates=29400, lr=0.000184428, gnorm=0.943, train_wall=19, wall=0
2024-07-07 20:20:08 | INFO | train_inner | epoch 001:  29500 / 150053 loss=5.624, nll_loss=4.387, ppl=20.92, wps=18389, ups=5.17, wpb=3559.4, bsz=103, num_updates=29500, lr=0.000184115, gnorm=0.93, train_wall=19, wall=0
2024-07-07 20:20:28 | INFO | train_inner | epoch 001:  29600 / 150053 loss=5.635, nll_loss=4.399, ppl=21.1, wps=18241.9, ups=5.19, wpb=3517.6, bsz=98.8, num_updates=29600, lr=0.000183804, gnorm=0.938, train_wall=19, wall=0
2024-07-07 20:20:47 | INFO | train_inner | epoch 001:  29700 / 150053 loss=5.688, nll_loss=4.459, ppl=21.99, wps=18104.7, ups=5.16, wpb=3507.6, bsz=100.2, num_updates=29700, lr=0.000183494, gnorm=0.971, train_wall=19, wall=0
2024-07-07 20:21:07 | INFO | train_inner | epoch 001:  29800 / 150053 loss=5.704, nll_loss=4.477, ppl=22.28, wps=18294.3, ups=5.13, wpb=3569.3, bsz=98.7, num_updates=29800, lr=0.000183186, gnorm=0.962, train_wall=19, wall=0
2024-07-07 20:21:26 | INFO | train_inner | epoch 001:  29900 / 150053 loss=5.667, nll_loss=4.436, ppl=21.65, wps=18426.6, ups=5.21, wpb=3534.7, bsz=105.3, num_updates=29900, lr=0.000182879, gnorm=0.961, train_wall=19, wall=0
2024-07-07 20:21:45 | INFO | train_inner | epoch 001:  30000 / 150053 loss=5.598, nll_loss=4.357, ppl=20.5, wps=18239.9, ups=5.17, wpb=3526.4, bsz=117, num_updates=30000, lr=0.000182574, gnorm=0.953, train_wall=19, wall=0
2024-07-07 20:21:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 20:21:47 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.266 | nll_loss 5.027 | ppl 32.6 | wps 53798.1 | wpb 2588.8 | bsz 75.3 | num_updates 30000 | best_loss 12.211
2024-07-07 20:21:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 20:21:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_30000.pt (epoch 1 @ 30000 updates, score 6.266) (writing took 3.4668023409321904 seconds)
2024-07-07 20:22:10 | INFO | train_inner | epoch 001:  30100 / 150053 loss=5.659, nll_loss=4.427, ppl=21.5, wps=14188.1, ups=4, wpb=3549.8, bsz=105.9, num_updates=30100, lr=0.000182271, gnorm=0.986, train_wall=19, wall=0
2024-07-07 20:22:29 | INFO | train_inner | epoch 001:  30200 / 150053 loss=5.649, nll_loss=4.416, ppl=21.34, wps=18248.9, ups=5.23, wpb=3487.3, bsz=107, num_updates=30200, lr=0.000181969, gnorm=0.972, train_wall=19, wall=0
2024-07-07 20:22:49 | INFO | train_inner | epoch 001:  30300 / 150053 loss=5.692, nll_loss=4.464, ppl=22.07, wps=18606.4, ups=5.19, wpb=3584.3, bsz=101.1, num_updates=30300, lr=0.000181668, gnorm=0.94, train_wall=19, wall=0
2024-07-07 20:23:08 | INFO | train_inner | epoch 001:  30400 / 150053 loss=5.636, nll_loss=4.4, ppl=21.11, wps=18429.2, ups=5.2, wpb=3544.7, bsz=105.8, num_updates=30400, lr=0.000181369, gnorm=0.95, train_wall=19, wall=0
2024-07-07 20:23:27 | INFO | train_inner | epoch 001:  30500 / 150053 loss=5.645, nll_loss=4.411, ppl=21.28, wps=18744.6, ups=5.25, wpb=3572.1, bsz=105.8, num_updates=30500, lr=0.000181071, gnorm=0.951, train_wall=19, wall=0
2024-07-07 20:23:46 | INFO | train_inner | epoch 001:  30600 / 150053 loss=5.682, nll_loss=4.454, ppl=21.91, wps=18239.3, ups=5.13, wpb=3553.6, bsz=95.7, num_updates=30600, lr=0.000180775, gnorm=0.962, train_wall=19, wall=0
2024-07-07 20:24:06 | INFO | train_inner | epoch 001:  30700 / 150053 loss=5.72, nll_loss=4.496, ppl=22.57, wps=18209.4, ups=5.16, wpb=3527, bsz=102.4, num_updates=30700, lr=0.000180481, gnorm=1.005, train_wall=19, wall=0
2024-07-07 20:24:25 | INFO | train_inner | epoch 001:  30800 / 150053 loss=5.695, nll_loss=4.468, ppl=22.13, wps=18344.7, ups=5.19, wpb=3536.3, bsz=97.5, num_updates=30800, lr=0.000180187, gnorm=0.959, train_wall=19, wall=0
2024-07-07 20:24:44 | INFO | train_inner | epoch 001:  30900 / 150053 loss=5.692, nll_loss=4.464, ppl=22.08, wps=18352.3, ups=5.19, wpb=3539, bsz=98.8, num_updates=30900, lr=0.000179896, gnorm=0.95, train_wall=19, wall=0
2024-07-07 20:25:03 | INFO | train_inner | epoch 001:  31000 / 150053 loss=5.698, nll_loss=4.471, ppl=22.18, wps=18568.8, ups=5.22, wpb=3554, bsz=114.7, num_updates=31000, lr=0.000179605, gnorm=1.144, train_wall=19, wall=0
2024-07-07 20:25:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 20:25:06 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.28 | nll_loss 5.048 | ppl 33.08 | wps 53019.3 | wpb 2588.8 | bsz 75.3 | num_updates 31000 | best_loss 12.211
2024-07-07 20:25:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 20:25:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_31000.pt (epoch 1 @ 31000 updates, score 6.28) (writing took 3.248189987614751 seconds)
2024-07-07 20:25:28 | INFO | train_inner | epoch 001:  31100 / 150053 loss=5.659, nll_loss=4.426, ppl=21.5, wps=14456.2, ups=4.04, wpb=3576.1, bsz=97.4, num_updates=31100, lr=0.000179316, gnorm=0.978, train_wall=19, wall=0
2024-07-07 20:25:47 | INFO | train_inner | epoch 001:  31200 / 150053 loss=5.617, nll_loss=4.379, ppl=20.81, wps=18259.8, ups=5.17, wpb=3534.7, bsz=109, num_updates=31200, lr=0.000179029, gnorm=0.958, train_wall=19, wall=0
2024-07-07 20:26:07 | INFO | train_inner | epoch 001:  31300 / 150053 loss=5.699, nll_loss=4.473, ppl=22.21, wps=17985.3, ups=5.19, wpb=3462.6, bsz=89.7, num_updates=31300, lr=0.000178743, gnorm=0.95, train_wall=19, wall=0
2024-07-07 20:26:26 | INFO | train_inner | epoch 001:  31400 / 150053 loss=5.719, nll_loss=4.495, ppl=22.54, wps=18148.8, ups=5.14, wpb=3530.1, bsz=91, num_updates=31400, lr=0.000178458, gnorm=0.999, train_wall=19, wall=0
2024-07-07 20:26:45 | INFO | train_inner | epoch 001:  31500 / 150053 loss=5.678, nll_loss=4.449, ppl=21.84, wps=17644.5, ups=5.2, wpb=3395.4, bsz=94.2, num_updates=31500, lr=0.000178174, gnorm=0.976, train_wall=19, wall=0
2024-07-07 20:27:05 | INFO | train_inner | epoch 001:  31600 / 150053 loss=5.599, nll_loss=4.358, ppl=20.51, wps=18694, ups=5.13, wpb=3646.3, bsz=108.2, num_updates=31600, lr=0.000177892, gnorm=0.952, train_wall=19, wall=0
2024-07-07 20:27:24 | INFO | train_inner | epoch 001:  31700 / 150053 loss=5.633, nll_loss=4.397, ppl=21.07, wps=18173.5, ups=5.22, wpb=3480.7, bsz=110.6, num_updates=31700, lr=0.000177611, gnorm=0.997, train_wall=19, wall=0
2024-07-07 20:27:43 | INFO | train_inner | epoch 001:  31800 / 150053 loss=5.659, nll_loss=4.427, ppl=21.51, wps=18431.1, ups=5.18, wpb=3561.2, bsz=92.4, num_updates=31800, lr=0.000177332, gnorm=0.947, train_wall=19, wall=0
2024-07-07 20:28:03 | INFO | train_inner | epoch 001:  31900 / 150053 loss=5.628, nll_loss=4.391, ppl=20.98, wps=18378.5, ups=5.12, wpb=3588.6, bsz=98.4, num_updates=31900, lr=0.000177054, gnorm=0.97, train_wall=19, wall=0
2024-07-07 20:28:22 | INFO | train_inner | epoch 001:  32000 / 150053 loss=5.669, nll_loss=4.439, ppl=21.68, wps=18291, ups=5.18, wpb=3527.8, bsz=96.6, num_updates=32000, lr=0.000176777, gnorm=0.95, train_wall=19, wall=0
2024-07-07 20:28:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 20:28:24 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.249 | nll_loss 5.01 | ppl 32.23 | wps 53635.1 | wpb 2588.8 | bsz 75.3 | num_updates 32000 | best_loss 12.211
2024-07-07 20:28:24 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 20:28:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_32000.pt (epoch 1 @ 32000 updates, score 6.249) (writing took 3.0995532469823956 seconds)
2024-07-07 20:28:47 | INFO | train_inner | epoch 001:  32100 / 150053 loss=5.552, nll_loss=4.304, ppl=19.75, wps=14529.4, ups=4.05, wpb=3584.3, bsz=123.6, num_updates=32100, lr=0.000176501, gnorm=0.987, train_wall=19, wall=0
2024-07-07 20:29:06 | INFO | train_inner | epoch 001:  32200 / 150053 loss=5.639, nll_loss=4.404, ppl=21.17, wps=18647, ups=5.2, wpb=3584.5, bsz=105.4, num_updates=32200, lr=0.000176227, gnorm=0.978, train_wall=19, wall=0
2024-07-07 20:29:26 | INFO | train_inner | epoch 001:  32300 / 150053 loss=5.582, nll_loss=4.339, ppl=20.24, wps=18166.6, ups=5.13, wpb=3542.5, bsz=108.3, num_updates=32300, lr=0.000175954, gnorm=0.961, train_wall=19, wall=0
2024-07-07 20:29:45 | INFO | train_inner | epoch 001:  32400 / 150053 loss=5.616, nll_loss=4.377, ppl=20.78, wps=18531.3, ups=5.2, wpb=3563.6, bsz=105.7, num_updates=32400, lr=0.000175682, gnorm=0.964, train_wall=19, wall=0
2024-07-07 20:30:04 | INFO | train_inner | epoch 001:  32500 / 150053 loss=5.578, nll_loss=4.335, ppl=20.18, wps=18684.3, ups=5.17, wpb=3614.2, bsz=101.5, num_updates=32500, lr=0.000175412, gnorm=0.935, train_wall=19, wall=0
2024-07-07 20:30:24 | INFO | train_inner | epoch 001:  32600 / 150053 loss=5.593, nll_loss=4.352, ppl=20.42, wps=18131.2, ups=5.16, wpb=3516.2, bsz=105.9, num_updates=32600, lr=0.000175142, gnorm=0.964, train_wall=19, wall=0
2024-07-07 20:30:43 | INFO | train_inner | epoch 001:  32700 / 150053 loss=5.621, nll_loss=4.384, ppl=20.88, wps=18279, ups=5.2, wpb=3516.5, bsz=99.5, num_updates=32700, lr=0.000174874, gnorm=0.946, train_wall=19, wall=0
2024-07-07 20:31:02 | INFO | train_inner | epoch 001:  32800 / 150053 loss=5.613, nll_loss=4.375, ppl=20.75, wps=17892.6, ups=5.15, wpb=3476.6, bsz=101.3, num_updates=32800, lr=0.000174608, gnorm=0.967, train_wall=19, wall=0
2024-07-07 20:31:22 | INFO | train_inner | epoch 001:  32900 / 150053 loss=5.622, nll_loss=4.385, ppl=20.89, wps=18398, ups=5.18, wpb=3550.1, bsz=96.5, num_updates=32900, lr=0.000174342, gnorm=0.957, train_wall=19, wall=0
2024-07-07 20:31:41 | INFO | train_inner | epoch 001:  33000 / 150053 loss=5.604, nll_loss=4.364, ppl=20.6, wps=18210.8, ups=5.23, wpb=3482.9, bsz=116.1, num_updates=33000, lr=0.000174078, gnorm=1.013, train_wall=19, wall=0
2024-07-07 20:31:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 20:31:43 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.262 | nll_loss 5.037 | ppl 32.83 | wps 53577.2 | wpb 2588.8 | bsz 75.3 | num_updates 33000 | best_loss 12.211
2024-07-07 20:31:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 20:31:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_33000.pt (epoch 1 @ 33000 updates, score 6.262) (writing took 3.0776539174839854 seconds)
2024-07-07 20:32:05 | INFO | train_inner | epoch 001:  33100 / 150053 loss=5.61, nll_loss=4.371, ppl=20.68, wps=14480.7, ups=4.06, wpb=3566.4, bsz=111, num_updates=33100, lr=0.000173814, gnorm=1.002, train_wall=19, wall=0
2024-07-07 20:32:25 | INFO | train_inner | epoch 001:  33200 / 150053 loss=5.552, nll_loss=4.305, ppl=19.76, wps=18594.3, ups=5.2, wpb=3578.4, bsz=110.9, num_updates=33200, lr=0.000173553, gnorm=0.937, train_wall=19, wall=0
2024-07-07 20:32:44 | INFO | train_inner | epoch 001:  33300 / 150053 loss=5.667, nll_loss=4.437, ppl=21.66, wps=18050.7, ups=5.19, wpb=3476.8, bsz=98.6, num_updates=33300, lr=0.000173292, gnorm=1.002, train_wall=19, wall=0
2024-07-07 20:33:03 | INFO | train_inner | epoch 001:  33400 / 150053 loss=5.604, nll_loss=4.364, ppl=20.6, wps=18574.9, ups=5.13, wpb=3621.4, bsz=100.5, num_updates=33400, lr=0.000173032, gnorm=0.931, train_wall=19, wall=0
2024-07-07 20:33:23 | INFO | train_inner | epoch 001:  33500 / 150053 loss=5.578, nll_loss=4.334, ppl=20.17, wps=18266.6, ups=5.2, wpb=3511.7, bsz=119, num_updates=33500, lr=0.000172774, gnorm=1.001, train_wall=19, wall=0
2024-07-07 20:33:42 | INFO | train_inner | epoch 001:  33600 / 150053 loss=5.577, nll_loss=4.334, ppl=20.16, wps=18347.1, ups=5.15, wpb=3563.8, bsz=111.4, num_updates=33600, lr=0.000172516, gnorm=0.969, train_wall=19, wall=0
2024-07-07 20:34:01 | INFO | train_inner | epoch 001:  33700 / 150053 loss=5.595, nll_loss=4.355, ppl=20.46, wps=18537.6, ups=5.19, wpb=3568.7, bsz=102.6, num_updates=33700, lr=0.00017226, gnorm=0.967, train_wall=19, wall=0
2024-07-07 20:34:20 | INFO | train_inner | epoch 001:  33800 / 150053 loss=5.605, nll_loss=4.365, ppl=20.61, wps=18135.5, ups=5.18, wpb=3498, bsz=99.5, num_updates=33800, lr=0.000172005, gnorm=0.988, train_wall=19, wall=0
2024-07-07 20:34:40 | INFO | train_inner | epoch 001:  33900 / 150053 loss=5.597, nll_loss=4.356, ppl=20.48, wps=18675.7, ups=5.19, wpb=3596, bsz=100.6, num_updates=33900, lr=0.000171751, gnorm=0.938, train_wall=19, wall=0
2024-07-07 20:34:59 | INFO | train_inner | epoch 001:  34000 / 150053 loss=5.609, nll_loss=4.369, ppl=20.67, wps=18527.8, ups=5.14, wpb=3602.7, bsz=106.2, num_updates=34000, lr=0.000171499, gnorm=0.964, train_wall=19, wall=0
2024-07-07 20:34:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 20:35:01 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.225 | nll_loss 4.986 | ppl 31.69 | wps 53709.6 | wpb 2588.8 | bsz 75.3 | num_updates 34000 | best_loss 12.211
2024-07-07 20:35:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 20:35:05 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_34000.pt (epoch 1 @ 34000 updates, score 6.225) (writing took 3.3129998594522476 seconds)
2024-07-07 20:35:24 | INFO | train_inner | epoch 001:  34100 / 150053 loss=5.645, nll_loss=4.411, ppl=21.27, wps=14185.1, ups=4.03, wpb=3522.7, bsz=115.4, num_updates=34100, lr=0.000171247, gnorm=1.063, train_wall=19, wall=0
2024-07-07 20:35:43 | INFO | train_inner | epoch 001:  34200 / 150053 loss=5.619, nll_loss=4.381, ppl=20.84, wps=18274.4, ups=5.16, wpb=3538.3, bsz=106.5, num_updates=34200, lr=0.000170996, gnorm=0.984, train_wall=19, wall=0
2024-07-07 20:36:03 | INFO | train_inner | epoch 001:  34300 / 150053 loss=5.651, nll_loss=4.418, ppl=21.38, wps=18280, ups=5.21, wpb=3510, bsz=90.1, num_updates=34300, lr=0.000170747, gnorm=0.961, train_wall=19, wall=0
2024-07-07 20:36:22 | INFO | train_inner | epoch 001:  34400 / 150053 loss=5.568, nll_loss=4.323, ppl=20.01, wps=18616.7, ups=5.14, wpb=3622.6, bsz=114.8, num_updates=34400, lr=0.000170499, gnorm=0.962, train_wall=19, wall=0
2024-07-07 20:36:41 | INFO | train_inner | epoch 001:  34500 / 150053 loss=5.605, nll_loss=4.365, ppl=20.61, wps=18094.9, ups=5.18, wpb=3492, bsz=98, num_updates=34500, lr=0.000170251, gnorm=0.99, train_wall=19, wall=0
2024-07-07 20:37:01 | INFO | train_inner | epoch 001:  34600 / 150053 loss=5.639, nll_loss=4.404, ppl=21.18, wps=18260.9, ups=5.17, wpb=3535.5, bsz=97.4, num_updates=34600, lr=0.000170005, gnorm=0.971, train_wall=19, wall=0
2024-07-07 20:37:20 | INFO | train_inner | epoch 001:  34700 / 150053 loss=5.613, nll_loss=4.375, ppl=20.75, wps=18636.4, ups=5.21, wpb=3574.1, bsz=101.1, num_updates=34700, lr=0.00016976, gnorm=0.955, train_wall=19, wall=0
2024-07-07 20:37:39 | INFO | train_inner | epoch 001:  34800 / 150053 loss=5.634, nll_loss=4.398, ppl=21.08, wps=18319.5, ups=5.16, wpb=3548.6, bsz=106.4, num_updates=34800, lr=0.000169516, gnorm=1.01, train_wall=19, wall=0
2024-07-07 20:37:59 | INFO | train_inner | epoch 001:  34900 / 150053 loss=5.614, nll_loss=4.376, ppl=20.76, wps=18110.2, ups=5.16, wpb=3510.3, bsz=95.7, num_updates=34900, lr=0.000169273, gnorm=0.966, train_wall=19, wall=0
2024-07-07 20:38:18 | INFO | train_inner | epoch 001:  35000 / 150053 loss=5.56, nll_loss=4.314, ppl=19.89, wps=18486.8, ups=5.2, wpb=3553.3, bsz=101.8, num_updates=35000, lr=0.000169031, gnorm=0.955, train_wall=19, wall=0
2024-07-07 20:38:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 20:38:20 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.258 | nll_loss 5.025 | ppl 32.57 | wps 53754.8 | wpb 2588.8 | bsz 75.3 | num_updates 35000 | best_loss 12.211
2024-07-07 20:38:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 20:38:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_35000.pt (epoch 1 @ 35000 updates, score 6.258) (writing took 3.170479136519134 seconds)
2024-07-07 20:38:43 | INFO | train_inner | epoch 001:  35100 / 150053 loss=5.546, nll_loss=4.299, ppl=19.69, wps=14216.1, ups=4.04, wpb=3516, bsz=109.8, num_updates=35100, lr=0.00016879, gnorm=0.979, train_wall=19, wall=0
2024-07-07 20:39:02 | INFO | train_inner | epoch 001:  35200 / 150053 loss=5.589, nll_loss=4.346, ppl=20.34, wps=18559.9, ups=5.14, wpb=3608.1, bsz=99, num_updates=35200, lr=0.00016855, gnorm=0.948, train_wall=19, wall=0
2024-07-07 20:39:21 | INFO | train_inner | epoch 001:  35300 / 150053 loss=5.545, nll_loss=4.297, ppl=19.66, wps=18630.4, ups=5.14, wpb=3624.1, bsz=99.8, num_updates=35300, lr=0.000168311, gnorm=0.943, train_wall=19, wall=0
2024-07-07 20:39:41 | INFO | train_inner | epoch 001:  35400 / 150053 loss=5.58, nll_loss=4.338, ppl=20.22, wps=18236.1, ups=5.16, wpb=3533.8, bsz=99.4, num_updates=35400, lr=0.000168073, gnorm=0.975, train_wall=19, wall=0
2024-07-07 20:40:00 | INFO | train_inner | epoch 001:  35500 / 150053 loss=5.594, nll_loss=4.353, ppl=20.43, wps=18158.6, ups=5.25, wpb=3462, bsz=102.3, num_updates=35500, lr=0.000167836, gnorm=1.002, train_wall=19, wall=0
2024-07-07 20:40:19 | INFO | train_inner | epoch 001:  35600 / 150053 loss=5.589, nll_loss=4.348, ppl=20.36, wps=18526.1, ups=5.13, wpb=3608.1, bsz=100.5, num_updates=35600, lr=0.0001676, gnorm=0.959, train_wall=19, wall=0
2024-07-07 20:40:39 | INFO | train_inner | epoch 001:  35700 / 150053 loss=5.633, nll_loss=4.397, ppl=21.07, wps=18371.7, ups=5.21, wpb=3525.9, bsz=96.2, num_updates=35700, lr=0.000167365, gnorm=0.97, train_wall=19, wall=0
2024-07-07 20:40:58 | INFO | train_inner | epoch 001:  35800 / 150053 loss=5.533, nll_loss=4.284, ppl=19.48, wps=18173.5, ups=5.14, wpb=3532.8, bsz=111, num_updates=35800, lr=0.000167132, gnorm=0.97, train_wall=19, wall=0
2024-07-07 20:41:17 | INFO | train_inner | epoch 001:  35900 / 150053 loss=5.651, nll_loss=4.418, ppl=21.37, wps=18654.9, ups=5.2, wpb=3586.3, bsz=88.9, num_updates=35900, lr=0.000166899, gnorm=0.969, train_wall=19, wall=0
2024-07-07 20:41:37 | INFO | train_inner | epoch 001:  36000 / 150053 loss=5.505, nll_loss=4.251, ppl=19.04, wps=18464.8, ups=5.12, wpb=3604.4, bsz=104.4, num_updates=36000, lr=0.000166667, gnorm=0.931, train_wall=19, wall=0
2024-07-07 20:41:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 20:41:39 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.223 | nll_loss 4.985 | ppl 31.67 | wps 53894.6 | wpb 2588.8 | bsz 75.3 | num_updates 36000 | best_loss 12.211
2024-07-07 20:41:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 20:41:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_36000.pt (epoch 1 @ 36000 updates, score 6.223) (writing took 3.0838460847735405 seconds)
2024-07-07 20:42:01 | INFO | train_inner | epoch 001:  36100 / 150053 loss=5.582, nll_loss=4.34, ppl=20.25, wps=14362.3, ups=4.11, wpb=3497.2, bsz=102.2, num_updates=36100, lr=0.000166436, gnorm=0.981, train_wall=19, wall=0
2024-07-07 20:42:20 | INFO | train_inner | epoch 001:  36200 / 150053 loss=5.539, nll_loss=4.291, ppl=19.57, wps=18297.8, ups=5.16, wpb=3543.5, bsz=113, num_updates=36200, lr=0.000166206, gnorm=0.979, train_wall=19, wall=0
2024-07-07 20:42:40 | INFO | train_inner | epoch 001:  36300 / 150053 loss=5.574, nll_loss=4.33, ppl=20.11, wps=18585, ups=5.25, wpb=3540, bsz=104.7, num_updates=36300, lr=0.000165977, gnorm=0.977, train_wall=19, wall=0
2024-07-07 20:42:59 | INFO | train_inner | epoch 001:  36400 / 150053 loss=5.624, nll_loss=4.387, ppl=20.93, wps=18025, ups=5.17, wpb=3483.7, bsz=94.3, num_updates=36400, lr=0.000165748, gnorm=0.963, train_wall=19, wall=0
2024-07-07 20:43:18 | INFO | train_inner | epoch 001:  36500 / 150053 loss=5.591, nll_loss=4.35, ppl=20.39, wps=18076.5, ups=5.2, wpb=3474.6, bsz=111.9, num_updates=36500, lr=0.000165521, gnorm=0.994, train_wall=19, wall=0
2024-07-07 20:43:37 | INFO | train_inner | epoch 001:  36600 / 150053 loss=5.582, nll_loss=4.339, ppl=20.23, wps=18367.8, ups=5.18, wpb=3547.7, bsz=90, num_updates=36600, lr=0.000165295, gnorm=0.946, train_wall=19, wall=0
2024-07-07 20:43:57 | INFO | train_inner | epoch 001:  36700 / 150053 loss=5.548, nll_loss=4.301, ppl=19.71, wps=18440.8, ups=5.19, wpb=3554.4, bsz=100.6, num_updates=36700, lr=0.00016507, gnorm=0.986, train_wall=19, wall=0
2024-07-07 20:44:16 | INFO | train_inner | epoch 001:  36800 / 150053 loss=5.508, nll_loss=4.255, ppl=19.1, wps=18431.6, ups=5.12, wpb=3597.4, bsz=108.2, num_updates=36800, lr=0.000164845, gnorm=0.962, train_wall=19, wall=0
2024-07-07 20:44:35 | INFO | train_inner | epoch 001:  36900 / 150053 loss=5.615, nll_loss=4.377, ppl=20.78, wps=18455.6, ups=5.27, wpb=3499.3, bsz=87.4, num_updates=36900, lr=0.000164622, gnorm=0.978, train_wall=19, wall=0
2024-07-07 20:44:55 | INFO | train_inner | epoch 001:  37000 / 150053 loss=5.587, nll_loss=4.346, ppl=20.33, wps=18684.9, ups=5.11, wpb=3655.4, bsz=94.9, num_updates=37000, lr=0.000164399, gnorm=0.933, train_wall=19, wall=0
2024-07-07 20:44:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 20:44:57 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.227 | nll_loss 4.991 | ppl 31.81 | wps 53241.9 | wpb 2588.8 | bsz 75.3 | num_updates 37000 | best_loss 12.211
2024-07-07 20:44:57 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 20:45:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_37000.pt (epoch 1 @ 37000 updates, score 6.227) (writing took 3.1840233858674765 seconds)
2024-07-07 20:45:19 | INFO | train_inner | epoch 001:  37100 / 150053 loss=5.524, nll_loss=4.273, ppl=19.34, wps=14303.5, ups=4.05, wpb=3535.4, bsz=97.2, num_updates=37100, lr=0.000164177, gnorm=0.971, train_wall=19, wall=0
2024-07-07 20:45:39 | INFO | train_inner | epoch 001:  37200 / 150053 loss=5.573, nll_loss=4.33, ppl=20.11, wps=18315.6, ups=5.17, wpb=3541.3, bsz=102.5, num_updates=37200, lr=0.000163956, gnorm=0.961, train_wall=19, wall=0
2024-07-07 20:45:58 | INFO | train_inner | epoch 001:  37300 / 150053 loss=5.54, nll_loss=4.291, ppl=19.58, wps=18291.2, ups=5.22, wpb=3501.4, bsz=111.1, num_updates=37300, lr=0.000163737, gnorm=1.003, train_wall=19, wall=0
2024-07-07 20:46:17 | INFO | train_inner | epoch 001:  37400 / 150053 loss=5.672, nll_loss=4.442, ppl=21.74, wps=18264.4, ups=5.22, wpb=3500.6, bsz=84.4, num_updates=37400, lr=0.000163517, gnorm=0.965, train_wall=19, wall=0
2024-07-07 20:46:36 | INFO | train_inner | epoch 001:  37500 / 150053 loss=5.538, nll_loss=4.29, ppl=19.56, wps=18253.7, ups=5.16, wpb=3540.2, bsz=113, num_updates=37500, lr=0.000163299, gnorm=0.994, train_wall=19, wall=0
2024-07-07 20:46:56 | INFO | train_inner | epoch 001:  37600 / 150053 loss=5.511, nll_loss=4.259, ppl=19.15, wps=18330.2, ups=5.11, wpb=3590.3, bsz=102.4, num_updates=37600, lr=0.000163082, gnorm=0.972, train_wall=19, wall=0
2024-07-07 20:47:15 | INFO | train_inner | epoch 001:  37700 / 150053 loss=5.609, nll_loss=4.371, ppl=20.69, wps=18390.7, ups=5.23, wpb=3513.6, bsz=93, num_updates=37700, lr=0.000162866, gnorm=0.986, train_wall=19, wall=0
2024-07-07 20:47:34 | INFO | train_inner | epoch 001:  37800 / 150053 loss=5.568, nll_loss=4.324, ppl=20.03, wps=18280.3, ups=5.18, wpb=3525.7, bsz=99.9, num_updates=37800, lr=0.00016265, gnorm=0.965, train_wall=19, wall=0
2024-07-07 20:47:54 | INFO | train_inner | epoch 001:  37900 / 150053 loss=5.507, nll_loss=4.254, ppl=19.08, wps=18208.3, ups=5.18, wpb=3515.2, bsz=113, num_updates=37900, lr=0.000162435, gnorm=0.991, train_wall=19, wall=0
2024-07-07 20:48:13 | INFO | train_inner | epoch 001:  38000 / 150053 loss=5.604, nll_loss=4.364, ppl=20.59, wps=18581.3, ups=5.16, wpb=3602.3, bsz=97.1, num_updates=38000, lr=0.000162221, gnorm=0.976, train_wall=19, wall=0
2024-07-07 20:48:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 20:48:15 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.185 | nll_loss 4.947 | ppl 30.84 | wps 53534.3 | wpb 2588.8 | bsz 75.3 | num_updates 38000 | best_loss 12.211
2024-07-07 20:48:15 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 20:48:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_38000.pt (epoch 1 @ 38000 updates, score 6.185) (writing took 3.780717625282705 seconds)
2024-07-07 20:48:38 | INFO | train_inner | epoch 001:  38100 / 150053 loss=5.603, nll_loss=4.363, ppl=20.58, wps=13844.7, ups=3.97, wpb=3488, bsz=96.2, num_updates=38100, lr=0.000162008, gnorm=0.999, train_wall=19, wall=0
2024-07-07 20:48:58 | INFO | train_inner | epoch 001:  38200 / 150053 loss=5.476, nll_loss=4.219, ppl=18.62, wps=18291.7, ups=5.2, wpb=3519.8, bsz=117.4, num_updates=38200, lr=0.000161796, gnorm=1.002, train_wall=19, wall=0
2024-07-07 20:49:17 | INFO | train_inner | epoch 001:  38300 / 150053 loss=5.526, nll_loss=4.275, ppl=19.36, wps=18356.6, ups=5.22, wpb=3519.1, bsz=109, num_updates=38300, lr=0.000161585, gnorm=0.998, train_wall=19, wall=0
2024-07-07 20:49:36 | INFO | train_inner | epoch 001:  38400 / 150053 loss=5.558, nll_loss=4.312, ppl=19.86, wps=18424, ups=5.18, wpb=3557.8, bsz=108, num_updates=38400, lr=0.000161374, gnorm=0.981, train_wall=19, wall=0
2024-07-07 20:49:56 | INFO | train_inner | epoch 001:  38500 / 150053 loss=5.572, nll_loss=4.329, ppl=20.09, wps=18360.8, ups=5.1, wpb=3597.3, bsz=93.4, num_updates=38500, lr=0.000161165, gnorm=0.944, train_wall=19, wall=0
2024-07-07 20:50:15 | INFO | train_inner | epoch 001:  38600 / 150053 loss=5.544, nll_loss=4.297, ppl=19.66, wps=18295.4, ups=5.2, wpb=3519.4, bsz=96.8, num_updates=38600, lr=0.000160956, gnorm=0.978, train_wall=19, wall=0
2024-07-07 20:50:34 | INFO | train_inner | epoch 001:  38700 / 150053 loss=5.55, nll_loss=4.303, ppl=19.74, wps=18506.9, ups=5.16, wpb=3585.5, bsz=91, num_updates=38700, lr=0.000160748, gnorm=0.944, train_wall=19, wall=0
2024-07-07 20:50:54 | INFO | train_inner | epoch 001:  38800 / 150053 loss=5.523, nll_loss=4.273, ppl=19.33, wps=17947.7, ups=5.11, wpb=3511.3, bsz=99.6, num_updates=38800, lr=0.00016054, gnorm=0.973, train_wall=19, wall=0
2024-07-07 20:51:13 | INFO | train_inner | epoch 001:  38900 / 150053 loss=5.559, nll_loss=4.314, ppl=19.88, wps=18300.4, ups=5.21, wpb=3512.2, bsz=102, num_updates=38900, lr=0.000160334, gnorm=0.993, train_wall=19, wall=0
2024-07-07 20:51:32 | INFO | train_inner | epoch 001:  39000 / 150053 loss=5.534, nll_loss=4.285, ppl=19.5, wps=18378.5, ups=5.24, wpb=3506.7, bsz=98.6, num_updates=39000, lr=0.000160128, gnorm=0.98, train_wall=19, wall=0
2024-07-07 20:51:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 20:51:34 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.192 | nll_loss 4.956 | ppl 31.04 | wps 53679.6 | wpb 2588.8 | bsz 75.3 | num_updates 39000 | best_loss 12.211
2024-07-07 20:51:34 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 20:51:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_39000.pt (epoch 1 @ 39000 updates, score 6.192) (writing took 3.6425673374906182 seconds)
2024-07-07 20:51:57 | INFO | train_inner | epoch 001:  39100 / 150053 loss=5.579, nll_loss=4.337, ppl=20.2, wps=13956.1, ups=3.97, wpb=3513.2, bsz=100.6, num_updates=39100, lr=0.000159923, gnorm=1.046, train_wall=19, wall=0
2024-07-07 20:52:17 | INFO | train_inner | epoch 001:  39200 / 150053 loss=5.521, nll_loss=4.271, ppl=19.3, wps=18229.1, ups=5.14, wpb=3547.9, bsz=104.2, num_updates=39200, lr=0.000159719, gnorm=0.951, train_wall=19, wall=0
2024-07-07 20:52:36 | INFO | train_inner | epoch 001:  39300 / 150053 loss=5.545, nll_loss=4.298, ppl=19.67, wps=18283.4, ups=5.18, wpb=3527.8, bsz=105.6, num_updates=39300, lr=0.000159516, gnorm=0.972, train_wall=19, wall=0
2024-07-07 20:52:56 | INFO | train_inner | epoch 001:  39400 / 150053 loss=5.517, nll_loss=4.265, ppl=19.23, wps=18532.2, ups=5.11, wpb=3624.7, bsz=101.3, num_updates=39400, lr=0.000159313, gnorm=0.944, train_wall=19, wall=0
2024-07-07 20:53:15 | INFO | train_inner | epoch 001:  39500 / 150053 loss=5.538, nll_loss=4.289, ppl=19.55, wps=18396.6, ups=5.17, wpb=3560.3, bsz=119.7, num_updates=39500, lr=0.000159111, gnorm=1.081, train_wall=19, wall=0
2024-07-07 20:53:34 | INFO | train_inner | epoch 001:  39600 / 150053 loss=5.53, nll_loss=4.28, ppl=19.42, wps=18568.2, ups=5.17, wpb=3592.3, bsz=106.4, num_updates=39600, lr=0.00015891, gnorm=0.99, train_wall=19, wall=0
2024-07-07 20:53:54 | INFO | train_inner | epoch 001:  39700 / 150053 loss=5.496, nll_loss=4.242, ppl=18.92, wps=17929.2, ups=5.17, wpb=3466.5, bsz=105.4, num_updates=39700, lr=0.00015871, gnorm=0.969, train_wall=19, wall=0
2024-07-07 20:54:13 | INFO | train_inner | epoch 001:  39800 / 150053 loss=5.515, nll_loss=4.264, ppl=19.21, wps=18486.8, ups=5.16, wpb=3584.6, bsz=105, num_updates=39800, lr=0.000158511, gnorm=0.972, train_wall=19, wall=0
2024-07-07 20:54:32 | INFO | train_inner | epoch 001:  39900 / 150053 loss=5.448, nll_loss=4.187, ppl=18.21, wps=18469.8, ups=5.15, wpb=3588.3, bsz=114.2, num_updates=39900, lr=0.000158312, gnorm=0.98, train_wall=19, wall=0
2024-07-07 20:54:52 | INFO | train_inner | epoch 001:  40000 / 150053 loss=5.527, nll_loss=4.276, ppl=19.38, wps=18254.8, ups=5.17, wpb=3534.2, bsz=93.9, num_updates=40000, lr=0.000158114, gnorm=0.978, train_wall=19, wall=0
2024-07-07 20:54:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 20:54:54 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.21 | nll_loss 4.97 | ppl 31.33 | wps 53770.3 | wpb 2588.8 | bsz 75.3 | num_updates 40000 | best_loss 12.211
2024-07-07 20:54:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 20:54:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_40000.pt (epoch 1 @ 40000 updates, score 6.21) (writing took 4.0674926191568375 seconds)
2024-07-07 20:55:18 | INFO | train_inner | epoch 001:  40100 / 150053 loss=5.528, nll_loss=4.278, ppl=19.4, wps=13992.6, ups=3.87, wpb=3615.7, bsz=94.8, num_updates=40100, lr=0.000157917, gnorm=0.956, train_wall=19, wall=0
2024-07-07 20:55:37 | INFO | train_inner | epoch 001:  40200 / 150053 loss=5.53, nll_loss=4.28, ppl=19.42, wps=18391.2, ups=5.18, wpb=3548.6, bsz=114.1, num_updates=40200, lr=0.00015772, gnorm=1.034, train_wall=19, wall=0
2024-07-07 20:55:56 | INFO | train_inner | epoch 001:  40300 / 150053 loss=5.564, nll_loss=4.32, ppl=19.97, wps=18317.8, ups=5.19, wpb=3528.8, bsz=99.4, num_updates=40300, lr=0.000157524, gnorm=0.977, train_wall=19, wall=0
2024-07-07 20:56:15 | INFO | train_inner | epoch 001:  40400 / 150053 loss=5.533, nll_loss=4.284, ppl=19.49, wps=18099.9, ups=5.19, wpb=3484.6, bsz=102.2, num_updates=40400, lr=0.000157329, gnorm=0.99, train_wall=19, wall=0
2024-07-07 20:56:35 | INFO | train_inner | epoch 001:  40500 / 150053 loss=5.463, nll_loss=4.205, ppl=18.44, wps=18407.7, ups=5.16, wpb=3566.9, bsz=101.8, num_updates=40500, lr=0.000157135, gnorm=0.95, train_wall=19, wall=0
2024-07-07 20:56:54 | INFO | train_inner | epoch 001:  40600 / 150053 loss=5.507, nll_loss=4.254, ppl=19.08, wps=18342.4, ups=5.19, wpb=3531.5, bsz=101.9, num_updates=40600, lr=0.000156941, gnorm=0.984, train_wall=19, wall=0
2024-07-07 20:57:13 | INFO | train_inner | epoch 001:  40700 / 150053 loss=5.493, nll_loss=4.239, ppl=18.88, wps=18105.9, ups=5.18, wpb=3493.7, bsz=100.1, num_updates=40700, lr=0.000156748, gnorm=0.988, train_wall=19, wall=0
2024-07-07 20:57:33 | INFO | train_inner | epoch 001:  40800 / 150053 loss=5.505, nll_loss=4.251, ppl=19.05, wps=18411, ups=5.19, wpb=3548.2, bsz=108, num_updates=40800, lr=0.000156556, gnorm=0.993, train_wall=19, wall=0
2024-07-07 20:57:52 | INFO | train_inner | epoch 001:  40900 / 150053 loss=5.496, nll_loss=4.242, ppl=18.92, wps=18452.4, ups=5.15, wpb=3584.7, bsz=104.5, num_updates=40900, lr=0.000156365, gnorm=0.983, train_wall=19, wall=0
2024-07-07 20:58:11 | INFO | train_inner | epoch 001:  41000 / 150053 loss=5.512, nll_loss=4.26, ppl=19.16, wps=18213.6, ups=5.23, wpb=3483.7, bsz=95.8, num_updates=41000, lr=0.000156174, gnorm=0.976, train_wall=19, wall=0
2024-07-07 20:58:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 20:58:13 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.193 | nll_loss 4.954 | ppl 30.99 | wps 53684.7 | wpb 2588.8 | bsz 75.3 | num_updates 41000 | best_loss 12.211
2024-07-07 20:58:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 20:58:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_41000.pt (epoch 1 @ 41000 updates, score 6.193) (writing took 3.89062272477895 seconds)
2024-07-07 20:58:37 | INFO | train_inner | epoch 001:  41100 / 150053 loss=5.535, nll_loss=4.286, ppl=19.5, wps=13966.9, ups=3.92, wpb=3561.1, bsz=107.6, num_updates=41100, lr=0.000155984, gnorm=1.014, train_wall=19, wall=0
2024-07-07 20:58:56 | INFO | train_inner | epoch 001:  41200 / 150053 loss=5.53, nll_loss=4.28, ppl=19.43, wps=18442.5, ups=5.14, wpb=3588.1, bsz=97.6, num_updates=41200, lr=0.000155794, gnorm=0.967, train_wall=19, wall=0
2024-07-07 20:59:16 | INFO | train_inner | epoch 001:  41300 / 150053 loss=5.447, nll_loss=4.185, ppl=18.19, wps=18616.4, ups=5.15, wpb=3612.5, bsz=114.6, num_updates=41300, lr=0.000155606, gnorm=1.018, train_wall=19, wall=0
2024-07-07 20:59:35 | INFO | train_inner | epoch 001:  41400 / 150053 loss=5.521, nll_loss=4.271, ppl=19.3, wps=18460.7, ups=5.21, wpb=3540.4, bsz=89.9, num_updates=41400, lr=0.000155417, gnorm=0.971, train_wall=19, wall=0
2024-07-07 20:59:54 | INFO | train_inner | epoch 001:  41500 / 150053 loss=5.566, nll_loss=4.322, ppl=19.99, wps=18277, ups=5.21, wpb=3508.3, bsz=97.4, num_updates=41500, lr=0.00015523, gnorm=0.995, train_wall=19, wall=0
2024-07-07 21:00:13 | INFO | train_inner | epoch 001:  41600 / 150053 loss=5.541, nll_loss=4.293, ppl=19.6, wps=18311, ups=5.16, wpb=3546.8, bsz=104.4, num_updates=41600, lr=0.000155043, gnorm=0.963, train_wall=19, wall=0
2024-07-07 21:00:33 | INFO | train_inner | epoch 001:  41700 / 150053 loss=5.526, nll_loss=4.276, ppl=19.37, wps=18442.7, ups=5.18, wpb=3560.8, bsz=106.2, num_updates=41700, lr=0.000154857, gnorm=0.988, train_wall=19, wall=0
2024-07-07 21:00:52 | INFO | train_inner | epoch 001:  41800 / 150053 loss=5.518, nll_loss=4.268, ppl=19.26, wps=18162.3, ups=5.19, wpb=3501.5, bsz=104.5, num_updates=41800, lr=0.000154672, gnorm=1.01, train_wall=19, wall=0
2024-07-07 21:01:11 | INFO | train_inner | epoch 001:  41900 / 150053 loss=5.507, nll_loss=4.254, ppl=19.09, wps=18268.8, ups=5.19, wpb=3517.8, bsz=111.5, num_updates=41900, lr=0.000154487, gnorm=1.018, train_wall=19, wall=0
2024-07-07 21:01:30 | INFO | train_inner | epoch 001:  42000 / 150053 loss=5.529, nll_loss=4.28, ppl=19.42, wps=18266.2, ups=5.21, wpb=3506.4, bsz=94, num_updates=42000, lr=0.000154303, gnorm=1.002, train_wall=19, wall=0
2024-07-07 21:01:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 21:01:33 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.189 | nll_loss 4.947 | ppl 30.84 | wps 53654.2 | wpb 2588.8 | bsz 75.3 | num_updates 42000 | best_loss 12.211
2024-07-07 21:01:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 21:01:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_42000.pt (epoch 1 @ 42000 updates, score 6.189) (writing took 4.263590362854302 seconds)
2024-07-07 21:01:56 | INFO | train_inner | epoch 001:  42100 / 150053 loss=5.476, nll_loss=4.22, ppl=18.64, wps=13788.6, ups=3.89, wpb=3541.1, bsz=112.7, num_updates=42100, lr=0.00015412, gnorm=0.983, train_wall=19, wall=0
2024-07-07 21:02:16 | INFO | train_inner | epoch 001:  42200 / 150053 loss=5.533, nll_loss=4.283, ppl=19.47, wps=18376.1, ups=5.13, wpb=3584.9, bsz=99.4, num_updates=42200, lr=0.000153937, gnorm=0.969, train_wall=19, wall=0
2024-07-07 21:02:35 | INFO | train_inner | epoch 001:  42300 / 150053 loss=5.524, nll_loss=4.274, ppl=19.35, wps=18422.1, ups=5.16, wpb=3572.3, bsz=101, num_updates=42300, lr=0.000153755, gnorm=0.988, train_wall=19, wall=0
2024-07-07 21:02:54 | INFO | train_inner | epoch 001:  42400 / 150053 loss=5.477, nll_loss=4.22, ppl=18.64, wps=18450.4, ups=5.12, wpb=3601.8, bsz=104.8, num_updates=42400, lr=0.000153574, gnorm=0.96, train_wall=19, wall=0
2024-07-07 21:03:14 | INFO | train_inner | epoch 001:  42500 / 150053 loss=5.446, nll_loss=4.185, ppl=18.19, wps=18227.5, ups=5.12, wpb=3560.6, bsz=103.3, num_updates=42500, lr=0.000153393, gnorm=0.963, train_wall=19, wall=0
2024-07-07 21:03:33 | INFO | train_inner | epoch 001:  42600 / 150053 loss=5.495, nll_loss=4.241, ppl=18.91, wps=18462.4, ups=5.14, wpb=3591.9, bsz=106.9, num_updates=42600, lr=0.000153213, gnorm=0.996, train_wall=19, wall=0
2024-07-07 21:03:53 | INFO | train_inner | epoch 001:  42700 / 150053 loss=5.457, nll_loss=4.197, ppl=18.34, wps=18408.4, ups=5.13, wpb=3591.8, bsz=107.2, num_updates=42700, lr=0.000153033, gnorm=0.97, train_wall=19, wall=0
2024-07-07 21:04:12 | INFO | train_inner | epoch 001:  42800 / 150053 loss=5.52, nll_loss=4.269, ppl=19.28, wps=18140.2, ups=5.17, wpb=3510.6, bsz=104.2, num_updates=42800, lr=0.000152854, gnorm=0.984, train_wall=19, wall=0
2024-07-07 21:04:32 | INFO | train_inner | epoch 001:  42900 / 150053 loss=5.509, nll_loss=4.257, ppl=19.12, wps=18314.4, ups=5.2, wpb=3522.9, bsz=107, num_updates=42900, lr=0.000152676, gnorm=1.009, train_wall=19, wall=0
2024-07-07 21:04:51 | INFO | train_inner | epoch 001:  43000 / 150053 loss=5.47, nll_loss=4.213, ppl=18.54, wps=18282.7, ups=5.11, wpb=3577.9, bsz=101, num_updates=43000, lr=0.000152499, gnorm=0.984, train_wall=19, wall=0
2024-07-07 21:04:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 21:04:53 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.196 | nll_loss 4.956 | ppl 31.03 | wps 53445.2 | wpb 2588.8 | bsz 75.3 | num_updates 43000 | best_loss 12.211
2024-07-07 21:04:53 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 21:04:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_43000.pt (epoch 1 @ 43000 updates, score 6.196) (writing took 3.916600196622312 seconds)
2024-07-07 21:05:17 | INFO | train_inner | epoch 001:  43100 / 150053 loss=5.501, nll_loss=4.248, ppl=19, wps=13876.8, ups=3.91, wpb=3551.7, bsz=97.2, num_updates=43100, lr=0.000152322, gnorm=0.981, train_wall=19, wall=0
2024-07-07 21:05:36 | INFO | train_inner | epoch 001:  43200 / 150053 loss=5.529, nll_loss=4.28, ppl=19.42, wps=18373.4, ups=5.15, wpb=3567.8, bsz=97, num_updates=43200, lr=0.000152145, gnorm=0.981, train_wall=19, wall=0
2024-07-07 21:05:56 | INFO | train_inner | epoch 001:  43300 / 150053 loss=5.449, nll_loss=4.188, ppl=18.22, wps=18284.3, ups=5.16, wpb=3546.7, bsz=117.1, num_updates=43300, lr=0.000151969, gnorm=1.026, train_wall=19, wall=0
2024-07-07 21:06:15 | INFO | train_inner | epoch 001:  43400 / 150053 loss=5.456, nll_loss=4.196, ppl=18.33, wps=18510.1, ups=5.08, wpb=3646.1, bsz=111.4, num_updates=43400, lr=0.000151794, gnorm=0.959, train_wall=20, wall=0
2024-07-07 21:06:35 | INFO | train_inner | epoch 001:  43500 / 150053 loss=5.524, nll_loss=4.274, ppl=19.34, wps=17981.6, ups=5.17, wpb=3480.7, bsz=100.4, num_updates=43500, lr=0.00015162, gnorm=0.987, train_wall=19, wall=0
2024-07-07 21:06:54 | INFO | train_inner | epoch 001:  43600 / 150053 loss=5.387, nll_loss=4.117, ppl=17.35, wps=18593.9, ups=5.1, wpb=3648.3, bsz=126.9, num_updates=43600, lr=0.000151446, gnorm=1.036, train_wall=19, wall=0
2024-07-07 21:07:14 | INFO | train_inner | epoch 001:  43700 / 150053 loss=5.529, nll_loss=4.28, ppl=19.43, wps=17955.1, ups=5.06, wpb=3551.9, bsz=103.8, num_updates=43700, lr=0.000151272, gnorm=1.013, train_wall=20, wall=0
2024-07-07 21:07:33 | INFO | train_inner | epoch 001:  43800 / 150053 loss=5.514, nll_loss=4.261, ppl=19.18, wps=18211.5, ups=5.16, wpb=3529, bsz=107, num_updates=43800, lr=0.000151099, gnorm=1.027, train_wall=19, wall=0
2024-07-07 21:07:53 | INFO | train_inner | epoch 001:  43900 / 150053 loss=5.477, nll_loss=4.22, ppl=18.63, wps=18572.1, ups=5.08, wpb=3658, bsz=105.8, num_updates=43900, lr=0.000150927, gnorm=0.98, train_wall=20, wall=0
2024-07-07 21:08:13 | INFO | train_inner | epoch 001:  44000 / 150053 loss=5.478, nll_loss=4.222, ppl=18.66, wps=17993, ups=5.15, wpb=3494.2, bsz=113, num_updates=44000, lr=0.000150756, gnorm=1.003, train_wall=19, wall=0
2024-07-07 21:08:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 21:08:15 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.166 | nll_loss 4.922 | ppl 30.32 | wps 53836.5 | wpb 2588.8 | bsz 75.3 | num_updates 44000 | best_loss 12.211
2024-07-07 21:08:15 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 21:08:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_44000.pt (epoch 1 @ 44000 updates, score 6.166) (writing took 3.3620602004230022 seconds)
2024-07-07 21:08:38 | INFO | train_inner | epoch 001:  44100 / 150053 loss=5.532, nll_loss=4.282, ppl=19.46, wps=13968.5, ups=3.99, wpb=3499.9, bsz=100.6, num_updates=44100, lr=0.000150585, gnorm=1.004, train_wall=19, wall=0
2024-07-07 21:08:57 | INFO | train_inner | epoch 001:  44200 / 150053 loss=5.468, nll_loss=4.21, ppl=18.5, wps=18190.8, ups=5.1, wpb=3566, bsz=101.8, num_updates=44200, lr=0.000150414, gnorm=0.968, train_wall=19, wall=0
2024-07-07 21:09:17 | INFO | train_inner | epoch 001:  44300 / 150053 loss=5.453, nll_loss=4.193, ppl=18.29, wps=18178.3, ups=5.13, wpb=3545.4, bsz=106.2, num_updates=44300, lr=0.000150244, gnorm=0.989, train_wall=19, wall=0
2024-07-07 21:09:36 | INFO | train_inner | epoch 001:  44400 / 150053 loss=5.509, nll_loss=4.258, ppl=19.13, wps=18286.6, ups=5.15, wpb=3551.9, bsz=92.5, num_updates=44400, lr=0.000150075, gnorm=0.974, train_wall=19, wall=0
2024-07-07 21:09:55 | INFO | train_inner | epoch 001:  44500 / 150053 loss=5.509, nll_loss=4.256, ppl=19.11, wps=18434.5, ups=5.18, wpb=3559.4, bsz=105.9, num_updates=44500, lr=0.000149906, gnorm=1.005, train_wall=19, wall=0
2024-07-07 21:10:15 | INFO | train_inner | epoch 001:  44600 / 150053 loss=5.496, nll_loss=4.242, ppl=18.92, wps=18211.1, ups=5.15, wpb=3538.5, bsz=92.7, num_updates=44600, lr=0.000149738, gnorm=0.971, train_wall=19, wall=0
2024-07-07 21:10:34 | INFO | train_inner | epoch 001:  44700 / 150053 loss=5.471, nll_loss=4.214, ppl=18.56, wps=18564.8, ups=5.15, wpb=3604.6, bsz=106.8, num_updates=44700, lr=0.000149571, gnorm=0.981, train_wall=19, wall=0
2024-07-07 21:10:54 | INFO | train_inner | epoch 001:  44800 / 150053 loss=5.504, nll_loss=4.251, ppl=19.05, wps=18608.4, ups=5.19, wpb=3587.9, bsz=108.3, num_updates=44800, lr=0.000149404, gnorm=1.002, train_wall=19, wall=0
2024-07-07 21:11:13 | INFO | train_inner | epoch 001:  44900 / 150053 loss=5.52, nll_loss=4.27, ppl=19.29, wps=18133.8, ups=5.17, wpb=3507.5, bsz=98.3, num_updates=44900, lr=0.000149237, gnorm=0.993, train_wall=19, wall=0
2024-07-07 21:11:32 | INFO | train_inner | epoch 001:  45000 / 150053 loss=5.556, nll_loss=4.311, ppl=19.85, wps=18498.1, ups=5.17, wpb=3577.6, bsz=99, num_updates=45000, lr=0.000149071, gnorm=1, train_wall=19, wall=0
2024-07-07 21:11:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 21:11:34 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.19 | nll_loss 4.949 | ppl 30.9 | wps 53706.8 | wpb 2588.8 | bsz 75.3 | num_updates 45000 | best_loss 12.211
2024-07-07 21:11:34 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 21:11:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_45000.pt (epoch 1 @ 45000 updates, score 6.19) (writing took 3.692551864311099 seconds)
2024-07-07 21:11:58 | INFO | train_inner | epoch 001:  45100 / 150053 loss=5.482, nll_loss=4.225, ppl=18.7, wps=14093, ups=3.94, wpb=3578.7, bsz=98.2, num_updates=45100, lr=0.000148906, gnorm=0.978, train_wall=19, wall=0
2024-07-07 21:12:17 | INFO | train_inner | epoch 001:  45200 / 150053 loss=5.448, nll_loss=4.187, ppl=18.21, wps=18385.4, ups=5.13, wpb=3582.8, bsz=109.9, num_updates=45200, lr=0.000148741, gnorm=0.97, train_wall=19, wall=0
2024-07-07 21:12:37 | INFO | train_inner | epoch 001:  45300 / 150053 loss=5.454, nll_loss=4.194, ppl=18.31, wps=18276.2, ups=5.14, wpb=3552.4, bsz=115.7, num_updates=45300, lr=0.000148577, gnorm=1.031, train_wall=19, wall=0
2024-07-07 21:12:56 | INFO | train_inner | epoch 001:  45400 / 150053 loss=5.504, nll_loss=4.251, ppl=19.04, wps=18492.7, ups=5.17, wpb=3573.8, bsz=106.6, num_updates=45400, lr=0.000148413, gnorm=1.003, train_wall=19, wall=0
2024-07-07 21:13:15 | INFO | train_inner | epoch 001:  45500 / 150053 loss=5.501, nll_loss=4.248, ppl=19, wps=18381.9, ups=5.22, wpb=3518.4, bsz=100.4, num_updates=45500, lr=0.00014825, gnorm=0.995, train_wall=19, wall=0
2024-07-07 21:13:34 | INFO | train_inner | epoch 001:  45600 / 150053 loss=5.536, nll_loss=4.288, ppl=19.53, wps=18178.3, ups=5.2, wpb=3494.6, bsz=100.4, num_updates=45600, lr=0.000148087, gnorm=1.019, train_wall=19, wall=0
2024-07-07 21:13:54 | INFO | train_inner | epoch 001:  45700 / 150053 loss=5.475, nll_loss=4.218, ppl=18.61, wps=18470.7, ups=5.13, wpb=3599.2, bsz=102.8, num_updates=45700, lr=0.000147925, gnorm=1.042, train_wall=19, wall=0
2024-07-07 21:14:13 | INFO | train_inner | epoch 001:  45800 / 150053 loss=5.457, nll_loss=4.198, ppl=18.35, wps=18607.5, ups=5.17, wpb=3600, bsz=110.4, num_updates=45800, lr=0.000147764, gnorm=1.034, train_wall=19, wall=0
2024-07-07 21:14:33 | INFO | train_inner | epoch 001:  45900 / 150053 loss=5.381, nll_loss=4.11, ppl=17.27, wps=18317.3, ups=5.13, wpb=3567.7, bsz=111.8, num_updates=45900, lr=0.000147602, gnorm=1.008, train_wall=19, wall=0
2024-07-07 21:14:52 | INFO | train_inner | epoch 001:  46000 / 150053 loss=5.44, nll_loss=4.177, ppl=18.09, wps=18545.3, ups=5.24, wpb=3539.6, bsz=102.7, num_updates=46000, lr=0.000147442, gnorm=1.02, train_wall=19, wall=0
2024-07-07 21:14:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 21:14:54 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.183 | nll_loss 4.941 | ppl 30.72 | wps 53902.2 | wpb 2588.8 | bsz 75.3 | num_updates 46000 | best_loss 12.211
2024-07-07 21:14:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 21:14:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_46000.pt (epoch 1 @ 46000 updates, score 6.183) (writing took 3.4247048487886786 seconds)
2024-07-07 21:15:17 | INFO | train_inner | epoch 001:  46100 / 150053 loss=5.416, nll_loss=4.151, ppl=17.77, wps=14166.2, ups=3.96, wpb=3573.2, bsz=100.4, num_updates=46100, lr=0.000147282, gnorm=1.027, train_wall=19, wall=0
2024-07-07 21:15:36 | INFO | train_inner | epoch 001:  46200 / 150053 loss=5.391, nll_loss=4.123, ppl=17.42, wps=18347.9, ups=5.13, wpb=3579.8, bsz=104.7, num_updates=46200, lr=0.000147122, gnorm=1.02, train_wall=19, wall=0
2024-07-07 21:15:56 | INFO | train_inner | epoch 001:  46300 / 150053 loss=5.415, nll_loss=4.15, ppl=17.75, wps=18276.3, ups=5.16, wpb=3542.8, bsz=105.5, num_updates=46300, lr=0.000146964, gnorm=1.111, train_wall=19, wall=0
2024-07-07 21:16:15 | INFO | train_inner | epoch 001:  46400 / 150053 loss=5.458, nll_loss=4.199, ppl=18.36, wps=17987.4, ups=5.22, wpb=3447.7, bsz=99, num_updates=46400, lr=0.000146805, gnorm=1.092, train_wall=19, wall=0
2024-07-07 21:16:34 | INFO | train_inner | epoch 001:  46500 / 150053 loss=5.407, nll_loss=4.141, ppl=17.64, wps=18471.7, ups=5.18, wpb=3566.4, bsz=107, num_updates=46500, lr=0.000146647, gnorm=1.017, train_wall=19, wall=0
2024-07-07 21:16:54 | INFO | train_inner | epoch 001:  46600 / 150053 loss=5.416, nll_loss=4.151, ppl=17.76, wps=18192.2, ups=5.15, wpb=3532.1, bsz=102.8, num_updates=46600, lr=0.00014649, gnorm=1.049, train_wall=19, wall=0
2024-07-07 21:17:13 | INFO | train_inner | epoch 001:  46700 / 150053 loss=5.36, nll_loss=4.088, ppl=17, wps=18464.2, ups=5.15, wpb=3587.9, bsz=103.8, num_updates=46700, lr=0.000146333, gnorm=1.011, train_wall=19, wall=0
2024-07-07 21:17:33 | INFO | train_inner | epoch 001:  46800 / 150053 loss=5.356, nll_loss=4.082, ppl=16.93, wps=18406.9, ups=5.12, wpb=3595.2, bsz=103.9, num_updates=46800, lr=0.000146176, gnorm=1.047, train_wall=19, wall=0
2024-07-07 21:17:52 | INFO | train_inner | epoch 001:  46900 / 150053 loss=5.417, nll_loss=4.152, ppl=17.78, wps=18310.9, ups=5.14, wpb=3561.7, bsz=105.6, num_updates=46900, lr=0.00014602, gnorm=1.071, train_wall=19, wall=0
2024-07-07 21:18:11 | INFO | train_inner | epoch 001:  47000 / 150053 loss=5.408, nll_loss=4.141, ppl=17.64, wps=18146.8, ups=5.16, wpb=3515.7, bsz=102, num_updates=47000, lr=0.000145865, gnorm=1.033, train_wall=19, wall=0
2024-07-07 21:18:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 21:18:14 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.055 | nll_loss 4.801 | ppl 27.88 | wps 53600.8 | wpb 2588.8 | bsz 75.3 | num_updates 47000 | best_loss 12.211
2024-07-07 21:18:14 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 21:18:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_47000.pt (epoch 1 @ 47000 updates, score 6.055) (writing took 3.649655455723405 seconds)
2024-07-07 21:18:37 | INFO | train_inner | epoch 001:  47100 / 150053 loss=5.347, nll_loss=4.072, ppl=16.82, wps=14212.8, ups=3.93, wpb=3614.3, bsz=123.2, num_updates=47100, lr=0.00014571, gnorm=1.083, train_wall=19, wall=0
2024-07-07 21:18:56 | INFO | train_inner | epoch 001:  47200 / 150053 loss=5.442, nll_loss=4.18, ppl=18.13, wps=18466.2, ups=5.16, wpb=3575.9, bsz=94.8, num_updates=47200, lr=0.000145556, gnorm=1.047, train_wall=19, wall=0
2024-07-07 21:19:15 | INFO | train_inner | epoch 001:  47300 / 150053 loss=5.403, nll_loss=4.137, ppl=17.6, wps=18498.4, ups=5.22, wpb=3544.4, bsz=101.5, num_updates=47300, lr=0.000145402, gnorm=1.078, train_wall=19, wall=0
2024-07-07 21:19:35 | INFO | train_inner | epoch 001:  47400 / 150053 loss=5.349, nll_loss=4.075, ppl=16.85, wps=18349.6, ups=5.15, wpb=3563.1, bsz=99.4, num_updates=47400, lr=0.000145248, gnorm=1.029, train_wall=19, wall=0
2024-07-07 21:19:54 | INFO | train_inner | epoch 001:  47500 / 150053 loss=5.387, nll_loss=4.117, ppl=17.36, wps=18436.7, ups=5.16, wpb=3573.2, bsz=105.2, num_updates=47500, lr=0.000145095, gnorm=1.031, train_wall=19, wall=0
2024-07-07 21:20:14 | INFO | train_inner | epoch 001:  47600 / 150053 loss=5.381, nll_loss=4.111, ppl=17.28, wps=18295.3, ups=5.13, wpb=3563.1, bsz=106.2, num_updates=47600, lr=0.000144943, gnorm=1.035, train_wall=19, wall=0
2024-07-07 21:20:33 | INFO | train_inner | epoch 001:  47700 / 150053 loss=5.391, nll_loss=4.122, ppl=17.41, wps=18346.4, ups=5.12, wpb=3580.6, bsz=103.2, num_updates=47700, lr=0.000144791, gnorm=1.027, train_wall=19, wall=0
2024-07-07 21:20:53 | INFO | train_inner | epoch 001:  47800 / 150053 loss=5.34, nll_loss=4.064, ppl=16.72, wps=18369.1, ups=5.13, wpb=3580.9, bsz=113.1, num_updates=47800, lr=0.000144639, gnorm=1.058, train_wall=19, wall=0
2024-07-07 21:21:12 | INFO | train_inner | epoch 001:  47900 / 150053 loss=5.426, nll_loss=4.162, ppl=17.9, wps=18097.2, ups=5.23, wpb=3462.5, bsz=94.2, num_updates=47900, lr=0.000144488, gnorm=1.083, train_wall=19, wall=0
2024-07-07 21:21:31 | INFO | train_inner | epoch 001:  48000 / 150053 loss=5.398, nll_loss=4.13, ppl=17.51, wps=18344.9, ups=5.16, wpb=3555.3, bsz=101.4, num_updates=48000, lr=0.000144338, gnorm=1.041, train_wall=19, wall=0
2024-07-07 21:21:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 21:21:33 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.02 | nll_loss 4.762 | ppl 27.13 | wps 53539.9 | wpb 2588.8 | bsz 75.3 | num_updates 48000 | best_loss 12.211
2024-07-07 21:21:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 21:21:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_48000.pt (epoch 1 @ 48000 updates, score 6.02) (writing took 3.973252670839429 seconds)
2024-07-07 21:21:57 | INFO | train_inner | epoch 001:  48100 / 150053 loss=5.407, nll_loss=4.141, ppl=17.64, wps=13677.2, ups=3.93, wpb=3477.2, bsz=109.5, num_updates=48100, lr=0.000144187, gnorm=1.1, train_wall=19, wall=0
2024-07-07 21:22:16 | INFO | train_inner | epoch 001:  48200 / 150053 loss=5.304, nll_loss=4.024, ppl=16.27, wps=18365, ups=5.16, wpb=3561, bsz=104.6, num_updates=48200, lr=0.000144038, gnorm=1.037, train_wall=19, wall=0
2024-07-07 21:22:36 | INFO | train_inner | epoch 001:  48300 / 150053 loss=5.329, nll_loss=4.052, ppl=16.58, wps=18282.1, ups=5.12, wpb=3570.9, bsz=110.5, num_updates=48300, lr=0.000143889, gnorm=1.064, train_wall=19, wall=0
2024-07-07 21:22:55 | INFO | train_inner | epoch 001:  48400 / 150053 loss=5.39, nll_loss=4.122, ppl=17.41, wps=18160.1, ups=5.18, wpb=3503.7, bsz=105.8, num_updates=48400, lr=0.00014374, gnorm=1.057, train_wall=19, wall=0
2024-07-07 21:23:14 | INFO | train_inner | epoch 001:  48500 / 150053 loss=5.424, nll_loss=4.16, ppl=17.87, wps=18417.4, ups=5.13, wpb=3588.4, bsz=97, num_updates=48500, lr=0.000143592, gnorm=1.053, train_wall=19, wall=0
2024-07-07 21:23:34 | INFO | train_inner | epoch 001:  48600 / 150053 loss=5.347, nll_loss=4.072, ppl=16.82, wps=18383.9, ups=5.14, wpb=3579.6, bsz=103.6, num_updates=48600, lr=0.000143444, gnorm=1.021, train_wall=19, wall=0
2024-07-07 21:23:53 | INFO | train_inner | epoch 001:  48700 / 150053 loss=5.385, nll_loss=4.115, ppl=17.33, wps=18618.4, ups=5.17, wpb=3598.1, bsz=105.3, num_updates=48700, lr=0.000143296, gnorm=1.056, train_wall=19, wall=0
2024-07-07 21:24:13 | INFO | train_inner | epoch 001:  48800 / 150053 loss=5.334, nll_loss=4.057, ppl=16.65, wps=18200.7, ups=5.17, wpb=3523.7, bsz=123.5, num_updates=48800, lr=0.00014315, gnorm=1.122, train_wall=19, wall=0
2024-07-07 21:24:32 | INFO | train_inner | epoch 001:  48900 / 150053 loss=5.391, nll_loss=4.122, ppl=17.41, wps=18372.9, ups=5.15, wpb=3565.8, bsz=98.7, num_updates=48900, lr=0.000143003, gnorm=1.041, train_wall=19, wall=0
2024-07-07 21:24:51 | INFO | train_inner | epoch 001:  49000 / 150053 loss=5.322, nll_loss=4.043, ppl=16.49, wps=18337.1, ups=5.12, wpb=3582.6, bsz=115.5, num_updates=49000, lr=0.000142857, gnorm=1.043, train_wall=19, wall=0
2024-07-07 21:24:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 21:24:54 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.956 | nll_loss 4.7 | ppl 25.99 | wps 53633.7 | wpb 2588.8 | bsz 75.3 | num_updates 49000 | best_loss 12.211
2024-07-07 21:24:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 21:24:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_49000.pt (epoch 1 @ 49000 updates, score 5.956) (writing took 3.45489589497447 seconds)
2024-07-07 21:25:16 | INFO | train_inner | epoch 001:  49100 / 150053 loss=5.347, nll_loss=4.072, ppl=16.81, wps=14377.9, ups=4, wpb=3591.9, bsz=97, num_updates=49100, lr=0.000142712, gnorm=1.039, train_wall=19, wall=0
2024-07-07 21:25:36 | INFO | train_inner | epoch 001:  49200 / 150053 loss=5.404, nll_loss=4.137, ppl=17.6, wps=18587.8, ups=5.19, wpb=3582.1, bsz=99, num_updates=49200, lr=0.000142566, gnorm=1.054, train_wall=19, wall=0
2024-07-07 21:25:55 | INFO | train_inner | epoch 001:  49300 / 150053 loss=5.318, nll_loss=4.039, ppl=16.43, wps=18534.9, ups=5.14, wpb=3607.8, bsz=108.5, num_updates=49300, lr=0.000142422, gnorm=1.085, train_wall=19, wall=0
2024-07-07 21:26:15 | INFO | train_inner | epoch 001:  49400 / 150053 loss=5.32, nll_loss=4.042, ppl=16.47, wps=18321.5, ups=5.13, wpb=3568.1, bsz=103.4, num_updates=49400, lr=0.000142278, gnorm=1.037, train_wall=19, wall=0
2024-07-07 21:26:34 | INFO | train_inner | epoch 001:  49500 / 150053 loss=5.35, nll_loss=4.075, ppl=16.86, wps=18249.1, ups=5.18, wpb=3524.2, bsz=108, num_updates=49500, lr=0.000142134, gnorm=1.078, train_wall=19, wall=0
2024-07-07 21:26:53 | INFO | train_inner | epoch 001:  49600 / 150053 loss=5.316, nll_loss=4.036, ppl=16.4, wps=18557.2, ups=5.16, wpb=3598.9, bsz=115, num_updates=49600, lr=0.00014199, gnorm=1.076, train_wall=19, wall=0
2024-07-07 21:27:13 | INFO | train_inner | epoch 001:  49700 / 150053 loss=5.347, nll_loss=4.072, ppl=16.81, wps=18318.8, ups=5.17, wpb=3544, bsz=102.3, num_updates=49700, lr=0.000141848, gnorm=1.054, train_wall=19, wall=0
2024-07-07 21:27:32 | INFO | train_inner | epoch 001:  49800 / 150053 loss=5.378, nll_loss=4.108, ppl=17.24, wps=18311.7, ups=5.15, wpb=3556.2, bsz=99, num_updates=49800, lr=0.000141705, gnorm=1.069, train_wall=19, wall=0
2024-07-07 21:27:51 | INFO | train_inner | epoch 001:  49900 / 150053 loss=5.378, nll_loss=4.108, ppl=17.24, wps=18321.4, ups=5.23, wpb=3502.3, bsz=85, num_updates=49900, lr=0.000141563, gnorm=1.059, train_wall=19, wall=0
2024-07-07 21:28:11 | INFO | train_inner | epoch 001:  50000 / 150053 loss=5.356, nll_loss=4.082, ppl=16.93, wps=18374.7, ups=5.14, wpb=3573.8, bsz=104.6, num_updates=50000, lr=0.000141421, gnorm=1.13, train_wall=19, wall=0
2024-07-07 21:28:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 21:28:13 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.887 | nll_loss 4.619 | ppl 24.56 | wps 53886.5 | wpb 2588.8 | bsz 75.3 | num_updates 50000 | best_loss 12.211
2024-07-07 21:28:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 21:28:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_50000.pt (epoch 1 @ 50000 updates, score 5.887) (writing took 4.338746106252074 seconds)
2024-07-07 21:28:37 | INFO | train_inner | epoch 001:  50100 / 150053 loss=5.319, nll_loss=4.04, ppl=16.45, wps=13764.7, ups=3.84, wpb=3582.7, bsz=106.8, num_updates=50100, lr=0.00014128, gnorm=1.073, train_wall=19, wall=0
2024-07-07 21:28:56 | INFO | train_inner | epoch 001:  50200 / 150053 loss=5.309, nll_loss=4.029, ppl=16.32, wps=18445.3, ups=5.15, wpb=3582.5, bsz=105.1, num_updates=50200, lr=0.000141139, gnorm=1.087, train_wall=19, wall=0
2024-07-07 21:29:16 | INFO | train_inner | epoch 001:  50300 / 150053 loss=5.312, nll_loss=4.031, ppl=16.35, wps=18289.1, ups=5.1, wpb=3582.8, bsz=103.6, num_updates=50300, lr=0.000140999, gnorm=1.1, train_wall=19, wall=0
2024-07-07 21:29:35 | INFO | train_inner | epoch 001:  50400 / 150053 loss=5.3, nll_loss=4.019, ppl=16.22, wps=18340.5, ups=5.16, wpb=3552.7, bsz=108.2, num_updates=50400, lr=0.000140859, gnorm=1.097, train_wall=19, wall=0
2024-07-07 21:29:55 | INFO | train_inner | epoch 001:  50500 / 150053 loss=5.232, nll_loss=3.94, ppl=15.35, wps=18429.6, ups=5.11, wpb=3606.8, bsz=118.7, num_updates=50500, lr=0.00014072, gnorm=1.101, train_wall=19, wall=0
2024-07-07 21:30:14 | INFO | train_inner | epoch 001:  50600 / 150053 loss=5.302, nll_loss=4.02, ppl=16.23, wps=18275.7, ups=5.13, wpb=3561.9, bsz=102.9, num_updates=50600, lr=0.00014058, gnorm=1.058, train_wall=19, wall=0
2024-07-07 21:30:34 | INFO | train_inner | epoch 001:  50700 / 150053 loss=5.267, nll_loss=3.981, ppl=15.79, wps=18427.1, ups=5.13, wpb=3590.2, bsz=103.4, num_updates=50700, lr=0.000140442, gnorm=1.06, train_wall=19, wall=0
2024-07-07 21:30:53 | INFO | train_inner | epoch 001:  50800 / 150053 loss=5.337, nll_loss=4.06, ppl=16.68, wps=18391.8, ups=5.17, wpb=3560.2, bsz=105.9, num_updates=50800, lr=0.000140303, gnorm=1.132, train_wall=19, wall=0
2024-07-07 21:31:12 | INFO | train_inner | epoch 001:  50900 / 150053 loss=5.311, nll_loss=4.031, ppl=16.34, wps=18089, ups=5.16, wpb=3508.8, bsz=98.9, num_updates=50900, lr=0.000140165, gnorm=1.133, train_wall=19, wall=0
2024-07-07 21:31:32 | INFO | train_inner | epoch 001:  51000 / 150053 loss=5.25, nll_loss=3.961, ppl=15.57, wps=18293.1, ups=5.12, wpb=3569.9, bsz=110.2, num_updates=51000, lr=0.000140028, gnorm=1.086, train_wall=19, wall=0
2024-07-07 21:31:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 21:31:34 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.647 | nll_loss 4.35 | ppl 20.39 | wps 53053.6 | wpb 2588.8 | bsz 75.3 | num_updates 51000 | best_loss 12.211
2024-07-07 21:31:34 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 21:31:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_51000.pt (epoch 1 @ 51000 updates, score 5.647) (writing took 3.7915252279490232 seconds)
2024-07-07 21:31:58 | INFO | train_inner | epoch 001:  51100 / 150053 loss=5.333, nll_loss=4.057, ppl=16.64, wps=13909.7, ups=3.9, wpb=3564.3, bsz=117.1, num_updates=51100, lr=0.000139891, gnorm=1.166, train_wall=19, wall=0
2024-07-07 21:32:17 | INFO | train_inner | epoch 001:  51200 / 150053 loss=5.328, nll_loss=4.05, ppl=16.57, wps=18210.2, ups=5.16, wpb=3532.4, bsz=94.3, num_updates=51200, lr=0.000139754, gnorm=1.089, train_wall=19, wall=0
2024-07-07 21:32:36 | INFO | train_inner | epoch 001:  51300 / 150053 loss=5.296, nll_loss=4.013, ppl=16.15, wps=18284.5, ups=5.15, wpb=3549.8, bsz=102.4, num_updates=51300, lr=0.000139618, gnorm=1.101, train_wall=19, wall=0
2024-07-07 21:32:56 | INFO | train_inner | epoch 001:  51400 / 150053 loss=5.322, nll_loss=4.044, ppl=16.49, wps=18271.3, ups=5.15, wpb=3550.2, bsz=97.4, num_updates=51400, lr=0.000139482, gnorm=1.13, train_wall=19, wall=0
2024-07-07 21:33:15 | INFO | train_inner | epoch 001:  51500 / 150053 loss=5.287, nll_loss=4.004, ppl=16.04, wps=18726.4, ups=5.17, wpb=3624.5, bsz=99.7, num_updates=51500, lr=0.000139347, gnorm=1.08, train_wall=19, wall=0
2024-07-07 21:33:34 | INFO | train_inner | epoch 001:  51600 / 150053 loss=5.26, nll_loss=3.972, ppl=15.69, wps=18114.7, ups=5.17, wpb=3504.4, bsz=131.4, num_updates=51600, lr=0.000139212, gnorm=1.246, train_wall=19, wall=0
2024-07-07 21:33:54 | INFO | train_inner | epoch 001:  51700 / 150053 loss=5.271, nll_loss=3.986, ppl=15.85, wps=18230.6, ups=5.15, wpb=3536.8, bsz=111.5, num_updates=51700, lr=0.000139077, gnorm=1.132, train_wall=19, wall=0
2024-07-07 21:34:13 | INFO | train_inner | epoch 001:  51800 / 150053 loss=5.267, nll_loss=3.981, ppl=15.79, wps=18187.9, ups=5.18, wpb=3510.8, bsz=95.8, num_updates=51800, lr=0.000138943, gnorm=1.072, train_wall=19, wall=0
2024-07-07 21:34:33 | INFO | train_inner | epoch 001:  51900 / 150053 loss=5.294, nll_loss=4.012, ppl=16.13, wps=17954.9, ups=5.15, wpb=3486.5, bsz=95.7, num_updates=51900, lr=0.000138809, gnorm=1.142, train_wall=19, wall=0
2024-07-07 21:34:52 | INFO | train_inner | epoch 001:  52000 / 150053 loss=5.246, nll_loss=3.958, ppl=15.54, wps=18362.2, ups=5.11, wpb=3596.6, bsz=104.9, num_updates=52000, lr=0.000138675, gnorm=1.095, train_wall=19, wall=0
2024-07-07 21:34:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 21:34:54 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.565 | nll_loss 4.236 | ppl 18.84 | wps 53638.1 | wpb 2588.8 | bsz 75.3 | num_updates 52000 | best_loss 12.211
2024-07-07 21:34:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 21:35:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_52000.pt (epoch 1 @ 52000 updates, score 5.565) (writing took 17.218515397049487 seconds)
2024-07-07 21:35:31 | INFO | train_inner | epoch 001:  52100 / 150053 loss=5.236, nll_loss=3.946, ppl=15.41, wps=9052.9, ups=2.57, wpb=3518.1, bsz=101.9, num_updates=52100, lr=0.000138542, gnorm=1.102, train_wall=19, wall=0
2024-07-07 21:35:50 | INFO | train_inner | epoch 001:  52200 / 150053 loss=5.242, nll_loss=3.951, ppl=15.47, wps=18509.7, ups=5.16, wpb=3588.2, bsz=101, num_updates=52200, lr=0.000138409, gnorm=1.088, train_wall=19, wall=0
2024-07-07 21:36:10 | INFO | train_inner | epoch 001:  52300 / 150053 loss=5.246, nll_loss=3.958, ppl=15.54, wps=18362.1, ups=5.16, wpb=3558.6, bsz=104, num_updates=52300, lr=0.000138277, gnorm=1.125, train_wall=19, wall=0
2024-07-07 21:36:29 | INFO | train_inner | epoch 001:  52400 / 150053 loss=5.256, nll_loss=3.968, ppl=15.65, wps=17932.4, ups=5.18, wpb=3459.2, bsz=111.1, num_updates=52400, lr=0.000138145, gnorm=1.221, train_wall=19, wall=0
2024-07-07 21:36:48 | INFO | train_inner | epoch 001:  52500 / 150053 loss=5.221, nll_loss=3.928, ppl=15.22, wps=18138.4, ups=5.17, wpb=3506.9, bsz=106.1, num_updates=52500, lr=0.000138013, gnorm=1.126, train_wall=19, wall=0
2024-07-07 21:37:08 | INFO | train_inner | epoch 001:  52600 / 150053 loss=5.235, nll_loss=3.945, ppl=15.4, wps=18336.4, ups=5.14, wpb=3568.5, bsz=114.3, num_updates=52600, lr=0.000137882, gnorm=1.143, train_wall=19, wall=0
2024-07-07 21:37:27 | INFO | train_inner | epoch 001:  52700 / 150053 loss=5.177, nll_loss=3.878, ppl=14.7, wps=18497.1, ups=5.11, wpb=3618.8, bsz=127, num_updates=52700, lr=0.000137751, gnorm=1.13, train_wall=19, wall=0
2024-07-07 21:37:47 | INFO | train_inner | epoch 001:  52800 / 150053 loss=5.293, nll_loss=4.011, ppl=16.12, wps=18471.2, ups=5.18, wpb=3567.9, bsz=107.6, num_updates=52800, lr=0.00013762, gnorm=1.145, train_wall=19, wall=0
2024-07-07 21:38:06 | INFO | train_inner | epoch 001:  52900 / 150053 loss=5.183, nll_loss=3.885, ppl=14.78, wps=18228.9, ups=5.13, wpb=3550.4, bsz=113.4, num_updates=52900, lr=0.00013749, gnorm=1.122, train_wall=19, wall=0
2024-07-07 21:38:26 | INFO | train_inner | epoch 001:  53000 / 150053 loss=5.226, nll_loss=3.934, ppl=15.28, wps=18322.5, ups=5.14, wpb=3562.1, bsz=100.6, num_updates=53000, lr=0.000137361, gnorm=1.157, train_wall=19, wall=0
2024-07-07 21:38:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 21:38:28 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.483 | nll_loss 4.139 | ppl 17.62 | wps 53571 | wpb 2588.8 | bsz 75.3 | num_updates 53000 | best_loss 12.211
2024-07-07 21:38:28 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 21:38:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_53000.pt (epoch 1 @ 53000 updates, score 5.483) (writing took 8.760782075114548 seconds)
2024-07-07 21:38:57 | INFO | train_inner | epoch 001:  53100 / 150053 loss=5.181, nll_loss=3.883, ppl=14.75, wps=11744.6, ups=3.23, wpb=3639.6, bsz=124.6, num_updates=53100, lr=0.000137231, gnorm=1.16, train_wall=19, wall=0
2024-07-07 21:39:16 | INFO | train_inner | epoch 001:  53200 / 150053 loss=5.213, nll_loss=3.919, ppl=15.13, wps=18228.6, ups=5.13, wpb=3555.1, bsz=99.3, num_updates=53200, lr=0.000137102, gnorm=1.115, train_wall=19, wall=0
2024-07-07 21:39:36 | INFO | train_inner | epoch 001:  53300 / 150053 loss=5.304, nll_loss=4.023, ppl=16.26, wps=18282.5, ups=5.15, wpb=3547.3, bsz=106.7, num_updates=53300, lr=0.000136973, gnorm=1.252, train_wall=19, wall=0
2024-07-07 21:40:13 | INFO | train_inner | epoch 001:  53400 / 150053 loss=5.205, nll_loss=3.911, ppl=15.04, wps=9656.5, ups=2.68, wpb=3602.6, bsz=109.7, num_updates=53400, lr=0.000136845, gnorm=1.127, train_wall=37, wall=0
2024-07-07 21:40:32 | INFO | train_inner | epoch 001:  53500 / 150053 loss=5.225, nll_loss=3.934, ppl=15.28, wps=18227.8, ups=5.15, wpb=3539.2, bsz=103.8, num_updates=53500, lr=0.000136717, gnorm=1.16, train_wall=19, wall=0
2024-07-07 21:40:52 | INFO | train_inner | epoch 001:  53600 / 150053 loss=5.216, nll_loss=3.922, ppl=15.16, wps=18268.2, ups=5.14, wpb=3553.6, bsz=103.8, num_updates=53600, lr=0.00013659, gnorm=1.142, train_wall=19, wall=0
2024-07-07 21:41:11 | INFO | train_inner | epoch 001:  53700 / 150053 loss=5.231, nll_loss=3.94, ppl=15.35, wps=18323.3, ups=5.14, wpb=3566.9, bsz=106.9, num_updates=53700, lr=0.000136462, gnorm=1.126, train_wall=19, wall=0
2024-07-07 21:41:31 | INFO | train_inner | epoch 001:  53800 / 150053 loss=5.182, nll_loss=3.884, ppl=14.76, wps=18308.4, ups=5.1, wpb=3590.6, bsz=106.2, num_updates=53800, lr=0.000136335, gnorm=1.173, train_wall=19, wall=0
2024-07-07 21:41:50 | INFO | train_inner | epoch 001:  53900 / 150053 loss=5.162, nll_loss=3.862, ppl=14.54, wps=18475, ups=5.13, wpb=3601.1, bsz=109.8, num_updates=53900, lr=0.000136209, gnorm=1.116, train_wall=19, wall=0
2024-07-07 21:42:10 | INFO | train_inner | epoch 001:  54000 / 150053 loss=5.144, nll_loss=3.841, ppl=14.33, wps=18419.6, ups=5.15, wpb=3577.7, bsz=108.6, num_updates=54000, lr=0.000136083, gnorm=1.125, train_wall=19, wall=0
2024-07-07 21:42:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 21:42:12 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.419 | nll_loss 4.059 | ppl 16.67 | wps 53811 | wpb 2588.8 | bsz 75.3 | num_updates 54000 | best_loss 12.211
2024-07-07 21:42:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 21:42:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_54000.pt (epoch 1 @ 54000 updates, score 5.419) (writing took 3.348565474152565 seconds)
2024-07-07 21:42:35 | INFO | train_inner | epoch 001:  54100 / 150053 loss=5.173, nll_loss=3.875, ppl=14.67, wps=14056.4, ups=4, wpb=3511.9, bsz=108.6, num_updates=54100, lr=0.000135957, gnorm=1.143, train_wall=19, wall=0
2024-07-07 21:42:54 | INFO | train_inner | epoch 001:  54200 / 150053 loss=5.207, nll_loss=3.912, ppl=15.06, wps=18404.6, ups=5.18, wpb=3549.7, bsz=106.8, num_updates=54200, lr=0.000135831, gnorm=1.219, train_wall=19, wall=0
2024-07-07 21:43:14 | INFO | train_inner | epoch 001:  54300 / 150053 loss=5.183, nll_loss=3.886, ppl=14.78, wps=18423.3, ups=5.15, wpb=3580.4, bsz=125.6, num_updates=54300, lr=0.000135706, gnorm=1.197, train_wall=19, wall=0
2024-07-07 21:43:33 | INFO | train_inner | epoch 001:  54400 / 150053 loss=5.178, nll_loss=3.88, ppl=14.72, wps=18344.9, ups=5.14, wpb=3568, bsz=101.4, num_updates=54400, lr=0.000135582, gnorm=1.151, train_wall=19, wall=0
2024-07-07 21:43:52 | INFO | train_inner | epoch 001:  54500 / 150053 loss=5.169, nll_loss=3.87, ppl=14.62, wps=18332.5, ups=5.15, wpb=3560.5, bsz=107.7, num_updates=54500, lr=0.000135457, gnorm=1.143, train_wall=19, wall=0
2024-07-07 21:44:12 | INFO | train_inner | epoch 001:  54600 / 150053 loss=5.199, nll_loss=3.903, ppl=14.96, wps=18517.2, ups=5.16, wpb=3591, bsz=96.4, num_updates=54600, lr=0.000135333, gnorm=1.13, train_wall=19, wall=0
2024-07-07 21:44:31 | INFO | train_inner | epoch 001:  54700 / 150053 loss=5.217, nll_loss=3.924, ppl=15.18, wps=18277.2, ups=5.21, wpb=3508.8, bsz=100.2, num_updates=54700, lr=0.000135209, gnorm=1.188, train_wall=19, wall=0
2024-07-07 21:44:50 | INFO | train_inner | epoch 001:  54800 / 150053 loss=5.124, nll_loss=3.819, ppl=14.12, wps=18068.9, ups=5.25, wpb=3438.8, bsz=103.1, num_updates=54800, lr=0.000135086, gnorm=1.161, train_wall=19, wall=0
2024-07-07 21:45:09 | INFO | train_inner | epoch 001:  54900 / 150053 loss=5.18, nll_loss=3.882, ppl=14.75, wps=18467.9, ups=5.18, wpb=3563.2, bsz=107.1, num_updates=54900, lr=0.000134963, gnorm=1.158, train_wall=19, wall=0
2024-07-07 21:45:29 | INFO | train_inner | epoch 001:  55000 / 150053 loss=5.179, nll_loss=3.881, ppl=14.73, wps=18045.2, ups=5.19, wpb=3476.7, bsz=95.1, num_updates=55000, lr=0.00013484, gnorm=1.118, train_wall=19, wall=0
2024-07-07 21:45:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 21:45:31 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.342 | nll_loss 3.975 | ppl 15.72 | wps 53751.6 | wpb 2588.8 | bsz 75.3 | num_updates 55000 | best_loss 12.211
2024-07-07 21:45:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 21:45:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_55000.pt (epoch 1 @ 55000 updates, score 5.342) (writing took 4.807841938920319 seconds)
2024-07-07 21:45:55 | INFO | train_inner | epoch 001:  55100 / 150053 loss=5.151, nll_loss=3.849, ppl=14.41, wps=13557.7, ups=3.79, wpb=3580.8, bsz=109.8, num_updates=55100, lr=0.000134718, gnorm=1.198, train_wall=19, wall=0
2024-07-07 21:46:14 | INFO | train_inner | epoch 001:  55200 / 150053 loss=5.182, nll_loss=3.884, ppl=14.77, wps=18468.7, ups=5.19, wpb=3556.5, bsz=105.9, num_updates=55200, lr=0.000134595, gnorm=1.142, train_wall=19, wall=0
2024-07-07 21:46:34 | INFO | train_inner | epoch 001:  55300 / 150053 loss=5.174, nll_loss=3.876, ppl=14.68, wps=18485.3, ups=5.16, wpb=3585.6, bsz=99.9, num_updates=55300, lr=0.000134474, gnorm=1.134, train_wall=19, wall=0
2024-07-07 21:46:53 | INFO | train_inner | epoch 001:  55400 / 150053 loss=5.165, nll_loss=3.865, ppl=14.57, wps=18269.9, ups=5.19, wpb=3520.3, bsz=98.3, num_updates=55400, lr=0.000134352, gnorm=1.131, train_wall=19, wall=0
2024-07-07 21:47:12 | INFO | train_inner | epoch 001:  55500 / 150053 loss=5.147, nll_loss=3.844, ppl=14.36, wps=18312.6, ups=5.21, wpb=3511.7, bsz=100.5, num_updates=55500, lr=0.000134231, gnorm=1.205, train_wall=19, wall=0
2024-07-07 21:47:31 | INFO | train_inner | epoch 001:  55600 / 150053 loss=5.125, nll_loss=3.819, ppl=14.11, wps=18093.4, ups=5.16, wpb=3509.7, bsz=104.7, num_updates=55600, lr=0.00013411, gnorm=1.113, train_wall=19, wall=0
2024-07-07 21:47:51 | INFO | train_inner | epoch 001:  55700 / 150053 loss=5.212, nll_loss=3.918, ppl=15.12, wps=18548.4, ups=5.16, wpb=3593.2, bsz=104, num_updates=55700, lr=0.00013399, gnorm=1.212, train_wall=19, wall=0
2024-07-07 21:48:10 | INFO | train_inner | epoch 001:  55800 / 150053 loss=5.086, nll_loss=3.775, ppl=13.69, wps=18678.2, ups=5.1, wpb=3664.2, bsz=109.3, num_updates=55800, lr=0.00013387, gnorm=1.113, train_wall=19, wall=0
2024-07-07 21:48:30 | INFO | train_inner | epoch 001:  55900 / 150053 loss=5.15, nll_loss=3.848, ppl=14.4, wps=18485, ups=5.16, wpb=3581.4, bsz=111.8, num_updates=55900, lr=0.00013375, gnorm=1.183, train_wall=19, wall=0
2024-07-07 21:48:49 | INFO | train_inner | epoch 001:  56000 / 150053 loss=5.126, nll_loss=3.821, ppl=14.13, wps=18229.8, ups=5.16, wpb=3530.2, bsz=105.6, num_updates=56000, lr=0.000133631, gnorm=1.147, train_wall=19, wall=0
2024-07-07 21:48:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 21:48:51 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.304 | nll_loss 3.917 | ppl 15.11 | wps 53173.2 | wpb 2588.8 | bsz 75.3 | num_updates 56000 | best_loss 12.211
2024-07-07 21:48:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 21:48:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_56000.pt (epoch 1 @ 56000 updates, score 5.304) (writing took 3.342515324242413 seconds)
2024-07-07 21:49:14 | INFO | train_inner | epoch 001:  56100 / 150053 loss=5.146, nll_loss=3.844, ppl=14.36, wps=14160.7, ups=4.02, wpb=3518.5, bsz=90.7, num_updates=56100, lr=0.000133511, gnorm=1.132, train_wall=19, wall=0
2024-07-07 21:49:33 | INFO | train_inner | epoch 001:  56200 / 150053 loss=5.159, nll_loss=3.858, ppl=14.5, wps=18556.5, ups=5.2, wpb=3571.5, bsz=107.6, num_updates=56200, lr=0.000133393, gnorm=1.176, train_wall=19, wall=0
2024-07-07 21:49:53 | INFO | train_inner | epoch 001:  56300 / 150053 loss=5.129, nll_loss=3.823, ppl=14.16, wps=18404.3, ups=5.14, wpb=3577.6, bsz=122.3, num_updates=56300, lr=0.000133274, gnorm=1.257, train_wall=19, wall=0
2024-07-07 21:50:12 | INFO | train_inner | epoch 001:  56400 / 150053 loss=5.156, nll_loss=3.855, ppl=14.47, wps=18269.3, ups=5.13, wpb=3562.3, bsz=97, num_updates=56400, lr=0.000133156, gnorm=1.161, train_wall=19, wall=0
2024-07-07 21:50:32 | INFO | train_inner | epoch 001:  56500 / 150053 loss=5.104, nll_loss=3.795, ppl=13.88, wps=18344.3, ups=5.13, wpb=3573.5, bsz=106.8, num_updates=56500, lr=0.000133038, gnorm=1.182, train_wall=19, wall=0
2024-07-07 21:50:51 | INFO | train_inner | epoch 001:  56600 / 150053 loss=5.239, nll_loss=3.95, ppl=15.45, wps=18079.4, ups=5.22, wpb=3462.2, bsz=85.1, num_updates=56600, lr=0.00013292, gnorm=1.164, train_wall=19, wall=0
2024-07-07 21:51:10 | INFO | train_inner | epoch 001:  56700 / 150053 loss=5.133, nll_loss=3.829, ppl=14.21, wps=18504.1, ups=5.15, wpb=3595.6, bsz=104.8, num_updates=56700, lr=0.000132803, gnorm=1.165, train_wall=19, wall=0
2024-07-07 21:51:30 | INFO | train_inner | epoch 001:  56800 / 150053 loss=5.137, nll_loss=3.833, ppl=14.25, wps=18283.6, ups=5.21, wpb=3512.6, bsz=96.9, num_updates=56800, lr=0.000132686, gnorm=1.18, train_wall=19, wall=0
2024-07-07 21:51:49 | INFO | train_inner | epoch 001:  56900 / 150053 loss=5.177, nll_loss=3.878, ppl=14.7, wps=18351.9, ups=5.18, wpb=3542.7, bsz=98.2, num_updates=56900, lr=0.00013257, gnorm=1.166, train_wall=19, wall=0
2024-07-07 21:52:08 | INFO | train_inner | epoch 001:  57000 / 150053 loss=5.032, nll_loss=3.713, ppl=13.12, wps=18090.7, ups=5.16, wpb=3506.5, bsz=122.6, num_updates=57000, lr=0.000132453, gnorm=1.213, train_wall=19, wall=0
2024-07-07 21:52:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 21:52:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.247 | nll_loss 3.85 | ppl 14.42 | wps 53595.8 | wpb 2588.8 | bsz 75.3 | num_updates 57000 | best_loss 12.211
2024-07-07 21:52:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 21:52:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_57000.pt (epoch 1 @ 57000 updates, score 5.247) (writing took 3.4718727143481374 seconds)
2024-07-07 21:52:33 | INFO | train_inner | epoch 001:  57100 / 150053 loss=5.177, nll_loss=3.879, ppl=14.71, wps=14203.9, ups=4.03, wpb=3521.5, bsz=99.8, num_updates=57100, lr=0.000132337, gnorm=1.213, train_wall=19, wall=0
2024-07-07 21:52:53 | INFO | train_inner | epoch 001:  57200 / 150053 loss=5.101, nll_loss=3.791, ppl=13.84, wps=18595, ups=5.12, wpb=3630.4, bsz=104.7, num_updates=57200, lr=0.000132221, gnorm=1.167, train_wall=19, wall=0
2024-07-07 21:53:12 | INFO | train_inner | epoch 001:  57300 / 150053 loss=5.142, nll_loss=3.838, ppl=14.3, wps=18312.2, ups=5.17, wpb=3539, bsz=100.6, num_updates=57300, lr=0.000132106, gnorm=1.21, train_wall=19, wall=0
2024-07-07 21:53:31 | INFO | train_inner | epoch 001:  57400 / 150053 loss=5.136, nll_loss=3.833, ppl=14.25, wps=18653, ups=5.19, wpb=3592.1, bsz=99.4, num_updates=57400, lr=0.000131991, gnorm=1.178, train_wall=19, wall=0
2024-07-07 21:53:50 | INFO | train_inner | epoch 001:  57500 / 150053 loss=5.099, nll_loss=3.79, ppl=13.83, wps=18487, ups=5.16, wpb=3580.2, bsz=101.4, num_updates=57500, lr=0.000131876, gnorm=1.177, train_wall=19, wall=0
2024-07-07 21:54:10 | INFO | train_inner | epoch 001:  57600 / 150053 loss=5.114, nll_loss=3.808, ppl=14, wps=18550.4, ups=5.19, wpb=3577.4, bsz=114.2, num_updates=57600, lr=0.000131762, gnorm=1.173, train_wall=19, wall=0
2024-07-07 21:54:29 | INFO | train_inner | epoch 001:  57700 / 150053 loss=5.065, nll_loss=3.751, ppl=13.46, wps=18351.8, ups=5.16, wpb=3557.8, bsz=112.6, num_updates=57700, lr=0.000131647, gnorm=1.211, train_wall=19, wall=0
2024-07-07 21:54:48 | INFO | train_inner | epoch 001:  57800 / 150053 loss=5.185, nll_loss=3.888, ppl=14.8, wps=18133.8, ups=5.18, wpb=3503.3, bsz=107.6, num_updates=57800, lr=0.000131533, gnorm=1.249, train_wall=19, wall=0
2024-07-07 21:55:08 | INFO | train_inner | epoch 001:  57900 / 150053 loss=5.129, nll_loss=3.824, ppl=14.16, wps=18221.6, ups=5.15, wpb=3535.1, bsz=109.8, num_updates=57900, lr=0.00013142, gnorm=1.204, train_wall=19, wall=0
2024-07-07 21:55:28 | INFO | train_inner | epoch 001:  58000 / 150053 loss=5.074, nll_loss=3.761, ppl=13.56, wps=18275, ups=5.09, wpb=3593.6, bsz=100.4, num_updates=58000, lr=0.000131306, gnorm=1.152, train_wall=19, wall=0
2024-07-07 21:55:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 21:55:30 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.236 | nll_loss 3.835 | ppl 14.27 | wps 53631.2 | wpb 2588.8 | bsz 75.3 | num_updates 58000 | best_loss 12.211
2024-07-07 21:55:30 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 21:55:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_58000.pt (epoch 1 @ 58000 updates, score 5.236) (writing took 3.520094409584999 seconds)
2024-07-07 21:55:53 | INFO | train_inner | epoch 001:  58100 / 150053 loss=5.114, nll_loss=3.807, ppl=14, wps=14183.7, ups=4, wpb=3543.9, bsz=107.2, num_updates=58100, lr=0.000131193, gnorm=1.234, train_wall=19, wall=0
2024-07-07 21:56:12 | INFO | train_inner | epoch 001:  58200 / 150053 loss=5.12, nll_loss=3.813, ppl=14.06, wps=18234.7, ups=5.15, wpb=3544, bsz=102.3, num_updates=58200, lr=0.000131081, gnorm=1.227, train_wall=19, wall=0
2024-07-07 21:56:31 | INFO | train_inner | epoch 001:  58300 / 150053 loss=5.104, nll_loss=3.796, ppl=13.89, wps=18387.5, ups=5.16, wpb=3566.6, bsz=103.5, num_updates=58300, lr=0.000130968, gnorm=1.169, train_wall=19, wall=0
2024-07-07 21:56:51 | INFO | train_inner | epoch 001:  58400 / 150053 loss=5.03, nll_loss=3.711, ppl=13.1, wps=17989.1, ups=5.16, wpb=3483.1, bsz=105.8, num_updates=58400, lr=0.000130856, gnorm=1.182, train_wall=19, wall=0
2024-07-07 21:57:10 | INFO | train_inner | epoch 001:  58500 / 150053 loss=5.135, nll_loss=3.832, ppl=14.24, wps=18307.3, ups=5.25, wpb=3487.1, bsz=102.6, num_updates=58500, lr=0.000130744, gnorm=1.255, train_wall=19, wall=0
2024-07-07 21:57:29 | INFO | train_inner | epoch 001:  58600 / 150053 loss=5.129, nll_loss=3.823, ppl=14.16, wps=18300.3, ups=5.22, wpb=3503, bsz=92.1, num_updates=58600, lr=0.000130632, gnorm=1.199, train_wall=19, wall=0
2024-07-07 21:57:48 | INFO | train_inner | epoch 001:  58700 / 150053 loss=5.131, nll_loss=3.827, ppl=14.19, wps=18513.7, ups=5.16, wpb=3587.8, bsz=94.4, num_updates=58700, lr=0.000130521, gnorm=1.168, train_wall=19, wall=0
2024-07-07 21:58:08 | INFO | train_inner | epoch 001:  58800 / 150053 loss=5.153, nll_loss=3.851, ppl=14.43, wps=17668.8, ups=5.19, wpb=3402.2, bsz=107.1, num_updates=58800, lr=0.00013041, gnorm=1.283, train_wall=19, wall=0
2024-07-07 21:58:27 | INFO | train_inner | epoch 001:  58900 / 150053 loss=4.994, nll_loss=3.671, ppl=12.74, wps=18215.7, ups=5.11, wpb=3565, bsz=121.9, num_updates=58900, lr=0.000130299, gnorm=1.213, train_wall=19, wall=0
2024-07-07 21:58:47 | INFO | train_inner | epoch 001:  59000 / 150053 loss=5.11, nll_loss=3.802, ppl=13.95, wps=18305.9, ups=5.14, wpb=3564.5, bsz=95, num_updates=59000, lr=0.000130189, gnorm=1.209, train_wall=19, wall=0
2024-07-07 21:58:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 21:58:49 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.2 | nll_loss 3.784 | ppl 13.77 | wps 53472.4 | wpb 2588.8 | bsz 75.3 | num_updates 59000 | best_loss 12.211
2024-07-07 21:58:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 21:58:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_59000.pt (epoch 1 @ 59000 updates, score 5.2) (writing took 3.294778946787119 seconds)
2024-07-07 21:59:12 | INFO | train_inner | epoch 001:  59100 / 150053 loss=5.004, nll_loss=3.681, ppl=12.83, wps=14195.7, ups=3.98, wpb=3571.2, bsz=121.7, num_updates=59100, lr=0.000130079, gnorm=1.189, train_wall=19, wall=0
2024-07-07 21:59:31 | INFO | train_inner | epoch 001:  59200 / 150053 loss=5.06, nll_loss=3.745, ppl=13.41, wps=18573.4, ups=5.11, wpb=3636.4, bsz=108.1, num_updates=59200, lr=0.000129969, gnorm=1.181, train_wall=19, wall=0
2024-07-07 21:59:51 | INFO | train_inner | epoch 001:  59300 / 150053 loss=4.961, nll_loss=3.633, ppl=12.4, wps=18206.7, ups=5.09, wpb=3574.1, bsz=131, num_updates=59300, lr=0.000129859, gnorm=1.209, train_wall=19, wall=0
2024-07-07 22:00:10 | INFO | train_inner | epoch 001:  59400 / 150053 loss=5.059, nll_loss=3.745, ppl=13.41, wps=18134.3, ups=5.15, wpb=3520.5, bsz=111.2, num_updates=59400, lr=0.00012975, gnorm=1.264, train_wall=19, wall=0
2024-07-07 22:00:30 | INFO | train_inner | epoch 001:  59500 / 150053 loss=5.084, nll_loss=3.773, ppl=13.67, wps=18478.4, ups=5.18, wpb=3564, bsz=108.6, num_updates=59500, lr=0.000129641, gnorm=1.226, train_wall=19, wall=0
2024-07-07 22:00:49 | INFO | train_inner | epoch 001:  59600 / 150053 loss=5.048, nll_loss=3.732, ppl=13.29, wps=18293, ups=5.18, wpb=3531.2, bsz=95.2, num_updates=59600, lr=0.000129532, gnorm=1.197, train_wall=19, wall=0
2024-07-07 22:01:08 | INFO | train_inner | epoch 001:  59700 / 150053 loss=5.069, nll_loss=3.756, ppl=13.51, wps=18602.7, ups=5.18, wpb=3593, bsz=101.4, num_updates=59700, lr=0.000129423, gnorm=1.211, train_wall=19, wall=0
2024-07-07 22:01:28 | INFO | train_inner | epoch 001:  59800 / 150053 loss=5.055, nll_loss=3.741, ppl=13.37, wps=18413.8, ups=5.18, wpb=3554.9, bsz=116.9, num_updates=59800, lr=0.000129315, gnorm=1.248, train_wall=19, wall=0
2024-07-07 22:01:47 | INFO | train_inner | epoch 001:  59900 / 150053 loss=5.058, nll_loss=3.743, ppl=13.39, wps=18359.1, ups=5.08, wpb=3610.8, bsz=105.4, num_updates=59900, lr=0.000129207, gnorm=1.206, train_wall=19, wall=0
2024-07-07 22:02:07 | INFO | train_inner | epoch 001:  60000 / 150053 loss=5.065, nll_loss=3.751, ppl=13.46, wps=18431.4, ups=5.13, wpb=3591.1, bsz=111.2, num_updates=60000, lr=0.000129099, gnorm=1.257, train_wall=19, wall=0
2024-07-07 22:02:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 22:02:09 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.109 | nll_loss 3.68 | ppl 12.81 | wps 53594.8 | wpb 2588.8 | bsz 75.3 | num_updates 60000 | best_loss 12.211
2024-07-07 22:02:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 22:02:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_60000.pt (epoch 1 @ 60000 updates, score 5.109) (writing took 3.715675041079521 seconds)
2024-07-07 22:02:32 | INFO | train_inner | epoch 001:  60100 / 150053 loss=5.02, nll_loss=3.7, ppl=13, wps=13783.2, ups=3.94, wpb=3502.3, bsz=108.2, num_updates=60100, lr=0.000128992, gnorm=1.205, train_wall=19, wall=0
2024-07-07 22:02:52 | INFO | train_inner | epoch 001:  60200 / 150053 loss=5.069, nll_loss=3.755, ppl=13.5, wps=18111.2, ups=5.14, wpb=3521.7, bsz=93.3, num_updates=60200, lr=0.000128885, gnorm=1.191, train_wall=19, wall=0
2024-07-07 22:03:11 | INFO | train_inner | epoch 001:  60300 / 150053 loss=4.99, nll_loss=3.666, ppl=12.69, wps=18532.4, ups=5.18, wpb=3580.3, bsz=111.4, num_updates=60300, lr=0.000128778, gnorm=1.191, train_wall=19, wall=0
2024-07-07 22:03:30 | INFO | train_inner | epoch 001:  60400 / 150053 loss=5.104, nll_loss=3.796, ppl=13.89, wps=18196.2, ups=5.17, wpb=3517.8, bsz=106.2, num_updates=60400, lr=0.000128671, gnorm=1.325, train_wall=19, wall=0
2024-07-07 22:03:50 | INFO | train_inner | epoch 001:  60500 / 150053 loss=4.994, nll_loss=3.671, ppl=12.73, wps=18133.5, ups=5.17, wpb=3510.4, bsz=107.6, num_updates=60500, lr=0.000128565, gnorm=1.183, train_wall=19, wall=0
2024-07-07 22:04:09 | INFO | train_inner | epoch 001:  60600 / 150053 loss=4.971, nll_loss=3.645, ppl=12.51, wps=18346.5, ups=5.12, wpb=3583.7, bsz=95.2, num_updates=60600, lr=0.000128459, gnorm=1.17, train_wall=19, wall=0
2024-07-07 22:04:29 | INFO | train_inner | epoch 001:  60700 / 150053 loss=4.992, nll_loss=3.668, ppl=12.72, wps=18148.3, ups=5.1, wpb=3557.7, bsz=115, num_updates=60700, lr=0.000128353, gnorm=1.308, train_wall=19, wall=0
2024-07-07 22:04:48 | INFO | train_inner | epoch 001:  60800 / 150053 loss=5.001, nll_loss=3.679, ppl=12.8, wps=18211.9, ups=5.16, wpb=3526.4, bsz=115, num_updates=60800, lr=0.000128247, gnorm=1.248, train_wall=19, wall=0
2024-07-07 22:05:07 | INFO | train_inner | epoch 001:  60900 / 150053 loss=4.979, nll_loss=3.652, ppl=12.57, wps=18179.1, ups=5.17, wpb=3515.3, bsz=98.2, num_updates=60900, lr=0.000128142, gnorm=1.199, train_wall=19, wall=0
2024-07-07 22:05:27 | INFO | train_inner | epoch 001:  61000 / 150053 loss=4.937, nll_loss=3.606, ppl=12.18, wps=18452.4, ups=5.17, wpb=3572, bsz=116.3, num_updates=61000, lr=0.000128037, gnorm=1.201, train_wall=19, wall=0
2024-07-07 22:05:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 22:05:29 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.965 | nll_loss 3.51 | ppl 11.39 | wps 53113 | wpb 2588.8 | bsz 75.3 | num_updates 61000 | best_loss 12.211
2024-07-07 22:05:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 22:05:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_61000.pt (epoch 1 @ 61000 updates, score 4.965) (writing took 4.7853121580556035 seconds)
2024-07-07 22:05:53 | INFO | train_inner | epoch 001:  61100 / 150053 loss=4.954, nll_loss=3.625, ppl=12.33, wps=13263.8, ups=3.79, wpb=3498.5, bsz=103.4, num_updates=61100, lr=0.000127932, gnorm=1.211, train_wall=19, wall=0
2024-07-07 22:06:12 | INFO | train_inner | epoch 001:  61200 / 150053 loss=5.018, nll_loss=3.699, ppl=12.98, wps=18502.1, ups=5.22, wpb=3547, bsz=100, num_updates=61200, lr=0.000127827, gnorm=1.17, train_wall=19, wall=0
2024-07-07 22:06:32 | INFO | train_inner | epoch 001:  61300 / 150053 loss=4.994, nll_loss=3.671, ppl=12.74, wps=18146.3, ups=5.15, wpb=3524.6, bsz=104.6, num_updates=61300, lr=0.000127723, gnorm=1.197, train_wall=19, wall=0
2024-07-07 22:06:51 | INFO | train_inner | epoch 001:  61400 / 150053 loss=4.953, nll_loss=3.625, ppl=12.33, wps=18316.2, ups=5.14, wpb=3564.9, bsz=114.1, num_updates=61400, lr=0.000127619, gnorm=1.2, train_wall=19, wall=0
2024-07-07 22:07:11 | INFO | train_inner | epoch 001:  61500 / 150053 loss=4.947, nll_loss=3.617, ppl=12.27, wps=18480, ups=5.14, wpb=3593, bsz=121.5, num_updates=61500, lr=0.000127515, gnorm=1.218, train_wall=19, wall=0
2024-07-07 22:07:30 | INFO | train_inner | epoch 001:  61600 / 150053 loss=5.012, nll_loss=3.691, ppl=12.92, wps=18373.9, ups=5.18, wpb=3545.7, bsz=110.2, num_updates=61600, lr=0.000127412, gnorm=1.225, train_wall=19, wall=0
2024-07-07 22:07:50 | INFO | train_inner | epoch 001:  61700 / 150053 loss=4.997, nll_loss=3.675, ppl=12.77, wps=17957.8, ups=5.13, wpb=3501.1, bsz=110.5, num_updates=61700, lr=0.000127309, gnorm=1.205, train_wall=19, wall=0
2024-07-07 22:08:09 | INFO | train_inner | epoch 001:  61800 / 150053 loss=4.975, nll_loss=3.65, ppl=12.55, wps=18615.8, ups=5.16, wpb=3606.5, bsz=133, num_updates=61800, lr=0.000127205, gnorm=1.231, train_wall=19, wall=0
2024-07-07 22:08:28 | INFO | train_inner | epoch 001:  61900 / 150053 loss=5.019, nll_loss=3.7, ppl=13, wps=18324.8, ups=5.18, wpb=3539.6, bsz=101.9, num_updates=61900, lr=0.000127103, gnorm=1.22, train_wall=19, wall=0
2024-07-07 22:08:48 | INFO | train_inner | epoch 001:  62000 / 150053 loss=4.974, nll_loss=3.648, ppl=12.54, wps=18268.2, ups=5.16, wpb=3539.4, bsz=101.4, num_updates=62000, lr=0.000127, gnorm=1.221, train_wall=19, wall=0
2024-07-07 22:08:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 22:08:50 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.956 | nll_loss 3.493 | ppl 11.26 | wps 52005.7 | wpb 2588.8 | bsz 75.3 | num_updates 62000 | best_loss 12.211
2024-07-07 22:08:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 22:08:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_62000.pt (epoch 1 @ 62000 updates, score 4.956) (writing took 3.8264142284169793 seconds)
2024-07-07 22:09:13 | INFO | train_inner | epoch 001:  62100 / 150053 loss=4.973, nll_loss=3.646, ppl=12.52, wps=13815.3, ups=3.95, wpb=3497.3, bsz=100, num_updates=62100, lr=0.000126898, gnorm=1.189, train_wall=19, wall=0
2024-07-07 22:09:32 | INFO | train_inner | epoch 001:  62200 / 150053 loss=5.042, nll_loss=3.726, ppl=13.23, wps=18373.9, ups=5.16, wpb=3559.5, bsz=92.8, num_updates=62200, lr=0.000126796, gnorm=1.245, train_wall=19, wall=0
2024-07-07 22:09:52 | INFO | train_inner | epoch 001:  62300 / 150053 loss=4.928, nll_loss=3.596, ppl=12.09, wps=18066.9, ups=5.18, wpb=3490.9, bsz=101.6, num_updates=62300, lr=0.000126694, gnorm=1.203, train_wall=19, wall=0
2024-07-07 22:10:11 | INFO | train_inner | epoch 001:  62400 / 150053 loss=4.988, nll_loss=3.664, ppl=12.67, wps=18309.3, ups=5.19, wpb=3527.7, bsz=105.8, num_updates=62400, lr=0.000126592, gnorm=1.212, train_wall=19, wall=0
2024-07-07 22:10:30 | INFO | train_inner | epoch 001:  62500 / 150053 loss=4.946, nll_loss=3.617, ppl=12.27, wps=18386.3, ups=5.15, wpb=3572.8, bsz=110.5, num_updates=62500, lr=0.000126491, gnorm=1.205, train_wall=19, wall=0
2024-07-07 22:10:50 | INFO | train_inner | epoch 001:  62600 / 150053 loss=4.802, nll_loss=3.453, ppl=10.95, wps=17955.8, ups=5.1, wpb=3520.2, bsz=129.1, num_updates=62600, lr=0.00012639, gnorm=1.2, train_wall=19, wall=0
2024-07-07 22:11:09 | INFO | train_inner | epoch 001:  62700 / 150053 loss=5.06, nll_loss=3.746, ppl=13.41, wps=18206.5, ups=5.19, wpb=3511.1, bsz=85.2, num_updates=62700, lr=0.000126289, gnorm=1.186, train_wall=19, wall=0
2024-07-07 22:11:29 | INFO | train_inner | epoch 001:  62800 / 150053 loss=4.929, nll_loss=3.597, ppl=12.1, wps=18378.3, ups=5.16, wpb=3563.8, bsz=97.7, num_updates=62800, lr=0.000126189, gnorm=1.191, train_wall=19, wall=0
2024-07-07 22:11:48 | INFO | train_inner | epoch 001:  62900 / 150053 loss=4.948, nll_loss=3.619, ppl=12.28, wps=18426.7, ups=5.12, wpb=3596.6, bsz=103.2, num_updates=62900, lr=0.000126088, gnorm=1.214, train_wall=19, wall=0
2024-07-07 22:12:08 | INFO | train_inner | epoch 001:  63000 / 150053 loss=4.931, nll_loss=3.6, ppl=12.12, wps=18171.6, ups=5.11, wpb=3553.1, bsz=108.6, num_updates=63000, lr=0.000125988, gnorm=1.23, train_wall=19, wall=0
2024-07-07 22:12:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 22:12:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.91 | nll_loss 3.442 | ppl 10.87 | wps 53448.9 | wpb 2588.8 | bsz 75.3 | num_updates 63000 | best_loss 12.211
2024-07-07 22:12:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 22:12:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_63000.pt (epoch 1 @ 63000 updates, score 4.91) (writing took 4.622102548368275 seconds)
2024-07-07 22:12:34 | INFO | train_inner | epoch 001:  63100 / 150053 loss=4.88, nll_loss=3.541, ppl=11.64, wps=13650.1, ups=3.79, wpb=3597.1, bsz=108.1, num_updates=63100, lr=0.000125888, gnorm=1.166, train_wall=19, wall=0
2024-07-07 22:12:54 | INFO | train_inner | epoch 001:  63200 / 150053 loss=4.925, nll_loss=3.592, ppl=12.06, wps=18536.1, ups=5.11, wpb=3625.1, bsz=101.9, num_updates=63200, lr=0.000125789, gnorm=1.186, train_wall=19, wall=0
2024-07-07 22:13:13 | INFO | train_inner | epoch 001:  63300 / 150053 loss=4.935, nll_loss=3.604, ppl=12.16, wps=18309.8, ups=5.1, wpb=3589.9, bsz=104.9, num_updates=63300, lr=0.000125689, gnorm=1.192, train_wall=19, wall=0
2024-07-07 22:13:32 | INFO | train_inner | epoch 001:  63400 / 150053 loss=4.89, nll_loss=3.553, ppl=11.73, wps=18092.6, ups=5.19, wpb=3488.7, bsz=107.4, num_updates=63400, lr=0.00012559, gnorm=1.174, train_wall=19, wall=0
2024-07-07 22:13:52 | INFO | train_inner | epoch 001:  63500 / 150053 loss=4.776, nll_loss=3.423, ppl=10.72, wps=18187.7, ups=5.12, wpb=3554.8, bsz=119.4, num_updates=63500, lr=0.000125491, gnorm=1.177, train_wall=19, wall=0
2024-07-07 22:14:11 | INFO | train_inner | epoch 001:  63600 / 150053 loss=4.932, nll_loss=3.601, ppl=12.14, wps=18600.8, ups=5.24, wpb=3547.7, bsz=130.2, num_updates=63600, lr=0.000125392, gnorm=1.272, train_wall=19, wall=0
2024-07-07 22:14:31 | INFO | train_inner | epoch 001:  63700 / 150053 loss=4.878, nll_loss=3.54, ppl=11.63, wps=18284.3, ups=5.12, wpb=3569, bsz=104, num_updates=63700, lr=0.000125294, gnorm=1.191, train_wall=19, wall=0
2024-07-07 22:14:50 | INFO | train_inner | epoch 001:  63800 / 150053 loss=4.95, nll_loss=3.621, ppl=12.3, wps=18292.9, ups=5.16, wpb=3546.8, bsz=97, num_updates=63800, lr=0.000125196, gnorm=1.222, train_wall=19, wall=0
2024-07-07 22:15:09 | INFO | train_inner | epoch 001:  63900 / 150053 loss=4.873, nll_loss=3.534, ppl=11.58, wps=18069.2, ups=5.19, wpb=3483.7, bsz=111.5, num_updates=63900, lr=0.000125098, gnorm=1.213, train_wall=19, wall=0
2024-07-07 22:15:29 | INFO | train_inner | epoch 001:  64000 / 150053 loss=4.908, nll_loss=3.573, ppl=11.9, wps=18291.6, ups=5.15, wpb=3551.9, bsz=110.8, num_updates=64000, lr=0.000125, gnorm=1.207, train_wall=19, wall=0
2024-07-07 22:15:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 22:15:31 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.865 | nll_loss 3.389 | ppl 10.48 | wps 53626.1 | wpb 2588.8 | bsz 75.3 | num_updates 64000 | best_loss 12.211
2024-07-07 22:15:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 22:15:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_64000.pt (epoch 1 @ 64000 updates, score 4.865) (writing took 3.3771763667464256 seconds)
2024-07-07 22:15:54 | INFO | train_inner | epoch 001:  64100 / 150053 loss=4.868, nll_loss=3.528, ppl=11.54, wps=14037.2, ups=3.98, wpb=3526.6, bsz=100.4, num_updates=64100, lr=0.000124902, gnorm=1.165, train_wall=19, wall=0
2024-07-07 22:16:13 | INFO | train_inner | epoch 001:  64200 / 150053 loss=4.901, nll_loss=3.565, ppl=11.84, wps=18352.7, ups=5.15, wpb=3562.1, bsz=95.3, num_updates=64200, lr=0.000124805, gnorm=1.176, train_wall=19, wall=0
2024-07-07 22:16:33 | INFO | train_inner | epoch 001:  64300 / 150053 loss=4.922, nll_loss=3.59, ppl=12.04, wps=18321.2, ups=5.17, wpb=3542.3, bsz=90.6, num_updates=64300, lr=0.000124708, gnorm=1.207, train_wall=19, wall=0
2024-07-07 22:16:52 | INFO | train_inner | epoch 001:  64400 / 150053 loss=4.949, nll_loss=3.621, ppl=12.3, wps=18157.3, ups=5.2, wpb=3494.8, bsz=103.8, num_updates=64400, lr=0.000124611, gnorm=1.244, train_wall=19, wall=0
2024-07-07 22:17:11 | INFO | train_inner | epoch 001:  64500 / 150053 loss=4.947, nll_loss=3.618, ppl=12.28, wps=18392.3, ups=5.18, wpb=3549, bsz=100.6, num_updates=64500, lr=0.000124515, gnorm=1.212, train_wall=19, wall=0
2024-07-07 22:17:31 | INFO | train_inner | epoch 001:  64600 / 150053 loss=4.886, nll_loss=3.548, ppl=11.7, wps=18330.2, ups=5.12, wpb=3578.1, bsz=99.4, num_updates=64600, lr=0.000124418, gnorm=1.193, train_wall=19, wall=0
2024-07-07 22:17:50 | INFO | train_inner | epoch 001:  64700 / 150053 loss=4.85, nll_loss=3.508, ppl=11.37, wps=18315.1, ups=5.11, wpb=3587.4, bsz=124.6, num_updates=64700, lr=0.000124322, gnorm=1.344, train_wall=19, wall=0
2024-07-07 22:18:09 | INFO | train_inner | epoch 001:  64800 / 150053 loss=4.95, nll_loss=3.621, ppl=12.3, wps=18231.1, ups=5.2, wpb=3504.6, bsz=94.1, num_updates=64800, lr=0.000124226, gnorm=1.208, train_wall=19, wall=0
2024-07-07 22:18:29 | INFO | train_inner | epoch 001:  64900 / 150053 loss=4.942, nll_loss=3.613, ppl=12.23, wps=18062.3, ups=5.18, wpb=3485.4, bsz=95.6, num_updates=64900, lr=0.00012413, gnorm=1.192, train_wall=19, wall=0
2024-07-07 22:18:48 | INFO | train_inner | epoch 001:  65000 / 150053 loss=4.837, nll_loss=3.492, ppl=11.25, wps=18417.6, ups=5.15, wpb=3576.3, bsz=117.9, num_updates=65000, lr=0.000124035, gnorm=1.182, train_wall=19, wall=0
2024-07-07 22:18:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 22:18:50 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.816 | nll_loss 3.331 | ppl 10.06 | wps 52119.3 | wpb 2588.8 | bsz 75.3 | num_updates 65000 | best_loss 12.211
2024-07-07 22:18:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 22:18:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_65000.pt (epoch 1 @ 65000 updates, score 4.816) (writing took 4.459794548340142 seconds)
2024-07-07 22:19:14 | INFO | train_inner | epoch 001:  65100 / 150053 loss=4.821, nll_loss=3.475, ppl=11.12, wps=13543.2, ups=3.81, wpb=3550.9, bsz=102.5, num_updates=65100, lr=0.000123939, gnorm=1.185, train_wall=19, wall=0
2024-07-07 22:19:34 | INFO | train_inner | epoch 001:  65200 / 150053 loss=4.926, nll_loss=3.594, ppl=12.08, wps=17832.5, ups=5.18, wpb=3444.3, bsz=99.3, num_updates=65200, lr=0.000123844, gnorm=1.242, train_wall=19, wall=0
2024-07-07 22:19:53 | INFO | train_inner | epoch 001:  65300 / 150053 loss=4.911, nll_loss=3.577, ppl=11.94, wps=18496.4, ups=5.21, wpb=3552.3, bsz=101.5, num_updates=65300, lr=0.000123749, gnorm=1.17, train_wall=19, wall=0
2024-07-07 22:20:12 | INFO | train_inner | epoch 001:  65400 / 150053 loss=4.859, nll_loss=3.517, ppl=11.45, wps=18318.4, ups=5.1, wpb=3592.1, bsz=104.2, num_updates=65400, lr=0.000123655, gnorm=1.176, train_wall=19, wall=0
2024-07-07 22:20:32 | INFO | train_inner | epoch 001:  65500 / 150053 loss=4.836, nll_loss=3.491, ppl=11.25, wps=18356.6, ups=5.12, wpb=3585.2, bsz=99.7, num_updates=65500, lr=0.00012356, gnorm=1.198, train_wall=19, wall=0
2024-07-07 22:20:51 | INFO | train_inner | epoch 001:  65600 / 150053 loss=4.872, nll_loss=3.533, ppl=11.57, wps=18230.2, ups=5.17, wpb=3529.4, bsz=97.6, num_updates=65600, lr=0.000123466, gnorm=1.183, train_wall=19, wall=0
2024-07-07 22:21:11 | INFO | train_inner | epoch 001:  65700 / 150053 loss=4.841, nll_loss=3.497, ppl=11.29, wps=18465.3, ups=5.14, wpb=3595.1, bsz=115.9, num_updates=65700, lr=0.000123372, gnorm=1.261, train_wall=19, wall=0
2024-07-07 22:21:30 | INFO | train_inner | epoch 001:  65800 / 150053 loss=4.871, nll_loss=3.532, ppl=11.57, wps=18618.3, ups=5.2, wpb=3583.8, bsz=102.7, num_updates=65800, lr=0.000123278, gnorm=1.18, train_wall=19, wall=0
2024-07-07 22:21:50 | INFO | train_inner | epoch 001:  65900 / 150053 loss=4.876, nll_loss=3.537, ppl=11.61, wps=18183.1, ups=5.13, wpb=3545.7, bsz=98.6, num_updates=65900, lr=0.000123185, gnorm=1.186, train_wall=19, wall=0
2024-07-07 22:22:09 | INFO | train_inner | epoch 001:  66000 / 150053 loss=4.786, nll_loss=3.434, ppl=10.81, wps=18493.1, ups=5.16, wpb=3580.7, bsz=117.5, num_updates=66000, lr=0.000123091, gnorm=1.204, train_wall=19, wall=0
2024-07-07 22:22:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 22:22:11 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.796 | nll_loss 3.312 | ppl 9.93 | wps 53320.9 | wpb 2588.8 | bsz 75.3 | num_updates 66000 | best_loss 12.211
2024-07-07 22:22:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 22:22:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_66000.pt (epoch 1 @ 66000 updates, score 4.796) (writing took 3.936135595664382 seconds)
2024-07-07 22:22:35 | INFO | train_inner | epoch 001:  66100 / 150053 loss=4.823, nll_loss=3.477, ppl=11.13, wps=14108.5, ups=3.88, wpb=3634.5, bsz=105.3, num_updates=66100, lr=0.000122998, gnorm=1.169, train_wall=19, wall=0
2024-07-07 22:22:54 | INFO | train_inner | epoch 001:  66200 / 150053 loss=4.866, nll_loss=3.526, ppl=11.52, wps=18219.6, ups=5.2, wpb=3505.9, bsz=102.3, num_updates=66200, lr=0.000122905, gnorm=1.227, train_wall=19, wall=0
2024-07-07 22:23:13 | INFO | train_inner | epoch 001:  66300 / 150053 loss=4.861, nll_loss=3.52, ppl=11.48, wps=18349.9, ups=5.19, wpb=3537, bsz=100.7, num_updates=66300, lr=0.000122813, gnorm=1.161, train_wall=19, wall=0
2024-07-07 22:23:33 | INFO | train_inner | epoch 001:  66400 / 150053 loss=4.868, nll_loss=3.529, ppl=11.54, wps=18489, ups=5.17, wpb=3576.3, bsz=100.4, num_updates=66400, lr=0.00012272, gnorm=1.206, train_wall=19, wall=0
2024-07-07 22:23:52 | INFO | train_inner | epoch 001:  66500 / 150053 loss=4.782, nll_loss=3.431, ppl=10.78, wps=18562, ups=5.14, wpb=3612.9, bsz=111, num_updates=66500, lr=0.000122628, gnorm=1.163, train_wall=19, wall=0
2024-07-07 22:24:11 | INFO | train_inner | epoch 001:  66600 / 150053 loss=4.897, nll_loss=3.561, ppl=11.8, wps=18504.2, ups=5.24, wpb=3534.6, bsz=99.4, num_updates=66600, lr=0.000122536, gnorm=1.22, train_wall=19, wall=0
2024-07-07 22:24:31 | INFO | train_inner | epoch 001:  66700 / 150053 loss=4.794, nll_loss=3.444, ppl=10.88, wps=18430.5, ups=5.14, wpb=3587.7, bsz=125.8, num_updates=66700, lr=0.000122444, gnorm=1.269, train_wall=19, wall=0
2024-07-07 22:24:50 | INFO | train_inner | epoch 001:  66800 / 150053 loss=4.775, nll_loss=3.424, ppl=10.73, wps=18352, ups=5.16, wpb=3553.8, bsz=107.1, num_updates=66800, lr=0.000122352, gnorm=1.157, train_wall=19, wall=0
2024-07-07 22:25:09 | INFO | train_inner | epoch 001:  66900 / 150053 loss=4.822, nll_loss=3.476, ppl=11.13, wps=18225.4, ups=5.16, wpb=3530.1, bsz=102, num_updates=66900, lr=0.000122261, gnorm=1.177, train_wall=19, wall=0
2024-07-07 22:25:29 | INFO | train_inner | epoch 001:  67000 / 150053 loss=4.842, nll_loss=3.498, ppl=11.3, wps=18222.7, ups=5.16, wpb=3528.2, bsz=94.3, num_updates=67000, lr=0.000122169, gnorm=1.188, train_wall=19, wall=0
2024-07-07 22:25:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 22:25:31 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.77 | nll_loss 3.282 | ppl 9.73 | wps 53610.2 | wpb 2588.8 | bsz 75.3 | num_updates 67000 | best_loss 12.211
2024-07-07 22:25:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 22:25:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_67000.pt (epoch 1 @ 67000 updates, score 4.77) (writing took 3.2643154710531235 seconds)
2024-07-07 22:25:53 | INFO | train_inner | epoch 001:  67100 / 150053 loss=4.901, nll_loss=3.567, ppl=11.85, wps=14436.4, ups=4.05, wpb=3562.9, bsz=99.9, num_updates=67100, lr=0.000122078, gnorm=1.281, train_wall=19, wall=0
2024-07-07 22:26:13 | INFO | train_inner | epoch 001:  67200 / 150053 loss=4.838, nll_loss=3.495, ppl=11.27, wps=18529.4, ups=5.18, wpb=3580.1, bsz=106.1, num_updates=67200, lr=0.000121988, gnorm=1.202, train_wall=19, wall=0
2024-07-07 22:26:32 | INFO | train_inner | epoch 001:  67300 / 150053 loss=4.82, nll_loss=3.474, ppl=11.11, wps=17995.3, ups=5.15, wpb=3491.4, bsz=100.9, num_updates=67300, lr=0.000121897, gnorm=1.228, train_wall=19, wall=0
2024-07-07 22:26:51 | INFO | train_inner | epoch 001:  67400 / 150053 loss=4.882, nll_loss=3.545, ppl=11.67, wps=18475.1, ups=5.18, wpb=3566.1, bsz=97, num_updates=67400, lr=0.000121806, gnorm=1.188, train_wall=19, wall=0
2024-07-07 22:27:11 | INFO | train_inner | epoch 001:  67500 / 150053 loss=4.841, nll_loss=3.497, ppl=11.29, wps=18610.3, ups=5.21, wpb=3574.9, bsz=101.2, num_updates=67500, lr=0.000121716, gnorm=1.228, train_wall=19, wall=0
2024-07-07 22:27:30 | INFO | train_inner | epoch 001:  67600 / 150053 loss=4.88, nll_loss=3.542, ppl=11.65, wps=18212.2, ups=5.14, wpb=3542.9, bsz=95.9, num_updates=67600, lr=0.000121626, gnorm=1.189, train_wall=19, wall=0
2024-07-07 22:27:49 | INFO | train_inner | epoch 001:  67700 / 150053 loss=4.838, nll_loss=3.495, ppl=11.27, wps=18320.9, ups=5.2, wpb=3524, bsz=98.6, num_updates=67700, lr=0.000121536, gnorm=1.196, train_wall=19, wall=0
2024-07-07 22:28:09 | INFO | train_inner | epoch 001:  67800 / 150053 loss=4.886, nll_loss=3.55, ppl=11.71, wps=18291, ups=5.15, wpb=3548.7, bsz=96.6, num_updates=67800, lr=0.000121447, gnorm=1.184, train_wall=19, wall=0
2024-07-07 22:28:28 | INFO | train_inner | epoch 001:  67900 / 150053 loss=4.79, nll_loss=3.439, ppl=10.84, wps=18310.5, ups=5.15, wpb=3555.8, bsz=90.2, num_updates=67900, lr=0.000121357, gnorm=1.175, train_wall=19, wall=0
2024-07-07 22:28:48 | INFO | train_inner | epoch 001:  68000 / 150053 loss=4.875, nll_loss=3.537, ppl=11.61, wps=18206.5, ups=5.14, wpb=3544.8, bsz=101.7, num_updates=68000, lr=0.000121268, gnorm=1.218, train_wall=19, wall=0
2024-07-07 22:28:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 22:28:50 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.756 | nll_loss 3.261 | ppl 9.59 | wps 53386.6 | wpb 2588.8 | bsz 75.3 | num_updates 68000 | best_loss 12.211
2024-07-07 22:28:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 22:28:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_68000.pt (epoch 1 @ 68000 updates, score 4.756) (writing took 3.4149977499619126 seconds)
2024-07-07 22:29:13 | INFO | train_inner | epoch 001:  68100 / 150053 loss=4.709, nll_loss=3.346, ppl=10.17, wps=14384.1, ups=3.96, wpb=3635.9, bsz=115.8, num_updates=68100, lr=0.000121179, gnorm=1.16, train_wall=19, wall=0
2024-07-07 22:29:32 | INFO | train_inner | epoch 001:  68200 / 150053 loss=4.88, nll_loss=3.542, ppl=11.65, wps=18130.4, ups=5.19, wpb=3493.5, bsz=92, num_updates=68200, lr=0.00012109, gnorm=1.219, train_wall=19, wall=0
2024-07-07 22:29:52 | INFO | train_inner | epoch 001:  68300 / 150053 loss=4.791, nll_loss=3.441, ppl=10.86, wps=18387.3, ups=5.15, wpb=3571.6, bsz=104.2, num_updates=68300, lr=0.000121001, gnorm=1.177, train_wall=19, wall=0
2024-07-07 22:30:11 | INFO | train_inner | epoch 001:  68400 / 150053 loss=4.905, nll_loss=3.571, ppl=11.89, wps=18338.4, ups=5.19, wpb=3534.8, bsz=84, num_updates=68400, lr=0.000120913, gnorm=1.216, train_wall=19, wall=0
2024-07-07 22:30:30 | INFO | train_inner | epoch 001:  68500 / 150053 loss=4.837, nll_loss=3.494, ppl=11.26, wps=18477.4, ups=5.21, wpb=3543.2, bsz=101.9, num_updates=68500, lr=0.000120824, gnorm=1.201, train_wall=19, wall=0
2024-07-07 22:30:49 | INFO | train_inner | epoch 001:  68600 / 150053 loss=4.812, nll_loss=3.466, ppl=11.05, wps=18503.6, ups=5.19, wpb=3563.5, bsz=105.4, num_updates=68600, lr=0.000120736, gnorm=1.195, train_wall=19, wall=0
2024-07-07 22:31:09 | INFO | train_inner | epoch 001:  68700 / 150053 loss=4.787, nll_loss=3.437, ppl=10.83, wps=18497.4, ups=5.15, wpb=3594.4, bsz=92.7, num_updates=68700, lr=0.000120648, gnorm=1.176, train_wall=19, wall=0
2024-07-07 22:31:28 | INFO | train_inner | epoch 001:  68800 / 150053 loss=4.764, nll_loss=3.41, ppl=10.63, wps=18428.9, ups=5.17, wpb=3562.3, bsz=114.9, num_updates=68800, lr=0.000120561, gnorm=1.203, train_wall=19, wall=0
2024-07-07 22:31:47 | INFO | train_inner | epoch 001:  68900 / 150053 loss=4.855, nll_loss=3.514, ppl=11.42, wps=18393, ups=5.16, wpb=3566.6, bsz=96.4, num_updates=68900, lr=0.000120473, gnorm=1.213, train_wall=19, wall=0
2024-07-07 22:32:07 | INFO | train_inner | epoch 001:  69000 / 150053 loss=4.774, nll_loss=3.422, ppl=10.72, wps=18722.9, ups=5.14, wpb=3645, bsz=100.9, num_updates=69000, lr=0.000120386, gnorm=1.167, train_wall=19, wall=0
2024-07-07 22:32:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 22:32:09 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.728 | nll_loss 3.224 | ppl 9.35 | wps 53584.8 | wpb 2588.8 | bsz 75.3 | num_updates 69000 | best_loss 12.211
2024-07-07 22:32:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 22:32:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_69000.pt (epoch 1 @ 69000 updates, score 4.728) (writing took 3.85095635894686 seconds)
2024-07-07 22:32:32 | INFO | train_inner | epoch 001:  69100 / 150053 loss=4.849, nll_loss=3.507, ppl=11.37, wps=14030.6, ups=3.95, wpb=3552.1, bsz=99.7, num_updates=69100, lr=0.000120299, gnorm=1.22, train_wall=19, wall=0
2024-07-07 22:32:52 | INFO | train_inner | epoch 001:  69200 / 150053 loss=4.735, nll_loss=3.377, ppl=10.39, wps=18262.3, ups=5.16, wpb=3536.9, bsz=112.2, num_updates=69200, lr=0.000120212, gnorm=1.175, train_wall=19, wall=0
2024-07-07 22:33:11 | INFO | train_inner | epoch 001:  69300 / 150053 loss=4.676, nll_loss=3.311, ppl=9.92, wps=18248.9, ups=5.16, wpb=3537.8, bsz=112.5, num_updates=69300, lr=0.000120125, gnorm=1.201, train_wall=19, wall=0
2024-07-07 22:33:30 | INFO | train_inner | epoch 001:  69400 / 150053 loss=4.854, nll_loss=3.513, ppl=11.41, wps=18233.8, ups=5.19, wpb=3510.2, bsz=87.9, num_updates=69400, lr=0.000120038, gnorm=1.23, train_wall=19, wall=0
2024-07-07 22:33:50 | INFO | train_inner | epoch 001:  69500 / 150053 loss=4.768, nll_loss=3.415, ppl=10.67, wps=18255.6, ups=5.13, wpb=3556.1, bsz=95.4, num_updates=69500, lr=0.000119952, gnorm=1.171, train_wall=19, wall=0
2024-07-07 22:34:09 | INFO | train_inner | epoch 001:  69600 / 150053 loss=4.735, nll_loss=3.377, ppl=10.39, wps=18797.6, ups=5.14, wpb=3657.4, bsz=100.8, num_updates=69600, lr=0.000119866, gnorm=1.187, train_wall=19, wall=0
2024-07-07 22:34:29 | INFO | train_inner | epoch 001:  69700 / 150053 loss=4.767, nll_loss=3.413, ppl=10.65, wps=18245.4, ups=5.17, wpb=3528.6, bsz=105.4, num_updates=69700, lr=0.00011978, gnorm=1.257, train_wall=19, wall=0
2024-07-07 22:34:48 | INFO | train_inner | epoch 001:  69800 / 150053 loss=4.739, nll_loss=3.382, ppl=10.42, wps=18261.2, ups=5.17, wpb=3529.9, bsz=110.8, num_updates=69800, lr=0.000119694, gnorm=1.221, train_wall=19, wall=0
2024-07-07 22:35:07 | INFO | train_inner | epoch 001:  69900 / 150053 loss=4.746, nll_loss=3.39, ppl=10.48, wps=18074.7, ups=5.21, wpb=3471.1, bsz=106.9, num_updates=69900, lr=0.000119608, gnorm=1.212, train_wall=19, wall=0
2024-07-07 22:35:27 | INFO | train_inner | epoch 001:  70000 / 150053 loss=4.82, nll_loss=3.474, ppl=11.11, wps=18346.3, ups=5.13, wpb=3578.5, bsz=83.9, num_updates=70000, lr=0.000119523, gnorm=1.195, train_wall=19, wall=0
2024-07-07 22:35:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 22:35:29 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.713 | nll_loss 3.207 | ppl 9.23 | wps 53294.4 | wpb 2588.8 | bsz 75.3 | num_updates 70000 | best_loss 12.211
2024-07-07 22:35:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 22:35:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_70000.pt (epoch 1 @ 70000 updates, score 4.713) (writing took 3.217672049999237 seconds)
2024-07-07 22:35:52 | INFO | train_inner | epoch 001:  70100 / 150053 loss=4.779, nll_loss=3.428, ppl=10.76, wps=14179.5, ups=4.01, wpb=3536.2, bsz=107.9, num_updates=70100, lr=0.000119438, gnorm=1.254, train_wall=19, wall=0
2024-07-07 22:36:11 | INFO | train_inner | epoch 001:  70200 / 150053 loss=4.779, nll_loss=3.428, ppl=10.76, wps=18199, ups=5.21, wpb=3491.4, bsz=99.4, num_updates=70200, lr=0.000119352, gnorm=1.224, train_wall=19, wall=0
2024-07-07 22:36:30 | INFO | train_inner | epoch 001:  70300 / 150053 loss=4.723, nll_loss=3.364, ppl=10.3, wps=18283.7, ups=5.17, wpb=3534.1, bsz=103.2, num_updates=70300, lr=0.000119268, gnorm=1.215, train_wall=19, wall=0
2024-07-07 22:36:49 | INFO | train_inner | epoch 001:  70400 / 150053 loss=4.706, nll_loss=3.345, ppl=10.16, wps=18480.2, ups=5.16, wpb=3580.2, bsz=112.3, num_updates=70400, lr=0.000119183, gnorm=1.188, train_wall=19, wall=0
2024-07-07 22:37:09 | INFO | train_inner | epoch 001:  70500 / 150053 loss=4.712, nll_loss=3.351, ppl=10.2, wps=18348, ups=5.13, wpb=3575.3, bsz=105.5, num_updates=70500, lr=0.000119098, gnorm=1.231, train_wall=19, wall=0
2024-07-07 22:37:28 | INFO | train_inner | epoch 001:  70600 / 150053 loss=4.747, nll_loss=3.392, ppl=10.5, wps=18068.5, ups=5.17, wpb=3492, bsz=102, num_updates=70600, lr=0.000119014, gnorm=1.22, train_wall=19, wall=0
2024-07-07 22:37:47 | INFO | train_inner | epoch 001:  70700 / 150053 loss=4.773, nll_loss=3.421, ppl=10.71, wps=18411.3, ups=5.23, wpb=3520.7, bsz=97.3, num_updates=70700, lr=0.00011893, gnorm=1.207, train_wall=19, wall=0
2024-07-07 22:38:07 | INFO | train_inner | epoch 001:  70800 / 150053 loss=4.699, nll_loss=3.335, ppl=10.09, wps=18846.7, ups=5.12, wpb=3680.8, bsz=109, num_updates=70800, lr=0.000118846, gnorm=1.148, train_wall=19, wall=0
2024-07-07 22:38:26 | INFO | train_inner | epoch 001:  70900 / 150053 loss=4.629, nll_loss=3.258, ppl=9.56, wps=18333.3, ups=5.12, wpb=3580, bsz=118.8, num_updates=70900, lr=0.000118762, gnorm=1.181, train_wall=19, wall=0
2024-07-07 22:38:46 | INFO | train_inner | epoch 001:  71000 / 150053 loss=4.73, nll_loss=3.372, ppl=10.35, wps=18251.8, ups=5.14, wpb=3552.2, bsz=101.8, num_updates=71000, lr=0.000118678, gnorm=1.165, train_wall=19, wall=0
2024-07-07 22:38:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 22:38:48 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.665 | nll_loss 3.155 | ppl 8.91 | wps 53586.4 | wpb 2588.8 | bsz 75.3 | num_updates 71000 | best_loss 12.211
2024-07-07 22:38:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 22:38:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_71000.pt (epoch 1 @ 71000 updates, score 4.665) (writing took 3.2910254895687103 seconds)
2024-07-07 22:39:11 | INFO | train_inner | epoch 001:  71100 / 150053 loss=4.728, nll_loss=3.371, ppl=10.34, wps=13987.6, ups=4.04, wpb=3464.2, bsz=105.1, num_updates=71100, lr=0.000118595, gnorm=1.243, train_wall=19, wall=0
2024-07-07 22:39:30 | INFO | train_inner | epoch 001:  71200 / 150053 loss=4.702, nll_loss=3.34, ppl=10.12, wps=18504.7, ups=5.16, wpb=3588.2, bsz=115.4, num_updates=71200, lr=0.000118511, gnorm=1.19, train_wall=19, wall=0
2024-07-07 22:39:49 | INFO | train_inner | epoch 001:  71300 / 150053 loss=4.685, nll_loss=3.321, ppl=9.99, wps=18243.7, ups=5.15, wpb=3540.1, bsz=102.7, num_updates=71300, lr=0.000118428, gnorm=1.184, train_wall=19, wall=0
2024-07-07 22:40:09 | INFO | train_inner | epoch 001:  71400 / 150053 loss=4.767, nll_loss=3.414, ppl=10.66, wps=18679.7, ups=5.12, wpb=3645.6, bsz=101, num_updates=71400, lr=0.000118345, gnorm=1.223, train_wall=19, wall=0
2024-07-07 22:40:28 | INFO | train_inner | epoch 001:  71500 / 150053 loss=4.805, nll_loss=3.457, ppl=10.98, wps=18521.6, ups=5.21, wpb=3553.9, bsz=93.9, num_updates=71500, lr=0.000118262, gnorm=1.189, train_wall=19, wall=0
2024-07-07 22:40:48 | INFO | train_inner | epoch 001:  71600 / 150053 loss=4.747, nll_loss=3.391, ppl=10.49, wps=18342.1, ups=5.14, wpb=3568.4, bsz=100.3, num_updates=71600, lr=0.00011818, gnorm=1.196, train_wall=19, wall=0
2024-07-07 22:41:07 | INFO | train_inner | epoch 001:  71700 / 150053 loss=4.664, nll_loss=3.297, ppl=9.83, wps=18202.8, ups=5.12, wpb=3553.1, bsz=106.3, num_updates=71700, lr=0.000118097, gnorm=1.19, train_wall=19, wall=0
2024-07-07 22:41:26 | INFO | train_inner | epoch 001:  71800 / 150053 loss=4.676, nll_loss=3.312, ppl=9.93, wps=18565.9, ups=5.16, wpb=3598.9, bsz=109, num_updates=71800, lr=0.000118015, gnorm=1.211, train_wall=19, wall=0
2024-07-07 22:41:46 | INFO | train_inner | epoch 001:  71900 / 150053 loss=4.733, nll_loss=3.375, ppl=10.38, wps=18542.8, ups=5.2, wpb=3564, bsz=99.8, num_updates=71900, lr=0.000117933, gnorm=1.192, train_wall=19, wall=0
2024-07-07 22:42:05 | INFO | train_inner | epoch 001:  72000 / 150053 loss=4.676, nll_loss=3.311, ppl=9.92, wps=18242, ups=5.18, wpb=3518.9, bsz=102.7, num_updates=72000, lr=0.000117851, gnorm=1.182, train_wall=19, wall=0
2024-07-07 22:42:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 22:42:07 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.631 | nll_loss 3.123 | ppl 8.71 | wps 53249.8 | wpb 2588.8 | bsz 75.3 | num_updates 72000 | best_loss 12.211
2024-07-07 22:42:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 22:42:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_72000.pt (epoch 1 @ 72000 updates, score 4.631) (writing took 3.5349733093753457 seconds)
2024-07-07 22:42:30 | INFO | train_inner | epoch 001:  72100 / 150053 loss=4.753, nll_loss=3.398, ppl=10.54, wps=14197.5, ups=3.99, wpb=3557.9, bsz=105.1, num_updates=72100, lr=0.000117769, gnorm=1.207, train_wall=19, wall=0
2024-07-07 22:42:49 | INFO | train_inner | epoch 001:  72200 / 150053 loss=4.724, nll_loss=3.365, ppl=10.31, wps=18332.6, ups=5.2, wpb=3525.6, bsz=99.7, num_updates=72200, lr=0.000117688, gnorm=1.24, train_wall=19, wall=0
2024-07-07 22:43:09 | INFO | train_inner | epoch 001:  72300 / 150053 loss=4.751, nll_loss=3.395, ppl=10.52, wps=18158.6, ups=5.18, wpb=3505.4, bsz=104, num_updates=72300, lr=0.000117606, gnorm=1.259, train_wall=19, wall=0
2024-07-07 22:43:28 | INFO | train_inner | epoch 001:  72400 / 150053 loss=4.731, nll_loss=3.374, ppl=10.37, wps=17970.9, ups=5.19, wpb=3461.6, bsz=93.7, num_updates=72400, lr=0.000117525, gnorm=1.222, train_wall=19, wall=0
2024-07-07 22:43:47 | INFO | train_inner | epoch 001:  72500 / 150053 loss=4.664, nll_loss=3.297, ppl=9.83, wps=18215, ups=5.13, wpb=3554.1, bsz=94.5, num_updates=72500, lr=0.000117444, gnorm=1.193, train_wall=19, wall=0
2024-07-07 22:44:07 | INFO | train_inner | epoch 001:  72600 / 150053 loss=4.674, nll_loss=3.309, ppl=9.91, wps=18628.7, ups=5.22, wpb=3568.5, bsz=110.7, num_updates=72600, lr=0.000117363, gnorm=1.192, train_wall=19, wall=0
2024-07-07 22:44:26 | INFO | train_inner | epoch 001:  72700 / 150053 loss=4.719, nll_loss=3.36, ppl=10.26, wps=18323, ups=5.2, wpb=3522.3, bsz=100.3, num_updates=72700, lr=0.000117282, gnorm=1.233, train_wall=19, wall=0
2024-07-07 22:44:45 | INFO | train_inner | epoch 001:  72800 / 150053 loss=4.618, nll_loss=3.245, ppl=9.48, wps=18291.1, ups=5.16, wpb=3541.6, bsz=106.6, num_updates=72800, lr=0.000117202, gnorm=1.183, train_wall=19, wall=0
2024-07-07 22:45:04 | INFO | train_inner | epoch 001:  72900 / 150053 loss=4.731, nll_loss=3.375, ppl=10.37, wps=18360.8, ups=5.16, wpb=3559.1, bsz=95.5, num_updates=72900, lr=0.000117121, gnorm=1.21, train_wall=19, wall=0
2024-07-07 22:45:24 | INFO | train_inner | epoch 001:  73000 / 150053 loss=4.689, nll_loss=3.326, ppl=10.03, wps=18229.7, ups=5.13, wpb=3551.1, bsz=97, num_updates=73000, lr=0.000117041, gnorm=1.195, train_wall=19, wall=0
2024-07-07 22:45:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 22:45:26 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.622 | nll_loss 3.1 | ppl 8.58 | wps 53701.3 | wpb 2588.8 | bsz 75.3 | num_updates 73000 | best_loss 12.211
2024-07-07 22:45:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 22:45:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_73000.pt (epoch 1 @ 73000 updates, score 4.622) (writing took 3.1237853514030576 seconds)
2024-07-07 22:45:49 | INFO | train_inner | epoch 001:  73100 / 150053 loss=4.638, nll_loss=3.268, ppl=9.63, wps=14507.6, ups=4.02, wpb=3612, bsz=107.3, num_updates=73100, lr=0.000116961, gnorm=1.178, train_wall=19, wall=0
2024-07-07 22:46:08 | INFO | train_inner | epoch 001:  73200 / 150053 loss=4.614, nll_loss=3.24, ppl=9.45, wps=18073.3, ups=5.17, wpb=3498.2, bsz=105.1, num_updates=73200, lr=0.000116881, gnorm=1.191, train_wall=19, wall=0
2024-07-07 22:46:28 | INFO | train_inner | epoch 001:  73300 / 150053 loss=4.644, nll_loss=3.274, ppl=9.68, wps=18180.4, ups=5.13, wpb=3542.6, bsz=103.6, num_updates=73300, lr=0.000116801, gnorm=1.193, train_wall=19, wall=0
2024-07-07 22:46:47 | INFO | train_inner | epoch 001:  73400 / 150053 loss=4.572, nll_loss=3.193, ppl=9.15, wps=18538.2, ups=5.14, wpb=3609.5, bsz=121.3, num_updates=73400, lr=0.000116722, gnorm=1.163, train_wall=19, wall=0
2024-07-07 22:47:06 | INFO | train_inner | epoch 001:  73500 / 150053 loss=4.708, nll_loss=3.348, ppl=10.18, wps=18255.3, ups=5.18, wpb=3524, bsz=103.1, num_updates=73500, lr=0.000116642, gnorm=1.268, train_wall=19, wall=0
2024-07-07 22:47:26 | INFO | train_inner | epoch 001:  73600 / 150053 loss=4.644, nll_loss=3.274, ppl=9.67, wps=18104.2, ups=5.16, wpb=3506.6, bsz=113.8, num_updates=73600, lr=0.000116563, gnorm=1.191, train_wall=19, wall=0
2024-07-07 22:47:45 | INFO | train_inner | epoch 001:  73700 / 150053 loss=4.641, nll_loss=3.272, ppl=9.66, wps=18160.6, ups=5.15, wpb=3523.4, bsz=111, num_updates=73700, lr=0.000116484, gnorm=1.21, train_wall=19, wall=0
2024-07-07 22:48:04 | INFO | train_inner | epoch 001:  73800 / 150053 loss=4.657, nll_loss=3.289, ppl=9.78, wps=18177.3, ups=5.22, wpb=3485.2, bsz=107.2, num_updates=73800, lr=0.000116405, gnorm=1.2, train_wall=19, wall=0
2024-07-07 22:48:24 | INFO | train_inner | epoch 001:  73900 / 150053 loss=4.585, nll_loss=3.207, ppl=9.23, wps=18193.5, ups=5.15, wpb=3531.7, bsz=123.7, num_updates=73900, lr=0.000116326, gnorm=1.181, train_wall=19, wall=0
2024-07-07 22:48:43 | INFO | train_inner | epoch 001:  74000 / 150053 loss=4.775, nll_loss=3.423, ppl=10.73, wps=18507.1, ups=5.18, wpb=3575.7, bsz=89.5, num_updates=74000, lr=0.000116248, gnorm=1.206, train_wall=19, wall=0
2024-07-07 22:48:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 22:48:45 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.596 | nll_loss 3.077 | ppl 8.44 | wps 53312.1 | wpb 2588.8 | bsz 75.3 | num_updates 74000 | best_loss 12.211
2024-07-07 22:48:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 22:48:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_74000.pt (epoch 1 @ 74000 updates, score 4.596) (writing took 3.2295540599152446 seconds)
2024-07-07 22:49:08 | INFO | train_inner | epoch 001:  74100 / 150053 loss=4.704, nll_loss=3.343, ppl=10.15, wps=14305.3, ups=4, wpb=3573.2, bsz=101.9, num_updates=74100, lr=0.000116169, gnorm=1.214, train_wall=19, wall=0
2024-07-07 22:49:28 | INFO | train_inner | epoch 001:  74200 / 150053 loss=4.673, nll_loss=3.307, ppl=9.9, wps=18208.2, ups=5.12, wpb=3554, bsz=106, num_updates=74200, lr=0.000116091, gnorm=1.245, train_wall=19, wall=0
2024-07-07 22:49:47 | INFO | train_inner | epoch 001:  74300 / 150053 loss=4.654, nll_loss=3.287, ppl=9.76, wps=18332.2, ups=5.13, wpb=3570.3, bsz=108.5, num_updates=74300, lr=0.000116013, gnorm=1.183, train_wall=19, wall=0
2024-07-07 22:50:07 | INFO | train_inner | epoch 001:  74400 / 150053 loss=4.567, nll_loss=3.187, ppl=9.11, wps=18237.9, ups=5.14, wpb=3551.5, bsz=108.8, num_updates=74400, lr=0.000115935, gnorm=1.175, train_wall=19, wall=0
2024-07-07 22:50:26 | INFO | train_inner | epoch 001:  74500 / 150053 loss=4.745, nll_loss=3.39, ppl=10.48, wps=18518.7, ups=5.18, wpb=3572.9, bsz=99, num_updates=74500, lr=0.000115857, gnorm=1.245, train_wall=19, wall=0
2024-07-07 22:50:45 | INFO | train_inner | epoch 001:  74600 / 150053 loss=4.734, nll_loss=3.377, ppl=10.39, wps=18334.5, ups=5.17, wpb=3543.9, bsz=94.5, num_updates=74600, lr=0.000115779, gnorm=1.182, train_wall=19, wall=0
2024-07-07 22:51:05 | INFO | train_inner | epoch 001:  74700 / 150053 loss=4.556, nll_loss=3.175, ppl=9.03, wps=18601.4, ups=5.11, wpb=3638.1, bsz=126.8, num_updates=74700, lr=0.000115702, gnorm=1.171, train_wall=19, wall=0
2024-07-07 22:51:24 | INFO | train_inner | epoch 001:  74800 / 150053 loss=4.594, nll_loss=3.217, ppl=9.3, wps=18314, ups=5.14, wpb=3565.7, bsz=99.6, num_updates=74800, lr=0.000115624, gnorm=1.19, train_wall=19, wall=0
2024-07-07 22:51:44 | INFO | train_inner | epoch 001:  74900 / 150053 loss=4.577, nll_loss=3.198, ppl=9.18, wps=18314, ups=5.18, wpb=3533.4, bsz=111.6, num_updates=74900, lr=0.000115547, gnorm=1.208, train_wall=19, wall=0
2024-07-07 22:52:03 | INFO | train_inner | epoch 001:  75000 / 150053 loss=4.618, nll_loss=3.245, ppl=9.48, wps=18358.3, ups=5.19, wpb=3538.9, bsz=112.3, num_updates=75000, lr=0.00011547, gnorm=1.199, train_wall=19, wall=0
2024-07-07 22:52:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 22:52:05 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.583 | nll_loss 3.056 | ppl 8.31 | wps 53825.6 | wpb 2588.8 | bsz 75.3 | num_updates 75000 | best_loss 12.211
2024-07-07 22:52:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 22:52:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_75000.pt (epoch 1 @ 75000 updates, score 4.583) (writing took 3.1968266805633903 seconds)
2024-07-07 22:52:28 | INFO | train_inner | epoch 001:  75100 / 150053 loss=4.557, nll_loss=3.175, ppl=9.03, wps=14494.6, ups=4.02, wpb=3606.2, bsz=119.8, num_updates=75100, lr=0.000115393, gnorm=1.172, train_wall=19, wall=0
2024-07-07 22:52:47 | INFO | train_inner | epoch 001:  75200 / 150053 loss=4.683, nll_loss=3.32, ppl=9.99, wps=18346.8, ups=5.17, wpb=3550.8, bsz=92.2, num_updates=75200, lr=0.000115316, gnorm=1.191, train_wall=19, wall=0
2024-07-07 22:53:07 | INFO | train_inner | epoch 001:  75300 / 150053 loss=4.655, nll_loss=3.288, ppl=9.77, wps=18050.5, ups=5.12, wpb=3526.9, bsz=105.6, num_updates=75300, lr=0.00011524, gnorm=1.219, train_wall=19, wall=0
2024-07-07 22:53:26 | INFO | train_inner | epoch 001:  75400 / 150053 loss=4.675, nll_loss=3.311, ppl=9.93, wps=18233.6, ups=5.27, wpb=3457, bsz=105.9, num_updates=75400, lr=0.000115163, gnorm=1.253, train_wall=19, wall=0
2024-07-07 22:53:45 | INFO | train_inner | epoch 001:  75500 / 150053 loss=4.59, nll_loss=3.213, ppl=9.28, wps=18331.5, ups=5.15, wpb=3557.9, bsz=116.8, num_updates=75500, lr=0.000115087, gnorm=1.202, train_wall=19, wall=0
2024-07-07 22:54:04 | INFO | train_inner | epoch 001:  75600 / 150053 loss=4.62, nll_loss=3.249, ppl=9.51, wps=17965.7, ups=5.19, wpb=3463.6, bsz=110.5, num_updates=75600, lr=0.000115011, gnorm=1.243, train_wall=19, wall=0
2024-07-07 22:54:24 | INFO | train_inner | epoch 001:  75700 / 150053 loss=4.705, nll_loss=3.344, ppl=10.16, wps=18312.1, ups=5.09, wpb=3597.3, bsz=95, num_updates=75700, lr=0.000114935, gnorm=1.189, train_wall=19, wall=0
2024-07-07 22:54:43 | INFO | train_inner | epoch 001:  75800 / 150053 loss=4.611, nll_loss=3.238, ppl=9.43, wps=18401.5, ups=5.13, wpb=3586.2, bsz=96.7, num_updates=75800, lr=0.000114859, gnorm=1.179, train_wall=19, wall=0
2024-07-07 22:55:03 | INFO | train_inner | epoch 001:  75900 / 150053 loss=4.646, nll_loss=3.277, ppl=9.69, wps=18463.8, ups=5.21, wpb=3545.5, bsz=94, num_updates=75900, lr=0.000114783, gnorm=1.213, train_wall=19, wall=0
2024-07-07 22:55:22 | INFO | train_inner | epoch 001:  76000 / 150053 loss=4.677, nll_loss=3.313, ppl=9.94, wps=18247.4, ups=5.18, wpb=3524.3, bsz=102, num_updates=76000, lr=0.000114708, gnorm=1.216, train_wall=19, wall=0
2024-07-07 22:55:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 22:55:24 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.555 | nll_loss 3.028 | ppl 8.16 | wps 53646.8 | wpb 2588.8 | bsz 75.3 | num_updates 76000 | best_loss 12.211
2024-07-07 22:55:24 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 22:55:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_76000.pt (epoch 1 @ 76000 updates, score 4.555) (writing took 3.1774432314559817 seconds)
2024-07-07 22:55:47 | INFO | train_inner | epoch 001:  76100 / 150053 loss=4.628, nll_loss=3.257, ppl=9.56, wps=14248.6, ups=4.05, wpb=3514.7, bsz=101.9, num_updates=76100, lr=0.000114632, gnorm=1.204, train_wall=19, wall=0
2024-07-07 22:56:06 | INFO | train_inner | epoch 001:  76200 / 150053 loss=4.693, nll_loss=3.332, ppl=10.07, wps=18250, ups=5.22, wpb=3495.4, bsz=90.5, num_updates=76200, lr=0.000114557, gnorm=1.243, train_wall=19, wall=0
2024-07-07 22:56:25 | INFO | train_inner | epoch 001:  76300 / 150053 loss=4.596, nll_loss=3.221, ppl=9.32, wps=18395.9, ups=5.19, wpb=3543.8, bsz=114.7, num_updates=76300, lr=0.000114482, gnorm=1.237, train_wall=19, wall=0
2024-07-07 22:56:44 | INFO | train_inner | epoch 001:  76400 / 150053 loss=4.659, nll_loss=3.293, ppl=9.8, wps=18280.5, ups=5.16, wpb=3544.3, bsz=103, num_updates=76400, lr=0.000114407, gnorm=1.222, train_wall=19, wall=0
2024-07-07 22:57:04 | INFO | train_inner | epoch 001:  76500 / 150053 loss=4.657, nll_loss=3.29, ppl=9.78, wps=18194.3, ups=5.15, wpb=3534.6, bsz=93.7, num_updates=76500, lr=0.000114332, gnorm=1.23, train_wall=19, wall=0
2024-07-07 22:57:23 | INFO | train_inner | epoch 001:  76600 / 150053 loss=4.592, nll_loss=3.216, ppl=9.29, wps=18747.2, ups=5.16, wpb=3632.4, bsz=115.4, num_updates=76600, lr=0.000114258, gnorm=1.173, train_wall=19, wall=0
2024-07-07 22:57:43 | INFO | train_inner | epoch 001:  76700 / 150053 loss=4.637, nll_loss=3.268, ppl=9.63, wps=18413, ups=5.18, wpb=3553.8, bsz=108, num_updates=76700, lr=0.000114183, gnorm=1.193, train_wall=19, wall=0
2024-07-07 22:58:02 | INFO | train_inner | epoch 001:  76800 / 150053 loss=4.616, nll_loss=3.244, ppl=9.47, wps=18310.2, ups=5.17, wpb=3543.6, bsz=109.8, num_updates=76800, lr=0.000114109, gnorm=1.243, train_wall=19, wall=0
2024-07-07 22:58:21 | INFO | train_inner | epoch 001:  76900 / 150053 loss=4.684, nll_loss=3.321, ppl=10, wps=18278.4, ups=5.23, wpb=3492.2, bsz=93.6, num_updates=76900, lr=0.000114035, gnorm=1.209, train_wall=19, wall=0
2024-07-07 22:58:40 | INFO | train_inner | epoch 001:  77000 / 150053 loss=4.536, nll_loss=3.152, ppl=8.89, wps=18278.5, ups=5.15, wpb=3551.6, bsz=125, num_updates=77000, lr=0.000113961, gnorm=1.261, train_wall=19, wall=0
2024-07-07 22:58:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 22:58:43 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.56 | nll_loss 3.031 | ppl 8.17 | wps 53622.3 | wpb 2588.8 | bsz 75.3 | num_updates 77000 | best_loss 12.211
2024-07-07 22:58:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 22:58:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_77000.pt (epoch 1 @ 77000 updates, score 4.56) (writing took 3.400855611078441 seconds)
2024-07-07 22:59:05 | INFO | train_inner | epoch 001:  77100 / 150053 loss=4.583, nll_loss=3.206, ppl=9.23, wps=14270.8, ups=3.99, wpb=3573.5, bsz=111.7, num_updates=77100, lr=0.000113887, gnorm=1.18, train_wall=19, wall=0
2024-07-07 22:59:24 | INFO | train_inner | epoch 001:  77200 / 150053 loss=4.682, nll_loss=3.318, ppl=9.98, wps=18386.3, ups=5.24, wpb=3505.6, bsz=93.8, num_updates=77200, lr=0.000113813, gnorm=1.209, train_wall=19, wall=0
2024-07-07 22:59:44 | INFO | train_inner | epoch 001:  77300 / 150053 loss=4.667, nll_loss=3.302, ppl=9.86, wps=18269.2, ups=5.25, wpb=3478.4, bsz=98.4, num_updates=77300, lr=0.000113739, gnorm=1.206, train_wall=19, wall=0
2024-07-07 23:00:03 | INFO | train_inner | epoch 001:  77400 / 150053 loss=4.612, nll_loss=3.239, ppl=9.44, wps=18464, ups=5.13, wpb=3597.1, bsz=96.9, num_updates=77400, lr=0.000113666, gnorm=1.169, train_wall=19, wall=0
2024-07-07 23:00:22 | INFO | train_inner | epoch 001:  77500 / 150053 loss=4.619, nll_loss=3.248, ppl=9.5, wps=18314.7, ups=5.15, wpb=3559.6, bsz=99.8, num_updates=77500, lr=0.000113592, gnorm=1.168, train_wall=19, wall=0
2024-07-07 23:00:42 | INFO | train_inner | epoch 001:  77600 / 150053 loss=4.579, nll_loss=3.202, ppl=9.2, wps=18226.5, ups=5.15, wpb=3536.2, bsz=97, num_updates=77600, lr=0.000113519, gnorm=1.179, train_wall=19, wall=0
2024-07-07 23:01:01 | INFO | train_inner | epoch 001:  77700 / 150053 loss=4.605, nll_loss=3.231, ppl=9.39, wps=18611.6, ups=5.11, wpb=3639.4, bsz=115.8, num_updates=77700, lr=0.000113446, gnorm=1.26, train_wall=19, wall=0
2024-07-07 23:01:21 | INFO | train_inner | epoch 001:  77800 / 150053 loss=4.666, nll_loss=3.301, ppl=9.86, wps=18605.2, ups=5.24, wpb=3553, bsz=98.2, num_updates=77800, lr=0.000113373, gnorm=1.217, train_wall=19, wall=0
2024-07-07 23:01:40 | INFO | train_inner | epoch 001:  77900 / 150053 loss=4.547, nll_loss=3.166, ppl=8.97, wps=18624.4, ups=5.16, wpb=3611.3, bsz=112.8, num_updates=77900, lr=0.0001133, gnorm=1.165, train_wall=19, wall=0
2024-07-07 23:01:59 | INFO | train_inner | epoch 001:  78000 / 150053 loss=4.592, nll_loss=3.217, ppl=9.3, wps=18109.4, ups=5.26, wpb=3446.1, bsz=90.4, num_updates=78000, lr=0.000113228, gnorm=1.279, train_wall=19, wall=0
2024-07-07 23:01:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 23:02:01 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.541 | nll_loss 3.012 | ppl 8.07 | wps 53731.3 | wpb 2588.8 | bsz 75.3 | num_updates 78000 | best_loss 12.211
2024-07-07 23:02:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 23:02:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_78000.pt (epoch 1 @ 78000 updates, score 4.541) (writing took 3.12128053791821 seconds)
2024-07-07 23:02:24 | INFO | train_inner | epoch 001:  78100 / 150053 loss=4.561, nll_loss=3.183, ppl=9.08, wps=14306.2, ups=4, wpb=3572.7, bsz=115.1, num_updates=78100, lr=0.000113155, gnorm=1.194, train_wall=19, wall=0
2024-07-07 23:02:43 | INFO | train_inner | epoch 001:  78200 / 150053 loss=4.669, nll_loss=3.304, ppl=9.88, wps=18535.7, ups=5.23, wpb=3544.5, bsz=94.6, num_updates=78200, lr=0.000113083, gnorm=1.206, train_wall=19, wall=0
2024-07-07 23:03:02 | INFO | train_inner | epoch 001:  78300 / 150053 loss=4.624, nll_loss=3.254, ppl=9.54, wps=18111.3, ups=5.15, wpb=3517.1, bsz=102.8, num_updates=78300, lr=0.000113011, gnorm=1.252, train_wall=19, wall=0
2024-07-07 23:03:22 | INFO | train_inner | epoch 001:  78400 / 150053 loss=4.563, nll_loss=3.185, ppl=9.09, wps=18131.9, ups=5.19, wpb=3492.1, bsz=115.2, num_updates=78400, lr=0.000112938, gnorm=1.215, train_wall=19, wall=0
2024-07-07 23:03:41 | INFO | train_inner | epoch 001:  78500 / 150053 loss=4.55, nll_loss=3.169, ppl=9, wps=18524.7, ups=5.14, wpb=3602.5, bsz=105.7, num_updates=78500, lr=0.000112867, gnorm=1.175, train_wall=19, wall=0
2024-07-07 23:04:01 | INFO | train_inner | epoch 001:  78600 / 150053 loss=4.602, nll_loss=3.228, ppl=9.37, wps=18474.3, ups=5.16, wpb=3580.8, bsz=94.6, num_updates=78600, lr=0.000112795, gnorm=1.17, train_wall=19, wall=0
2024-07-07 23:04:20 | INFO | train_inner | epoch 001:  78700 / 150053 loss=4.602, nll_loss=3.229, ppl=9.38, wps=18312.3, ups=5.18, wpb=3537.8, bsz=104.2, num_updates=78700, lr=0.000112723, gnorm=1.222, train_wall=19, wall=0
2024-07-07 23:04:39 | INFO | train_inner | epoch 001:  78800 / 150053 loss=4.554, nll_loss=3.173, ppl=9.02, wps=18291.5, ups=5.12, wpb=3574.7, bsz=98.7, num_updates=78800, lr=0.000112651, gnorm=1.178, train_wall=19, wall=0
2024-07-07 23:04:59 | INFO | train_inner | epoch 001:  78900 / 150053 loss=4.644, nll_loss=3.276, ppl=9.69, wps=18041.3, ups=5.22, wpb=3453.7, bsz=86.8, num_updates=78900, lr=0.00011258, gnorm=1.252, train_wall=19, wall=0
2024-07-07 23:05:18 | INFO | train_inner | epoch 001:  79000 / 150053 loss=4.609, nll_loss=3.236, ppl=9.42, wps=18401.6, ups=5.13, wpb=3584.5, bsz=110.2, num_updates=79000, lr=0.000112509, gnorm=1.267, train_wall=19, wall=0
2024-07-07 23:05:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 23:05:20 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.529 | nll_loss 3 | ppl 8 | wps 53559.9 | wpb 2588.8 | bsz 75.3 | num_updates 79000 | best_loss 12.211
2024-07-07 23:05:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 23:05:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_79000.pt (epoch 1 @ 79000 updates, score 4.529) (writing took 3.1920215636491776 seconds)
2024-07-07 23:05:43 | INFO | train_inner | epoch 001:  79100 / 150053 loss=4.58, nll_loss=3.204, ppl=9.21, wps=14270.8, ups=4.03, wpb=3544.9, bsz=100.6, num_updates=79100, lr=0.000112438, gnorm=1.161, train_wall=19, wall=0
2024-07-07 23:06:02 | INFO | train_inner | epoch 001:  79200 / 150053 loss=4.55, nll_loss=3.169, ppl=9, wps=18262.4, ups=5.14, wpb=3552.8, bsz=115.4, num_updates=79200, lr=0.000112367, gnorm=1.175, train_wall=19, wall=0
2024-07-07 23:06:22 | INFO | train_inner | epoch 001:  79300 / 150053 loss=4.538, nll_loss=3.157, ppl=8.92, wps=18138.4, ups=5.12, wpb=3545.5, bsz=108.7, num_updates=79300, lr=0.000112296, gnorm=1.187, train_wall=19, wall=0
2024-07-07 23:06:41 | INFO | train_inner | epoch 001:  79400 / 150053 loss=4.634, nll_loss=3.265, ppl=9.61, wps=18694.1, ups=5.16, wpb=3625.4, bsz=98.2, num_updates=79400, lr=0.000112225, gnorm=1.175, train_wall=19, wall=0
2024-07-07 23:07:01 | INFO | train_inner | epoch 001:  79500 / 150053 loss=4.585, nll_loss=3.21, ppl=9.25, wps=18321, ups=5.16, wpb=3550.9, bsz=108.2, num_updates=79500, lr=0.000112154, gnorm=1.174, train_wall=19, wall=0
2024-07-07 23:07:20 | INFO | train_inner | epoch 001:  79600 / 150053 loss=4.556, nll_loss=3.177, ppl=9.04, wps=17754.6, ups=5.16, wpb=3441.4, bsz=95.4, num_updates=79600, lr=0.000112084, gnorm=1.202, train_wall=19, wall=0
2024-07-07 23:07:39 | INFO | train_inner | epoch 001:  79700 / 150053 loss=4.631, nll_loss=3.262, ppl=9.59, wps=18211.5, ups=5.19, wpb=3507.3, bsz=105.3, num_updates=79700, lr=0.000112014, gnorm=1.214, train_wall=19, wall=0
2024-07-07 23:07:59 | INFO | train_inner | epoch 001:  79800 / 150053 loss=4.589, nll_loss=3.214, ppl=9.28, wps=18588.5, ups=5.16, wpb=3603.8, bsz=109.1, num_updates=79800, lr=0.000111943, gnorm=1.192, train_wall=19, wall=0
2024-07-07 23:08:18 | INFO | train_inner | epoch 001:  79900 / 150053 loss=4.435, nll_loss=3.038, ppl=8.21, wps=17814.1, ups=5.08, wpb=3504.8, bsz=126, num_updates=79900, lr=0.000111873, gnorm=1.183, train_wall=19, wall=0
2024-07-07 23:08:38 | INFO | train_inner | epoch 001:  80000 / 150053 loss=4.571, nll_loss=3.193, ppl=9.15, wps=17920.4, ups=5.18, wpb=3462.6, bsz=88.7, num_updates=80000, lr=0.000111803, gnorm=1.204, train_wall=19, wall=0
2024-07-07 23:08:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 23:08:40 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.491 | nll_loss 2.954 | ppl 7.75 | wps 53638.3 | wpb 2588.8 | bsz 75.3 | num_updates 80000 | best_loss 12.211
2024-07-07 23:08:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 23:08:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_80000.pt (epoch 1 @ 80000 updates, score 4.491) (writing took 3.237875065766275 seconds)
2024-07-07 23:09:03 | INFO | train_inner | epoch 001:  80100 / 150053 loss=4.609, nll_loss=3.237, ppl=9.43, wps=14551.1, ups=4.02, wpb=3622.4, bsz=103.5, num_updates=80100, lr=0.000111734, gnorm=1.178, train_wall=19, wall=0
2024-07-07 23:09:22 | INFO | train_inner | epoch 001:  80200 / 150053 loss=4.507, nll_loss=3.12, ppl=8.7, wps=18222.7, ups=5.1, wpb=3569.7, bsz=106.8, num_updates=80200, lr=0.000111664, gnorm=1.188, train_wall=19, wall=0
2024-07-07 23:09:41 | INFO | train_inner | epoch 001:  80300 / 150053 loss=4.548, nll_loss=3.168, ppl=8.99, wps=18596.3, ups=5.19, wpb=3586.3, bsz=119.6, num_updates=80300, lr=0.000111594, gnorm=1.24, train_wall=19, wall=0
2024-07-07 23:10:01 | INFO | train_inner | epoch 001:  80400 / 150053 loss=4.514, nll_loss=3.129, ppl=8.75, wps=18291.1, ups=5.11, wpb=3582.3, bsz=110.3, num_updates=80400, lr=0.000111525, gnorm=1.183, train_wall=19, wall=0
2024-07-07 23:10:20 | INFO | train_inner | epoch 001:  80500 / 150053 loss=4.56, nll_loss=3.182, ppl=9.08, wps=18626.6, ups=5.18, wpb=3594.8, bsz=107.6, num_updates=80500, lr=0.000111456, gnorm=1.176, train_wall=19, wall=0
2024-07-07 23:10:40 | INFO | train_inner | epoch 001:  80600 / 150053 loss=4.609, nll_loss=3.236, ppl=9.42, wps=18267.4, ups=5.17, wpb=3535.3, bsz=87.1, num_updates=80600, lr=0.000111386, gnorm=1.243, train_wall=19, wall=0
2024-07-07 23:10:59 | INFO | train_inner | epoch 001:  80700 / 150053 loss=4.49, nll_loss=3.101, ppl=8.58, wps=18133.4, ups=5.13, wpb=3536.3, bsz=97.1, num_updates=80700, lr=0.000111317, gnorm=1.174, train_wall=19, wall=0
2024-07-07 23:11:19 | INFO | train_inner | epoch 001:  80800 / 150053 loss=4.61, nll_loss=3.238, ppl=9.44, wps=18118.3, ups=5.12, wpb=3538.3, bsz=93, num_updates=80800, lr=0.000111249, gnorm=1.19, train_wall=19, wall=0
2024-07-07 23:11:38 | INFO | train_inner | epoch 001:  80900 / 150053 loss=4.593, nll_loss=3.219, ppl=9.31, wps=18515.6, ups=5.2, wpb=3563.5, bsz=94.2, num_updates=80900, lr=0.00011118, gnorm=1.199, train_wall=19, wall=0
2024-07-07 23:11:57 | INFO | train_inner | epoch 001:  81000 / 150053 loss=4.571, nll_loss=3.195, ppl=9.15, wps=18098.7, ups=5.15, wpb=3516.6, bsz=93.8, num_updates=81000, lr=0.000111111, gnorm=1.199, train_wall=19, wall=0
2024-07-07 23:11:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 23:12:00 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.479 | nll_loss 2.943 | ppl 7.69 | wps 53586.9 | wpb 2588.8 | bsz 75.3 | num_updates 81000 | best_loss 12.211
2024-07-07 23:12:00 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 23:12:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_81000.pt (epoch 1 @ 81000 updates, score 4.479) (writing took 3.1810698164626956 seconds)
2024-07-07 23:12:22 | INFO | train_inner | epoch 001:  81100 / 150053 loss=4.563, nll_loss=3.185, ppl=9.09, wps=14337.8, ups=4.04, wpb=3546.6, bsz=111.4, num_updates=81100, lr=0.000111043, gnorm=1.19, train_wall=19, wall=0
2024-07-07 23:12:42 | INFO | train_inner | epoch 001:  81200 / 150053 loss=4.547, nll_loss=3.166, ppl=8.97, wps=18176.2, ups=5.14, wpb=3535.9, bsz=98.6, num_updates=81200, lr=0.000110974, gnorm=1.191, train_wall=19, wall=0
2024-07-07 23:13:01 | INFO | train_inner | epoch 001:  81300 / 150053 loss=4.531, nll_loss=3.149, ppl=8.87, wps=17840.1, ups=5.15, wpb=3461.1, bsz=113.9, num_updates=81300, lr=0.000110906, gnorm=1.205, train_wall=19, wall=0
2024-07-07 23:13:20 | INFO | train_inner | epoch 001:  81400 / 150053 loss=4.567, nll_loss=3.189, ppl=9.12, wps=18094.9, ups=5.18, wpb=3490.4, bsz=92.7, num_updates=81400, lr=0.000110838, gnorm=1.185, train_wall=19, wall=0
2024-07-07 23:13:40 | INFO | train_inner | epoch 001:  81500 / 150053 loss=4.546, nll_loss=3.166, ppl=8.97, wps=18485.3, ups=5.2, wpb=3557.5, bsz=112.5, num_updates=81500, lr=0.00011077, gnorm=1.163, train_wall=19, wall=0
2024-07-07 23:13:59 | INFO | train_inner | epoch 001:  81600 / 150053 loss=4.509, nll_loss=3.124, ppl=8.72, wps=18631.6, ups=5.2, wpb=3583.5, bsz=106.6, num_updates=81600, lr=0.000110702, gnorm=1.197, train_wall=19, wall=0
2024-07-07 23:14:18 | INFO | train_inner | epoch 001:  81700 / 150053 loss=4.547, nll_loss=3.166, ppl=8.98, wps=18251.9, ups=5.16, wpb=3535.6, bsz=106.7, num_updates=81700, lr=0.000110634, gnorm=1.181, train_wall=19, wall=0
2024-07-07 23:14:37 | INFO | train_inner | epoch 001:  81800 / 150053 loss=4.601, nll_loss=3.229, ppl=9.37, wps=18135.8, ups=5.22, wpb=3473.4, bsz=92.4, num_updates=81800, lr=0.000110566, gnorm=1.198, train_wall=19, wall=0
2024-07-07 23:14:57 | INFO | train_inner | epoch 001:  81900 / 150053 loss=4.431, nll_loss=3.034, ppl=8.19, wps=18915, ups=5.07, wpb=3731.6, bsz=127.2, num_updates=81900, lr=0.000110499, gnorm=1.12, train_wall=20, wall=0
2024-07-07 23:15:16 | INFO | train_inner | epoch 001:  82000 / 150053 loss=4.573, nll_loss=3.196, ppl=9.16, wps=18387.8, ups=5.24, wpb=3508.2, bsz=103.4, num_updates=82000, lr=0.000110432, gnorm=1.194, train_wall=19, wall=0
2024-07-07 23:15:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 23:15:18 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.465 | nll_loss 2.926 | ppl 7.6 | wps 53774.5 | wpb 2588.8 | bsz 75.3 | num_updates 82000 | best_loss 12.211
2024-07-07 23:15:18 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 23:15:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_82000.pt (epoch 1 @ 82000 updates, score 4.465) (writing took 3.321019858121872 seconds)
2024-07-07 23:15:41 | INFO | train_inner | epoch 001:  82100 / 150053 loss=4.546, nll_loss=3.166, ppl=8.98, wps=14115.8, ups=3.97, wpb=3552.3, bsz=105.5, num_updates=82100, lr=0.000110364, gnorm=1.209, train_wall=19, wall=0
2024-07-07 23:16:01 | INFO | train_inner | epoch 001:  82200 / 150053 loss=4.561, nll_loss=3.182, ppl=9.08, wps=18049.8, ups=5.13, wpb=3519.4, bsz=87.8, num_updates=82200, lr=0.000110297, gnorm=1.176, train_wall=19, wall=0
2024-07-07 23:16:20 | INFO | train_inner | epoch 001:  82300 / 150053 loss=4.6, nll_loss=3.227, ppl=9.36, wps=18595, ups=5.2, wpb=3576.2, bsz=108.2, num_updates=82300, lr=0.00011023, gnorm=1.225, train_wall=19, wall=0
2024-07-07 23:16:40 | INFO | train_inner | epoch 001:  82400 / 150053 loss=4.465, nll_loss=3.073, ppl=8.42, wps=18398.9, ups=5.09, wpb=3616.9, bsz=102.6, num_updates=82400, lr=0.000110163, gnorm=1.123, train_wall=19, wall=0
2024-07-07 23:16:59 | INFO | train_inner | epoch 001:  82500 / 150053 loss=4.499, nll_loss=3.112, ppl=8.65, wps=18284.7, ups=5.14, wpb=3557.6, bsz=101.4, num_updates=82500, lr=0.000110096, gnorm=1.157, train_wall=19, wall=0
2024-07-07 23:17:19 | INFO | train_inner | epoch 001:  82600 / 150053 loss=4.577, nll_loss=3.202, ppl=9.2, wps=18262.2, ups=5.13, wpb=3556.5, bsz=83.4, num_updates=82600, lr=0.00011003, gnorm=1.184, train_wall=19, wall=0
2024-07-07 23:17:38 | INFO | train_inner | epoch 001:  82700 / 150053 loss=4.546, nll_loss=3.165, ppl=8.97, wps=18185.4, ups=5.11, wpb=3559.1, bsz=103.1, num_updates=82700, lr=0.000109963, gnorm=1.172, train_wall=19, wall=0
2024-07-07 23:17:58 | INFO | train_inner | epoch 001:  82800 / 150053 loss=4.561, nll_loss=3.183, ppl=9.08, wps=18243.5, ups=5.14, wpb=3548.5, bsz=95.7, num_updates=82800, lr=0.000109897, gnorm=1.189, train_wall=19, wall=0
2024-07-07 23:18:17 | INFO | train_inner | epoch 001:  82900 / 150053 loss=4.475, nll_loss=3.084, ppl=8.48, wps=18426.8, ups=5.2, wpb=3543.7, bsz=109.6, num_updates=82900, lr=0.00010983, gnorm=1.175, train_wall=19, wall=0
2024-07-07 23:18:36 | INFO | train_inner | epoch 001:  83000 / 150053 loss=4.474, nll_loss=3.084, ppl=8.48, wps=18239.5, ups=5.16, wpb=3533.6, bsz=119.4, num_updates=83000, lr=0.000109764, gnorm=1.172, train_wall=19, wall=0
2024-07-07 23:18:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 23:18:38 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.455 | nll_loss 2.916 | ppl 7.55 | wps 53491 | wpb 2588.8 | bsz 75.3 | num_updates 83000 | best_loss 12.211
2024-07-07 23:18:38 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 23:18:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_83000.pt (epoch 1 @ 83000 updates, score 4.455) (writing took 3.2728485940024257 seconds)
2024-07-07 23:19:01 | INFO | train_inner | epoch 001:  83100 / 150053 loss=4.558, nll_loss=3.18, ppl=9.06, wps=13924.5, ups=4, wpb=3476.9, bsz=101, num_updates=83100, lr=0.000109698, gnorm=1.21, train_wall=19, wall=0
2024-07-07 23:19:21 | INFO | train_inner | epoch 001:  83200 / 150053 loss=4.594, nll_loss=3.221, ppl=9.33, wps=18218.6, ups=5.15, wpb=3535.7, bsz=94, num_updates=83200, lr=0.000109632, gnorm=1.203, train_wall=19, wall=0
2024-07-07 23:19:40 | INFO | train_inner | epoch 001:  83300 / 150053 loss=4.558, nll_loss=3.182, ppl=9.08, wps=18421.9, ups=5.16, wpb=3572.5, bsz=113.9, num_updates=83300, lr=0.000109566, gnorm=1.207, train_wall=19, wall=0
2024-07-07 23:19:59 | INFO | train_inner | epoch 001:  83400 / 150053 loss=4.513, nll_loss=3.128, ppl=8.74, wps=18023.5, ups=5.17, wpb=3489.4, bsz=93.5, num_updates=83400, lr=0.000109501, gnorm=1.185, train_wall=19, wall=0
2024-07-07 23:20:19 | INFO | train_inner | epoch 001:  83500 / 150053 loss=4.552, nll_loss=3.173, ppl=9.02, wps=18423.5, ups=5.21, wpb=3533.7, bsz=100.2, num_updates=83500, lr=0.000109435, gnorm=1.188, train_wall=19, wall=0
2024-07-07 23:20:38 | INFO | train_inner | epoch 001:  83600 / 150053 loss=4.535, nll_loss=3.154, ppl=8.9, wps=18288.5, ups=5.16, wpb=3541.8, bsz=92.6, num_updates=83600, lr=0.00010937, gnorm=1.174, train_wall=19, wall=0
2024-07-07 23:20:57 | INFO | train_inner | epoch 001:  83700 / 150053 loss=4.539, nll_loss=3.158, ppl=8.93, wps=18292, ups=5.19, wpb=3523.6, bsz=90.2, num_updates=83700, lr=0.000109304, gnorm=1.223, train_wall=19, wall=0
2024-07-07 23:21:17 | INFO | train_inner | epoch 001:  83800 / 150053 loss=4.481, nll_loss=3.092, ppl=8.53, wps=18468.5, ups=5.12, wpb=3608, bsz=102.2, num_updates=83800, lr=0.000109239, gnorm=1.151, train_wall=19, wall=0
2024-07-07 23:21:36 | INFO | train_inner | epoch 001:  83900 / 150053 loss=4.542, nll_loss=3.162, ppl=8.95, wps=18422.8, ups=5.16, wpb=3570.9, bsz=93.4, num_updates=83900, lr=0.000109174, gnorm=1.214, train_wall=19, wall=0
2024-07-07 23:21:55 | INFO | train_inner | epoch 001:  84000 / 150053 loss=4.604, nll_loss=3.232, ppl=9.4, wps=18585.4, ups=5.21, wpb=3567.8, bsz=85.8, num_updates=84000, lr=0.000109109, gnorm=1.215, train_wall=19, wall=0
2024-07-07 23:21:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 23:21:57 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.421 | nll_loss 2.872 | ppl 7.32 | wps 53746.7 | wpb 2588.8 | bsz 75.3 | num_updates 84000 | best_loss 12.211
2024-07-07 23:21:57 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 23:22:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_84000.pt (epoch 1 @ 84000 updates, score 4.421) (writing took 3.1791992699727416 seconds)
2024-07-07 23:22:20 | INFO | train_inner | epoch 001:  84100 / 150053 loss=4.583, nll_loss=3.207, ppl=9.24, wps=14249.7, ups=4.05, wpb=3514.4, bsz=95.3, num_updates=84100, lr=0.000109044, gnorm=1.206, train_wall=19, wall=0
2024-07-07 23:22:39 | INFO | train_inner | epoch 001:  84200 / 150053 loss=4.589, nll_loss=3.215, ppl=9.29, wps=18535.2, ups=5.18, wpb=3576.7, bsz=92.9, num_updates=84200, lr=0.000108979, gnorm=1.2, train_wall=19, wall=0
2024-07-07 23:22:59 | INFO | train_inner | epoch 001:  84300 / 150053 loss=4.491, nll_loss=3.103, ppl=8.59, wps=18494.9, ups=5.14, wpb=3598.4, bsz=100.6, num_updates=84300, lr=0.000108915, gnorm=1.15, train_wall=19, wall=0
2024-07-07 23:23:18 | INFO | train_inner | epoch 001:  84400 / 150053 loss=4.46, nll_loss=3.069, ppl=8.39, wps=18315.8, ups=5.18, wpb=3537.2, bsz=104.3, num_updates=84400, lr=0.00010885, gnorm=1.179, train_wall=19, wall=0
2024-07-07 23:23:38 | INFO | train_inner | epoch 001:  84500 / 150053 loss=4.456, nll_loss=3.063, ppl=8.36, wps=18016.7, ups=5.08, wpb=3546.1, bsz=101.3, num_updates=84500, lr=0.000108786, gnorm=1.213, train_wall=20, wall=0
2024-07-07 23:23:57 | INFO | train_inner | epoch 001:  84600 / 150053 loss=4.477, nll_loss=3.088, ppl=8.5, wps=18259.1, ups=5.14, wpb=3551.5, bsz=99.6, num_updates=84600, lr=0.000108721, gnorm=1.182, train_wall=19, wall=0
2024-07-07 23:24:17 | INFO | train_inner | epoch 001:  84700 / 150053 loss=4.477, nll_loss=3.088, ppl=8.5, wps=18658.3, ups=5.14, wpb=3633.2, bsz=106.9, num_updates=84700, lr=0.000108657, gnorm=1.145, train_wall=19, wall=0
2024-07-07 23:24:36 | INFO | train_inner | epoch 001:  84800 / 150053 loss=4.435, nll_loss=3.041, ppl=8.23, wps=18313.2, ups=5.06, wpb=3619.9, bsz=106.9, num_updates=84800, lr=0.000108593, gnorm=1.155, train_wall=20, wall=0
2024-07-07 23:24:56 | INFO | train_inner | epoch 001:  84900 / 150053 loss=4.484, nll_loss=3.096, ppl=8.55, wps=18299.8, ups=5.19, wpb=3526.4, bsz=113.2, num_updates=84900, lr=0.000108529, gnorm=1.201, train_wall=19, wall=0
2024-07-07 23:25:15 | INFO | train_inner | epoch 001:  85000 / 150053 loss=4.411, nll_loss=3.013, ppl=8.07, wps=18061, ups=5.2, wpb=3475.2, bsz=113.9, num_updates=85000, lr=0.000108465, gnorm=1.185, train_wall=19, wall=0
2024-07-07 23:25:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 23:25:17 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.42 | nll_loss 2.874 | ppl 7.33 | wps 53607.4 | wpb 2588.8 | bsz 75.3 | num_updates 85000 | best_loss 12.211
2024-07-07 23:25:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 23:25:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_85000.pt (epoch 1 @ 85000 updates, score 4.42) (writing took 3.1994447112083435 seconds)
2024-07-07 23:25:40 | INFO | train_inner | epoch 001:  85100 / 150053 loss=4.471, nll_loss=3.081, ppl=8.46, wps=13908, ups=4.05, wpb=3437, bsz=97.4, num_updates=85100, lr=0.000108401, gnorm=1.176, train_wall=19, wall=0
2024-07-07 23:25:59 | INFO | train_inner | epoch 001:  85200 / 150053 loss=4.548, nll_loss=3.169, ppl=8.99, wps=18591.1, ups=5.19, wpb=3582.5, bsz=93.3, num_updates=85200, lr=0.000108338, gnorm=1.164, train_wall=19, wall=0
2024-07-07 23:26:18 | INFO | train_inner | epoch 001:  85300 / 150053 loss=4.445, nll_loss=3.051, ppl=8.29, wps=18377.7, ups=5.15, wpb=3567.5, bsz=114.7, num_updates=85300, lr=0.000108274, gnorm=1.19, train_wall=19, wall=0
2024-07-07 23:26:38 | INFO | train_inner | epoch 001:  85400 / 150053 loss=4.452, nll_loss=3.061, ppl=8.34, wps=18397.6, ups=5.16, wpb=3565.5, bsz=122.1, num_updates=85400, lr=0.000108211, gnorm=1.203, train_wall=19, wall=0
2024-07-07 23:26:57 | INFO | train_inner | epoch 001:  85500 / 150053 loss=4.457, nll_loss=3.065, ppl=8.37, wps=18468.8, ups=5.14, wpb=3594.9, bsz=107.9, num_updates=85500, lr=0.000108148, gnorm=1.158, train_wall=19, wall=0
2024-07-07 23:27:16 | INFO | train_inner | epoch 001:  85600 / 150053 loss=4.423, nll_loss=3.027, ppl=8.15, wps=18455.6, ups=5.2, wpb=3551.7, bsz=121, num_updates=85600, lr=0.000108084, gnorm=1.176, train_wall=19, wall=0
2024-07-07 23:27:36 | INFO | train_inner | epoch 001:  85700 / 150053 loss=4.475, nll_loss=3.087, ppl=8.5, wps=18186.7, ups=5.19, wpb=3505.8, bsz=102.2, num_updates=85700, lr=0.000108021, gnorm=1.173, train_wall=19, wall=0
2024-07-07 23:27:55 | INFO | train_inner | epoch 001:  85800 / 150053 loss=4.503, nll_loss=3.117, ppl=8.68, wps=18358.6, ups=5.19, wpb=3539.3, bsz=97.9, num_updates=85800, lr=0.000107958, gnorm=1.19, train_wall=19, wall=0
2024-07-07 23:28:14 | INFO | train_inner | epoch 001:  85900 / 150053 loss=4.426, nll_loss=3.031, ppl=8.17, wps=18425.2, ups=5.21, wpb=3536.3, bsz=107.4, num_updates=85900, lr=0.000107896, gnorm=1.178, train_wall=19, wall=0
2024-07-07 23:28:34 | INFO | train_inner | epoch 001:  86000 / 150053 loss=4.481, nll_loss=3.094, ppl=8.54, wps=18067.4, ups=5.13, wpb=3521.7, bsz=110.3, num_updates=86000, lr=0.000107833, gnorm=1.177, train_wall=19, wall=0
2024-07-07 23:28:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 23:28:36 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.418 | nll_loss 2.872 | ppl 7.32 | wps 53396.9 | wpb 2588.8 | bsz 75.3 | num_updates 86000 | best_loss 12.211
2024-07-07 23:28:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 23:28:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_86000.pt (epoch 1 @ 86000 updates, score 4.418) (writing took 3.1575714219361544 seconds)
2024-07-07 23:28:58 | INFO | train_inner | epoch 001:  86100 / 150053 loss=4.467, nll_loss=3.077, ppl=8.44, wps=14464.2, ups=4.05, wpb=3571.8, bsz=104.6, num_updates=86100, lr=0.00010777, gnorm=1.153, train_wall=19, wall=0
2024-07-07 23:29:18 | INFO | train_inner | epoch 001:  86200 / 150053 loss=4.438, nll_loss=3.046, ppl=8.26, wps=18218.6, ups=5.14, wpb=3544.7, bsz=112.6, num_updates=86200, lr=0.000107708, gnorm=1.164, train_wall=19, wall=0
2024-07-07 23:29:37 | INFO | train_inner | epoch 001:  86300 / 150053 loss=4.543, nll_loss=3.164, ppl=8.96, wps=18188.7, ups=5.19, wpb=3503.5, bsz=91.4, num_updates=86300, lr=0.000107645, gnorm=1.188, train_wall=19, wall=0
2024-07-07 23:29:57 | INFO | train_inner | epoch 001:  86400 / 150053 loss=4.43, nll_loss=3.035, ppl=8.2, wps=18362.4, ups=5.12, wpb=3589.6, bsz=106.6, num_updates=86400, lr=0.000107583, gnorm=1.149, train_wall=19, wall=0
2024-07-07 23:30:16 | INFO | train_inner | epoch 001:  86500 / 150053 loss=4.581, nll_loss=3.207, ppl=9.23, wps=18584.1, ups=5.25, wpb=3539.3, bsz=91.7, num_updates=86500, lr=0.000107521, gnorm=1.184, train_wall=19, wall=0
2024-07-07 23:30:35 | INFO | train_inner | epoch 001:  86600 / 150053 loss=4.39, nll_loss=2.99, ppl=7.94, wps=18358.3, ups=5.13, wpb=3575.7, bsz=114.6, num_updates=86600, lr=0.000107459, gnorm=1.132, train_wall=19, wall=0
2024-07-07 23:30:54 | INFO | train_inner | epoch 001:  86700 / 150053 loss=4.461, nll_loss=3.07, ppl=8.4, wps=17793.9, ups=5.17, wpb=3441.2, bsz=94.2, num_updates=86700, lr=0.000107397, gnorm=1.222, train_wall=19, wall=0
2024-07-07 23:31:14 | INFO | train_inner | epoch 001:  86800 / 150053 loss=4.584, nll_loss=3.209, ppl=9.25, wps=18394.1, ups=5.22, wpb=3523.1, bsz=84.6, num_updates=86800, lr=0.000107335, gnorm=1.189, train_wall=19, wall=0
2024-07-07 23:31:33 | INFO | train_inner | epoch 001:  86900 / 150053 loss=4.543, nll_loss=3.163, ppl=8.95, wps=18509, ups=5.16, wpb=3586.7, bsz=93, num_updates=86900, lr=0.000107273, gnorm=1.192, train_wall=19, wall=0
2024-07-07 23:31:52 | INFO | train_inner | epoch 001:  87000 / 150053 loss=4.417, nll_loss=3.021, ppl=8.12, wps=18381.6, ups=5.19, wpb=3543.5, bsz=106, num_updates=87000, lr=0.000107211, gnorm=1.173, train_wall=19, wall=0
2024-07-07 23:31:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 23:31:54 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.407 | nll_loss 2.862 | ppl 7.27 | wps 53597.3 | wpb 2588.8 | bsz 75.3 | num_updates 87000 | best_loss 12.211
2024-07-07 23:31:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 23:31:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_87000.pt (epoch 1 @ 87000 updates, score 4.407) (writing took 3.1800692100077868 seconds)
2024-07-07 23:32:17 | INFO | train_inner | epoch 001:  87100 / 150053 loss=4.546, nll_loss=3.167, ppl=8.98, wps=13677.2, ups=4.09, wpb=3341.4, bsz=86.4, num_updates=87100, lr=0.00010715, gnorm=1.254, train_wall=19, wall=0
2024-07-07 23:32:36 | INFO | train_inner | epoch 001:  87200 / 150053 loss=4.492, nll_loss=3.106, ppl=8.61, wps=18217.6, ups=5.16, wpb=3533.9, bsz=105.5, num_updates=87200, lr=0.000107088, gnorm=1.196, train_wall=19, wall=0
2024-07-07 23:32:55 | INFO | train_inner | epoch 001:  87300 / 150053 loss=4.448, nll_loss=3.056, ppl=8.32, wps=18179.1, ups=5.22, wpb=3481.5, bsz=99.5, num_updates=87300, lr=0.000107027, gnorm=1.198, train_wall=19, wall=0
2024-07-07 23:33:15 | INFO | train_inner | epoch 001:  87400 / 150053 loss=4.466, nll_loss=3.076, ppl=8.43, wps=18395.7, ups=5.15, wpb=3569.5, bsz=102.2, num_updates=87400, lr=0.000106966, gnorm=1.155, train_wall=19, wall=0
2024-07-07 23:33:34 | INFO | train_inner | epoch 001:  87500 / 150053 loss=4.383, nll_loss=2.981, ppl=7.9, wps=18541.1, ups=5.13, wpb=3611.5, bsz=114.7, num_updates=87500, lr=0.000106904, gnorm=1.15, train_wall=19, wall=0
2024-07-07 23:33:53 | INFO | train_inner | epoch 001:  87600 / 150053 loss=4.57, nll_loss=3.194, ppl=9.15, wps=18625.3, ups=5.19, wpb=3590.2, bsz=91.8, num_updates=87600, lr=0.000106843, gnorm=1.183, train_wall=19, wall=0
2024-07-07 23:34:13 | INFO | train_inner | epoch 001:  87700 / 150053 loss=4.349, nll_loss=2.944, ppl=7.7, wps=18289.2, ups=5.11, wpb=3581.4, bsz=113.7, num_updates=87700, lr=0.000106783, gnorm=1.131, train_wall=19, wall=0
2024-07-07 23:34:32 | INFO | train_inner | epoch 001:  87800 / 150053 loss=4.487, nll_loss=3.1, ppl=8.58, wps=18470.2, ups=5.2, wpb=3552, bsz=98.7, num_updates=87800, lr=0.000106722, gnorm=1.222, train_wall=19, wall=0
2024-07-07 23:34:52 | INFO | train_inner | epoch 001:  87900 / 150053 loss=4.503, nll_loss=3.119, ppl=8.69, wps=17850.2, ups=5.17, wpb=3454.9, bsz=90.6, num_updates=87900, lr=0.000106661, gnorm=1.213, train_wall=19, wall=0
2024-07-07 23:35:11 | INFO | train_inner | epoch 001:  88000 / 150053 loss=4.375, nll_loss=2.973, ppl=7.85, wps=18201.9, ups=5.15, wpb=3533.2, bsz=108.4, num_updates=88000, lr=0.0001066, gnorm=1.175, train_wall=19, wall=0
2024-07-07 23:35:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 23:35:13 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.401 | nll_loss 2.857 | ppl 7.24 | wps 53407.4 | wpb 2588.8 | bsz 75.3 | num_updates 88000 | best_loss 12.211
2024-07-07 23:35:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 23:35:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_88000.pt (epoch 1 @ 88000 updates, score 4.401) (writing took 3.1769942473620176 seconds)
2024-07-07 23:35:36 | INFO | train_inner | epoch 001:  88100 / 150053 loss=4.438, nll_loss=3.044, ppl=8.25, wps=14166.5, ups=4.06, wpb=3487.7, bsz=99.3, num_updates=88100, lr=0.00010654, gnorm=1.192, train_wall=19, wall=0
2024-07-07 23:35:55 | INFO | train_inner | epoch 001:  88200 / 150053 loss=4.426, nll_loss=3.03, ppl=8.17, wps=18119.5, ups=5.18, wpb=3494.9, bsz=106.1, num_updates=88200, lr=0.000106479, gnorm=1.18, train_wall=19, wall=0
2024-07-07 23:36:14 | INFO | train_inner | epoch 001:  88300 / 150053 loss=4.46, nll_loss=3.07, ppl=8.4, wps=18358.6, ups=5.15, wpb=3562.5, bsz=100.4, num_updates=88300, lr=0.000106419, gnorm=1.159, train_wall=19, wall=0
2024-07-07 23:36:34 | INFO | train_inner | epoch 001:  88400 / 150053 loss=4.507, nll_loss=3.124, ppl=8.72, wps=18328.8, ups=5.19, wpb=3528.3, bsz=96.4, num_updates=88400, lr=0.000106359, gnorm=1.178, train_wall=19, wall=0
2024-07-07 23:36:53 | INFO | train_inner | epoch 001:  88500 / 150053 loss=4.502, nll_loss=3.117, ppl=8.68, wps=18297.4, ups=5.2, wpb=3518.1, bsz=94.2, num_updates=88500, lr=0.000106299, gnorm=1.2, train_wall=19, wall=0
2024-07-07 23:37:12 | INFO | train_inner | epoch 001:  88600 / 150053 loss=4.517, nll_loss=3.135, ppl=8.79, wps=18403, ups=5.2, wpb=3541.1, bsz=87.2, num_updates=88600, lr=0.000106239, gnorm=1.181, train_wall=19, wall=0
2024-07-07 23:37:32 | INFO | train_inner | epoch 001:  88700 / 150053 loss=4.365, nll_loss=2.961, ppl=7.79, wps=18189.4, ups=5.13, wpb=3544.6, bsz=123.2, num_updates=88700, lr=0.000106179, gnorm=1.153, train_wall=19, wall=0
2024-07-07 23:37:51 | INFO | train_inner | epoch 001:  88800 / 150053 loss=4.459, nll_loss=3.07, ppl=8.4, wps=18262.7, ups=5.17, wpb=3534.4, bsz=107.5, num_updates=88800, lr=0.000106119, gnorm=1.206, train_wall=19, wall=0
2024-07-07 23:38:10 | INFO | train_inner | epoch 001:  88900 / 150053 loss=4.406, nll_loss=3.007, ppl=8.04, wps=18268, ups=5.17, wpb=3531.9, bsz=100, num_updates=88900, lr=0.000106059, gnorm=1.15, train_wall=19, wall=0
2024-07-07 23:38:30 | INFO | train_inner | epoch 001:  89000 / 150053 loss=4.434, nll_loss=3.04, ppl=8.23, wps=18331.5, ups=5.14, wpb=3568, bsz=99.8, num_updates=89000, lr=0.000106, gnorm=1.186, train_wall=19, wall=0
2024-07-07 23:38:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 23:38:32 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.377 | nll_loss 2.829 | ppl 7.11 | wps 53361.8 | wpb 2588.8 | bsz 75.3 | num_updates 89000 | best_loss 12.211
2024-07-07 23:38:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 23:38:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_89000.pt (epoch 1 @ 89000 updates, score 4.377) (writing took 3.1958560962229967 seconds)
2024-07-07 23:38:54 | INFO | train_inner | epoch 001:  89100 / 150053 loss=4.462, nll_loss=3.073, ppl=8.42, wps=14083.2, ups=4.04, wpb=3483.9, bsz=113.1, num_updates=89100, lr=0.00010594, gnorm=1.177, train_wall=19, wall=0
2024-07-07 23:39:14 | INFO | train_inner | epoch 001:  89200 / 150053 loss=4.465, nll_loss=3.075, ppl=8.43, wps=18253.7, ups=5.15, wpb=3546.7, bsz=90.2, num_updates=89200, lr=0.000105881, gnorm=1.183, train_wall=19, wall=0
2024-07-07 23:39:33 | INFO | train_inner | epoch 001:  89300 / 150053 loss=4.441, nll_loss=3.049, ppl=8.28, wps=18399.9, ups=5.16, wpb=3562.7, bsz=106.8, num_updates=89300, lr=0.000105822, gnorm=1.156, train_wall=19, wall=0
2024-07-07 23:39:53 | INFO | train_inner | epoch 001:  89400 / 150053 loss=4.483, nll_loss=3.096, ppl=8.55, wps=18194, ups=5.1, wpb=3569.9, bsz=84.1, num_updates=89400, lr=0.000105762, gnorm=1.183, train_wall=19, wall=0
2024-07-07 23:40:12 | INFO | train_inner | epoch 001:  89500 / 150053 loss=4.404, nll_loss=3.007, ppl=8.04, wps=18308.5, ups=5.2, wpb=3523, bsz=125, num_updates=89500, lr=0.000105703, gnorm=1.181, train_wall=19, wall=0
2024-07-07 23:40:31 | INFO | train_inner | epoch 001:  89600 / 150053 loss=4.442, nll_loss=3.049, ppl=8.28, wps=18741, ups=5.21, wpb=3599.4, bsz=118.8, num_updates=89600, lr=0.000105644, gnorm=1.143, train_wall=19, wall=0
2024-07-07 23:40:51 | INFO | train_inner | epoch 001:  89700 / 150053 loss=4.413, nll_loss=3.016, ppl=8.09, wps=18609.6, ups=5.15, wpb=3616.9, bsz=113.1, num_updates=89700, lr=0.000105585, gnorm=1.163, train_wall=19, wall=0
2024-07-07 23:41:10 | INFO | train_inner | epoch 001:  89800 / 150053 loss=4.31, nll_loss=2.9, ppl=7.46, wps=18374.5, ups=5.1, wpb=3601.5, bsz=111.7, num_updates=89800, lr=0.000105527, gnorm=1.139, train_wall=19, wall=0
2024-07-07 23:41:30 | INFO | train_inner | epoch 001:  89900 / 150053 loss=4.478, nll_loss=3.091, ppl=8.52, wps=18378.6, ups=5.2, wpb=3534.7, bsz=97.5, num_updates=89900, lr=0.000105468, gnorm=1.203, train_wall=19, wall=0
2024-07-07 23:41:49 | INFO | train_inner | epoch 001:  90000 / 150053 loss=4.397, nll_loss=2.999, ppl=7.99, wps=18268.5, ups=5.14, wpb=3555.9, bsz=102.2, num_updates=90000, lr=0.000105409, gnorm=1.16, train_wall=19, wall=0
2024-07-07 23:41:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 23:41:51 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.355 | nll_loss 2.802 | ppl 6.98 | wps 53478.9 | wpb 2588.8 | bsz 75.3 | num_updates 90000 | best_loss 12.211
2024-07-07 23:41:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 23:41:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_90000.pt (epoch 1 @ 90000 updates, score 4.355) (writing took 3.228198589757085 seconds)
2024-07-07 23:42:14 | INFO | train_inner | epoch 001:  90100 / 150053 loss=4.437, nll_loss=3.044, ppl=8.25, wps=14369.5, ups=4.05, wpb=3550.8, bsz=102.5, num_updates=90100, lr=0.000105351, gnorm=1.162, train_wall=19, wall=0
2024-07-07 23:42:33 | INFO | train_inner | epoch 001:  90200 / 150053 loss=4.475, nll_loss=3.088, ppl=8.5, wps=18316.3, ups=5.21, wpb=3517.5, bsz=92.8, num_updates=90200, lr=0.000105292, gnorm=1.152, train_wall=19, wall=0
2024-07-07 23:42:52 | INFO | train_inner | epoch 001:  90300 / 150053 loss=4.379, nll_loss=2.979, ppl=7.89, wps=18068.9, ups=5.14, wpb=3512.4, bsz=117.6, num_updates=90300, lr=0.000105234, gnorm=1.18, train_wall=19, wall=0
2024-07-07 23:43:12 | INFO | train_inner | epoch 001:  90400 / 150053 loss=4.423, nll_loss=3.028, ppl=8.16, wps=18113.9, ups=5.16, wpb=3507.5, bsz=98.2, num_updates=90400, lr=0.000105176, gnorm=1.21, train_wall=19, wall=0
2024-07-07 23:43:31 | INFO | train_inner | epoch 001:  90500 / 150053 loss=4.465, nll_loss=3.075, ppl=8.43, wps=18390.6, ups=5.19, wpb=3545.4, bsz=88.2, num_updates=90500, lr=0.000105118, gnorm=1.154, train_wall=19, wall=0
2024-07-07 23:43:50 | INFO | train_inner | epoch 001:  90600 / 150053 loss=4.416, nll_loss=3.021, ppl=8.12, wps=18361.7, ups=5.17, wpb=3551, bsz=107, num_updates=90600, lr=0.00010506, gnorm=1.183, train_wall=19, wall=0
2024-07-07 23:44:09 | INFO | train_inner | epoch 001:  90700 / 150053 loss=4.445, nll_loss=3.054, ppl=8.3, wps=17994.2, ups=5.26, wpb=3419.7, bsz=103.4, num_updates=90700, lr=0.000105002, gnorm=1.238, train_wall=19, wall=0
2024-07-07 23:44:29 | INFO | train_inner | epoch 001:  90800 / 150053 loss=4.356, nll_loss=2.952, ppl=7.74, wps=18136.1, ups=5.16, wpb=3514.7, bsz=101.2, num_updates=90800, lr=0.000104944, gnorm=1.154, train_wall=19, wall=0
2024-07-07 23:44:48 | INFO | train_inner | epoch 001:  90900 / 150053 loss=4.368, nll_loss=2.966, ppl=7.81, wps=18077.1, ups=5.14, wpb=3514.3, bsz=110.8, num_updates=90900, lr=0.000104886, gnorm=1.168, train_wall=19, wall=0
2024-07-07 23:45:08 | INFO | train_inner | epoch 001:  91000 / 150053 loss=4.421, nll_loss=3.026, ppl=8.14, wps=18232.2, ups=5.17, wpb=3528.6, bsz=102.2, num_updates=91000, lr=0.000104828, gnorm=1.171, train_wall=19, wall=0
2024-07-07 23:45:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 23:45:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.347 | nll_loss 2.793 | ppl 6.93 | wps 52962.8 | wpb 2588.8 | bsz 75.3 | num_updates 91000 | best_loss 12.211
2024-07-07 23:45:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 23:45:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_91000.pt (epoch 1 @ 91000 updates, score 4.347) (writing took 3.208042566664517 seconds)
2024-07-07 23:45:33 | INFO | train_inner | epoch 001:  91100 / 150053 loss=4.428, nll_loss=3.034, ppl=8.19, wps=14337.5, ups=3.99, wpb=3590.7, bsz=96.6, num_updates=91100, lr=0.000104771, gnorm=1.152, train_wall=19, wall=0
2024-07-07 23:45:52 | INFO | train_inner | epoch 001:  91200 / 150053 loss=4.349, nll_loss=2.945, ppl=7.7, wps=17965.5, ups=5.14, wpb=3494.5, bsz=107.4, num_updates=91200, lr=0.000104713, gnorm=1.16, train_wall=19, wall=0
2024-07-07 23:46:12 | INFO | train_inner | epoch 001:  91300 / 150053 loss=4.357, nll_loss=2.954, ppl=7.75, wps=18133.4, ups=5.1, wpb=3555.8, bsz=110.3, num_updates=91300, lr=0.000104656, gnorm=1.186, train_wall=19, wall=0
2024-07-07 23:46:31 | INFO | train_inner | epoch 001:  91400 / 150053 loss=4.462, nll_loss=3.074, ppl=8.42, wps=17989.1, ups=5.15, wpb=3494.2, bsz=97.4, num_updates=91400, lr=0.000104599, gnorm=1.189, train_wall=19, wall=0
2024-07-07 23:46:51 | INFO | train_inner | epoch 001:  91500 / 150053 loss=4.347, nll_loss=2.943, ppl=7.69, wps=18381, ups=5.11, wpb=3593.6, bsz=105.8, num_updates=91500, lr=0.000104542, gnorm=1.128, train_wall=19, wall=0
2024-07-07 23:47:10 | INFO | train_inner | epoch 001:  91600 / 150053 loss=4.361, nll_loss=2.958, ppl=7.77, wps=18328.5, ups=5.09, wpb=3599.1, bsz=104.6, num_updates=91600, lr=0.000104485, gnorm=1.159, train_wall=19, wall=0
2024-07-07 23:47:30 | INFO | train_inner | epoch 001:  91700 / 150053 loss=4.4, nll_loss=3.004, ppl=8.02, wps=18024.2, ups=5.18, wpb=3479.1, bsz=102.8, num_updates=91700, lr=0.000104428, gnorm=1.184, train_wall=19, wall=0
2024-07-07 23:47:49 | INFO | train_inner | epoch 001:  91800 / 150053 loss=4.365, nll_loss=2.962, ppl=7.79, wps=18228, ups=5.13, wpb=3553.7, bsz=109, num_updates=91800, lr=0.000104371, gnorm=1.144, train_wall=19, wall=0
2024-07-07 23:48:08 | INFO | train_inner | epoch 001:  91900 / 150053 loss=4.444, nll_loss=3.053, ppl=8.3, wps=18303.6, ups=5.24, wpb=3493.8, bsz=102, num_updates=91900, lr=0.000104314, gnorm=1.198, train_wall=19, wall=0
2024-07-07 23:48:28 | INFO | train_inner | epoch 001:  92000 / 150053 loss=4.382, nll_loss=2.982, ppl=7.9, wps=18117.7, ups=5.11, wpb=3546.9, bsz=120, num_updates=92000, lr=0.000104257, gnorm=1.149, train_wall=19, wall=0
2024-07-07 23:48:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 23:48:30 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.343 | nll_loss 2.793 | ppl 6.93 | wps 53207.8 | wpb 2588.8 | bsz 75.3 | num_updates 92000 | best_loss 12.211
2024-07-07 23:48:30 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 23:48:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_92000.pt (epoch 1 @ 92000 updates, score 4.343) (writing took 3.365207988768816 seconds)
2024-07-07 23:48:53 | INFO | train_inner | epoch 001:  92100 / 150053 loss=4.453, nll_loss=3.064, ppl=8.36, wps=13922.8, ups=4.01, wpb=3471, bsz=94.2, num_updates=92100, lr=0.000104201, gnorm=1.193, train_wall=19, wall=0
2024-07-07 23:49:12 | INFO | train_inner | epoch 001:  92200 / 150053 loss=4.448, nll_loss=3.057, ppl=8.32, wps=18243.6, ups=5.16, wpb=3537.6, bsz=98.2, num_updates=92200, lr=0.000104144, gnorm=1.17, train_wall=19, wall=0
2024-07-07 23:49:31 | INFO | train_inner | epoch 001:  92300 / 150053 loss=4.421, nll_loss=3.027, ppl=8.15, wps=17903.5, ups=5.17, wpb=3465.9, bsz=107, num_updates=92300, lr=0.000104088, gnorm=1.181, train_wall=19, wall=0
2024-07-07 23:49:51 | INFO | train_inner | epoch 001:  92400 / 150053 loss=4.457, nll_loss=3.068, ppl=8.38, wps=17991.9, ups=5.21, wpb=3455.6, bsz=96.4, num_updates=92400, lr=0.000104031, gnorm=1.203, train_wall=19, wall=0
2024-07-07 23:50:10 | INFO | train_inner | epoch 001:  92500 / 150053 loss=4.426, nll_loss=3.033, ppl=8.18, wps=18379.3, ups=5.15, wpb=3565.4, bsz=99.5, num_updates=92500, lr=0.000103975, gnorm=1.181, train_wall=19, wall=0
2024-07-07 23:50:29 | INFO | train_inner | epoch 001:  92600 / 150053 loss=4.433, nll_loss=3.04, ppl=8.22, wps=18110.3, ups=5.14, wpb=3520.3, bsz=92.2, num_updates=92600, lr=0.000103919, gnorm=1.168, train_wall=19, wall=0
2024-07-07 23:50:49 | INFO | train_inner | epoch 001:  92700 / 150053 loss=4.372, nll_loss=2.97, ppl=7.84, wps=18144.8, ups=5.14, wpb=3527.3, bsz=101.7, num_updates=92700, lr=0.000103863, gnorm=1.169, train_wall=19, wall=0
2024-07-07 23:51:08 | INFO | train_inner | epoch 001:  92800 / 150053 loss=4.379, nll_loss=2.979, ppl=7.88, wps=18280.6, ups=5.13, wpb=3560.1, bsz=110.4, num_updates=92800, lr=0.000103807, gnorm=1.148, train_wall=19, wall=0
2024-07-07 23:51:28 | INFO | train_inner | epoch 001:  92900 / 150053 loss=4.401, nll_loss=3.004, ppl=8.02, wps=18055.1, ups=5.15, wpb=3502.7, bsz=94.6, num_updates=92900, lr=0.000103751, gnorm=1.171, train_wall=19, wall=0
2024-07-07 23:51:47 | INFO | train_inner | epoch 001:  93000 / 150053 loss=4.37, nll_loss=2.969, ppl=7.83, wps=17996.5, ups=5.13, wpb=3509.7, bsz=105.1, num_updates=93000, lr=0.000103695, gnorm=1.158, train_wall=19, wall=0
2024-07-07 23:51:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 23:51:49 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.331 | nll_loss 2.78 | ppl 6.87 | wps 53431.7 | wpb 2588.8 | bsz 75.3 | num_updates 93000 | best_loss 12.211
2024-07-07 23:51:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 23:51:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_93000.pt (epoch 1 @ 93000 updates, score 4.331) (writing took 3.127732763066888 seconds)
2024-07-07 23:52:12 | INFO | train_inner | epoch 001:  93100 / 150053 loss=4.44, nll_loss=3.049, ppl=8.27, wps=14246, ups=4.02, wpb=3547.1, bsz=101.1, num_updates=93100, lr=0.000103639, gnorm=1.158, train_wall=19, wall=0
2024-07-07 23:52:32 | INFO | train_inner | epoch 001:  93200 / 150053 loss=4.365, nll_loss=2.963, ppl=7.8, wps=18092.2, ups=5.13, wpb=3525.3, bsz=96.2, num_updates=93200, lr=0.000103584, gnorm=1.162, train_wall=19, wall=0
2024-07-07 23:52:51 | INFO | train_inner | epoch 001:  93300 / 150053 loss=4.392, nll_loss=2.993, ppl=7.96, wps=18707.9, ups=5.19, wpb=3601.9, bsz=107.1, num_updates=93300, lr=0.000103528, gnorm=1.17, train_wall=19, wall=0
2024-07-07 23:53:10 | INFO | train_inner | epoch 001:  93400 / 150053 loss=4.412, nll_loss=3.017, ppl=8.1, wps=18196.2, ups=5.18, wpb=3514, bsz=103.8, num_updates=93400, lr=0.000103473, gnorm=1.153, train_wall=19, wall=0
2024-07-07 23:53:29 | INFO | train_inner | epoch 001:  93500 / 150053 loss=4.467, nll_loss=3.079, ppl=8.45, wps=18166.9, ups=5.23, wpb=3474.7, bsz=94.8, num_updates=93500, lr=0.000103418, gnorm=1.191, train_wall=19, wall=0
2024-07-07 23:53:49 | INFO | train_inner | epoch 001:  93600 / 150053 loss=4.503, nll_loss=3.12, ppl=8.69, wps=18347.7, ups=5.2, wpb=3529.8, bsz=86, num_updates=93600, lr=0.000103362, gnorm=1.182, train_wall=19, wall=0
2024-07-07 23:54:08 | INFO | train_inner | epoch 001:  93700 / 150053 loss=4.351, nll_loss=2.947, ppl=7.71, wps=18380.7, ups=5.11, wpb=3595.6, bsz=111.4, num_updates=93700, lr=0.000103307, gnorm=1.153, train_wall=19, wall=0
2024-07-07 23:54:28 | INFO | train_inner | epoch 001:  93800 / 150053 loss=4.457, nll_loss=3.068, ppl=8.38, wps=18476.8, ups=5.17, wpb=3576.8, bsz=92.5, num_updates=93800, lr=0.000103252, gnorm=1.138, train_wall=19, wall=0
2024-07-07 23:54:47 | INFO | train_inner | epoch 001:  93900 / 150053 loss=4.426, nll_loss=3.032, ppl=8.18, wps=18473.2, ups=5.18, wpb=3564, bsz=101, num_updates=93900, lr=0.000103197, gnorm=1.149, train_wall=19, wall=0
2024-07-07 23:55:06 | INFO | train_inner | epoch 001:  94000 / 150053 loss=4.363, nll_loss=2.961, ppl=7.78, wps=18286.9, ups=5.16, wpb=3543.4, bsz=109.1, num_updates=94000, lr=0.000103142, gnorm=1.162, train_wall=19, wall=0
2024-07-07 23:55:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 23:55:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.331 | nll_loss 2.78 | ppl 6.87 | wps 53600.7 | wpb 2588.8 | bsz 75.3 | num_updates 94000 | best_loss 12.211
2024-07-07 23:55:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 23:55:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_94000.pt (epoch 1 @ 94000 updates, score 4.331) (writing took 3.287615144625306 seconds)
2024-07-07 23:55:31 | INFO | train_inner | epoch 001:  94100 / 150053 loss=4.311, nll_loss=2.902, ppl=7.47, wps=14307.2, ups=3.96, wpb=3613.8, bsz=116.3, num_updates=94100, lr=0.000103087, gnorm=1.143, train_wall=20, wall=0
2024-07-07 23:55:51 | INFO | train_inner | epoch 001:  94200 / 150053 loss=4.399, nll_loss=3.002, ppl=8.01, wps=18556.4, ups=5.13, wpb=3616.4, bsz=110, num_updates=94200, lr=0.000103033, gnorm=1.219, train_wall=19, wall=0
2024-07-07 23:56:10 | INFO | train_inner | epoch 001:  94300 / 150053 loss=4.346, nll_loss=2.942, ppl=7.68, wps=18183.8, ups=5.13, wpb=3544, bsz=105.3, num_updates=94300, lr=0.000102978, gnorm=1.157, train_wall=19, wall=0
2024-07-07 23:56:30 | INFO | train_inner | epoch 001:  94400 / 150053 loss=4.322, nll_loss=2.916, ppl=7.55, wps=18168.5, ups=5.16, wpb=3518.6, bsz=109.4, num_updates=94400, lr=0.000102923, gnorm=1.124, train_wall=19, wall=0
2024-07-07 23:56:49 | INFO | train_inner | epoch 001:  94500 / 150053 loss=4.35, nll_loss=2.947, ppl=7.71, wps=18476.4, ups=5.18, wpb=3567.5, bsz=113.4, num_updates=94500, lr=0.000102869, gnorm=1.146, train_wall=19, wall=0
2024-07-07 23:57:08 | INFO | train_inner | epoch 001:  94600 / 150053 loss=4.379, nll_loss=2.98, ppl=7.89, wps=18399.2, ups=5.19, wpb=3545.4, bsz=104.6, num_updates=94600, lr=0.000102815, gnorm=1.164, train_wall=19, wall=0
2024-07-07 23:57:28 | INFO | train_inner | epoch 001:  94700 / 150053 loss=4.447, nll_loss=3.058, ppl=8.33, wps=18129.2, ups=5.23, wpb=3468.8, bsz=94.8, num_updates=94700, lr=0.00010276, gnorm=1.196, train_wall=19, wall=0
2024-07-07 23:57:47 | INFO | train_inner | epoch 001:  94800 / 150053 loss=4.409, nll_loss=3.014, ppl=8.08, wps=18038.5, ups=5.19, wpb=3478.5, bsz=93.2, num_updates=94800, lr=0.000102706, gnorm=1.184, train_wall=19, wall=0
2024-07-07 23:58:06 | INFO | train_inner | epoch 001:  94900 / 150053 loss=4.376, nll_loss=2.978, ppl=7.88, wps=18389.4, ups=5.2, wpb=3536.8, bsz=113.7, num_updates=94900, lr=0.000102652, gnorm=1.176, train_wall=19, wall=0
2024-07-07 23:58:25 | INFO | train_inner | epoch 001:  95000 / 150053 loss=4.342, nll_loss=2.937, ppl=7.66, wps=17992.9, ups=5.18, wpb=3471, bsz=105.9, num_updates=95000, lr=0.000102598, gnorm=1.155, train_wall=19, wall=0
2024-07-07 23:58:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-07 23:58:28 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.317 | nll_loss 2.769 | ppl 6.81 | wps 48497.2 | wpb 2588.8 | bsz 75.3 | num_updates 95000 | best_loss 12.211
2024-07-07 23:58:28 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-07 23:58:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_95000.pt (epoch 1 @ 95000 updates, score 4.317) (writing took 3.1708228001371026 seconds)
2024-07-07 23:58:51 | INFO | train_inner | epoch 001:  95100 / 150053 loss=4.376, nll_loss=2.976, ppl=7.87, wps=14295, ups=3.93, wpb=3632.9, bsz=102.6, num_updates=95100, lr=0.000102544, gnorm=1.119, train_wall=19, wall=0
2024-07-07 23:59:10 | INFO | train_inner | epoch 001:  95200 / 150053 loss=4.472, nll_loss=3.085, ppl=8.48, wps=18138.4, ups=5.23, wpb=3465.1, bsz=95.9, num_updates=95200, lr=0.00010249, gnorm=1.233, train_wall=19, wall=0
2024-07-07 23:59:30 | INFO | train_inner | epoch 001:  95300 / 150053 loss=4.317, nll_loss=2.91, ppl=7.51, wps=18204.4, ups=5.08, wpb=3581, bsz=102.5, num_updates=95300, lr=0.000102436, gnorm=1.123, train_wall=19, wall=0
2024-07-07 23:59:49 | INFO | train_inner | epoch 001:  95400 / 150053 loss=4.421, nll_loss=3.027, ppl=8.15, wps=18364.6, ups=5.17, wpb=3554, bsz=95.8, num_updates=95400, lr=0.000102383, gnorm=1.189, train_wall=19, wall=0
2024-07-08 00:00:08 | INFO | train_inner | epoch 001:  95500 / 150053 loss=4.411, nll_loss=3.016, ppl=8.09, wps=18017.4, ups=5.2, wpb=3464.3, bsz=94.4, num_updates=95500, lr=0.000102329, gnorm=1.183, train_wall=19, wall=0
2024-07-08 00:00:28 | INFO | train_inner | epoch 001:  95600 / 150053 loss=4.325, nll_loss=2.918, ppl=7.56, wps=18718.4, ups=5.1, wpb=3668, bsz=103.4, num_updates=95600, lr=0.000102275, gnorm=1.112, train_wall=19, wall=0
2024-07-08 00:00:47 | INFO | train_inner | epoch 001:  95700 / 150053 loss=4.271, nll_loss=2.857, ppl=7.25, wps=18203.2, ups=5.17, wpb=3521, bsz=114.8, num_updates=95700, lr=0.000102222, gnorm=1.187, train_wall=19, wall=0
2024-07-08 00:01:07 | INFO | train_inner | epoch 001:  95800 / 150053 loss=4.397, nll_loss=3.001, ppl=8.01, wps=18241.7, ups=5.13, wpb=3556.8, bsz=101.8, num_updates=95800, lr=0.000102169, gnorm=1.157, train_wall=19, wall=0
2024-07-08 00:01:26 | INFO | train_inner | epoch 001:  95900 / 150053 loss=4.431, nll_loss=3.039, ppl=8.22, wps=17978.6, ups=5.18, wpb=3469.9, bsz=92.3, num_updates=95900, lr=0.000102115, gnorm=1.179, train_wall=19, wall=0
2024-07-08 00:01:45 | INFO | train_inner | epoch 001:  96000 / 150053 loss=4.348, nll_loss=2.945, ppl=7.7, wps=18320.3, ups=5.17, wpb=3541.7, bsz=100, num_updates=96000, lr=0.000102062, gnorm=1.141, train_wall=19, wall=0
2024-07-08 00:01:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-08 00:01:47 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.315 | nll_loss 2.758 | ppl 6.76 | wps 53107.2 | wpb 2588.8 | bsz 75.3 | num_updates 96000 | best_loss 12.211
2024-07-08 00:01:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-08 00:01:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_96000.pt (epoch 1 @ 96000 updates, score 4.315) (writing took 3.196542624384165 seconds)
2024-07-08 00:02:10 | INFO | train_inner | epoch 001:  96100 / 150053 loss=4.354, nll_loss=2.951, ppl=7.73, wps=14439.4, ups=3.99, wpb=3618.1, bsz=105.7, num_updates=96100, lr=0.000102009, gnorm=1.13, train_wall=19, wall=0
2024-07-08 00:02:30 | INFO | train_inner | epoch 001:  96200 / 150053 loss=4.39, nll_loss=2.992, ppl=7.96, wps=18368, ups=5.14, wpb=3571.1, bsz=89.9, num_updates=96200, lr=0.000101956, gnorm=1.138, train_wall=19, wall=0
2024-07-08 00:02:49 | INFO | train_inner | epoch 001:  96300 / 150053 loss=4.322, nll_loss=2.915, ppl=7.54, wps=18490.8, ups=5.16, wpb=3581.9, bsz=106.2, num_updates=96300, lr=0.000101903, gnorm=1.122, train_wall=19, wall=0
2024-07-08 00:03:09 | INFO | train_inner | epoch 001:  96400 / 150053 loss=4.313, nll_loss=2.905, ppl=7.49, wps=18161, ups=5.08, wpb=3574.8, bsz=111.8, num_updates=96400, lr=0.00010185, gnorm=1.126, train_wall=20, wall=0
2024-07-08 00:03:28 | INFO | train_inner | epoch 001:  96500 / 150053 loss=4.319, nll_loss=2.913, ppl=7.53, wps=18084, ups=5.1, wpb=3543.6, bsz=107, num_updates=96500, lr=0.000101797, gnorm=1.164, train_wall=19, wall=0
2024-07-08 00:03:48 | INFO | train_inner | epoch 001:  96600 / 150053 loss=4.445, nll_loss=3.055, ppl=8.31, wps=18569.9, ups=5.17, wpb=3589.9, bsz=103.6, num_updates=96600, lr=0.000101745, gnorm=1.167, train_wall=19, wall=0
2024-07-08 00:04:07 | INFO | train_inner | epoch 001:  96700 / 150053 loss=4.378, nll_loss=2.98, ppl=7.89, wps=18139.2, ups=5.15, wpb=3521.4, bsz=88.9, num_updates=96700, lr=0.000101692, gnorm=1.149, train_wall=19, wall=0
2024-07-08 00:04:27 | INFO | train_inner | epoch 001:  96800 / 150053 loss=4.335, nll_loss=2.93, ppl=7.62, wps=18290.8, ups=5.13, wpb=3563.3, bsz=100.6, num_updates=96800, lr=0.000101639, gnorm=1.166, train_wall=19, wall=0
2024-07-08 00:04:46 | INFO | train_inner | epoch 001:  96900 / 150053 loss=4.413, nll_loss=3.018, ppl=8.1, wps=18414.8, ups=5.15, wpb=3572.7, bsz=109.3, num_updates=96900, lr=0.000101587, gnorm=1.164, train_wall=19, wall=0
2024-07-08 00:05:05 | INFO | train_inner | epoch 001:  97000 / 150053 loss=4.384, nll_loss=2.986, ppl=7.92, wps=18299.6, ups=5.12, wpb=3575.1, bsz=103.9, num_updates=97000, lr=0.000101535, gnorm=1.162, train_wall=19, wall=0
2024-07-08 00:05:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-08 00:05:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.321 | nll_loss 2.761 | ppl 6.78 | wps 53216.8 | wpb 2588.8 | bsz 75.3 | num_updates 97000 | best_loss 12.211
2024-07-08 00:05:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-08 00:05:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_97000.pt (epoch 1 @ 97000 updates, score 4.321) (writing took 3.5269185192883015 seconds)
2024-07-08 00:05:31 | INFO | train_inner | epoch 001:  97100 / 150053 loss=4.367, nll_loss=2.966, ppl=7.81, wps=14366.8, ups=3.95, wpb=3638.5, bsz=99.1, num_updates=97100, lr=0.000101482, gnorm=1.129, train_wall=19, wall=0
2024-07-08 00:05:50 | INFO | train_inner | epoch 001:  97200 / 150053 loss=4.357, nll_loss=2.955, ppl=7.75, wps=18404.9, ups=5.12, wpb=3595.9, bsz=115.4, num_updates=97200, lr=0.00010143, gnorm=1.153, train_wall=19, wall=0
2024-07-08 00:06:10 | INFO | train_inner | epoch 001:  97300 / 150053 loss=4.426, nll_loss=3.034, ppl=8.19, wps=18334.6, ups=5.2, wpb=3526.7, bsz=95, num_updates=97300, lr=0.000101378, gnorm=1.187, train_wall=19, wall=0
2024-07-08 00:06:29 | INFO | train_inner | epoch 001:  97400 / 150053 loss=4.399, nll_loss=3.004, ppl=8.02, wps=18067.2, ups=5.26, wpb=3434.6, bsz=103, num_updates=97400, lr=0.000101326, gnorm=1.261, train_wall=19, wall=0
2024-07-08 00:06:48 | INFO | train_inner | epoch 001:  97500 / 150053 loss=4.396, nll_loss=3, ppl=8, wps=18476.2, ups=5.18, wpb=3567.6, bsz=100.8, num_updates=97500, lr=0.000101274, gnorm=1.155, train_wall=19, wall=0
2024-07-08 00:07:07 | INFO | train_inner | epoch 001:  97600 / 150053 loss=4.343, nll_loss=2.94, ppl=7.68, wps=18451.4, ups=5.15, wpb=3580.7, bsz=107.8, num_updates=97600, lr=0.000101222, gnorm=1.141, train_wall=19, wall=0
2024-07-08 00:07:27 | INFO | train_inner | epoch 001:  97700 / 150053 loss=4.355, nll_loss=2.953, ppl=7.75, wps=18214.6, ups=5.15, wpb=3535.2, bsz=107.8, num_updates=97700, lr=0.00010117, gnorm=1.167, train_wall=19, wall=0
2024-07-08 00:07:46 | INFO | train_inner | epoch 001:  97800 / 150053 loss=4.379, nll_loss=2.982, ppl=7.9, wps=18250, ups=5.22, wpb=3495.6, bsz=116.9, num_updates=97800, lr=0.000101118, gnorm=1.183, train_wall=19, wall=0
2024-07-08 00:08:05 | INFO | train_inner | epoch 001:  97900 / 150053 loss=4.324, nll_loss=2.918, ppl=7.56, wps=18241.2, ups=5.13, wpb=3552.8, bsz=109.4, num_updates=97900, lr=0.000101067, gnorm=1.156, train_wall=19, wall=0
2024-07-08 00:08:25 | INFO | train_inner | epoch 001:  98000 / 150053 loss=4.295, nll_loss=2.884, ppl=7.38, wps=18511.9, ups=5.1, wpb=3627.3, bsz=114.4, num_updates=98000, lr=0.000101015, gnorm=1.11, train_wall=19, wall=0
2024-07-08 00:08:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-08 00:08:27 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.281 | nll_loss 2.724 | ppl 6.61 | wps 53262.9 | wpb 2588.8 | bsz 75.3 | num_updates 98000 | best_loss 12.211
2024-07-08 00:08:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-08 00:08:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_98000.pt (epoch 1 @ 98000 updates, score 4.281) (writing took 3.229926520958543 seconds)
2024-07-08 00:08:50 | INFO | train_inner | epoch 001:  98100 / 150053 loss=4.447, nll_loss=3.058, ppl=8.33, wps=14145.6, ups=4.05, wpb=3490.6, bsz=91.8, num_updates=98100, lr=0.000100964, gnorm=1.185, train_wall=19, wall=0
2024-07-08 00:09:09 | INFO | train_inner | epoch 001:  98200 / 150053 loss=4.342, nll_loss=2.94, ppl=7.67, wps=18467.4, ups=5.2, wpb=3553.5, bsz=129.4, num_updates=98200, lr=0.000100912, gnorm=1.14, train_wall=19, wall=0
2024-07-08 00:09:28 | INFO | train_inner | epoch 001:  98300 / 150053 loss=4.414, nll_loss=3.021, ppl=8.12, wps=18628.1, ups=5.2, wpb=3584, bsz=105.7, num_updates=98300, lr=0.000100861, gnorm=1.169, train_wall=19, wall=0
2024-07-08 00:09:47 | INFO | train_inner | epoch 001:  98400 / 150053 loss=4.429, nll_loss=3.037, ppl=8.21, wps=18439.9, ups=5.22, wpb=3532.2, bsz=99.4, num_updates=98400, lr=0.00010081, gnorm=1.174, train_wall=19, wall=0
2024-07-08 00:10:07 | INFO | train_inner | epoch 001:  98500 / 150053 loss=4.385, nll_loss=2.988, ppl=7.94, wps=18407.7, ups=5.16, wpb=3566.9, bsz=98.1, num_updates=98500, lr=0.000100759, gnorm=1.153, train_wall=19, wall=0
2024-07-08 00:10:26 | INFO | train_inner | epoch 001:  98600 / 150053 loss=4.423, nll_loss=3.031, ppl=8.17, wps=18123.2, ups=5.18, wpb=3499.2, bsz=88.4, num_updates=98600, lr=0.000100707, gnorm=1.184, train_wall=19, wall=0
2024-07-08 00:10:45 | INFO | train_inner | epoch 001:  98700 / 150053 loss=4.361, nll_loss=2.96, ppl=7.78, wps=18207.3, ups=5.17, wpb=3523.9, bsz=104.1, num_updates=98700, lr=0.000100656, gnorm=1.151, train_wall=19, wall=0
2024-07-08 00:11:05 | INFO | train_inner | epoch 001:  98800 / 150053 loss=4.342, nll_loss=2.939, ppl=7.67, wps=18270.5, ups=5.14, wpb=3555.5, bsz=105, num_updates=98800, lr=0.000100605, gnorm=1.137, train_wall=19, wall=0
2024-07-08 00:11:24 | INFO | train_inner | epoch 001:  98900 / 150053 loss=4.379, nll_loss=2.981, ppl=7.9, wps=18191.7, ups=5.18, wpb=3508.8, bsz=100.2, num_updates=98900, lr=0.000100555, gnorm=1.159, train_wall=19, wall=0
2024-07-08 00:11:44 | INFO | train_inner | epoch 001:  99000 / 150053 loss=4.369, nll_loss=2.969, ppl=7.83, wps=18429.4, ups=5.12, wpb=3596, bsz=102.1, num_updates=99000, lr=0.000100504, gnorm=1.137, train_wall=19, wall=0
2024-07-08 00:11:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-08 00:11:46 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.287 | nll_loss 2.733 | ppl 6.65 | wps 53528.1 | wpb 2588.8 | bsz 75.3 | num_updates 99000 | best_loss 12.211
2024-07-08 00:11:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-08 00:11:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_99000.pt (epoch 1 @ 99000 updates, score 4.287) (writing took 3.2189089506864548 seconds)
2024-07-08 00:12:08 | INFO | train_inner | epoch 001:  99100 / 150053 loss=4.336, nll_loss=2.932, ppl=7.63, wps=14061.9, ups=4.03, wpb=3485.1, bsz=97.4, num_updates=99100, lr=0.000100453, gnorm=1.189, train_wall=19, wall=0
2024-07-08 00:12:28 | INFO | train_inner | epoch 001:  99200 / 150053 loss=4.306, nll_loss=2.897, ppl=7.45, wps=18654.6, ups=5.17, wpb=3607.7, bsz=122.6, num_updates=99200, lr=0.000100402, gnorm=1.149, train_wall=19, wall=0
2024-07-08 00:12:47 | INFO | train_inner | epoch 001:  99300 / 150053 loss=4.393, nll_loss=2.997, ppl=7.98, wps=18279.3, ups=5.17, wpb=3536.5, bsz=95.9, num_updates=99300, lr=0.000100352, gnorm=1.136, train_wall=19, wall=0
2024-07-08 00:13:06 | INFO | train_inner | epoch 001:  99400 / 150053 loss=4.45, nll_loss=3.062, ppl=8.35, wps=18337, ups=5.22, wpb=3512.7, bsz=95, num_updates=99400, lr=0.000100301, gnorm=1.184, train_wall=19, wall=0
2024-07-08 00:13:26 | INFO | train_inner | epoch 001:  99500 / 150053 loss=4.483, nll_loss=3.099, ppl=8.57, wps=17861.2, ups=5.13, wpb=3484.2, bsz=79.2, num_updates=99500, lr=0.000100251, gnorm=1.175, train_wall=19, wall=0
2024-07-08 00:13:45 | INFO | train_inner | epoch 001:  99600 / 150053 loss=4.323, nll_loss=2.918, ppl=7.56, wps=18353, ups=5.15, wpb=3566.3, bsz=109.5, num_updates=99600, lr=0.000100201, gnorm=1.15, train_wall=19, wall=0
2024-07-08 00:14:05 | INFO | train_inner | epoch 001:  99700 / 150053 loss=4.344, nll_loss=2.941, ppl=7.68, wps=18466, ups=5.16, wpb=3580.6, bsz=99.8, num_updates=99700, lr=0.00010015, gnorm=1.123, train_wall=19, wall=0
2024-07-08 00:14:24 | INFO | train_inner | epoch 001:  99800 / 150053 loss=4.364, nll_loss=2.965, ppl=7.81, wps=17985.8, ups=5.19, wpb=3467.4, bsz=99.2, num_updates=99800, lr=0.0001001, gnorm=1.177, train_wall=19, wall=0
2024-07-08 00:14:43 | INFO | train_inner | epoch 001:  99900 / 150053 loss=4.332, nll_loss=2.928, ppl=7.61, wps=18556.9, ups=5.18, wpb=3580.3, bsz=128.9, num_updates=99900, lr=0.00010005, gnorm=1.187, train_wall=19, wall=0
2024-07-08 00:15:02 | INFO | train_inner | epoch 001:  100000 / 150053 loss=4.358, nll_loss=2.957, ppl=7.77, wps=18356.6, ups=5.19, wpb=3534.4, bsz=110, num_updates=100000, lr=0.0001, gnorm=1.179, train_wall=19, wall=0
2024-07-08 00:15:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-08 00:15:05 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.251 | nll_loss 2.695 | ppl 6.47 | wps 52808.1 | wpb 2588.8 | bsz 75.3 | num_updates 100000 | best_loss 12.211
2024-07-08 00:15:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-08 00:15:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_100000.pt (epoch 1 @ 100000 updates, score 4.251) (writing took 3.190072196535766 seconds)
2024-07-08 00:15:08 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-08 00:15:08 | INFO | train | epoch 001 | loss 5.39 | nll_loss 4.123 | ppl 17.43 | wps 17637.5 | ups 4.97 | wpb 3546.4 | bsz 103.7 | num_updates 100000 | lr 0.0001 | gnorm 1.089 | train_wall 19212 | wall 0
2024-07-08 00:15:08 | INFO | fairseq_cli.train | done training in 17974.2 seconds
