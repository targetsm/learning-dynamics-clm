2024-07-14 16:55:52 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/wmt22.sep.tokenized.fr-de', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='fr', srcdict=None, target_lang='de', task='translation', tensorboard_logdir=None, testpref='/local/home/ggabriel/ma/data/tl/wmt22frde/full/wmt22.sep.tokenized.fr-de/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/local/home/ggabriel/ma/data/tl/wmt22frde/full/wmt22.sep.tokenized.fr-de/train', user_dir=None, validpref='/local/home/ggabriel/ma/data/tl/wmt22frde/full/wmt22.sep.tokenized.fr-de/valid', workers=8)
2024-07-14 17:02:45 | INFO | fairseq_cli.preprocess | [fr] Dictionary: 10016 types
2024-07-14 17:12:37 | INFO | fairseq_cli.preprocess | [fr] /local/home/ggabriel/ma/data/tl/wmt22frde/full/wmt22.sep.tokenized.fr-de/train.fr: 15571322 sents, 551269582 tokens, 0.0% replaced by <unk>
2024-07-14 17:12:37 | INFO | fairseq_cli.preprocess | [fr] Dictionary: 10016 types
2024-07-14 17:12:37 | INFO | fairseq_cli.preprocess | [fr] /local/home/ggabriel/ma/data/tl/wmt22frde/full/wmt22.sep.tokenized.fr-de/valid.fr: 3238 sents, 122712 tokens, 0.0% replaced by <unk>
2024-07-14 17:12:37 | INFO | fairseq_cli.preprocess | [fr] Dictionary: 10016 types
2024-07-14 17:12:38 | INFO | fairseq_cli.preprocess | [fr] /local/home/ggabriel/ma/data/tl/wmt22frde/full/wmt22.sep.tokenized.fr-de/test.fr: 1619 sents, 61356 tokens, 0.0% replaced by <unk>
2024-07-14 17:12:38 | INFO | fairseq_cli.preprocess | [de] Dictionary: 10032 types
2024-07-14 17:22:18 | INFO | fairseq_cli.preprocess | [de] /local/home/ggabriel/ma/data/tl/wmt22frde/full/wmt22.sep.tokenized.fr-de/train.de: 15571322 sents, 532430094 tokens, 0.0% replaced by <unk>
2024-07-14 17:22:18 | INFO | fairseq_cli.preprocess | [de] Dictionary: 10032 types
2024-07-14 17:22:18 | INFO | fairseq_cli.preprocess | [de] /local/home/ggabriel/ma/data/tl/wmt22frde/full/wmt22.sep.tokenized.fr-de/valid.de: 3238 sents, 111318 tokens, 0.0% replaced by <unk>
2024-07-14 17:22:18 | INFO | fairseq_cli.preprocess | [de] Dictionary: 10032 types
2024-07-14 17:22:18 | INFO | fairseq_cli.preprocess | [de] /local/home/ggabriel/ma/data/tl/wmt22frde/full/wmt22.sep.tokenized.fr-de/test.de: 1619 sents, 55659 tokens, 0.0% replaced by <unk>
2024-07-14 17:22:18 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/wmt22.sep.tokenized.fr-de
2024-07-14 17:22:20 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt22.sep.tokenized.fr-de', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=1000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=100, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-14 17:22:20 | INFO | fairseq.tasks.translation | [fr] dictionary: 10016 types
2024-07-14 17:22:20 | INFO | fairseq.tasks.translation | [de] dictionary: 10032 types
2024-07-14 17:22:20 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.fr
2024-07-14 17:22:20 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.de
2024-07-14 17:22:20 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de valid fr-de 3238 examples
2024-07-14 17:22:21 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10016, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10032, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=10032, bias=False)
  )
)
2024-07-14 17:22:21 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-14 17:22:21 | INFO | fairseq_cli.train | model: transformer_wmt_en_de (TransformerModel)
2024-07-14 17:22:21 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-14 17:22:21 | INFO | fairseq_cli.train | num. model params: 54403072 (num. trained: 54403072)
2024-07-14 17:22:27 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-14 17:22:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-14 17:22:27 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-14 17:22:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-14 17:22:27 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-14 17:22:27 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-14 17:22:27 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/checkpoint_last.pt
2024-07-14 17:22:27 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-14 17:22:28 | INFO | fairseq.data.data_utils | loaded 15571322 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.fr
2024-07-14 17:22:29 | INFO | fairseq.data.data_utils | loaded 15571322 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.de
2024-07-14 17:22:29 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de train fr-de 15571322 examples
2024-07-14 17:22:46 | INFO | fairseq.trainer | begin training epoch 1
2024-07-14 17:23:11 | INFO | train_inner | epoch 001:    100 / 150053 loss=13.019, nll_loss=12.906, ppl=7677.34, wps=14946.8, ups=4.31, wpb=3474.8, bsz=91.2, num_updates=100, lr=1.25e-05, gnorm=2.77, train_wall=24, wall=44
2024-07-14 17:23:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-14 17:23:13 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.174 | nll_loss 11.96 | ppl 3983.09 | wps 44360.2 | wpb 2588.8 | bsz 75.3 | num_updates 100
2024-07-14 17:23:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:23:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_100.pt (epoch 1 @ 100 updates, score 12.174) (writing took 2.5437174243852496 seconds)
2024-07-14 17:23:39 | INFO | train_inner | epoch 001:    200 / 150053 loss=11.812, nll_loss=11.558, ppl=3014.18, wps=12639.6, ups=3.54, wpb=3570.1, bsz=80.2, num_updates=200, lr=2.5e-05, gnorm=1.253, train_wall=23, wall=72
2024-07-14 17:23:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:23:41 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.23 | nll_loss 10.893 | ppl 1902.02 | wps 43721.2 | wpb 2588.8 | bsz 75.3 | num_updates 200 | best_loss 12.174
2024-07-14 17:23:41 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:23:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_200.pt (epoch 1 @ 200 updates, score 11.23) (writing took 9.595552208833396 seconds)
2024-07-14 17:24:14 | INFO | train_inner | epoch 001:    300 / 150053 loss=10.936, nll_loss=10.54, ppl=1489.12, wps=10017.3, ups=2.8, wpb=3574.9, bsz=95.8, num_updates=300, lr=3.75e-05, gnorm=1.495, train_wall=23, wall=108
2024-07-14 17:24:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:24:17 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.598 | nll_loss 10.114 | ppl 1107.96 | wps 43901.8 | wpb 2588.8 | bsz 75.3 | num_updates 300 | best_loss 12.174
2024-07-14 17:24:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:24:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_300.pt (epoch 1 @ 300 updates, score 10.598) (writing took 4.988289794884622 seconds)
2024-07-14 17:24:46 | INFO | train_inner | epoch 001:    400 / 150053 loss=10.517, nll_loss=10.006, ppl=1027.93, wps=11314.7, ups=3.16, wpb=3576.8, bsz=110.7, num_updates=400, lr=5e-05, gnorm=1.42, train_wall=24, wall=139
2024-07-14 17:24:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:24:49 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.476 | nll_loss 9.906 | ppl 959.12 | wps 43831.9 | wpb 2588.8 | bsz 75.3 | num_updates 400 | best_loss 12.174
2024-07-14 17:24:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:24:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_400.pt (epoch 1 @ 400 updates, score 10.476) (writing took 5.604093820787966 seconds)
2024-07-14 17:25:18 | INFO | train_inner | epoch 001:    500 / 150053 loss=10.382, nll_loss=9.82, ppl=903.8, wps=11281.7, ups=3.18, wpb=3545.1, bsz=106.6, num_updates=500, lr=6.25e-05, gnorm=1.243, train_wall=23, wall=171
2024-07-14 17:25:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:25:20 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.351 | nll_loss 9.742 | ppl 856.54 | wps 43887.4 | wpb 2588.8 | bsz 75.3 | num_updates 500 | best_loss 12.174
2024-07-14 17:25:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:25:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_500.pt (epoch 1 @ 500 updates, score 10.351) (writing took 11.525143588893116 seconds)
2024-07-14 17:25:55 | INFO | train_inner | epoch 001:    600 / 150053 loss=10.295, nll_loss=9.714, ppl=839.79, wps=9616.9, ups=2.67, wpb=3598.9, bsz=98.6, num_updates=600, lr=7.5e-05, gnorm=1.304, train_wall=23, wall=208
2024-07-14 17:25:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:25:58 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.319 | nll_loss 9.723 | ppl 845.05 | wps 44025.7 | wpb 2588.8 | bsz 75.3 | num_updates 600 | best_loss 12.174
2024-07-14 17:25:58 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:26:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_600.pt (epoch 1 @ 600 updates, score 10.319) (writing took 4.852355835027993 seconds)
2024-07-14 17:26:26 | INFO | train_inner | epoch 001:    700 / 150053 loss=10.187, nll_loss=9.59, ppl=770.93, wps=11561.7, ups=3.25, wpb=3559.1, bsz=89.2, num_updates=700, lr=8.75e-05, gnorm=1.339, train_wall=23, wall=239
2024-07-14 17:26:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:26:28 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.144 | nll_loss 9.53 | ppl 739.16 | wps 44043.1 | wpb 2588.8 | bsz 75.3 | num_updates 700 | best_loss 12.174
2024-07-14 17:26:28 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:26:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_700.pt (epoch 1 @ 700 updates, score 10.144) (writing took 6.331362513825297 seconds)
2024-07-14 17:26:58 | INFO | train_inner | epoch 001:    800 / 150053 loss=9.979, nll_loss=9.356, ppl=655.32, wps=11026.3, ups=3.14, wpb=3517, bsz=99.8, num_updates=800, lr=0.0001, gnorm=1.351, train_wall=23, wall=271
2024-07-14 17:26:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:27:00 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.967 | nll_loss 9.355 | ppl 655.04 | wps 43893.4 | wpb 2588.8 | bsz 75.3 | num_updates 800 | best_loss 12.174
2024-07-14 17:27:00 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:27:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_800.pt (epoch 1 @ 800 updates, score 9.967) (writing took 11.793061124160886 seconds)
2024-07-14 17:27:35 | INFO | train_inner | epoch 001:    900 / 150053 loss=9.783, nll_loss=9.131, ppl=560.78, wps=9270.1, ups=2.66, wpb=3486.5, bsz=101.7, num_updates=900, lr=0.0001125, gnorm=1.455, train_wall=23, wall=308
2024-07-14 17:27:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:27:38 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.677 | nll_loss 8.984 | ppl 506.22 | wps 43368.9 | wpb 2588.8 | bsz 75.3 | num_updates 900 | best_loss 12.174
2024-07-14 17:27:38 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:27:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_900.pt (epoch 1 @ 900 updates, score 9.677) (writing took 5.505301694385707 seconds)
2024-07-14 17:28:07 | INFO | train_inner | epoch 001:   1000 / 150053 loss=9.588, nll_loss=8.907, ppl=480.18, wps=11196.2, ups=3.12, wpb=3589.7, bsz=108.6, num_updates=1000, lr=0.000125, gnorm=1.506, train_wall=24, wall=340
2024-07-14 17:28:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:28:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.568 | nll_loss 8.854 | ppl 462.69 | wps 43866.6 | wpb 2588.8 | bsz 75.3 | num_updates 1000 | best_loss 12.174
2024-07-14 17:28:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:28:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 9.568) (writing took 7.259645275771618 seconds)
2024-07-14 17:28:17 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-14 17:28:17 | INFO | train | epoch 001 | loss 10.646 | nll_loss 10.148 | ppl 1134.99 | wps 10753.7 | ups 3.03 | wpb 3549.3 | bsz 98.3 | num_updates 1000 | lr 0.000125 | gnorm 1.514 | train_wall 232 | wall 350
2024-07-14 17:28:17 | INFO | fairseq_cli.train | done training in 331.1 seconds
2024-07-14 17:28:21 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt22.sep.tokenized.fr-de', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=10000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=500, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-14 17:28:21 | INFO | fairseq.tasks.translation | [fr] dictionary: 10016 types
2024-07-14 17:28:21 | INFO | fairseq.tasks.translation | [de] dictionary: 10032 types
2024-07-14 17:28:21 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.fr
2024-07-14 17:28:21 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.de
2024-07-14 17:28:21 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de valid fr-de 3238 examples
2024-07-14 17:28:21 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10016, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10032, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=10032, bias=False)
  )
)
2024-07-14 17:28:21 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-14 17:28:21 | INFO | fairseq_cli.train | model: transformer_wmt_en_de (TransformerModel)
2024-07-14 17:28:21 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-14 17:28:21 | INFO | fairseq_cli.train | num. model params: 54403072 (num. trained: 54403072)
2024-07-14 17:28:27 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-14 17:28:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-14 17:28:27 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-14 17:28:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-14 17:28:27 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-14 17:28:27 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-14 17:28:28 | INFO | fairseq.trainer | loaded checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 1000 updates)
2024-07-14 17:28:28 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-14 17:28:28 | INFO | fairseq.data.data_utils | loaded 15571322 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.fr
2024-07-14 17:28:29 | INFO | fairseq.data.data_utils | loaded 15571322 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.de
2024-07-14 17:28:29 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de train fr-de 15571322 examples
2024-07-14 17:28:47 | INFO | fairseq.trainer | begin training epoch 1
2024-07-14 17:29:11 | INFO | train_inner | epoch 001:   1100 / 150053 loss=9.412, nll_loss=8.705, ppl=417.28, wps=7937.8, ups=2.21, wpb=3597.6, bsz=98.8, num_updates=1100, lr=0.0001375, gnorm=1.392, train_wall=23, wall=0
2024-07-14 17:29:34 | INFO | train_inner | epoch 001:   1200 / 150053 loss=9.255, nll_loss=8.525, ppl=368.29, wps=15446.5, ups=4.32, wpb=3573.8, bsz=106.6, num_updates=1200, lr=0.00015, gnorm=1.509, train_wall=23, wall=0
2024-07-14 17:29:57 | INFO | train_inner | epoch 001:   1300 / 150053 loss=9.1, nll_loss=8.346, ppl=325.31, wps=15506.2, ups=4.39, wpb=3536, bsz=107.9, num_updates=1300, lr=0.0001625, gnorm=1.428, train_wall=23, wall=0
2024-07-14 17:30:19 | INFO | train_inner | epoch 001:   1400 / 150053 loss=8.978, nll_loss=8.206, ppl=295.34, wps=15141, ups=4.37, wpb=3462.6, bsz=101.4, num_updates=1400, lr=0.000175, gnorm=1.506, train_wall=23, wall=0
2024-07-14 17:30:42 | INFO | train_inner | epoch 001:   1500 / 150053 loss=8.817, nll_loss=8.023, ppl=260.18, wps=15635.8, ups=4.44, wpb=3522.5, bsz=93.2, num_updates=1500, lr=0.0001875, gnorm=1.675, train_wall=22, wall=0
2024-07-14 17:30:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-14 17:30:45 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.063 | nll_loss 8.255 | ppl 305.5 | wps 43882.4 | wpb 2588.8 | bsz 75.3 | num_updates 1500 | best_loss 12.174
2024-07-14 17:30:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:30:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_1500.pt (epoch 1 @ 1500 updates, score 9.063) (writing took 5.206559774465859 seconds)
2024-07-14 17:31:13 | INFO | train_inner | epoch 001:   1600 / 150053 loss=8.676, nll_loss=7.864, ppl=232.99, wps=11684.1, ups=3.27, wpb=3577.1, bsz=112, num_updates=1600, lr=0.0002, gnorm=1.441, train_wall=23, wall=0
2024-07-14 17:31:35 | INFO | train_inner | epoch 001:   1700 / 150053 loss=8.534, nll_loss=7.702, ppl=208.2, wps=15326.1, ups=4.38, wpb=3495.3, bsz=96.6, num_updates=1700, lr=0.0002125, gnorm=1.478, train_wall=23, wall=0
2024-07-14 17:31:58 | INFO | train_inner | epoch 001:   1800 / 150053 loss=8.427, nll_loss=7.582, ppl=191.57, wps=15539.4, ups=4.37, wpb=3552.6, bsz=99.4, num_updates=1800, lr=0.000225, gnorm=1.506, train_wall=23, wall=0
2024-07-14 17:32:21 | INFO | train_inner | epoch 001:   1900 / 150053 loss=8.345, nll_loss=7.486, ppl=179.28, wps=15269.9, ups=4.39, wpb=3474.4, bsz=124, num_updates=1900, lr=0.0002375, gnorm=1.778, train_wall=23, wall=0
2024-07-14 17:32:44 | INFO | train_inner | epoch 001:   2000 / 150053 loss=8.246, nll_loss=7.373, ppl=165.82, wps=15276.8, ups=4.38, wpb=3484.9, bsz=102.2, num_updates=2000, lr=0.00025, gnorm=1.667, train_wall=23, wall=0
2024-07-14 17:32:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:32:46 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.307 | nll_loss 7.381 | ppl 166.66 | wps 43870.4 | wpb 2588.8 | bsz 75.3 | num_updates 2000 | best_loss 12.174
2024-07-14 17:32:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:32:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 8.307) (writing took 4.917856101877987 seconds)
2024-07-14 17:33:14 | INFO | train_inner | epoch 001:   2100 / 150053 loss=8.155, nll_loss=7.268, ppl=154.17, wps=11748.3, ups=3.3, wpb=3564.7, bsz=123.1, num_updates=2100, lr=0.0002625, gnorm=1.635, train_wall=23, wall=0
2024-07-14 17:33:37 | INFO | train_inner | epoch 001:   2200 / 150053 loss=8.146, nll_loss=7.259, ppl=153.21, wps=15439.2, ups=4.31, wpb=3582.8, bsz=101.4, num_updates=2200, lr=0.000275, gnorm=1.428, train_wall=23, wall=0
2024-07-14 17:34:00 | INFO | train_inner | epoch 001:   2300 / 150053 loss=8.007, nll_loss=7.102, ppl=137.42, wps=15306.8, ups=4.41, wpb=3471.3, bsz=97.7, num_updates=2300, lr=0.0002875, gnorm=1.301, train_wall=23, wall=0
2024-07-14 17:34:23 | INFO | train_inner | epoch 001:   2400 / 150053 loss=7.903, nll_loss=6.984, ppl=126.59, wps=15353.8, ups=4.33, wpb=3545.5, bsz=92.4, num_updates=2400, lr=0.0003, gnorm=1.284, train_wall=23, wall=0
2024-07-14 17:34:46 | INFO | train_inner | epoch 001:   2500 / 150053 loss=7.839, nll_loss=6.91, ppl=120.22, wps=15564.4, ups=4.41, wpb=3526.7, bsz=93.9, num_updates=2500, lr=0.0003125, gnorm=1.3, train_wall=22, wall=0
2024-07-14 17:34:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:34:49 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.985 | nll_loss 7.017 | ppl 129.53 | wps 42647 | wpb 2588.8 | bsz 75.3 | num_updates 2500 | best_loss 12.174
2024-07-14 17:34:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:34:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_2500.pt (epoch 1 @ 2500 updates, score 7.985) (writing took 4.748523103073239 seconds)
2024-07-14 17:35:17 | INFO | train_inner | epoch 001:   2600 / 150053 loss=7.789, nll_loss=6.853, ppl=115.58, wps=11417.5, ups=3.23, wpb=3532.1, bsz=97.6, num_updates=2600, lr=0.000325, gnorm=1.336, train_wall=23, wall=0
2024-07-14 17:35:40 | INFO | train_inner | epoch 001:   2700 / 150053 loss=7.725, nll_loss=6.781, ppl=109.95, wps=15422.1, ups=4.34, wpb=3552.8, bsz=91, num_updates=2700, lr=0.0003375, gnorm=1.215, train_wall=23, wall=0
2024-07-14 17:36:03 | INFO | train_inner | epoch 001:   2800 / 150053 loss=7.753, nll_loss=6.811, ppl=112.27, wps=15650.1, ups=4.33, wpb=3618.3, bsz=127.4, num_updates=2800, lr=0.00035, gnorm=1.501, train_wall=23, wall=0
2024-07-14 17:36:26 | INFO | train_inner | epoch 001:   2900 / 150053 loss=7.569, nll_loss=6.603, ppl=97.18, wps=15331.9, ups=4.34, wpb=3531.4, bsz=106.8, num_updates=2900, lr=0.0003625, gnorm=1.158, train_wall=23, wall=0
2024-07-14 17:36:49 | INFO | train_inner | epoch 001:   3000 / 150053 loss=7.524, nll_loss=6.55, ppl=93.72, wps=15659.6, ups=4.32, wpb=3627.2, bsz=122.6, num_updates=3000, lr=0.000375, gnorm=1.301, train_wall=23, wall=0
2024-07-14 17:36:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:36:52 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.716 | nll_loss 6.702 | ppl 104.14 | wps 43531.1 | wpb 2588.8 | bsz 75.3 | num_updates 3000 | best_loss 12.174
2024-07-14 17:36:52 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:36:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_3000.pt (epoch 1 @ 3000 updates, score 7.716) (writing took 4.7721093110740185 seconds)
2024-07-14 17:37:20 | INFO | train_inner | epoch 001:   3100 / 150053 loss=7.496, nll_loss=6.519, ppl=91.71, wps=11552, ups=3.26, wpb=3538.4, bsz=95.5, num_updates=3100, lr=0.0003875, gnorm=1.153, train_wall=23, wall=0
2024-07-14 17:37:43 | INFO | train_inner | epoch 001:   3200 / 150053 loss=7.494, nll_loss=6.515, ppl=91.48, wps=15324, ups=4.32, wpb=3550.8, bsz=120.2, num_updates=3200, lr=0.0004, gnorm=1.37, train_wall=23, wall=0
2024-07-14 17:38:05 | INFO | train_inner | epoch 001:   3300 / 150053 loss=7.419, nll_loss=6.431, ppl=86.28, wps=15483.9, ups=4.42, wpb=3507, bsz=103.1, num_updates=3300, lr=0.0004125, gnorm=1.162, train_wall=22, wall=0
2024-07-14 17:38:29 | INFO | train_inner | epoch 001:   3400 / 150053 loss=7.354, nll_loss=6.357, ppl=81.94, wps=15401.9, ups=4.31, wpb=3574.5, bsz=110.2, num_updates=3400, lr=0.000425, gnorm=1.162, train_wall=23, wall=0
2024-07-14 17:38:52 | INFO | train_inner | epoch 001:   3500 / 150053 loss=7.383, nll_loss=6.39, ppl=83.84, wps=15497.3, ups=4.38, wpb=3537.1, bsz=97.6, num_updates=3500, lr=0.0004375, gnorm=1.15, train_wall=23, wall=0
2024-07-14 17:38:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:38:54 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.531 | nll_loss 6.496 | ppl 90.25 | wps 43821.7 | wpb 2588.8 | bsz 75.3 | num_updates 3500 | best_loss 12.174
2024-07-14 17:38:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:38:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_3500.pt (epoch 1 @ 3500 updates, score 7.531) (writing took 4.795182630419731 seconds)
2024-07-14 17:39:22 | INFO | train_inner | epoch 001:   3600 / 150053 loss=7.255, nll_loss=6.244, ppl=75.81, wps=11678.8, ups=3.26, wpb=3583.8, bsz=111.4, num_updates=3600, lr=0.00045, gnorm=1.112, train_wall=23, wall=0
2024-07-14 17:39:45 | INFO | train_inner | epoch 001:   3700 / 150053 loss=7.329, nll_loss=6.327, ppl=80.25, wps=15526.4, ups=4.35, wpb=3573.2, bsz=110.3, num_updates=3700, lr=0.0004625, gnorm=1.232, train_wall=23, wall=0
2024-07-14 17:40:08 | INFO | train_inner | epoch 001:   3800 / 150053 loss=7.208, nll_loss=6.19, ppl=72.99, wps=15411.2, ups=4.33, wpb=3555.6, bsz=114.6, num_updates=3800, lr=0.000475, gnorm=1.129, train_wall=23, wall=0
2024-07-14 17:40:31 | INFO | train_inner | epoch 001:   3900 / 150053 loss=7.23, nll_loss=6.215, ppl=74.27, wps=15273.8, ups=4.33, wpb=3528.4, bsz=111.5, num_updates=3900, lr=0.0004875, gnorm=1.187, train_wall=23, wall=0
2024-07-14 17:40:54 | INFO | train_inner | epoch 001:   4000 / 150053 loss=7.279, nll_loss=6.269, ppl=77.13, wps=15678.9, ups=4.35, wpb=3601.8, bsz=101.4, num_updates=4000, lr=0.0005, gnorm=1.125, train_wall=23, wall=0
2024-07-14 17:40:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:40:57 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.356 | nll_loss 6.289 | ppl 78.22 | wps 43657.1 | wpb 2588.8 | bsz 75.3 | num_updates 4000 | best_loss 12.174
2024-07-14 17:40:57 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:41:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 7.356) (writing took 4.891257414594293 seconds)
2024-07-14 17:41:25 | INFO | train_inner | epoch 001:   4100 / 150053 loss=7.263, nll_loss=6.252, ppl=76.22, wps=11277, ups=3.28, wpb=3440.3, bsz=107.4, num_updates=4100, lr=0.000493865, gnorm=1.243, train_wall=23, wall=0
2024-07-14 17:41:48 | INFO | train_inner | epoch 001:   4200 / 150053 loss=7.184, nll_loss=6.162, ppl=71.6, wps=15172.7, ups=4.38, wpb=3464.4, bsz=96.7, num_updates=4200, lr=0.00048795, gnorm=1.146, train_wall=23, wall=0
2024-07-14 17:42:10 | INFO | train_inner | epoch 001:   4300 / 150053 loss=7.147, nll_loss=6.12, ppl=69.54, wps=15509, ups=4.4, wpb=3524.1, bsz=93.2, num_updates=4300, lr=0.000482243, gnorm=1.033, train_wall=23, wall=0
2024-07-14 17:42:33 | INFO | train_inner | epoch 001:   4400 / 150053 loss=7.082, nll_loss=6.047, ppl=66.11, wps=15486, ups=4.36, wpb=3552.5, bsz=117.7, num_updates=4400, lr=0.000476731, gnorm=1.085, train_wall=23, wall=0
2024-07-14 17:42:56 | INFO | train_inner | epoch 001:   4500 / 150053 loss=7.113, nll_loss=6.083, ppl=67.78, wps=15325.6, ups=4.4, wpb=3480.3, bsz=119.7, num_updates=4500, lr=0.000471405, gnorm=1.232, train_wall=23, wall=0
2024-07-14 17:42:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:42:59 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.264 | nll_loss 6.162 | ppl 71.62 | wps 43860.5 | wpb 2588.8 | bsz 75.3 | num_updates 4500 | best_loss 12.174
2024-07-14 17:42:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:43:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_4500.pt (epoch 1 @ 4500 updates, score 7.264) (writing took 4.710541075095534 seconds)
2024-07-14 17:43:26 | INFO | train_inner | epoch 001:   4600 / 150053 loss=7.035, nll_loss=5.993, ppl=63.69, wps=11478.1, ups=3.3, wpb=3474.9, bsz=99.1, num_updates=4600, lr=0.000466252, gnorm=1.013, train_wall=23, wall=0
2024-07-14 17:43:49 | INFO | train_inner | epoch 001:   4700 / 150053 loss=6.997, nll_loss=5.949, ppl=61.78, wps=15542.3, ups=4.39, wpb=3542.3, bsz=104.3, num_updates=4700, lr=0.000461266, gnorm=1.037, train_wall=23, wall=0
2024-07-14 17:44:12 | INFO | train_inner | epoch 001:   4800 / 150053 loss=6.946, nll_loss=5.892, ppl=59.38, wps=15513.6, ups=4.36, wpb=3559, bsz=101, num_updates=4800, lr=0.000456435, gnorm=1.033, train_wall=23, wall=0
2024-07-14 17:44:35 | INFO | train_inner | epoch 001:   4900 / 150053 loss=6.84, nll_loss=5.771, ppl=54.61, wps=15758.8, ups=4.34, wpb=3628.7, bsz=120.2, num_updates=4900, lr=0.000451754, gnorm=1.039, train_wall=23, wall=0
2024-07-14 17:44:58 | INFO | train_inner | epoch 001:   5000 / 150053 loss=6.875, nll_loss=5.811, ppl=56.15, wps=15686.3, ups=4.37, wpb=3587.5, bsz=100.1, num_updates=5000, lr=0.000447214, gnorm=0.967, train_wall=23, wall=0
2024-07-14 17:44:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:45:01 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.071 | nll_loss 5.949 | ppl 61.77 | wps 43883.1 | wpb 2588.8 | bsz 75.3 | num_updates 5000 | best_loss 12.174
2024-07-14 17:45:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:45:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_5000.pt (epoch 1 @ 5000 updates, score 7.071) (writing took 5.1406636368483305 seconds)
2024-07-14 17:45:29 | INFO | train_inner | epoch 001:   5100 / 150053 loss=6.919, nll_loss=5.861, ppl=58.11, wps=11444, ups=3.24, wpb=3531.2, bsz=87, num_updates=5100, lr=0.000442807, gnorm=0.978, train_wall=23, wall=0
2024-07-14 17:45:52 | INFO | train_inner | epoch 001:   5200 / 150053 loss=6.785, nll_loss=5.71, ppl=52.34, wps=15209.8, ups=4.36, wpb=3490.8, bsz=103.4, num_updates=5200, lr=0.000438529, gnorm=0.994, train_wall=23, wall=0
2024-07-14 17:46:15 | INFO | train_inner | epoch 001:   5300 / 150053 loss=6.824, nll_loss=5.752, ppl=53.88, wps=15226.7, ups=4.35, wpb=3500.6, bsz=93.7, num_updates=5300, lr=0.000434372, gnorm=0.994, train_wall=23, wall=0
2024-07-14 17:46:38 | INFO | train_inner | epoch 001:   5400 / 150053 loss=6.845, nll_loss=5.776, ppl=54.81, wps=15470.9, ups=4.38, wpb=3533.6, bsz=94.8, num_updates=5400, lr=0.000430331, gnorm=0.97, train_wall=23, wall=0
2024-07-14 17:47:01 | INFO | train_inner | epoch 001:   5500 / 150053 loss=6.823, nll_loss=5.752, ppl=53.89, wps=15443.4, ups=4.37, wpb=3533, bsz=100.2, num_updates=5500, lr=0.000426401, gnorm=0.99, train_wall=23, wall=0
2024-07-14 17:47:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:47:03 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.992 | nll_loss 5.869 | ppl 58.43 | wps 43786.1 | wpb 2588.8 | bsz 75.3 | num_updates 5500 | best_loss 12.174
2024-07-14 17:47:03 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:47:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_5500.pt (epoch 1 @ 5500 updates, score 6.992) (writing took 4.63826684653759 seconds)
2024-07-14 17:47:31 | INFO | train_inner | epoch 001:   5600 / 150053 loss=6.816, nll_loss=5.744, ppl=53.6, wps=11757.5, ups=3.31, wpb=3556.5, bsz=111.6, num_updates=5600, lr=0.000422577, gnorm=1.044, train_wall=23, wall=0
2024-07-14 17:47:54 | INFO | train_inner | epoch 001:   5700 / 150053 loss=6.765, nll_loss=5.686, ppl=51.49, wps=15367, ups=4.38, wpb=3507.4, bsz=97.7, num_updates=5700, lr=0.000418854, gnorm=0.998, train_wall=23, wall=0
2024-07-14 17:48:17 | INFO | train_inner | epoch 001:   5800 / 150053 loss=6.674, nll_loss=5.583, ppl=47.94, wps=15077.2, ups=4.28, wpb=3520.8, bsz=125, num_updates=5800, lr=0.000415227, gnorm=1.021, train_wall=23, wall=0
2024-07-14 17:48:40 | INFO | train_inner | epoch 001:   5900 / 150053 loss=6.683, nll_loss=5.592, ppl=48.24, wps=15451.4, ups=4.28, wpb=3610.4, bsz=129.4, num_updates=5900, lr=0.000411693, gnorm=1.008, train_wall=23, wall=0
2024-07-14 17:49:03 | INFO | train_inner | epoch 001:   6000 / 150053 loss=6.743, nll_loss=5.661, ppl=50.59, wps=15478.6, ups=4.38, wpb=3533.7, bsz=85, num_updates=6000, lr=0.000408248, gnorm=0.939, train_wall=23, wall=0
2024-07-14 17:49:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:49:06 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.866 | nll_loss 5.721 | ppl 52.74 | wps 42641.5 | wpb 2588.8 | bsz 75.3 | num_updates 6000 | best_loss 12.174
2024-07-14 17:49:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:49:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 6.866) (writing took 4.832081141881645 seconds)
2024-07-14 17:49:34 | INFO | train_inner | epoch 001:   6100 / 150053 loss=6.681, nll_loss=5.59, ppl=48.18, wps=11612.7, ups=3.26, wpb=3562.8, bsz=105.6, num_updates=6100, lr=0.000404888, gnorm=1.021, train_wall=23, wall=0
2024-07-14 17:49:57 | INFO | train_inner | epoch 001:   6200 / 150053 loss=6.639, nll_loss=5.542, ppl=46.59, wps=15609.8, ups=4.3, wpb=3626.9, bsz=108.6, num_updates=6200, lr=0.00040161, gnorm=0.98, train_wall=23, wall=0
2024-07-14 17:50:20 | INFO | train_inner | epoch 001:   6300 / 150053 loss=6.658, nll_loss=5.565, ppl=47.33, wps=15354.9, ups=4.37, wpb=3511.1, bsz=98.6, num_updates=6300, lr=0.00039841, gnorm=0.957, train_wall=23, wall=0
2024-07-14 17:50:43 | INFO | train_inner | epoch 001:   6400 / 150053 loss=6.584, nll_loss=5.481, ppl=44.66, wps=15267.3, ups=4.28, wpb=3571.2, bsz=117.7, num_updates=6400, lr=0.000395285, gnorm=0.962, train_wall=23, wall=0
2024-07-14 17:51:07 | INFO | train_inner | epoch 001:   6500 / 150053 loss=6.616, nll_loss=5.515, ppl=45.73, wps=15366.3, ups=4.25, wpb=3613.8, bsz=94.4, num_updates=6500, lr=0.000392232, gnorm=0.965, train_wall=23, wall=0
2024-07-14 17:51:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:51:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.779 | nll_loss 5.625 | ppl 49.34 | wps 43086.8 | wpb 2588.8 | bsz 75.3 | num_updates 6500 | best_loss 12.174
2024-07-14 17:51:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:51:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_6500.pt (epoch 1 @ 6500 updates, score 6.779) (writing took 4.66914486605674 seconds)
2024-07-14 17:51:37 | INFO | train_inner | epoch 001:   6600 / 150053 loss=6.604, nll_loss=5.502, ppl=45.31, wps=11552.7, ups=3.3, wpb=3500.1, bsz=98.1, num_updates=6600, lr=0.000389249, gnorm=0.952, train_wall=23, wall=0
2024-07-14 17:52:00 | INFO | train_inner | epoch 001:   6700 / 150053 loss=6.623, nll_loss=5.524, ppl=46.02, wps=15079.6, ups=4.35, wpb=3467.1, bsz=87.9, num_updates=6700, lr=0.000386334, gnorm=0.985, train_wall=23, wall=0
2024-07-14 17:52:23 | INFO | train_inner | epoch 001:   6800 / 150053 loss=6.577, nll_loss=5.472, ppl=44.37, wps=15456.6, ups=4.36, wpb=3548.9, bsz=106.6, num_updates=6800, lr=0.000383482, gnorm=0.986, train_wall=23, wall=0
2024-07-14 17:52:46 | INFO | train_inner | epoch 001:   6900 / 150053 loss=6.522, nll_loss=5.41, ppl=42.51, wps=15410.5, ups=4.31, wpb=3574, bsz=97.1, num_updates=6900, lr=0.000380693, gnorm=0.914, train_wall=23, wall=0
2024-07-14 17:53:09 | INFO | train_inner | epoch 001:   7000 / 150053 loss=6.468, nll_loss=5.348, ppl=40.74, wps=15123, ups=4.36, wpb=3467, bsz=120.3, num_updates=7000, lr=0.000377964, gnorm=1.01, train_wall=23, wall=0
2024-07-14 17:53:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:53:12 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.743 | nll_loss 5.582 | ppl 47.91 | wps 43648.4 | wpb 2588.8 | bsz 75.3 | num_updates 7000 | best_loss 12.174
2024-07-14 17:53:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:53:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_7000.pt (epoch 1 @ 7000 updates, score 6.743) (writing took 4.613688886165619 seconds)
2024-07-14 17:53:39 | INFO | train_inner | epoch 001:   7100 / 150053 loss=6.487, nll_loss=5.369, ppl=41.33, wps=11772.2, ups=3.3, wpb=3565.4, bsz=98.9, num_updates=7100, lr=0.000375293, gnorm=0.92, train_wall=23, wall=0
2024-07-14 17:54:02 | INFO | train_inner | epoch 001:   7200 / 150053 loss=6.503, nll_loss=5.388, ppl=41.88, wps=15311.3, ups=4.37, wpb=3500, bsz=103, num_updates=7200, lr=0.000372678, gnorm=0.958, train_wall=23, wall=0
2024-07-14 17:54:25 | INFO | train_inner | epoch 001:   7300 / 150053 loss=6.473, nll_loss=5.353, ppl=40.87, wps=15559.9, ups=4.36, wpb=3572.2, bsz=103.3, num_updates=7300, lr=0.000370117, gnorm=0.937, train_wall=23, wall=0
2024-07-14 17:54:48 | INFO | train_inner | epoch 001:   7400 / 150053 loss=6.524, nll_loss=5.411, ppl=42.55, wps=15203.9, ups=4.39, wpb=3466.7, bsz=101, num_updates=7400, lr=0.000367607, gnorm=1.035, train_wall=23, wall=0
2024-07-14 17:55:11 | INFO | train_inner | epoch 001:   7500 / 150053 loss=6.496, nll_loss=5.379, ppl=41.61, wps=15541.1, ups=4.37, wpb=3557, bsz=101.4, num_updates=7500, lr=0.000365148, gnorm=0.965, train_wall=23, wall=0
2024-07-14 17:55:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:55:14 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.688 | nll_loss 5.525 | ppl 46.03 | wps 43736.5 | wpb 2588.8 | bsz 75.3 | num_updates 7500 | best_loss 12.174
2024-07-14 17:55:14 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:55:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_7500.pt (epoch 1 @ 7500 updates, score 6.688) (writing took 4.6400084821507335 seconds)
2024-07-14 17:55:41 | INFO | train_inner | epoch 001:   7600 / 150053 loss=6.442, nll_loss=5.318, ppl=39.88, wps=11748.1, ups=3.3, wpb=3561.3, bsz=101.6, num_updates=7600, lr=0.000362738, gnorm=0.946, train_wall=23, wall=0
2024-07-14 17:56:04 | INFO | train_inner | epoch 001:   7700 / 150053 loss=6.469, nll_loss=5.35, ppl=40.78, wps=15417.3, ups=4.33, wpb=3560.4, bsz=107.1, num_updates=7700, lr=0.000360375, gnorm=0.981, train_wall=23, wall=0
2024-07-14 17:56:27 | INFO | train_inner | epoch 001:   7800 / 150053 loss=6.441, nll_loss=5.317, ppl=39.87, wps=15492.4, ups=4.39, wpb=3525.8, bsz=105.8, num_updates=7800, lr=0.000358057, gnorm=0.955, train_wall=23, wall=0
2024-07-14 17:56:51 | INFO | train_inner | epoch 001:   7900 / 150053 loss=6.361, nll_loss=5.226, ppl=37.43, wps=15100.3, ups=4.26, wpb=3544.1, bsz=112.8, num_updates=7900, lr=0.000355784, gnorm=0.958, train_wall=23, wall=0
2024-07-14 17:57:14 | INFO | train_inner | epoch 001:   8000 / 150053 loss=6.378, nll_loss=5.245, ppl=37.92, wps=15701.4, ups=4.31, wpb=3640.9, bsz=102.1, num_updates=8000, lr=0.000353553, gnorm=0.909, train_wall=23, wall=0
2024-07-14 17:57:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:57:17 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.628 | nll_loss 5.469 | ppl 44.29 | wps 43687.8 | wpb 2588.8 | bsz 75.3 | num_updates 8000 | best_loss 12.174
2024-07-14 17:57:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:57:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 6.628) (writing took 4.782108409330249 seconds)
2024-07-14 17:57:44 | INFO | train_inner | epoch 001:   8100 / 150053 loss=6.402, nll_loss=5.273, ppl=38.66, wps=11670.7, ups=3.26, wpb=3578.7, bsz=97.4, num_updates=8100, lr=0.000351364, gnorm=0.921, train_wall=23, wall=0
2024-07-14 17:58:08 | INFO | train_inner | epoch 001:   8200 / 150053 loss=6.362, nll_loss=5.227, ppl=37.45, wps=15220.2, ups=4.34, wpb=3504.3, bsz=110.1, num_updates=8200, lr=0.000349215, gnorm=0.975, train_wall=23, wall=0
2024-07-14 17:58:31 | INFO | train_inner | epoch 001:   8300 / 150053 loss=6.36, nll_loss=5.225, ppl=37.41, wps=15259.5, ups=4.3, wpb=3546.8, bsz=107.2, num_updates=8300, lr=0.000347105, gnorm=0.953, train_wall=23, wall=0
2024-07-14 17:58:54 | INFO | train_inner | epoch 001:   8400 / 150053 loss=6.316, nll_loss=5.175, ppl=36.12, wps=15394.7, ups=4.3, wpb=3577, bsz=106.9, num_updates=8400, lr=0.000345033, gnorm=0.96, train_wall=23, wall=0
2024-07-14 17:59:17 | INFO | train_inner | epoch 001:   8500 / 150053 loss=6.316, nll_loss=5.175, ppl=36.14, wps=15386.3, ups=4.36, wpb=3527.2, bsz=99.2, num_updates=8500, lr=0.000342997, gnorm=0.961, train_wall=23, wall=0
2024-07-14 17:59:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 17:59:20 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.627 | nll_loss 5.484 | ppl 44.77 | wps 43180 | wpb 2588.8 | bsz 75.3 | num_updates 8500 | best_loss 12.174
2024-07-14 17:59:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 17:59:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_8500.pt (epoch 1 @ 8500 updates, score 6.627) (writing took 5.2223469307646155 seconds)
2024-07-14 17:59:48 | INFO | train_inner | epoch 001:   8600 / 150053 loss=6.32, nll_loss=5.179, ppl=36.22, wps=11576.1, ups=3.24, wpb=3575, bsz=103, num_updates=8600, lr=0.000340997, gnorm=0.926, train_wall=23, wall=0
2024-07-14 18:00:11 | INFO | train_inner | epoch 001:   8700 / 150053 loss=6.375, nll_loss=5.242, ppl=37.85, wps=15595.7, ups=4.39, wpb=3555.3, bsz=101.6, num_updates=8700, lr=0.000339032, gnorm=1.024, train_wall=23, wall=0
2024-07-14 18:00:34 | INFO | train_inner | epoch 001:   8800 / 150053 loss=6.366, nll_loss=5.232, ppl=37.59, wps=15629.7, ups=4.32, wpb=3613.8, bsz=103.5, num_updates=8800, lr=0.0003371, gnorm=0.94, train_wall=23, wall=0
2024-07-14 18:00:57 | INFO | train_inner | epoch 001:   8900 / 150053 loss=6.38, nll_loss=5.248, ppl=37.99, wps=15501.8, ups=4.39, wpb=3534.4, bsz=106.6, num_updates=8900, lr=0.000335201, gnorm=1.017, train_wall=23, wall=0
2024-07-14 18:01:20 | INFO | train_inner | epoch 001:   9000 / 150053 loss=6.308, nll_loss=5.165, ppl=35.88, wps=15786, ups=4.33, wpb=3641.8, bsz=98.7, num_updates=9000, lr=0.000333333, gnorm=0.903, train_wall=23, wall=0
2024-07-14 18:01:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 18:01:22 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.544 | nll_loss 5.375 | ppl 41.48 | wps 43869.5 | wpb 2588.8 | bsz 75.3 | num_updates 9000 | best_loss 12.174
2024-07-14 18:01:22 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 18:01:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_9000.pt (epoch 1 @ 9000 updates, score 6.544) (writing took 4.515597617253661 seconds)
2024-07-14 18:01:50 | INFO | train_inner | epoch 001:   9100 / 150053 loss=6.282, nll_loss=5.136, ppl=35.17, wps=11549.3, ups=3.32, wpb=3478.3, bsz=92.1, num_updates=9100, lr=0.000331497, gnorm=0.918, train_wall=23, wall=0
2024-07-14 18:02:13 | INFO | train_inner | epoch 001:   9200 / 150053 loss=6.34, nll_loss=5.203, ppl=36.84, wps=15315.6, ups=4.36, wpb=3508.7, bsz=101.1, num_updates=9200, lr=0.00032969, gnorm=0.961, train_wall=23, wall=0
2024-07-14 18:02:36 | INFO | train_inner | epoch 001:   9300 / 150053 loss=6.272, nll_loss=5.126, ppl=34.91, wps=15441.8, ups=4.27, wpb=3618.6, bsz=100.7, num_updates=9300, lr=0.000327913, gnorm=0.911, train_wall=23, wall=0
2024-07-14 18:02:59 | INFO | train_inner | epoch 001:   9400 / 150053 loss=6.291, nll_loss=5.146, ppl=35.4, wps=15380.3, ups=4.4, wpb=3495.1, bsz=95.6, num_updates=9400, lr=0.000326164, gnorm=0.95, train_wall=23, wall=0
2024-07-14 18:03:22 | INFO | train_inner | epoch 001:   9500 / 150053 loss=6.269, nll_loss=5.123, ppl=34.84, wps=15172.3, ups=4.33, wpb=3507.6, bsz=91.5, num_updates=9500, lr=0.000324443, gnorm=0.912, train_wall=23, wall=0
2024-07-14 18:03:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 18:03:25 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.511 | nll_loss 5.341 | ppl 40.52 | wps 43652.5 | wpb 2588.8 | bsz 75.3 | num_updates 9500 | best_loss 12.174
2024-07-14 18:03:25 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 18:03:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_9500.pt (epoch 1 @ 9500 updates, score 6.511) (writing took 5.071582378819585 seconds)
2024-07-14 18:03:53 | INFO | train_inner | epoch 001:   9600 / 150053 loss=6.187, nll_loss=5.029, ppl=32.64, wps=11776.4, ups=3.24, wpb=3630.1, bsz=122.1, num_updates=9600, lr=0.000322749, gnorm=0.931, train_wall=23, wall=0
2024-07-14 18:04:16 | INFO | train_inner | epoch 001:   9700 / 150053 loss=6.254, nll_loss=5.105, ppl=34.41, wps=15272.8, ups=4.37, wpb=3491.1, bsz=95.9, num_updates=9700, lr=0.000321081, gnorm=0.943, train_wall=23, wall=0
2024-07-14 18:04:39 | INFO | train_inner | epoch 001:   9800 / 150053 loss=6.197, nll_loss=5.041, ppl=32.91, wps=15232.7, ups=4.3, wpb=3545.5, bsz=112.2, num_updates=9800, lr=0.000319438, gnorm=0.952, train_wall=23, wall=0
2024-07-14 18:05:02 | INFO | train_inner | epoch 001:   9900 / 150053 loss=6.248, nll_loss=5.098, ppl=34.24, wps=15359.9, ups=4.31, wpb=3565.9, bsz=103.8, num_updates=9900, lr=0.000317821, gnorm=0.951, train_wall=23, wall=0
2024-07-14 18:05:25 | INFO | train_inner | epoch 001:  10000 / 150053 loss=6.166, nll_loss=5.004, ppl=32.09, wps=15291.3, ups=4.28, wpb=3574.7, bsz=107.8, num_updates=10000, lr=0.000316228, gnorm=0.935, train_wall=23, wall=0
2024-07-14 18:05:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 18:05:28 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.5 | nll_loss 5.332 | ppl 40.27 | wps 43712 | wpb 2588.8 | bsz 75.3 | num_updates 10000 | best_loss 12.174
2024-07-14 18:05:28 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 18:05:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score 6.5) (writing took 5.079995424486697 seconds)
2024-07-14 18:05:33 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-14 18:05:33 | INFO | train | epoch 001 | loss 7.41 | nll_loss 6.425 | ppl 85.91 | wps 13911 | ups 3.92 | wpb 3544.5 | bsz 103.7 | num_updates 10000 | lr 0.000316228 | gnorm 1.148 | train_wall 2287 | wall 0
2024-07-14 18:05:33 | INFO | fairseq_cli.train | done training in 2206.7 seconds
2024-07-14 18:05:37 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt22.sep.tokenized.fr-de', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=100000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=1000, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-14 18:05:37 | INFO | fairseq.tasks.translation | [fr] dictionary: 10016 types
2024-07-14 18:05:37 | INFO | fairseq.tasks.translation | [de] dictionary: 10032 types
2024-07-14 18:05:37 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.fr
2024-07-14 18:05:37 | INFO | fairseq.data.data_utils | loaded 3238 examples from: data-bin/wmt22.sep.tokenized.fr-de/valid.fr-de.de
2024-07-14 18:05:37 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de valid fr-de 3238 examples
2024-07-14 18:05:38 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10016, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10032, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=10032, bias=False)
  )
)
2024-07-14 18:05:38 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-14 18:05:38 | INFO | fairseq_cli.train | model: transformer_wmt_en_de (TransformerModel)
2024-07-14 18:05:38 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-14 18:05:38 | INFO | fairseq_cli.train | num. model params: 54403072 (num. trained: 54403072)
2024-07-14 18:05:44 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-14 18:05:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-14 18:05:44 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-14 18:05:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-14 18:05:44 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-14 18:05:44 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-14 18:05:45 | INFO | fairseq.trainer | loaded checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 10000 updates)
2024-07-14 18:05:45 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-14 18:05:46 | INFO | fairseq.data.data_utils | loaded 15571322 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.fr
2024-07-14 18:05:46 | INFO | fairseq.data.data_utils | loaded 15571322 examples from: data-bin/wmt22.sep.tokenized.fr-de/train.fr-de.de
2024-07-14 18:05:46 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.fr-de train fr-de 15571322 examples
2024-07-14 18:06:07 | INFO | fairseq.trainer | begin training epoch 1
2024-07-14 18:06:30 | INFO | train_inner | epoch 001:  10100 / 150053 loss=6.173, nll_loss=5.013, ppl=32.3, wps=7414.7, ups=2.11, wpb=3518.4, bsz=94.2, num_updates=10100, lr=0.000314658, gnorm=0.905, train_wall=23, wall=0
2024-07-14 18:06:53 | INFO | train_inner | epoch 001:  10200 / 150053 loss=6.179, nll_loss=5.019, ppl=32.43, wps=15423.6, ups=4.3, wpb=3584.4, bsz=123.5, num_updates=10200, lr=0.000313112, gnorm=0.961, train_wall=23, wall=0
2024-07-14 18:07:17 | INFO | train_inner | epoch 001:  10300 / 150053 loss=6.226, nll_loss=5.072, ppl=33.64, wps=15126.6, ups=4.22, wpb=3584.2, bsz=106.1, num_updates=10300, lr=0.000311588, gnorm=1.024, train_wall=23, wall=0
2024-07-14 18:07:40 | INFO | train_inner | epoch 001:  10400 / 150053 loss=6.223, nll_loss=5.07, ppl=33.58, wps=15235.7, ups=4.31, wpb=3538.3, bsz=101.8, num_updates=10400, lr=0.000310087, gnorm=0.943, train_wall=23, wall=0
2024-07-14 18:08:04 | INFO | train_inner | epoch 001:  10500 / 150053 loss=6.096, nll_loss=4.926, ppl=30.39, wps=15429.4, ups=4.26, wpb=3623.7, bsz=117, num_updates=10500, lr=0.000308607, gnorm=0.933, train_wall=23, wall=0
2024-07-14 18:08:27 | INFO | train_inner | epoch 001:  10600 / 150053 loss=6.183, nll_loss=5.024, ppl=32.53, wps=15206.3, ups=4.33, wpb=3512.3, bsz=92.6, num_updates=10600, lr=0.000307148, gnorm=0.942, train_wall=23, wall=0
2024-07-14 18:08:50 | INFO | train_inner | epoch 001:  10700 / 150053 loss=6.203, nll_loss=5.047, ppl=33.06, wps=15101, ups=4.3, wpb=3513.3, bsz=112.2, num_updates=10700, lr=0.000305709, gnorm=0.962, train_wall=23, wall=0
2024-07-14 18:09:13 | INFO | train_inner | epoch 001:  10800 / 150053 loss=6.243, nll_loss=5.092, ppl=34.11, wps=15333.9, ups=4.35, wpb=3521.7, bsz=97.4, num_updates=10800, lr=0.00030429, gnorm=0.962, train_wall=23, wall=0
2024-07-14 18:09:36 | INFO | train_inner | epoch 001:  10900 / 150053 loss=6.138, nll_loss=4.974, ppl=31.43, wps=15305.4, ups=4.33, wpb=3538.2, bsz=104.9, num_updates=10900, lr=0.000302891, gnorm=0.906, train_wall=23, wall=0
2024-07-14 18:09:59 | INFO | train_inner | epoch 001:  11000 / 150053 loss=6.184, nll_loss=5.026, ppl=32.57, wps=15065.7, ups=4.3, wpb=3500, bsz=99.6, num_updates=11000, lr=0.000301511, gnorm=0.949, train_wall=23, wall=0
2024-07-14 18:09:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-14 18:10:02 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.437 | nll_loss 5.252 | ppl 38.09 | wps 43707.5 | wpb 2588.8 | bsz 75.3 | num_updates 11000 | best_loss 12.174
2024-07-14 18:10:02 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 18:10:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_11000.pt (epoch 1 @ 11000 updates, score 6.437) (writing took 5.532177411019802 seconds)
2024-07-14 18:10:31 | INFO | train_inner | epoch 001:  11100 / 150053 loss=6.144, nll_loss=4.98, ppl=31.57, wps=11236.9, ups=3.18, wpb=3533.3, bsz=98.6, num_updates=11100, lr=0.00030015, gnorm=0.93, train_wall=23, wall=0
2024-07-14 18:10:54 | INFO | train_inner | epoch 001:  11200 / 150053 loss=6.125, nll_loss=4.958, ppl=31.08, wps=15230.9, ups=4.29, wpb=3551.9, bsz=99, num_updates=11200, lr=0.000298807, gnorm=0.942, train_wall=23, wall=0
2024-07-14 18:11:17 | INFO | train_inner | epoch 001:  11300 / 150053 loss=6.145, nll_loss=4.98, ppl=31.56, wps=15429.3, ups=4.31, wpb=3583.8, bsz=111.2, num_updates=11300, lr=0.000297482, gnorm=0.973, train_wall=23, wall=0
2024-07-14 18:11:41 | INFO | train_inner | epoch 001:  11400 / 150053 loss=6.095, nll_loss=4.925, ppl=30.37, wps=15145.3, ups=4.24, wpb=3576, bsz=112.7, num_updates=11400, lr=0.000296174, gnorm=0.952, train_wall=23, wall=0
2024-07-14 18:12:04 | INFO | train_inner | epoch 001:  11500 / 150053 loss=6.16, nll_loss=4.998, ppl=31.96, wps=15366.9, ups=4.36, wpb=3528.1, bsz=97.8, num_updates=11500, lr=0.000294884, gnorm=0.916, train_wall=23, wall=0
2024-07-14 18:12:27 | INFO | train_inner | epoch 001:  11600 / 150053 loss=6.119, nll_loss=4.952, ppl=30.96, wps=15361.9, ups=4.42, wpb=3475, bsz=101.4, num_updates=11600, lr=0.00029361, gnorm=0.961, train_wall=22, wall=0
2024-07-14 18:12:49 | INFO | train_inner | epoch 001:  11700 / 150053 loss=6.215, nll_loss=5.06, ppl=33.37, wps=15405.2, ups=4.4, wpb=3500.3, bsz=112.6, num_updates=11700, lr=0.000292353, gnorm=0.998, train_wall=23, wall=0
2024-07-14 18:13:12 | INFO | train_inner | epoch 001:  11800 / 150053 loss=6.218, nll_loss=5.065, ppl=33.46, wps=14999.2, ups=4.36, wpb=3442.9, bsz=92.8, num_updates=11800, lr=0.000291111, gnorm=1.004, train_wall=23, wall=0
2024-07-14 18:13:35 | INFO | train_inner | epoch 001:  11900 / 150053 loss=6.145, nll_loss=4.981, ppl=31.59, wps=15262.8, ups=4.33, wpb=3525.3, bsz=95.3, num_updates=11900, lr=0.000289886, gnorm=0.938, train_wall=23, wall=0
2024-07-14 18:13:58 | INFO | train_inner | epoch 001:  12000 / 150053 loss=6.081, nll_loss=4.909, ppl=30.04, wps=15333.2, ups=4.36, wpb=3517.7, bsz=114.8, num_updates=12000, lr=0.000288675, gnorm=0.944, train_wall=23, wall=0
2024-07-14 18:13:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 18:14:01 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.388 | nll_loss 5.186 | ppl 36.42 | wps 43795.6 | wpb 2588.8 | bsz 75.3 | num_updates 12000 | best_loss 12.174
2024-07-14 18:14:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 18:14:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_12000.pt (epoch 1 @ 12000 updates, score 6.388) (writing took 5.32256069034338 seconds)
2024-07-14 18:14:29 | INFO | train_inner | epoch 001:  12100 / 150053 loss=6.116, nll_loss=4.948, ppl=30.87, wps=11279.7, ups=3.22, wpb=3505.8, bsz=91.4, num_updates=12100, lr=0.00028748, gnorm=0.898, train_wall=23, wall=0
2024-07-14 18:14:52 | INFO | train_inner | epoch 001:  12200 / 150053 loss=6.112, nll_loss=4.944, ppl=30.78, wps=15346.9, ups=4.34, wpb=3539.1, bsz=98.1, num_updates=12200, lr=0.000286299, gnorm=0.925, train_wall=23, wall=0
2024-07-14 18:15:17 | INFO | train_inner | epoch 001:  12300 / 150053 loss=6.142, nll_loss=4.979, ppl=31.53, wps=14769.3, ups=4.16, wpb=3550.9, bsz=102.6, num_updates=12300, lr=0.000285133, gnorm=0.95, train_wall=24, wall=0
2024-07-14 18:15:41 | INFO | train_inner | epoch 001:  12400 / 150053 loss=6.121, nll_loss=4.954, ppl=30.99, wps=14741, ups=4.15, wpb=3553.6, bsz=101.6, num_updates=12400, lr=0.000283981, gnorm=0.949, train_wall=24, wall=0
2024-07-14 18:16:04 | INFO | train_inner | epoch 001:  12500 / 150053 loss=6.072, nll_loss=4.899, ppl=29.83, wps=15252.3, ups=4.27, wpb=3575.1, bsz=107.4, num_updates=12500, lr=0.000282843, gnorm=0.909, train_wall=23, wall=0
2024-07-14 18:16:27 | INFO | train_inner | epoch 001:  12600 / 150053 loss=6.049, nll_loss=4.873, ppl=29.29, wps=15162.5, ups=4.28, wpb=3541.7, bsz=120.1, num_updates=12600, lr=0.000281718, gnorm=0.974, train_wall=23, wall=0
2024-07-14 18:16:51 | INFO | train_inner | epoch 001:  12700 / 150053 loss=6.101, nll_loss=4.931, ppl=30.5, wps=14964.9, ups=4.23, wpb=3537.9, bsz=109.3, num_updates=12700, lr=0.000280607, gnorm=0.958, train_wall=23, wall=0
2024-07-14 18:17:14 | INFO | train_inner | epoch 001:  12800 / 150053 loss=6.108, nll_loss=4.94, ppl=30.69, wps=15311.7, ups=4.36, wpb=3515.1, bsz=92.3, num_updates=12800, lr=0.000279508, gnorm=0.952, train_wall=23, wall=0
2024-07-14 18:17:38 | INFO | train_inner | epoch 001:  12900 / 150053 loss=6.013, nll_loss=4.831, ppl=28.46, wps=15162.4, ups=4.23, wpb=3581.4, bsz=112.2, num_updates=12900, lr=0.000278423, gnorm=0.911, train_wall=23, wall=0
2024-07-14 18:18:01 | INFO | train_inner | epoch 001:  13000 / 150053 loss=6.034, nll_loss=4.856, ppl=28.95, wps=15275.9, ups=4.29, wpb=3560.9, bsz=101.3, num_updates=13000, lr=0.00027735, gnorm=0.909, train_wall=23, wall=0
2024-07-14 18:18:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 18:18:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.344 | nll_loss 5.134 | ppl 35.11 | wps 43728.3 | wpb 2588.8 | bsz 75.3 | num_updates 13000 | best_loss 12.174
2024-07-14 18:18:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 18:18:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_13000.pt (epoch 1 @ 13000 updates, score 6.344) (writing took 4.849638629704714 seconds)
2024-07-14 18:18:32 | INFO | train_inner | epoch 001:  13100 / 150053 loss=6.026, nll_loss=4.846, ppl=28.76, wps=11605.4, ups=3.22, wpb=3601.3, bsz=115, num_updates=13100, lr=0.000276289, gnorm=0.939, train_wall=23, wall=0
2024-07-14 18:18:55 | INFO | train_inner | epoch 001:  13200 / 150053 loss=6.066, nll_loss=4.892, ppl=29.68, wps=15241.5, ups=4.3, wpb=3548.1, bsz=86.9, num_updates=13200, lr=0.000275241, gnorm=0.91, train_wall=23, wall=0
2024-07-14 18:19:19 | INFO | train_inner | epoch 001:  13300 / 150053 loss=5.972, nll_loss=4.785, ppl=27.56, wps=15313.8, ups=4.28, wpb=3578.7, bsz=124.6, num_updates=13300, lr=0.000274204, gnorm=0.96, train_wall=23, wall=0
2024-07-14 18:19:42 | INFO | train_inner | epoch 001:  13400 / 150053 loss=6.06, nll_loss=4.884, ppl=29.53, wps=15633, ups=4.36, wpb=3583.2, bsz=103.8, num_updates=13400, lr=0.000273179, gnorm=0.94, train_wall=23, wall=0
2024-07-14 18:20:05 | INFO | train_inner | epoch 001:  13500 / 150053 loss=6.01, nll_loss=4.828, ppl=28.4, wps=15199, ups=4.31, wpb=3529.4, bsz=100.4, num_updates=13500, lr=0.000272166, gnorm=0.917, train_wall=23, wall=0
2024-07-14 18:20:28 | INFO | train_inner | epoch 001:  13600 / 150053 loss=6.037, nll_loss=4.859, ppl=29.01, wps=15338.3, ups=4.29, wpb=3572.3, bsz=101.9, num_updates=13600, lr=0.000271163, gnorm=0.925, train_wall=23, wall=0
2024-07-14 18:20:51 | INFO | train_inner | epoch 001:  13700 / 150053 loss=6.054, nll_loss=4.878, ppl=29.4, wps=15023.3, ups=4.31, wpb=3486.1, bsz=90.5, num_updates=13700, lr=0.000270172, gnorm=0.92, train_wall=23, wall=0
2024-07-14 18:21:15 | INFO | train_inner | epoch 001:  13800 / 150053 loss=6.005, nll_loss=4.823, ppl=28.3, wps=14909.6, ups=4.25, wpb=3510.7, bsz=102.9, num_updates=13800, lr=0.000269191, gnorm=0.944, train_wall=23, wall=0
2024-07-14 18:21:38 | INFO | train_inner | epoch 001:  13900 / 150053 loss=5.997, nll_loss=4.813, ppl=28.11, wps=15500.9, ups=4.3, wpb=3601, bsz=110.6, num_updates=13900, lr=0.000268221, gnorm=0.944, train_wall=23, wall=0
2024-07-14 18:22:01 | INFO | train_inner | epoch 001:  14000 / 150053 loss=6.011, nll_loss=4.829, ppl=28.43, wps=15454.5, ups=4.31, wpb=3587.7, bsz=103.8, num_updates=14000, lr=0.000267261, gnorm=0.938, train_wall=23, wall=0
2024-07-14 18:22:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 18:22:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.346 | nll_loss 5.137 | ppl 35.19 | wps 43944.9 | wpb 2588.8 | bsz 75.3 | num_updates 14000 | best_loss 12.174
2024-07-14 18:22:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 18:22:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_14000.pt (epoch 1 @ 14000 updates, score 6.346) (writing took 5.1494123209267855 seconds)
2024-07-14 18:22:32 | INFO | train_inner | epoch 001:  14100 / 150053 loss=6.065, nll_loss=4.89, ppl=29.65, wps=11548.4, ups=3.26, wpb=3540.6, bsz=97.8, num_updates=14100, lr=0.000266312, gnorm=0.997, train_wall=23, wall=0
2024-07-14 18:22:55 | INFO | train_inner | epoch 001:  14200 / 150053 loss=6.033, nll_loss=4.854, ppl=28.92, wps=15719.8, ups=4.32, wpb=3635.4, bsz=112.6, num_updates=14200, lr=0.000265372, gnorm=0.937, train_wall=23, wall=0
2024-07-14 18:23:18 | INFO | train_inner | epoch 001:  14300 / 150053 loss=5.944, nll_loss=4.754, ppl=26.99, wps=15259.3, ups=4.31, wpb=3539.2, bsz=116.7, num_updates=14300, lr=0.000264443, gnorm=0.967, train_wall=23, wall=0
2024-07-14 18:23:42 | INFO | train_inner | epoch 001:  14400 / 150053 loss=5.978, nll_loss=4.792, ppl=27.71, wps=14970.9, ups=4.29, wpb=3490.8, bsz=101.3, num_updates=14400, lr=0.000263523, gnorm=0.949, train_wall=23, wall=0
2024-07-14 18:24:05 | INFO | train_inner | epoch 001:  14500 / 150053 loss=6.006, nll_loss=4.824, ppl=28.32, wps=15482.7, ups=4.35, wpb=3562.2, bsz=110.7, num_updates=14500, lr=0.000262613, gnorm=0.934, train_wall=23, wall=0
2024-07-14 18:24:28 | INFO | train_inner | epoch 001:  14600 / 150053 loss=6.001, nll_loss=4.817, ppl=28.19, wps=15348.4, ups=4.32, wpb=3554.2, bsz=104.8, num_updates=14600, lr=0.000261712, gnorm=0.948, train_wall=23, wall=0
2024-07-14 18:24:51 | INFO | train_inner | epoch 001:  14700 / 150053 loss=5.96, nll_loss=4.772, ppl=27.31, wps=15341.6, ups=4.29, wpb=3577.3, bsz=109, num_updates=14700, lr=0.00026082, gnorm=0.942, train_wall=23, wall=0
2024-07-14 18:25:14 | INFO | train_inner | epoch 001:  14800 / 150053 loss=5.985, nll_loss=4.8, ppl=27.86, wps=15261.4, ups=4.35, wpb=3509.9, bsz=92.8, num_updates=14800, lr=0.000259938, gnorm=0.931, train_wall=23, wall=0
2024-07-14 18:25:37 | INFO | train_inner | epoch 001:  14900 / 150053 loss=5.932, nll_loss=4.74, ppl=26.72, wps=15546.5, ups=4.27, wpb=3644.3, bsz=102.9, num_updates=14900, lr=0.000259064, gnorm=0.919, train_wall=23, wall=0
2024-07-14 18:26:01 | INFO | train_inner | epoch 001:  15000 / 150053 loss=5.905, nll_loss=4.709, ppl=26.15, wps=15308.3, ups=4.35, wpb=3522.3, bsz=105, num_updates=15000, lr=0.000258199, gnorm=0.933, train_wall=23, wall=0
2024-07-14 18:26:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 18:26:03 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.279 | nll_loss 5.083 | ppl 33.91 | wps 43571.2 | wpb 2588.8 | bsz 75.3 | num_updates 15000 | best_loss 12.174
2024-07-14 18:26:03 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 18:26:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_15000.pt (epoch 1 @ 15000 updates, score 6.279) (writing took 5.137816164642572 seconds)
2024-07-14 18:26:31 | INFO | train_inner | epoch 001:  15100 / 150053 loss=5.949, nll_loss=4.758, ppl=27.07, wps=11327.8, ups=3.23, wpb=3505.5, bsz=99.8, num_updates=15100, lr=0.000257343, gnorm=0.931, train_wall=23, wall=0
2024-07-14 18:26:55 | INFO | train_inner | epoch 001:  15200 / 150053 loss=6.073, nll_loss=4.901, ppl=29.87, wps=15243.1, ups=4.32, wpb=3528.6, bsz=92.9, num_updates=15200, lr=0.000256495, gnorm=0.974, train_wall=23, wall=0
2024-07-14 18:27:17 | INFO | train_inner | epoch 001:  15300 / 150053 loss=5.992, nll_loss=4.808, ppl=28.02, wps=15463.1, ups=4.39, wpb=3520.5, bsz=96.7, num_updates=15300, lr=0.000255655, gnorm=0.936, train_wall=23, wall=0
2024-07-14 18:27:40 | INFO | train_inner | epoch 001:  15400 / 150053 loss=6.01, nll_loss=4.828, ppl=28.4, wps=15681.2, ups=4.41, wpb=3555.6, bsz=93.8, num_updates=15400, lr=0.000254824, gnorm=0.937, train_wall=22, wall=0
2024-07-14 18:28:03 | INFO | train_inner | epoch 001:  15500 / 150053 loss=5.973, nll_loss=4.787, ppl=27.61, wps=15273.9, ups=4.31, wpb=3545, bsz=95.5, num_updates=15500, lr=0.000254, gnorm=0.919, train_wall=23, wall=0
2024-07-14 18:28:27 | INFO | train_inner | epoch 001:  15600 / 150053 loss=5.931, nll_loss=4.739, ppl=26.71, wps=14894.6, ups=4.27, wpb=3488.3, bsz=115.1, num_updates=15600, lr=0.000253185, gnorm=0.943, train_wall=23, wall=0
2024-07-14 18:28:50 | INFO | train_inner | epoch 001:  15700 / 150053 loss=5.927, nll_loss=4.733, ppl=26.6, wps=15223, ups=4.37, wpb=3482.6, bsz=100.7, num_updates=15700, lr=0.000252377, gnorm=0.95, train_wall=23, wall=0
2024-07-14 18:29:13 | INFO | train_inner | epoch 001:  15800 / 150053 loss=5.965, nll_loss=4.778, ppl=27.43, wps=15434.1, ups=4.27, wpb=3614.9, bsz=103.3, num_updates=15800, lr=0.000251577, gnorm=0.916, train_wall=23, wall=0
2024-07-14 18:29:36 | INFO | train_inner | epoch 001:  15900 / 150053 loss=5.891, nll_loss=4.694, ppl=25.88, wps=15254.6, ups=4.28, wpb=3560.9, bsz=102.1, num_updates=15900, lr=0.000250785, gnorm=0.921, train_wall=23, wall=0
2024-07-14 18:30:00 | INFO | train_inner | epoch 001:  16000 / 150053 loss=5.862, nll_loss=4.66, ppl=25.28, wps=15348.8, ups=4.28, wpb=3587.4, bsz=108.7, num_updates=16000, lr=0.00025, gnorm=0.91, train_wall=23, wall=0
2024-07-14 18:30:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 18:30:02 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.301 | nll_loss 5.106 | ppl 34.44 | wps 43297.7 | wpb 2588.8 | bsz 75.3 | num_updates 16000 | best_loss 12.174
2024-07-14 18:30:02 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 18:30:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_16000.pt (epoch 1 @ 16000 updates, score 6.301) (writing took 5.88447218388319 seconds)
2024-07-14 18:30:32 | INFO | train_inner | epoch 001:  16100 / 150053 loss=5.949, nll_loss=4.759, ppl=27.08, wps=10856.6, ups=3.1, wpb=3507.6, bsz=104.5, num_updates=16100, lr=0.000249222, gnorm=0.982, train_wall=24, wall=0
2024-07-14 18:30:55 | INFO | train_inner | epoch 001:  16200 / 150053 loss=6.001, nll_loss=4.819, ppl=28.22, wps=15277.8, ups=4.32, wpb=3534.7, bsz=95.8, num_updates=16200, lr=0.000248452, gnorm=0.943, train_wall=23, wall=0
2024-07-14 18:31:18 | INFO | train_inner | epoch 001:  16300 / 150053 loss=5.858, nll_loss=4.655, ppl=25.2, wps=15494.1, ups=4.29, wpb=3611.1, bsz=115.8, num_updates=16300, lr=0.000247689, gnorm=0.926, train_wall=23, wall=0
2024-07-14 18:31:42 | INFO | train_inner | epoch 001:  16400 / 150053 loss=5.966, nll_loss=4.779, ppl=27.45, wps=15323.3, ups=4.29, wpb=3569.5, bsz=99.4, num_updates=16400, lr=0.000246932, gnorm=0.981, train_wall=23, wall=0
2024-07-14 18:32:06 | INFO | train_inner | epoch 001:  16500 / 150053 loss=5.933, nll_loss=4.741, ppl=26.75, wps=14667.9, ups=4.16, wpb=3528.3, bsz=90.3, num_updates=16500, lr=0.000246183, gnorm=0.935, train_wall=24, wall=0
2024-07-14 18:32:28 | INFO | train_inner | epoch 001:  16600 / 150053 loss=5.886, nll_loss=4.688, ppl=25.78, wps=15593.2, ups=4.43, wpb=3521.1, bsz=113.3, num_updates=16600, lr=0.00024544, gnorm=0.948, train_wall=22, wall=0
2024-07-14 18:32:52 | INFO | train_inner | epoch 001:  16700 / 150053 loss=5.916, nll_loss=4.722, ppl=26.39, wps=15230.1, ups=4.28, wpb=3555.6, bsz=119.6, num_updates=16700, lr=0.000244704, gnorm=1.017, train_wall=23, wall=0
2024-07-14 18:33:15 | INFO | train_inner | epoch 001:  16800 / 150053 loss=5.878, nll_loss=4.678, ppl=25.6, wps=15442.9, ups=4.36, wpb=3541.1, bsz=99.9, num_updates=16800, lr=0.000243975, gnorm=0.959, train_wall=23, wall=0
2024-07-14 18:33:38 | INFO | train_inner | epoch 001:  16900 / 150053 loss=5.843, nll_loss=4.639, ppl=24.92, wps=15414.3, ups=4.34, wpb=3547.8, bsz=120.5, num_updates=16900, lr=0.000243252, gnorm=0.949, train_wall=23, wall=0
2024-07-14 18:34:01 | INFO | train_inner | epoch 001:  17000 / 150053 loss=5.893, nll_loss=4.695, ppl=25.9, wps=15432, ups=4.29, wpb=3594.3, bsz=110.6, num_updates=17000, lr=0.000242536, gnorm=0.938, train_wall=23, wall=0
2024-07-14 18:34:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 18:34:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.228 | nll_loss 5.01 | ppl 32.22 | wps 43588.2 | wpb 2588.8 | bsz 75.3 | num_updates 17000 | best_loss 12.174
2024-07-14 18:34:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 18:34:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_17000.pt (epoch 1 @ 17000 updates, score 6.228) (writing took 5.004181928932667 seconds)
2024-07-14 18:34:32 | INFO | train_inner | epoch 001:  17100 / 150053 loss=5.907, nll_loss=4.711, ppl=26.2, wps=11565.6, ups=3.21, wpb=3605.4, bsz=101.4, num_updates=17100, lr=0.000241825, gnorm=0.948, train_wall=23, wall=0
2024-07-14 18:34:55 | INFO | train_inner | epoch 001:  17200 / 150053 loss=5.957, nll_loss=4.768, ppl=27.25, wps=15480.8, ups=4.35, wpb=3555.4, bsz=96.1, num_updates=17200, lr=0.000241121, gnorm=0.922, train_wall=23, wall=0
2024-07-14 18:35:19 | INFO | train_inner | epoch 001:  17300 / 150053 loss=5.848, nll_loss=4.645, ppl=25.02, wps=15066.1, ups=4.21, wpb=3578.7, bsz=110.5, num_updates=17300, lr=0.000240424, gnorm=0.925, train_wall=24, wall=0
2024-07-14 18:35:43 | INFO | train_inner | epoch 001:  17400 / 150053 loss=5.818, nll_loss=4.611, ppl=24.44, wps=14914.8, ups=4.22, wpb=3530.8, bsz=112.6, num_updates=17400, lr=0.000239732, gnorm=0.936, train_wall=23, wall=0
2024-07-14 18:36:05 | INFO | train_inner | epoch 001:  17500 / 150053 loss=5.846, nll_loss=4.642, ppl=24.97, wps=15401.5, ups=4.4, wpb=3501.3, bsz=104.2, num_updates=17500, lr=0.000239046, gnorm=0.942, train_wall=23, wall=0
2024-07-14 18:36:28 | INFO | train_inner | epoch 001:  17600 / 150053 loss=5.841, nll_loss=4.637, ppl=24.88, wps=15226.7, ups=4.33, wpb=3513.8, bsz=96.9, num_updates=17600, lr=0.000238366, gnorm=0.916, train_wall=23, wall=0
2024-07-14 18:36:51 | INFO | train_inner | epoch 001:  17700 / 150053 loss=5.907, nll_loss=4.711, ppl=26.19, wps=15438.1, ups=4.34, wpb=3556.3, bsz=99.7, num_updates=17700, lr=0.000237691, gnorm=0.951, train_wall=23, wall=0
2024-07-14 18:37:15 | INFO | train_inner | epoch 001:  17800 / 150053 loss=5.912, nll_loss=4.718, ppl=26.31, wps=15556.5, ups=4.29, wpb=3624, bsz=103.9, num_updates=17800, lr=0.000237023, gnorm=0.959, train_wall=23, wall=0
2024-07-14 18:37:38 | INFO | train_inner | epoch 001:  17900 / 150053 loss=5.911, nll_loss=4.717, ppl=26.3, wps=15224.1, ups=4.35, wpb=3499.6, bsz=100.5, num_updates=17900, lr=0.00023636, gnorm=0.966, train_wall=23, wall=0
2024-07-14 18:38:01 | INFO | train_inner | epoch 001:  18000 / 150053 loss=5.839, nll_loss=4.635, ppl=24.84, wps=15325.8, ups=4.29, wpb=3572.1, bsz=104.4, num_updates=18000, lr=0.000235702, gnorm=0.914, train_wall=23, wall=0
2024-07-14 18:38:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 18:38:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.247 | nll_loss 5.052 | ppl 33.17 | wps 43775.2 | wpb 2588.8 | bsz 75.3 | num_updates 18000 | best_loss 12.174
2024-07-14 18:38:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 18:38:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_18000.pt (epoch 1 @ 18000 updates, score 6.247) (writing took 5.043364017270505 seconds)
2024-07-14 18:38:32 | INFO | train_inner | epoch 001:  18100 / 150053 loss=5.874, nll_loss=4.674, ppl=25.54, wps=11335.8, ups=3.2, wpb=3543.6, bsz=98.8, num_updates=18100, lr=0.00023505, gnorm=0.936, train_wall=23, wall=0
2024-07-14 18:38:55 | INFO | train_inner | epoch 001:  18200 / 150053 loss=5.869, nll_loss=4.668, ppl=25.43, wps=15401, ups=4.34, wpb=3551.5, bsz=116.9, num_updates=18200, lr=0.000234404, gnorm=0.951, train_wall=23, wall=0
2024-07-14 18:39:18 | INFO | train_inner | epoch 001:  18300 / 150053 loss=5.818, nll_loss=4.61, ppl=24.42, wps=15422.3, ups=4.31, wpb=3576.7, bsz=106.4, num_updates=18300, lr=0.000233762, gnorm=0.928, train_wall=23, wall=0
2024-07-14 18:39:41 | INFO | train_inner | epoch 001:  18400 / 150053 loss=5.877, nll_loss=4.678, ppl=25.59, wps=15090.7, ups=4.36, wpb=3462.3, bsz=96, num_updates=18400, lr=0.000233126, gnorm=0.95, train_wall=23, wall=0
2024-07-14 18:40:05 | INFO | train_inner | epoch 001:  18500 / 150053 loss=5.919, nll_loss=4.725, ppl=26.45, wps=14872.7, ups=4.29, wpb=3470.5, bsz=83.8, num_updates=18500, lr=0.000232495, gnorm=0.969, train_wall=23, wall=0
2024-07-14 18:40:28 | INFO | train_inner | epoch 001:  18600 / 150053 loss=5.766, nll_loss=4.552, ppl=23.45, wps=15291.1, ups=4.31, wpb=3547, bsz=115.9, num_updates=18600, lr=0.000231869, gnorm=0.938, train_wall=23, wall=0
2024-07-14 18:40:52 | INFO | train_inner | epoch 001:  18700 / 150053 loss=5.89, nll_loss=4.692, ppl=25.85, wps=14279.2, ups=4.16, wpb=3436.4, bsz=105, num_updates=18700, lr=0.000231249, gnorm=0.986, train_wall=24, wall=0
2024-07-14 18:41:15 | INFO | train_inner | epoch 001:  18800 / 150053 loss=5.884, nll_loss=4.685, ppl=25.73, wps=15394.7, ups=4.4, wpb=3495.2, bsz=99.4, num_updates=18800, lr=0.000230633, gnorm=0.954, train_wall=23, wall=0
2024-07-14 18:41:39 | INFO | train_inner | epoch 001:  18900 / 150053 loss=5.857, nll_loss=4.655, ppl=25.2, wps=14715.6, ups=4.2, wpb=3506.7, bsz=97, num_updates=18900, lr=0.000230022, gnorm=0.948, train_wall=24, wall=0
2024-07-14 18:42:02 | INFO | train_inner | epoch 001:  19000 / 150053 loss=5.831, nll_loss=4.626, ppl=24.69, wps=15444.2, ups=4.33, wpb=3562.7, bsz=101.2, num_updates=19000, lr=0.000229416, gnorm=0.953, train_wall=23, wall=0
2024-07-14 18:42:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 18:42:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.213 | nll_loss 5.004 | ppl 32.08 | wps 43619.1 | wpb 2588.8 | bsz 75.3 | num_updates 19000 | best_loss 12.174
2024-07-14 18:42:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 18:42:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_19000.pt (epoch 1 @ 19000 updates, score 6.213) (writing took 4.685835162177682 seconds)
2024-07-14 18:42:32 | INFO | train_inner | epoch 001:  19100 / 150053 loss=5.882, nll_loss=4.683, ppl=25.69, wps=11681.2, ups=3.26, wpb=3580.9, bsz=85.3, num_updates=19100, lr=0.000228814, gnorm=0.915, train_wall=23, wall=0
2024-07-14 18:42:56 | INFO | train_inner | epoch 001:  19200 / 150053 loss=5.819, nll_loss=4.612, ppl=24.45, wps=15378.3, ups=4.3, wpb=3575.5, bsz=98.9, num_updates=19200, lr=0.000228218, gnorm=0.915, train_wall=23, wall=0
2024-07-14 18:43:19 | INFO | train_inner | epoch 001:  19300 / 150053 loss=5.812, nll_loss=4.604, ppl=24.32, wps=15357.5, ups=4.35, wpb=3529.3, bsz=101.8, num_updates=19300, lr=0.000227626, gnorm=0.945, train_wall=23, wall=0
2024-07-14 18:43:42 | INFO | train_inner | epoch 001:  19400 / 150053 loss=5.788, nll_loss=4.577, ppl=23.86, wps=15172.3, ups=4.25, wpb=3572.4, bsz=110.4, num_updates=19400, lr=0.000227038, gnorm=0.946, train_wall=23, wall=0
2024-07-14 18:44:05 | INFO | train_inner | epoch 001:  19500 / 150053 loss=5.801, nll_loss=4.591, ppl=24.1, wps=15076.7, ups=4.27, wpb=3528.5, bsz=111.6, num_updates=19500, lr=0.000226455, gnorm=0.967, train_wall=23, wall=0
2024-07-14 18:44:28 | INFO | train_inner | epoch 001:  19600 / 150053 loss=5.785, nll_loss=4.573, ppl=23.8, wps=15657.4, ups=4.4, wpb=3558.9, bsz=106.9, num_updates=19600, lr=0.000225877, gnorm=0.945, train_wall=23, wall=0
2024-07-14 18:44:52 | INFO | train_inner | epoch 001:  19700 / 150053 loss=5.848, nll_loss=4.644, ppl=25.01, wps=15212.1, ups=4.26, wpb=3569.5, bsz=105.5, num_updates=19700, lr=0.000225303, gnorm=0.941, train_wall=23, wall=0
2024-07-14 18:45:15 | INFO | train_inner | epoch 001:  19800 / 150053 loss=5.871, nll_loss=4.671, ppl=25.47, wps=14801.6, ups=4.31, wpb=3437.3, bsz=97.2, num_updates=19800, lr=0.000224733, gnorm=0.971, train_wall=23, wall=0
2024-07-14 18:45:38 | INFO | train_inner | epoch 001:  19900 / 150053 loss=5.783, nll_loss=4.571, ppl=23.76, wps=15189.8, ups=4.34, wpb=3499.4, bsz=115.4, num_updates=19900, lr=0.000224168, gnorm=0.954, train_wall=23, wall=0
2024-07-14 18:46:01 | INFO | train_inner | epoch 001:  20000 / 150053 loss=5.808, nll_loss=4.599, ppl=24.24, wps=15282.7, ups=4.35, wpb=3515.1, bsz=92.5, num_updates=20000, lr=0.000223607, gnorm=0.938, train_wall=23, wall=0
2024-07-14 18:46:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 18:46:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.177 | nll_loss 4.96 | ppl 31.12 | wps 43902.3 | wpb 2588.8 | bsz 75.3 | num_updates 20000 | best_loss 12.174
2024-07-14 18:46:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 18:46:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_20000.pt (epoch 1 @ 20000 updates, score 6.177) (writing took 4.9779128562659025 seconds)
2024-07-14 18:46:32 | INFO | train_inner | epoch 001:  20100 / 150053 loss=5.729, nll_loss=4.51, ppl=22.79, wps=11485.5, ups=3.22, wpb=3564.3, bsz=112.7, num_updates=20100, lr=0.00022305, gnorm=0.915, train_wall=23, wall=0
2024-07-14 18:46:55 | INFO | train_inner | epoch 001:  20200 / 150053 loss=5.793, nll_loss=4.583, ppl=23.96, wps=15366.6, ups=4.31, wpb=3566.9, bsz=96.2, num_updates=20200, lr=0.000222497, gnorm=0.93, train_wall=23, wall=0
2024-07-14 18:47:18 | INFO | train_inner | epoch 001:  20300 / 150053 loss=5.787, nll_loss=4.577, ppl=23.86, wps=15301.8, ups=4.36, wpb=3508.2, bsz=105.4, num_updates=20300, lr=0.000221948, gnorm=0.935, train_wall=23, wall=0
2024-07-14 18:47:41 | INFO | train_inner | epoch 001:  20400 / 150053 loss=5.808, nll_loss=4.6, ppl=24.26, wps=15336.7, ups=4.34, wpb=3530.7, bsz=99.2, num_updates=20400, lr=0.000221404, gnorm=0.947, train_wall=23, wall=0
2024-07-14 18:48:05 | INFO | train_inner | epoch 001:  20500 / 150053 loss=5.776, nll_loss=4.563, ppl=23.63, wps=15374.2, ups=4.28, wpb=3595.7, bsz=107.8, num_updates=20500, lr=0.000220863, gnorm=0.956, train_wall=23, wall=0
2024-07-14 18:48:28 | INFO | train_inner | epoch 001:  20600 / 150053 loss=5.823, nll_loss=4.617, ppl=24.54, wps=15185.8, ups=4.33, wpb=3505.8, bsz=102.6, num_updates=20600, lr=0.000220326, gnorm=0.985, train_wall=23, wall=0
2024-07-14 18:48:51 | INFO | train_inner | epoch 001:  20700 / 150053 loss=5.894, nll_loss=4.698, ppl=25.95, wps=15451.4, ups=4.36, wpb=3543.4, bsz=96.1, num_updates=20700, lr=0.000219793, gnorm=0.953, train_wall=23, wall=0
2024-07-14 18:49:13 | INFO | train_inner | epoch 001:  20800 / 150053 loss=5.771, nll_loss=4.557, ppl=23.54, wps=15256.9, ups=4.35, wpb=3504, bsz=99.7, num_updates=20800, lr=0.000219265, gnorm=0.946, train_wall=23, wall=0
2024-07-14 18:49:37 | INFO | train_inner | epoch 001:  20900 / 150053 loss=5.759, nll_loss=4.544, ppl=23.33, wps=15399, ups=4.3, wpb=3580.9, bsz=116, num_updates=20900, lr=0.000218739, gnorm=0.95, train_wall=23, wall=0
2024-07-14 18:50:00 | INFO | train_inner | epoch 001:  21000 / 150053 loss=5.782, nll_loss=4.57, ppl=23.76, wps=15097.2, ups=4.23, wpb=3565.4, bsz=100.6, num_updates=21000, lr=0.000218218, gnorm=0.939, train_wall=23, wall=0
2024-07-14 18:50:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 18:50:03 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.192 | nll_loss 4.983 | ppl 31.63 | wps 43425.1 | wpb 2588.8 | bsz 75.3 | num_updates 21000 | best_loss 12.174
2024-07-14 18:50:03 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 18:50:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_21000.pt (epoch 1 @ 21000 updates, score 6.192) (writing took 5.4183327574282885 seconds)
2024-07-14 18:50:32 | INFO | train_inner | epoch 001:  21100 / 150053 loss=5.764, nll_loss=4.55, ppl=23.42, wps=11259.2, ups=3.21, wpb=3507.2, bsz=108.6, num_updates=21100, lr=0.0002177, gnorm=0.953, train_wall=23, wall=0
2024-07-14 18:50:55 | INFO | train_inner | epoch 001:  21200 / 150053 loss=5.814, nll_loss=4.607, ppl=24.37, wps=15148.6, ups=4.32, wpb=3503.1, bsz=93.4, num_updates=21200, lr=0.000217186, gnorm=0.957, train_wall=23, wall=0
2024-07-14 18:51:18 | INFO | train_inner | epoch 001:  21300 / 150053 loss=5.747, nll_loss=4.53, ppl=23.1, wps=15443.3, ups=4.24, wpb=3643.3, bsz=98.2, num_updates=21300, lr=0.000216676, gnorm=0.911, train_wall=23, wall=0
2024-07-14 18:51:41 | INFO | train_inner | epoch 001:  21400 / 150053 loss=5.748, nll_loss=4.531, ppl=23.12, wps=15144, ups=4.33, wpb=3498.7, bsz=103.8, num_updates=21400, lr=0.000216169, gnorm=0.979, train_wall=23, wall=0
2024-07-14 18:52:04 | INFO | train_inner | epoch 001:  21500 / 150053 loss=5.858, nll_loss=4.657, ppl=25.23, wps=14978.4, ups=4.32, wpb=3465.2, bsz=91, num_updates=21500, lr=0.000215666, gnorm=0.998, train_wall=23, wall=0
2024-07-14 18:52:28 | INFO | train_inner | epoch 001:  21600 / 150053 loss=5.826, nll_loss=4.621, ppl=24.6, wps=14865.4, ups=4.23, wpb=3511.7, bsz=103.8, num_updates=21600, lr=0.000215166, gnorm=0.976, train_wall=23, wall=0
2024-07-14 18:52:51 | INFO | train_inner | epoch 001:  21700 / 150053 loss=5.793, nll_loss=4.583, ppl=23.97, wps=15012.2, ups=4.28, wpb=3508.9, bsz=97.7, num_updates=21700, lr=0.000214669, gnorm=0.932, train_wall=23, wall=0
2024-07-14 18:53:15 | INFO | train_inner | epoch 001:  21800 / 150053 loss=5.736, nll_loss=4.518, ppl=22.9, wps=15215, ups=4.28, wpb=3557.4, bsz=97.2, num_updates=21800, lr=0.000214176, gnorm=0.928, train_wall=23, wall=0
2024-07-14 18:53:38 | INFO | train_inner | epoch 001:  21900 / 150053 loss=5.799, nll_loss=4.59, ppl=24.09, wps=15108.6, ups=4.29, wpb=3522.7, bsz=96.9, num_updates=21900, lr=0.000213687, gnorm=0.939, train_wall=23, wall=0
2024-07-14 18:54:01 | INFO | train_inner | epoch 001:  22000 / 150053 loss=5.761, nll_loss=4.547, ppl=23.37, wps=15318, ups=4.32, wpb=3548.5, bsz=106.9, num_updates=22000, lr=0.000213201, gnorm=0.944, train_wall=23, wall=0
2024-07-14 18:54:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 18:54:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.132 | nll_loss 4.902 | ppl 29.89 | wps 43771.3 | wpb 2588.8 | bsz 75.3 | num_updates 22000 | best_loss 12.174
2024-07-14 18:54:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 18:54:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_22000.pt (epoch 1 @ 22000 updates, score 6.132) (writing took 5.322265055961907 seconds)
2024-07-14 18:54:33 | INFO | train_inner | epoch 001:  22100 / 150053 loss=5.755, nll_loss=4.54, ppl=23.26, wps=11531.3, ups=3.2, wpb=3599.2, bsz=105.1, num_updates=22100, lr=0.000212718, gnorm=0.924, train_wall=23, wall=0
2024-07-14 18:54:56 | INFO | train_inner | epoch 001:  22200 / 150053 loss=5.823, nll_loss=4.617, ppl=24.54, wps=15354.7, ups=4.33, wpb=3546.4, bsz=98.9, num_updates=22200, lr=0.000212238, gnorm=0.958, train_wall=23, wall=0
2024-07-14 18:55:19 | INFO | train_inner | epoch 001:  22300 / 150053 loss=5.731, nll_loss=4.512, ppl=22.82, wps=15009.8, ups=4.24, wpb=3541.5, bsz=95.4, num_updates=22300, lr=0.000211762, gnorm=0.932, train_wall=23, wall=0
2024-07-14 18:55:42 | INFO | train_inner | epoch 001:  22400 / 150053 loss=5.747, nll_loss=4.53, ppl=23.1, wps=15438, ups=4.35, wpb=3551.5, bsz=97, num_updates=22400, lr=0.000211289, gnorm=0.951, train_wall=23, wall=0
2024-07-14 18:56:05 | INFO | train_inner | epoch 001:  22500 / 150053 loss=5.832, nll_loss=4.627, ppl=24.72, wps=14909.8, ups=4.33, wpb=3443.6, bsz=103.8, num_updates=22500, lr=0.000210819, gnorm=0.967, train_wall=23, wall=0
2024-07-14 18:56:29 | INFO | train_inner | epoch 001:  22600 / 150053 loss=5.733, nll_loss=4.513, ppl=22.84, wps=15568, ups=4.31, wpb=3615.6, bsz=100.8, num_updates=22600, lr=0.000210352, gnorm=0.928, train_wall=23, wall=0
2024-07-14 18:56:52 | INFO | train_inner | epoch 001:  22700 / 150053 loss=5.746, nll_loss=4.53, ppl=23.11, wps=14796.8, ups=4.27, wpb=3468.2, bsz=103.8, num_updates=22700, lr=0.000209888, gnorm=0.943, train_wall=23, wall=0
2024-07-14 18:57:15 | INFO | train_inner | epoch 001:  22800 / 150053 loss=5.794, nll_loss=4.584, ppl=23.99, wps=14997.2, ups=4.3, wpb=3486.4, bsz=96.3, num_updates=22800, lr=0.000209427, gnorm=0.942, train_wall=23, wall=0
2024-07-14 18:57:38 | INFO | train_inner | epoch 001:  22900 / 150053 loss=5.813, nll_loss=4.607, ppl=24.37, wps=15124.6, ups=4.35, wpb=3476.6, bsz=88.3, num_updates=22900, lr=0.000208969, gnorm=1.027, train_wall=23, wall=0
2024-07-14 18:58:01 | INFO | train_inner | epoch 001:  23000 / 150053 loss=5.745, nll_loss=4.529, ppl=23.08, wps=15320.3, ups=4.31, wpb=3554.6, bsz=108.9, num_updates=23000, lr=0.000208514, gnorm=0.979, train_wall=23, wall=0
2024-07-14 18:58:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 18:58:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.103 | nll_loss 4.875 | ppl 29.35 | wps 43834.9 | wpb 2588.8 | bsz 75.3 | num_updates 23000 | best_loss 12.174
2024-07-14 18:58:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 18:58:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_23000.pt (epoch 1 @ 23000 updates, score 6.103) (writing took 5.273050772026181 seconds)
2024-07-14 18:58:33 | INFO | train_inner | epoch 001:  23100 / 150053 loss=5.766, nll_loss=4.551, ppl=23.45, wps=11440.3, ups=3.21, wpb=3567.8, bsz=100.2, num_updates=23100, lr=0.000208063, gnorm=0.972, train_wall=23, wall=0
2024-07-14 18:58:56 | INFO | train_inner | epoch 001:  23200 / 150053 loss=5.745, nll_loss=4.528, ppl=23.07, wps=15264, ups=4.37, wpb=3494.4, bsz=103.4, num_updates=23200, lr=0.000207614, gnorm=1.01, train_wall=23, wall=0
2024-07-14 18:59:19 | INFO | train_inner | epoch 001:  23300 / 150053 loss=5.659, nll_loss=4.431, ppl=21.56, wps=15437.6, ups=4.31, wpb=3580.2, bsz=112.8, num_updates=23300, lr=0.000207168, gnorm=0.919, train_wall=23, wall=0
2024-07-14 18:59:42 | INFO | train_inner | epoch 001:  23400 / 150053 loss=5.675, nll_loss=4.449, ppl=21.84, wps=15514, ups=4.32, wpb=3592.6, bsz=108.7, num_updates=23400, lr=0.000206725, gnorm=0.936, train_wall=23, wall=0
2024-07-14 19:00:05 | INFO | train_inner | epoch 001:  23500 / 150053 loss=5.732, nll_loss=4.514, ppl=22.84, wps=15181.5, ups=4.27, wpb=3553.8, bsz=95, num_updates=23500, lr=0.000206284, gnorm=0.932, train_wall=23, wall=0
2024-07-14 19:00:29 | INFO | train_inner | epoch 001:  23600 / 150053 loss=5.756, nll_loss=4.542, ppl=23.29, wps=15098.6, ups=4.27, wpb=3536.4, bsz=91.5, num_updates=23600, lr=0.000205847, gnorm=0.941, train_wall=23, wall=0
2024-07-14 19:00:52 | INFO | train_inner | epoch 001:  23700 / 150053 loss=5.705, nll_loss=4.483, ppl=22.36, wps=14992, ups=4.24, wpb=3537.2, bsz=104.3, num_updates=23700, lr=0.000205412, gnorm=0.93, train_wall=23, wall=0
2024-07-14 19:01:15 | INFO | train_inner | epoch 001:  23800 / 150053 loss=5.798, nll_loss=4.589, ppl=24.06, wps=15169.3, ups=4.33, wpb=3506.4, bsz=104.6, num_updates=23800, lr=0.00020498, gnorm=0.975, train_wall=23, wall=0
2024-07-14 19:01:39 | INFO | train_inner | epoch 001:  23900 / 150053 loss=5.763, nll_loss=4.549, ppl=23.41, wps=15292.4, ups=4.33, wpb=3531.8, bsz=93.6, num_updates=23900, lr=0.000204551, gnorm=0.939, train_wall=23, wall=0
2024-07-14 19:02:02 | INFO | train_inner | epoch 001:  24000 / 150053 loss=5.706, nll_loss=4.485, ppl=22.39, wps=15180.9, ups=4.26, wpb=3560.4, bsz=100.8, num_updates=24000, lr=0.000204124, gnorm=0.944, train_wall=23, wall=0
2024-07-14 19:02:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 19:02:05 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.163 | nll_loss 4.948 | ppl 30.87 | wps 43594.2 | wpb 2588.8 | bsz 75.3 | num_updates 24000 | best_loss 12.174
2024-07-14 19:02:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 19:02:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_24000.pt (epoch 1 @ 24000 updates, score 6.163) (writing took 5.73223621211946 seconds)
2024-07-14 19:02:34 | INFO | train_inner | epoch 001:  24100 / 150053 loss=5.772, nll_loss=4.559, ppl=23.57, wps=11215.5, ups=3.16, wpb=3551.2, bsz=96.4, num_updates=24100, lr=0.0002037, gnorm=0.979, train_wall=23, wall=0
2024-07-14 19:02:57 | INFO | train_inner | epoch 001:  24200 / 150053 loss=5.771, nll_loss=4.558, ppl=23.56, wps=14893.3, ups=4.33, wpb=3443.1, bsz=88.2, num_updates=24200, lr=0.000203279, gnorm=0.959, train_wall=23, wall=0
2024-07-14 19:03:21 | INFO | train_inner | epoch 001:  24300 / 150053 loss=5.663, nll_loss=4.435, ppl=21.63, wps=14820.4, ups=4.2, wpb=3528.9, bsz=127.1, num_updates=24300, lr=0.00020286, gnorm=0.968, train_wall=24, wall=0
2024-07-14 19:03:44 | INFO | train_inner | epoch 001:  24400 / 150053 loss=5.679, nll_loss=4.453, ppl=21.91, wps=15258.9, ups=4.34, wpb=3519.1, bsz=104.6, num_updates=24400, lr=0.000202444, gnorm=0.94, train_wall=23, wall=0
2024-07-14 19:04:07 | INFO | train_inner | epoch 001:  24500 / 150053 loss=5.707, nll_loss=4.486, ppl=22.4, wps=15683.7, ups=4.31, wpb=3639.6, bsz=116.6, num_updates=24500, lr=0.000202031, gnorm=0.932, train_wall=23, wall=0
2024-07-14 19:04:30 | INFO | train_inner | epoch 001:  24600 / 150053 loss=5.717, nll_loss=4.497, ppl=22.58, wps=15289.5, ups=4.35, wpb=3512.4, bsz=94.5, num_updates=24600, lr=0.000201619, gnorm=0.968, train_wall=23, wall=0
2024-07-14 19:04:53 | INFO | train_inner | epoch 001:  24700 / 150053 loss=5.747, nll_loss=4.531, ppl=23.12, wps=15179.9, ups=4.33, wpb=3508.1, bsz=97.2, num_updates=24700, lr=0.000201211, gnorm=0.971, train_wall=23, wall=0
2024-07-14 19:05:16 | INFO | train_inner | epoch 001:  24800 / 150053 loss=5.701, nll_loss=4.478, ppl=22.29, wps=15438.8, ups=4.29, wpb=3599.7, bsz=107.7, num_updates=24800, lr=0.000200805, gnorm=0.936, train_wall=23, wall=0
2024-07-14 19:05:39 | INFO | train_inner | epoch 001:  24900 / 150053 loss=5.692, nll_loss=4.468, ppl=22.14, wps=15263.7, ups=4.31, wpb=3543.9, bsz=116.7, num_updates=24900, lr=0.000200401, gnorm=1.009, train_wall=23, wall=0
2024-07-14 19:06:03 | INFO | train_inner | epoch 001:  25000 / 150053 loss=5.677, nll_loss=4.451, ppl=21.87, wps=15511.1, ups=4.3, wpb=3606.2, bsz=109.4, num_updates=25000, lr=0.0002, gnorm=0.955, train_wall=23, wall=0
2024-07-14 19:06:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 19:06:05 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.106 | nll_loss 4.868 | ppl 29.21 | wps 43714.1 | wpb 2588.8 | bsz 75.3 | num_updates 25000 | best_loss 12.174
2024-07-14 19:06:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 19:06:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_25000.pt (epoch 1 @ 25000 updates, score 6.106) (writing took 5.985103411599994 seconds)
2024-07-14 19:06:35 | INFO | train_inner | epoch 001:  25100 / 150053 loss=5.729, nll_loss=4.512, ppl=22.81, wps=10948.1, ups=3.13, wpb=3502.9, bsz=103.6, num_updates=25100, lr=0.000199601, gnorm=0.958, train_wall=23, wall=0
2024-07-14 19:06:58 | INFO | train_inner | epoch 001:  25200 / 150053 loss=5.748, nll_loss=4.532, ppl=23.14, wps=15353.5, ups=4.32, wpb=3557.4, bsz=100.1, num_updates=25200, lr=0.000199205, gnorm=1.028, train_wall=23, wall=0
2024-07-14 19:07:21 | INFO | train_inner | epoch 001:  25300 / 150053 loss=5.646, nll_loss=4.416, ppl=21.35, wps=15310.1, ups=4.32, wpb=3546, bsz=115.2, num_updates=25300, lr=0.000198811, gnorm=0.939, train_wall=23, wall=0
2024-07-14 19:07:44 | INFO | train_inner | epoch 001:  25400 / 150053 loss=5.719, nll_loss=4.499, ppl=22.61, wps=15011.1, ups=4.35, wpb=3448.4, bsz=96.2, num_updates=25400, lr=0.000198419, gnorm=0.967, train_wall=23, wall=0
2024-07-14 19:08:07 | INFO | train_inner | epoch 001:  25500 / 150053 loss=5.657, nll_loss=4.428, ppl=21.53, wps=15363.8, ups=4.3, wpb=3574.3, bsz=116.3, num_updates=25500, lr=0.00019803, gnorm=0.953, train_wall=23, wall=0
2024-07-14 19:08:30 | INFO | train_inner | epoch 001:  25600 / 150053 loss=5.696, nll_loss=4.473, ppl=22.21, wps=15346.3, ups=4.32, wpb=3551.9, bsz=98.6, num_updates=25600, lr=0.000197642, gnorm=0.988, train_wall=23, wall=0
2024-07-14 19:08:54 | INFO | train_inner | epoch 001:  25700 / 150053 loss=5.667, nll_loss=4.44, ppl=21.71, wps=14731.1, ups=4.19, wpb=3518.7, bsz=113.8, num_updates=25700, lr=0.000197257, gnorm=0.942, train_wall=24, wall=0
2024-07-14 19:09:18 | INFO | train_inner | epoch 001:  25800 / 150053 loss=5.688, nll_loss=4.463, ppl=22.06, wps=15226.4, ups=4.28, wpb=3559.2, bsz=109, num_updates=25800, lr=0.000196875, gnorm=0.952, train_wall=23, wall=0
2024-07-14 19:09:41 | INFO | train_inner | epoch 001:  25900 / 150053 loss=5.714, nll_loss=4.494, ppl=22.53, wps=15244.2, ups=4.29, wpb=3555.2, bsz=93.4, num_updates=25900, lr=0.000196494, gnorm=0.941, train_wall=23, wall=0
2024-07-14 19:10:04 | INFO | train_inner | epoch 001:  26000 / 150053 loss=5.708, nll_loss=4.487, ppl=22.42, wps=15092.6, ups=4.28, wpb=3527, bsz=92.6, num_updates=26000, lr=0.000196116, gnorm=0.95, train_wall=23, wall=0
2024-07-14 19:10:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 19:10:07 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.086 | nll_loss 4.86 | ppl 29.04 | wps 43108.7 | wpb 2588.8 | bsz 75.3 | num_updates 26000 | best_loss 12.174
2024-07-14 19:10:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 19:10:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_26000.pt (epoch 1 @ 26000 updates, score 6.086) (writing took 5.647645276039839 seconds)
2024-07-14 19:10:36 | INFO | train_inner | epoch 001:  26100 / 150053 loss=5.639, nll_loss=4.409, ppl=21.24, wps=11301.8, ups=3.15, wpb=3590.7, bsz=102.6, num_updates=26100, lr=0.00019574, gnorm=0.929, train_wall=23, wall=0
2024-07-14 19:10:59 | INFO | train_inner | epoch 001:  26200 / 150053 loss=5.681, nll_loss=4.455, ppl=21.94, wps=15439.8, ups=4.35, wpb=3548.4, bsz=103.6, num_updates=26200, lr=0.000195366, gnorm=0.974, train_wall=23, wall=0
2024-07-14 19:11:22 | INFO | train_inner | epoch 001:  26300 / 150053 loss=5.692, nll_loss=4.469, ppl=22.15, wps=15253.9, ups=4.28, wpb=3560.2, bsz=106.5, num_updates=26300, lr=0.000194994, gnorm=0.976, train_wall=23, wall=0
2024-07-14 19:11:45 | INFO | train_inner | epoch 001:  26400 / 150053 loss=5.702, nll_loss=4.479, ppl=22.3, wps=15424.9, ups=4.35, wpb=3548.7, bsz=106.1, num_updates=26400, lr=0.000194625, gnorm=0.973, train_wall=23, wall=0
2024-07-14 19:12:09 | INFO | train_inner | epoch 001:  26500 / 150053 loss=5.65, nll_loss=4.421, ppl=21.42, wps=15063.8, ups=4.31, wpb=3491.3, bsz=113.6, num_updates=26500, lr=0.000194257, gnorm=0.989, train_wall=23, wall=0
2024-07-14 19:12:32 | INFO | train_inner | epoch 001:  26600 / 150053 loss=5.708, nll_loss=4.486, ppl=22.41, wps=15145.9, ups=4.29, wpb=3529.3, bsz=100.5, num_updates=26600, lr=0.000193892, gnorm=0.96, train_wall=23, wall=0
2024-07-14 19:12:56 | INFO | train_inner | epoch 001:  26700 / 150053 loss=5.633, nll_loss=4.402, ppl=21.13, wps=14796.9, ups=4.15, wpb=3565.4, bsz=108.1, num_updates=26700, lr=0.000193528, gnorm=0.967, train_wall=24, wall=0
2024-07-14 19:13:19 | INFO | train_inner | epoch 001:  26800 / 150053 loss=5.671, nll_loss=4.444, ppl=21.77, wps=15463.5, ups=4.35, wpb=3557.8, bsz=94.2, num_updates=26800, lr=0.000193167, gnorm=0.95, train_wall=23, wall=0
2024-07-14 19:13:42 | INFO | train_inner | epoch 001:  26900 / 150053 loss=5.684, nll_loss=4.46, ppl=22.01, wps=15080.3, ups=4.33, wpb=3479.7, bsz=93.8, num_updates=26900, lr=0.000192807, gnorm=0.944, train_wall=23, wall=0
2024-07-14 19:14:05 | INFO | train_inner | epoch 001:  27000 / 150053 loss=5.658, nll_loss=4.43, ppl=21.55, wps=15365.8, ups=4.34, wpb=3538.3, bsz=103.4, num_updates=27000, lr=0.00019245, gnorm=0.961, train_wall=23, wall=0
2024-07-14 19:14:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 19:14:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.079 | nll_loss 4.84 | ppl 28.64 | wps 43467.2 | wpb 2588.8 | bsz 75.3 | num_updates 27000 | best_loss 12.174
2024-07-14 19:14:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 19:14:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_27000.pt (epoch 1 @ 27000 updates, score 6.079) (writing took 6.7451887130737305 seconds)
2024-07-14 19:14:38 | INFO | train_inner | epoch 001:  27100 / 150053 loss=5.657, nll_loss=4.429, ppl=21.54, wps=10738.4, ups=3.04, wpb=3531.3, bsz=105, num_updates=27100, lr=0.000192095, gnorm=0.988, train_wall=23, wall=0
2024-07-14 19:15:01 | INFO | train_inner | epoch 001:  27200 / 150053 loss=5.684, nll_loss=4.459, ppl=22, wps=15524, ups=4.38, wpb=3541.8, bsz=103, num_updates=27200, lr=0.000191741, gnorm=0.976, train_wall=23, wall=0
2024-07-14 19:15:24 | INFO | train_inner | epoch 001:  27300 / 150053 loss=5.624, nll_loss=4.392, ppl=20.99, wps=15327.1, ups=4.31, wpb=3555.1, bsz=106.7, num_updates=27300, lr=0.00019139, gnorm=0.929, train_wall=23, wall=0
2024-07-14 19:15:48 | INFO | train_inner | epoch 001:  27400 / 150053 loss=5.735, nll_loss=4.517, ppl=22.89, wps=14758.4, ups=4.24, wpb=3478.2, bsz=89.7, num_updates=27400, lr=0.00019104, gnorm=0.965, train_wall=23, wall=0
2024-07-14 19:16:11 | INFO | train_inner | epoch 001:  27500 / 150053 loss=5.644, nll_loss=4.415, ppl=21.33, wps=15193.9, ups=4.3, wpb=3529.5, bsz=104.2, num_updates=27500, lr=0.000190693, gnorm=0.976, train_wall=23, wall=0
2024-07-14 19:16:34 | INFO | train_inner | epoch 001:  27600 / 150053 loss=5.663, nll_loss=4.435, ppl=21.64, wps=15407.9, ups=4.32, wpb=3569.9, bsz=107.4, num_updates=27600, lr=0.000190347, gnorm=0.99, train_wall=23, wall=0
2024-07-14 19:16:58 | INFO | train_inner | epoch 001:  27700 / 150053 loss=5.645, nll_loss=4.416, ppl=21.35, wps=15105.6, ups=4.26, wpb=3548.6, bsz=102.2, num_updates=27700, lr=0.000190003, gnorm=0.958, train_wall=23, wall=0
2024-07-14 19:17:21 | INFO | train_inner | epoch 001:  27800 / 150053 loss=5.678, nll_loss=4.453, ppl=21.9, wps=15012.3, ups=4.25, wpb=3528.5, bsz=93.8, num_updates=27800, lr=0.000189661, gnorm=0.986, train_wall=23, wall=0
2024-07-14 19:17:45 | INFO | train_inner | epoch 001:  27900 / 150053 loss=5.593, nll_loss=4.356, ppl=20.48, wps=15227.6, ups=4.22, wpb=3606.3, bsz=105.4, num_updates=27900, lr=0.000189321, gnorm=0.933, train_wall=23, wall=0
2024-07-14 19:18:08 | INFO | train_inner | epoch 001:  28000 / 150053 loss=5.595, nll_loss=4.359, ppl=20.52, wps=15305.4, ups=4.24, wpb=3609.7, bsz=118.2, num_updates=28000, lr=0.000188982, gnorm=0.954, train_wall=23, wall=0
2024-07-14 19:18:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 19:18:11 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.056 | nll_loss 4.811 | ppl 28.07 | wps 43339.9 | wpb 2588.8 | bsz 75.3 | num_updates 28000 | best_loss 12.174
2024-07-14 19:18:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 19:18:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_28000.pt (epoch 1 @ 28000 updates, score 6.056) (writing took 5.150433181785047 seconds)
2024-07-14 19:18:39 | INFO | train_inner | epoch 001:  28100 / 150053 loss=5.66, nll_loss=4.433, ppl=21.6, wps=11233.4, ups=3.23, wpb=3478.8, bsz=94.4, num_updates=28100, lr=0.000188646, gnorm=0.966, train_wall=23, wall=0
2024-07-14 19:19:02 | INFO | train_inner | epoch 001:  28200 / 150053 loss=5.665, nll_loss=4.439, ppl=21.69, wps=14960.7, ups=4.32, wpb=3466.6, bsz=108.4, num_updates=28200, lr=0.000188311, gnorm=0.961, train_wall=23, wall=0
2024-07-14 19:19:26 | INFO | train_inner | epoch 001:  28300 / 150053 loss=5.672, nll_loss=4.446, ppl=21.8, wps=15118.6, ups=4.28, wpb=3530.2, bsz=89.1, num_updates=28300, lr=0.000187978, gnorm=0.96, train_wall=23, wall=0
2024-07-14 19:19:49 | INFO | train_inner | epoch 001:  28400 / 150053 loss=5.583, nll_loss=4.344, ppl=20.31, wps=15163.2, ups=4.24, wpb=3575, bsz=111, num_updates=28400, lr=0.000187647, gnorm=0.949, train_wall=23, wall=0
2024-07-14 19:20:12 | INFO | train_inner | epoch 001:  28500 / 150053 loss=5.698, nll_loss=4.476, ppl=22.25, wps=15253.6, ups=4.33, wpb=3523.4, bsz=89.7, num_updates=28500, lr=0.000187317, gnorm=0.967, train_wall=23, wall=0
2024-07-14 19:20:36 | INFO | train_inner | epoch 001:  28600 / 150053 loss=5.625, nll_loss=4.393, ppl=21.01, wps=15067.5, ups=4.24, wpb=3553.5, bsz=102.3, num_updates=28600, lr=0.000186989, gnorm=0.97, train_wall=23, wall=0
2024-07-14 19:20:59 | INFO | train_inner | epoch 001:  28700 / 150053 loss=5.633, nll_loss=4.402, ppl=21.14, wps=15211, ups=4.32, wpb=3520.6, bsz=113.4, num_updates=28700, lr=0.000186663, gnorm=0.974, train_wall=23, wall=0
2024-07-14 19:21:23 | INFO | train_inner | epoch 001:  28800 / 150053 loss=5.698, nll_loss=4.476, ppl=22.25, wps=15115.2, ups=4.25, wpb=3559.9, bsz=90.2, num_updates=28800, lr=0.000186339, gnorm=0.97, train_wall=23, wall=0
2024-07-14 19:21:46 | INFO | train_inner | epoch 001:  28900 / 150053 loss=5.671, nll_loss=4.445, ppl=21.78, wps=15209, ups=4.36, wpb=3490.8, bsz=101.4, num_updates=28900, lr=0.000186016, gnorm=0.997, train_wall=23, wall=0
2024-07-14 19:22:09 | INFO | train_inner | epoch 001:  29000 / 150053 loss=5.59, nll_loss=4.353, ppl=20.44, wps=15047.8, ups=4.29, wpb=3507.6, bsz=118.6, num_updates=29000, lr=0.000185695, gnorm=1.016, train_wall=23, wall=0
2024-07-14 19:22:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 19:22:12 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.037 | nll_loss 4.8 | ppl 27.86 | wps 43560.3 | wpb 2588.8 | bsz 75.3 | num_updates 29000 | best_loss 12.174
2024-07-14 19:22:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 19:22:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_29000.pt (epoch 1 @ 29000 updates, score 6.037) (writing took 4.218906513415277 seconds)
2024-07-14 19:22:39 | INFO | train_inner | epoch 001:  29100 / 150053 loss=5.655, nll_loss=4.427, ppl=21.51, wps=11801.6, ups=3.33, wpb=3542.7, bsz=88.4, num_updates=29100, lr=0.000185376, gnorm=0.973, train_wall=23, wall=0
2024-07-14 19:23:03 | INFO | train_inner | epoch 001:  29200 / 150053 loss=5.658, nll_loss=4.43, ppl=21.56, wps=15298, ups=4.25, wpb=3599.5, bsz=101.8, num_updates=29200, lr=0.000185058, gnorm=0.97, train_wall=23, wall=0
2024-07-14 19:23:26 | INFO | train_inner | epoch 001:  29300 / 150053 loss=5.612, nll_loss=4.378, ppl=20.79, wps=15256, ups=4.27, wpb=3574.5, bsz=101.8, num_updates=29300, lr=0.000184742, gnorm=0.947, train_wall=23, wall=0
2024-07-14 19:23:49 | INFO | train_inner | epoch 001:  29400 / 150053 loss=5.64, nll_loss=4.409, ppl=21.25, wps=15515.2, ups=4.36, wpb=3561.1, bsz=102.1, num_updates=29400, lr=0.000184428, gnorm=0.956, train_wall=23, wall=0
2024-07-14 19:24:12 | INFO | train_inner | epoch 001:  29500 / 150053 loss=5.58, nll_loss=4.342, ppl=20.28, wps=15353.7, ups=4.31, wpb=3559.4, bsz=103, num_updates=29500, lr=0.000184115, gnorm=0.94, train_wall=23, wall=0
2024-07-14 19:24:35 | INFO | train_inner | epoch 001:  29600 / 150053 loss=5.589, nll_loss=4.352, ppl=20.42, wps=15067.1, ups=4.28, wpb=3517.6, bsz=98.8, num_updates=29600, lr=0.000183804, gnorm=0.947, train_wall=23, wall=0
2024-07-14 19:24:59 | INFO | train_inner | epoch 001:  29700 / 150053 loss=5.637, nll_loss=4.406, ppl=21.2, wps=15078.4, ups=4.3, wpb=3507.6, bsz=100.2, num_updates=29700, lr=0.000183494, gnorm=0.976, train_wall=23, wall=0
2024-07-14 19:25:22 | INFO | train_inner | epoch 001:  29800 / 150053 loss=5.65, nll_loss=4.421, ppl=21.42, wps=15238, ups=4.27, wpb=3569.3, bsz=98.7, num_updates=29800, lr=0.000183186, gnorm=0.965, train_wall=23, wall=0
2024-07-14 19:25:45 | INFO | train_inner | epoch 001:  29900 / 150053 loss=5.619, nll_loss=4.386, ppl=20.91, wps=15316.5, ups=4.33, wpb=3534.7, bsz=105.3, num_updates=29900, lr=0.000182879, gnorm=0.971, train_wall=23, wall=0
2024-07-14 19:26:08 | INFO | train_inner | epoch 001:  30000 / 150053 loss=5.559, nll_loss=4.318, ppl=19.95, wps=15218.5, ups=4.32, wpb=3526.4, bsz=117, num_updates=30000, lr=0.000182574, gnorm=0.963, train_wall=23, wall=0
2024-07-14 19:26:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 19:26:11 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.032 | nll_loss 4.776 | ppl 27.41 | wps 43713.4 | wpb 2588.8 | bsz 75.3 | num_updates 30000 | best_loss 12.174
2024-07-14 19:26:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 19:26:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_30000.pt (epoch 1 @ 30000 updates, score 6.032) (writing took 4.329072183929384 seconds)
2024-07-14 19:26:39 | INFO | train_inner | epoch 001:  30100 / 150053 loss=5.618, nll_loss=4.384, ppl=20.88, wps=11721.4, ups=3.3, wpb=3549.8, bsz=105.9, num_updates=30100, lr=0.000182271, gnorm=0.995, train_wall=23, wall=0
2024-07-14 19:27:02 | INFO | train_inner | epoch 001:  30200 / 150053 loss=5.607, nll_loss=4.372, ppl=20.71, wps=15166.6, ups=4.35, wpb=3487.3, bsz=107, num_updates=30200, lr=0.000181969, gnorm=0.973, train_wall=23, wall=0
2024-07-14 19:27:25 | INFO | train_inner | epoch 001:  30300 / 150053 loss=5.647, nll_loss=4.417, ppl=21.36, wps=15519.8, ups=4.33, wpb=3584.3, bsz=101.1, num_updates=30300, lr=0.000181668, gnorm=0.945, train_wall=23, wall=0
2024-07-14 19:27:48 | INFO | train_inner | epoch 001:  30400 / 150053 loss=5.589, nll_loss=4.352, ppl=20.41, wps=15234.1, ups=4.3, wpb=3544.7, bsz=105.8, num_updates=30400, lr=0.000181369, gnorm=0.954, train_wall=23, wall=0
2024-07-14 19:28:12 | INFO | train_inner | epoch 001:  30500 / 150053 loss=5.594, nll_loss=4.357, ppl=20.49, wps=15070.7, ups=4.22, wpb=3572.1, bsz=105.8, num_updates=30500, lr=0.000181071, gnorm=0.962, train_wall=24, wall=0
2024-07-14 19:28:35 | INFO | train_inner | epoch 001:  30600 / 150053 loss=5.626, nll_loss=4.395, ppl=21.04, wps=15384.7, ups=4.33, wpb=3553.6, bsz=95.7, num_updates=30600, lr=0.000180775, gnorm=0.964, train_wall=23, wall=0
2024-07-14 19:28:58 | INFO | train_inner | epoch 001:  30700 / 150053 loss=5.676, nll_loss=4.451, ppl=21.88, wps=15216.7, ups=4.31, wpb=3527, bsz=102.4, num_updates=30700, lr=0.000180481, gnorm=1.012, train_wall=23, wall=0
2024-07-14 19:29:22 | INFO | train_inner | epoch 001:  30800 / 150053 loss=5.638, nll_loss=4.407, ppl=21.21, wps=15070.7, ups=4.26, wpb=3536.3, bsz=97.5, num_updates=30800, lr=0.000180187, gnorm=0.962, train_wall=23, wall=0
2024-07-14 19:29:45 | INFO | train_inner | epoch 001:  30900 / 150053 loss=5.638, nll_loss=4.407, ppl=21.22, wps=15215.6, ups=4.3, wpb=3539, bsz=98.8, num_updates=30900, lr=0.000179896, gnorm=0.945, train_wall=23, wall=0
2024-07-14 19:30:08 | INFO | train_inner | epoch 001:  31000 / 150053 loss=5.652, nll_loss=4.423, ppl=21.45, wps=15390.9, ups=4.33, wpb=3554, bsz=114.7, num_updates=31000, lr=0.000179605, gnorm=1.12, train_wall=23, wall=0
2024-07-14 19:30:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 19:30:11 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.037 | nll_loss 4.8 | ppl 27.86 | wps 43668.9 | wpb 2588.8 | bsz 75.3 | num_updates 31000 | best_loss 12.174
2024-07-14 19:30:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 19:30:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_31000.pt (epoch 1 @ 31000 updates, score 6.037) (writing took 3.787367478944361 seconds)
2024-07-14 19:30:37 | INFO | train_inner | epoch 001:  31100 / 150053 loss=5.608, nll_loss=4.373, ppl=20.72, wps=12141.6, ups=3.4, wpb=3576.1, bsz=97.4, num_updates=31100, lr=0.000179316, gnorm=0.988, train_wall=23, wall=0
2024-07-14 19:31:00 | INFO | train_inner | epoch 001:  31200 / 150053 loss=5.575, nll_loss=4.335, ppl=20.19, wps=15289.2, ups=4.33, wpb=3534.7, bsz=109, num_updates=31200, lr=0.000179029, gnorm=0.961, train_wall=23, wall=0
2024-07-14 19:31:23 | INFO | train_inner | epoch 001:  31300 / 150053 loss=5.645, nll_loss=4.416, ppl=21.34, wps=15017.7, ups=4.34, wpb=3462.6, bsz=89.7, num_updates=31300, lr=0.000178743, gnorm=0.96, train_wall=23, wall=0
2024-07-14 19:31:47 | INFO | train_inner | epoch 001:  31400 / 150053 loss=5.664, nll_loss=4.437, ppl=21.66, wps=15055.7, ups=4.26, wpb=3530.1, bsz=91, num_updates=31400, lr=0.000178458, gnorm=1.012, train_wall=23, wall=0
2024-07-14 19:32:10 | INFO | train_inner | epoch 001:  31500 / 150053 loss=5.625, nll_loss=4.394, ppl=21.02, wps=14786, ups=4.35, wpb=3395.4, bsz=94.2, num_updates=31500, lr=0.000178174, gnorm=0.979, train_wall=23, wall=0
2024-07-14 19:32:34 | INFO | train_inner | epoch 001:  31600 / 150053 loss=5.553, nll_loss=4.31, ppl=19.84, wps=15319.6, ups=4.2, wpb=3646.3, bsz=108.2, num_updates=31600, lr=0.000177892, gnorm=0.944, train_wall=24, wall=0
2024-07-14 19:32:57 | INFO | train_inner | epoch 001:  31700 / 150053 loss=5.589, nll_loss=4.353, ppl=20.43, wps=15229.6, ups=4.38, wpb=3480.7, bsz=110.6, num_updates=31700, lr=0.000177611, gnorm=1.012, train_wall=23, wall=0
2024-07-14 19:33:20 | INFO | train_inner | epoch 001:  31800 / 150053 loss=5.604, nll_loss=4.37, ppl=20.67, wps=15286.2, ups=4.29, wpb=3561.2, bsz=92.4, num_updates=31800, lr=0.000177332, gnorm=0.948, train_wall=23, wall=0
2024-07-14 19:33:43 | INFO | train_inner | epoch 001:  31900 / 150053 loss=5.58, nll_loss=4.341, ppl=20.27, wps=15367.6, ups=4.28, wpb=3588.6, bsz=98.4, num_updates=31900, lr=0.000177054, gnorm=0.986, train_wall=23, wall=0
2024-07-14 19:34:06 | INFO | train_inner | epoch 001:  32000 / 150053 loss=5.619, nll_loss=4.387, ppl=20.92, wps=15281.4, ups=4.33, wpb=3527.8, bsz=96.6, num_updates=32000, lr=0.000176777, gnorm=0.958, train_wall=23, wall=0
2024-07-14 19:34:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 19:34:09 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.029 | nll_loss 4.788 | ppl 27.62 | wps 43719.2 | wpb 2588.8 | bsz 75.3 | num_updates 32000 | best_loss 12.174
2024-07-14 19:34:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 19:34:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_32000.pt (epoch 1 @ 32000 updates, score 6.029) (writing took 4.025406303815544 seconds)
2024-07-14 19:34:36 | INFO | train_inner | epoch 001:  32100 / 150053 loss=5.513, nll_loss=4.266, ppl=19.24, wps=11972.7, ups=3.34, wpb=3584.3, bsz=123.6, num_updates=32100, lr=0.000176501, gnorm=0.978, train_wall=23, wall=0
2024-07-14 19:34:59 | INFO | train_inner | epoch 001:  32200 / 150053 loss=5.592, nll_loss=4.355, ppl=20.47, wps=15574.4, ups=4.34, wpb=3584.5, bsz=105.4, num_updates=32200, lr=0.000176227, gnorm=0.983, train_wall=23, wall=0
2024-07-14 19:35:23 | INFO | train_inner | epoch 001:  32300 / 150053 loss=5.543, nll_loss=4.299, ppl=19.69, wps=14909.8, ups=4.21, wpb=3542.5, bsz=108.3, num_updates=32300, lr=0.000175954, gnorm=0.97, train_wall=24, wall=0
2024-07-14 19:35:46 | INFO | train_inner | epoch 001:  32400 / 150053 loss=5.568, nll_loss=4.328, ppl=20.09, wps=15507.9, ups=4.35, wpb=3563.6, bsz=105.7, num_updates=32400, lr=0.000175682, gnorm=0.967, train_wall=23, wall=0
2024-07-14 19:36:10 | INFO | train_inner | epoch 001:  32500 / 150053 loss=5.532, nll_loss=4.287, ppl=19.52, wps=15215.8, ups=4.21, wpb=3614.2, bsz=101.5, num_updates=32500, lr=0.000175412, gnorm=0.936, train_wall=24, wall=0
2024-07-14 19:36:33 | INFO | train_inner | epoch 001:  32600 / 150053 loss=5.553, nll_loss=4.311, ppl=19.85, wps=15211.6, ups=4.33, wpb=3516.2, bsz=105.9, num_updates=32600, lr=0.000175142, gnorm=0.971, train_wall=23, wall=0
2024-07-14 19:36:56 | INFO | train_inner | epoch 001:  32700 / 150053 loss=5.57, nll_loss=4.331, ppl=20.13, wps=15296.8, ups=4.35, wpb=3516.5, bsz=99.5, num_updates=32700, lr=0.000174874, gnorm=0.946, train_wall=23, wall=0
2024-07-14 19:37:19 | INFO | train_inner | epoch 001:  32800 / 150053 loss=5.566, nll_loss=4.326, ppl=20.05, wps=14862, ups=4.27, wpb=3476.6, bsz=101.3, num_updates=32800, lr=0.000174608, gnorm=0.968, train_wall=23, wall=0
2024-07-14 19:37:43 | INFO | train_inner | epoch 001:  32900 / 150053 loss=5.572, nll_loss=4.333, ppl=20.16, wps=15249, ups=4.3, wpb=3550.1, bsz=96.5, num_updates=32900, lr=0.000174342, gnorm=0.963, train_wall=23, wall=0
2024-07-14 19:38:06 | INFO | train_inner | epoch 001:  33000 / 150053 loss=5.567, nll_loss=4.327, ppl=20.07, wps=15124.7, ups=4.34, wpb=3482.9, bsz=116.1, num_updates=33000, lr=0.000174078, gnorm=1.016, train_wall=23, wall=0
2024-07-14 19:38:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 19:38:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.266 | nll_loss 5.083 | ppl 33.89 | wps 43133.7 | wpb 2588.8 | bsz 75.3 | num_updates 33000 | best_loss 12.174
2024-07-14 19:38:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 19:38:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_33000.pt (epoch 1 @ 33000 updates, score 6.266) (writing took 3.9038806529715657 seconds)
2024-07-14 19:38:35 | INFO | train_inner | epoch 001:  33100 / 150053 loss=5.56, nll_loss=4.32, ppl=19.97, wps=11959.4, ups=3.35, wpb=3566.4, bsz=111, num_updates=33100, lr=0.000173814, gnorm=0.985, train_wall=23, wall=0
2024-07-14 19:38:59 | INFO | train_inner | epoch 001:  33200 / 150053 loss=5.509, nll_loss=4.261, ppl=19.17, wps=15381.3, ups=4.3, wpb=3578.4, bsz=110.9, num_updates=33200, lr=0.000173553, gnorm=0.947, train_wall=23, wall=0
2024-07-14 19:39:22 | INFO | train_inner | epoch 001:  33300 / 150053 loss=5.618, nll_loss=4.386, ppl=20.9, wps=14896, ups=4.28, wpb=3476.8, bsz=98.6, num_updates=33300, lr=0.000173292, gnorm=1, train_wall=23, wall=0
2024-07-14 19:39:45 | INFO | train_inner | epoch 001:  33400 / 150053 loss=5.552, nll_loss=4.31, ppl=19.84, wps=15418, ups=4.26, wpb=3621.4, bsz=100.5, num_updates=33400, lr=0.000173032, gnorm=0.934, train_wall=23, wall=0
2024-07-14 19:40:09 | INFO | train_inner | epoch 001:  33500 / 150053 loss=5.539, nll_loss=4.295, ppl=19.63, wps=15223.8, ups=4.34, wpb=3511.7, bsz=119, num_updates=33500, lr=0.000172774, gnorm=1.011, train_wall=23, wall=0
2024-07-14 19:40:32 | INFO | train_inner | epoch 001:  33600 / 150053 loss=5.534, nll_loss=4.29, ppl=19.56, wps=15400, ups=4.32, wpb=3563.8, bsz=111.4, num_updates=33600, lr=0.000172516, gnorm=0.967, train_wall=23, wall=0
2024-07-14 19:40:55 | INFO | train_inner | epoch 001:  33700 / 150053 loss=5.548, nll_loss=4.306, ppl=19.78, wps=15236.1, ups=4.27, wpb=3568.7, bsz=102.6, num_updates=33700, lr=0.00017226, gnorm=0.997, train_wall=23, wall=0
2024-07-14 19:41:19 | INFO | train_inner | epoch 001:  33800 / 150053 loss=5.559, nll_loss=4.318, ppl=19.94, wps=14774.8, ups=4.22, wpb=3498, bsz=99.5, num_updates=33800, lr=0.000172005, gnorm=0.984, train_wall=23, wall=0
2024-07-14 19:41:42 | INFO | train_inner | epoch 001:  33900 / 150053 loss=5.546, nll_loss=4.303, ppl=19.74, wps=15438.3, ups=4.29, wpb=3596, bsz=100.6, num_updates=33900, lr=0.000171751, gnorm=0.947, train_wall=23, wall=0
2024-07-14 19:42:05 | INFO | train_inner | epoch 001:  34000 / 150053 loss=5.557, nll_loss=4.315, ppl=19.91, wps=15399.2, ups=4.27, wpb=3602.7, bsz=106.2, num_updates=34000, lr=0.000171499, gnorm=0.961, train_wall=23, wall=0
2024-07-14 19:42:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 19:42:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.993 | nll_loss 4.738 | ppl 26.69 | wps 43647.9 | wpb 2588.8 | bsz 75.3 | num_updates 34000 | best_loss 12.174
2024-07-14 19:42:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 19:42:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_34000.pt (epoch 1 @ 34000 updates, score 5.993) (writing took 6.026905438862741 seconds)
2024-07-14 19:42:37 | INFO | train_inner | epoch 001:  34100 / 150053 loss=5.605, nll_loss=4.371, ppl=20.69, wps=11082.3, ups=3.15, wpb=3522.7, bsz=115.4, num_updates=34100, lr=0.000171247, gnorm=1.084, train_wall=23, wall=0
2024-07-14 19:43:01 | INFO | train_inner | epoch 001:  34200 / 150053 loss=5.569, nll_loss=4.329, ppl=20.1, wps=15145.3, ups=4.28, wpb=3538.3, bsz=106.5, num_updates=34200, lr=0.000170996, gnorm=0.974, train_wall=23, wall=0
2024-07-14 19:43:24 | INFO | train_inner | epoch 001:  34300 / 150053 loss=5.596, nll_loss=4.36, ppl=20.54, wps=15142.7, ups=4.31, wpb=3510, bsz=90.1, num_updates=34300, lr=0.000170747, gnorm=0.964, train_wall=23, wall=0
2024-07-14 19:43:47 | INFO | train_inner | epoch 001:  34400 / 150053 loss=5.531, nll_loss=4.286, ppl=19.51, wps=15389.5, ups=4.25, wpb=3622.6, bsz=114.8, num_updates=34400, lr=0.000170499, gnorm=0.968, train_wall=23, wall=0
2024-07-14 19:44:10 | INFO | train_inner | epoch 001:  34500 / 150053 loss=5.558, nll_loss=4.317, ppl=19.93, wps=15187.9, ups=4.35, wpb=3492, bsz=98, num_updates=34500, lr=0.000170251, gnorm=0.99, train_wall=23, wall=0
2024-07-14 19:44:34 | INFO | train_inner | epoch 001:  34600 / 150053 loss=5.585, nll_loss=4.348, ppl=20.37, wps=15221.8, ups=4.31, wpb=3535.5, bsz=97.4, num_updates=34600, lr=0.000170005, gnorm=0.976, train_wall=23, wall=0
2024-07-14 19:44:57 | INFO | train_inner | epoch 001:  34700 / 150053 loss=5.567, nll_loss=4.327, ppl=20.07, wps=15331, ups=4.29, wpb=3574.1, bsz=101.1, num_updates=34700, lr=0.00016976, gnorm=0.961, train_wall=23, wall=0
2024-07-14 19:45:20 | INFO | train_inner | epoch 001:  34800 / 150053 loss=5.588, nll_loss=4.351, ppl=20.41, wps=15241.2, ups=4.29, wpb=3548.6, bsz=106.4, num_updates=34800, lr=0.000169516, gnorm=1.01, train_wall=23, wall=0
2024-07-14 19:45:44 | INFO | train_inner | epoch 001:  34900 / 150053 loss=5.565, nll_loss=4.324, ppl=20.03, wps=15019.9, ups=4.28, wpb=3510.3, bsz=95.7, num_updates=34900, lr=0.000169273, gnorm=0.978, train_wall=23, wall=0
2024-07-14 19:46:07 | INFO | train_inner | epoch 001:  35000 / 150053 loss=5.513, nll_loss=4.266, ppl=19.24, wps=15114.7, ups=4.25, wpb=3553.3, bsz=101.8, num_updates=35000, lr=0.000169031, gnorm=0.96, train_wall=23, wall=0
2024-07-14 19:46:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 19:46:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.99 | nll_loss 4.743 | ppl 26.78 | wps 43208.8 | wpb 2588.8 | bsz 75.3 | num_updates 35000 | best_loss 12.174
2024-07-14 19:46:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 19:46:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_35000.pt (epoch 1 @ 35000 updates, score 5.99) (writing took 4.1952639780938625 seconds)
2024-07-14 19:46:37 | INFO | train_inner | epoch 001:  35100 / 150053 loss=5.501, nll_loss=4.252, ppl=19.06, wps=11651, ups=3.31, wpb=3516, bsz=109.8, num_updates=35100, lr=0.00016879, gnorm=0.977, train_wall=23, wall=0
2024-07-14 19:47:00 | INFO | train_inner | epoch 001:  35200 / 150053 loss=5.539, nll_loss=4.294, ppl=19.62, wps=15501, ups=4.3, wpb=3608.1, bsz=99, num_updates=35200, lr=0.00016855, gnorm=0.957, train_wall=23, wall=0
2024-07-14 19:47:24 | INFO | train_inner | epoch 001:  35300 / 150053 loss=5.495, nll_loss=4.246, ppl=18.97, wps=15273.6, ups=4.21, wpb=3624.1, bsz=99.8, num_updates=35300, lr=0.000168311, gnorm=0.952, train_wall=24, wall=0
2024-07-14 19:47:48 | INFO | train_inner | epoch 001:  35400 / 150053 loss=5.531, nll_loss=4.287, ppl=19.52, wps=15101.3, ups=4.27, wpb=3533.8, bsz=99.4, num_updates=35400, lr=0.000168073, gnorm=0.973, train_wall=23, wall=0
2024-07-14 19:48:11 | INFO | train_inner | epoch 001:  35500 / 150053 loss=5.548, nll_loss=4.306, ppl=19.78, wps=14985.3, ups=4.33, wpb=3462, bsz=102.3, num_updates=35500, lr=0.000167836, gnorm=1.004, train_wall=23, wall=0
2024-07-14 19:48:34 | INFO | train_inner | epoch 001:  35600 / 150053 loss=5.54, nll_loss=4.296, ppl=19.64, wps=15482.4, ups=4.29, wpb=3608.1, bsz=100.5, num_updates=35600, lr=0.0001676, gnorm=0.964, train_wall=23, wall=0
2024-07-14 19:48:57 | INFO | train_inner | epoch 001:  35700 / 150053 loss=5.582, nll_loss=4.344, ppl=20.31, wps=15300.1, ups=4.34, wpb=3525.9, bsz=96.2, num_updates=35700, lr=0.000167365, gnorm=0.976, train_wall=23, wall=0
2024-07-14 19:49:21 | INFO | train_inner | epoch 001:  35800 / 150053 loss=5.492, nll_loss=4.242, ppl=18.92, wps=14905.9, ups=4.22, wpb=3532.8, bsz=111, num_updates=35800, lr=0.000167132, gnorm=0.973, train_wall=24, wall=0
2024-07-14 19:49:44 | INFO | train_inner | epoch 001:  35900 / 150053 loss=5.593, nll_loss=4.357, ppl=20.49, wps=15561.9, ups=4.34, wpb=3586.3, bsz=88.9, num_updates=35900, lr=0.000166899, gnorm=0.972, train_wall=23, wall=0
2024-07-14 19:50:07 | INFO | train_inner | epoch 001:  36000 / 150053 loss=5.463, nll_loss=4.208, ppl=18.49, wps=15368.5, ups=4.26, wpb=3604.4, bsz=104.4, num_updates=36000, lr=0.000166667, gnorm=0.937, train_wall=23, wall=0
2024-07-14 19:50:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 19:50:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.008 | nll_loss 4.757 | ppl 27.03 | wps 43257.5 | wpb 2588.8 | bsz 75.3 | num_updates 36000 | best_loss 12.174
2024-07-14 19:50:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 19:50:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_36000.pt (epoch 1 @ 36000 updates, score 6.008) (writing took 4.553686008788645 seconds)
2024-07-14 19:50:37 | INFO | train_inner | epoch 001:  36100 / 150053 loss=5.533, nll_loss=4.289, ppl=19.55, wps=11581.3, ups=3.31, wpb=3497.2, bsz=102.2, num_updates=36100, lr=0.000166436, gnorm=0.989, train_wall=23, wall=0
2024-07-14 19:51:01 | INFO | train_inner | epoch 001:  36200 / 150053 loss=5.5, nll_loss=4.252, ppl=19.05, wps=15235.2, ups=4.3, wpb=3543.5, bsz=113, num_updates=36200, lr=0.000166206, gnorm=0.993, train_wall=23, wall=0
2024-07-14 19:51:24 | INFO | train_inner | epoch 001:  36300 / 150053 loss=5.526, nll_loss=4.281, ppl=19.44, wps=15332.6, ups=4.33, wpb=3540, bsz=104.7, num_updates=36300, lr=0.000165977, gnorm=0.977, train_wall=23, wall=0
2024-07-14 19:51:47 | INFO | train_inner | epoch 001:  36400 / 150053 loss=5.576, nll_loss=4.338, ppl=20.22, wps=14978.9, ups=4.3, wpb=3483.7, bsz=94.3, num_updates=36400, lr=0.000165748, gnorm=0.969, train_wall=23, wall=0
2024-07-14 19:52:10 | INFO | train_inner | epoch 001:  36500 / 150053 loss=5.554, nll_loss=4.313, ppl=19.87, wps=15014.7, ups=4.32, wpb=3474.6, bsz=111.9, num_updates=36500, lr=0.000165521, gnorm=0.999, train_wall=23, wall=0
2024-07-14 19:52:34 | INFO | train_inner | epoch 001:  36600 / 150053 loss=5.528, nll_loss=4.282, ppl=19.46, wps=15183.1, ups=4.28, wpb=3547.7, bsz=90, num_updates=36600, lr=0.000165295, gnorm=0.949, train_wall=23, wall=0
2024-07-14 19:52:57 | INFO | train_inner | epoch 001:  36700 / 150053 loss=5.502, nll_loss=4.254, ppl=19.08, wps=15178.2, ups=4.27, wpb=3554.4, bsz=100.6, num_updates=36700, lr=0.00016507, gnorm=0.993, train_wall=23, wall=0
2024-07-14 19:53:21 | INFO | train_inner | epoch 001:  36800 / 150053 loss=5.467, nll_loss=4.214, ppl=18.56, wps=15273.8, ups=4.25, wpb=3597.4, bsz=108.2, num_updates=36800, lr=0.000164845, gnorm=0.963, train_wall=23, wall=0
2024-07-14 19:53:43 | INFO | train_inner | epoch 001:  36900 / 150053 loss=5.555, nll_loss=4.313, ppl=19.88, wps=15329.4, ups=4.38, wpb=3499.3, bsz=87.4, num_updates=36900, lr=0.000164622, gnorm=0.978, train_wall=23, wall=0
2024-07-14 19:54:07 | INFO | train_inner | epoch 001:  37000 / 150053 loss=5.537, nll_loss=4.294, ppl=19.61, wps=15508.7, ups=4.24, wpb=3655.4, bsz=94.9, num_updates=37000, lr=0.000164399, gnorm=0.936, train_wall=23, wall=0
2024-07-14 19:54:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 19:54:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.973 | nll_loss 4.715 | ppl 26.27 | wps 43204.7 | wpb 2588.8 | bsz 75.3 | num_updates 37000 | best_loss 12.174
2024-07-14 19:54:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 19:54:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_37000.pt (epoch 1 @ 37000 updates, score 5.973) (writing took 4.197420028038323 seconds)
2024-07-14 19:54:37 | INFO | train_inner | epoch 001:  37100 / 150053 loss=5.473, nll_loss=4.221, ppl=18.65, wps=11764, ups=3.33, wpb=3535.4, bsz=97.2, num_updates=37100, lr=0.000164177, gnorm=0.971, train_wall=23, wall=0
2024-07-14 19:55:00 | INFO | train_inner | epoch 001:  37200 / 150053 loss=5.529, nll_loss=4.284, ppl=19.48, wps=15206.2, ups=4.29, wpb=3541.3, bsz=102.5, num_updates=37200, lr=0.000163956, gnorm=0.966, train_wall=23, wall=0
2024-07-14 19:55:23 | INFO | train_inner | epoch 001:  37300 / 150053 loss=5.497, nll_loss=4.248, ppl=19, wps=15189.5, ups=4.34, wpb=3501.4, bsz=111.1, num_updates=37300, lr=0.000163737, gnorm=1.015, train_wall=23, wall=0
2024-07-14 19:55:46 | INFO | train_inner | epoch 001:  37400 / 150053 loss=5.622, nll_loss=4.39, ppl=20.96, wps=15221.2, ups=4.35, wpb=3500.6, bsz=84.4, num_updates=37400, lr=0.000163517, gnorm=0.97, train_wall=23, wall=0
2024-07-14 19:56:09 | INFO | train_inner | epoch 001:  37500 / 150053 loss=5.502, nll_loss=4.254, ppl=19.08, wps=15307.8, ups=4.32, wpb=3540.2, bsz=113, num_updates=37500, lr=0.000163299, gnorm=0.999, train_wall=23, wall=0
2024-07-14 19:56:33 | INFO | train_inner | epoch 001:  37600 / 150053 loss=5.466, nll_loss=4.212, ppl=18.53, wps=15170.5, ups=4.23, wpb=3590.3, bsz=102.4, num_updates=37600, lr=0.000163082, gnorm=0.959, train_wall=23, wall=0
2024-07-14 19:56:56 | INFO | train_inner | epoch 001:  37700 / 150053 loss=5.554, nll_loss=4.313, ppl=19.88, wps=15262.6, ups=4.34, wpb=3513.6, bsz=93, num_updates=37700, lr=0.000162866, gnorm=0.998, train_wall=23, wall=0
2024-07-14 19:57:19 | INFO | train_inner | epoch 001:  37800 / 150053 loss=5.524, nll_loss=4.279, ppl=19.41, wps=15192.5, ups=4.31, wpb=3525.7, bsz=99.9, num_updates=37800, lr=0.00016265, gnorm=0.968, train_wall=23, wall=0
2024-07-14 19:57:43 | INFO | train_inner | epoch 001:  37900 / 150053 loss=5.47, nll_loss=4.217, ppl=18.6, wps=15114.6, ups=4.3, wpb=3515.2, bsz=113, num_updates=37900, lr=0.000162435, gnorm=0.978, train_wall=23, wall=0
2024-07-14 19:58:06 | INFO | train_inner | epoch 001:  38000 / 150053 loss=5.555, nll_loss=4.313, ppl=19.88, wps=15352.1, ups=4.26, wpb=3602.3, bsz=97.1, num_updates=38000, lr=0.000162221, gnorm=0.977, train_wall=23, wall=0
2024-07-14 19:58:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 19:58:09 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.979 | nll_loss 4.724 | ppl 26.43 | wps 43576.2 | wpb 2588.8 | bsz 75.3 | num_updates 38000 | best_loss 12.174
2024-07-14 19:58:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 19:58:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_38000.pt (epoch 1 @ 38000 updates, score 5.979) (writing took 3.8226197687909007 seconds)
2024-07-14 19:58:36 | INFO | train_inner | epoch 001:  38100 / 150053 loss=5.556, nll_loss=4.316, ppl=19.91, wps=11733, ups=3.36, wpb=3488, bsz=96.2, num_updates=38100, lr=0.000162008, gnorm=1.003, train_wall=23, wall=0
2024-07-14 19:59:00 | INFO | train_inner | epoch 001:  38200 / 150053 loss=5.436, nll_loss=4.178, ppl=18.1, wps=14790.4, ups=4.2, wpb=3519.8, bsz=117.4, num_updates=38200, lr=0.000161796, gnorm=0.996, train_wall=24, wall=0
2024-07-14 19:59:23 | INFO | train_inner | epoch 001:  38300 / 150053 loss=5.483, nll_loss=4.232, ppl=18.8, wps=15141.4, ups=4.3, wpb=3519.1, bsz=109, num_updates=38300, lr=0.000161585, gnorm=0.995, train_wall=23, wall=0
2024-07-14 19:59:46 | INFO | train_inner | epoch 001:  38400 / 150053 loss=5.512, nll_loss=4.265, ppl=19.23, wps=15065.6, ups=4.23, wpb=3557.8, bsz=108, num_updates=38400, lr=0.000161374, gnorm=0.988, train_wall=23, wall=0
2024-07-14 20:00:10 | INFO | train_inner | epoch 001:  38500 / 150053 loss=5.518, nll_loss=4.272, ppl=19.32, wps=15169.8, ups=4.22, wpb=3597.3, bsz=93.4, num_updates=38500, lr=0.000161165, gnorm=0.942, train_wall=24, wall=0
2024-07-14 20:00:34 | INFO | train_inner | epoch 001:  38600 / 150053 loss=5.494, nll_loss=4.245, ppl=18.96, wps=15111.7, ups=4.29, wpb=3519.4, bsz=96.8, num_updates=38600, lr=0.000160956, gnorm=0.979, train_wall=23, wall=0
2024-07-14 20:00:57 | INFO | train_inner | epoch 001:  38700 / 150053 loss=5.497, nll_loss=4.248, ppl=19, wps=15480.9, ups=4.32, wpb=3585.5, bsz=91, num_updates=38700, lr=0.000160748, gnorm=0.94, train_wall=23, wall=0
2024-07-14 20:01:20 | INFO | train_inner | epoch 001:  38800 / 150053 loss=5.474, nll_loss=4.222, ppl=18.66, wps=15048.8, ups=4.29, wpb=3511.3, bsz=99.6, num_updates=38800, lr=0.00016054, gnorm=0.975, train_wall=23, wall=0
2024-07-14 20:01:43 | INFO | train_inner | epoch 001:  38900 / 150053 loss=5.514, nll_loss=4.267, ppl=19.25, wps=15050.1, ups=4.29, wpb=3512.2, bsz=102, num_updates=38900, lr=0.000160334, gnorm=0.991, train_wall=23, wall=0
2024-07-14 20:02:06 | INFO | train_inner | epoch 001:  39000 / 150053 loss=5.489, nll_loss=4.24, ppl=18.89, wps=15185.3, ups=4.33, wpb=3506.7, bsz=98.6, num_updates=39000, lr=0.000160128, gnorm=0.978, train_wall=23, wall=0
2024-07-14 20:02:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 20:02:09 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.964 | nll_loss 4.71 | ppl 26.18 | wps 43531.4 | wpb 2588.8 | bsz 75.3 | num_updates 39000 | best_loss 12.174
2024-07-14 20:02:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 20:02:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_39000.pt (epoch 1 @ 39000 updates, score 5.964) (writing took 4.57165112439543 seconds)
2024-07-14 20:02:37 | INFO | train_inner | epoch 001:  39100 / 150053 loss=5.536, nll_loss=4.292, ppl=19.59, wps=11417.4, ups=3.25, wpb=3513.2, bsz=100.6, num_updates=39100, lr=0.000159923, gnorm=1.047, train_wall=23, wall=0
2024-07-14 20:03:00 | INFO | train_inner | epoch 001:  39200 / 150053 loss=5.476, nll_loss=4.224, ppl=18.69, wps=15253.8, ups=4.3, wpb=3547.9, bsz=104.2, num_updates=39200, lr=0.000159719, gnorm=0.958, train_wall=23, wall=0
2024-07-14 20:03:24 | INFO | train_inner | epoch 001:  39300 / 150053 loss=5.506, nll_loss=4.258, ppl=19.13, wps=15112, ups=4.28, wpb=3527.8, bsz=105.6, num_updates=39300, lr=0.000159516, gnorm=0.972, train_wall=23, wall=0
2024-07-14 20:03:47 | INFO | train_inner | epoch 001:  39400 / 150053 loss=5.468, nll_loss=4.216, ppl=18.58, wps=15393.9, ups=4.25, wpb=3624.7, bsz=101.3, num_updates=39400, lr=0.000159313, gnorm=0.935, train_wall=23, wall=0
2024-07-14 20:04:11 | INFO | train_inner | epoch 001:  39500 / 150053 loss=5.502, nll_loss=4.253, ppl=19.07, wps=15175.9, ups=4.26, wpb=3560.3, bsz=119.7, num_updates=39500, lr=0.000159111, gnorm=1.111, train_wall=23, wall=0
2024-07-14 20:04:34 | INFO | train_inner | epoch 001:  39600 / 150053 loss=5.485, nll_loss=4.234, ppl=18.82, wps=15388.3, ups=4.28, wpb=3592.3, bsz=106.4, num_updates=39600, lr=0.00015891, gnorm=0.99, train_wall=23, wall=0
2024-07-14 20:04:57 | INFO | train_inner | epoch 001:  39700 / 150053 loss=5.454, nll_loss=4.199, ppl=18.37, wps=14967.7, ups=4.32, wpb=3466.5, bsz=105.4, num_updates=39700, lr=0.00015871, gnorm=0.969, train_wall=23, wall=0
2024-07-14 20:05:21 | INFO | train_inner | epoch 001:  39800 / 150053 loss=5.474, nll_loss=4.223, ppl=18.67, wps=15410.1, ups=4.3, wpb=3584.6, bsz=105, num_updates=39800, lr=0.000158511, gnorm=0.974, train_wall=23, wall=0
2024-07-14 20:05:44 | INFO | train_inner | epoch 001:  39900 / 150053 loss=5.409, nll_loss=4.147, ppl=17.72, wps=15277.6, ups=4.26, wpb=3588.3, bsz=114.2, num_updates=39900, lr=0.000158312, gnorm=0.983, train_wall=23, wall=0
2024-07-14 20:06:07 | INFO | train_inner | epoch 001:  40000 / 150053 loss=5.483, nll_loss=4.233, ppl=18.8, wps=15103.1, ups=4.27, wpb=3534.2, bsz=93.9, num_updates=40000, lr=0.000158114, gnorm=0.973, train_wall=23, wall=0
2024-07-14 20:06:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 20:06:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.982 | nll_loss 4.727 | ppl 26.49 | wps 43163.3 | wpb 2588.8 | bsz 75.3 | num_updates 40000 | best_loss 12.174
2024-07-14 20:06:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 20:06:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_40000.pt (epoch 1 @ 40000 updates, score 5.982) (writing took 4.087535571306944 seconds)
2024-07-14 20:06:38 | INFO | train_inner | epoch 001:  40100 / 150053 loss=5.475, nll_loss=4.223, ppl=18.68, wps=11889.4, ups=3.29, wpb=3615.7, bsz=94.8, num_updates=40100, lr=0.000157917, gnorm=0.96, train_wall=23, wall=0
2024-07-14 20:07:01 | INFO | train_inner | epoch 001:  40200 / 150053 loss=5.486, nll_loss=4.236, ppl=18.84, wps=15212.3, ups=4.29, wpb=3548.6, bsz=114.1, num_updates=40200, lr=0.00015772, gnorm=1.016, train_wall=23, wall=0
2024-07-14 20:07:24 | INFO | train_inner | epoch 001:  40300 / 150053 loss=5.516, nll_loss=4.27, ppl=19.3, wps=15280.4, ups=4.33, wpb=3528.8, bsz=99.4, num_updates=40300, lr=0.000157524, gnorm=0.974, train_wall=23, wall=0
2024-07-14 20:07:48 | INFO | train_inner | epoch 001:  40400 / 150053 loss=5.492, nll_loss=4.243, ppl=18.93, wps=14779.6, ups=4.24, wpb=3484.6, bsz=102.2, num_updates=40400, lr=0.000157329, gnorm=0.99, train_wall=23, wall=0
2024-07-14 20:08:11 | INFO | train_inner | epoch 001:  40500 / 150053 loss=5.417, nll_loss=4.157, ppl=17.84, wps=15308.6, ups=4.29, wpb=3566.9, bsz=101.8, num_updates=40500, lr=0.000157135, gnorm=0.95, train_wall=23, wall=0
2024-07-14 20:08:35 | INFO | train_inner | epoch 001:  40600 / 150053 loss=5.461, nll_loss=4.207, ppl=18.47, wps=15106.1, ups=4.28, wpb=3531.5, bsz=101.9, num_updates=40600, lr=0.000156941, gnorm=0.986, train_wall=23, wall=0
2024-07-14 20:08:58 | INFO | train_inner | epoch 001:  40700 / 150053 loss=5.448, nll_loss=4.193, ppl=18.29, wps=14819.2, ups=4.24, wpb=3493.7, bsz=100.1, num_updates=40700, lr=0.000156748, gnorm=0.968, train_wall=23, wall=0
2024-07-14 20:09:21 | INFO | train_inner | epoch 001:  40800 / 150053 loss=5.468, nll_loss=4.215, ppl=18.57, wps=15358.6, ups=4.33, wpb=3548.2, bsz=108, num_updates=40800, lr=0.000156556, gnorm=1.049, train_wall=23, wall=0
2024-07-14 20:09:45 | INFO | train_inner | epoch 001:  40900 / 150053 loss=5.448, nll_loss=4.192, ppl=18.28, wps=15381.6, ups=4.29, wpb=3584.7, bsz=104.5, num_updates=40900, lr=0.000156365, gnorm=0.979, train_wall=23, wall=0
2024-07-14 20:10:08 | INFO | train_inner | epoch 001:  41000 / 150053 loss=5.464, nll_loss=4.211, ppl=18.52, wps=15103.5, ups=4.34, wpb=3483.7, bsz=95.8, num_updates=41000, lr=0.000156174, gnorm=0.98, train_wall=23, wall=0
2024-07-14 20:10:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 20:10:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.96 | nll_loss 4.704 | ppl 26.06 | wps 43137.1 | wpb 2588.8 | bsz 75.3 | num_updates 41000 | best_loss 12.174
2024-07-14 20:10:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 20:10:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_41000.pt (epoch 1 @ 41000 updates, score 5.96) (writing took 3.8596077328547835 seconds)
2024-07-14 20:10:38 | INFO | train_inner | epoch 001:  41100 / 150053 loss=5.487, nll_loss=4.237, ppl=18.86, wps=11901.6, ups=3.34, wpb=3561.1, bsz=107.6, num_updates=41100, lr=0.000155984, gnorm=0.991, train_wall=23, wall=0
2024-07-14 20:11:01 | INFO | train_inner | epoch 001:  41200 / 150053 loss=5.479, nll_loss=4.228, ppl=18.74, wps=15264.8, ups=4.25, wpb=3588.1, bsz=97.6, num_updates=41200, lr=0.000155794, gnorm=0.96, train_wall=23, wall=0
2024-07-14 20:11:25 | INFO | train_inner | epoch 001:  41300 / 150053 loss=5.414, nll_loss=4.154, ppl=17.8, wps=15368.7, ups=4.25, wpb=3612.5, bsz=114.6, num_updates=41300, lr=0.000155606, gnorm=1.014, train_wall=23, wall=0
2024-07-14 20:11:48 | INFO | train_inner | epoch 001:  41400 / 150053 loss=5.47, nll_loss=4.219, ppl=18.62, wps=15267.7, ups=4.31, wpb=3540.4, bsz=89.9, num_updates=41400, lr=0.000155417, gnorm=0.975, train_wall=23, wall=0
2024-07-14 20:12:11 | INFO | train_inner | epoch 001:  41500 / 150053 loss=5.515, nll_loss=4.269, ppl=19.28, wps=15220.3, ups=4.34, wpb=3508.3, bsz=97.4, num_updates=41500, lr=0.00015523, gnorm=0.997, train_wall=23, wall=0
2024-07-14 20:12:34 | INFO | train_inner | epoch 001:  41600 / 150053 loss=5.494, nll_loss=4.244, ppl=18.95, wps=15229.1, ups=4.29, wpb=3546.8, bsz=104.4, num_updates=41600, lr=0.000155043, gnorm=0.961, train_wall=23, wall=0
2024-07-14 20:12:57 | INFO | train_inner | epoch 001:  41700 / 150053 loss=5.481, nll_loss=4.23, ppl=18.77, wps=15275.2, ups=4.29, wpb=3560.8, bsz=106.2, num_updates=41700, lr=0.000154857, gnorm=0.989, train_wall=23, wall=0
2024-07-14 20:13:21 | INFO | train_inner | epoch 001:  41800 / 150053 loss=5.473, nll_loss=4.222, ppl=18.66, wps=15123.4, ups=4.32, wpb=3501.5, bsz=104.5, num_updates=41800, lr=0.000154672, gnorm=1.003, train_wall=23, wall=0
2024-07-14 20:13:44 | INFO | train_inner | epoch 001:  41900 / 150053 loss=5.472, nll_loss=4.22, ppl=18.63, wps=15103.8, ups=4.29, wpb=3517.8, bsz=111.5, num_updates=41900, lr=0.000154487, gnorm=1.024, train_wall=23, wall=0
2024-07-14 20:14:07 | INFO | train_inner | epoch 001:  42000 / 150053 loss=5.478, nll_loss=4.227, ppl=18.72, wps=15158.1, ups=4.32, wpb=3506.4, bsz=94, num_updates=42000, lr=0.000154303, gnorm=1.016, train_wall=23, wall=0
2024-07-14 20:14:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 20:14:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.96 | nll_loss 4.699 | ppl 25.97 | wps 42849.3 | wpb 2588.8 | bsz 75.3 | num_updates 42000 | best_loss 12.174
2024-07-14 20:14:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 20:14:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_42000.pt (epoch 1 @ 42000 updates, score 5.96) (writing took 4.603438613936305 seconds)
2024-07-14 20:14:38 | INFO | train_inner | epoch 001:  42100 / 150053 loss=5.433, nll_loss=4.176, ppl=18.07, wps=11567.2, ups=3.27, wpb=3541.1, bsz=112.7, num_updates=42100, lr=0.00015412, gnorm=0.986, train_wall=23, wall=0
2024-07-14 20:15:01 | INFO | train_inner | epoch 001:  42200 / 150053 loss=5.483, nll_loss=4.232, ppl=18.79, wps=15204.4, ups=4.24, wpb=3584.9, bsz=99.4, num_updates=42200, lr=0.000153937, gnorm=0.967, train_wall=23, wall=0
2024-07-14 20:15:25 | INFO | train_inner | epoch 001:  42300 / 150053 loss=5.471, nll_loss=4.219, ppl=18.63, wps=15290.3, ups=4.28, wpb=3572.3, bsz=101, num_updates=42300, lr=0.000153755, gnorm=0.975, train_wall=23, wall=0
2024-07-14 20:15:48 | INFO | train_inner | epoch 001:  42400 / 150053 loss=5.434, nll_loss=4.176, ppl=18.08, wps=15477.1, ups=4.3, wpb=3601.8, bsz=104.8, num_updates=42400, lr=0.000153574, gnorm=0.965, train_wall=23, wall=0
2024-07-14 20:16:11 | INFO | train_inner | epoch 001:  42500 / 150053 loss=5.403, nll_loss=4.141, ppl=17.64, wps=15235.7, ups=4.28, wpb=3560.6, bsz=103.3, num_updates=42500, lr=0.000153393, gnorm=0.962, train_wall=23, wall=0
2024-07-14 20:16:34 | INFO | train_inner | epoch 001:  42600 / 150053 loss=5.453, nll_loss=4.197, ppl=18.34, wps=15420.4, ups=4.29, wpb=3591.9, bsz=106.9, num_updates=42600, lr=0.000153213, gnorm=0.994, train_wall=23, wall=0
2024-07-14 20:16:58 | INFO | train_inner | epoch 001:  42700 / 150053 loss=5.416, nll_loss=4.156, ppl=17.83, wps=15346.9, ups=4.27, wpb=3591.8, bsz=107.2, num_updates=42700, lr=0.000153033, gnorm=0.978, train_wall=23, wall=0
2024-07-14 20:17:21 | INFO | train_inner | epoch 001:  42800 / 150053 loss=5.484, nll_loss=4.233, ppl=18.81, wps=15232.3, ups=4.34, wpb=3510.6, bsz=104.2, num_updates=42800, lr=0.000152854, gnorm=0.988, train_wall=23, wall=0
2024-07-14 20:17:44 | INFO | train_inner | epoch 001:  42900 / 150053 loss=5.461, nll_loss=4.208, ppl=18.48, wps=15302.8, ups=4.34, wpb=3522.9, bsz=107, num_updates=42900, lr=0.000152676, gnorm=0.999, train_wall=23, wall=0
2024-07-14 20:18:07 | INFO | train_inner | epoch 001:  43000 / 150053 loss=5.424, nll_loss=4.166, ppl=17.95, wps=15246.2, ups=4.26, wpb=3577.9, bsz=101, num_updates=43000, lr=0.000152499, gnorm=0.97, train_wall=23, wall=0
2024-07-14 20:18:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 20:18:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.911 | nll_loss 4.654 | ppl 25.17 | wps 43666.2 | wpb 2588.8 | bsz 75.3 | num_updates 43000 | best_loss 12.174
2024-07-14 20:18:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 20:18:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_43000.pt (epoch 1 @ 43000 updates, score 5.911) (writing took 4.535945028997958 seconds)
2024-07-14 20:18:38 | INFO | train_inner | epoch 001:  43100 / 150053 loss=5.455, nll_loss=4.201, ppl=18.39, wps=11629.6, ups=3.27, wpb=3551.7, bsz=97.2, num_updates=43100, lr=0.000152322, gnorm=0.978, train_wall=23, wall=0
2024-07-14 20:19:01 | INFO | train_inner | epoch 001:  43200 / 150053 loss=5.487, nll_loss=4.237, ppl=18.86, wps=15318.1, ups=4.29, wpb=3567.8, bsz=97, num_updates=43200, lr=0.000152145, gnorm=0.978, train_wall=23, wall=0
2024-07-14 20:19:25 | INFO | train_inner | epoch 001:  43300 / 150053 loss=5.411, nll_loss=4.15, ppl=17.75, wps=15228.7, ups=4.29, wpb=3546.7, bsz=117.1, num_updates=43300, lr=0.000151969, gnorm=1.006, train_wall=23, wall=0
2024-07-14 20:19:48 | INFO | train_inner | epoch 001:  43400 / 150053 loss=5.418, nll_loss=4.158, ppl=17.86, wps=15433.2, ups=4.23, wpb=3646.1, bsz=111.4, num_updates=43400, lr=0.000151794, gnorm=0.956, train_wall=23, wall=0
2024-07-14 20:20:11 | INFO | train_inner | epoch 001:  43500 / 150053 loss=5.48, nll_loss=4.229, ppl=18.75, wps=14986.7, ups=4.31, wpb=3480.7, bsz=100.4, num_updates=43500, lr=0.00015162, gnorm=0.988, train_wall=23, wall=0
2024-07-14 20:20:35 | INFO | train_inner | epoch 001:  43600 / 150053 loss=5.358, nll_loss=4.09, ppl=17.03, wps=15474.8, ups=4.24, wpb=3648.3, bsz=126.9, num_updates=43600, lr=0.000151446, gnorm=1.005, train_wall=23, wall=0
2024-07-14 20:20:58 | INFO | train_inner | epoch 001:  43700 / 150053 loss=5.489, nll_loss=4.24, ppl=18.9, wps=15166, ups=4.27, wpb=3551.9, bsz=103.8, num_updates=43700, lr=0.000151272, gnorm=1.007, train_wall=23, wall=0
2024-07-14 20:21:22 | INFO | train_inner | epoch 001:  43800 / 150053 loss=5.481, nll_loss=4.229, ppl=18.76, wps=15101.7, ups=4.28, wpb=3529, bsz=107, num_updates=43800, lr=0.000151099, gnorm=1.019, train_wall=23, wall=0
2024-07-14 20:21:45 | INFO | train_inner | epoch 001:  43900 / 150053 loss=5.426, nll_loss=4.167, ppl=17.96, wps=15437, ups=4.22, wpb=3658, bsz=105.8, num_updates=43900, lr=0.000150927, gnorm=0.973, train_wall=24, wall=0
2024-07-14 20:22:09 | INFO | train_inner | epoch 001:  44000 / 150053 loss=5.447, nll_loss=4.192, ppl=18.27, wps=15018.1, ups=4.3, wpb=3494.2, bsz=113, num_updates=44000, lr=0.000150756, gnorm=1.002, train_wall=23, wall=0
2024-07-14 20:22:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 20:22:11 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.94 | nll_loss 4.687 | ppl 25.75 | wps 42898.6 | wpb 2588.8 | bsz 75.3 | num_updates 44000 | best_loss 12.174
2024-07-14 20:22:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 20:22:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_44000.pt (epoch 1 @ 44000 updates, score 5.94) (writing took 4.376838978379965 seconds)
2024-07-14 20:22:39 | INFO | train_inner | epoch 001:  44100 / 150053 loss=5.487, nll_loss=4.236, ppl=18.85, wps=11490.1, ups=3.28, wpb=3499.9, bsz=100.6, num_updates=44100, lr=0.000150585, gnorm=1.005, train_wall=23, wall=0
2024-07-14 20:23:03 | INFO | train_inner | epoch 001:  44200 / 150053 loss=5.426, nll_loss=4.167, ppl=17.97, wps=15202.3, ups=4.26, wpb=3566, bsz=101.8, num_updates=44200, lr=0.000150414, gnorm=0.964, train_wall=23, wall=0
2024-07-14 20:23:26 | INFO | train_inner | epoch 001:  44300 / 150053 loss=5.417, nll_loss=4.158, ppl=17.85, wps=15310.8, ups=4.32, wpb=3545.4, bsz=106.2, num_updates=44300, lr=0.000150244, gnorm=0.984, train_wall=23, wall=0
2024-07-14 20:23:49 | INFO | train_inner | epoch 001:  44400 / 150053 loss=5.464, nll_loss=4.212, ppl=18.53, wps=15415.7, ups=4.34, wpb=3551.9, bsz=92.5, num_updates=44400, lr=0.000150075, gnorm=0.975, train_wall=23, wall=0
2024-07-14 20:24:12 | INFO | train_inner | epoch 001:  44500 / 150053 loss=5.465, nll_loss=4.212, ppl=18.53, wps=15425.6, ups=4.33, wpb=3559.4, bsz=105.9, num_updates=44500, lr=0.000149906, gnorm=0.998, train_wall=23, wall=0
2024-07-14 20:24:35 | INFO | train_inner | epoch 001:  44600 / 150053 loss=5.451, nll_loss=4.196, ppl=18.33, wps=15181.1, ups=4.29, wpb=3538.5, bsz=92.7, num_updates=44600, lr=0.000149738, gnorm=0.971, train_wall=23, wall=0
2024-07-14 20:24:59 | INFO | train_inner | epoch 001:  44700 / 150053 loss=5.429, nll_loss=4.171, ppl=18.01, wps=15357.3, ups=4.26, wpb=3604.6, bsz=106.8, num_updates=44700, lr=0.000149571, gnorm=0.981, train_wall=23, wall=0
2024-07-14 20:25:22 | INFO | train_inner | epoch 001:  44800 / 150053 loss=5.462, nll_loss=4.209, ppl=18.49, wps=15325.8, ups=4.27, wpb=3587.9, bsz=108.3, num_updates=44800, lr=0.000149404, gnorm=0.992, train_wall=23, wall=0
2024-07-14 20:25:46 | INFO | train_inner | epoch 001:  44900 / 150053 loss=5.476, nll_loss=4.225, ppl=18.7, wps=14957.5, ups=4.26, wpb=3507.5, bsz=98.3, num_updates=44900, lr=0.000149237, gnorm=0.99, train_wall=23, wall=0
2024-07-14 20:26:09 | INFO | train_inner | epoch 001:  45000 / 150053 loss=5.511, nll_loss=4.264, ppl=19.21, wps=15316.5, ups=4.28, wpb=3577.6, bsz=99, num_updates=45000, lr=0.000149071, gnorm=1.002, train_wall=23, wall=0
2024-07-14 20:26:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 20:26:12 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.929 | nll_loss 4.678 | ppl 25.6 | wps 43250.2 | wpb 2588.8 | bsz 75.3 | num_updates 45000 | best_loss 12.174
2024-07-14 20:26:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 20:26:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_45000.pt (epoch 1 @ 45000 updates, score 5.929) (writing took 4.174855785444379 seconds)
2024-07-14 20:26:39 | INFO | train_inner | epoch 001:  45100 / 150053 loss=5.437, nll_loss=4.181, ppl=18.13, wps=11768.1, ups=3.29, wpb=3578.7, bsz=98.2, num_updates=45100, lr=0.000148906, gnorm=0.979, train_wall=23, wall=0
2024-07-14 20:27:03 | INFO | train_inner | epoch 001:  45200 / 150053 loss=5.412, nll_loss=4.151, ppl=17.76, wps=15333.8, ups=4.28, wpb=3582.8, bsz=109.9, num_updates=45200, lr=0.000148741, gnorm=0.972, train_wall=23, wall=0
2024-07-14 20:27:26 | INFO | train_inner | epoch 001:  45300 / 150053 loss=5.418, nll_loss=4.159, ppl=17.86, wps=15142.5, ups=4.26, wpb=3552.4, bsz=115.7, num_updates=45300, lr=0.000148577, gnorm=1.008, train_wall=23, wall=0
2024-07-14 20:27:49 | INFO | train_inner | epoch 001:  45400 / 150053 loss=5.46, nll_loss=4.206, ppl=18.46, wps=15438.8, ups=4.32, wpb=3573.8, bsz=106.6, num_updates=45400, lr=0.000148413, gnorm=0.995, train_wall=23, wall=0
2024-07-14 20:28:12 | INFO | train_inner | epoch 001:  45500 / 150053 loss=5.457, nll_loss=4.203, ppl=18.42, wps=15251.5, ups=4.33, wpb=3518.4, bsz=100.4, num_updates=45500, lr=0.00014825, gnorm=0.986, train_wall=23, wall=0
2024-07-14 20:28:35 | INFO | train_inner | epoch 001:  45600 / 150053 loss=5.499, nll_loss=4.251, ppl=19.04, wps=15199.9, ups=4.35, wpb=3494.6, bsz=100.4, num_updates=45600, lr=0.000148087, gnorm=1.008, train_wall=23, wall=0
2024-07-14 20:28:59 | INFO | train_inner | epoch 001:  45700 / 150053 loss=5.448, nll_loss=4.192, ppl=18.28, wps=15422.7, ups=4.28, wpb=3599.2, bsz=102.8, num_updates=45700, lr=0.000147925, gnorm=1.011, train_wall=23, wall=0
2024-07-14 20:29:22 | INFO | train_inner | epoch 001:  45800 / 150053 loss=5.432, nll_loss=4.175, ppl=18.07, wps=15505.2, ups=4.31, wpb=3600, bsz=110.4, num_updates=45800, lr=0.000147764, gnorm=1.005, train_wall=23, wall=0
2024-07-14 20:29:45 | INFO | train_inner | epoch 001:  45900 / 150053 loss=5.371, nll_loss=4.106, ppl=17.21, wps=15249.4, ups=4.27, wpb=3567.7, bsz=111.8, num_updates=45900, lr=0.000147602, gnorm=1.006, train_wall=23, wall=0
2024-07-14 20:30:08 | INFO | train_inner | epoch 001:  46000 / 150053 loss=5.426, nll_loss=4.167, ppl=17.97, wps=15333.4, ups=4.33, wpb=3539.6, bsz=102.7, num_updates=46000, lr=0.000147442, gnorm=0.98, train_wall=23, wall=0
2024-07-14 20:30:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 20:30:11 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.92 | nll_loss 4.659 | ppl 25.27 | wps 43409.7 | wpb 2588.8 | bsz 75.3 | num_updates 46000 | best_loss 12.174
2024-07-14 20:30:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 20:30:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_46000.pt (epoch 1 @ 46000 updates, score 5.92) (writing took 3.94962593447417 seconds)
2024-07-14 20:30:39 | INFO | train_inner | epoch 001:  46100 / 150053 loss=5.409, nll_loss=4.148, ppl=17.73, wps=11857.4, ups=3.32, wpb=3573.2, bsz=100.4, num_updates=46100, lr=0.000147282, gnorm=0.978, train_wall=23, wall=0
2024-07-14 20:31:02 | INFO | train_inner | epoch 001:  46200 / 150053 loss=5.393, nll_loss=4.131, ppl=17.52, wps=15314.9, ups=4.28, wpb=3579.8, bsz=104.7, num_updates=46200, lr=0.000147122, gnorm=0.972, train_wall=23, wall=0
2024-07-14 20:31:25 | INFO | train_inner | epoch 001:  46300 / 150053 loss=5.417, nll_loss=4.158, ppl=17.85, wps=15358.7, ups=4.34, wpb=3542.8, bsz=105.5, num_updates=46300, lr=0.000146964, gnorm=1.04, train_wall=23, wall=0
2024-07-14 20:31:48 | INFO | train_inner | epoch 001:  46400 / 150053 loss=5.457, nll_loss=4.203, ppl=18.42, wps=15008.9, ups=4.35, wpb=3447.7, bsz=99, num_updates=46400, lr=0.000146805, gnorm=1.044, train_wall=23, wall=0
2024-07-14 20:32:11 | INFO | train_inner | epoch 001:  46500 / 150053 loss=5.415, nll_loss=4.155, ppl=17.81, wps=15380.2, ups=4.31, wpb=3566.4, bsz=107, num_updates=46500, lr=0.000146647, gnorm=0.975, train_wall=23, wall=0
2024-07-14 20:32:35 | INFO | train_inner | epoch 001:  46600 / 150053 loss=5.426, nll_loss=4.168, ppl=17.98, wps=14984.1, ups=4.24, wpb=3532.1, bsz=102.8, num_updates=46600, lr=0.00014649, gnorm=1.003, train_wall=23, wall=0
2024-07-14 20:32:58 | INFO | train_inner | epoch 001:  46700 / 150053 loss=5.375, nll_loss=4.11, ppl=17.27, wps=15456.4, ups=4.31, wpb=3587.9, bsz=103.8, num_updates=46700, lr=0.000146333, gnorm=0.96, train_wall=23, wall=0
2024-07-14 20:33:21 | INFO | train_inner | epoch 001:  46800 / 150053 loss=5.381, nll_loss=4.117, ppl=17.35, wps=15410.3, ups=4.29, wpb=3595.2, bsz=103.9, num_updates=46800, lr=0.000146176, gnorm=0.975, train_wall=23, wall=0
2024-07-14 20:33:44 | INFO | train_inner | epoch 001:  46900 / 150053 loss=5.43, nll_loss=4.172, ppl=18.03, wps=15445.1, ups=4.34, wpb=3561.7, bsz=105.6, num_updates=46900, lr=0.00014602, gnorm=1.026, train_wall=23, wall=0
2024-07-14 20:34:07 | INFO | train_inner | epoch 001:  47000 / 150053 loss=5.431, nll_loss=4.173, ppl=18.04, wps=15229.1, ups=4.33, wpb=3515.7, bsz=102, num_updates=47000, lr=0.000145865, gnorm=0.98, train_wall=23, wall=0
2024-07-14 20:34:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 20:34:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.896 | nll_loss 4.632 | ppl 24.8 | wps 43672.6 | wpb 2588.8 | bsz 75.3 | num_updates 47000 | best_loss 12.174
2024-07-14 20:34:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 20:34:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_47000.pt (epoch 1 @ 47000 updates, score 5.896) (writing took 4.395475871860981 seconds)
2024-07-14 20:34:38 | INFO | train_inner | epoch 001:  47100 / 150053 loss=5.379, nll_loss=4.115, ppl=17.32, wps=11879.7, ups=3.29, wpb=3614.3, bsz=123.2, num_updates=47100, lr=0.00014571, gnorm=1.034, train_wall=23, wall=0
2024-07-14 20:35:01 | INFO | train_inner | epoch 001:  47200 / 150053 loss=5.461, nll_loss=4.207, ppl=18.47, wps=15520, ups=4.34, wpb=3575.9, bsz=94.8, num_updates=47200, lr=0.000145556, gnorm=0.993, train_wall=23, wall=0
2024-07-14 20:35:24 | INFO | train_inner | epoch 001:  47300 / 150053 loss=5.418, nll_loss=4.159, ppl=17.86, wps=15297, ups=4.32, wpb=3544.4, bsz=101.5, num_updates=47300, lr=0.000145402, gnorm=1.015, train_wall=23, wall=0
2024-07-14 20:35:47 | INFO | train_inner | epoch 001:  47400 / 150053 loss=5.378, nll_loss=4.113, ppl=17.31, wps=15425.6, ups=4.33, wpb=3563.1, bsz=99.4, num_updates=47400, lr=0.000145248, gnorm=0.98, train_wall=23, wall=0
2024-07-14 20:36:10 | INFO | train_inner | epoch 001:  47500 / 150053 loss=5.414, nll_loss=4.154, ppl=17.8, wps=15413.1, ups=4.31, wpb=3573.2, bsz=105.2, num_updates=47500, lr=0.000145095, gnorm=0.978, train_wall=23, wall=0
2024-07-14 20:36:34 | INFO | train_inner | epoch 001:  47600 / 150053 loss=5.414, nll_loss=4.153, ppl=17.79, wps=15187.9, ups=4.26, wpb=3563.1, bsz=106.2, num_updates=47600, lr=0.000144943, gnorm=0.986, train_wall=23, wall=0
2024-07-14 20:36:57 | INFO | train_inner | epoch 001:  47700 / 150053 loss=5.424, nll_loss=4.166, ppl=17.96, wps=15213.7, ups=4.25, wpb=3580.6, bsz=103.2, num_updates=47700, lr=0.000144791, gnorm=0.971, train_wall=23, wall=0
2024-07-14 20:37:21 | INFO | train_inner | epoch 001:  47800 / 150053 loss=5.373, nll_loss=4.107, ppl=17.23, wps=15350, ups=4.29, wpb=3580.9, bsz=113.1, num_updates=47800, lr=0.000144639, gnorm=1.259, train_wall=23, wall=0
2024-07-14 20:37:44 | INFO | train_inner | epoch 001:  47900 / 150053 loss=5.448, nll_loss=4.193, ppl=18.29, wps=14894.5, ups=4.3, wpb=3462.5, bsz=94.2, num_updates=47900, lr=0.000144488, gnorm=1.027, train_wall=23, wall=0
2024-07-14 20:38:07 | INFO | train_inner | epoch 001:  48000 / 150053 loss=5.429, nll_loss=4.171, ppl=18.01, wps=15189.2, ups=4.27, wpb=3555.3, bsz=101.4, num_updates=48000, lr=0.000144338, gnorm=0.979, train_wall=23, wall=0
2024-07-14 20:38:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 20:38:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.959 | nll_loss 4.697 | ppl 25.94 | wps 43561.6 | wpb 2588.8 | bsz 75.3 | num_updates 48000 | best_loss 12.174
2024-07-14 20:38:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 20:38:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_48000.pt (epoch 1 @ 48000 updates, score 5.959) (writing took 11.958491700701416 seconds)
2024-07-14 20:38:45 | INFO | train_inner | epoch 001:  48100 / 150053 loss=5.428, nll_loss=4.17, ppl=18, wps=9190.1, ups=2.64, wpb=3477.2, bsz=109.5, num_updates=48100, lr=0.000144187, gnorm=1.045, train_wall=23, wall=0
2024-07-14 20:39:08 | INFO | train_inner | epoch 001:  48200 / 150053 loss=5.344, nll_loss=4.075, ppl=16.85, wps=15353.8, ups=4.31, wpb=3561, bsz=104.6, num_updates=48200, lr=0.000144038, gnorm=0.982, train_wall=23, wall=0
2024-07-14 20:39:32 | INFO | train_inner | epoch 001:  48300 / 150053 loss=5.372, nll_loss=4.107, ppl=17.23, wps=15386.9, ups=4.31, wpb=3570.9, bsz=110.5, num_updates=48300, lr=0.000143889, gnorm=1.007, train_wall=23, wall=0
2024-07-14 20:39:55 | INFO | train_inner | epoch 001:  48400 / 150053 loss=5.422, nll_loss=4.164, ppl=17.93, wps=15200.8, ups=4.34, wpb=3503.7, bsz=105.8, num_updates=48400, lr=0.00014374, gnorm=1.019, train_wall=23, wall=0
2024-07-14 20:40:18 | INFO | train_inner | epoch 001:  48500 / 150053 loss=5.445, nll_loss=4.19, ppl=18.25, wps=15338.2, ups=4.27, wpb=3588.4, bsz=97, num_updates=48500, lr=0.000143592, gnorm=0.991, train_wall=23, wall=0
2024-07-14 20:40:41 | INFO | train_inner | epoch 001:  48600 / 150053 loss=5.393, nll_loss=4.131, ppl=17.52, wps=15333.7, ups=4.28, wpb=3579.6, bsz=103.6, num_updates=48600, lr=0.000143444, gnorm=0.964, train_wall=23, wall=0
2024-07-14 20:41:04 | INFO | train_inner | epoch 001:  48700 / 150053 loss=5.409, nll_loss=4.148, ppl=17.73, wps=15539.2, ups=4.32, wpb=3598.1, bsz=105.3, num_updates=48700, lr=0.000143296, gnorm=1.002, train_wall=23, wall=0
2024-07-14 20:41:28 | INFO | train_inner | epoch 001:  48800 / 150053 loss=5.378, nll_loss=4.114, ppl=17.31, wps=15127.1, ups=4.29, wpb=3523.7, bsz=123.5, num_updates=48800, lr=0.00014315, gnorm=1.031, train_wall=23, wall=0
2024-07-14 20:41:51 | INFO | train_inner | epoch 001:  48900 / 150053 loss=5.431, nll_loss=4.173, ppl=18.04, wps=15300.1, ups=4.29, wpb=3565.8, bsz=98.7, num_updates=48900, lr=0.000143003, gnorm=0.988, train_wall=23, wall=0
2024-07-14 20:42:15 | INFO | train_inner | epoch 001:  49000 / 150053 loss=5.372, nll_loss=4.106, ppl=17.22, wps=15239.6, ups=4.25, wpb=3582.6, bsz=115.5, num_updates=49000, lr=0.000142857, gnorm=0.994, train_wall=23, wall=0
2024-07-14 20:42:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 20:42:17 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.913 | nll_loss 4.662 | ppl 25.31 | wps 43609.9 | wpb 2588.8 | bsz 75.3 | num_updates 49000 | best_loss 12.174
2024-07-14 20:42:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 20:42:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_49000.pt (epoch 1 @ 49000 updates, score 5.913) (writing took 4.092552458867431 seconds)
2024-07-14 20:42:44 | INFO | train_inner | epoch 001:  49100 / 150053 loss=5.382, nll_loss=4.117, ppl=17.36, wps=12016, ups=3.35, wpb=3591.9, bsz=97, num_updates=49100, lr=0.000142712, gnorm=0.97, train_wall=23, wall=0
2024-07-14 20:43:08 | INFO | train_inner | epoch 001:  49200 / 150053 loss=5.435, nll_loss=4.179, ppl=18.11, wps=15517.3, ups=4.33, wpb=3582.1, bsz=99, num_updates=49200, lr=0.000142566, gnorm=0.997, train_wall=23, wall=0
2024-07-14 20:43:31 | INFO | train_inner | epoch 001:  49300 / 150053 loss=5.355, nll_loss=4.087, ppl=16.99, wps=15429.6, ups=4.28, wpb=3607.8, bsz=108.5, num_updates=49300, lr=0.000142422, gnorm=1.002, train_wall=23, wall=0
2024-07-14 20:43:54 | INFO | train_inner | epoch 001:  49400 / 150053 loss=5.372, nll_loss=4.107, ppl=17.23, wps=15277.5, ups=4.28, wpb=3568.1, bsz=103.4, num_updates=49400, lr=0.000142278, gnorm=0.982, train_wall=23, wall=0
2024-07-14 20:44:17 | INFO | train_inner | epoch 001:  49500 / 150053 loss=5.396, nll_loss=4.133, ppl=17.55, wps=15267.7, ups=4.33, wpb=3524.2, bsz=108, num_updates=49500, lr=0.000142134, gnorm=1.019, train_wall=23, wall=0
2024-07-14 20:44:40 | INFO | train_inner | epoch 001:  49600 / 150053 loss=5.371, nll_loss=4.106, ppl=17.21, wps=15748.3, ups=4.38, wpb=3598.9, bsz=115, num_updates=49600, lr=0.00014199, gnorm=1.006, train_wall=23, wall=0
2024-07-14 20:45:03 | INFO | train_inner | epoch 001:  49700 / 150053 loss=5.404, nll_loss=4.142, ppl=17.66, wps=15326.2, ups=4.32, wpb=3544, bsz=102.3, num_updates=49700, lr=0.000141848, gnorm=0.99, train_wall=23, wall=0
2024-07-14 20:45:26 | INFO | train_inner | epoch 001:  49800 / 150053 loss=5.433, nll_loss=4.176, ppl=18.07, wps=15385.1, ups=4.33, wpb=3556.2, bsz=99, num_updates=49800, lr=0.000141705, gnorm=0.993, train_wall=23, wall=0
2024-07-14 20:45:49 | INFO | train_inner | epoch 001:  49900 / 150053 loss=5.422, nll_loss=4.163, ppl=17.91, wps=15252.7, ups=4.35, wpb=3502.3, bsz=85, num_updates=49900, lr=0.000141563, gnorm=0.992, train_wall=23, wall=0
2024-07-14 20:46:13 | INFO | train_inner | epoch 001:  50000 / 150053 loss=5.402, nll_loss=4.14, ppl=17.63, wps=15450.2, ups=4.32, wpb=3573.8, bsz=104.6, num_updates=50000, lr=0.000141421, gnorm=1.043, train_wall=23, wall=0
2024-07-14 20:46:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 20:46:15 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.992 | nll_loss 4.734 | ppl 26.62 | wps 43656.2 | wpb 2588.8 | bsz 75.3 | num_updates 50000 | best_loss 12.174
2024-07-14 20:46:15 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 20:46:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_50000.pt (epoch 1 @ 50000 updates, score 5.992) (writing took 4.032475230284035 seconds)
2024-07-14 20:46:43 | INFO | train_inner | epoch 001:  50100 / 150053 loss=5.389, nll_loss=4.126, ppl=17.47, wps=11917.4, ups=3.33, wpb=3582.7, bsz=106.8, num_updates=50100, lr=0.00014128, gnorm=0.99, train_wall=23, wall=0
2024-07-14 20:47:06 | INFO | train_inner | epoch 001:  50200 / 150053 loss=5.379, nll_loss=4.114, ppl=17.32, wps=15361.3, ups=4.29, wpb=3582.5, bsz=105.1, num_updates=50200, lr=0.000141139, gnorm=0.986, train_wall=23, wall=0
2024-07-14 20:47:29 | INFO | train_inner | epoch 001:  50300 / 150053 loss=5.375, nll_loss=4.109, ppl=17.26, wps=15541.4, ups=4.34, wpb=3582.8, bsz=103.6, num_updates=50300, lr=0.000140999, gnorm=1.002, train_wall=23, wall=0
2024-07-14 20:47:52 | INFO | train_inner | epoch 001:  50400 / 150053 loss=5.379, nll_loss=4.115, ppl=17.32, wps=15522.1, ups=4.37, wpb=3552.7, bsz=108.2, num_updates=50400, lr=0.000140859, gnorm=0.998, train_wall=23, wall=0
2024-07-14 20:48:15 | INFO | train_inner | epoch 001:  50500 / 150053 loss=5.318, nll_loss=4.044, ppl=16.5, wps=15396.4, ups=4.27, wpb=3606.8, bsz=118.7, num_updates=50500, lr=0.00014072, gnorm=0.982, train_wall=23, wall=0
2024-07-14 20:48:39 | INFO | train_inner | epoch 001:  50600 / 150053 loss=5.381, nll_loss=4.116, ppl=17.34, wps=15170.1, ups=4.26, wpb=3561.9, bsz=102.9, num_updates=50600, lr=0.00014058, gnorm=0.97, train_wall=23, wall=0
2024-07-14 20:49:02 | INFO | train_inner | epoch 001:  50700 / 150053 loss=5.346, nll_loss=4.076, ppl=16.87, wps=15410.7, ups=4.29, wpb=3590.2, bsz=103.4, num_updates=50700, lr=0.000140442, gnorm=0.97, train_wall=23, wall=0
2024-07-14 20:49:25 | INFO | train_inner | epoch 001:  50800 / 150053 loss=5.422, nll_loss=4.162, ppl=17.91, wps=15436.2, ups=4.34, wpb=3560.2, bsz=105.9, num_updates=50800, lr=0.000140303, gnorm=1.012, train_wall=23, wall=0
2024-07-14 20:49:48 | INFO | train_inner | epoch 001:  50900 / 150053 loss=5.39, nll_loss=4.127, ppl=17.47, wps=15127.5, ups=4.31, wpb=3508.8, bsz=98.9, num_updates=50900, lr=0.000140165, gnorm=1.029, train_wall=23, wall=0
2024-07-14 20:50:12 | INFO | train_inner | epoch 001:  51000 / 150053 loss=5.336, nll_loss=4.066, ppl=16.75, wps=15348.2, ups=4.3, wpb=3569.9, bsz=110.2, num_updates=51000, lr=0.000140028, gnorm=0.985, train_wall=23, wall=0
2024-07-14 20:50:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 20:50:14 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.915 | nll_loss 4.657 | ppl 25.23 | wps 43556 | wpb 2588.8 | bsz 75.3 | num_updates 51000 | best_loss 12.174
2024-07-14 20:50:14 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 20:50:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_51000.pt (epoch 1 @ 51000 updates, score 5.915) (writing took 4.044989183545113 seconds)
2024-07-14 20:50:42 | INFO | train_inner | epoch 001:  51100 / 150053 loss=5.423, nll_loss=4.166, ppl=17.95, wps=11853.2, ups=3.33, wpb=3564.3, bsz=117.1, num_updates=51100, lr=0.000139891, gnorm=1.055, train_wall=23, wall=0
2024-07-14 20:51:05 | INFO | train_inner | epoch 001:  51200 / 150053 loss=5.408, nll_loss=4.147, ppl=17.72, wps=15356.8, ups=4.35, wpb=3532.4, bsz=94.3, num_updates=51200, lr=0.000139754, gnorm=0.988, train_wall=23, wall=0
2024-07-14 20:51:28 | INFO | train_inner | epoch 001:  51300 / 150053 loss=5.397, nll_loss=4.135, ppl=17.57, wps=15264.1, ups=4.3, wpb=3549.8, bsz=102.4, num_updates=51300, lr=0.000139618, gnorm=1.002, train_wall=23, wall=0
2024-07-14 20:51:51 | INFO | train_inner | epoch 001:  51400 / 150053 loss=5.412, nll_loss=4.152, ppl=17.78, wps=15293.8, ups=4.31, wpb=3550.2, bsz=97.4, num_updates=51400, lr=0.000139482, gnorm=1.018, train_wall=23, wall=0
2024-07-14 20:52:14 | INFO | train_inner | epoch 001:  51500 / 150053 loss=5.38, nll_loss=4.115, ppl=17.33, wps=15582.9, ups=4.3, wpb=3624.5, bsz=99.7, num_updates=51500, lr=0.000139347, gnorm=0.98, train_wall=23, wall=0
2024-07-14 20:52:38 | INFO | train_inner | epoch 001:  51600 / 150053 loss=5.364, nll_loss=4.097, ppl=17.11, wps=15133.2, ups=4.32, wpb=3504.4, bsz=131.4, num_updates=51600, lr=0.000139212, gnorm=1.072, train_wall=23, wall=0
2024-07-14 20:53:01 | INFO | train_inner | epoch 001:  51700 / 150053 loss=5.368, nll_loss=4.103, ppl=17.19, wps=15317.4, ups=4.33, wpb=3536.8, bsz=111.5, num_updates=51700, lr=0.000139077, gnorm=1.039, train_wall=23, wall=0
2024-07-14 20:53:24 | INFO | train_inner | epoch 001:  51800 / 150053 loss=5.372, nll_loss=4.107, ppl=17.23, wps=15191.7, ups=4.33, wpb=3510.8, bsz=95.8, num_updates=51800, lr=0.000138943, gnorm=0.966, train_wall=23, wall=0
2024-07-14 20:53:47 | INFO | train_inner | epoch 001:  51900 / 150053 loss=5.4, nll_loss=4.139, ppl=17.61, wps=15085.5, ups=4.33, wpb=3486.5, bsz=95.7, num_updates=51900, lr=0.000138809, gnorm=1.004, train_wall=23, wall=0
2024-07-14 20:54:10 | INFO | train_inner | epoch 001:  52000 / 150053 loss=5.353, nll_loss=4.085, ppl=16.97, wps=15471.3, ups=4.3, wpb=3596.6, bsz=104.9, num_updates=52000, lr=0.000138675, gnorm=0.994, train_wall=23, wall=0
2024-07-14 20:54:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 20:54:13 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.875 | nll_loss 4.609 | ppl 24.41 | wps 43676.9 | wpb 2588.8 | bsz 75.3 | num_updates 52000 | best_loss 12.174
2024-07-14 20:54:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 20:54:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_52000.pt (epoch 1 @ 52000 updates, score 5.875) (writing took 4.377458719536662 seconds)
2024-07-14 20:54:40 | INFO | train_inner | epoch 001:  52100 / 150053 loss=5.357, nll_loss=4.09, ppl=17.02, wps=11713.6, ups=3.33, wpb=3518.1, bsz=101.9, num_updates=52100, lr=0.000138542, gnorm=0.975, train_wall=23, wall=0
2024-07-14 20:55:03 | INFO | train_inner | epoch 001:  52200 / 150053 loss=5.342, nll_loss=4.072, ppl=16.82, wps=15514.3, ups=4.32, wpb=3588.2, bsz=101, num_updates=52200, lr=0.000138409, gnorm=0.975, train_wall=23, wall=0
2024-07-14 20:55:26 | INFO | train_inner | epoch 001:  52300 / 150053 loss=5.361, nll_loss=4.093, ppl=17.07, wps=15372.3, ups=4.32, wpb=3558.6, bsz=104, num_updates=52300, lr=0.000138277, gnorm=1.003, train_wall=23, wall=0
2024-07-14 20:55:50 | INFO | train_inner | epoch 001:  52400 / 150053 loss=5.388, nll_loss=4.126, ppl=17.46, wps=14966.8, ups=4.33, wpb=3459.2, bsz=111.1, num_updates=52400, lr=0.000138145, gnorm=1.086, train_wall=23, wall=0
2024-07-14 20:56:13 | INFO | train_inner | epoch 001:  52500 / 150053 loss=5.344, nll_loss=4.075, ppl=16.86, wps=15217.3, ups=4.34, wpb=3506.9, bsz=106.1, num_updates=52500, lr=0.000138013, gnorm=0.993, train_wall=23, wall=0
2024-07-14 20:56:36 | INFO | train_inner | epoch 001:  52600 / 150053 loss=5.35, nll_loss=4.082, ppl=16.93, wps=15357.3, ups=4.3, wpb=3568.5, bsz=114.3, num_updates=52600, lr=0.000137882, gnorm=1.009, train_wall=23, wall=0
2024-07-14 20:56:59 | INFO | train_inner | epoch 001:  52700 / 150053 loss=5.305, nll_loss=4.03, ppl=16.34, wps=15600.5, ups=4.31, wpb=3618.8, bsz=127, num_updates=52700, lr=0.000137751, gnorm=0.993, train_wall=23, wall=0
2024-07-14 20:57:22 | INFO | train_inner | epoch 001:  52800 / 150053 loss=5.404, nll_loss=4.143, ppl=17.66, wps=15482.1, ups=4.34, wpb=3567.9, bsz=107.6, num_updates=52800, lr=0.00013762, gnorm=1.018, train_wall=23, wall=0
2024-07-14 20:57:45 | INFO | train_inner | epoch 001:  52900 / 150053 loss=5.319, nll_loss=4.046, ppl=16.52, wps=15232.6, ups=4.29, wpb=3550.4, bsz=113.4, num_updates=52900, lr=0.00013749, gnorm=0.983, train_wall=23, wall=0
2024-07-14 20:58:08 | INFO | train_inner | epoch 001:  53000 / 150053 loss=5.357, nll_loss=4.089, ppl=17.02, wps=15525.4, ups=4.36, wpb=3562.1, bsz=100.6, num_updates=53000, lr=0.000137361, gnorm=1.011, train_wall=23, wall=0
2024-07-14 20:58:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 20:58:11 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.889 | nll_loss 4.631 | ppl 24.77 | wps 43627.2 | wpb 2588.8 | bsz 75.3 | num_updates 53000 | best_loss 12.174
2024-07-14 20:58:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 20:58:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_53000.pt (epoch 1 @ 53000 updates, score 5.889) (writing took 4.31020150706172 seconds)
2024-07-14 20:58:39 | INFO | train_inner | epoch 001:  53100 / 150053 loss=5.326, nll_loss=4.054, ppl=16.61, wps=12004.6, ups=3.3, wpb=3639.6, bsz=124.6, num_updates=53100, lr=0.000137231, gnorm=1.051, train_wall=23, wall=0
2024-07-14 20:59:02 | INFO | train_inner | epoch 001:  53200 / 150053 loss=5.352, nll_loss=4.084, ppl=16.95, wps=15294.2, ups=4.3, wpb=3555.1, bsz=99.3, num_updates=53200, lr=0.000137102, gnorm=0.987, train_wall=23, wall=0
2024-07-14 20:59:25 | INFO | train_inner | epoch 001:  53300 / 150053 loss=5.426, nll_loss=4.168, ppl=17.98, wps=15338.7, ups=4.32, wpb=3547.3, bsz=106.7, num_updates=53300, lr=0.000136973, gnorm=1.076, train_wall=23, wall=0
2024-07-14 20:59:48 | INFO | train_inner | epoch 001:  53400 / 150053 loss=5.344, nll_loss=4.074, ppl=16.85, wps=15574.8, ups=4.32, wpb=3602.6, bsz=109.7, num_updates=53400, lr=0.000136845, gnorm=0.985, train_wall=23, wall=0
2024-07-14 21:00:11 | INFO | train_inner | epoch 001:  53500 / 150053 loss=5.361, nll_loss=4.094, ppl=17.08, wps=15285.2, ups=4.32, wpb=3539.2, bsz=103.8, num_updates=53500, lr=0.000136717, gnorm=1.021, train_wall=23, wall=0
2024-07-14 21:00:35 | INFO | train_inner | epoch 001:  53600 / 150053 loss=5.355, nll_loss=4.086, ppl=16.99, wps=15297.5, ups=4.3, wpb=3553.6, bsz=103.8, num_updates=53600, lr=0.00013659, gnorm=1.005, train_wall=23, wall=0
2024-07-14 21:00:58 | INFO | train_inner | epoch 001:  53700 / 150053 loss=5.379, nll_loss=4.115, ppl=17.33, wps=15557.6, ups=4.36, wpb=3566.9, bsz=106.9, num_updates=53700, lr=0.000136462, gnorm=1.004, train_wall=23, wall=0
2024-07-14 21:01:21 | INFO | train_inner | epoch 001:  53800 / 150053 loss=5.334, nll_loss=4.064, ppl=16.72, wps=15280.4, ups=4.26, wpb=3590.6, bsz=106.2, num_updates=53800, lr=0.000136335, gnorm=1.014, train_wall=23, wall=0
2024-07-14 21:01:44 | INFO | train_inner | epoch 001:  53900 / 150053 loss=5.313, nll_loss=4.04, ppl=16.45, wps=15534, ups=4.31, wpb=3601.1, bsz=109.8, num_updates=53900, lr=0.000136209, gnorm=0.976, train_wall=23, wall=0
2024-07-14 21:02:08 | INFO | train_inner | epoch 001:  54000 / 150053 loss=5.305, nll_loss=4.031, ppl=16.35, wps=15237.7, ups=4.26, wpb=3577.7, bsz=108.6, num_updates=54000, lr=0.000136083, gnorm=0.981, train_wall=23, wall=0
2024-07-14 21:02:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 21:02:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.854 | nll_loss 4.598 | ppl 24.22 | wps 43246.3 | wpb 2588.8 | bsz 75.3 | num_updates 54000 | best_loss 12.174
2024-07-14 21:02:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 21:02:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_54000.pt (epoch 1 @ 54000 updates, score 5.854) (writing took 4.38105707988143 seconds)
2024-07-14 21:02:38 | INFO | train_inner | epoch 001:  54100 / 150053 loss=5.324, nll_loss=4.053, ppl=16.6, wps=11657.7, ups=3.32, wpb=3511.9, bsz=108.6, num_updates=54100, lr=0.000135957, gnorm=0.994, train_wall=23, wall=0
2024-07-14 21:03:01 | INFO | train_inner | epoch 001:  54200 / 150053 loss=5.351, nll_loss=4.083, ppl=16.95, wps=15340.5, ups=4.32, wpb=3549.7, bsz=106.8, num_updates=54200, lr=0.000135831, gnorm=1.082, train_wall=23, wall=0
2024-07-14 21:03:24 | INFO | train_inner | epoch 001:  54300 / 150053 loss=5.329, nll_loss=4.058, ppl=16.65, wps=15479.8, ups=4.32, wpb=3580.4, bsz=125.6, num_updates=54300, lr=0.000135706, gnorm=1.04, train_wall=23, wall=0
2024-07-14 21:03:47 | INFO | train_inner | epoch 001:  54400 / 150053 loss=5.345, nll_loss=4.075, ppl=16.86, wps=15282.2, ups=4.28, wpb=3568, bsz=101.4, num_updates=54400, lr=0.000135582, gnorm=1.018, train_wall=23, wall=0
2024-07-14 21:04:11 | INFO | train_inner | epoch 001:  54500 / 150053 loss=5.334, nll_loss=4.063, ppl=16.71, wps=15260.9, ups=4.29, wpb=3560.5, bsz=107.7, num_updates=54500, lr=0.000135457, gnorm=0.991, train_wall=23, wall=0
2024-07-14 21:04:34 | INFO | train_inner | epoch 001:  54600 / 150053 loss=5.362, nll_loss=4.096, ppl=17.1, wps=15353.3, ups=4.28, wpb=3591, bsz=96.4, num_updates=54600, lr=0.000135333, gnorm=1.002, train_wall=23, wall=0
2024-07-14 21:04:57 | INFO | train_inner | epoch 001:  54700 / 150053 loss=5.369, nll_loss=4.104, ppl=17.19, wps=15124.4, ups=4.31, wpb=3508.8, bsz=100.2, num_updates=54700, lr=0.000135209, gnorm=1.039, train_wall=23, wall=0
2024-07-14 21:05:20 | INFO | train_inner | epoch 001:  54800 / 150053 loss=5.275, nll_loss=3.997, ppl=15.97, wps=14937.6, ups=4.34, wpb=3438.8, bsz=103.1, num_updates=54800, lr=0.000135086, gnorm=1.018, train_wall=23, wall=0
2024-07-14 21:05:44 | INFO | train_inner | epoch 001:  54900 / 150053 loss=5.344, nll_loss=4.075, ppl=16.85, wps=15313.6, ups=4.3, wpb=3563.2, bsz=107.1, num_updates=54900, lr=0.000134963, gnorm=0.994, train_wall=23, wall=0
2024-07-14 21:06:07 | INFO | train_inner | epoch 001:  55000 / 150053 loss=5.352, nll_loss=4.084, ppl=16.96, wps=15001.6, ups=4.31, wpb=3476.7, bsz=95.1, num_updates=55000, lr=0.00013484, gnorm=1.002, train_wall=23, wall=0
2024-07-14 21:06:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 21:06:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.877 | nll_loss 4.617 | ppl 24.54 | wps 43227.1 | wpb 2588.8 | bsz 75.3 | num_updates 55000 | best_loss 12.174
2024-07-14 21:06:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 21:06:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_55000.pt (epoch 1 @ 55000 updates, score 5.877) (writing took 4.418231124058366 seconds)
2024-07-14 21:06:37 | INFO | train_inner | epoch 001:  55100 / 150053 loss=5.332, nll_loss=4.061, ppl=16.69, wps=11706.3, ups=3.27, wpb=3580.8, bsz=109.8, num_updates=55100, lr=0.000134718, gnorm=1.004, train_wall=23, wall=0
2024-07-14 21:07:01 | INFO | train_inner | epoch 001:  55200 / 150053 loss=5.36, nll_loss=4.093, ppl=17.06, wps=15302.6, ups=4.3, wpb=3556.5, bsz=105.9, num_updates=55200, lr=0.000134595, gnorm=1.005, train_wall=23, wall=0
2024-07-14 21:07:24 | INFO | train_inner | epoch 001:  55300 / 150053 loss=5.346, nll_loss=4.078, ppl=16.89, wps=15290.8, ups=4.26, wpb=3585.6, bsz=99.9, num_updates=55300, lr=0.000134474, gnorm=0.974, train_wall=23, wall=0
2024-07-14 21:07:47 | INFO | train_inner | epoch 001:  55400 / 150053 loss=5.355, nll_loss=4.087, ppl=17, wps=15248.6, ups=4.33, wpb=3520.3, bsz=98.3, num_updates=55400, lr=0.000134352, gnorm=0.986, train_wall=23, wall=0
2024-07-14 21:08:10 | INFO | train_inner | epoch 001:  55500 / 150053 loss=5.332, nll_loss=4.061, ppl=16.69, wps=15253.9, ups=4.34, wpb=3511.7, bsz=100.5, num_updates=55500, lr=0.000134231, gnorm=1.03, train_wall=23, wall=0
2024-07-14 21:08:33 | INFO | train_inner | epoch 001:  55600 / 150053 loss=5.314, nll_loss=4.041, ppl=16.46, wps=15113.7, ups=4.31, wpb=3509.7, bsz=104.7, num_updates=55600, lr=0.00013411, gnorm=0.974, train_wall=23, wall=0
2024-07-14 21:08:57 | INFO | train_inner | epoch 001:  55700 / 150053 loss=5.385, nll_loss=4.121, ppl=17.41, wps=15376.2, ups=4.28, wpb=3593.2, bsz=104, num_updates=55700, lr=0.00013399, gnorm=1.056, train_wall=23, wall=0
2024-07-14 21:09:20 | INFO | train_inner | epoch 001:  55800 / 150053 loss=5.273, nll_loss=3.994, ppl=15.94, wps=15462.7, ups=4.22, wpb=3664.2, bsz=109.3, num_updates=55800, lr=0.00013387, gnorm=0.959, train_wall=24, wall=0
2024-07-14 21:09:44 | INFO | train_inner | epoch 001:  55900 / 150053 loss=5.327, nll_loss=4.055, ppl=16.62, wps=15489.6, ups=4.32, wpb=3581.4, bsz=111.8, num_updates=55900, lr=0.00013375, gnorm=0.992, train_wall=23, wall=0
2024-07-14 21:10:07 | INFO | train_inner | epoch 001:  56000 / 150053 loss=5.306, nll_loss=4.033, ppl=16.37, wps=15253.6, ups=4.32, wpb=3530.2, bsz=105.6, num_updates=56000, lr=0.000133631, gnorm=0.991, train_wall=23, wall=0
2024-07-14 21:10:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 21:10:09 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.893 | nll_loss 4.633 | ppl 24.81 | wps 43612.6 | wpb 2588.8 | bsz 75.3 | num_updates 56000 | best_loss 12.174
2024-07-14 21:10:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 21:10:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_56000.pt (epoch 1 @ 56000 updates, score 5.893) (writing took 4.579311991110444 seconds)
2024-07-14 21:10:37 | INFO | train_inner | epoch 001:  56100 / 150053 loss=5.351, nll_loss=4.083, ppl=16.94, wps=11620.5, ups=3.3, wpb=3518.5, bsz=90.7, num_updates=56100, lr=0.000133511, gnorm=0.979, train_wall=23, wall=0
2024-07-14 21:11:00 | INFO | train_inner | epoch 001:  56200 / 150053 loss=5.344, nll_loss=4.075, ppl=16.86, wps=15410.2, ups=4.31, wpb=3571.5, bsz=107.6, num_updates=56200, lr=0.000133393, gnorm=1.005, train_wall=23, wall=0
2024-07-14 21:11:24 | INFO | train_inner | epoch 001:  56300 / 150053 loss=5.325, nll_loss=4.054, ppl=16.61, wps=15280.5, ups=4.27, wpb=3577.6, bsz=122.3, num_updates=56300, lr=0.000133274, gnorm=1.02, train_wall=23, wall=0
2024-07-14 21:11:47 | INFO | train_inner | epoch 001:  56400 / 150053 loss=5.369, nll_loss=4.103, ppl=17.18, wps=15516.3, ups=4.36, wpb=3562.3, bsz=97, num_updates=56400, lr=0.000133156, gnorm=0.996, train_wall=23, wall=0
2024-07-14 21:12:09 | INFO | train_inner | epoch 001:  56500 / 150053 loss=5.312, nll_loss=4.038, ppl=16.43, wps=15592.9, ups=4.36, wpb=3573.5, bsz=106.8, num_updates=56500, lr=0.000133038, gnorm=0.994, train_wall=23, wall=0
2024-07-14 21:12:32 | INFO | train_inner | epoch 001:  56600 / 150053 loss=5.433, nll_loss=4.176, ppl=18.08, wps=15133.9, ups=4.37, wpb=3462.2, bsz=85.1, num_updates=56600, lr=0.00013292, gnorm=1.014, train_wall=23, wall=0
2024-07-14 21:12:56 | INFO | train_inner | epoch 001:  56700 / 150053 loss=5.34, nll_loss=4.07, ppl=16.8, wps=15411.7, ups=4.29, wpb=3595.6, bsz=104.8, num_updates=56700, lr=0.000132803, gnorm=0.987, train_wall=23, wall=0
2024-07-14 21:13:19 | INFO | train_inner | epoch 001:  56800 / 150053 loss=5.345, nll_loss=4.077, ppl=16.88, wps=15274.5, ups=4.35, wpb=3512.6, bsz=96.9, num_updates=56800, lr=0.000132686, gnorm=1.014, train_wall=23, wall=0
2024-07-14 21:13:42 | INFO | train_inner | epoch 001:  56900 / 150053 loss=5.387, nll_loss=4.124, ppl=17.43, wps=15240.2, ups=4.3, wpb=3542.7, bsz=98.2, num_updates=56900, lr=0.00013257, gnorm=1.004, train_wall=23, wall=0
2024-07-14 21:14:05 | INFO | train_inner | epoch 001:  57000 / 150053 loss=5.246, nll_loss=3.964, ppl=15.61, wps=15079.6, ups=4.3, wpb=3506.5, bsz=122.6, num_updates=57000, lr=0.000132453, gnorm=1.033, train_wall=23, wall=0
2024-07-14 21:14:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 21:14:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.873 | nll_loss 4.603 | ppl 24.31 | wps 43551.5 | wpb 2588.8 | bsz 75.3 | num_updates 57000 | best_loss 12.174
2024-07-14 21:14:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 21:14:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_57000.pt (epoch 1 @ 57000 updates, score 5.873) (writing took 4.280527484603226 seconds)
2024-07-14 21:14:35 | INFO | train_inner | epoch 001:  57100 / 150053 loss=5.379, nll_loss=4.114, ppl=17.32, wps=11746.2, ups=3.34, wpb=3521.5, bsz=99.8, num_updates=57100, lr=0.000132337, gnorm=1.034, train_wall=23, wall=0
2024-07-14 21:14:59 | INFO | train_inner | epoch 001:  57200 / 150053 loss=5.312, nll_loss=4.038, ppl=16.43, wps=15508.9, ups=4.27, wpb=3630.4, bsz=104.7, num_updates=57200, lr=0.000132221, gnorm=0.986, train_wall=23, wall=0
2024-07-14 21:15:22 | INFO | train_inner | epoch 001:  57300 / 150053 loss=5.363, nll_loss=4.096, ppl=17.1, wps=15351, ups=4.34, wpb=3539, bsz=100.6, num_updates=57300, lr=0.000132106, gnorm=1.014, train_wall=23, wall=0
2024-07-14 21:15:45 | INFO | train_inner | epoch 001:  57400 / 150053 loss=5.341, nll_loss=4.072, ppl=16.82, wps=15598.6, ups=4.34, wpb=3592.1, bsz=99.4, num_updates=57400, lr=0.000131991, gnorm=0.994, train_wall=23, wall=0
2024-07-14 21:16:08 | INFO | train_inner | epoch 001:  57500 / 150053 loss=5.322, nll_loss=4.05, ppl=16.57, wps=15247.2, ups=4.26, wpb=3580.2, bsz=101.4, num_updates=57500, lr=0.000131876, gnorm=1.01, train_wall=23, wall=0
2024-07-14 21:16:31 | INFO | train_inner | epoch 001:  57600 / 150053 loss=5.331, nll_loss=4.061, ppl=16.69, wps=15440.6, ups=4.32, wpb=3577.4, bsz=114.2, num_updates=57600, lr=0.000131762, gnorm=1.008, train_wall=23, wall=0
2024-07-14 21:16:54 | INFO | train_inner | epoch 001:  57700 / 150053 loss=5.304, nll_loss=4.029, ppl=16.33, wps=15396, ups=4.33, wpb=3557.8, bsz=112.6, num_updates=57700, lr=0.000131647, gnorm=1.012, train_wall=23, wall=0
2024-07-14 21:17:17 | INFO | train_inner | epoch 001:  57800 / 150053 loss=5.412, nll_loss=4.153, ppl=17.79, wps=15213.3, ups=4.34, wpb=3503.3, bsz=107.6, num_updates=57800, lr=0.000131533, gnorm=1.065, train_wall=23, wall=0
2024-07-14 21:17:41 | INFO | train_inner | epoch 001:  57900 / 150053 loss=5.366, nll_loss=4.1, ppl=17.15, wps=15275.3, ups=4.32, wpb=3535.1, bsz=109.8, num_updates=57900, lr=0.00013142, gnorm=1, train_wall=23, wall=0
2024-07-14 21:18:04 | INFO | train_inner | epoch 001:  58000 / 150053 loss=5.318, nll_loss=4.045, ppl=16.51, wps=15293.4, ups=4.26, wpb=3593.6, bsz=100.4, num_updates=58000, lr=0.000131306, gnorm=0.98, train_wall=23, wall=0
2024-07-14 21:18:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 21:18:07 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.883 | nll_loss 4.616 | ppl 24.52 | wps 43658.2 | wpb 2588.8 | bsz 75.3 | num_updates 58000 | best_loss 12.174
2024-07-14 21:18:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 21:18:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_58000.pt (epoch 1 @ 58000 updates, score 5.883) (writing took 4.259585848078132 seconds)
2024-07-14 21:18:34 | INFO | train_inner | epoch 001:  58100 / 150053 loss=5.33, nll_loss=4.059, ppl=16.67, wps=11788.6, ups=3.33, wpb=3543.9, bsz=107.2, num_updates=58100, lr=0.000131193, gnorm=1.038, train_wall=23, wall=0
2024-07-14 21:18:57 | INFO | train_inner | epoch 001:  58200 / 150053 loss=5.358, nll_loss=4.09, ppl=17.03, wps=15186.1, ups=4.28, wpb=3544, bsz=102.3, num_updates=58200, lr=0.000131081, gnorm=1.061, train_wall=23, wall=0
2024-07-14 21:19:21 | INFO | train_inner | epoch 001:  58300 / 150053 loss=5.328, nll_loss=4.057, ppl=16.65, wps=15305.1, ups=4.29, wpb=3566.6, bsz=103.5, num_updates=58300, lr=0.000130968, gnorm=0.99, train_wall=23, wall=0
2024-07-14 21:19:44 | INFO | train_inner | epoch 001:  58400 / 150053 loss=5.284, nll_loss=4.007, ppl=16.08, wps=14915.9, ups=4.28, wpb=3483.1, bsz=105.8, num_updates=58400, lr=0.000130856, gnorm=1, train_wall=23, wall=0
2024-07-14 21:20:07 | INFO | train_inner | epoch 001:  58500 / 150053 loss=5.369, nll_loss=4.104, ppl=17.19, wps=15217.3, ups=4.36, wpb=3487.1, bsz=102.6, num_updates=58500, lr=0.000130744, gnorm=1.055, train_wall=23, wall=0
2024-07-14 21:20:30 | INFO | train_inner | epoch 001:  58600 / 150053 loss=5.379, nll_loss=4.114, ppl=17.31, wps=15234.5, ups=4.35, wpb=3503, bsz=92.1, num_updates=58600, lr=0.000130632, gnorm=1.004, train_wall=23, wall=0
2024-07-14 21:20:53 | INFO | train_inner | epoch 001:  58700 / 150053 loss=5.365, nll_loss=4.1, ppl=17.14, wps=15368.9, ups=4.28, wpb=3587.8, bsz=94.4, num_updates=58700, lr=0.000130521, gnorm=0.996, train_wall=23, wall=0
2024-07-14 21:21:16 | INFO | train_inner | epoch 001:  58800 / 150053 loss=5.407, nll_loss=4.146, ppl=17.71, wps=14784.6, ups=4.35, wpb=3402.2, bsz=107.1, num_updates=58800, lr=0.00013041, gnorm=1.086, train_wall=23, wall=0
2024-07-14 21:21:40 | INFO | train_inner | epoch 001:  58900 / 150053 loss=5.264, nll_loss=3.985, ppl=15.84, wps=15131.2, ups=4.24, wpb=3565, bsz=121.9, num_updates=58900, lr=0.000130299, gnorm=1.015, train_wall=23, wall=0
2024-07-14 21:22:03 | INFO | train_inner | epoch 001:  59000 / 150053 loss=5.369, nll_loss=4.103, ppl=17.18, wps=15256, ups=4.28, wpb=3564.5, bsz=95, num_updates=59000, lr=0.000130189, gnorm=1.013, train_wall=23, wall=0
2024-07-14 21:22:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 21:22:06 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.871 | nll_loss 4.604 | ppl 24.33 | wps 43527.2 | wpb 2588.8 | bsz 75.3 | num_updates 59000 | best_loss 12.174
2024-07-14 21:22:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 21:22:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_59000.pt (epoch 1 @ 59000 updates, score 5.871) (writing took 4.777541050687432 seconds)
2024-07-14 21:22:34 | INFO | train_inner | epoch 001:  59100 / 150053 loss=5.273, nll_loss=3.994, ppl=15.93, wps=11523.1, ups=3.23, wpb=3571.2, bsz=121.7, num_updates=59100, lr=0.000130079, gnorm=1, train_wall=23, wall=0
2024-07-14 21:22:58 | INFO | train_inner | epoch 001:  59200 / 150053 loss=5.32, nll_loss=4.048, ppl=16.54, wps=15483.5, ups=4.26, wpb=3636.4, bsz=108.1, num_updates=59200, lr=0.000129969, gnorm=1.01, train_wall=23, wall=0
2024-07-14 21:23:21 | INFO | train_inner | epoch 001:  59300 / 150053 loss=5.224, nll_loss=3.938, ppl=15.33, wps=15292.3, ups=4.28, wpb=3574.1, bsz=131, num_updates=59300, lr=0.000129859, gnorm=1.009, train_wall=23, wall=0
2024-07-14 21:23:45 | INFO | train_inner | epoch 001:  59400 / 150053 loss=5.31, nll_loss=4.036, ppl=16.41, wps=15090.4, ups=4.29, wpb=3520.5, bsz=111.2, num_updates=59400, lr=0.00012975, gnorm=1.054, train_wall=23, wall=0
2024-07-14 21:24:08 | INFO | train_inner | epoch 001:  59500 / 150053 loss=5.334, nll_loss=4.063, ppl=16.72, wps=15400.5, ups=4.32, wpb=3564, bsz=108.6, num_updates=59500, lr=0.000129641, gnorm=1.028, train_wall=23, wall=0
2024-07-14 21:24:31 | INFO | train_inner | epoch 001:  59600 / 150053 loss=5.299, nll_loss=4.025, ppl=16.28, wps=15356, ups=4.35, wpb=3531.2, bsz=95.2, num_updates=59600, lr=0.000129532, gnorm=1.007, train_wall=23, wall=0
2024-07-14 21:24:54 | INFO | train_inner | epoch 001:  59700 / 150053 loss=5.334, nll_loss=4.063, ppl=16.72, wps=15509.8, ups=4.32, wpb=3593, bsz=101.4, num_updates=59700, lr=0.000129423, gnorm=1.012, train_wall=23, wall=0
2024-07-14 21:25:17 | INFO | train_inner | epoch 001:  59800 / 150053 loss=5.319, nll_loss=4.047, ppl=16.53, wps=15354.2, ups=4.32, wpb=3554.9, bsz=116.9, num_updates=59800, lr=0.000129315, gnorm=1.037, train_wall=23, wall=0
2024-07-14 21:25:41 | INFO | train_inner | epoch 001:  59900 / 150053 loss=5.346, nll_loss=4.077, ppl=16.87, wps=15329.1, ups=4.25, wpb=3610.8, bsz=105.4, num_updates=59900, lr=0.000129207, gnorm=0.986, train_wall=23, wall=0
2024-07-14 21:26:04 | INFO | train_inner | epoch 001:  60000 / 150053 loss=5.336, nll_loss=4.065, ppl=16.74, wps=15445.2, ups=4.3, wpb=3591.1, bsz=111.2, num_updates=60000, lr=0.000129099, gnorm=1.036, train_wall=23, wall=0
2024-07-14 21:26:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 21:26:07 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.908 | nll_loss 4.65 | ppl 25.1 | wps 43516 | wpb 2588.8 | bsz 75.3 | num_updates 60000 | best_loss 12.174
2024-07-14 21:26:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 21:26:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_60000.pt (epoch 1 @ 60000 updates, score 5.908) (writing took 4.731623034924269 seconds)
2024-07-14 21:26:34 | INFO | train_inner | epoch 001:  60100 / 150053 loss=5.298, nll_loss=4.023, ppl=16.26, wps=11545.6, ups=3.3, wpb=3502.3, bsz=108.2, num_updates=60100, lr=0.000128992, gnorm=1.007, train_wall=23, wall=0
2024-07-14 21:26:57 | INFO | train_inner | epoch 001:  60200 / 150053 loss=5.334, nll_loss=4.064, ppl=16.73, wps=15257.4, ups=4.33, wpb=3521.7, bsz=93.3, num_updates=60200, lr=0.000128885, gnorm=1.009, train_wall=23, wall=0
2024-07-14 21:27:20 | INFO | train_inner | epoch 001:  60300 / 150053 loss=5.281, nll_loss=4.003, ppl=16.03, wps=15467.5, ups=4.32, wpb=3580.3, bsz=111.4, num_updates=60300, lr=0.000128778, gnorm=0.992, train_wall=23, wall=0
2024-07-14 21:27:43 | INFO | train_inner | epoch 001:  60400 / 150053 loss=5.375, nll_loss=4.111, ppl=17.28, wps=15234.1, ups=4.33, wpb=3517.8, bsz=106.2, num_updates=60400, lr=0.000128671, gnorm=1.117, train_wall=23, wall=0
2024-07-14 21:28:07 | INFO | train_inner | epoch 001:  60500 / 150053 loss=5.29, nll_loss=4.014, ppl=16.15, wps=15223.6, ups=4.34, wpb=3510.4, bsz=107.6, num_updates=60500, lr=0.000128565, gnorm=0.998, train_wall=23, wall=0
2024-07-14 21:28:30 | INFO | train_inner | epoch 001:  60600 / 150053 loss=5.261, nll_loss=3.981, ppl=15.79, wps=15425.1, ups=4.3, wpb=3583.7, bsz=95.2, num_updates=60600, lr=0.000128459, gnorm=0.978, train_wall=23, wall=0
2024-07-14 21:28:53 | INFO | train_inner | epoch 001:  60700 / 150053 loss=5.289, nll_loss=4.014, ppl=16.16, wps=15215.9, ups=4.28, wpb=3557.7, bsz=115, num_updates=60700, lr=0.000128353, gnorm=1.1, train_wall=23, wall=0
2024-07-14 21:29:16 | INFO | train_inner | epoch 001:  60800 / 150053 loss=5.311, nll_loss=4.038, ppl=16.42, wps=15209.6, ups=4.31, wpb=3526.4, bsz=115, num_updates=60800, lr=0.000128247, gnorm=1.063, train_wall=23, wall=0
2024-07-14 21:29:39 | INFO | train_inner | epoch 001:  60900 / 150053 loss=5.278, nll_loss=4, ppl=16, wps=15166.5, ups=4.31, wpb=3515.3, bsz=98.2, num_updates=60900, lr=0.000128142, gnorm=1.006, train_wall=23, wall=0
2024-07-14 21:30:03 | INFO | train_inner | epoch 001:  61000 / 150053 loss=5.238, nll_loss=3.955, ppl=15.5, wps=15454.9, ups=4.33, wpb=3572, bsz=116.3, num_updates=61000, lr=0.000128037, gnorm=1.017, train_wall=23, wall=0
2024-07-14 21:30:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 21:30:05 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.843 | nll_loss 4.579 | ppl 23.9 | wps 42732.4 | wpb 2588.8 | bsz 75.3 | num_updates 61000 | best_loss 12.174
2024-07-14 21:30:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 21:30:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_61000.pt (epoch 1 @ 61000 updates, score 5.843) (writing took 4.898321169428527 seconds)
2024-07-14 21:30:34 | INFO | train_inner | epoch 001:  61100 / 150053 loss=5.258, nll_loss=3.978, ppl=15.75, wps=11325.2, ups=3.24, wpb=3498.5, bsz=103.4, num_updates=61100, lr=0.000127932, gnorm=1.011, train_wall=23, wall=0
2024-07-14 21:30:57 | INFO | train_inner | epoch 001:  61200 / 150053 loss=5.316, nll_loss=4.043, ppl=16.48, wps=15339.3, ups=4.32, wpb=3547, bsz=100, num_updates=61200, lr=0.000127827, gnorm=0.995, train_wall=23, wall=0
2024-07-14 21:31:20 | INFO | train_inner | epoch 001:  61300 / 150053 loss=5.323, nll_loss=4.052, ppl=16.59, wps=15167.6, ups=4.3, wpb=3524.6, bsz=104.6, num_updates=61300, lr=0.000127723, gnorm=1.002, train_wall=23, wall=0
2024-07-14 21:31:43 | INFO | train_inner | epoch 001:  61400 / 150053 loss=5.263, nll_loss=3.984, ppl=15.82, wps=15222.2, ups=4.27, wpb=3564.9, bsz=114.1, num_updates=61400, lr=0.000127619, gnorm=1.009, train_wall=23, wall=0
2024-07-14 21:32:06 | INFO | train_inner | epoch 001:  61500 / 150053 loss=5.269, nll_loss=3.99, ppl=15.89, wps=15482.2, ups=4.31, wpb=3593, bsz=121.5, num_updates=61500, lr=0.000127515, gnorm=1.039, train_wall=23, wall=0
2024-07-14 21:32:30 | INFO | train_inner | epoch 001:  61600 / 150053 loss=5.311, nll_loss=4.038, ppl=16.43, wps=15212.2, ups=4.29, wpb=3545.7, bsz=110.2, num_updates=61600, lr=0.000127412, gnorm=1.035, train_wall=23, wall=0
2024-07-14 21:32:53 | INFO | train_inner | epoch 001:  61700 / 150053 loss=5.319, nll_loss=4.047, ppl=16.53, wps=15104.8, ups=4.31, wpb=3501.1, bsz=110.5, num_updates=61700, lr=0.000127309, gnorm=1.044, train_wall=23, wall=0
2024-07-14 21:33:16 | INFO | train_inner | epoch 001:  61800 / 150053 loss=5.305, nll_loss=4.031, ppl=16.35, wps=15529.2, ups=4.31, wpb=3606.5, bsz=133, num_updates=61800, lr=0.000127205, gnorm=1.084, train_wall=23, wall=0
2024-07-14 21:33:39 | INFO | train_inner | epoch 001:  61900 / 150053 loss=5.356, nll_loss=4.089, ppl=17.02, wps=15274.6, ups=4.32, wpb=3539.6, bsz=101.9, num_updates=61900, lr=0.000127103, gnorm=1.037, train_wall=23, wall=0
2024-07-14 21:34:03 | INFO | train_inner | epoch 001:  62000 / 150053 loss=5.324, nll_loss=4.053, ppl=16.6, wps=15232.3, ups=4.3, wpb=3539.4, bsz=101.4, num_updates=62000, lr=0.000127, gnorm=1.007, train_wall=23, wall=0
2024-07-14 21:34:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 21:34:05 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.87 | nll_loss 4.603 | ppl 24.31 | wps 43624.6 | wpb 2588.8 | bsz 75.3 | num_updates 62000 | best_loss 12.174
2024-07-14 21:34:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 21:34:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_62000.pt (epoch 1 @ 62000 updates, score 5.87) (writing took 4.729950172826648 seconds)
2024-07-14 21:34:33 | INFO | train_inner | epoch 001:  62100 / 150053 loss=5.3, nll_loss=4.025, ppl=16.28, wps=11538.1, ups=3.3, wpb=3497.3, bsz=100, num_updates=62100, lr=0.000126898, gnorm=1.018, train_wall=23, wall=0
2024-07-14 21:34:56 | INFO | train_inner | epoch 001:  62200 / 150053 loss=5.367, nll_loss=4.102, ppl=17.17, wps=15666.8, ups=4.4, wpb=3559.5, bsz=92.8, num_updates=62200, lr=0.000126796, gnorm=1.043, train_wall=23, wall=0
2024-07-14 21:35:19 | INFO | train_inner | epoch 001:  62300 / 150053 loss=5.28, nll_loss=4.003, ppl=16.03, wps=14892.4, ups=4.27, wpb=3490.9, bsz=101.6, num_updates=62300, lr=0.000126694, gnorm=1.01, train_wall=23, wall=0
2024-07-14 21:35:42 | INFO | train_inner | epoch 001:  62400 / 150053 loss=5.32, nll_loss=4.048, ppl=16.54, wps=15180.4, ups=4.3, wpb=3527.7, bsz=105.8, num_updates=62400, lr=0.000126592, gnorm=1.022, train_wall=23, wall=0
2024-07-14 21:36:06 | INFO | train_inner | epoch 001:  62500 / 150053 loss=5.291, nll_loss=4.015, ppl=16.17, wps=15258, ups=4.27, wpb=3572.8, bsz=110.5, num_updates=62500, lr=0.000126491, gnorm=1.011, train_wall=23, wall=0
2024-07-14 21:36:29 | INFO | train_inner | epoch 001:  62600 / 150053 loss=5.18, nll_loss=3.889, ppl=14.82, wps=15050.3, ups=4.28, wpb=3520.2, bsz=129.1, num_updates=62600, lr=0.00012639, gnorm=1.032, train_wall=23, wall=0
2024-07-14 21:36:52 | INFO | train_inner | epoch 001:  62700 / 150053 loss=5.403, nll_loss=4.142, ppl=17.65, wps=15164.3, ups=4.32, wpb=3511.1, bsz=85.2, num_updates=62700, lr=0.000126289, gnorm=1.004, train_wall=23, wall=0
2024-07-14 21:37:15 | INFO | train_inner | epoch 001:  62800 / 150053 loss=5.281, nll_loss=4.004, ppl=16.04, wps=15503.1, ups=4.35, wpb=3563.8, bsz=97.7, num_updates=62800, lr=0.000126189, gnorm=1.002, train_wall=23, wall=0
2024-07-14 21:37:39 | INFO | train_inner | epoch 001:  62900 / 150053 loss=5.308, nll_loss=4.035, ppl=16.39, wps=15360, ups=4.27, wpb=3596.6, bsz=103.2, num_updates=62900, lr=0.000126088, gnorm=0.992, train_wall=23, wall=0
2024-07-14 21:38:02 | INFO | train_inner | epoch 001:  63000 / 150053 loss=5.299, nll_loss=4.024, ppl=16.27, wps=15168.4, ups=4.27, wpb=3553.1, bsz=108.6, num_updates=63000, lr=0.000125988, gnorm=1.049, train_wall=23, wall=0
2024-07-14 21:38:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 21:38:05 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.838 | nll_loss 4.571 | ppl 23.77 | wps 43537.2 | wpb 2588.8 | bsz 75.3 | num_updates 63000 | best_loss 12.174
2024-07-14 21:38:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 21:38:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_63000.pt (epoch 1 @ 63000 updates, score 5.838) (writing took 5.42934678401798 seconds)
2024-07-14 21:38:33 | INFO | train_inner | epoch 001:  63100 / 150053 loss=5.252, nll_loss=3.971, ppl=15.68, wps=11495.7, ups=3.2, wpb=3597.1, bsz=108.1, num_updates=63100, lr=0.000125888, gnorm=0.983, train_wall=23, wall=0
2024-07-14 21:38:57 | INFO | train_inner | epoch 001:  63200 / 150053 loss=5.266, nll_loss=3.987, ppl=15.85, wps=15537.9, ups=4.29, wpb=3625.1, bsz=101.9, num_updates=63200, lr=0.000125789, gnorm=1.004, train_wall=23, wall=0
2024-07-14 21:39:20 | INFO | train_inner | epoch 001:  63300 / 150053 loss=5.305, nll_loss=4.031, ppl=16.34, wps=15377.2, ups=4.28, wpb=3589.9, bsz=104.9, num_updates=63300, lr=0.000125689, gnorm=1.001, train_wall=23, wall=0
2024-07-14 21:39:43 | INFO | train_inner | epoch 001:  63400 / 150053 loss=5.256, nll_loss=3.976, ppl=15.73, wps=15145, ups=4.34, wpb=3488.7, bsz=107.4, num_updates=63400, lr=0.00012559, gnorm=1.009, train_wall=23, wall=0
2024-07-14 21:40:06 | INFO | train_inner | epoch 001:  63500 / 150053 loss=5.167, nll_loss=3.873, ppl=14.66, wps=15287.5, ups=4.3, wpb=3554.8, bsz=119.4, num_updates=63500, lr=0.000125491, gnorm=0.994, train_wall=23, wall=0
2024-07-14 21:40:29 | INFO | train_inner | epoch 001:  63600 / 150053 loss=5.281, nll_loss=4.005, ppl=16.05, wps=15458.1, ups=4.36, wpb=3547.7, bsz=130.2, num_updates=63600, lr=0.000125392, gnorm=1.075, train_wall=23, wall=0
2024-07-14 21:40:53 | INFO | train_inner | epoch 001:  63700 / 150053 loss=5.256, nll_loss=3.976, ppl=15.73, wps=15336.5, ups=4.3, wpb=3569, bsz=104, num_updates=63700, lr=0.000125294, gnorm=1.002, train_wall=23, wall=0
2024-07-14 21:41:16 | INFO | train_inner | epoch 001:  63800 / 150053 loss=5.321, nll_loss=4.049, ppl=16.55, wps=15261.8, ups=4.3, wpb=3546.8, bsz=97, num_updates=63800, lr=0.000125196, gnorm=1.04, train_wall=23, wall=0
2024-07-14 21:41:39 | INFO | train_inner | epoch 001:  63900 / 150053 loss=5.247, nll_loss=3.965, ppl=15.61, wps=15179.1, ups=4.36, wpb=3483.7, bsz=111.5, num_updates=63900, lr=0.000125098, gnorm=1.034, train_wall=23, wall=0
2024-07-14 21:42:02 | INFO | train_inner | epoch 001:  64000 / 150053 loss=5.29, nll_loss=4.015, ppl=16.16, wps=15259, ups=4.3, wpb=3551.9, bsz=110.8, num_updates=64000, lr=0.000125, gnorm=1.026, train_wall=23, wall=0
2024-07-14 21:42:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 21:42:05 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.853 | nll_loss 4.588 | ppl 24.05 | wps 43512.1 | wpb 2588.8 | bsz 75.3 | num_updates 64000 | best_loss 12.174
2024-07-14 21:42:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 21:42:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_64000.pt (epoch 1 @ 64000 updates, score 5.853) (writing took 4.806928827427328 seconds)
2024-07-14 21:42:33 | INFO | train_inner | epoch 001:  64100 / 150053 loss=5.262, nll_loss=3.982, ppl=15.8, wps=11440.3, ups=3.24, wpb=3526.6, bsz=100.4, num_updates=64100, lr=0.000124902, gnorm=0.994, train_wall=23, wall=0
2024-07-14 21:42:56 | INFO | train_inner | epoch 001:  64200 / 150053 loss=5.284, nll_loss=4.006, ppl=16.07, wps=15517.4, ups=4.36, wpb=3562.1, bsz=95.3, num_updates=64200, lr=0.000124805, gnorm=0.993, train_wall=23, wall=0
2024-07-14 21:43:19 | INFO | train_inner | epoch 001:  64300 / 150053 loss=5.318, nll_loss=4.046, ppl=16.52, wps=15273.7, ups=4.31, wpb=3542.3, bsz=90.6, num_updates=64300, lr=0.000124708, gnorm=1.01, train_wall=23, wall=0
2024-07-14 21:43:42 | INFO | train_inner | epoch 001:  64400 / 150053 loss=5.332, nll_loss=4.062, ppl=16.7, wps=15106.5, ups=4.32, wpb=3494.8, bsz=103.8, num_updates=64400, lr=0.000124611, gnorm=1.045, train_wall=23, wall=0
2024-07-14 21:44:05 | INFO | train_inner | epoch 001:  64500 / 150053 loss=5.316, nll_loss=4.043, ppl=16.48, wps=15377, ups=4.33, wpb=3549, bsz=100.6, num_updates=64500, lr=0.000124515, gnorm=1.024, train_wall=23, wall=0
2024-07-14 21:44:29 | INFO | train_inner | epoch 001:  64600 / 150053 loss=5.282, nll_loss=4.005, ppl=16.05, wps=15355.6, ups=4.29, wpb=3578.1, bsz=99.4, num_updates=64600, lr=0.000124418, gnorm=0.998, train_wall=23, wall=0
2024-07-14 21:44:52 | INFO | train_inner | epoch 001:  64700 / 150053 loss=5.237, nll_loss=3.954, ppl=15.5, wps=15320.4, ups=4.27, wpb=3587.4, bsz=124.6, num_updates=64700, lr=0.000124322, gnorm=1.126, train_wall=23, wall=0
2024-07-14 21:45:15 | INFO | train_inner | epoch 001:  64800 / 150053 loss=5.32, nll_loss=4.048, ppl=16.54, wps=15315.9, ups=4.37, wpb=3504.6, bsz=94.1, num_updates=64800, lr=0.000124226, gnorm=1.021, train_wall=23, wall=0
2024-07-14 21:45:38 | INFO | train_inner | epoch 001:  64900 / 150053 loss=5.327, nll_loss=4.056, ppl=16.64, wps=15177, ups=4.35, wpb=3485.4, bsz=95.6, num_updates=64900, lr=0.00012413, gnorm=1.008, train_wall=23, wall=0
2024-07-14 21:46:01 | INFO | train_inner | epoch 001:  65000 / 150053 loss=5.257, nll_loss=3.976, ppl=15.74, wps=15468.1, ups=4.33, wpb=3576.3, bsz=117.9, num_updates=65000, lr=0.000124035, gnorm=1.015, train_wall=23, wall=0
2024-07-14 21:46:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 21:46:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.876 | nll_loss 4.605 | ppl 24.34 | wps 43176.1 | wpb 2588.8 | bsz 75.3 | num_updates 65000 | best_loss 12.174
2024-07-14 21:46:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 21:46:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_65000.pt (epoch 1 @ 65000 updates, score 5.876) (writing took 4.959584459662437 seconds)
2024-07-14 21:46:32 | INFO | train_inner | epoch 001:  65100 / 150053 loss=5.222, nll_loss=3.937, ppl=15.31, wps=11458.1, ups=3.23, wpb=3550.9, bsz=102.5, num_updates=65100, lr=0.000123939, gnorm=1.002, train_wall=23, wall=0
2024-07-14 21:46:55 | INFO | train_inner | epoch 001:  65200 / 150053 loss=5.31, nll_loss=4.037, ppl=16.42, wps=15111.8, ups=4.39, wpb=3444.3, bsz=99.3, num_updates=65200, lr=0.000123844, gnorm=1.051, train_wall=23, wall=0
2024-07-14 21:47:18 | INFO | train_inner | epoch 001:  65300 / 150053 loss=5.297, nll_loss=4.022, ppl=16.24, wps=15378.7, ups=4.33, wpb=3552.3, bsz=101.5, num_updates=65300, lr=0.000123749, gnorm=0.995, train_wall=23, wall=0
2024-07-14 21:47:41 | INFO | train_inner | epoch 001:  65400 / 150053 loss=5.286, nll_loss=4.01, ppl=16.11, wps=15221.1, ups=4.24, wpb=3592.1, bsz=104.2, num_updates=65400, lr=0.000123655, gnorm=1.002, train_wall=23, wall=0
2024-07-14 21:48:05 | INFO | train_inner | epoch 001:  65500 / 150053 loss=5.25, nll_loss=3.968, ppl=15.65, wps=15257.6, ups=4.26, wpb=3585.2, bsz=99.7, num_updates=65500, lr=0.00012356, gnorm=1.012, train_wall=23, wall=0
2024-07-14 21:48:28 | INFO | train_inner | epoch 001:  65600 / 150053 loss=5.277, nll_loss=3.999, ppl=15.99, wps=15215.4, ups=4.31, wpb=3529.4, bsz=97.6, num_updates=65600, lr=0.000123466, gnorm=1.01, train_wall=23, wall=0
2024-07-14 21:48:51 | INFO | train_inner | epoch 001:  65700 / 150053 loss=5.267, nll_loss=3.988, ppl=15.87, wps=15465.1, ups=4.3, wpb=3595.1, bsz=115.9, num_updates=65700, lr=0.000123372, gnorm=1.06, train_wall=23, wall=0
2024-07-14 21:49:15 | INFO | train_inner | epoch 001:  65800 / 150053 loss=5.267, nll_loss=3.988, ppl=15.87, wps=15463, ups=4.31, wpb=3583.8, bsz=102.7, num_updates=65800, lr=0.000123278, gnorm=1.008, train_wall=23, wall=0
2024-07-14 21:49:38 | INFO | train_inner | epoch 001:  65900 / 150053 loss=5.296, nll_loss=4.021, ppl=16.24, wps=15243.9, ups=4.3, wpb=3545.7, bsz=98.6, num_updates=65900, lr=0.000123185, gnorm=1.002, train_wall=23, wall=0
2024-07-14 21:50:01 | INFO | train_inner | epoch 001:  66000 / 150053 loss=5.209, nll_loss=3.922, ppl=15.16, wps=15230.9, ups=4.25, wpb=3580.7, bsz=117.5, num_updates=66000, lr=0.000123091, gnorm=1.12, train_wall=23, wall=0
2024-07-14 21:50:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 21:50:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.841 | nll_loss 4.572 | ppl 23.79 | wps 42829.7 | wpb 2588.8 | bsz 75.3 | num_updates 66000 | best_loss 12.174
2024-07-14 21:50:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 21:50:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_66000.pt (epoch 1 @ 66000 updates, score 5.841) (writing took 4.527272623963654 seconds)
2024-07-14 21:50:32 | INFO | train_inner | epoch 001:  66100 / 150053 loss=5.261, nll_loss=3.98, ppl=15.78, wps=11786.7, ups=3.24, wpb=3634.5, bsz=105.3, num_updates=66100, lr=0.000122998, gnorm=1.01, train_wall=23, wall=0
2024-07-14 21:50:55 | INFO | train_inner | epoch 001:  66200 / 150053 loss=5.268, nll_loss=3.989, ppl=15.87, wps=15241, ups=4.35, wpb=3505.9, bsz=102.3, num_updates=66200, lr=0.000122905, gnorm=1.044, train_wall=23, wall=0
2024-07-14 21:51:18 | INFO | train_inner | epoch 001:  66300 / 150053 loss=5.265, nll_loss=3.986, ppl=15.84, wps=15316.6, ups=4.33, wpb=3537, bsz=100.7, num_updates=66300, lr=0.000122813, gnorm=1.004, train_wall=23, wall=0
2024-07-14 21:51:41 | INFO | train_inner | epoch 001:  66400 / 150053 loss=5.291, nll_loss=4.016, ppl=16.18, wps=15458.5, ups=4.32, wpb=3576.3, bsz=100.4, num_updates=66400, lr=0.00012272, gnorm=1.021, train_wall=23, wall=0
2024-07-14 21:52:05 | INFO | train_inner | epoch 001:  66500 / 150053 loss=5.199, nll_loss=3.91, ppl=15.04, wps=15502.3, ups=4.29, wpb=3612.9, bsz=111, num_updates=66500, lr=0.000122628, gnorm=0.999, train_wall=23, wall=0
2024-07-14 21:52:28 | INFO | train_inner | epoch 001:  66600 / 150053 loss=5.314, nll_loss=4.042, ppl=16.47, wps=15320.3, ups=4.33, wpb=3534.6, bsz=99.4, num_updates=66600, lr=0.000122536, gnorm=1.04, train_wall=23, wall=0
2024-07-14 21:52:51 | INFO | train_inner | epoch 001:  66700 / 150053 loss=5.239, nll_loss=3.957, ppl=15.53, wps=15422.5, ups=4.3, wpb=3587.7, bsz=125.8, num_updates=66700, lr=0.000122444, gnorm=1.096, train_wall=23, wall=0
2024-07-14 21:53:14 | INFO | train_inner | epoch 001:  66800 / 150053 loss=5.192, nll_loss=3.903, ppl=14.96, wps=15325.2, ups=4.31, wpb=3553.8, bsz=107.1, num_updates=66800, lr=0.000122352, gnorm=0.982, train_wall=23, wall=0
2024-07-14 21:53:38 | INFO | train_inner | epoch 001:  66900 / 150053 loss=5.251, nll_loss=3.97, ppl=15.67, wps=15140, ups=4.29, wpb=3530.1, bsz=102, num_updates=66900, lr=0.000122261, gnorm=1.009, train_wall=23, wall=0
2024-07-14 21:54:01 | INFO | train_inner | epoch 001:  67000 / 150053 loss=5.294, nll_loss=4.018, ppl=16.2, wps=15115.5, ups=4.28, wpb=3528.2, bsz=94.3, num_updates=67000, lr=0.000122169, gnorm=1.01, train_wall=23, wall=0
2024-07-14 21:54:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 21:54:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.878 | nll_loss 4.611 | ppl 24.44 | wps 43171.7 | wpb 2588.8 | bsz 75.3 | num_updates 67000 | best_loss 12.174
2024-07-14 21:54:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 21:54:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_67000.pt (epoch 1 @ 67000 updates, score 5.878) (writing took 5.316484916955233 seconds)
2024-07-14 21:54:32 | INFO | train_inner | epoch 001:  67100 / 150053 loss=5.325, nll_loss=4.054, ppl=16.61, wps=11486, ups=3.22, wpb=3562.9, bsz=99.9, num_updates=67100, lr=0.000122078, gnorm=1.094, train_wall=23, wall=0
2024-07-14 21:54:55 | INFO | train_inner | epoch 001:  67200 / 150053 loss=5.263, nll_loss=3.983, ppl=15.82, wps=15416.4, ups=4.31, wpb=3580.1, bsz=106.1, num_updates=67200, lr=0.000121988, gnorm=1.011, train_wall=23, wall=0
2024-07-14 21:55:18 | INFO | train_inner | epoch 001:  67300 / 150053 loss=5.262, nll_loss=3.983, ppl=15.81, wps=15003.5, ups=4.3, wpb=3491.4, bsz=100.9, num_updates=67300, lr=0.000121897, gnorm=1.03, train_wall=23, wall=0
2024-07-14 21:55:41 | INFO | train_inner | epoch 001:  67400 / 150053 loss=5.318, nll_loss=4.046, ppl=16.52, wps=15521.7, ups=4.35, wpb=3566.1, bsz=97, num_updates=67400, lr=0.000121806, gnorm=1.008, train_wall=23, wall=0
2024-07-14 21:56:04 | INFO | train_inner | epoch 001:  67500 / 150053 loss=5.266, nll_loss=3.986, ppl=15.85, wps=15492.9, ups=4.33, wpb=3574.9, bsz=101.2, num_updates=67500, lr=0.000121716, gnorm=1.046, train_wall=23, wall=0
2024-07-14 21:56:28 | INFO | train_inner | epoch 001:  67600 / 150053 loss=5.32, nll_loss=4.048, ppl=16.55, wps=15197.4, ups=4.29, wpb=3542.9, bsz=95.9, num_updates=67600, lr=0.000121626, gnorm=1.009, train_wall=23, wall=0
2024-07-14 21:56:51 | INFO | train_inner | epoch 001:  67700 / 150053 loss=5.274, nll_loss=3.996, ppl=15.95, wps=15231.6, ups=4.32, wpb=3524, bsz=98.6, num_updates=67700, lr=0.000121536, gnorm=1.019, train_wall=23, wall=0
2024-07-14 21:57:14 | INFO | train_inner | epoch 001:  67800 / 150053 loss=5.321, nll_loss=4.049, ppl=16.56, wps=15233.5, ups=4.29, wpb=3548.7, bsz=96.6, num_updates=67800, lr=0.000121447, gnorm=1.005, train_wall=23, wall=0
2024-07-14 21:57:37 | INFO | train_inner | epoch 001:  67900 / 150053 loss=5.261, nll_loss=3.981, ppl=15.79, wps=15286.8, ups=4.3, wpb=3555.8, bsz=90.2, num_updates=67900, lr=0.000121357, gnorm=0.982, train_wall=23, wall=0
2024-07-14 21:58:01 | INFO | train_inner | epoch 001:  68000 / 150053 loss=5.308, nll_loss=4.034, ppl=16.39, wps=15248.7, ups=4.3, wpb=3544.8, bsz=101.7, num_updates=68000, lr=0.000121268, gnorm=1.039, train_wall=23, wall=0
2024-07-14 21:58:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 21:58:03 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.885 | nll_loss 4.617 | ppl 24.55 | wps 43217.4 | wpb 2588.8 | bsz 75.3 | num_updates 68000 | best_loss 12.174
2024-07-14 21:58:03 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 21:58:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_68000.pt (epoch 1 @ 68000 updates, score 5.885) (writing took 4.74650583602488 seconds)
2024-07-14 21:58:32 | INFO | train_inner | epoch 001:  68100 / 150053 loss=5.172, nll_loss=3.879, ppl=14.71, wps=11747.8, ups=3.23, wpb=3635.9, bsz=115.8, num_updates=68100, lr=0.000121179, gnorm=1.001, train_wall=23, wall=0
2024-07-14 21:58:55 | INFO | train_inner | epoch 001:  68200 / 150053 loss=5.341, nll_loss=4.072, ppl=16.82, wps=15049, ups=4.31, wpb=3493.5, bsz=92, num_updates=68200, lr=0.00012109, gnorm=1.029, train_wall=23, wall=0
2024-07-14 21:59:18 | INFO | train_inner | epoch 001:  68300 / 150053 loss=5.254, nll_loss=3.974, ppl=15.71, wps=15366.9, ups=4.3, wpb=3571.6, bsz=104.2, num_updates=68300, lr=0.000121001, gnorm=1.015, train_wall=23, wall=0
2024-07-14 21:59:41 | INFO | train_inner | epoch 001:  68400 / 150053 loss=5.333, nll_loss=4.064, ppl=16.72, wps=15284.2, ups=4.32, wpb=3534.8, bsz=84, num_updates=68400, lr=0.000120913, gnorm=1.018, train_wall=23, wall=0
2024-07-14 22:00:04 | INFO | train_inner | epoch 001:  68500 / 150053 loss=5.282, nll_loss=4.005, ppl=16.06, wps=15343.9, ups=4.33, wpb=3543.2, bsz=101.9, num_updates=68500, lr=0.000120824, gnorm=1.023, train_wall=23, wall=0
2024-07-14 22:00:28 | INFO | train_inner | epoch 001:  68600 / 150053 loss=5.275, nll_loss=3.998, ppl=15.98, wps=15287.7, ups=4.29, wpb=3563.5, bsz=105.4, num_updates=68600, lr=0.000120736, gnorm=1.028, train_wall=23, wall=0
2024-07-14 22:00:51 | INFO | train_inner | epoch 001:  68700 / 150053 loss=5.274, nll_loss=3.996, ppl=15.95, wps=15419.9, ups=4.29, wpb=3594.4, bsz=92.7, num_updates=68700, lr=0.000120648, gnorm=0.988, train_wall=23, wall=0
2024-07-14 22:01:14 | INFO | train_inner | epoch 001:  68800 / 150053 loss=5.236, nll_loss=3.953, ppl=15.48, wps=15353.7, ups=4.31, wpb=3562.3, bsz=114.9, num_updates=68800, lr=0.000120561, gnorm=1.04, train_wall=23, wall=0
2024-07-14 22:01:37 | INFO | train_inner | epoch 001:  68900 / 150053 loss=5.314, nll_loss=4.042, ppl=16.48, wps=15316.7, ups=4.29, wpb=3566.6, bsz=96.4, num_updates=68900, lr=0.000120473, gnorm=1.016, train_wall=23, wall=0
2024-07-14 22:02:01 | INFO | train_inner | epoch 001:  69000 / 150053 loss=5.252, nll_loss=3.972, ppl=15.69, wps=15560.6, ups=4.27, wpb=3645, bsz=100.9, num_updates=69000, lr=0.000120386, gnorm=0.992, train_wall=23, wall=0
2024-07-14 22:02:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 22:02:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.889 | nll_loss 4.62 | ppl 24.58 | wps 43332.3 | wpb 2588.8 | bsz 75.3 | num_updates 69000 | best_loss 12.174
2024-07-14 22:02:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 22:02:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_69000.pt (epoch 1 @ 69000 updates, score 5.889) (writing took 4.68283317796886 seconds)
2024-07-14 22:02:32 | INFO | train_inner | epoch 001:  69100 / 150053 loss=5.297, nll_loss=4.022, ppl=16.24, wps=11552.9, ups=3.25, wpb=3552.1, bsz=99.7, num_updates=69100, lr=0.000120299, gnorm=1.024, train_wall=23, wall=0
2024-07-14 22:02:55 | INFO | train_inner | epoch 001:  69200 / 150053 loss=5.207, nll_loss=3.92, ppl=15.14, wps=15159.9, ups=4.29, wpb=3536.9, bsz=112.2, num_updates=69200, lr=0.000120212, gnorm=0.996, train_wall=23, wall=0
2024-07-14 22:03:18 | INFO | train_inner | epoch 001:  69300 / 150053 loss=5.159, nll_loss=3.866, ppl=14.58, wps=15107.5, ups=4.27, wpb=3537.8, bsz=112.5, num_updates=69300, lr=0.000120125, gnorm=1.022, train_wall=23, wall=0
2024-07-14 22:03:42 | INFO | train_inner | epoch 001:  69400 / 150053 loss=5.317, nll_loss=4.045, ppl=16.51, wps=15114.9, ups=4.31, wpb=3510.2, bsz=87.9, num_updates=69400, lr=0.000120038, gnorm=1.036, train_wall=23, wall=0
2024-07-14 22:04:05 | INFO | train_inner | epoch 001:  69500 / 150053 loss=5.262, nll_loss=3.983, ppl=15.81, wps=15325.3, ups=4.31, wpb=3556.1, bsz=95.4, num_updates=69500, lr=0.000119952, gnorm=0.99, train_wall=23, wall=0
2024-07-14 22:04:28 | INFO | train_inner | epoch 001:  69600 / 150053 loss=5.231, nll_loss=3.947, ppl=15.43, wps=15572.8, ups=4.26, wpb=3657.4, bsz=100.8, num_updates=69600, lr=0.000119866, gnorm=1.006, train_wall=23, wall=0
2024-07-14 22:04:52 | INFO | train_inner | epoch 001:  69700 / 150053 loss=5.277, nll_loss=3.999, ppl=15.99, wps=15100.9, ups=4.28, wpb=3528.6, bsz=105.4, num_updates=69700, lr=0.00011978, gnorm=1.103, train_wall=23, wall=0
2024-07-14 22:05:15 | INFO | train_inner | epoch 001:  69800 / 150053 loss=5.228, nll_loss=3.944, ppl=15.39, wps=15209.7, ups=4.31, wpb=3529.9, bsz=110.8, num_updates=69800, lr=0.000119694, gnorm=1.072, train_wall=23, wall=0
2024-07-14 22:05:38 | INFO | train_inner | epoch 001:  69900 / 150053 loss=5.235, nll_loss=3.952, ppl=15.47, wps=14989.8, ups=4.32, wpb=3471.1, bsz=106.9, num_updates=69900, lr=0.000119608, gnorm=1.026, train_wall=23, wall=0
2024-07-14 22:06:02 | INFO | train_inner | epoch 001:  70000 / 150053 loss=5.321, nll_loss=4.05, ppl=16.56, wps=15189.7, ups=4.24, wpb=3578.5, bsz=83.9, num_updates=70000, lr=0.000119523, gnorm=1.002, train_wall=23, wall=0
2024-07-14 22:06:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 22:06:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.852 | nll_loss 4.581 | ppl 23.93 | wps 43339.9 | wpb 2588.8 | bsz 75.3 | num_updates 70000 | best_loss 12.174
2024-07-14 22:06:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 22:06:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_70000.pt (epoch 1 @ 70000 updates, score 5.852) (writing took 8.1467400258407 seconds)
2024-07-14 22:06:36 | INFO | train_inner | epoch 001:  70100 / 150053 loss=5.269, nll_loss=3.99, ppl=15.89, wps=10328.3, ups=2.92, wpb=3536.2, bsz=107.9, num_updates=70100, lr=0.000119438, gnorm=1.049, train_wall=23, wall=0
2024-07-14 22:06:59 | INFO | train_inner | epoch 001:  70200 / 150053 loss=5.277, nll_loss=4, ppl=16, wps=15046.5, ups=4.31, wpb=3491.4, bsz=99.4, num_updates=70200, lr=0.000119352, gnorm=1.044, train_wall=23, wall=0
2024-07-14 22:07:22 | INFO | train_inner | epoch 001:  70300 / 150053 loss=5.212, nll_loss=3.926, ppl=15.2, wps=15196, ups=4.3, wpb=3534.1, bsz=103.2, num_updates=70300, lr=0.000119268, gnorm=1.027, train_wall=23, wall=0
2024-07-14 22:07:46 | INFO | train_inner | epoch 001:  70400 / 150053 loss=5.208, nll_loss=3.921, ppl=15.15, wps=15320.9, ups=4.28, wpb=3580.2, bsz=112.3, num_updates=70400, lr=0.000119183, gnorm=1.026, train_wall=23, wall=0
2024-07-14 22:08:09 | INFO | train_inner | epoch 001:  70500 / 150053 loss=5.226, nll_loss=3.941, ppl=15.36, wps=15343.2, ups=4.29, wpb=3575.3, bsz=105.5, num_updates=70500, lr=0.000119098, gnorm=1.04, train_wall=23, wall=0
2024-07-14 22:08:32 | INFO | train_inner | epoch 001:  70600 / 150053 loss=5.251, nll_loss=3.97, ppl=15.68, wps=14968.1, ups=4.29, wpb=3492, bsz=102, num_updates=70600, lr=0.000119014, gnorm=1.027, train_wall=23, wall=0
2024-07-14 22:08:55 | INFO | train_inner | epoch 001:  70700 / 150053 loss=5.246, nll_loss=3.964, ppl=15.61, wps=15264.9, ups=4.34, wpb=3520.7, bsz=97.3, num_updates=70700, lr=0.00011893, gnorm=1.031, train_wall=23, wall=0
2024-07-14 22:09:19 | INFO | train_inner | epoch 001:  70800 / 150053 loss=5.203, nll_loss=3.914, ppl=15.08, wps=15718.8, ups=4.27, wpb=3680.8, bsz=109, num_updates=70800, lr=0.000118846, gnorm=0.978, train_wall=23, wall=0
2024-07-14 22:09:42 | INFO | train_inner | epoch 001:  70900 / 150053 loss=5.156, nll_loss=3.862, ppl=14.54, wps=15270.1, ups=4.27, wpb=3580, bsz=118.8, num_updates=70900, lr=0.000118762, gnorm=1.015, train_wall=23, wall=0
2024-07-14 22:10:06 | INFO | train_inner | epoch 001:  71000 / 150053 loss=5.232, nll_loss=3.948, ppl=15.43, wps=15227.6, ups=4.29, wpb=3552.2, bsz=101.8, num_updates=71000, lr=0.000118678, gnorm=1.008, train_wall=23, wall=0
2024-07-14 22:10:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 22:10:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.854 | nll_loss 4.58 | ppl 23.91 | wps 42979.1 | wpb 2588.8 | bsz 75.3 | num_updates 71000 | best_loss 12.174
2024-07-14 22:10:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 22:10:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_71000.pt (epoch 1 @ 71000 updates, score 5.854) (writing took 7.8223286885768175 seconds)
2024-07-14 22:10:39 | INFO | train_inner | epoch 001:  71100 / 150053 loss=5.252, nll_loss=3.971, ppl=15.68, wps=10260.6, ups=2.96, wpb=3464.2, bsz=105.1, num_updates=71100, lr=0.000118595, gnorm=1.08, train_wall=23, wall=0
2024-07-14 22:11:03 | INFO | train_inner | epoch 001:  71200 / 150053 loss=5.206, nll_loss=3.918, ppl=15.12, wps=15337.6, ups=4.27, wpb=3588.2, bsz=115.4, num_updates=71200, lr=0.000118511, gnorm=1.002, train_wall=23, wall=0
2024-07-14 22:11:26 | INFO | train_inner | epoch 001:  71300 / 150053 loss=5.223, nll_loss=3.938, ppl=15.33, wps=15220.7, ups=4.3, wpb=3540.1, bsz=102.7, num_updates=71300, lr=0.000118428, gnorm=1.014, train_wall=23, wall=0
2024-07-14 22:11:49 | INFO | train_inner | epoch 001:  71400 / 150053 loss=5.27, nll_loss=3.992, ppl=15.91, wps=15595.7, ups=4.28, wpb=3645.6, bsz=101, num_updates=71400, lr=0.000118345, gnorm=1.05, train_wall=23, wall=0
2024-07-14 22:12:13 | INFO | train_inner | epoch 001:  71500 / 150053 loss=5.303, nll_loss=4.029, ppl=16.33, wps=15311, ups=4.31, wpb=3553.9, bsz=93.9, num_updates=71500, lr=0.000118262, gnorm=1.025, train_wall=23, wall=0
2024-07-14 22:12:36 | INFO | train_inner | epoch 001:  71600 / 150053 loss=5.258, nll_loss=3.978, ppl=15.76, wps=15302.3, ups=4.29, wpb=3568.4, bsz=100.3, num_updates=71600, lr=0.00011818, gnorm=1.024, train_wall=23, wall=0
2024-07-14 22:12:59 | INFO | train_inner | epoch 001:  71700 / 150053 loss=5.178, nll_loss=3.886, ppl=14.79, wps=15182.5, ups=4.27, wpb=3553.1, bsz=106.3, num_updates=71700, lr=0.000118097, gnorm=1.006, train_wall=23, wall=0
2024-07-14 22:13:22 | INFO | train_inner | epoch 001:  71800 / 150053 loss=5.181, nll_loss=3.891, ppl=14.83, wps=15658, ups=4.35, wpb=3598.9, bsz=109, num_updates=71800, lr=0.000118015, gnorm=1.051, train_wall=23, wall=0
2024-07-14 22:13:46 | INFO | train_inner | epoch 001:  71900 / 150053 loss=5.255, nll_loss=3.974, ppl=15.71, wps=15271.4, ups=4.28, wpb=3564, bsz=99.8, num_updates=71900, lr=0.000117933, gnorm=1.022, train_wall=23, wall=0
2024-07-14 22:14:09 | INFO | train_inner | epoch 001:  72000 / 150053 loss=5.197, nll_loss=3.909, ppl=15.02, wps=15196.1, ups=4.32, wpb=3518.9, bsz=102.7, num_updates=72000, lr=0.000117851, gnorm=1.013, train_wall=23, wall=0
2024-07-14 22:14:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 22:14:11 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.873 | nll_loss 4.605 | ppl 24.33 | wps 43382.6 | wpb 2588.8 | bsz 75.3 | num_updates 72000 | best_loss 12.174
2024-07-14 22:14:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 22:14:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_72000.pt (epoch 1 @ 72000 updates, score 5.873) (writing took 8.37974346615374 seconds)
2024-07-14 22:14:43 | INFO | train_inner | epoch 001:  72100 / 150053 loss=5.279, nll_loss=4.002, ppl=16.02, wps=10392.1, ups=2.92, wpb=3557.9, bsz=105.1, num_updates=72100, lr=0.000117769, gnorm=1.027, train_wall=23, wall=0
2024-07-14 22:15:06 | INFO | train_inner | epoch 001:  72200 / 150053 loss=5.248, nll_loss=3.967, ppl=15.64, wps=15275.7, ups=4.33, wpb=3525.6, bsz=99.7, num_updates=72200, lr=0.000117688, gnorm=1.057, train_wall=23, wall=0
2024-07-14 22:15:29 | INFO | train_inner | epoch 001:  72300 / 150053 loss=5.302, nll_loss=4.028, ppl=16.32, wps=15099.6, ups=4.31, wpb=3505.4, bsz=104, num_updates=72300, lr=0.000117606, gnorm=1.074, train_wall=23, wall=0
2024-07-14 22:15:53 | INFO | train_inner | epoch 001:  72400 / 150053 loss=5.269, nll_loss=3.991, ppl=15.9, wps=14865.7, ups=4.29, wpb=3461.6, bsz=93.7, num_updates=72400, lr=0.000117525, gnorm=1.057, train_wall=23, wall=0
2024-07-14 22:16:16 | INFO | train_inner | epoch 001:  72500 / 150053 loss=5.224, nll_loss=3.939, ppl=15.34, wps=15087.5, ups=4.25, wpb=3554.1, bsz=94.5, num_updates=72500, lr=0.000117444, gnorm=1.001, train_wall=23, wall=0
2024-07-14 22:16:39 | INFO | train_inner | epoch 001:  72600 / 150053 loss=5.203, nll_loss=3.915, ppl=15.09, wps=15315.6, ups=4.29, wpb=3568.5, bsz=110.7, num_updates=72600, lr=0.000117363, gnorm=1.023, train_wall=23, wall=0
2024-07-14 22:17:02 | INFO | train_inner | epoch 001:  72700 / 150053 loss=5.23, nll_loss=3.946, ppl=15.41, wps=15296.8, ups=4.34, wpb=3522.3, bsz=100.3, num_updates=72700, lr=0.000117282, gnorm=1.038, train_wall=23, wall=0
2024-07-14 22:17:26 | INFO | train_inner | epoch 001:  72800 / 150053 loss=5.149, nll_loss=3.853, ppl=14.45, wps=15206.2, ups=4.29, wpb=3541.6, bsz=106.6, num_updates=72800, lr=0.000117202, gnorm=1.018, train_wall=23, wall=0
2024-07-14 22:17:49 | INFO | train_inner | epoch 001:  72900 / 150053 loss=5.269, nll_loss=3.99, ppl=15.89, wps=15332.7, ups=4.31, wpb=3559.1, bsz=95.5, num_updates=72900, lr=0.000117121, gnorm=1.032, train_wall=23, wall=0
2024-07-14 22:18:12 | INFO | train_inner | epoch 001:  73000 / 150053 loss=5.265, nll_loss=3.986, ppl=15.85, wps=15318.4, ups=4.31, wpb=3551.1, bsz=97, num_updates=73000, lr=0.000117041, gnorm=1.026, train_wall=23, wall=0
2024-07-14 22:18:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 22:18:15 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.803 | nll_loss 4.529 | ppl 23.09 | wps 43165.3 | wpb 2588.8 | bsz 75.3 | num_updates 73000 | best_loss 12.174
2024-07-14 22:18:15 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 22:18:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_73000.pt (epoch 1 @ 73000 updates, score 5.803) (writing took 6.38156786840409 seconds)
2024-07-14 22:18:44 | INFO | train_inner | epoch 001:  73100 / 150053 loss=5.193, nll_loss=3.904, ppl=14.97, wps=11188.2, ups=3.1, wpb=3612, bsz=107.3, num_updates=73100, lr=0.000116961, gnorm=1.005, train_wall=23, wall=0
2024-07-14 22:19:08 | INFO | train_inner | epoch 001:  73200 / 150053 loss=5.171, nll_loss=3.879, ppl=14.71, wps=14986.7, ups=4.28, wpb=3498.2, bsz=105.1, num_updates=73200, lr=0.000116881, gnorm=1.023, train_wall=23, wall=0
2024-07-14 22:19:31 | INFO | train_inner | epoch 001:  73300 / 150053 loss=5.201, nll_loss=3.913, ppl=15.06, wps=15184, ups=4.29, wpb=3542.6, bsz=103.6, num_updates=73300, lr=0.000116801, gnorm=1.02, train_wall=23, wall=0
2024-07-14 22:19:54 | INFO | train_inner | epoch 001:  73400 / 150053 loss=5.113, nll_loss=3.813, ppl=14.06, wps=15467, ups=4.29, wpb=3609.5, bsz=121.3, num_updates=73400, lr=0.000116722, gnorm=1.017, train_wall=23, wall=0
2024-07-14 22:20:18 | INFO | train_inner | epoch 001:  73500 / 150053 loss=5.274, nll_loss=3.996, ppl=15.96, wps=15144.4, ups=4.3, wpb=3524, bsz=103.1, num_updates=73500, lr=0.000116642, gnorm=1.088, train_wall=23, wall=0
2024-07-14 22:20:41 | INFO | train_inner | epoch 001:  73600 / 150053 loss=5.228, nll_loss=3.944, ppl=15.39, wps=15054.5, ups=4.29, wpb=3506.6, bsz=113.8, num_updates=73600, lr=0.000116563, gnorm=1.051, train_wall=23, wall=0
2024-07-14 22:21:04 | INFO | train_inner | epoch 001:  73700 / 150053 loss=5.191, nll_loss=3.902, ppl=14.95, wps=15177, ups=4.31, wpb=3523.4, bsz=111, num_updates=73700, lr=0.000116484, gnorm=1.025, train_wall=23, wall=0
2024-07-14 22:21:27 | INFO | train_inner | epoch 001:  73800 / 150053 loss=5.2, nll_loss=3.913, ppl=15.06, wps=15303.3, ups=4.39, wpb=3485.2, bsz=107.2, num_updates=73800, lr=0.000116405, gnorm=1.04, train_wall=23, wall=0
2024-07-14 22:21:50 | INFO | train_inner | epoch 001:  73900 / 150053 loss=5.15, nll_loss=3.855, ppl=14.47, wps=15160.6, ups=4.29, wpb=3531.7, bsz=123.7, num_updates=73900, lr=0.000116326, gnorm=1.029, train_wall=23, wall=0
2024-07-14 22:22:13 | INFO | train_inner | epoch 001:  74000 / 150053 loss=5.31, nll_loss=4.037, ppl=16.41, wps=15508.7, ups=4.34, wpb=3575.7, bsz=89.5, num_updates=74000, lr=0.000116248, gnorm=1.027, train_wall=23, wall=0
2024-07-14 22:22:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 22:22:16 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.798 | nll_loss 4.524 | ppl 23.01 | wps 43427 | wpb 2588.8 | bsz 75.3 | num_updates 74000 | best_loss 12.174
2024-07-14 22:22:16 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 22:22:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_74000.pt (epoch 1 @ 74000 updates, score 5.798) (writing took 7.3982863537967205 seconds)
2024-07-14 22:22:47 | INFO | train_inner | epoch 001:  74100 / 150053 loss=5.272, nll_loss=3.994, ppl=15.94, wps=10622.4, ups=2.97, wpb=3573.2, bsz=101.9, num_updates=74100, lr=0.000116169, gnorm=1.058, train_wall=23, wall=0
2024-07-14 22:23:10 | INFO | train_inner | epoch 001:  74200 / 150053 loss=5.253, nll_loss=3.973, ppl=15.7, wps=15256.8, ups=4.29, wpb=3554, bsz=106, num_updates=74200, lr=0.000116091, gnorm=1.083, train_wall=23, wall=0
2024-07-14 22:23:34 | INFO | train_inner | epoch 001:  74300 / 150053 loss=5.205, nll_loss=3.918, ppl=15.11, wps=15177.8, ups=4.25, wpb=3570.3, bsz=108.5, num_updates=74300, lr=0.000116013, gnorm=1.015, train_wall=23, wall=0
2024-07-14 22:23:57 | INFO | train_inner | epoch 001:  74400 / 150053 loss=5.158, nll_loss=3.864, ppl=14.56, wps=15081.7, ups=4.25, wpb=3551.5, bsz=108.8, num_updates=74400, lr=0.000115935, gnorm=1.027, train_wall=23, wall=0
2024-07-14 22:24:21 | INFO | train_inner | epoch 001:  74500 / 150053 loss=5.318, nll_loss=4.046, ppl=16.52, wps=15192, ups=4.25, wpb=3572.9, bsz=99, num_updates=74500, lr=0.000115857, gnorm=1.066, train_wall=23, wall=0
2024-07-14 22:24:44 | INFO | train_inner | epoch 001:  74600 / 150053 loss=5.29, nll_loss=4.014, ppl=16.16, wps=15225.8, ups=4.3, wpb=3543.9, bsz=94.5, num_updates=74600, lr=0.000115779, gnorm=1.018, train_wall=23, wall=0
2024-07-14 22:25:08 | INFO | train_inner | epoch 001:  74700 / 150053 loss=5.13, nll_loss=3.832, ppl=14.24, wps=15417.7, ups=4.24, wpb=3638.1, bsz=126.8, num_updates=74700, lr=0.000115702, gnorm=1.025, train_wall=23, wall=0
2024-07-14 22:25:31 | INFO | train_inner | epoch 001:  74800 / 150053 loss=5.177, nll_loss=3.885, ppl=14.77, wps=15206.5, ups=4.26, wpb=3565.7, bsz=99.6, num_updates=74800, lr=0.000115624, gnorm=1.002, train_wall=23, wall=0
2024-07-14 22:25:54 | INFO | train_inner | epoch 001:  74900 / 150053 loss=5.184, nll_loss=3.893, ppl=14.86, wps=15262.1, ups=4.32, wpb=3533.4, bsz=111.6, num_updates=74900, lr=0.000115547, gnorm=1.038, train_wall=23, wall=0
2024-07-14 22:26:18 | INFO | train_inner | epoch 001:  75000 / 150053 loss=5.189, nll_loss=3.899, ppl=14.92, wps=15172.2, ups=4.29, wpb=3538.9, bsz=112.3, num_updates=75000, lr=0.00011547, gnorm=1.037, train_wall=23, wall=0
2024-07-14 22:26:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 22:26:20 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.824 | nll_loss 4.552 | ppl 23.46 | wps 43410 | wpb 2588.8 | bsz 75.3 | num_updates 75000 | best_loss 12.174
2024-07-14 22:26:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 22:26:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_75000.pt (epoch 1 @ 75000 updates, score 5.824) (writing took 11.232981780543923 seconds)
2024-07-14 22:26:55 | INFO | train_inner | epoch 001:  75100 / 150053 loss=5.135, nll_loss=3.838, ppl=14.3, wps=9657.1, ups=2.68, wpb=3606.2, bsz=119.8, num_updates=75100, lr=0.000115393, gnorm=1.019, train_wall=23, wall=0
2024-07-14 22:27:18 | INFO | train_inner | epoch 001:  75200 / 150053 loss=5.246, nll_loss=3.965, ppl=15.62, wps=15259.4, ups=4.3, wpb=3550.8, bsz=92.2, num_updates=75200, lr=0.000115316, gnorm=1.019, train_wall=23, wall=0
2024-07-14 22:27:42 | INFO | train_inner | epoch 001:  75300 / 150053 loss=5.264, nll_loss=3.985, ppl=15.83, wps=15110.3, ups=4.28, wpb=3526.9, bsz=105.6, num_updates=75300, lr=0.00011524, gnorm=1.043, train_wall=23, wall=0
2024-07-14 22:28:04 | INFO | train_inner | epoch 001:  75400 / 150053 loss=5.24, nll_loss=3.957, ppl=15.53, wps=15172.1, ups=4.39, wpb=3457, bsz=105.9, num_updates=75400, lr=0.000115163, gnorm=1.099, train_wall=23, wall=0
2024-07-14 22:28:28 | INFO | train_inner | epoch 001:  75500 / 150053 loss=5.166, nll_loss=3.873, ppl=14.65, wps=15224.4, ups=4.28, wpb=3557.9, bsz=116.8, num_updates=75500, lr=0.000115087, gnorm=1.065, train_wall=23, wall=0
2024-07-14 22:28:51 | INFO | train_inner | epoch 001:  75600 / 150053 loss=5.215, nll_loss=3.93, ppl=15.24, wps=14984, ups=4.33, wpb=3463.6, bsz=110.5, num_updates=75600, lr=0.000115011, gnorm=1.077, train_wall=23, wall=0
2024-07-14 22:29:14 | INFO | train_inner | epoch 001:  75700 / 150053 loss=5.28, nll_loss=4.003, ppl=16.03, wps=15344.3, ups=4.27, wpb=3597.3, bsz=95, num_updates=75700, lr=0.000114935, gnorm=1.028, train_wall=23, wall=0
2024-07-14 22:29:38 | INFO | train_inner | epoch 001:  75800 / 150053 loss=5.211, nll_loss=3.925, ppl=15.19, wps=15296, ups=4.27, wpb=3586.2, bsz=96.7, num_updates=75800, lr=0.000114859, gnorm=1.014, train_wall=23, wall=0
2024-07-14 22:30:01 | INFO | train_inner | epoch 001:  75900 / 150053 loss=5.225, nll_loss=3.941, ppl=15.36, wps=15333.2, ups=4.32, wpb=3545.5, bsz=94, num_updates=75900, lr=0.000114783, gnorm=1.033, train_wall=23, wall=0
2024-07-14 22:30:24 | INFO | train_inner | epoch 001:  76000 / 150053 loss=5.24, nll_loss=3.957, ppl=15.53, wps=15254.4, ups=4.33, wpb=3524.3, bsz=102, num_updates=76000, lr=0.000114708, gnorm=1.058, train_wall=23, wall=0
2024-07-14 22:30:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 22:30:27 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.882 | nll_loss 4.612 | ppl 24.45 | wps 43452 | wpb 2588.8 | bsz 75.3 | num_updates 76000 | best_loss 12.174
2024-07-14 22:30:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 22:30:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_76000.pt (epoch 1 @ 76000 updates, score 5.882) (writing took 8.394538396969438 seconds)
2024-07-14 22:30:58 | INFO | train_inner | epoch 001:  76100 / 150053 loss=5.215, nll_loss=3.929, ppl=15.23, wps=10301, ups=2.93, wpb=3514.7, bsz=101.9, num_updates=76100, lr=0.000114632, gnorm=1.037, train_wall=23, wall=0
2024-07-14 22:31:21 | INFO | train_inner | epoch 001:  76200 / 150053 loss=5.258, nll_loss=3.979, ppl=15.77, wps=15083.1, ups=4.32, wpb=3495.4, bsz=90.5, num_updates=76200, lr=0.000114557, gnorm=1.055, train_wall=23, wall=0
2024-07-14 22:31:44 | INFO | train_inner | epoch 001:  76300 / 150053 loss=5.169, nll_loss=3.877, ppl=14.69, wps=15302.3, ups=4.32, wpb=3543.8, bsz=114.7, num_updates=76300, lr=0.000114482, gnorm=1.054, train_wall=23, wall=0
2024-07-14 22:32:08 | INFO | train_inner | epoch 001:  76400 / 150053 loss=5.242, nll_loss=3.96, ppl=15.57, wps=15231.8, ups=4.3, wpb=3544.3, bsz=103, num_updates=76400, lr=0.000114407, gnorm=1.055, train_wall=23, wall=0
2024-07-14 22:32:31 | INFO | train_inner | epoch 001:  76500 / 150053 loss=5.276, nll_loss=3.998, ppl=15.98, wps=15023.3, ups=4.25, wpb=3534.6, bsz=93.7, num_updates=76500, lr=0.000114332, gnorm=1.062, train_wall=23, wall=0
2024-07-14 22:32:55 | INFO | train_inner | epoch 001:  76600 / 150053 loss=5.156, nll_loss=3.861, ppl=14.53, wps=15616.4, ups=4.3, wpb=3632.4, bsz=115.4, num_updates=76600, lr=0.000114258, gnorm=1.018, train_wall=23, wall=0
2024-07-14 22:33:18 | INFO | train_inner | epoch 001:  76700 / 150053 loss=5.24, nll_loss=3.958, ppl=15.54, wps=15264.9, ups=4.3, wpb=3553.8, bsz=108, num_updates=76700, lr=0.000114183, gnorm=1.041, train_wall=23, wall=0
2024-07-14 22:33:41 | INFO | train_inner | epoch 001:  76800 / 150053 loss=5.224, nll_loss=3.939, ppl=15.34, wps=14975.5, ups=4.23, wpb=3543.6, bsz=109.8, num_updates=76800, lr=0.000114109, gnorm=1.089, train_wall=23, wall=0
2024-07-14 22:34:05 | INFO | train_inner | epoch 001:  76900 / 150053 loss=5.285, nll_loss=4.009, ppl=16.1, wps=15001.7, ups=4.3, wpb=3492.2, bsz=93.6, num_updates=76900, lr=0.000114035, gnorm=1.038, train_wall=23, wall=0
2024-07-14 22:34:28 | INFO | train_inner | epoch 001:  77000 / 150053 loss=5.168, nll_loss=3.875, ppl=14.68, wps=15306, ups=4.31, wpb=3551.6, bsz=125, num_updates=77000, lr=0.000113961, gnorm=1.209, train_wall=23, wall=0
2024-07-14 22:34:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 22:34:31 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.905 | nll_loss 4.637 | ppl 24.89 | wps 43507 | wpb 2588.8 | bsz 75.3 | num_updates 77000 | best_loss 12.174
2024-07-14 22:34:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 22:34:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_77000.pt (epoch 1 @ 77000 updates, score 5.905) (writing took 8.35558452643454 seconds)
2024-07-14 22:35:02 | INFO | train_inner | epoch 001:  77100 / 150053 loss=5.19, nll_loss=3.902, ppl=14.94, wps=10407.2, ups=2.91, wpb=3573.5, bsz=111.7, num_updates=77100, lr=0.000113887, gnorm=1.019, train_wall=23, wall=0
2024-07-14 22:35:25 | INFO | train_inner | epoch 001:  77200 / 150053 loss=5.267, nll_loss=3.988, ppl=15.87, wps=15279.4, ups=4.36, wpb=3505.6, bsz=93.8, num_updates=77200, lr=0.000113813, gnorm=1.049, train_wall=23, wall=0
2024-07-14 22:35:48 | INFO | train_inner | epoch 001:  77300 / 150053 loss=5.255, nll_loss=3.975, ppl=15.73, wps=15163.6, ups=4.36, wpb=3478.4, bsz=98.4, num_updates=77300, lr=0.000113739, gnorm=1.039, train_wall=23, wall=0
2024-07-14 22:36:12 | INFO | train_inner | epoch 001:  77400 / 150053 loss=5.219, nll_loss=3.934, ppl=15.29, wps=15350.7, ups=4.27, wpb=3597.1, bsz=96.9, num_updates=77400, lr=0.000113666, gnorm=1.018, train_wall=23, wall=0
2024-07-14 22:36:35 | INFO | train_inner | epoch 001:  77500 / 150053 loss=5.227, nll_loss=3.943, ppl=15.38, wps=15352.5, ups=4.31, wpb=3559.6, bsz=99.8, num_updates=77500, lr=0.000113592, gnorm=1.023, train_wall=23, wall=0
2024-07-14 22:36:58 | INFO | train_inner | epoch 001:  77600 / 150053 loss=5.209, nll_loss=3.922, ppl=15.16, wps=15355.4, ups=4.34, wpb=3536.2, bsz=97, num_updates=77600, lr=0.000113519, gnorm=1.021, train_wall=23, wall=0
2024-07-14 22:37:21 | INFO | train_inner | epoch 001:  77700 / 150053 loss=5.238, nll_loss=3.956, ppl=15.51, wps=15530.1, ups=4.27, wpb=3639.4, bsz=115.8, num_updates=77700, lr=0.000113446, gnorm=1.107, train_wall=23, wall=0
2024-07-14 22:37:44 | INFO | train_inner | epoch 001:  77800 / 150053 loss=5.266, nll_loss=3.987, ppl=15.86, wps=15480.8, ups=4.36, wpb=3553, bsz=98.2, num_updates=77800, lr=0.000113373, gnorm=1.044, train_wall=23, wall=0
2024-07-14 22:38:08 | INFO | train_inner | epoch 001:  77900 / 150053 loss=5.16, nll_loss=3.865, ppl=14.57, wps=15447.4, ups=4.28, wpb=3611.3, bsz=112.8, num_updates=77900, lr=0.0001133, gnorm=1.009, train_wall=23, wall=0
2024-07-14 22:38:31 | INFO | train_inner | epoch 001:  78000 / 150053 loss=5.22, nll_loss=3.936, ppl=15.3, wps=14991.3, ups=4.35, wpb=3446.1, bsz=90.4, num_updates=78000, lr=0.000113228, gnorm=1.067, train_wall=23, wall=0
2024-07-14 22:38:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 22:38:33 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.802 | nll_loss 4.524 | ppl 23 | wps 43634.7 | wpb 2588.8 | bsz 75.3 | num_updates 78000 | best_loss 12.174
2024-07-14 22:38:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 22:38:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_78000.pt (epoch 1 @ 78000 updates, score 5.802) (writing took 19.658711163327098 seconds)
2024-07-14 22:39:16 | INFO | train_inner | epoch 001:  78100 / 150053 loss=5.164, nll_loss=3.872, ppl=14.64, wps=7806.5, ups=2.19, wpb=3572.7, bsz=115.1, num_updates=78100, lr=0.000113155, gnorm=1.05, train_wall=23, wall=0
2024-07-14 22:39:39 | INFO | train_inner | epoch 001:  78200 / 150053 loss=5.26, nll_loss=3.981, ppl=15.79, wps=15622.7, ups=4.41, wpb=3544.5, bsz=94.6, num_updates=78200, lr=0.000113083, gnorm=1.032, train_wall=23, wall=0
2024-07-14 22:40:02 | INFO | train_inner | epoch 001:  78300 / 150053 loss=5.217, nll_loss=3.931, ppl=15.26, wps=15204.3, ups=4.32, wpb=3517.1, bsz=102.8, num_updates=78300, lr=0.000113011, gnorm=1.098, train_wall=23, wall=0
2024-07-14 22:40:25 | INFO | train_inner | epoch 001:  78400 / 150053 loss=5.171, nll_loss=3.88, ppl=14.72, wps=15070.9, ups=4.32, wpb=3492.1, bsz=115.2, num_updates=78400, lr=0.000112938, gnorm=1.067, train_wall=23, wall=0
2024-07-14 22:40:49 | INFO | train_inner | epoch 001:  78500 / 150053 loss=5.179, nll_loss=3.889, ppl=14.81, wps=15414.8, ups=4.28, wpb=3602.5, bsz=105.7, num_updates=78500, lr=0.000112867, gnorm=1.002, train_wall=23, wall=0
2024-07-14 22:41:12 | INFO | train_inner | epoch 001:  78600 / 150053 loss=5.215, nll_loss=3.929, ppl=15.23, wps=15320.3, ups=4.28, wpb=3580.8, bsz=94.6, num_updates=78600, lr=0.000112795, gnorm=1.015, train_wall=23, wall=0
2024-07-14 22:41:35 | INFO | train_inner | epoch 001:  78700 / 150053 loss=5.214, nll_loss=3.929, ppl=15.23, wps=15245.8, ups=4.31, wpb=3537.8, bsz=104.2, num_updates=78700, lr=0.000112723, gnorm=1.036, train_wall=23, wall=0
2024-07-14 22:41:59 | INFO | train_inner | epoch 001:  78800 / 150053 loss=5.197, nll_loss=3.908, ppl=15.01, wps=15248.4, ups=4.27, wpb=3574.7, bsz=98.7, num_updates=78800, lr=0.000112651, gnorm=1.013, train_wall=23, wall=0
2024-07-14 22:42:22 | INFO | train_inner | epoch 001:  78900 / 150053 loss=5.272, nll_loss=3.994, ppl=15.94, wps=15030.5, ups=4.35, wpb=3453.7, bsz=86.8, num_updates=78900, lr=0.00011258, gnorm=1.081, train_wall=23, wall=0
2024-07-14 22:42:45 | INFO | train_inner | epoch 001:  79000 / 150053 loss=5.212, nll_loss=3.926, ppl=15.2, wps=15301, ups=4.27, wpb=3584.5, bsz=110.2, num_updates=79000, lr=0.000112509, gnorm=1.107, train_wall=23, wall=0
2024-07-14 22:42:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 22:42:48 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.817 | nll_loss 4.549 | ppl 23.4 | wps 43484.5 | wpb 2588.8 | bsz 75.3 | num_updates 79000 | best_loss 12.174
2024-07-14 22:42:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 22:42:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_79000.pt (epoch 1 @ 79000 updates, score 5.817) (writing took 6.116495383903384 seconds)
2024-07-14 22:43:17 | INFO | train_inner | epoch 001:  79100 / 150053 loss=5.19, nll_loss=3.901, ppl=14.94, wps=11014.3, ups=3.11, wpb=3544.9, bsz=100.6, num_updates=79100, lr=0.000112438, gnorm=1.006, train_wall=23, wall=0
2024-07-14 22:43:41 | INFO | train_inner | epoch 001:  79200 / 150053 loss=5.16, nll_loss=3.866, ppl=14.58, wps=15214, ups=4.28, wpb=3552.8, bsz=115.4, num_updates=79200, lr=0.000112367, gnorm=1.032, train_wall=23, wall=0
2024-07-14 22:44:04 | INFO | train_inner | epoch 001:  79300 / 150053 loss=5.167, nll_loss=3.874, ppl=14.67, wps=15229.5, ups=4.3, wpb=3545.5, bsz=108.7, num_updates=79300, lr=0.000112296, gnorm=1.042, train_wall=23, wall=0
2024-07-14 22:44:27 | INFO | train_inner | epoch 001:  79400 / 150053 loss=5.237, nll_loss=3.954, ppl=15.5, wps=15588.7, ups=4.3, wpb=3625.4, bsz=98.2, num_updates=79400, lr=0.000112225, gnorm=1.026, train_wall=23, wall=0
2024-07-14 22:44:50 | INFO | train_inner | epoch 001:  79500 / 150053 loss=5.194, nll_loss=3.906, ppl=14.99, wps=15320.7, ups=4.31, wpb=3550.9, bsz=108.2, num_updates=79500, lr=0.000112154, gnorm=1.027, train_wall=23, wall=0
2024-07-14 22:45:13 | INFO | train_inner | epoch 001:  79600 / 150053 loss=5.183, nll_loss=3.894, ppl=14.86, wps=15067.2, ups=4.38, wpb=3441.4, bsz=95.4, num_updates=79600, lr=0.000112084, gnorm=1.042, train_wall=23, wall=0
2024-07-14 22:45:36 | INFO | train_inner | epoch 001:  79700 / 150053 loss=5.25, nll_loss=3.969, ppl=15.66, wps=15120.3, ups=4.31, wpb=3507.3, bsz=105.3, num_updates=79700, lr=0.000112014, gnorm=1.043, train_wall=23, wall=0
2024-07-14 22:46:00 | INFO | train_inner | epoch 001:  79800 / 150053 loss=5.199, nll_loss=3.911, ppl=15.04, wps=15570.1, ups=4.32, wpb=3603.8, bsz=109.1, num_updates=79800, lr=0.000111943, gnorm=1.052, train_wall=23, wall=0
2024-07-14 22:46:23 | INFO | train_inner | epoch 001:  79900 / 150053 loss=5.108, nll_loss=3.808, ppl=14, wps=15176.6, ups=4.33, wpb=3504.8, bsz=126, num_updates=79900, lr=0.000111873, gnorm=1.045, train_wall=23, wall=0
2024-07-14 22:46:46 | INFO | train_inner | epoch 001:  80000 / 150053 loss=5.225, nll_loss=3.941, ppl=15.36, wps=15048.7, ups=4.35, wpb=3462.6, bsz=88.7, num_updates=80000, lr=0.000111803, gnorm=1.026, train_wall=23, wall=0
2024-07-14 22:46:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 22:46:48 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.798 | nll_loss 4.522 | ppl 22.98 | wps 43584.1 | wpb 2588.8 | bsz 75.3 | num_updates 80000 | best_loss 12.174
2024-07-14 22:46:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 22:47:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_80000.pt (epoch 1 @ 80000 updates, score 5.798) (writing took 13.63988214544952 seconds)
2024-07-14 22:47:25 | INFO | train_inner | epoch 001:  80100 / 150053 loss=5.234, nll_loss=3.951, ppl=15.47, wps=9101.7, ups=2.51, wpb=3622.4, bsz=103.5, num_updates=80100, lr=0.000111734, gnorm=1.044, train_wall=23, wall=0
2024-07-14 22:47:49 | INFO | train_inner | epoch 001:  80200 / 150053 loss=5.159, nll_loss=3.865, ppl=14.57, wps=15269.5, ups=4.28, wpb=3569.7, bsz=106.8, num_updates=80200, lr=0.000111664, gnorm=1.032, train_wall=23, wall=0
2024-07-14 22:48:12 | INFO | train_inner | epoch 001:  80300 / 150053 loss=5.17, nll_loss=3.878, ppl=14.71, wps=15581.9, ups=4.34, wpb=3586.3, bsz=119.6, num_updates=80300, lr=0.000111594, gnorm=1.12, train_wall=23, wall=0
2024-07-14 22:48:35 | INFO | train_inner | epoch 001:  80400 / 150053 loss=5.178, nll_loss=3.887, ppl=14.8, wps=15304.5, ups=4.27, wpb=3582.3, bsz=110.3, num_updates=80400, lr=0.000111525, gnorm=1.023, train_wall=23, wall=0
2024-07-14 22:48:58 | INFO | train_inner | epoch 001:  80500 / 150053 loss=5.176, nll_loss=3.885, ppl=14.77, wps=15705.7, ups=4.37, wpb=3594.8, bsz=107.6, num_updates=80500, lr=0.000111456, gnorm=1.033, train_wall=23, wall=0
2024-07-14 22:49:21 | INFO | train_inner | epoch 001:  80600 / 150053 loss=5.271, nll_loss=3.993, ppl=15.93, wps=15397.7, ups=4.36, wpb=3535.3, bsz=87.1, num_updates=80600, lr=0.000111386, gnorm=1.049, train_wall=23, wall=0
2024-07-14 22:49:44 | INFO | train_inner | epoch 001:  80700 / 150053 loss=5.171, nll_loss=3.879, ppl=14.71, wps=15158.6, ups=4.29, wpb=3536.3, bsz=97.1, num_updates=80700, lr=0.000111317, gnorm=1.014, train_wall=23, wall=0
2024-07-14 22:50:08 | INFO | train_inner | epoch 001:  80800 / 150053 loss=5.256, nll_loss=3.975, ppl=15.73, wps=15233.3, ups=4.31, wpb=3538.3, bsz=93, num_updates=80800, lr=0.000111249, gnorm=1.041, train_wall=23, wall=0
2024-07-14 22:50:31 | INFO | train_inner | epoch 001:  80900 / 150053 loss=5.235, nll_loss=3.952, ppl=15.48, wps=15609, ups=4.38, wpb=3563.5, bsz=94.2, num_updates=80900, lr=0.00011118, gnorm=1.027, train_wall=23, wall=0
2024-07-14 22:50:54 | INFO | train_inner | epoch 001:  81000 / 150053 loss=5.201, nll_loss=3.914, ppl=15.07, wps=15303.6, ups=4.35, wpb=3516.6, bsz=93.8, num_updates=81000, lr=0.000111111, gnorm=1.031, train_wall=23, wall=0
2024-07-14 22:50:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 22:50:56 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.8 | nll_loss 4.522 | ppl 22.97 | wps 43798 | wpb 2588.8 | bsz 75.3 | num_updates 81000 | best_loss 12.174
2024-07-14 22:50:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 22:51:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_81000.pt (epoch 1 @ 81000 updates, score 5.8) (writing took 7.487486999481916 seconds)
2024-07-14 22:51:27 | INFO | train_inner | epoch 001:  81100 / 150053 loss=5.199, nll_loss=3.911, ppl=15.04, wps=10603.8, ups=2.99, wpb=3546.6, bsz=111.4, num_updates=81100, lr=0.000111043, gnorm=1.036, train_wall=23, wall=0
2024-07-14 22:51:50 | INFO | train_inner | epoch 001:  81200 / 150053 loss=5.208, nll_loss=3.921, ppl=15.15, wps=15208.3, ups=4.3, wpb=3535.9, bsz=98.6, num_updates=81200, lr=0.000110974, gnorm=1.054, train_wall=23, wall=0
2024-07-14 22:52:13 | INFO | train_inner | epoch 001:  81300 / 150053 loss=5.169, nll_loss=3.877, ppl=14.7, wps=14860.2, ups=4.29, wpb=3461.1, bsz=113.9, num_updates=81300, lr=0.000110906, gnorm=1.059, train_wall=23, wall=0
2024-07-14 22:52:37 | INFO | train_inner | epoch 001:  81400 / 150053 loss=5.183, nll_loss=3.893, ppl=14.85, wps=15158.7, ups=4.34, wpb=3490.4, bsz=92.7, num_updates=81400, lr=0.000110838, gnorm=1.03, train_wall=23, wall=0
2024-07-14 22:53:00 | INFO | train_inner | epoch 001:  81500 / 150053 loss=5.183, nll_loss=3.893, ppl=14.85, wps=15271.8, ups=4.29, wpb=3557.5, bsz=112.5, num_updates=81500, lr=0.00011077, gnorm=1.041, train_wall=23, wall=0
2024-07-14 22:53:23 | INFO | train_inner | epoch 001:  81600 / 150053 loss=5.144, nll_loss=3.849, ppl=14.41, wps=15376.9, ups=4.29, wpb=3583.5, bsz=106.6, num_updates=81600, lr=0.000110702, gnorm=1.037, train_wall=23, wall=0
2024-07-14 22:53:46 | INFO | train_inner | epoch 001:  81700 / 150053 loss=5.191, nll_loss=3.903, ppl=14.96, wps=15171, ups=4.29, wpb=3535.6, bsz=106.7, num_updates=81700, lr=0.000110634, gnorm=1.063, train_wall=23, wall=0
2024-07-14 22:54:10 | INFO | train_inner | epoch 001:  81800 / 150053 loss=5.262, nll_loss=3.983, ppl=15.82, wps=15047.3, ups=4.33, wpb=3473.4, bsz=92.4, num_updates=81800, lr=0.000110566, gnorm=1.04, train_wall=23, wall=0
2024-07-14 22:54:33 | INFO | train_inner | epoch 001:  81900 / 150053 loss=5.097, nll_loss=3.794, ppl=13.87, wps=15618.2, ups=4.19, wpb=3731.6, bsz=127.2, num_updates=81900, lr=0.000110499, gnorm=1.007, train_wall=24, wall=0
2024-07-14 22:54:56 | INFO | train_inner | epoch 001:  82000 / 150053 loss=5.2, nll_loss=3.912, ppl=15.05, wps=15301.2, ups=4.36, wpb=3508.2, bsz=103.4, num_updates=82000, lr=0.000110432, gnorm=1.061, train_wall=23, wall=0
2024-07-14 22:54:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 22:54:59 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.836 | nll_loss 4.56 | ppl 23.58 | wps 43401.4 | wpb 2588.8 | bsz 75.3 | num_updates 82000 | best_loss 12.174
2024-07-14 22:54:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 22:55:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_82000.pt (epoch 1 @ 82000 updates, score 5.836) (writing took 11.614186293445528 seconds)
2024-07-14 22:55:34 | INFO | train_inner | epoch 001:  82100 / 150053 loss=5.206, nll_loss=3.919, ppl=15.13, wps=9359.3, ups=2.63, wpb=3552.3, bsz=105.5, num_updates=82100, lr=0.000110364, gnorm=1.062, train_wall=23, wall=0
2024-07-14 22:55:58 | INFO | train_inner | epoch 001:  82200 / 150053 loss=5.239, nll_loss=3.956, ppl=15.52, wps=15079.6, ups=4.28, wpb=3519.4, bsz=87.8, num_updates=82200, lr=0.000110297, gnorm=1.016, train_wall=23, wall=0
2024-07-14 22:56:21 | INFO | train_inner | epoch 001:  82300 / 150053 loss=5.215, nll_loss=3.929, ppl=15.23, wps=15495.9, ups=4.33, wpb=3576.2, bsz=108.2, num_updates=82300, lr=0.00011023, gnorm=1.088, train_wall=23, wall=0
2024-07-14 22:56:44 | INFO | train_inner | epoch 001:  82400 / 150053 loss=5.139, nll_loss=3.844, ppl=14.36, wps=15380, ups=4.25, wpb=3616.9, bsz=102.6, num_updates=82400, lr=0.000110163, gnorm=0.995, train_wall=23, wall=0
2024-07-14 22:57:08 | INFO | train_inner | epoch 001:  82500 / 150053 loss=5.148, nll_loss=3.854, ppl=14.46, wps=15278.1, ups=4.29, wpb=3557.6, bsz=101.4, num_updates=82500, lr=0.000110096, gnorm=1.014, train_wall=23, wall=0
2024-07-14 22:57:31 | INFO | train_inner | epoch 001:  82600 / 150053 loss=5.258, nll_loss=3.978, ppl=15.76, wps=15193, ups=4.27, wpb=3556.5, bsz=83.4, num_updates=82600, lr=0.00011003, gnorm=1.028, train_wall=23, wall=0
2024-07-14 22:57:54 | INFO | train_inner | epoch 001:  82700 / 150053 loss=5.198, nll_loss=3.91, ppl=15.03, wps=15153.7, ups=4.26, wpb=3559.1, bsz=103.1, num_updates=82700, lr=0.000109963, gnorm=1.034, train_wall=23, wall=0
2024-07-14 22:58:18 | INFO | train_inner | epoch 001:  82800 / 150053 loss=5.234, nll_loss=3.951, ppl=15.46, wps=15192.9, ups=4.28, wpb=3548.5, bsz=95.7, num_updates=82800, lr=0.000109897, gnorm=1.035, train_wall=23, wall=0
2024-07-14 22:58:41 | INFO | train_inner | epoch 001:  82900 / 150053 loss=5.164, nll_loss=3.871, ppl=14.63, wps=15272.6, ups=4.31, wpb=3543.7, bsz=109.6, num_updates=82900, lr=0.00010983, gnorm=1.05, train_wall=23, wall=0
2024-07-14 22:59:04 | INFO | train_inner | epoch 001:  83000 / 150053 loss=5.124, nll_loss=3.826, ppl=14.18, wps=15395.3, ups=4.36, wpb=3533.6, bsz=119.4, num_updates=83000, lr=0.000109764, gnorm=1.052, train_wall=23, wall=0
2024-07-14 22:59:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 22:59:07 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.808 | nll_loss 4.538 | ppl 23.23 | wps 43511 | wpb 2588.8 | bsz 75.3 | num_updates 83000 | best_loss 12.174
2024-07-14 22:59:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 22:59:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_83000.pt (epoch 1 @ 83000 updates, score 5.808) (writing took 6.907361504621804 seconds)
2024-07-14 22:59:37 | INFO | train_inner | epoch 001:  83100 / 150053 loss=5.212, nll_loss=3.926, ppl=15.2, wps=10559.9, ups=3.04, wpb=3476.9, bsz=101, num_updates=83100, lr=0.000109698, gnorm=1.053, train_wall=23, wall=0
2024-07-14 23:00:00 | INFO | train_inner | epoch 001:  83200 / 150053 loss=5.245, nll_loss=3.964, ppl=15.6, wps=15205.6, ups=4.3, wpb=3535.7, bsz=94, num_updates=83200, lr=0.000109632, gnorm=1.058, train_wall=23, wall=0
2024-07-14 23:00:23 | INFO | train_inner | epoch 001:  83300 / 150053 loss=5.211, nll_loss=3.925, ppl=15.19, wps=15339.2, ups=4.29, wpb=3572.5, bsz=113.9, num_updates=83300, lr=0.000109566, gnorm=1.07, train_wall=23, wall=0
2024-07-14 23:00:46 | INFO | train_inner | epoch 001:  83400 / 150053 loss=5.175, nll_loss=3.884, ppl=14.77, wps=15170, ups=4.35, wpb=3489.4, bsz=93.5, num_updates=83400, lr=0.000109501, gnorm=1.037, train_wall=23, wall=0
2024-07-14 23:01:09 | INFO | train_inner | epoch 001:  83500 / 150053 loss=5.211, nll_loss=3.925, ppl=15.19, wps=15394.1, ups=4.36, wpb=3533.7, bsz=100.2, num_updates=83500, lr=0.000109435, gnorm=1.053, train_wall=23, wall=0
2024-07-14 23:01:33 | INFO | train_inner | epoch 001:  83600 / 150053 loss=5.188, nll_loss=3.899, ppl=14.92, wps=15276.9, ups=4.31, wpb=3541.8, bsz=92.6, num_updates=83600, lr=0.00010937, gnorm=1.018, train_wall=23, wall=0
2024-07-14 23:01:56 | INFO | train_inner | epoch 001:  83700 / 150053 loss=5.191, nll_loss=3.902, ppl=14.95, wps=15195, ups=4.31, wpb=3523.6, bsz=90.2, num_updates=83700, lr=0.000109304, gnorm=1.059, train_wall=23, wall=0
2024-07-14 23:02:19 | INFO | train_inner | epoch 001:  83800 / 150053 loss=5.122, nll_loss=3.823, ppl=14.15, wps=15392.2, ups=4.27, wpb=3608, bsz=102.2, num_updates=83800, lr=0.000109239, gnorm=1.004, train_wall=23, wall=0
2024-07-14 23:02:43 | INFO | train_inner | epoch 001:  83900 / 150053 loss=5.206, nll_loss=3.92, ppl=15.14, wps=15302.8, ups=4.29, wpb=3570.9, bsz=93.4, num_updates=83900, lr=0.000109174, gnorm=1.053, train_wall=23, wall=0
2024-07-14 23:03:06 | INFO | train_inner | epoch 001:  84000 / 150053 loss=5.267, nll_loss=3.989, ppl=15.87, wps=15349, ups=4.3, wpb=3567.8, bsz=85.8, num_updates=84000, lr=0.000109109, gnorm=1.055, train_wall=23, wall=0
2024-07-14 23:03:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 23:03:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.823 | nll_loss 4.547 | ppl 23.37 | wps 43348.2 | wpb 2588.8 | bsz 75.3 | num_updates 84000 | best_loss 12.174
2024-07-14 23:03:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 23:03:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_84000.pt (epoch 1 @ 84000 updates, score 5.823) (writing took 7.949774279259145 seconds)
2024-07-14 23:03:40 | INFO | train_inner | epoch 001:  84100 / 150053 loss=5.269, nll_loss=3.992, ppl=15.91, wps=10384.6, ups=2.95, wpb=3514.4, bsz=95.3, num_updates=84100, lr=0.000109044, gnorm=1.061, train_wall=23, wall=0
2024-07-14 23:04:03 | INFO | train_inner | epoch 001:  84200 / 150053 loss=5.238, nll_loss=3.956, ppl=15.52, wps=15353.3, ups=4.29, wpb=3576.7, bsz=92.9, num_updates=84200, lr=0.000108979, gnorm=1.038, train_wall=23, wall=0
2024-07-14 23:04:26 | INFO | train_inner | epoch 001:  84300 / 150053 loss=5.16, nll_loss=3.866, ppl=14.58, wps=15420.7, ups=4.29, wpb=3598.4, bsz=100.6, num_updates=84300, lr=0.000108915, gnorm=1.009, train_wall=23, wall=0
2024-07-14 23:04:50 | INFO | train_inner | epoch 001:  84400 / 150053 loss=5.137, nll_loss=3.841, ppl=14.33, wps=15099.5, ups=4.27, wpb=3537.2, bsz=104.3, num_updates=84400, lr=0.00010885, gnorm=1.053, train_wall=23, wall=0
2024-07-14 23:05:13 | INFO | train_inner | epoch 001:  84500 / 150053 loss=5.141, nll_loss=3.845, ppl=14.37, wps=15123.3, ups=4.26, wpb=3546.1, bsz=101.3, num_updates=84500, lr=0.000108786, gnorm=1.058, train_wall=23, wall=0
2024-07-14 23:05:36 | INFO | train_inner | epoch 001:  84600 / 150053 loss=5.179, nll_loss=3.889, ppl=14.81, wps=15199.7, ups=4.28, wpb=3551.5, bsz=99.6, num_updates=84600, lr=0.000108721, gnorm=1.038, train_wall=23, wall=0
2024-07-14 23:06:00 | INFO | train_inner | epoch 001:  84700 / 150053 loss=5.146, nll_loss=3.851, ppl=14.43, wps=15547.4, ups=4.28, wpb=3633.2, bsz=106.9, num_updates=84700, lr=0.000108657, gnorm=1.036, train_wall=23, wall=0
2024-07-14 23:06:23 | INFO | train_inner | epoch 001:  84800 / 150053 loss=5.098, nll_loss=3.797, ppl=13.9, wps=15399.1, ups=4.25, wpb=3619.9, bsz=106.9, num_updates=84800, lr=0.000108593, gnorm=1.028, train_wall=23, wall=0
2024-07-14 23:06:46 | INFO | train_inner | epoch 001:  84900 / 150053 loss=5.15, nll_loss=3.855, ppl=14.47, wps=15277.1, ups=4.33, wpb=3526.4, bsz=113.2, num_updates=84900, lr=0.000108529, gnorm=1.078, train_wall=23, wall=0
2024-07-14 23:07:09 | INFO | train_inner | epoch 001:  85000 / 150053 loss=5.085, nll_loss=3.782, ppl=13.76, wps=15066.7, ups=4.34, wpb=3475.2, bsz=113.9, num_updates=85000, lr=0.000108465, gnorm=1.036, train_wall=23, wall=0
2024-07-14 23:07:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 23:07:12 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.821 | nll_loss 4.54 | ppl 23.26 | wps 43570.9 | wpb 2588.8 | bsz 75.3 | num_updates 85000 | best_loss 12.174
2024-07-14 23:07:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 23:07:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_85000.pt (epoch 1 @ 85000 updates, score 5.821) (writing took 8.359248012304306 seconds)
2024-07-14 23:07:44 | INFO | train_inner | epoch 001:  85100 / 150053 loss=5.161, nll_loss=3.868, ppl=14.6, wps=10034.8, ups=2.92, wpb=3437, bsz=97.4, num_updates=85100, lr=0.000108401, gnorm=1.045, train_wall=23, wall=0
2024-07-14 23:08:07 | INFO | train_inner | epoch 001:  85200 / 150053 loss=5.215, nll_loss=3.93, ppl=15.24, wps=15517.7, ups=4.33, wpb=3582.5, bsz=93.3, num_updates=85200, lr=0.000108338, gnorm=1.026, train_wall=23, wall=0
2024-07-14 23:08:30 | INFO | train_inner | epoch 001:  85300 / 150053 loss=5.167, nll_loss=3.874, ppl=14.66, wps=15350.5, ups=4.3, wpb=3567.5, bsz=114.7, num_updates=85300, lr=0.000108274, gnorm=1.072, train_wall=23, wall=0
2024-07-14 23:08:53 | INFO | train_inner | epoch 001:  85400 / 150053 loss=5.12, nll_loss=3.822, ppl=14.14, wps=15318.4, ups=4.3, wpb=3565.5, bsz=122.1, num_updates=85400, lr=0.000108211, gnorm=1.096, train_wall=23, wall=0
2024-07-14 23:09:17 | INFO | train_inner | epoch 001:  85500 / 150053 loss=5.139, nll_loss=3.842, ppl=14.34, wps=15351.7, ups=4.27, wpb=3594.9, bsz=107.9, num_updates=85500, lr=0.000108148, gnorm=1.025, train_wall=23, wall=0
2024-07-14 23:09:40 | INFO | train_inner | epoch 001:  85600 / 150053 loss=5.12, nll_loss=3.822, ppl=14.14, wps=15352.4, ups=4.32, wpb=3551.7, bsz=121, num_updates=85600, lr=0.000108084, gnorm=1.065, train_wall=23, wall=0
2024-07-14 23:10:03 | INFO | train_inner | epoch 001:  85700 / 150053 loss=5.164, nll_loss=3.872, ppl=14.64, wps=15163.9, ups=4.33, wpb=3505.8, bsz=102.2, num_updates=85700, lr=0.000108021, gnorm=1.041, train_wall=23, wall=0
2024-07-14 23:10:26 | INFO | train_inner | epoch 001:  85800 / 150053 loss=5.184, nll_loss=3.893, ppl=14.86, wps=15222.7, ups=4.3, wpb=3539.3, bsz=97.9, num_updates=85800, lr=0.000107958, gnorm=1.041, train_wall=23, wall=0
2024-07-14 23:10:49 | INFO | train_inner | epoch 001:  85900 / 150053 loss=5.099, nll_loss=3.798, ppl=13.91, wps=15324.7, ups=4.33, wpb=3536.3, bsz=107.4, num_updates=85900, lr=0.000107896, gnorm=1.057, train_wall=23, wall=0
2024-07-14 23:11:13 | INFO | train_inner | epoch 001:  86000 / 150053 loss=5.16, nll_loss=3.867, ppl=14.59, wps=15051.3, ups=4.27, wpb=3521.7, bsz=110.3, num_updates=86000, lr=0.000107833, gnorm=1.045, train_wall=23, wall=0
2024-07-14 23:11:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 23:11:15 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.817 | nll_loss 4.538 | ppl 23.22 | wps 43355.5 | wpb 2588.8 | bsz 75.3 | num_updates 86000 | best_loss 12.174
2024-07-14 23:11:15 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 23:11:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_86000.pt (epoch 1 @ 86000 updates, score 5.817) (writing took 7.993310501798987 seconds)
2024-07-14 23:11:47 | INFO | train_inner | epoch 001:  86100 / 150053 loss=5.12, nll_loss=3.822, ppl=14.14, wps=10494.2, ups=2.94, wpb=3571.8, bsz=104.6, num_updates=86100, lr=0.00010777, gnorm=1.027, train_wall=23, wall=0
2024-07-14 23:12:10 | INFO | train_inner | epoch 001:  86200 / 150053 loss=5.105, nll_loss=3.805, ppl=13.97, wps=15127.9, ups=4.27, wpb=3544.7, bsz=112.6, num_updates=86200, lr=0.000107708, gnorm=1.035, train_wall=23, wall=0
2024-07-14 23:12:33 | INFO | train_inner | epoch 001:  86300 / 150053 loss=5.255, nll_loss=3.975, ppl=15.72, wps=15189.2, ups=4.34, wpb=3503.5, bsz=91.4, num_updates=86300, lr=0.000107645, gnorm=1.067, train_wall=23, wall=0
2024-07-14 23:12:57 | INFO | train_inner | epoch 001:  86400 / 150053 loss=5.139, nll_loss=3.844, ppl=14.36, wps=15336.3, ups=4.27, wpb=3589.6, bsz=106.6, num_updates=86400, lr=0.000107583, gnorm=1.027, train_wall=23, wall=0
2024-07-14 23:13:20 | INFO | train_inner | epoch 001:  86500 / 150053 loss=5.204, nll_loss=3.917, ppl=15.1, wps=15454, ups=4.37, wpb=3539.3, bsz=91.7, num_updates=86500, lr=0.000107521, gnorm=1.046, train_wall=23, wall=0
2024-07-14 23:13:43 | INFO | train_inner | epoch 001:  86600 / 150053 loss=5.092, nll_loss=3.789, ppl=13.83, wps=15313.4, ups=4.28, wpb=3575.7, bsz=114.6, num_updates=86600, lr=0.000107459, gnorm=1.019, train_wall=23, wall=0
2024-07-14 23:14:06 | INFO | train_inner | epoch 001:  86700 / 150053 loss=5.166, nll_loss=3.874, ppl=14.66, wps=14803.9, ups=4.3, wpb=3441.2, bsz=94.2, num_updates=86700, lr=0.000107397, gnorm=1.064, train_wall=23, wall=0
2024-07-14 23:14:29 | INFO | train_inner | epoch 001:  86800 / 150053 loss=5.274, nll_loss=3.997, ppl=15.96, wps=15409.6, ups=4.37, wpb=3523.1, bsz=84.6, num_updates=86800, lr=0.000107335, gnorm=1.041, train_wall=23, wall=0
2024-07-14 23:14:53 | INFO | train_inner | epoch 001:  86900 / 150053 loss=5.231, nll_loss=3.948, ppl=15.43, wps=15252.3, ups=4.25, wpb=3586.7, bsz=93, num_updates=86900, lr=0.000107273, gnorm=1.047, train_wall=23, wall=0
2024-07-14 23:15:16 | INFO | train_inner | epoch 001:  87000 / 150053 loss=5.101, nll_loss=3.8, ppl=13.93, wps=15288, ups=4.31, wpb=3543.5, bsz=106, num_updates=87000, lr=0.000107211, gnorm=1.037, train_wall=23, wall=0
2024-07-14 23:15:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 23:15:18 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.798 | nll_loss 4.519 | ppl 22.92 | wps 43465.2 | wpb 2588.8 | bsz 75.3 | num_updates 87000 | best_loss 12.174
2024-07-14 23:15:18 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 23:15:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_87000.pt (epoch 1 @ 87000 updates, score 5.798) (writing took 5.581291011534631 seconds)
2024-07-14 23:15:47 | INFO | train_inner | epoch 001:  87100 / 150053 loss=5.25, nll_loss=3.97, ppl=15.67, wps=10754.5, ups=3.22, wpb=3341.4, bsz=86.4, num_updates=87100, lr=0.00010715, gnorm=1.1, train_wall=23, wall=0
2024-07-14 23:16:10 | INFO | train_inner | epoch 001:  87200 / 150053 loss=5.179, nll_loss=3.889, ppl=14.82, wps=15337.5, ups=4.34, wpb=3533.9, bsz=105.5, num_updates=87200, lr=0.000107088, gnorm=1.054, train_wall=23, wall=0
2024-07-14 23:16:33 | INFO | train_inner | epoch 001:  87300 / 150053 loss=5.142, nll_loss=3.847, ppl=14.39, wps=15136.6, ups=4.35, wpb=3481.5, bsz=99.5, num_updates=87300, lr=0.000107027, gnorm=1.069, train_wall=23, wall=0
2024-07-14 23:16:56 | INFO | train_inner | epoch 001:  87400 / 150053 loss=5.129, nll_loss=3.832, ppl=14.24, wps=15345.4, ups=4.3, wpb=3569.5, bsz=102.2, num_updates=87400, lr=0.000106966, gnorm=1.032, train_wall=23, wall=0
2024-07-14 23:17:19 | INFO | train_inner | epoch 001:  87500 / 150053 loss=5.112, nll_loss=3.811, ppl=14.04, wps=15497.4, ups=4.29, wpb=3611.5, bsz=114.7, num_updates=87500, lr=0.000106904, gnorm=1.039, train_wall=23, wall=0
2024-07-14 23:17:42 | INFO | train_inner | epoch 001:  87600 / 150053 loss=5.224, nll_loss=3.94, ppl=15.34, wps=15602.9, ups=4.35, wpb=3590.2, bsz=91.8, num_updates=87600, lr=0.000106843, gnorm=1.039, train_wall=23, wall=0
2024-07-14 23:18:06 | INFO | train_inner | epoch 001:  87700 / 150053 loss=5.055, nll_loss=3.748, ppl=13.43, wps=15276.8, ups=4.27, wpb=3581.4, bsz=113.7, num_updates=87700, lr=0.000106783, gnorm=1.023, train_wall=23, wall=0
2024-07-14 23:18:29 | INFO | train_inner | epoch 001:  87800 / 150053 loss=5.156, nll_loss=3.861, ppl=14.53, wps=15586.4, ups=4.39, wpb=3552, bsz=98.7, num_updates=87800, lr=0.000106722, gnorm=1.049, train_wall=23, wall=0
2024-07-14 23:18:51 | INFO | train_inner | epoch 001:  87900 / 150053 loss=5.23, nll_loss=3.947, ppl=15.43, wps=15278.5, ups=4.42, wpb=3454.9, bsz=90.6, num_updates=87900, lr=0.000106661, gnorm=1.068, train_wall=22, wall=0
2024-07-14 23:19:15 | INFO | train_inner | epoch 001:  88000 / 150053 loss=5.079, nll_loss=3.775, ppl=13.69, wps=15024.7, ups=4.25, wpb=3533.2, bsz=108.4, num_updates=88000, lr=0.0001066, gnorm=1.062, train_wall=23, wall=0
2024-07-14 23:19:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 23:19:18 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.779 | nll_loss 4.496 | ppl 22.57 | wps 43332.1 | wpb 2588.8 | bsz 75.3 | num_updates 88000 | best_loss 12.174
2024-07-14 23:19:18 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 23:19:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_88000.pt (epoch 1 @ 88000 updates, score 5.779) (writing took 8.738131538964808 seconds)
2024-07-14 23:19:49 | INFO | train_inner | epoch 001:  88100 / 150053 loss=5.162, nll_loss=3.868, ppl=14.61, wps=10134.8, ups=2.91, wpb=3487.7, bsz=99.3, num_updates=88100, lr=0.00010654, gnorm=1.078, train_wall=23, wall=0
2024-07-14 23:20:12 | INFO | train_inner | epoch 001:  88200 / 150053 loss=5.149, nll_loss=3.855, ppl=14.47, wps=15054.1, ups=4.31, wpb=3494.9, bsz=106.1, num_updates=88200, lr=0.000106479, gnorm=1.064, train_wall=23, wall=0
2024-07-14 23:20:36 | INFO | train_inner | epoch 001:  88300 / 150053 loss=5.153, nll_loss=3.859, ppl=14.51, wps=15362.2, ups=4.31, wpb=3562.5, bsz=100.4, num_updates=88300, lr=0.000106419, gnorm=1.048, train_wall=23, wall=0
2024-07-14 23:20:59 | INFO | train_inner | epoch 001:  88400 / 150053 loss=5.186, nll_loss=3.896, ppl=14.89, wps=15418.9, ups=4.37, wpb=3528.3, bsz=96.4, num_updates=88400, lr=0.000106359, gnorm=1.042, train_wall=23, wall=0
2024-07-14 23:21:22 | INFO | train_inner | epoch 001:  88500 / 150053 loss=5.202, nll_loss=3.915, ppl=15.09, wps=15191.9, ups=4.32, wpb=3518.1, bsz=94.2, num_updates=88500, lr=0.000106299, gnorm=1.065, train_wall=23, wall=0
2024-07-14 23:21:45 | INFO | train_inner | epoch 001:  88600 / 150053 loss=5.222, nll_loss=3.938, ppl=15.33, wps=15299.2, ups=4.32, wpb=3541.1, bsz=87.2, num_updates=88600, lr=0.000106239, gnorm=1.047, train_wall=23, wall=0
2024-07-14 23:22:08 | INFO | train_inner | epoch 001:  88700 / 150053 loss=5.064, nll_loss=3.759, ppl=13.53, wps=15099.6, ups=4.26, wpb=3544.6, bsz=123.2, num_updates=88700, lr=0.000106179, gnorm=1.056, train_wall=23, wall=0
2024-07-14 23:22:31 | INFO | train_inner | epoch 001:  88800 / 150053 loss=5.166, nll_loss=3.875, ppl=14.67, wps=15237.5, ups=4.31, wpb=3534.4, bsz=107.5, num_updates=88800, lr=0.000106119, gnorm=1.075, train_wall=23, wall=0
2024-07-14 23:22:55 | INFO | train_inner | epoch 001:  88900 / 150053 loss=5.121, nll_loss=3.822, ppl=14.14, wps=15221.9, ups=4.31, wpb=3531.9, bsz=100, num_updates=88900, lr=0.000106059, gnorm=1.012, train_wall=23, wall=0
2024-07-14 23:23:18 | INFO | train_inner | epoch 001:  89000 / 150053 loss=5.163, nll_loss=3.87, ppl=14.62, wps=15194.3, ups=4.26, wpb=3568, bsz=99.8, num_updates=89000, lr=0.000106, gnorm=1.054, train_wall=23, wall=0
2024-07-14 23:23:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 23:23:21 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.877 | nll_loss 4.622 | ppl 24.62 | wps 42751.7 | wpb 2588.8 | bsz 75.3 | num_updates 89000 | best_loss 12.174
2024-07-14 23:23:21 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 23:23:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_89000.pt (epoch 1 @ 89000 updates, score 5.877) (writing took 6.926646146923304 seconds)
2024-07-14 23:23:51 | INFO | train_inner | epoch 001:  89100 / 150053 loss=5.171, nll_loss=3.88, ppl=14.73, wps=10551.4, ups=3.03, wpb=3483.9, bsz=113.1, num_updates=89100, lr=0.00010594, gnorm=1.078, train_wall=23, wall=0
2024-07-14 23:24:15 | INFO | train_inner | epoch 001:  89200 / 150053 loss=5.204, nll_loss=3.917, ppl=15.11, wps=15167.8, ups=4.28, wpb=3546.7, bsz=90.2, num_updates=89200, lr=0.000105881, gnorm=1.038, train_wall=23, wall=0
2024-07-14 23:24:38 | INFO | train_inner | epoch 001:  89300 / 150053 loss=5.125, nll_loss=3.827, ppl=14.19, wps=15325.8, ups=4.3, wpb=3562.7, bsz=106.8, num_updates=89300, lr=0.000105822, gnorm=1.04, train_wall=23, wall=0
2024-07-14 23:25:01 | INFO | train_inner | epoch 001:  89400 / 150053 loss=5.236, nll_loss=3.952, ppl=15.48, wps=15293.3, ups=4.28, wpb=3569.9, bsz=84.1, num_updates=89400, lr=0.000105762, gnorm=1.034, train_wall=23, wall=0
2024-07-14 23:25:24 | INFO | train_inner | epoch 001:  89500 / 150053 loss=5.111, nll_loss=3.811, ppl=14.03, wps=15292.1, ups=4.34, wpb=3523, bsz=125, num_updates=89500, lr=0.000105703, gnorm=1.096, train_wall=23, wall=0
2024-07-14 23:25:47 | INFO | train_inner | epoch 001:  89600 / 150053 loss=5.123, nll_loss=3.824, ppl=14.16, wps=15563.6, ups=4.32, wpb=3599.4, bsz=118.8, num_updates=89600, lr=0.000105644, gnorm=1.038, train_wall=23, wall=0
2024-07-14 23:26:11 | INFO | train_inner | epoch 001:  89700 / 150053 loss=5.109, nll_loss=3.809, ppl=14.02, wps=15566.9, ups=4.3, wpb=3616.9, bsz=113.1, num_updates=89700, lr=0.000105585, gnorm=1.059, train_wall=23, wall=0
2024-07-14 23:26:34 | INFO | train_inner | epoch 001:  89800 / 150053 loss=5.039, nll_loss=3.729, ppl=13.26, wps=15422.1, ups=4.28, wpb=3601.5, bsz=111.7, num_updates=89800, lr=0.000105527, gnorm=1.043, train_wall=23, wall=0
2024-07-14 23:26:57 | INFO | train_inner | epoch 001:  89900 / 150053 loss=5.187, nll_loss=3.898, ppl=14.9, wps=15302.6, ups=4.33, wpb=3534.7, bsz=97.5, num_updates=89900, lr=0.000105468, gnorm=1.05, train_wall=23, wall=0
2024-07-14 23:27:20 | INFO | train_inner | epoch 001:  90000 / 150053 loss=5.139, nll_loss=3.843, ppl=14.35, wps=15181.3, ups=4.27, wpb=3555.9, bsz=102.2, num_updates=90000, lr=0.000105409, gnorm=1.035, train_wall=23, wall=0
2024-07-14 23:27:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 23:27:23 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.77 | nll_loss 4.494 | ppl 22.53 | wps 43347.2 | wpb 2588.8 | bsz 75.3 | num_updates 90000 | best_loss 12.174
2024-07-14 23:27:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 23:27:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_90000.pt (epoch 1 @ 90000 updates, score 5.77) (writing took 7.055072451010346 seconds)
2024-07-14 23:27:53 | INFO | train_inner | epoch 001:  90100 / 150053 loss=5.134, nll_loss=3.838, ppl=14.3, wps=10761.2, ups=3.03, wpb=3550.8, bsz=102.5, num_updates=90100, lr=0.000105351, gnorm=1.046, train_wall=23, wall=0
2024-07-14 23:28:17 | INFO | train_inner | epoch 001:  90200 / 150053 loss=5.184, nll_loss=3.895, ppl=14.87, wps=15190.6, ups=4.32, wpb=3517.5, bsz=92.8, num_updates=90200, lr=0.000105292, gnorm=1.027, train_wall=23, wall=0
2024-07-14 23:28:40 | INFO | train_inner | epoch 001:  90300 / 150053 loss=5.092, nll_loss=3.79, ppl=13.83, wps=15113.3, ups=4.3, wpb=3512.4, bsz=117.6, num_updates=90300, lr=0.000105234, gnorm=1.066, train_wall=23, wall=0
2024-07-14 23:29:03 | INFO | train_inner | epoch 001:  90400 / 150053 loss=5.144, nll_loss=3.849, ppl=14.41, wps=15149.4, ups=4.32, wpb=3507.5, bsz=98.2, num_updates=90400, lr=0.000105176, gnorm=1.085, train_wall=23, wall=0
2024-07-14 23:29:26 | INFO | train_inner | epoch 001:  90500 / 150053 loss=5.196, nll_loss=3.908, ppl=15.01, wps=15280, ups=4.31, wpb=3545.4, bsz=88.2, num_updates=90500, lr=0.000105118, gnorm=1.026, train_wall=23, wall=0
2024-07-14 23:29:49 | INFO | train_inner | epoch 001:  90600 / 150053 loss=5.158, nll_loss=3.864, ppl=14.56, wps=15336.3, ups=4.32, wpb=3551, bsz=107, num_updates=90600, lr=0.00010506, gnorm=1.101, train_wall=23, wall=0
2024-07-14 23:30:12 | INFO | train_inner | epoch 001:  90700 / 150053 loss=5.202, nll_loss=3.915, ppl=15.09, wps=14950.2, ups=4.37, wpb=3419.7, bsz=103.4, num_updates=90700, lr=0.000105002, gnorm=1.166, train_wall=23, wall=0
2024-07-14 23:30:35 | INFO | train_inner | epoch 001:  90800 / 150053 loss=5.075, nll_loss=3.771, ppl=13.65, wps=15178.6, ups=4.32, wpb=3514.7, bsz=101.2, num_updates=90800, lr=0.000104944, gnorm=1.058, train_wall=23, wall=0
2024-07-14 23:30:59 | INFO | train_inner | epoch 001:  90900 / 150053 loss=5.119, nll_loss=3.82, ppl=14.13, wps=15031.7, ups=4.28, wpb=3514.3, bsz=110.8, num_updates=90900, lr=0.000104886, gnorm=1.053, train_wall=23, wall=0
2024-07-14 23:31:22 | INFO | train_inner | epoch 001:  91000 / 150053 loss=5.12, nll_loss=3.822, ppl=14.14, wps=15273.2, ups=4.33, wpb=3528.6, bsz=102.2, num_updates=91000, lr=0.000104828, gnorm=1.06, train_wall=23, wall=0
2024-07-14 23:31:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 23:31:25 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.809 | nll_loss 4.525 | ppl 23.02 | wps 43587.4 | wpb 2588.8 | bsz 75.3 | num_updates 91000 | best_loss 12.174
2024-07-14 23:31:25 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 23:31:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_91000.pt (epoch 1 @ 91000 updates, score 5.809) (writing took 6.483818672597408 seconds)
2024-07-14 23:31:55 | INFO | train_inner | epoch 001:  91100 / 150053 loss=5.164, nll_loss=3.872, ppl=14.64, wps=10994.8, ups=3.06, wpb=3590.7, bsz=96.6, num_updates=91100, lr=0.000104771, gnorm=1.025, train_wall=23, wall=0
2024-07-14 23:32:18 | INFO | train_inner | epoch 001:  91200 / 150053 loss=5.065, nll_loss=3.76, ppl=13.54, wps=15068.8, ups=4.31, wpb=3494.5, bsz=107.4, num_updates=91200, lr=0.000104713, gnorm=1.03, train_wall=23, wall=0
2024-07-14 23:32:41 | INFO | train_inner | epoch 001:  91300 / 150053 loss=5.089, nll_loss=3.786, ppl=13.8, wps=15216.9, ups=4.28, wpb=3555.8, bsz=110.3, num_updates=91300, lr=0.000104656, gnorm=1.036, train_wall=23, wall=0
2024-07-14 23:33:04 | INFO | train_inner | epoch 001:  91400 / 150053 loss=5.186, nll_loss=3.897, ppl=14.9, wps=15043.6, ups=4.31, wpb=3494.2, bsz=97.4, num_updates=91400, lr=0.000104599, gnorm=1.067, train_wall=23, wall=0
2024-07-14 23:33:28 | INFO | train_inner | epoch 001:  91500 / 150053 loss=5.066, nll_loss=3.76, ppl=13.55, wps=15343, ups=4.27, wpb=3593.6, bsz=105.8, num_updates=91500, lr=0.000104542, gnorm=1.019, train_wall=23, wall=0
2024-07-14 23:33:51 | INFO | train_inner | epoch 001:  91600 / 150053 loss=5.099, nll_loss=3.797, ppl=13.9, wps=15359.9, ups=4.27, wpb=3599.1, bsz=104.6, num_updates=91600, lr=0.000104485, gnorm=1.048, train_wall=23, wall=0
2024-07-14 23:34:14 | INFO | train_inner | epoch 001:  91700 / 150053 loss=5.133, nll_loss=3.836, ppl=14.28, wps=15018.7, ups=4.32, wpb=3479.1, bsz=102.8, num_updates=91700, lr=0.000104428, gnorm=1.07, train_wall=23, wall=0
2024-07-14 23:34:37 | INFO | train_inner | epoch 001:  91800 / 150053 loss=5.106, nll_loss=3.806, ppl=13.99, wps=15388.9, ups=4.33, wpb=3553.7, bsz=109, num_updates=91800, lr=0.000104371, gnorm=1.051, train_wall=23, wall=0
2024-07-14 23:35:00 | INFO | train_inner | epoch 001:  91900 / 150053 loss=5.161, nll_loss=3.868, ppl=14.6, wps=15205.7, ups=4.35, wpb=3493.8, bsz=102, num_updates=91900, lr=0.000104314, gnorm=1.072, train_wall=23, wall=0
2024-07-14 23:35:24 | INFO | train_inner | epoch 001:  92000 / 150053 loss=5.098, nll_loss=3.797, ppl=13.9, wps=15145.1, ups=4.27, wpb=3546.9, bsz=120, num_updates=92000, lr=0.000104257, gnorm=1.061, train_wall=23, wall=0
2024-07-14 23:35:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 23:35:27 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.78 | nll_loss 4.502 | ppl 22.66 | wps 43397.3 | wpb 2588.8 | bsz 75.3 | num_updates 92000 | best_loss 12.174
2024-07-14 23:35:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 23:35:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_92000.pt (epoch 1 @ 92000 updates, score 5.78) (writing took 7.050405162386596 seconds)
2024-07-14 23:35:57 | INFO | train_inner | epoch 001:  92100 / 150053 loss=5.166, nll_loss=3.875, ppl=14.67, wps=10543.2, ups=3.04, wpb=3471, bsz=94.2, num_updates=92100, lr=0.000104201, gnorm=1.063, train_wall=23, wall=0
2024-07-14 23:36:20 | INFO | train_inner | epoch 001:  92200 / 150053 loss=5.144, nll_loss=3.849, ppl=14.41, wps=15317.6, ups=4.33, wpb=3537.6, bsz=98.2, num_updates=92200, lr=0.000104144, gnorm=1.048, train_wall=23, wall=0
2024-07-14 23:36:43 | INFO | train_inner | epoch 001:  92300 / 150053 loss=5.184, nll_loss=3.894, ppl=14.87, wps=14989.6, ups=4.32, wpb=3465.9, bsz=107, num_updates=92300, lr=0.000104088, gnorm=1.064, train_wall=23, wall=0
2024-07-14 23:37:06 | INFO | train_inner | epoch 001:  92400 / 150053 loss=5.17, nll_loss=3.878, ppl=14.71, wps=15278.8, ups=4.42, wpb=3455.6, bsz=96.4, num_updates=92400, lr=0.000104031, gnorm=1.075, train_wall=22, wall=0
2024-07-14 23:37:29 | INFO | train_inner | epoch 001:  92500 / 150053 loss=5.162, nll_loss=3.87, ppl=14.62, wps=15379.2, ups=4.31, wpb=3565.4, bsz=99.5, num_updates=92500, lr=0.000103975, gnorm=1.102, train_wall=23, wall=0
2024-07-14 23:37:52 | INFO | train_inner | epoch 001:  92600 / 150053 loss=5.192, nll_loss=3.903, ppl=14.96, wps=15133.2, ups=4.3, wpb=3520.3, bsz=92.2, num_updates=92600, lr=0.000103919, gnorm=1.052, train_wall=23, wall=0
2024-07-14 23:38:15 | INFO | train_inner | epoch 001:  92700 / 150053 loss=5.147, nll_loss=3.851, ppl=14.43, wps=15439.6, ups=4.38, wpb=3527.3, bsz=101.7, num_updates=92700, lr=0.000103863, gnorm=1.056, train_wall=23, wall=0
2024-07-14 23:38:38 | INFO | train_inner | epoch 001:  92800 / 150053 loss=5.131, nll_loss=3.833, ppl=14.25, wps=15328.5, ups=4.31, wpb=3560.1, bsz=110.4, num_updates=92800, lr=0.000103807, gnorm=1.057, train_wall=23, wall=0
2024-07-14 23:39:01 | INFO | train_inner | epoch 001:  92900 / 150053 loss=5.134, nll_loss=3.838, ppl=14.3, wps=15125, ups=4.32, wpb=3502.7, bsz=94.6, num_updates=92900, lr=0.000103751, gnorm=1.063, train_wall=23, wall=0
2024-07-14 23:39:24 | INFO | train_inner | epoch 001:  93000 / 150053 loss=5.081, nll_loss=3.777, ppl=13.71, wps=15150.7, ups=4.32, wpb=3509.7, bsz=105.1, num_updates=93000, lr=0.000103695, gnorm=1.045, train_wall=23, wall=0
2024-07-14 23:39:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 23:39:27 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.791 | nll_loss 4.509 | ppl 22.77 | wps 43365.8 | wpb 2588.8 | bsz 75.3 | num_updates 93000 | best_loss 12.174
2024-07-14 23:39:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 23:39:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_93000.pt (epoch 1 @ 93000 updates, score 5.791) (writing took 6.774518176913261 seconds)
2024-07-14 23:39:57 | INFO | train_inner | epoch 001:  93100 / 150053 loss=5.154, nll_loss=3.861, ppl=14.53, wps=10793.9, ups=3.04, wpb=3547.1, bsz=101.1, num_updates=93100, lr=0.000103639, gnorm=1.064, train_wall=23, wall=0
2024-07-14 23:40:21 | INFO | train_inner | epoch 001:  93200 / 150053 loss=5.121, nll_loss=3.822, ppl=14.14, wps=15012.5, ups=4.26, wpb=3525.3, bsz=96.2, num_updates=93200, lr=0.000103584, gnorm=1.044, train_wall=23, wall=0
2024-07-14 23:40:44 | INFO | train_inner | epoch 001:  93300 / 150053 loss=5.127, nll_loss=3.829, ppl=14.21, wps=15392.1, ups=4.27, wpb=3601.9, bsz=107.1, num_updates=93300, lr=0.000103528, gnorm=1.056, train_wall=23, wall=0
2024-07-14 23:41:07 | INFO | train_inner | epoch 001:  93400 / 150053 loss=5.115, nll_loss=3.816, ppl=14.08, wps=15181.7, ups=4.32, wpb=3514, bsz=103.8, num_updates=93400, lr=0.000103473, gnorm=1.058, train_wall=23, wall=0
2024-07-14 23:41:30 | INFO | train_inner | epoch 001:  93500 / 150053 loss=5.191, nll_loss=3.903, ppl=14.96, wps=15076.4, ups=4.34, wpb=3474.7, bsz=94.8, num_updates=93500, lr=0.000103418, gnorm=1.076, train_wall=23, wall=0
2024-07-14 23:41:54 | INFO | train_inner | epoch 001:  93600 / 150053 loss=5.239, nll_loss=3.957, ppl=15.53, wps=15220.9, ups=4.31, wpb=3529.8, bsz=86, num_updates=93600, lr=0.000103362, gnorm=1.049, train_wall=23, wall=0
2024-07-14 23:42:17 | INFO | train_inner | epoch 001:  93700 / 150053 loss=5.11, nll_loss=3.81, ppl=14.03, wps=15438.5, ups=4.29, wpb=3595.6, bsz=111.4, num_updates=93700, lr=0.000103307, gnorm=1.053, train_wall=23, wall=0
2024-07-14 23:42:40 | INFO | train_inner | epoch 001:  93800 / 150053 loss=5.165, nll_loss=3.873, ppl=14.65, wps=15399.6, ups=4.31, wpb=3576.8, bsz=92.5, num_updates=93800, lr=0.000103252, gnorm=1.023, train_wall=23, wall=0
2024-07-14 23:43:03 | INFO | train_inner | epoch 001:  93900 / 150053 loss=5.132, nll_loss=3.835, ppl=14.27, wps=15353.1, ups=4.31, wpb=3564, bsz=101, num_updates=93900, lr=0.000103197, gnorm=1.046, train_wall=23, wall=0
2024-07-14 23:43:26 | INFO | train_inner | epoch 001:  94000 / 150053 loss=5.1, nll_loss=3.798, ppl=13.91, wps=15485.7, ups=4.37, wpb=3543.4, bsz=109.1, num_updates=94000, lr=0.000103142, gnorm=1.049, train_wall=23, wall=0
2024-07-14 23:43:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 23:43:29 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.762 | nll_loss 4.477 | ppl 22.26 | wps 43418.6 | wpb 2588.8 | bsz 75.3 | num_updates 94000 | best_loss 12.174
2024-07-14 23:43:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 23:43:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_94000.pt (epoch 1 @ 94000 updates, score 5.762) (writing took 6.192912151105702 seconds)
2024-07-14 23:43:59 | INFO | train_inner | epoch 001:  94100 / 150053 loss=5.093, nll_loss=3.79, ppl=13.84, wps=11085.6, ups=3.07, wpb=3613.8, bsz=116.3, num_updates=94100, lr=0.000103087, gnorm=1.046, train_wall=23, wall=0
2024-07-14 23:44:22 | INFO | train_inner | epoch 001:  94200 / 150053 loss=5.135, nll_loss=3.839, ppl=14.31, wps=15488.1, ups=4.28, wpb=3616.4, bsz=110, num_updates=94200, lr=0.000103033, gnorm=1.14, train_wall=23, wall=0
2024-07-14 23:44:46 | INFO | train_inner | epoch 001:  94300 / 150053 loss=5.121, nll_loss=3.823, ppl=14.15, wps=15148, ups=4.27, wpb=3544, bsz=105.3, num_updates=94300, lr=0.000102978, gnorm=1.073, train_wall=23, wall=0
2024-07-14 23:45:09 | INFO | train_inner | epoch 001:  94400 / 150053 loss=5.058, nll_loss=3.751, ppl=13.47, wps=15044.9, ups=4.28, wpb=3518.6, bsz=109.4, num_updates=94400, lr=0.000102923, gnorm=1.028, train_wall=23, wall=0
2024-07-14 23:45:32 | INFO | train_inner | epoch 001:  94500 / 150053 loss=5.075, nll_loss=3.77, ppl=13.64, wps=15363, ups=4.31, wpb=3567.5, bsz=113.4, num_updates=94500, lr=0.000102869, gnorm=1.046, train_wall=23, wall=0
2024-07-14 23:45:55 | INFO | train_inner | epoch 001:  94600 / 150053 loss=5.115, nll_loss=3.817, ppl=14.09, wps=15247.2, ups=4.3, wpb=3545.4, bsz=104.6, num_updates=94600, lr=0.000102815, gnorm=1.048, train_wall=23, wall=0
2024-07-14 23:46:18 | INFO | train_inner | epoch 001:  94700 / 150053 loss=5.194, nll_loss=3.906, ppl=14.99, wps=15065.4, ups=4.34, wpb=3468.8, bsz=94.8, num_updates=94700, lr=0.00010276, gnorm=1.069, train_wall=23, wall=0
2024-07-14 23:46:41 | INFO | train_inner | epoch 001:  94800 / 150053 loss=5.166, nll_loss=3.873, ppl=14.66, wps=15074.1, ups=4.33, wpb=3478.5, bsz=93.2, num_updates=94800, lr=0.000102706, gnorm=1.06, train_wall=23, wall=0
2024-07-14 23:47:05 | INFO | train_inner | epoch 001:  94900 / 150053 loss=5.085, nll_loss=3.782, ppl=13.76, wps=15280.4, ups=4.32, wpb=3536.8, bsz=113.7, num_updates=94900, lr=0.000102652, gnorm=1.089, train_wall=23, wall=0
2024-07-14 23:47:28 | INFO | train_inner | epoch 001:  95000 / 150053 loss=5.061, nll_loss=3.754, ppl=13.5, wps=14953.8, ups=4.31, wpb=3471, bsz=105.9, num_updates=95000, lr=0.000102598, gnorm=1.041, train_wall=23, wall=0
2024-07-14 23:47:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 23:47:31 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.754 | nll_loss 4.476 | ppl 22.26 | wps 43374.6 | wpb 2588.8 | bsz 75.3 | num_updates 95000 | best_loss 12.174
2024-07-14 23:47:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 23:47:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_95000.pt (epoch 1 @ 95000 updates, score 5.754) (writing took 5.568504625931382 seconds)
2024-07-14 23:48:00 | INFO | train_inner | epoch 001:  95100 / 150053 loss=5.109, nll_loss=3.809, ppl=14.01, wps=11475.4, ups=3.16, wpb=3632.9, bsz=102.6, num_updates=95100, lr=0.000102544, gnorm=1.024, train_wall=23, wall=0
2024-07-14 23:48:22 | INFO | train_inner | epoch 001:  95200 / 150053 loss=5.196, nll_loss=3.908, ppl=15.01, wps=15101.1, ups=4.36, wpb=3465.1, bsz=95.9, num_updates=95200, lr=0.00010249, gnorm=1.095, train_wall=23, wall=0
2024-07-14 23:48:45 | INFO | train_inner | epoch 001:  95300 / 150053 loss=5.057, nll_loss=3.75, ppl=13.46, wps=15574.3, ups=4.35, wpb=3581, bsz=102.5, num_updates=95300, lr=0.000102436, gnorm=1.023, train_wall=23, wall=0
2024-07-14 23:49:09 | INFO | train_inner | epoch 001:  95400 / 150053 loss=5.169, nll_loss=3.878, ppl=14.7, wps=15222.2, ups=4.28, wpb=3554, bsz=95.8, num_updates=95400, lr=0.000102383, gnorm=1.08, train_wall=23, wall=0
2024-07-14 23:49:32 | INFO | train_inner | epoch 001:  95500 / 150053 loss=5.152, nll_loss=3.859, ppl=14.51, wps=15130.8, ups=4.37, wpb=3464.3, bsz=94.4, num_updates=95500, lr=0.000102329, gnorm=1.071, train_wall=23, wall=0
2024-07-14 23:49:56 | INFO | train_inner | epoch 001:  95600 / 150053 loss=5.072, nll_loss=3.767, ppl=13.61, wps=15390.8, ups=4.2, wpb=3668, bsz=103.4, num_updates=95600, lr=0.000102275, gnorm=1.017, train_wall=24, wall=0
2024-07-14 23:50:19 | INFO | train_inner | epoch 001:  95700 / 150053 loss=5.087, nll_loss=3.784, ppl=13.78, wps=14873.4, ups=4.22, wpb=3521, bsz=114.8, num_updates=95700, lr=0.000102222, gnorm=1.105, train_wall=23, wall=0
2024-07-14 23:50:42 | INFO | train_inner | epoch 001:  95800 / 150053 loss=5.162, nll_loss=3.87, ppl=14.62, wps=15398, ups=4.33, wpb=3556.8, bsz=101.8, num_updates=95800, lr=0.000102169, gnorm=1.061, train_wall=23, wall=0
2024-07-14 23:51:05 | INFO | train_inner | epoch 001:  95900 / 150053 loss=5.172, nll_loss=3.881, ppl=14.73, wps=15079.5, ups=4.35, wpb=3469.9, bsz=92.3, num_updates=95900, lr=0.000102115, gnorm=1.058, train_wall=23, wall=0
2024-07-14 23:51:28 | INFO | train_inner | epoch 001:  96000 / 150053 loss=5.094, nll_loss=3.792, ppl=13.85, wps=15290.8, ups=4.32, wpb=3541.7, bsz=100, num_updates=96000, lr=0.000102062, gnorm=1.044, train_wall=23, wall=0
2024-07-14 23:51:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 23:51:31 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.751 | nll_loss 4.467 | ppl 22.12 | wps 43513.6 | wpb 2588.8 | bsz 75.3 | num_updates 96000 | best_loss 12.174
2024-07-14 23:51:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 23:51:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_96000.pt (epoch 1 @ 96000 updates, score 5.751) (writing took 9.43292597681284 seconds)
2024-07-14 23:52:04 | INFO | train_inner | epoch 001:  96100 / 150053 loss=5.107, nll_loss=3.806, ppl=13.99, wps=10172.1, ups=2.81, wpb=3618.1, bsz=105.7, num_updates=96100, lr=0.000102009, gnorm=1.037, train_wall=23, wall=0
2024-07-14 23:52:27 | INFO | train_inner | epoch 001:  96200 / 150053 loss=5.137, nll_loss=3.841, ppl=14.33, wps=15444.3, ups=4.32, wpb=3571.1, bsz=89.9, num_updates=96200, lr=0.000101956, gnorm=1.044, train_wall=23, wall=0
2024-07-14 23:52:50 | INFO | train_inner | epoch 001:  96300 / 150053 loss=5.064, nll_loss=3.758, ppl=13.52, wps=15411.9, ups=4.3, wpb=3581.9, bsz=106.2, num_updates=96300, lr=0.000101903, gnorm=1.033, train_wall=23, wall=0
2024-07-14 23:53:14 | INFO | train_inner | epoch 001:  96400 / 150053 loss=5.055, nll_loss=3.747, ppl=13.43, wps=15197.5, ups=4.25, wpb=3574.8, bsz=111.8, num_updates=96400, lr=0.00010185, gnorm=1.033, train_wall=23, wall=0
2024-07-14 23:53:37 | INFO | train_inner | epoch 001:  96500 / 150053 loss=5.058, nll_loss=3.752, ppl=13.47, wps=15102.6, ups=4.26, wpb=3543.6, bsz=107, num_updates=96500, lr=0.000101797, gnorm=1.072, train_wall=23, wall=0
2024-07-14 23:54:00 | INFO | train_inner | epoch 001:  96600 / 150053 loss=5.14, nll_loss=3.844, ppl=14.36, wps=15543.9, ups=4.33, wpb=3589.9, bsz=103.6, num_updates=96600, lr=0.000101745, gnorm=1.068, train_wall=23, wall=0
2024-07-14 23:54:24 | INFO | train_inner | epoch 001:  96700 / 150053 loss=5.146, nll_loss=3.852, ppl=14.44, wps=15227.9, ups=4.32, wpb=3521.4, bsz=88.9, num_updates=96700, lr=0.000101692, gnorm=1.041, train_wall=23, wall=0
2024-07-14 23:54:47 | INFO | train_inner | epoch 001:  96800 / 150053 loss=5.085, nll_loss=3.781, ppl=13.75, wps=15328.2, ups=4.3, wpb=3563.3, bsz=100.6, num_updates=96800, lr=0.000101639, gnorm=1.043, train_wall=23, wall=0
2024-07-14 23:55:10 | INFO | train_inner | epoch 001:  96900 / 150053 loss=5.148, nll_loss=3.853, ppl=14.45, wps=15352.8, ups=4.3, wpb=3572.7, bsz=109.3, num_updates=96900, lr=0.000101587, gnorm=1.065, train_wall=23, wall=0
2024-07-14 23:55:33 | INFO | train_inner | epoch 001:  97000 / 150053 loss=5.123, nll_loss=3.826, ppl=14.18, wps=15368.7, ups=4.3, wpb=3575.1, bsz=103.9, num_updates=97000, lr=0.000101535, gnorm=1.059, train_wall=23, wall=0
2024-07-14 23:55:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 23:55:36 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.737 | nll_loss 4.452 | ppl 21.89 | wps 43708.8 | wpb 2588.8 | bsz 75.3 | num_updates 97000 | best_loss 12.174
2024-07-14 23:55:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 23:55:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_97000.pt (epoch 1 @ 97000 updates, score 5.737) (writing took 11.642420385032892 seconds)
2024-07-14 23:56:11 | INFO | train_inner | epoch 001:  97100 / 150053 loss=5.137, nll_loss=3.84, ppl=14.32, wps=9631, ups=2.65, wpb=3638.5, bsz=99.1, num_updates=97100, lr=0.000101482, gnorm=1.033, train_wall=23, wall=0
2024-07-14 23:56:34 | INFO | train_inner | epoch 001:  97200 / 150053 loss=5.108, nll_loss=3.807, ppl=14, wps=15477, ups=4.3, wpb=3595.9, bsz=115.4, num_updates=97200, lr=0.00010143, gnorm=1.066, train_wall=23, wall=0
2024-07-14 23:56:57 | INFO | train_inner | epoch 001:  97300 / 150053 loss=5.172, nll_loss=3.88, ppl=14.73, wps=15405.5, ups=4.37, wpb=3526.7, bsz=95, num_updates=97300, lr=0.000101378, gnorm=1.083, train_wall=23, wall=0
2024-07-14 23:57:20 | INFO | train_inner | epoch 001:  97400 / 150053 loss=5.136, nll_loss=3.84, ppl=14.32, wps=14994, ups=4.37, wpb=3434.6, bsz=103, num_updates=97400, lr=0.000101326, gnorm=1.138, train_wall=23, wall=0
2024-07-14 23:57:43 | INFO | train_inner | epoch 001:  97500 / 150053 loss=5.124, nll_loss=3.826, ppl=14.19, wps=15342.2, ups=4.3, wpb=3567.6, bsz=100.8, num_updates=97500, lr=0.000101274, gnorm=1.056, train_wall=23, wall=0
2024-07-14 23:58:07 | INFO | train_inner | epoch 001:  97600 / 150053 loss=5.088, nll_loss=3.785, ppl=13.79, wps=15201.6, ups=4.25, wpb=3580.7, bsz=107.8, num_updates=97600, lr=0.000101222, gnorm=1.052, train_wall=23, wall=0
2024-07-14 23:58:30 | INFO | train_inner | epoch 001:  97700 / 150053 loss=5.109, nll_loss=3.809, ppl=14.02, wps=15159.9, ups=4.29, wpb=3535.2, bsz=107.8, num_updates=97700, lr=0.00010117, gnorm=1.067, train_wall=23, wall=0
2024-07-14 23:58:53 | INFO | train_inner | epoch 001:  97800 / 150053 loss=5.116, nll_loss=3.817, ppl=14.09, wps=15095.8, ups=4.32, wpb=3495.6, bsz=116.9, num_updates=97800, lr=0.000101118, gnorm=1.137, train_wall=23, wall=0
2024-07-14 23:59:17 | INFO | train_inner | epoch 001:  97900 / 150053 loss=5.06, nll_loss=3.754, ppl=13.49, wps=15149.6, ups=4.26, wpb=3552.8, bsz=109.4, num_updates=97900, lr=0.000101067, gnorm=1.081, train_wall=23, wall=0
2024-07-14 23:59:41 | INFO | train_inner | epoch 001:  98000 / 150053 loss=5.037, nll_loss=3.727, ppl=13.24, wps=15395.8, ups=4.24, wpb=3627.3, bsz=114.4, num_updates=98000, lr=0.000101015, gnorm=1.028, train_wall=23, wall=0
2024-07-14 23:59:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-14 23:59:43 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.78 | nll_loss 4.495 | ppl 22.56 | wps 43250.3 | wpb 2588.8 | bsz 75.3 | num_updates 98000 | best_loss 12.174
2024-07-14 23:59:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-14 23:59:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_98000.pt (epoch 1 @ 98000 updates, score 5.78) (writing took 8.662871157750487 seconds)
2024-07-15 00:00:15 | INFO | train_inner | epoch 001:  98100 / 150053 loss=5.186, nll_loss=3.897, ppl=14.9, wps=10147.9, ups=2.91, wpb=3490.6, bsz=91.8, num_updates=98100, lr=0.000100964, gnorm=1.081, train_wall=23, wall=0
2024-07-15 00:00:38 | INFO | train_inner | epoch 001:  98200 / 150053 loss=5.038, nll_loss=3.729, ppl=13.26, wps=15477, ups=4.36, wpb=3553.5, bsz=129.4, num_updates=98200, lr=0.000100912, gnorm=1.073, train_wall=23, wall=0
2024-07-15 00:01:01 | INFO | train_inner | epoch 001:  98300 / 150053 loss=5.137, nll_loss=3.841, ppl=14.33, wps=15590.6, ups=4.35, wpb=3584, bsz=105.7, num_updates=98300, lr=0.000100861, gnorm=1.07, train_wall=23, wall=0
2024-07-15 00:01:24 | INFO | train_inner | epoch 001:  98400 / 150053 loss=5.141, nll_loss=3.846, ppl=14.38, wps=15396.1, ups=4.36, wpb=3532.2, bsz=99.4, num_updates=98400, lr=0.00010081, gnorm=1.099, train_wall=23, wall=0
2024-07-15 00:01:46 | INFO | train_inner | epoch 001:  98500 / 150053 loss=5.116, nll_loss=3.817, ppl=14.09, wps=15741.6, ups=4.41, wpb=3566.9, bsz=98.1, num_updates=98500, lr=0.000100759, gnorm=1.049, train_wall=22, wall=0
2024-07-15 00:02:10 | INFO | train_inner | epoch 001:  98600 / 150053 loss=5.177, nll_loss=3.887, ppl=14.8, wps=15176.3, ups=4.34, wpb=3499.2, bsz=88.4, num_updates=98600, lr=0.000100707, gnorm=1.07, train_wall=23, wall=0
2024-07-15 00:02:33 | INFO | train_inner | epoch 001:  98700 / 150053 loss=5.125, nll_loss=3.827, ppl=14.19, wps=15219.6, ups=4.32, wpb=3523.9, bsz=104.1, num_updates=98700, lr=0.000100656, gnorm=1.059, train_wall=23, wall=0
2024-07-15 00:02:56 | INFO | train_inner | epoch 001:  98800 / 150053 loss=5.074, nll_loss=3.77, ppl=13.64, wps=15250.2, ups=4.29, wpb=3555.5, bsz=105, num_updates=98800, lr=0.000100605, gnorm=1.069, train_wall=23, wall=0
2024-07-15 00:03:19 | INFO | train_inner | epoch 001:  98900 / 150053 loss=5.143, nll_loss=3.847, ppl=14.39, wps=15122.8, ups=4.31, wpb=3508.8, bsz=100.2, num_updates=98900, lr=0.000100555, gnorm=1.06, train_wall=23, wall=0
2024-07-15 00:03:43 | INFO | train_inner | epoch 001:  99000 / 150053 loss=5.145, nll_loss=3.85, ppl=14.42, wps=15311, ups=4.26, wpb=3596, bsz=102.1, num_updates=99000, lr=0.000100504, gnorm=1.048, train_wall=23, wall=0
2024-07-15 00:03:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 00:03:45 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.78 | nll_loss 4.498 | ppl 22.59 | wps 42865.2 | wpb 2588.8 | bsz 75.3 | num_updates 99000 | best_loss 12.174
2024-07-15 00:03:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 00:03:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_99000.pt (epoch 1 @ 99000 updates, score 5.78) (writing took 10.90505728404969 seconds)
2024-07-15 00:04:20 | INFO | train_inner | epoch 001:  99100 / 150053 loss=5.086, nll_loss=3.784, ppl=13.77, wps=9431.9, ups=2.71, wpb=3485.1, bsz=97.4, num_updates=99100, lr=0.000100453, gnorm=1.084, train_wall=23, wall=0
2024-07-15 00:04:43 | INFO | train_inner | epoch 001:  99200 / 150053 loss=5.061, nll_loss=3.754, ppl=13.49, wps=15507.4, ups=4.3, wpb=3607.7, bsz=122.6, num_updates=99200, lr=0.000100402, gnorm=1.088, train_wall=23, wall=0
2024-07-15 00:05:06 | INFO | train_inner | epoch 001:  99300 / 150053 loss=5.138, nll_loss=3.843, ppl=14.35, wps=15201.7, ups=4.3, wpb=3536.5, bsz=95.9, num_updates=99300, lr=0.000100352, gnorm=1.04, train_wall=23, wall=0
2024-07-15 00:05:29 | INFO | train_inner | epoch 001:  99400 / 150053 loss=5.187, nll_loss=3.897, ppl=14.9, wps=15184.6, ups=4.32, wpb=3512.7, bsz=95, num_updates=99400, lr=0.000100301, gnorm=1.073, train_wall=23, wall=0
2024-07-15 00:05:52 | INFO | train_inner | epoch 001:  99500 / 150053 loss=5.223, nll_loss=3.939, ppl=15.34, wps=15026.7, ups=4.31, wpb=3484.2, bsz=79.2, num_updates=99500, lr=0.000100251, gnorm=1.059, train_wall=23, wall=0
2024-07-15 00:06:16 | INFO | train_inner | epoch 001:  99600 / 150053 loss=5.085, nll_loss=3.782, ppl=13.76, wps=15197, ups=4.26, wpb=3566.3, bsz=109.5, num_updates=99600, lr=0.000100201, gnorm=1.049, train_wall=23, wall=0
2024-07-15 00:06:39 | INFO | train_inner | epoch 001:  99700 / 150053 loss=5.079, nll_loss=3.775, ppl=13.69, wps=15670.5, ups=4.38, wpb=3580.6, bsz=99.8, num_updates=99700, lr=0.00010015, gnorm=1.032, train_wall=23, wall=0
2024-07-15 00:07:02 | INFO | train_inner | epoch 001:  99800 / 150053 loss=5.117, nll_loss=3.819, ppl=14.12, wps=15030.4, ups=4.33, wpb=3467.4, bsz=99.2, num_updates=99800, lr=0.0001001, gnorm=1.081, train_wall=23, wall=0
2024-07-15 00:07:25 | INFO | train_inner | epoch 001:  99900 / 150053 loss=5.119, nll_loss=3.821, ppl=14.13, wps=15445.5, ups=4.31, wpb=3580.3, bsz=128.9, num_updates=99900, lr=0.00010005, gnorm=1.137, train_wall=23, wall=0
2024-07-15 00:07:48 | INFO | train_inner | epoch 001:  100000 / 150053 loss=5.109, nll_loss=3.81, ppl=14.02, wps=15583, ups=4.41, wpb=3534.4, bsz=110, num_updates=100000, lr=0.0001, gnorm=1.12, train_wall=23, wall=0
2024-07-15 00:07:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-15 00:07:50 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.751 | nll_loss 4.464 | ppl 22.08 | wps 43551.8 | wpb 2588.8 | bsz 75.3 | num_updates 100000 | best_loss 12.174
2024-07-15 00:07:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-15 00:07:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_100000.pt (epoch 1 @ 100000 updates, score 5.751) (writing took 7.198800543323159 seconds)
2024-07-15 00:07:58 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-15 00:07:58 | INFO | train | epoch 001 | loss 5.623 | nll_loss 4.392 | ppl 20.99 | wps 14609 | ups 4.12 | wpb 3546.4 | bsz 103.7 | num_updates 100000 | lr 0.0001 | gnorm 1.02 | train_wall 23039 | wall 0
2024-07-15 00:07:58 | INFO | fairseq_cli.train | done training in 21711.1 seconds
