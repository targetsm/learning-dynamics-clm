2024-07-18 11:58:29 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt22.sep.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=1000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=100, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-18 11:58:29 | INFO | fairseq.tasks.translation | [de] dictionary: 9968 types
2024-07-18 11:58:29 | INFO | fairseq.tasks.translation | [en] dictionary: 9968 types
2024-07-18 11:58:29 | INFO | fairseq.data.data_utils | loaded 2203 examples from: data-bin/wmt22.sep.tokenized.de-en/valid.de-en.de
2024-07-18 11:58:29 | INFO | fairseq.data.data_utils | loaded 2203 examples from: data-bin/wmt22.sep.tokenized.de-en/valid.de-en.en
2024-07-18 11:58:29 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.de-en valid de-en 2203 examples
2024-07-18 11:58:30 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9968, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9968, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=9968, bias=False)
  )
)
2024-07-18 11:58:30 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-18 11:58:30 | INFO | fairseq_cli.train | model: transformer_wmt_en_de (TransformerModel)
2024-07-18 11:58:30 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-18 11:58:30 | INFO | fairseq_cli.train | num. model params: 54345728 (num. trained: 54345728)
2024-07-18 11:58:34 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-18 11:58:34 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-18 11:58:34 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-18 11:58:34 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-18 11:58:34 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-18 11:58:34 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-18 11:58:34 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/checkpoint_last.pt
2024-07-18 11:58:34 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-18 11:58:34 | INFO | fairseq.data.data_utils | loaded 2782552 examples from: data-bin/wmt22.sep.tokenized.de-en/train.de-en.de
2024-07-18 11:58:34 | INFO | fairseq.data.data_utils | loaded 2782552 examples from: data-bin/wmt22.sep.tokenized.de-en/train.de-en.en
2024-07-18 11:58:34 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.de-en train de-en 2782552 examples
2024-07-18 11:58:37 | INFO | fairseq.trainer | begin training epoch 1
2024-07-18 11:59:01 | INFO | train_inner | epoch 001:    100 / 19564 loss=12.838, nll_loss=12.701, ppl=6659.83, wps=15256.8, ups=4.39, wpb=3472.3, bsz=130, num_updates=100, lr=1.25e-05, gnorm=3.118, train_wall=24, wall=27
2024-07-18 11:59:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-18 11:59:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.094 | nll_loss 11.859 | ppl 3714.75 | wps 45232.8 | wpb 2872.6 | bsz 51.2 | num_updates 100
2024-07-18 11:59:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 11:59:07 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_100.pt (epoch 1 @ 100 updates, score 12.094) (writing took 2.6306959772482514 seconds)
2024-07-18 11:59:29 | INFO | train_inner | epoch 001:    200 / 19564 loss=11.689, nll_loss=11.422, ppl=2743.08, wps=12291.5, ups=3.55, wpb=3460.4, bsz=135.9, num_updates=200, lr=2.5e-05, gnorm=1.331, train_wall=23, wall=55
2024-07-18 11:59:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 11:59:32 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.365 | nll_loss 11.05 | ppl 2119.85 | wps 45471.9 | wpb 2872.6 | bsz 51.2 | num_updates 200 | best_loss 12.094
2024-07-18 11:59:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 11:59:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_200.pt (epoch 1 @ 200 updates, score 11.365) (writing took 4.776834316551685 seconds)
2024-07-18 12:00:00 | INFO | train_inner | epoch 001:    300 / 19564 loss=11.043, nll_loss=10.687, ppl=1648.6, wps=11445, ups=3.3, wpb=3468.5, bsz=137.4, num_updates=300, lr=3.75e-05, gnorm=1.821, train_wall=23, wall=86
2024-07-18 12:00:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:00:02 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.885 | nll_loss 10.479 | ppl 1426.89 | wps 45000.9 | wpb 2872.6 | bsz 51.2 | num_updates 300 | best_loss 12.094
2024-07-18 12:00:02 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:00:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_300.pt (epoch 1 @ 300 updates, score 10.885) (writing took 11.695167103782296 seconds)
2024-07-18 12:00:37 | INFO | train_inner | epoch 001:    400 / 19564 loss=10.651, nll_loss=10.212, ppl=1186, wps=9368.1, ups=2.68, wpb=3493.5, bsz=127.3, num_updates=400, lr=5e-05, gnorm=1.551, train_wall=23, wall=123
2024-07-18 12:00:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:00:40 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.949 | nll_loss 10.474 | ppl 1421.91 | wps 45158.9 | wpb 2872.6 | bsz 51.2 | num_updates 400 | best_loss 12.094
2024-07-18 12:00:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:00:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_400.pt (epoch 1 @ 400 updates, score 10.949) (writing took 7.463136684149504 seconds)
2024-07-18 12:01:10 | INFO | train_inner | epoch 001:    500 / 19564 loss=10.543, nll_loss=10.069, ppl=1074.23, wps=10466.9, ups=3.03, wpb=3455.4, bsz=161.1, num_updates=500, lr=6.25e-05, gnorm=1.691, train_wall=23, wall=156
2024-07-18 12:01:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:01:13 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.522 | nll_loss 10.017 | ppl 1036.01 | wps 44587.7 | wpb 2872.6 | bsz 51.2 | num_updates 500 | best_loss 12.094
2024-07-18 12:01:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:01:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_500.pt (epoch 1 @ 500 updates, score 10.522) (writing took 8.491693492047489 seconds)
2024-07-18 12:01:44 | INFO | train_inner | epoch 001:    600 / 19564 loss=10.434, nll_loss=9.94, ppl=982.13, wps=9970.9, ups=2.94, wpb=3391.6, bsz=143, num_updates=600, lr=7.5e-05, gnorm=1.609, train_wall=22, wall=190
2024-07-18 12:01:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:01:47 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.347 | nll_loss 9.788 | ppl 883.82 | wps 44622.8 | wpb 2872.6 | bsz 51.2 | num_updates 600 | best_loss 12.094
2024-07-18 12:01:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:01:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_600.pt (epoch 1 @ 600 updates, score 10.347) (writing took 4.083598518744111 seconds)
2024-07-18 12:02:14 | INFO | train_inner | epoch 001:    700 / 19564 loss=10.305, nll_loss=9.791, ppl=885.98, wps=11626, ups=3.37, wpb=3451.4, bsz=127.6, num_updates=700, lr=8.75e-05, gnorm=1.419, train_wall=23, wall=220
2024-07-18 12:02:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:02:17 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.262 | nll_loss 9.684 | ppl 822.49 | wps 44416.4 | wpb 2872.6 | bsz 51.2 | num_updates 700 | best_loss 12.094
2024-07-18 12:02:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:02:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_700.pt (epoch 1 @ 700 updates, score 10.262) (writing took 6.6488713482394814 seconds)
2024-07-18 12:02:46 | INFO | train_inner | epoch 001:    800 / 19564 loss=10.18, nll_loss=9.648, ppl=802.4, wps=10774, ups=3.1, wpb=3480.4, bsz=141.1, num_updates=800, lr=0.0001, gnorm=1.463, train_wall=23, wall=252
2024-07-18 12:02:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:02:49 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.099 | nll_loss 9.513 | ppl 730.61 | wps 44698 | wpb 2872.6 | bsz 51.2 | num_updates 800 | best_loss 12.094
2024-07-18 12:02:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:03:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_800.pt (epoch 1 @ 800 updates, score 10.099) (writing took 12.448228812776506 seconds)
2024-07-18 12:03:24 | INFO | train_inner | epoch 001:    900 / 19564 loss=9.997, nll_loss=9.439, ppl=694.12, wps=8961.3, ups=2.61, wpb=3436.1, bsz=157, num_updates=900, lr=0.0001125, gnorm=1.343, train_wall=23, wall=290
2024-07-18 12:03:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:03:27 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.984 | nll_loss 9.396 | ppl 673.63 | wps 45196.5 | wpb 2872.6 | bsz 51.2 | num_updates 900 | best_loss 12.094
2024-07-18 12:03:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:03:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_900.pt (epoch 1 @ 900 updates, score 9.984) (writing took 4.110291503369808 seconds)
2024-07-18 12:03:54 | INFO | train_inner | epoch 001:   1000 / 19564 loss=9.895, nll_loss=9.319, ppl=638.51, wps=11606.7, ups=3.33, wpb=3485.2, bsz=135.1, num_updates=1000, lr=0.000125, gnorm=1.466, train_wall=23, wall=320
2024-07-18 12:03:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:03:57 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.803 | nll_loss 9.202 | ppl 589.06 | wps 44793.1 | wpb 2872.6 | bsz 51.2 | num_updates 1000 | best_loss 12.094
2024-07-18 12:03:57 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:04:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 9.803) (writing took 8.956138441339135 seconds)
2024-07-18 12:04:06 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-18 12:04:06 | INFO | train | epoch 001 | loss 10.759 | nll_loss 10.324 | ppl 1281.83 | wps 10552.9 | ups 3.05 | wpb 3459.5 | bsz 139.6 | num_updates 1000 | lr 0.000125 | gnorm 1.681 | train_wall 227 | wall 332
2024-07-18 12:04:06 | INFO | fairseq_cli.train | done training in 329.1 seconds
2024-07-18 12:04:09 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt22.sep.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=10000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=500, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-18 12:04:09 | INFO | fairseq.tasks.translation | [de] dictionary: 9968 types
2024-07-18 12:04:09 | INFO | fairseq.tasks.translation | [en] dictionary: 9968 types
2024-07-18 12:04:09 | INFO | fairseq.data.data_utils | loaded 2203 examples from: data-bin/wmt22.sep.tokenized.de-en/valid.de-en.de
2024-07-18 12:04:09 | INFO | fairseq.data.data_utils | loaded 2203 examples from: data-bin/wmt22.sep.tokenized.de-en/valid.de-en.en
2024-07-18 12:04:09 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.de-en valid de-en 2203 examples
2024-07-18 12:04:10 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9968, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9968, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=9968, bias=False)
  )
)
2024-07-18 12:04:10 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-18 12:04:10 | INFO | fairseq_cli.train | model: transformer_wmt_en_de (TransformerModel)
2024-07-18 12:04:10 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-18 12:04:10 | INFO | fairseq_cli.train | num. model params: 54345728 (num. trained: 54345728)
2024-07-18 12:04:14 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-18 12:04:14 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-18 12:04:14 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-18 12:04:14 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-18 12:04:14 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-18 12:04:14 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-18 12:04:15 | INFO | fairseq.trainer | loaded checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 1000 updates)
2024-07-18 12:04:15 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-18 12:04:15 | INFO | fairseq.data.data_utils | loaded 2782552 examples from: data-bin/wmt22.sep.tokenized.de-en/train.de-en.de
2024-07-18 12:04:16 | INFO | fairseq.data.data_utils | loaded 2782552 examples from: data-bin/wmt22.sep.tokenized.de-en/train.de-en.en
2024-07-18 12:04:16 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.de-en train de-en 2782552 examples
2024-07-18 12:04:18 | INFO | fairseq.trainer | begin training epoch 1
2024-07-18 12:04:42 | INFO | train_inner | epoch 001:   1100 / 19564 loss=9.764, nll_loss=9.167, ppl=574.8, wps=11737.4, ups=3.38, wpb=3470.4, bsz=132.9, num_updates=1100, lr=0.0001375, gnorm=1.406, train_wall=23, wall=0
2024-07-18 12:05:05 | INFO | train_inner | epoch 001:   1200 / 19564 loss=9.586, nll_loss=8.962, ppl=498.75, wps=15094.4, ups=4.37, wpb=3455.1, bsz=148.4, num_updates=1200, lr=0.00015, gnorm=1.506, train_wall=23, wall=0
2024-07-18 12:05:28 | INFO | train_inner | epoch 001:   1300 / 19564 loss=9.552, nll_loss=8.92, ppl=484.22, wps=14998.3, ups=4.35, wpb=3447.1, bsz=130.7, num_updates=1300, lr=0.0001625, gnorm=1.348, train_wall=23, wall=0
2024-07-18 12:05:51 | INFO | train_inner | epoch 001:   1400 / 19564 loss=9.432, nll_loss=8.78, ppl=439.59, wps=14800.1, ups=4.39, wpb=3371.5, bsz=154.4, num_updates=1400, lr=0.000175, gnorm=1.435, train_wall=23, wall=0
2024-07-18 12:06:13 | INFO | train_inner | epoch 001:   1500 / 19564 loss=9.32, nll_loss=8.65, ppl=401.8, wps=15016.7, ups=4.37, wpb=3436.6, bsz=146.6, num_updates=1500, lr=0.0001875, gnorm=1.273, train_wall=23, wall=0
2024-07-18 12:06:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-18 12:06:16 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.344 | nll_loss 8.64 | ppl 398.8 | wps 44545.1 | wpb 2872.6 | bsz 51.2 | num_updates 1500 | best_loss 12.094
2024-07-18 12:06:16 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:06:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_1500.pt (epoch 1 @ 1500 updates, score 9.344) (writing took 4.031134326942265 seconds)
2024-07-18 12:06:44 | INFO | train_inner | epoch 001:   1600 / 19564 loss=9.177, nll_loss=8.484, ppl=358.06, wps=11690.7, ups=3.33, wpb=3511.6, bsz=145.8, num_updates=1600, lr=0.0002, gnorm=1.367, train_wall=23, wall=0
2024-07-18 12:07:06 | INFO | train_inner | epoch 001:   1700 / 19564 loss=9.094, nll_loss=8.387, ppl=334.69, wps=15010, ups=4.36, wpb=3442.8, bsz=150.1, num_updates=1700, lr=0.0002125, gnorm=1.246, train_wall=23, wall=0
2024-07-18 12:07:29 | INFO | train_inner | epoch 001:   1800 / 19564 loss=9.035, nll_loss=8.317, ppl=318.82, wps=14954.4, ups=4.35, wpb=3440.4, bsz=134.2, num_updates=1800, lr=0.000225, gnorm=1.235, train_wall=23, wall=0
2024-07-18 12:07:52 | INFO | train_inner | epoch 001:   1900 / 19564 loss=8.97, nll_loss=8.24, ppl=302.36, wps=14986.4, ups=4.36, wpb=3438.6, bsz=149.8, num_updates=1900, lr=0.0002375, gnorm=1.226, train_wall=23, wall=0
2024-07-18 12:08:15 | INFO | train_inner | epoch 001:   2000 / 19564 loss=8.902, nll_loss=8.161, ppl=286.14, wps=14849.5, ups=4.35, wpb=3416.2, bsz=140, num_updates=2000, lr=0.00025, gnorm=1.238, train_wall=23, wall=0
2024-07-18 12:08:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:08:18 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.162 | nll_loss 8.428 | ppl 344.35 | wps 45022.8 | wpb 2872.6 | bsz 51.2 | num_updates 2000 | best_loss 12.094
2024-07-18 12:08:18 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:08:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 9.162) (writing took 6.641180923208594 seconds)
2024-07-18 12:08:48 | INFO | train_inner | epoch 001:   2100 / 19564 loss=8.822, nll_loss=8.068, ppl=268.29, wps=10737, ups=3.08, wpb=3488.3, bsz=145.5, num_updates=2100, lr=0.0002625, gnorm=1.164, train_wall=23, wall=0
2024-07-18 12:09:11 | INFO | train_inner | epoch 001:   2200 / 19564 loss=8.767, nll_loss=8.002, ppl=256.33, wps=15052.6, ups=4.37, wpb=3441.6, bsz=151.7, num_updates=2200, lr=0.000275, gnorm=1.224, train_wall=23, wall=0
2024-07-18 12:09:33 | INFO | train_inner | epoch 001:   2300 / 19564 loss=8.732, nll_loss=7.962, ppl=249.28, wps=15102.6, ups=4.41, wpb=3424.2, bsz=136.8, num_updates=2300, lr=0.0002875, gnorm=1.134, train_wall=22, wall=0
2024-07-18 12:09:57 | INFO | train_inner | epoch 001:   2400 / 19564 loss=8.607, nll_loss=7.818, ppl=225.72, wps=15088.4, ups=4.32, wpb=3490.1, bsz=159, num_updates=2400, lr=0.0003, gnorm=1.131, train_wall=23, wall=0
2024-07-18 12:10:20 | INFO | train_inner | epoch 001:   2500 / 19564 loss=8.574, nll_loss=7.779, ppl=219.66, wps=14978.6, ups=4.33, wpb=3461.4, bsz=147.8, num_updates=2500, lr=0.0003125, gnorm=1.127, train_wall=23, wall=0
2024-07-18 12:10:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:10:23 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.887 | nll_loss 8.102 | ppl 274.75 | wps 44791.4 | wpb 2872.6 | bsz 51.2 | num_updates 2500 | best_loss 12.094
2024-07-18 12:10:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:10:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_2500.pt (epoch 1 @ 2500 updates, score 8.887) (writing took 4.932220097631216 seconds)
2024-07-18 12:10:50 | INFO | train_inner | epoch 001:   2600 / 19564 loss=8.564, nll_loss=7.765, ppl=217.54, wps=11076.2, ups=3.25, wpb=3404, bsz=146.8, num_updates=2600, lr=0.000325, gnorm=1.184, train_wall=23, wall=0
2024-07-18 12:11:13 | INFO | train_inner | epoch 001:   2700 / 19564 loss=8.569, nll_loss=7.771, ppl=218.49, wps=14520, ups=4.4, wpb=3303.6, bsz=156.4, num_updates=2700, lr=0.0003375, gnorm=1.202, train_wall=23, wall=0
2024-07-18 12:11:36 | INFO | train_inner | epoch 001:   2800 / 19564 loss=8.389, nll_loss=7.563, ppl=189.11, wps=15103.8, ups=4.32, wpb=3498.2, bsz=140.9, num_updates=2800, lr=0.00035, gnorm=1.023, train_wall=23, wall=0
2024-07-18 12:11:59 | INFO | train_inner | epoch 001:   2900 / 19564 loss=8.431, nll_loss=7.611, ppl=195.49, wps=14762.2, ups=4.33, wpb=3405.5, bsz=139.1, num_updates=2900, lr=0.0003625, gnorm=1.141, train_wall=23, wall=0
2024-07-18 12:12:22 | INFO | train_inner | epoch 001:   3000 / 19564 loss=8.287, nll_loss=7.445, ppl=174.27, wps=15066.7, ups=4.37, wpb=3449.5, bsz=155, num_updates=3000, lr=0.000375, gnorm=1.109, train_wall=23, wall=0
2024-07-18 12:12:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:12:25 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.782 | nll_loss 7.976 | ppl 251.72 | wps 44886.5 | wpb 2872.6 | bsz 51.2 | num_updates 3000 | best_loss 12.094
2024-07-18 12:12:25 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:12:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_3000.pt (epoch 1 @ 3000 updates, score 8.782) (writing took 4.713074206374586 seconds)
2024-07-18 12:12:53 | INFO | train_inner | epoch 001:   3100 / 19564 loss=8.357, nll_loss=7.523, ppl=183.93, wps=11291.9, ups=3.28, wpb=3440.4, bsz=133.9, num_updates=3100, lr=0.0003875, gnorm=1.173, train_wall=23, wall=0
2024-07-18 12:13:16 | INFO | train_inner | epoch 001:   3200 / 19564 loss=8.23, nll_loss=7.378, ppl=166.39, wps=15207.9, ups=4.33, wpb=3512.1, bsz=158.6, num_updates=3200, lr=0.0004, gnorm=1.128, train_wall=23, wall=0
2024-07-18 12:13:39 | INFO | train_inner | epoch 001:   3300 / 19564 loss=8.201, nll_loss=7.344, ppl=162.47, wps=15201, ups=4.36, wpb=3487.9, bsz=143.7, num_updates=3300, lr=0.0004125, gnorm=1.098, train_wall=23, wall=0
2024-07-18 12:14:02 | INFO | train_inner | epoch 001:   3400 / 19564 loss=8.272, nll_loss=7.424, ppl=171.77, wps=14743.9, ups=4.35, wpb=3389.8, bsz=135.8, num_updates=3400, lr=0.000425, gnorm=1.151, train_wall=23, wall=0
2024-07-18 12:14:24 | INFO | train_inner | epoch 001:   3500 / 19564 loss=8.197, nll_loss=7.339, ppl=161.93, wps=14858.1, ups=4.41, wpb=3370.5, bsz=139.7, num_updates=3500, lr=0.0004375, gnorm=1.112, train_wall=23, wall=0
2024-07-18 12:14:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:14:27 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.522 | nll_loss 7.663 | ppl 202.61 | wps 44867.9 | wpb 2872.6 | bsz 51.2 | num_updates 3500 | best_loss 12.094
2024-07-18 12:14:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:14:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_3500.pt (epoch 1 @ 3500 updates, score 8.522) (writing took 4.202290713787079 seconds)
2024-07-18 12:14:55 | INFO | train_inner | epoch 001:   3600 / 19564 loss=8.125, nll_loss=7.255, ppl=152.79, wps=11408.5, ups=3.33, wpb=3427.4, bsz=136.9, num_updates=3600, lr=0.00045, gnorm=1.082, train_wall=23, wall=0
2024-07-18 12:15:17 | INFO | train_inner | epoch 001:   3700 / 19564 loss=8.148, nll_loss=7.281, ppl=155.55, wps=14837.4, ups=4.4, wpb=3375.7, bsz=125.6, num_updates=3700, lr=0.0004625, gnorm=1.095, train_wall=23, wall=0
2024-07-18 12:15:40 | INFO | train_inner | epoch 001:   3800 / 19564 loss=8.061, nll_loss=7.182, ppl=145.23, wps=14628.9, ups=4.38, wpb=3341.5, bsz=138.2, num_updates=3800, lr=0.000475, gnorm=1.099, train_wall=23, wall=0
2024-07-18 12:16:03 | INFO | train_inner | epoch 001:   3900 / 19564 loss=8.038, nll_loss=7.155, ppl=142.55, wps=14758.1, ups=4.35, wpb=3392.5, bsz=130.8, num_updates=3900, lr=0.0004875, gnorm=1.088, train_wall=23, wall=0
2024-07-18 12:16:26 | INFO | train_inner | epoch 001:   4000 / 19564 loss=7.933, nll_loss=7.034, ppl=131.06, wps=14930.6, ups=4.38, wpb=3411.4, bsz=162.5, num_updates=4000, lr=0.0005, gnorm=1.143, train_wall=23, wall=0
2024-07-18 12:16:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:16:29 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.41 | nll_loss 7.541 | ppl 186.23 | wps 44501.5 | wpb 2872.6 | bsz 51.2 | num_updates 4000 | best_loss 12.094
2024-07-18 12:16:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:16:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 8.41) (writing took 8.287276799790561 seconds)
2024-07-18 12:17:00 | INFO | train_inner | epoch 001:   4100 / 19564 loss=7.976, nll_loss=7.083, ppl=135.54, wps=10112.7, ups=2.94, wpb=3438.8, bsz=128.1, num_updates=4100, lr=0.000493865, gnorm=1.034, train_wall=23, wall=0
2024-07-18 12:17:23 | INFO | train_inner | epoch 001:   4200 / 19564 loss=7.953, nll_loss=7.055, ppl=133, wps=14990.6, ups=4.38, wpb=3421.6, bsz=120.7, num_updates=4200, lr=0.00048795, gnorm=1.049, train_wall=23, wall=0
2024-07-18 12:17:46 | INFO | train_inner | epoch 001:   4300 / 19564 loss=7.801, nll_loss=6.883, ppl=118.01, wps=15426.1, ups=4.38, wpb=3521.3, bsz=146.3, num_updates=4300, lr=0.000482243, gnorm=1.017, train_wall=23, wall=0
2024-07-18 12:18:09 | INFO | train_inner | epoch 001:   4400 / 19564 loss=7.814, nll_loss=6.895, ppl=119.05, wps=15117.5, ups=4.36, wpb=3463.8, bsz=132.4, num_updates=4400, lr=0.000476731, gnorm=1.023, train_wall=23, wall=0
2024-07-18 12:18:31 | INFO | train_inner | epoch 001:   4500 / 19564 loss=7.761, nll_loss=6.836, ppl=114.22, wps=14899.1, ups=4.41, wpb=3381.8, bsz=139.2, num_updates=4500, lr=0.000471405, gnorm=1.032, train_wall=23, wall=0
2024-07-18 12:18:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:18:34 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.132 | nll_loss 7.218 | ppl 148.84 | wps 44585.5 | wpb 2872.6 | bsz 51.2 | num_updates 4500 | best_loss 12.094
2024-07-18 12:18:34 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:18:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_4500.pt (epoch 1 @ 4500 updates, score 8.132) (writing took 3.9709387747570872 seconds)
2024-07-18 12:19:01 | INFO | train_inner | epoch 001:   4600 / 19564 loss=7.708, nll_loss=6.776, ppl=109.56, wps=11620.5, ups=3.33, wpb=3492.1, bsz=140.2, num_updates=4600, lr=0.000466252, gnorm=0.963, train_wall=23, wall=0
2024-07-18 12:19:24 | INFO | train_inner | epoch 001:   4700 / 19564 loss=7.681, nll_loss=6.744, ppl=107.16, wps=14916.3, ups=4.34, wpb=3438.3, bsz=140.8, num_updates=4700, lr=0.000461266, gnorm=1.013, train_wall=23, wall=0
2024-07-18 12:19:47 | INFO | train_inner | epoch 001:   4800 / 19564 loss=7.608, nll_loss=6.66, ppl=101.1, wps=15144.2, ups=4.32, wpb=3504.1, bsz=154.2, num_updates=4800, lr=0.000456435, gnorm=1.022, train_wall=23, wall=0
2024-07-18 12:20:11 | INFO | train_inner | epoch 001:   4900 / 19564 loss=7.545, nll_loss=6.587, ppl=96.14, wps=15252.6, ups=4.3, wpb=3547.3, bsz=136.9, num_updates=4900, lr=0.000451754, gnorm=0.968, train_wall=23, wall=0
2024-07-18 12:20:34 | INFO | train_inner | epoch 001:   5000 / 19564 loss=7.59, nll_loss=6.639, ppl=99.66, wps=15029.1, ups=4.33, wpb=3469, bsz=132.6, num_updates=5000, lr=0.000447214, gnorm=0.958, train_wall=23, wall=0
2024-07-18 12:20:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:20:37 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.099 | nll_loss 7.159 | ppl 142.94 | wps 44804.6 | wpb 2872.6 | bsz 51.2 | num_updates 5000 | best_loss 12.094
2024-07-18 12:20:37 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:20:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_5000.pt (epoch 1 @ 5000 updates, score 8.099) (writing took 5.856256337836385 seconds)
2024-07-18 12:21:05 | INFO | train_inner | epoch 001:   5100 / 19564 loss=7.586, nll_loss=6.634, ppl=99.29, wps=10953.5, ups=3.17, wpb=3455.8, bsz=127.3, num_updates=5100, lr=0.000442807, gnorm=0.983, train_wall=23, wall=0
2024-07-18 12:21:28 | INFO | train_inner | epoch 001:   5200 / 19564 loss=7.552, nll_loss=6.595, ppl=96.67, wps=14727.5, ups=4.36, wpb=3378.8, bsz=142.3, num_updates=5200, lr=0.000438529, gnorm=1.004, train_wall=23, wall=0
2024-07-18 12:21:51 | INFO | train_inner | epoch 001:   5300 / 19564 loss=7.378, nll_loss=6.396, ppl=84.22, wps=14998, ups=4.32, wpb=3471.3, bsz=150.4, num_updates=5300, lr=0.000434372, gnorm=0.935, train_wall=23, wall=0
2024-07-18 12:22:14 | INFO | train_inner | epoch 001:   5400 / 19564 loss=7.441, nll_loss=6.468, ppl=88.51, wps=14957.1, ups=4.35, wpb=3436, bsz=134.6, num_updates=5400, lr=0.000430331, gnorm=0.956, train_wall=23, wall=0
2024-07-18 12:22:38 | INFO | train_inner | epoch 001:   5500 / 19564 loss=7.447, nll_loss=6.474, ppl=88.87, wps=14810.9, ups=4.32, wpb=3428.4, bsz=132.5, num_updates=5500, lr=0.000426401, gnorm=0.984, train_wall=23, wall=0
2024-07-18 12:22:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:22:40 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.929 | nll_loss 6.979 | ppl 126.18 | wps 45025.7 | wpb 2872.6 | bsz 51.2 | num_updates 5500 | best_loss 12.094
2024-07-18 12:22:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:22:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_5500.pt (epoch 1 @ 5500 updates, score 7.929) (writing took 5.126223258674145 seconds)
2024-07-18 12:23:08 | INFO | train_inner | epoch 001:   5600 / 19564 loss=7.416, nll_loss=6.438, ppl=86.7, wps=11052.5, ups=3.24, wpb=3415.3, bsz=149.5, num_updates=5600, lr=0.000422577, gnorm=1.022, train_wall=23, wall=0
2024-07-18 12:23:31 | INFO | train_inner | epoch 001:   5700 / 19564 loss=7.351, nll_loss=6.363, ppl=82.31, wps=15407, ups=4.36, wpb=3534.9, bsz=143.6, num_updates=5700, lr=0.000418854, gnorm=0.927, train_wall=23, wall=0
2024-07-18 12:23:54 | INFO | train_inner | epoch 001:   5800 / 19564 loss=7.314, nll_loss=6.321, ppl=79.93, wps=15203.4, ups=4.35, wpb=3496.3, bsz=145, num_updates=5800, lr=0.000415227, gnorm=0.937, train_wall=23, wall=0
2024-07-18 12:24:18 | INFO | train_inner | epoch 001:   5900 / 19564 loss=7.294, nll_loss=6.299, ppl=78.72, wps=14968, ups=4.31, wpb=3469.8, bsz=154.8, num_updates=5900, lr=0.000411693, gnorm=0.968, train_wall=23, wall=0
2024-07-18 12:24:41 | INFO | train_inner | epoch 001:   6000 / 19564 loss=7.287, nll_loss=6.29, ppl=78.27, wps=14873.9, ups=4.34, wpb=3428.1, bsz=143.4, num_updates=6000, lr=0.000408248, gnorm=0.965, train_wall=23, wall=0
2024-07-18 12:24:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:24:44 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.836 | nll_loss 6.86 | ppl 116.17 | wps 44876.8 | wpb 2872.6 | bsz 51.2 | num_updates 6000 | best_loss 12.094
2024-07-18 12:24:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:24:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 7.836) (writing took 4.818853288888931 seconds)
2024-07-18 12:25:11 | INFO | train_inner | epoch 001:   6100 / 19564 loss=7.201, nll_loss=6.192, ppl=73.1, wps=11287.9, ups=3.25, wpb=3470.6, bsz=163.8, num_updates=6100, lr=0.000404888, gnorm=0.953, train_wall=23, wall=0
2024-07-18 12:25:34 | INFO | train_inner | epoch 001:   6200 / 19564 loss=7.231, nll_loss=6.224, ppl=74.78, wps=15021.2, ups=4.36, wpb=3448.4, bsz=133.8, num_updates=6200, lr=0.00040161, gnorm=0.948, train_wall=23, wall=0
2024-07-18 12:25:57 | INFO | train_inner | epoch 001:   6300 / 19564 loss=7.14, nll_loss=6.121, ppl=69.59, wps=14969.9, ups=4.37, wpb=3427.9, bsz=147.8, num_updates=6300, lr=0.00039841, gnorm=0.974, train_wall=23, wall=0
2024-07-18 12:26:20 | INFO | train_inner | epoch 001:   6400 / 19564 loss=7.205, nll_loss=6.194, ppl=73.21, wps=14794.8, ups=4.39, wpb=3370.9, bsz=135, num_updates=6400, lr=0.000395285, gnorm=1.002, train_wall=23, wall=0
2024-07-18 12:26:43 | INFO | train_inner | epoch 001:   6500 / 19564 loss=7.162, nll_loss=6.145, ppl=70.77, wps=15016.2, ups=4.39, wpb=3423.7, bsz=130.3, num_updates=6500, lr=0.000392232, gnorm=0.976, train_wall=23, wall=0
2024-07-18 12:26:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:26:46 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.755 | nll_loss 6.769 | ppl 109.06 | wps 44826.3 | wpb 2872.6 | bsz 51.2 | num_updates 6500 | best_loss 12.094
2024-07-18 12:26:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:26:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_6500.pt (epoch 1 @ 6500 updates, score 7.755) (writing took 4.770152946002781 seconds)
2024-07-18 12:27:14 | INFO | train_inner | epoch 001:   6600 / 19564 loss=7.072, nll_loss=6.041, ppl=65.85, wps=11222.5, ups=3.25, wpb=3456.9, bsz=150.5, num_updates=6600, lr=0.000389249, gnorm=0.984, train_wall=23, wall=0
2024-07-18 12:27:37 | INFO | train_inner | epoch 001:   6700 / 19564 loss=7.03, nll_loss=5.994, ppl=63.72, wps=14849.2, ups=4.29, wpb=3460.6, bsz=146.6, num_updates=6700, lr=0.000386334, gnorm=0.945, train_wall=23, wall=0
2024-07-18 12:28:00 | INFO | train_inner | epoch 001:   6800 / 19564 loss=7.054, nll_loss=6.021, ppl=64.95, wps=14901.2, ups=4.38, wpb=3400, bsz=145.2, num_updates=6800, lr=0.000383482, gnorm=1.011, train_wall=23, wall=0
2024-07-18 12:28:23 | INFO | train_inner | epoch 001:   6900 / 19564 loss=7.039, nll_loss=6.003, ppl=64.13, wps=15111.1, ups=4.32, wpb=3501.9, bsz=132.8, num_updates=6900, lr=0.000380693, gnorm=0.946, train_wall=23, wall=0
2024-07-18 12:28:46 | INFO | train_inner | epoch 001:   7000 / 19564 loss=7.019, nll_loss=5.98, ppl=63.14, wps=14826.1, ups=4.34, wpb=3414.3, bsz=133, num_updates=7000, lr=0.000377964, gnorm=1.041, train_wall=23, wall=0
2024-07-18 12:28:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:28:49 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.554 | nll_loss 6.532 | ppl 92.55 | wps 44769.5 | wpb 2872.6 | bsz 51.2 | num_updates 7000 | best_loss 12.094
2024-07-18 12:28:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:28:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_7000.pt (epoch 1 @ 7000 updates, score 7.554) (writing took 4.653070697560906 seconds)
2024-07-18 12:29:16 | INFO | train_inner | epoch 001:   7100 / 19564 loss=7.023, nll_loss=5.984, ppl=63.3, wps=11192.2, ups=3.31, wpb=3384.2, bsz=126.8, num_updates=7100, lr=0.000375293, gnorm=1.002, train_wall=23, wall=0
2024-07-18 12:29:40 | INFO | train_inner | epoch 001:   7200 / 19564 loss=6.951, nll_loss=5.902, ppl=59.79, wps=14463.7, ups=4.19, wpb=3453.7, bsz=132.5, num_updates=7200, lr=0.000372678, gnorm=1.022, train_wall=24, wall=0
2024-07-18 12:30:03 | INFO | train_inner | epoch 001:   7300 / 19564 loss=6.936, nll_loss=5.885, ppl=59.08, wps=14808.8, ups=4.37, wpb=3389.7, bsz=127.6, num_updates=7300, lr=0.000370117, gnorm=1.033, train_wall=23, wall=0
2024-07-18 12:30:26 | INFO | train_inner | epoch 001:   7400 / 19564 loss=6.854, nll_loss=5.793, ppl=55.43, wps=14599.7, ups=4.26, wpb=3429.9, bsz=143.8, num_updates=7400, lr=0.000367607, gnorm=1.028, train_wall=23, wall=0
2024-07-18 12:30:49 | INFO | train_inner | epoch 001:   7500 / 19564 loss=6.876, nll_loss=5.815, ppl=56.3, wps=15020.7, ups=4.36, wpb=3443.2, bsz=151.7, num_updates=7500, lr=0.000365148, gnorm=1.096, train_wall=23, wall=0
2024-07-18 12:30:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:30:52 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.373 | nll_loss 6.329 | ppl 80.4 | wps 44512.1 | wpb 2872.6 | bsz 51.2 | num_updates 7500 | best_loss 12.094
2024-07-18 12:30:52 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:30:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_7500.pt (epoch 1 @ 7500 updates, score 7.373) (writing took 4.1863701259717345 seconds)
2024-07-18 12:31:19 | INFO | train_inner | epoch 001:   7600 / 19564 loss=6.75, nll_loss=5.67, ppl=50.92, wps=11492.2, ups=3.33, wpb=3446.7, bsz=142.3, num_updates=7600, lr=0.000362738, gnorm=1.014, train_wall=23, wall=0
2024-07-18 12:31:43 | INFO | train_inner | epoch 001:   7700 / 19564 loss=6.85, nll_loss=5.784, ppl=55.12, wps=14851.3, ups=4.28, wpb=3466.6, bsz=136.2, num_updates=7700, lr=0.000360375, gnorm=1.066, train_wall=23, wall=0
2024-07-18 12:32:06 | INFO | train_inner | epoch 001:   7800 / 19564 loss=6.64, nll_loss=5.544, ppl=46.64, wps=15092.2, ups=4.33, wpb=3489.4, bsz=158.5, num_updates=7800, lr=0.000358057, gnorm=1.046, train_wall=23, wall=0
2024-07-18 12:32:29 | INFO | train_inner | epoch 001:   7900 / 19564 loss=6.662, nll_loss=5.569, ppl=47.46, wps=14875.5, ups=4.35, wpb=3422.8, bsz=147.4, num_updates=7900, lr=0.000355784, gnorm=1.093, train_wall=23, wall=0
2024-07-18 12:32:52 | INFO | train_inner | epoch 001:   8000 / 19564 loss=6.699, nll_loss=5.611, ppl=48.87, wps=14742.8, ups=4.39, wpb=3354.8, bsz=141, num_updates=8000, lr=0.000353553, gnorm=1.094, train_wall=23, wall=0
2024-07-18 12:32:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:32:54 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.257 | nll_loss 6.191 | ppl 73.06 | wps 44839.2 | wpb 2872.6 | bsz 51.2 | num_updates 8000 | best_loss 12.094
2024-07-18 12:32:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:32:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 7.257) (writing took 4.182560213841498 seconds)
2024-07-18 12:33:22 | INFO | train_inner | epoch 001:   8100 / 19564 loss=6.652, nll_loss=5.557, ppl=47.08, wps=11610.3, ups=3.33, wpb=3490.7, bsz=146, num_updates=8100, lr=0.000351364, gnorm=1.054, train_wall=23, wall=0
2024-07-18 12:33:45 | INFO | train_inner | epoch 001:   8200 / 19564 loss=6.644, nll_loss=5.548, ppl=46.78, wps=14832.8, ups=4.35, wpb=3408.7, bsz=137.4, num_updates=8200, lr=0.000349215, gnorm=1.065, train_wall=23, wall=0
2024-07-18 12:34:08 | INFO | train_inner | epoch 001:   8300 / 19564 loss=6.554, nll_loss=5.444, ppl=43.53, wps=15025.6, ups=4.3, wpb=3491.9, bsz=143, num_updates=8300, lr=0.000347105, gnorm=1.073, train_wall=23, wall=0
2024-07-18 12:34:32 | INFO | train_inner | epoch 001:   8400 / 19564 loss=6.516, nll_loss=5.4, ppl=42.24, wps=15055.7, ups=4.23, wpb=3563.4, bsz=151.5, num_updates=8400, lr=0.000345033, gnorm=1.095, train_wall=23, wall=0
2024-07-18 12:34:55 | INFO | train_inner | epoch 001:   8500 / 19564 loss=6.5, nll_loss=5.383, ppl=41.72, wps=14840.4, ups=4.35, wpb=3412.6, bsz=156.9, num_updates=8500, lr=0.000342997, gnorm=1.11, train_wall=23, wall=0
2024-07-18 12:34:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:34:57 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.057 | nll_loss 5.949 | ppl 61.8 | wps 45198.3 | wpb 2872.6 | bsz 51.2 | num_updates 8500 | best_loss 12.094
2024-07-18 12:34:57 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:35:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_8500.pt (epoch 1 @ 8500 updates, score 7.057) (writing took 4.287753158248961 seconds)
2024-07-18 12:35:25 | INFO | train_inner | epoch 001:   8600 / 19564 loss=6.422, nll_loss=5.293, ppl=39.2, wps=11553, ups=3.29, wpb=3513.1, bsz=157.5, num_updates=8600, lr=0.000340997, gnorm=1.103, train_wall=23, wall=0
2024-07-18 12:35:48 | INFO | train_inner | epoch 001:   8700 / 19564 loss=6.486, nll_loss=5.366, ppl=41.25, wps=14872.7, ups=4.34, wpb=3423.1, bsz=149.6, num_updates=8700, lr=0.000339032, gnorm=1.139, train_wall=23, wall=0
2024-07-18 12:36:11 | INFO | train_inner | epoch 001:   8800 / 19564 loss=6.424, nll_loss=5.295, ppl=39.25, wps=14943.9, ups=4.29, wpb=3480, bsz=151.8, num_updates=8800, lr=0.0003371, gnorm=1.131, train_wall=23, wall=0
2024-07-18 12:36:35 | INFO | train_inner | epoch 001:   8900 / 19564 loss=6.438, nll_loss=5.311, ppl=39.69, wps=15032.1, ups=4.3, wpb=3494.8, bsz=142.5, num_updates=8900, lr=0.000335201, gnorm=1.161, train_wall=23, wall=0
2024-07-18 12:36:58 | INFO | train_inner | epoch 001:   9000 / 19564 loss=6.383, nll_loss=5.248, ppl=38.01, wps=15054.3, ups=4.31, wpb=3492.3, bsz=140.2, num_updates=9000, lr=0.000333333, gnorm=1.085, train_wall=23, wall=0
2024-07-18 12:36:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:37:01 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.907 | nll_loss 5.783 | ppl 55.06 | wps 44809.4 | wpb 2872.6 | bsz 51.2 | num_updates 9000 | best_loss 12.094
2024-07-18 12:37:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:37:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_9000.pt (epoch 1 @ 9000 updates, score 6.907) (writing took 4.92010383028537 seconds)
2024-07-18 12:37:28 | INFO | train_inner | epoch 001:   9100 / 19564 loss=6.461, nll_loss=5.337, ppl=40.43, wps=10960, ups=3.27, wpb=3348.3, bsz=146.9, num_updates=9100, lr=0.000331497, gnorm=1.152, train_wall=23, wall=0
2024-07-18 12:37:51 | INFO | train_inner | epoch 001:   9200 / 19564 loss=6.45, nll_loss=5.325, ppl=40.08, wps=14819.9, ups=4.37, wpb=3392.5, bsz=135.1, num_updates=9200, lr=0.00032969, gnorm=1.174, train_wall=23, wall=0
2024-07-18 12:38:14 | INFO | train_inner | epoch 001:   9300 / 19564 loss=6.373, nll_loss=5.236, ppl=37.69, wps=14917.7, ups=4.33, wpb=3446.4, bsz=133.7, num_updates=9300, lr=0.000327913, gnorm=1.109, train_wall=23, wall=0
2024-07-18 12:38:38 | INFO | train_inner | epoch 001:   9400 / 19564 loss=6.265, nll_loss=5.112, ppl=34.58, wps=15206.9, ups=4.3, wpb=3532.6, bsz=149.8, num_updates=9400, lr=0.000326164, gnorm=1.116, train_wall=23, wall=0
2024-07-18 12:39:00 | INFO | train_inner | epoch 001:   9500 / 19564 loss=6.334, nll_loss=5.191, ppl=36.54, wps=14967.4, ups=4.36, wpb=3431.6, bsz=127.5, num_updates=9500, lr=0.000324443, gnorm=1.146, train_wall=23, wall=0
2024-07-18 12:39:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:39:03 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.852 | nll_loss 5.711 | ppl 52.38 | wps 44820.4 | wpb 2872.6 | bsz 51.2 | num_updates 9500 | best_loss 12.094
2024-07-18 12:39:03 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:39:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_9500.pt (epoch 1 @ 9500 updates, score 6.852) (writing took 4.81028803717345 seconds)
2024-07-18 12:39:31 | INFO | train_inner | epoch 001:   9600 / 19564 loss=6.295, nll_loss=5.147, ppl=35.44, wps=11197.5, ups=3.27, wpb=3428.9, bsz=137.1, num_updates=9600, lr=0.000322749, gnorm=1.177, train_wall=23, wall=0
2024-07-18 12:39:54 | INFO | train_inner | epoch 001:   9700 / 19564 loss=6.244, nll_loss=5.088, ppl=34.02, wps=14817.5, ups=4.35, wpb=3408, bsz=147.2, num_updates=9700, lr=0.000321081, gnorm=1.171, train_wall=23, wall=0
2024-07-18 12:40:17 | INFO | train_inner | epoch 001:   9800 / 19564 loss=6.277, nll_loss=5.126, ppl=34.92, wps=14820.7, ups=4.34, wpb=3411.9, bsz=132.9, num_updates=9800, lr=0.000319438, gnorm=1.213, train_wall=23, wall=0
2024-07-18 12:40:40 | INFO | train_inner | epoch 001:   9900 / 19564 loss=6.18, nll_loss=5.014, ppl=32.3, wps=14960.9, ups=4.31, wpb=3474.1, bsz=140.2, num_updates=9900, lr=0.000317821, gnorm=1.136, train_wall=23, wall=0
2024-07-18 12:41:04 | INFO | train_inner | epoch 001:  10000 / 19564 loss=6.116, nll_loss=4.94, ppl=30.69, wps=14967, ups=4.25, wpb=3524.8, bsz=151.4, num_updates=10000, lr=0.000316228, gnorm=1.192, train_wall=23, wall=0
2024-07-18 12:41:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:41:07 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.747 | nll_loss 5.593 | ppl 48.26 | wps 44873.1 | wpb 2872.6 | bsz 51.2 | num_updates 10000 | best_loss 12.094
2024-07-18 12:41:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:41:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score 6.747) (writing took 10.269096383824944 seconds)
2024-07-18 12:41:17 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-18 12:41:17 | INFO | train | epoch 001 | loss 7.866 | nll_loss 6.963 | ppl 124.73 | wps 13562.5 | ups 3.94 | wpb 3445.6 | bsz 142.1 | num_updates 10000 | lr 0.000316228 | gnorm 1.153 | train_wall 2283 | wall 0
2024-07-18 12:41:17 | INFO | fairseq_cli.train | done training in 2218.5 seconds
2024-07-18 12:41:20 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt22.sep.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=100000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=1000, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-18 12:41:20 | INFO | fairseq.tasks.translation | [de] dictionary: 9968 types
2024-07-18 12:41:20 | INFO | fairseq.tasks.translation | [en] dictionary: 9968 types
2024-07-18 12:41:20 | INFO | fairseq.data.data_utils | loaded 2203 examples from: data-bin/wmt22.sep.tokenized.de-en/valid.de-en.de
2024-07-18 12:41:20 | INFO | fairseq.data.data_utils | loaded 2203 examples from: data-bin/wmt22.sep.tokenized.de-en/valid.de-en.en
2024-07-18 12:41:20 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.de-en valid de-en 2203 examples
2024-07-18 12:41:21 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9968, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9968, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=9968, bias=False)
  )
)
2024-07-18 12:41:21 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-18 12:41:21 | INFO | fairseq_cli.train | model: transformer_wmt_en_de (TransformerModel)
2024-07-18 12:41:21 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-18 12:41:21 | INFO | fairseq_cli.train | num. model params: 54345728 (num. trained: 54345728)
2024-07-18 12:41:26 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-18 12:41:26 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-18 12:41:26 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-18 12:41:26 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-18 12:41:26 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-18 12:41:26 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-18 12:41:28 | INFO | fairseq.trainer | loaded checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 10000 updates)
2024-07-18 12:41:28 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-18 12:41:28 | INFO | fairseq.data.data_utils | loaded 2782552 examples from: data-bin/wmt22.sep.tokenized.de-en/train.de-en.de
2024-07-18 12:41:28 | INFO | fairseq.data.data_utils | loaded 2782552 examples from: data-bin/wmt22.sep.tokenized.de-en/train.de-en.en
2024-07-18 12:41:28 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.de-en train de-en 2782552 examples
2024-07-18 12:41:31 | INFO | fairseq.trainer | begin training epoch 1
2024-07-18 12:41:54 | INFO | train_inner | epoch 001:  10100 / 19564 loss=6.185, nll_loss=5.02, ppl=32.44, wps=11887.4, ups=3.47, wpb=3421.2, bsz=143.8, num_updates=10100, lr=0.000314658, gnorm=1.146, train_wall=23, wall=0
2024-07-18 12:42:16 | INFO | train_inner | epoch 001:  10200 / 19564 loss=6.123, nll_loss=4.949, ppl=30.89, wps=15107.6, ups=4.42, wpb=3420.4, bsz=132.2, num_updates=10200, lr=0.000313112, gnorm=1.155, train_wall=22, wall=0
2024-07-18 12:42:39 | INFO | train_inner | epoch 001:  10300 / 19564 loss=6.186, nll_loss=5.021, ppl=32.46, wps=15005.4, ups=4.34, wpb=3458.6, bsz=138.9, num_updates=10300, lr=0.000311588, gnorm=1.162, train_wall=23, wall=0
2024-07-18 12:43:02 | INFO | train_inner | epoch 001:  10400 / 19564 loss=6.091, nll_loss=4.913, ppl=30.12, wps=14932.7, ups=4.36, wpb=3423.8, bsz=141.6, num_updates=10400, lr=0.000310087, gnorm=1.2, train_wall=23, wall=0
2024-07-18 12:43:25 | INFO | train_inner | epoch 001:  10500 / 19564 loss=6.136, nll_loss=4.964, ppl=31.21, wps=14881.5, ups=4.43, wpb=3359.4, bsz=142.2, num_updates=10500, lr=0.000308607, gnorm=1.231, train_wall=22, wall=0
2024-07-18 12:43:48 | INFO | train_inner | epoch 001:  10600 / 19564 loss=6.006, nll_loss=4.815, ppl=28.15, wps=15092.4, ups=4.37, wpb=3451.5, bsz=151, num_updates=10600, lr=0.000307148, gnorm=1.187, train_wall=23, wall=0
2024-07-18 12:44:11 | INFO | train_inner | epoch 001:  10700 / 19564 loss=6.059, nll_loss=4.875, ppl=29.34, wps=14645.9, ups=4.29, wpb=3416.7, bsz=133.4, num_updates=10700, lr=0.000305709, gnorm=1.193, train_wall=23, wall=0
2024-07-18 12:44:34 | INFO | train_inner | epoch 001:  10800 / 19564 loss=6.049, nll_loss=4.864, ppl=29.11, wps=14805.9, ups=4.32, wpb=3428.5, bsz=119.5, num_updates=10800, lr=0.00030429, gnorm=1.211, train_wall=23, wall=0
2024-07-18 12:44:57 | INFO | train_inner | epoch 001:  10900 / 19564 loss=5.908, nll_loss=4.701, ppl=26.02, wps=15078, ups=4.31, wpb=3500.4, bsz=150, num_updates=10900, lr=0.000302891, gnorm=1.168, train_wall=23, wall=0
2024-07-18 12:45:20 | INFO | train_inner | epoch 001:  11000 / 19564 loss=5.982, nll_loss=4.787, ppl=27.61, wps=15132.2, ups=4.4, wpb=3438.7, bsz=141.5, num_updates=11000, lr=0.000301511, gnorm=1.249, train_wall=23, wall=0
2024-07-18 12:45:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-18 12:45:23 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.516 | nll_loss 5.328 | ppl 40.17 | wps 44601.4 | wpb 2872.6 | bsz 51.2 | num_updates 11000 | best_loss 12.094
2024-07-18 12:45:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:45:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_11000.pt (epoch 1 @ 11000 updates, score 6.516) (writing took 4.8560085985809565 seconds)
2024-07-18 12:45:51 | INFO | train_inner | epoch 001:  11100 / 19564 loss=5.9, nll_loss=4.692, ppl=25.85, wps=11311.2, ups=3.26, wpb=3470.3, bsz=144.4, num_updates=11100, lr=0.00030015, gnorm=1.204, train_wall=23, wall=0
2024-07-18 12:46:14 | INFO | train_inner | epoch 001:  11200 / 19564 loss=5.85, nll_loss=4.635, ppl=24.85, wps=14947.4, ups=4.33, wpb=3453.6, bsz=150, num_updates=11200, lr=0.000298807, gnorm=1.196, train_wall=23, wall=0
2024-07-18 12:46:37 | INFO | train_inner | epoch 001:  11300 / 19564 loss=5.85, nll_loss=4.635, ppl=24.84, wps=15087.1, ups=4.35, wpb=3469.5, bsz=148.2, num_updates=11300, lr=0.000297482, gnorm=1.219, train_wall=23, wall=0
2024-07-18 12:47:00 | INFO | train_inner | epoch 001:  11400 / 19564 loss=5.826, nll_loss=4.608, ppl=24.38, wps=15426.7, ups=4.38, wpb=3521.4, bsz=151.4, num_updates=11400, lr=0.000296174, gnorm=1.166, train_wall=23, wall=0
2024-07-18 12:47:23 | INFO | train_inner | epoch 001:  11500 / 19564 loss=5.866, nll_loss=4.654, ppl=25.18, wps=15084.9, ups=4.36, wpb=3456, bsz=138.8, num_updates=11500, lr=0.000294884, gnorm=1.226, train_wall=23, wall=0
2024-07-18 12:47:46 | INFO | train_inner | epoch 001:  11600 / 19564 loss=5.787, nll_loss=4.563, ppl=23.64, wps=14981.5, ups=4.36, wpb=3437.1, bsz=130.8, num_updates=11600, lr=0.00029361, gnorm=1.198, train_wall=23, wall=0
2024-07-18 12:48:08 | INFO | train_inner | epoch 001:  11700 / 19564 loss=5.782, nll_loss=4.557, ppl=23.54, wps=15158.9, ups=4.38, wpb=3463, bsz=147.7, num_updates=11700, lr=0.000292353, gnorm=1.248, train_wall=23, wall=0
2024-07-18 12:48:31 | INFO | train_inner | epoch 001:  11800 / 19564 loss=5.696, nll_loss=4.458, ppl=21.98, wps=15254.9, ups=4.33, wpb=3524.3, bsz=144.2, num_updates=11800, lr=0.000291111, gnorm=1.17, train_wall=23, wall=0
2024-07-18 12:48:54 | INFO | train_inner | epoch 001:  11900 / 19564 loss=5.713, nll_loss=4.479, ppl=22.3, wps=15222.3, ups=4.37, wpb=3485.5, bsz=150.2, num_updates=11900, lr=0.000289886, gnorm=1.209, train_wall=23, wall=0
2024-07-18 12:49:18 | INFO | train_inner | epoch 001:  12000 / 19564 loss=5.732, nll_loss=4.5, ppl=22.63, wps=15030.9, ups=4.3, wpb=3494.6, bsz=148.8, num_updates=12000, lr=0.000288675, gnorm=1.207, train_wall=23, wall=0
2024-07-18 12:49:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:49:20 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.186 | nll_loss 4.939 | ppl 30.68 | wps 44938.8 | wpb 2872.6 | bsz 51.2 | num_updates 12000 | best_loss 12.094
2024-07-18 12:49:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:49:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_12000.pt (epoch 1 @ 12000 updates, score 6.186) (writing took 4.425922982394695 seconds)
2024-07-18 12:49:48 | INFO | train_inner | epoch 001:  12100 / 19564 loss=5.668, nll_loss=4.428, ppl=21.53, wps=11338, ups=3.3, wpb=3435.5, bsz=139.9, num_updates=12100, lr=0.00028748, gnorm=1.206, train_wall=23, wall=0
2024-07-18 12:50:11 | INFO | train_inner | epoch 001:  12200 / 19564 loss=5.657, nll_loss=4.415, ppl=21.33, wps=15062.6, ups=4.35, wpb=3464.2, bsz=141.9, num_updates=12200, lr=0.000286299, gnorm=1.212, train_wall=23, wall=0
2024-07-18 12:50:34 | INFO | train_inner | epoch 001:  12300 / 19564 loss=5.579, nll_loss=4.324, ppl=20.03, wps=15175.3, ups=4.28, wpb=3548.5, bsz=162.3, num_updates=12300, lr=0.000285133, gnorm=1.183, train_wall=23, wall=0
2024-07-18 12:50:58 | INFO | train_inner | epoch 001:  12400 / 19564 loss=5.596, nll_loss=4.345, ppl=20.32, wps=14894.1, ups=4.3, wpb=3461.2, bsz=140.4, num_updates=12400, lr=0.000283981, gnorm=1.221, train_wall=23, wall=0
2024-07-18 12:51:20 | INFO | train_inner | epoch 001:  12500 / 19564 loss=5.575, nll_loss=4.321, ppl=19.98, wps=15252.9, ups=4.42, wpb=3453.3, bsz=160.8, num_updates=12500, lr=0.000282843, gnorm=1.204, train_wall=22, wall=0
2024-07-18 12:51:43 | INFO | train_inner | epoch 001:  12600 / 19564 loss=5.542, nll_loss=4.283, ppl=19.47, wps=15166.9, ups=4.35, wpb=3489.3, bsz=153.6, num_updates=12600, lr=0.000281718, gnorm=1.209, train_wall=23, wall=0
2024-07-18 12:52:06 | INFO | train_inner | epoch 001:  12700 / 19564 loss=5.571, nll_loss=4.317, ppl=19.94, wps=14740.9, ups=4.39, wpb=3360.9, bsz=152.8, num_updates=12700, lr=0.000280607, gnorm=1.323, train_wall=23, wall=0
2024-07-18 12:52:29 | INFO | train_inner | epoch 001:  12800 / 19564 loss=5.561, nll_loss=4.305, ppl=19.77, wps=15068.2, ups=4.37, wpb=3451.1, bsz=159.3, num_updates=12800, lr=0.000279508, gnorm=1.233, train_wall=23, wall=0
2024-07-18 12:52:52 | INFO | train_inner | epoch 001:  12900 / 19564 loss=5.53, nll_loss=4.27, ppl=19.3, wps=14900.9, ups=4.36, wpb=3414.2, bsz=157, num_updates=12900, lr=0.000278423, gnorm=1.222, train_wall=23, wall=0
2024-07-18 12:53:14 | INFO | train_inner | epoch 001:  13000 / 19564 loss=5.571, nll_loss=4.316, ppl=19.92, wps=15052.5, ups=4.42, wpb=3409.3, bsz=130.8, num_updates=13000, lr=0.00027735, gnorm=1.202, train_wall=22, wall=0
2024-07-18 12:53:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:53:17 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6 | nll_loss 4.72 | ppl 26.36 | wps 44653.9 | wpb 2872.6 | bsz 51.2 | num_updates 13000 | best_loss 12.094
2024-07-18 12:53:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:53:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_13000.pt (epoch 1 @ 13000 updates, score 6.0) (writing took 4.312645066529512 seconds)
2024-07-18 12:53:45 | INFO | train_inner | epoch 001:  13100 / 19564 loss=5.499, nll_loss=4.235, ppl=18.83, wps=11297.7, ups=3.31, wpb=3410.9, bsz=141, num_updates=13100, lr=0.000276289, gnorm=1.226, train_wall=23, wall=0
2024-07-18 12:54:08 | INFO | train_inner | epoch 001:  13200 / 19564 loss=5.449, nll_loss=4.176, ppl=18.07, wps=14944.6, ups=4.23, wpb=3531.6, bsz=147.7, num_updates=13200, lr=0.000275241, gnorm=1.216, train_wall=23, wall=0
2024-07-18 12:54:31 | INFO | train_inner | epoch 001:  13300 / 19564 loss=5.424, nll_loss=4.148, ppl=17.73, wps=14919.3, ups=4.31, wpb=3462.9, bsz=159.8, num_updates=13300, lr=0.000274204, gnorm=1.221, train_wall=23, wall=0
2024-07-18 12:54:54 | INFO | train_inner | epoch 001:  13400 / 19564 loss=5.546, nll_loss=4.288, ppl=19.54, wps=14981.9, ups=4.37, wpb=3427.9, bsz=127.6, num_updates=13400, lr=0.000273179, gnorm=1.222, train_wall=23, wall=0
2024-07-18 12:55:17 | INFO | train_inner | epoch 001:  13500 / 19564 loss=5.424, nll_loss=4.149, ppl=17.74, wps=14929.9, ups=4.36, wpb=3426.7, bsz=153.8, num_updates=13500, lr=0.000272166, gnorm=1.231, train_wall=23, wall=0
2024-07-18 12:55:40 | INFO | train_inner | epoch 001:  13600 / 19564 loss=5.501, nll_loss=4.238, ppl=18.87, wps=14578.7, ups=4.38, wpb=3327.7, bsz=148.2, num_updates=13600, lr=0.000271163, gnorm=1.24, train_wall=23, wall=0
2024-07-18 12:56:03 | INFO | train_inner | epoch 001:  13700 / 19564 loss=5.479, nll_loss=4.211, ppl=18.52, wps=15062.1, ups=4.38, wpb=3440.5, bsz=135.8, num_updates=13700, lr=0.000270172, gnorm=1.197, train_wall=23, wall=0
2024-07-18 12:56:26 | INFO | train_inner | epoch 001:  13800 / 19564 loss=5.463, nll_loss=4.194, ppl=18.3, wps=15025.9, ups=4.38, wpb=3433.5, bsz=140.6, num_updates=13800, lr=0.000269191, gnorm=1.238, train_wall=23, wall=0
2024-07-18 12:56:49 | INFO | train_inner | epoch 001:  13900 / 19564 loss=5.398, nll_loss=4.119, ppl=17.38, wps=14959.5, ups=4.41, wpb=3395.4, bsz=147, num_updates=13900, lr=0.000268221, gnorm=1.215, train_wall=23, wall=0
2024-07-18 12:57:11 | INFO | train_inner | epoch 001:  14000 / 19564 loss=5.444, nll_loss=4.173, ppl=18.04, wps=14976.7, ups=4.36, wpb=3434.8, bsz=143.6, num_updates=14000, lr=0.000267261, gnorm=1.197, train_wall=23, wall=0
2024-07-18 12:57:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:57:14 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.846 | nll_loss 4.539 | ppl 23.24 | wps 44817.5 | wpb 2872.6 | bsz 51.2 | num_updates 14000 | best_loss 12.094
2024-07-18 12:57:14 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:57:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_14000.pt (epoch 1 @ 14000 updates, score 5.846) (writing took 4.308767655864358 seconds)
2024-07-18 12:57:42 | INFO | train_inner | epoch 001:  14100 / 19564 loss=5.411, nll_loss=4.133, ppl=17.55, wps=11498.9, ups=3.32, wpb=3462, bsz=135.2, num_updates=14100, lr=0.000266312, gnorm=1.202, train_wall=23, wall=0
2024-07-18 12:58:04 | INFO | train_inner | epoch 001:  14200 / 19564 loss=5.394, nll_loss=4.116, ppl=17.33, wps=15140.4, ups=4.37, wpb=3464.1, bsz=145.9, num_updates=14200, lr=0.000265372, gnorm=1.24, train_wall=23, wall=0
2024-07-18 12:58:27 | INFO | train_inner | epoch 001:  14300 / 19564 loss=5.379, nll_loss=4.098, ppl=17.12, wps=14689.3, ups=4.36, wpb=3368, bsz=141.1, num_updates=14300, lr=0.000264443, gnorm=1.244, train_wall=23, wall=0
2024-07-18 12:58:51 | INFO | train_inner | epoch 001:  14400 / 19564 loss=5.348, nll_loss=4.062, ppl=16.71, wps=14668.5, ups=4.27, wpb=3437.4, bsz=144.2, num_updates=14400, lr=0.000263523, gnorm=1.18, train_wall=23, wall=0
2024-07-18 12:59:14 | INFO | train_inner | epoch 001:  14500 / 19564 loss=5.358, nll_loss=4.074, ppl=16.85, wps=14768.1, ups=4.33, wpb=3408.2, bsz=142.5, num_updates=14500, lr=0.000262613, gnorm=1.217, train_wall=23, wall=0
2024-07-18 12:59:37 | INFO | train_inner | epoch 001:  14600 / 19564 loss=5.407, nll_loss=4.131, ppl=17.52, wps=15005.1, ups=4.39, wpb=3421.9, bsz=131.1, num_updates=14600, lr=0.000261712, gnorm=1.207, train_wall=23, wall=0
2024-07-18 13:00:00 | INFO | train_inner | epoch 001:  14700 / 19564 loss=5.36, nll_loss=4.077, ppl=16.87, wps=14809.2, ups=4.34, wpb=3415.7, bsz=134.3, num_updates=14700, lr=0.00026082, gnorm=1.227, train_wall=23, wall=0
2024-07-18 13:00:23 | INFO | train_inner | epoch 001:  14800 / 19564 loss=5.239, nll_loss=3.939, ppl=15.33, wps=15111.1, ups=4.36, wpb=3463.8, bsz=158.6, num_updates=14800, lr=0.000259938, gnorm=1.165, train_wall=23, wall=0
2024-07-18 13:00:46 | INFO | train_inner | epoch 001:  14900 / 19564 loss=5.267, nll_loss=3.97, ppl=15.67, wps=14784.6, ups=4.33, wpb=3414.4, bsz=142.2, num_updates=14900, lr=0.000259064, gnorm=1.182, train_wall=23, wall=0
2024-07-18 13:01:09 | INFO | train_inner | epoch 001:  15000 / 19564 loss=5.297, nll_loss=4.005, ppl=16.05, wps=15119.9, ups=4.3, wpb=3517.2, bsz=141.4, num_updates=15000, lr=0.000258199, gnorm=1.179, train_wall=23, wall=0
2024-07-18 13:01:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:01:12 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.706 | nll_loss 4.376 | ppl 20.77 | wps 44432.3 | wpb 2872.6 | bsz 51.2 | num_updates 15000 | best_loss 12.094
2024-07-18 13:01:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:01:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_15000.pt (epoch 1 @ 15000 updates, score 5.706) (writing took 7.236804373562336 seconds)
2024-07-18 13:01:42 | INFO | train_inner | epoch 001:  15100 / 19564 loss=5.265, nll_loss=3.969, ppl=15.66, wps=10295.6, ups=3.02, wpb=3408.4, bsz=155.4, num_updates=15100, lr=0.000257343, gnorm=1.208, train_wall=23, wall=0
2024-07-18 13:02:05 | INFO | train_inner | epoch 001:  15200 / 19564 loss=5.388, nll_loss=4.111, ppl=17.28, wps=14960.4, ups=4.37, wpb=3421.7, bsz=131.3, num_updates=15200, lr=0.000256495, gnorm=1.247, train_wall=23, wall=0
2024-07-18 13:02:28 | INFO | train_inner | epoch 001:  15300 / 19564 loss=5.316, nll_loss=4.026, ppl=16.29, wps=15196.5, ups=4.34, wpb=3502.3, bsz=130.8, num_updates=15300, lr=0.000255655, gnorm=1.173, train_wall=23, wall=0
2024-07-18 13:02:51 | INFO | train_inner | epoch 001:  15400 / 19564 loss=5.162, nll_loss=3.851, ppl=14.43, wps=15284, ups=4.35, wpb=3511.8, bsz=175.4, num_updates=15400, lr=0.000254824, gnorm=1.171, train_wall=23, wall=0
2024-07-18 13:03:14 | INFO | train_inner | epoch 001:  15500 / 19564 loss=5.219, nll_loss=3.916, ppl=15.09, wps=14988.5, ups=4.3, wpb=3481.9, bsz=152.6, num_updates=15500, lr=0.000254, gnorm=1.184, train_wall=23, wall=0
2024-07-18 13:03:37 | INFO | train_inner | epoch 001:  15600 / 19564 loss=5.249, nll_loss=3.951, ppl=15.47, wps=15396.9, ups=4.32, wpb=3562.3, bsz=141.1, num_updates=15600, lr=0.000253185, gnorm=1.171, train_wall=23, wall=0
2024-07-18 13:04:00 | INFO | train_inner | epoch 001:  15700 / 19564 loss=5.257, nll_loss=3.959, ppl=15.56, wps=15099.3, ups=4.33, wpb=3484.5, bsz=141, num_updates=15700, lr=0.000252377, gnorm=1.194, train_wall=23, wall=0
2024-07-18 13:04:24 | INFO | train_inner | epoch 001:  15800 / 19564 loss=5.236, nll_loss=3.937, ppl=15.31, wps=15127.4, ups=4.34, wpb=3485, bsz=128.7, num_updates=15800, lr=0.000251577, gnorm=1.185, train_wall=23, wall=0
2024-07-18 13:04:46 | INFO | train_inner | epoch 001:  15900 / 19564 loss=5.219, nll_loss=3.918, ppl=15.11, wps=15139.8, ups=4.35, wpb=3476.8, bsz=148.9, num_updates=15900, lr=0.000250785, gnorm=1.193, train_wall=23, wall=0
2024-07-18 13:05:10 | INFO | train_inner | epoch 001:  16000 / 19564 loss=5.154, nll_loss=3.842, ppl=14.34, wps=15119.6, ups=4.34, wpb=3487.4, bsz=147.9, num_updates=16000, lr=0.00025, gnorm=1.181, train_wall=23, wall=0
2024-07-18 13:05:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:05:12 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.557 | nll_loss 4.214 | ppl 18.56 | wps 44461.8 | wpb 2872.6 | bsz 51.2 | num_updates 16000 | best_loss 12.094
2024-07-18 13:05:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:05:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_16000.pt (epoch 1 @ 16000 updates, score 5.557) (writing took 4.179301476106048 seconds)
2024-07-18 13:05:40 | INFO | train_inner | epoch 001:  16100 / 19564 loss=5.202, nll_loss=3.898, ppl=14.91, wps=11390.8, ups=3.3, wpb=3450.6, bsz=126.9, num_updates=16100, lr=0.000249222, gnorm=1.194, train_wall=23, wall=0
2024-07-18 13:06:03 | INFO | train_inner | epoch 001:  16200 / 19564 loss=5.168, nll_loss=3.86, ppl=14.52, wps=15055, ups=4.37, wpb=3448.8, bsz=154.6, num_updates=16200, lr=0.000248452, gnorm=1.179, train_wall=23, wall=0
2024-07-18 13:06:26 | INFO | train_inner | epoch 001:  16300 / 19564 loss=5.263, nll_loss=3.968, ppl=15.65, wps=15091.1, ups=4.33, wpb=3483.6, bsz=140.9, num_updates=16300, lr=0.000247689, gnorm=1.206, train_wall=23, wall=0
2024-07-18 13:06:49 | INFO | train_inner | epoch 001:  16400 / 19564 loss=5.204, nll_loss=3.901, ppl=14.94, wps=14874.1, ups=4.36, wpb=3412.8, bsz=134, num_updates=16400, lr=0.000246932, gnorm=1.201, train_wall=23, wall=0
2024-07-18 13:07:12 | INFO | train_inner | epoch 001:  16500 / 19564 loss=5.166, nll_loss=3.858, ppl=14.5, wps=14937.5, ups=4.4, wpb=3397.6, bsz=150.4, num_updates=16500, lr=0.000246183, gnorm=1.202, train_wall=23, wall=0
2024-07-18 13:07:34 | INFO | train_inner | epoch 001:  16600 / 19564 loss=5.244, nll_loss=3.947, ppl=15.42, wps=14853.6, ups=4.38, wpb=3391.8, bsz=132.5, num_updates=16600, lr=0.00024544, gnorm=1.227, train_wall=23, wall=0
2024-07-18 13:07:57 | INFO | train_inner | epoch 001:  16700 / 19564 loss=5.167, nll_loss=3.858, ppl=14.5, wps=15113.5, ups=4.39, wpb=3444.4, bsz=140, num_updates=16700, lr=0.000244704, gnorm=1.194, train_wall=23, wall=0
2024-07-18 13:08:20 | INFO | train_inner | epoch 001:  16800 / 19564 loss=5.191, nll_loss=3.886, ppl=14.79, wps=15077.2, ups=4.36, wpb=3455.5, bsz=145, num_updates=16800, lr=0.000243975, gnorm=1.186, train_wall=23, wall=0
2024-07-18 13:08:43 | INFO | train_inner | epoch 001:  16900 / 19564 loss=5.183, nll_loss=3.877, ppl=14.69, wps=15024.6, ups=4.38, wpb=3430.1, bsz=132.7, num_updates=16900, lr=0.000243252, gnorm=1.19, train_wall=23, wall=0
2024-07-18 13:09:06 | INFO | train_inner | epoch 001:  17000 / 19564 loss=5.203, nll_loss=3.901, ppl=14.94, wps=15007.3, ups=4.37, wpb=3437.6, bsz=127, num_updates=17000, lr=0.000242536, gnorm=1.197, train_wall=23, wall=0
2024-07-18 13:09:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:09:09 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.442 | nll_loss 4.073 | ppl 16.83 | wps 44595.6 | wpb 2872.6 | bsz 51.2 | num_updates 17000 | best_loss 12.094
2024-07-18 13:09:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:09:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_17000.pt (epoch 1 @ 17000 updates, score 5.442) (writing took 4.550040361471474 seconds)
2024-07-18 13:09:36 | INFO | train_inner | epoch 001:  17100 / 19564 loss=5.155, nll_loss=3.845, ppl=14.37, wps=11340.2, ups=3.3, wpb=3434.7, bsz=133.3, num_updates=17100, lr=0.000241825, gnorm=1.172, train_wall=23, wall=0
2024-07-18 13:09:59 | INFO | train_inner | epoch 001:  17200 / 19564 loss=5.145, nll_loss=3.834, ppl=14.26, wps=15085.5, ups=4.36, wpb=3458.5, bsz=132.9, num_updates=17200, lr=0.000241121, gnorm=1.167, train_wall=23, wall=0
2024-07-18 13:10:22 | INFO | train_inner | epoch 001:  17300 / 19564 loss=5.056, nll_loss=3.732, ppl=13.29, wps=14959.1, ups=4.34, wpb=3444.1, bsz=152.3, num_updates=17300, lr=0.000240424, gnorm=1.172, train_wall=23, wall=0
2024-07-18 13:10:45 | INFO | train_inner | epoch 001:  17400 / 19564 loss=5.188, nll_loss=3.884, ppl=14.77, wps=14959.7, ups=4.39, wpb=3410.9, bsz=137.8, num_updates=17400, lr=0.000239732, gnorm=1.214, train_wall=23, wall=0
2024-07-18 13:11:08 | INFO | train_inner | epoch 001:  17500 / 19564 loss=5.08, nll_loss=3.759, ppl=13.54, wps=15068.7, ups=4.31, wpb=3494.8, bsz=131.4, num_updates=17500, lr=0.000239046, gnorm=1.159, train_wall=23, wall=0
2024-07-18 13:11:31 | INFO | train_inner | epoch 001:  17600 / 19564 loss=5.099, nll_loss=3.783, ppl=13.76, wps=15026.8, ups=4.4, wpb=3417.2, bsz=129.8, num_updates=17600, lr=0.000238366, gnorm=1.195, train_wall=23, wall=0
2024-07-18 13:11:54 | INFO | train_inner | epoch 001:  17700 / 19564 loss=5.14, nll_loss=3.828, ppl=14.2, wps=15281.4, ups=4.37, wpb=3497.3, bsz=120.3, num_updates=17700, lr=0.000237691, gnorm=1.187, train_wall=23, wall=0
2024-07-18 13:12:17 | INFO | train_inner | epoch 001:  17800 / 19564 loss=5.08, nll_loss=3.761, ppl=13.55, wps=14837.4, ups=4.36, wpb=3402, bsz=145.8, num_updates=17800, lr=0.000237023, gnorm=1.183, train_wall=23, wall=0
2024-07-18 13:12:40 | INFO | train_inner | epoch 001:  17900 / 19564 loss=5.136, nll_loss=3.823, ppl=14.16, wps=15108.8, ups=4.32, wpb=3494.1, bsz=117.6, num_updates=17900, lr=0.00023636, gnorm=1.193, train_wall=23, wall=0
2024-07-18 13:13:03 | INFO | train_inner | epoch 001:  18000 / 19564 loss=5.038, nll_loss=3.713, ppl=13.12, wps=14783.2, ups=4.32, wpb=3425.4, bsz=139, num_updates=18000, lr=0.000235702, gnorm=1.168, train_wall=23, wall=0
2024-07-18 13:13:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:13:06 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.338 | nll_loss 3.961 | ppl 15.57 | wps 43328.4 | wpb 2872.6 | bsz 51.2 | num_updates 18000 | best_loss 12.094
2024-07-18 13:13:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:13:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_18000.pt (epoch 1 @ 18000 updates, score 5.338) (writing took 4.532976470887661 seconds)
2024-07-18 13:13:34 | INFO | train_inner | epoch 001:  18100 / 19564 loss=5.051, nll_loss=3.728, ppl=13.25, wps=11123, ups=3.26, wpb=3406.9, bsz=134.6, num_updates=18100, lr=0.00023505, gnorm=1.154, train_wall=23, wall=0
2024-07-18 13:13:57 | INFO | train_inner | epoch 001:  18200 / 19564 loss=5.053, nll_loss=3.731, ppl=13.28, wps=14863.7, ups=4.33, wpb=3432.7, bsz=146.2, num_updates=18200, lr=0.000234404, gnorm=1.181, train_wall=23, wall=0
2024-07-18 13:14:20 | INFO | train_inner | epoch 001:  18300 / 19564 loss=5.051, nll_loss=3.729, ppl=13.26, wps=15036.1, ups=4.35, wpb=3459.8, bsz=149.4, num_updates=18300, lr=0.000233762, gnorm=1.185, train_wall=23, wall=0
2024-07-18 13:14:43 | INFO | train_inner | epoch 001:  18400 / 19564 loss=4.977, nll_loss=3.644, ppl=12.5, wps=14906.3, ups=4.34, wpb=3431.9, bsz=155.1, num_updates=18400, lr=0.000233126, gnorm=1.166, train_wall=23, wall=0
2024-07-18 13:15:06 | INFO | train_inner | epoch 001:  18500 / 19564 loss=5.016, nll_loss=3.689, ppl=12.9, wps=14959.9, ups=4.36, wpb=3431.9, bsz=141.4, num_updates=18500, lr=0.000232495, gnorm=1.215, train_wall=23, wall=0
2024-07-18 13:15:29 | INFO | train_inner | epoch 001:  18600 / 19564 loss=5.038, nll_loss=3.714, ppl=13.12, wps=14834.1, ups=4.33, wpb=3424.4, bsz=150.3, num_updates=18600, lr=0.000231869, gnorm=1.2, train_wall=23, wall=0
2024-07-18 13:15:52 | INFO | train_inner | epoch 001:  18700 / 19564 loss=5.064, nll_loss=3.744, ppl=13.4, wps=14933, ups=4.33, wpb=3450.1, bsz=137.8, num_updates=18700, lr=0.000231249, gnorm=1.184, train_wall=23, wall=0
2024-07-18 13:16:15 | INFO | train_inner | epoch 001:  18800 / 19564 loss=5.047, nll_loss=3.726, ppl=13.23, wps=14914.7, ups=4.32, wpb=3455.8, bsz=142.8, num_updates=18800, lr=0.000230633, gnorm=1.196, train_wall=23, wall=0
2024-07-18 13:16:38 | INFO | train_inner | epoch 001:  18900 / 19564 loss=4.995, nll_loss=3.663, ppl=12.67, wps=15216.8, ups=4.34, wpb=3506.6, bsz=139.9, num_updates=18900, lr=0.000230022, gnorm=1.153, train_wall=23, wall=0
2024-07-18 13:17:01 | INFO | train_inner | epoch 001:  19000 / 19564 loss=4.982, nll_loss=3.65, ppl=12.55, wps=15039.1, ups=4.28, wpb=3510.8, bsz=135.3, num_updates=19000, lr=0.000229416, gnorm=1.161, train_wall=23, wall=0
2024-07-18 13:17:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:17:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.283 | nll_loss 3.89 | ppl 14.83 | wps 44592.9 | wpb 2872.6 | bsz 51.2 | num_updates 19000 | best_loss 12.094
2024-07-18 13:17:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:17:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_19000.pt (epoch 1 @ 19000 updates, score 5.283) (writing took 4.654314225539565 seconds)
2024-07-18 13:17:32 | INFO | train_inner | epoch 001:  19100 / 19564 loss=5.013, nll_loss=3.686, ppl=12.87, wps=11229.5, ups=3.27, wpb=3430.4, bsz=133, num_updates=19100, lr=0.000228814, gnorm=1.223, train_wall=23, wall=0
2024-07-18 13:17:55 | INFO | train_inner | epoch 001:  19200 / 19564 loss=5.005, nll_loss=3.677, ppl=12.79, wps=14858.7, ups=4.38, wpb=3393.7, bsz=143.4, num_updates=19200, lr=0.000228218, gnorm=1.197, train_wall=23, wall=0
2024-07-18 13:18:18 | INFO | train_inner | epoch 001:  19300 / 19564 loss=4.979, nll_loss=3.647, ppl=12.53, wps=14794.8, ups=4.35, wpb=3398.8, bsz=145.8, num_updates=19300, lr=0.000227626, gnorm=1.181, train_wall=23, wall=0
2024-07-18 13:18:41 | INFO | train_inner | epoch 001:  19400 / 19564 loss=4.985, nll_loss=3.655, ppl=12.6, wps=15176.4, ups=4.35, wpb=3488.3, bsz=148, num_updates=19400, lr=0.000227038, gnorm=1.146, train_wall=23, wall=0
2024-07-18 13:19:04 | INFO | train_inner | epoch 001:  19500 / 19564 loss=5, nll_loss=3.671, ppl=12.74, wps=14944.8, ups=4.37, wpb=3423.1, bsz=132.8, num_updates=19500, lr=0.000226455, gnorm=1.201, train_wall=23, wall=0
2024-07-18 13:19:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:19:21 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.255 | nll_loss 3.859 | ppl 14.51 | wps 44687.6 | wpb 2872.6 | bsz 51.2 | num_updates 19564 | best_loss 12.094
2024-07-18 13:19:21 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:19:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 19564 updates, score 5.255) (writing took 5.542423123493791 seconds)
2024-07-18 13:19:27 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-18 13:19:27 | INFO | train | epoch 001 | loss 6.662 | nll_loss 5.576 | ppl 47.7 | wps 14020.1 | ups 4.07 | wpb 3446.5 | bsz 142.2 | num_updates 19564 | lr 0.000226085 | gnorm 1.175 | train_wall 4464 | wall 0
2024-07-18 13:19:27 | INFO | fairseq.trainer | begin training epoch 2
2024-07-18 13:19:35 | INFO | train_inner | epoch 002:     36 / 19564 loss=5.055, nll_loss=3.735, ppl=13.32, wps=10706.7, ups=3.18, wpb=3368.4, bsz=135.8, num_updates=19600, lr=0.000225877, gnorm=1.195, train_wall=23, wall=0
2024-07-18 13:19:58 | INFO | train_inner | epoch 002:    136 / 19564 loss=4.921, nll_loss=3.581, ppl=11.97, wps=15235, ups=4.31, wpb=3538.6, bsz=150.3, num_updates=19700, lr=0.000225303, gnorm=1.147, train_wall=23, wall=0
2024-07-18 13:20:21 | INFO | train_inner | epoch 002:    236 / 19564 loss=4.981, nll_loss=3.652, ppl=12.57, wps=14724.6, ups=4.34, wpb=3394.6, bsz=148.8, num_updates=19800, lr=0.000224733, gnorm=1.205, train_wall=23, wall=0
2024-07-18 13:20:45 | INFO | train_inner | epoch 002:    336 / 19564 loss=4.93, nll_loss=3.592, ppl=12.06, wps=15046.7, ups=4.31, wpb=3495.1, bsz=158.8, num_updates=19900, lr=0.000224168, gnorm=1.134, train_wall=23, wall=0
2024-07-18 13:21:08 | INFO | train_inner | epoch 002:    436 / 19564 loss=4.911, nll_loss=3.57, ppl=11.88, wps=14853.1, ups=4.33, wpb=3427.3, bsz=150.8, num_updates=20000, lr=0.000223607, gnorm=1.167, train_wall=23, wall=0
2024-07-18 13:21:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:21:11 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 5.225 | nll_loss 3.824 | ppl 14.16 | wps 44724.5 | wpb 2872.6 | bsz 51.2 | num_updates 20000 | best_loss 12.094
2024-07-18 13:21:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:21:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_20000.pt (epoch 2 @ 20000 updates, score 5.225) (writing took 4.982834585942328 seconds)
2024-07-18 13:21:39 | INFO | train_inner | epoch 002:    536 / 19564 loss=4.882, nll_loss=3.538, ppl=11.61, wps=10893.8, ups=3.24, wpb=3362.9, bsz=145.2, num_updates=20100, lr=0.00022305, gnorm=1.176, train_wall=23, wall=0
2024-07-18 13:22:01 | INFO | train_inner | epoch 002:    636 / 19564 loss=4.998, nll_loss=3.67, ppl=12.73, wps=14943.8, ups=4.37, wpb=3417.4, bsz=120.5, num_updates=20200, lr=0.000222497, gnorm=1.198, train_wall=23, wall=0
2024-07-18 13:22:25 | INFO | train_inner | epoch 002:    736 / 19564 loss=4.795, nll_loss=3.438, ppl=10.84, wps=14791.9, ups=4.32, wpb=3420.6, bsz=163.4, num_updates=20300, lr=0.000221948, gnorm=1.136, train_wall=23, wall=0
2024-07-18 13:22:48 | INFO | train_inner | epoch 002:    836 / 19564 loss=4.941, nll_loss=3.605, ppl=12.17, wps=15176.3, ups=4.31, wpb=3519.3, bsz=145, num_updates=20400, lr=0.000221404, gnorm=1.182, train_wall=23, wall=0
2024-07-18 13:23:11 | INFO | train_inner | epoch 002:    936 / 19564 loss=4.925, nll_loss=3.586, ppl=12.01, wps=15185.3, ups=4.31, wpb=3520.8, bsz=129.4, num_updates=20500, lr=0.000220863, gnorm=1.136, train_wall=23, wall=0
2024-07-18 13:23:34 | INFO | train_inner | epoch 002:   1036 / 19564 loss=4.989, nll_loss=3.66, ppl=12.64, wps=14833.4, ups=4.32, wpb=3436.7, bsz=136.6, num_updates=20600, lr=0.000220326, gnorm=1.226, train_wall=23, wall=0
2024-07-18 13:23:57 | INFO | train_inner | epoch 002:   1136 / 19564 loss=4.91, nll_loss=3.571, ppl=11.88, wps=14989.5, ups=4.33, wpb=3463.2, bsz=154.4, num_updates=20700, lr=0.000219793, gnorm=1.197, train_wall=23, wall=0
2024-07-18 13:24:20 | INFO | train_inner | epoch 002:   1236 / 19564 loss=4.951, nll_loss=3.618, ppl=12.28, wps=14837.8, ups=4.4, wpb=3372.3, bsz=147, num_updates=20800, lr=0.000219265, gnorm=1.181, train_wall=23, wall=0
2024-07-18 13:24:43 | INFO | train_inner | epoch 002:   1336 / 19564 loss=4.926, nll_loss=3.588, ppl=12.03, wps=15211.5, ups=4.34, wpb=3506.7, bsz=140.5, num_updates=20900, lr=0.000218739, gnorm=1.148, train_wall=23, wall=0
2024-07-18 13:25:06 | INFO | train_inner | epoch 002:   1436 / 19564 loss=4.992, nll_loss=3.664, ppl=12.68, wps=15002.7, ups=4.43, wpb=3390.4, bsz=139, num_updates=21000, lr=0.000218218, gnorm=1.198, train_wall=22, wall=0
2024-07-18 13:25:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:25:08 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 5.152 | nll_loss 3.747 | ppl 13.43 | wps 44587.3 | wpb 2872.6 | bsz 51.2 | num_updates 21000 | best_loss 12.094
2024-07-18 13:25:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:25:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_21000.pt (epoch 2 @ 21000 updates, score 5.152) (writing took 4.415698332712054 seconds)
2024-07-18 13:25:36 | INFO | train_inner | epoch 002:   1536 / 19564 loss=4.903, nll_loss=3.562, ppl=11.81, wps=11509.2, ups=3.28, wpb=3509.6, bsz=136.7, num_updates=21100, lr=0.0002177, gnorm=1.14, train_wall=23, wall=0
2024-07-18 13:26:00 | INFO | train_inner | epoch 002:   1636 / 19564 loss=4.901, nll_loss=3.561, ppl=11.8, wps=14386.8, ups=4.26, wpb=3375.5, bsz=140.9, num_updates=21200, lr=0.000217186, gnorm=1.196, train_wall=23, wall=0
2024-07-18 13:26:23 | INFO | train_inner | epoch 002:   1736 / 19564 loss=4.867, nll_loss=3.521, ppl=11.48, wps=15011.9, ups=4.31, wpb=3479.4, bsz=153.1, num_updates=21300, lr=0.000216676, gnorm=1.131, train_wall=23, wall=0
2024-07-18 13:26:46 | INFO | train_inner | epoch 002:   1836 / 19564 loss=4.821, nll_loss=3.469, ppl=11.07, wps=15042.1, ups=4.32, wpb=3484.4, bsz=152.6, num_updates=21400, lr=0.000216169, gnorm=1.127, train_wall=23, wall=0
2024-07-18 13:27:09 | INFO | train_inner | epoch 002:   1936 / 19564 loss=4.963, nll_loss=3.633, ppl=12.4, wps=14688.4, ups=4.39, wpb=3346.9, bsz=132.6, num_updates=21500, lr=0.000215666, gnorm=1.19, train_wall=23, wall=0
2024-07-18 13:27:32 | INFO | train_inner | epoch 002:   2036 / 19564 loss=4.864, nll_loss=3.518, ppl=11.46, wps=15233.3, ups=4.35, wpb=3503.3, bsz=133.1, num_updates=21600, lr=0.000215166, gnorm=1.112, train_wall=23, wall=0
2024-07-18 13:27:55 | INFO | train_inner | epoch 002:   2136 / 19564 loss=4.889, nll_loss=3.547, ppl=11.69, wps=15183.5, ups=4.35, wpb=3490.3, bsz=135.4, num_updates=21700, lr=0.000214669, gnorm=1.16, train_wall=23, wall=0
2024-07-18 13:28:18 | INFO | train_inner | epoch 002:   2236 / 19564 loss=4.829, nll_loss=3.478, ppl=11.14, wps=14999.1, ups=4.32, wpb=3468.8, bsz=164.6, num_updates=21800, lr=0.000214176, gnorm=1.164, train_wall=23, wall=0
2024-07-18 13:28:41 | INFO | train_inner | epoch 002:   2336 / 19564 loss=4.874, nll_loss=3.531, ppl=11.56, wps=14851.4, ups=4.3, wpb=3452.5, bsz=142.2, num_updates=21900, lr=0.000213687, gnorm=1.151, train_wall=23, wall=0
2024-07-18 13:29:05 | INFO | train_inner | epoch 002:   2436 / 19564 loss=4.858, nll_loss=3.513, ppl=11.42, wps=14249.5, ups=4.24, wpb=3362.7, bsz=145.7, num_updates=22000, lr=0.000213201, gnorm=1.167, train_wall=23, wall=0
2024-07-18 13:29:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:29:08 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 5.087 | nll_loss 3.664 | ppl 12.68 | wps 43884.9 | wpb 2872.6 | bsz 51.2 | num_updates 22000 | best_loss 12.094
2024-07-18 13:29:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:29:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_22000.pt (epoch 2 @ 22000 updates, score 5.087) (writing took 4.154258661903441 seconds)
2024-07-18 13:29:36 | INFO | train_inner | epoch 002:   2536 / 19564 loss=4.772, nll_loss=3.414, ppl=10.66, wps=10915.2, ups=3.17, wpb=3443.1, bsz=144.3, num_updates=22100, lr=0.000212718, gnorm=1.135, train_wall=24, wall=0
2024-07-18 13:29:59 | INFO | train_inner | epoch 002:   2636 / 19564 loss=4.825, nll_loss=3.473, ppl=11.11, wps=14877.4, ups=4.37, wpb=3405.6, bsz=129, num_updates=22200, lr=0.000212238, gnorm=1.142, train_wall=23, wall=0
2024-07-18 13:30:22 | INFO | train_inner | epoch 002:   2736 / 19564 loss=4.822, nll_loss=3.471, ppl=11.09, wps=14738.9, ups=4.28, wpb=3443.3, bsz=139.1, num_updates=22300, lr=0.000211762, gnorm=1.159, train_wall=23, wall=0
2024-07-18 13:30:46 | INFO | train_inner | epoch 002:   2836 / 19564 loss=4.849, nll_loss=3.502, ppl=11.33, wps=14874.9, ups=4.26, wpb=3490.4, bsz=145, num_updates=22400, lr=0.000211289, gnorm=1.161, train_wall=23, wall=0
2024-07-18 13:31:09 | INFO | train_inner | epoch 002:   2936 / 19564 loss=4.883, nll_loss=3.542, ppl=11.64, wps=15086.9, ups=4.3, wpb=3508.1, bsz=136.2, num_updates=22500, lr=0.000210819, gnorm=1.153, train_wall=23, wall=0
2024-07-18 13:31:32 | INFO | train_inner | epoch 002:   3036 / 19564 loss=4.835, nll_loss=3.485, ppl=11.2, wps=14903.9, ups=4.38, wpb=3403, bsz=140.5, num_updates=22600, lr=0.000210352, gnorm=1.172, train_wall=23, wall=0
2024-07-18 13:31:55 | INFO | train_inner | epoch 002:   3136 / 19564 loss=4.768, nll_loss=3.41, ppl=10.63, wps=15037.2, ups=4.35, wpb=3460.2, bsz=146.3, num_updates=22700, lr=0.000209888, gnorm=1.113, train_wall=23, wall=0
2024-07-18 13:32:18 | INFO | train_inner | epoch 002:   3236 / 19564 loss=4.853, nll_loss=3.508, ppl=11.38, wps=15116.2, ups=4.34, wpb=3479.5, bsz=147.1, num_updates=22800, lr=0.000209427, gnorm=1.155, train_wall=23, wall=0
2024-07-18 13:32:41 | INFO | train_inner | epoch 002:   3336 / 19564 loss=4.807, nll_loss=3.454, ppl=10.96, wps=14843.8, ups=4.35, wpb=3409.4, bsz=143.4, num_updates=22900, lr=0.000208969, gnorm=1.152, train_wall=23, wall=0
2024-07-18 13:33:04 | INFO | train_inner | epoch 002:   3436 / 19564 loss=4.736, nll_loss=3.373, ppl=10.36, wps=15107.3, ups=4.3, wpb=3513.6, bsz=141.6, num_updates=23000, lr=0.000208514, gnorm=1.155, train_wall=23, wall=0
2024-07-18 13:33:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:33:07 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 5.038 | nll_loss 3.615 | ppl 12.25 | wps 44596.1 | wpb 2872.6 | bsz 51.2 | num_updates 23000 | best_loss 12.094
2024-07-18 13:33:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:33:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_23000.pt (epoch 2 @ 23000 updates, score 5.038) (writing took 4.709116708487272 seconds)
2024-07-18 13:33:35 | INFO | train_inner | epoch 002:   3536 / 19564 loss=4.834, nll_loss=3.485, ppl=11.2, wps=11223.6, ups=3.27, wpb=3435.6, bsz=142.7, num_updates=23100, lr=0.000208063, gnorm=1.184, train_wall=23, wall=0
2024-07-18 13:33:58 | INFO | train_inner | epoch 002:   3636 / 19564 loss=4.774, nll_loss=3.418, ppl=10.69, wps=14659.3, ups=4.35, wpb=3372.6, bsz=146, num_updates=23200, lr=0.000207614, gnorm=1.167, train_wall=23, wall=0
2024-07-18 13:34:21 | INFO | train_inner | epoch 002:   3736 / 19564 loss=4.791, nll_loss=3.436, ppl=10.82, wps=15148.5, ups=4.31, wpb=3512.9, bsz=138, num_updates=23300, lr=0.000207168, gnorm=1.127, train_wall=23, wall=0
2024-07-18 13:34:44 | INFO | train_inner | epoch 002:   3836 / 19564 loss=4.853, nll_loss=3.506, ppl=11.36, wps=15267.9, ups=4.33, wpb=3523, bsz=140.4, num_updates=23400, lr=0.000206725, gnorm=1.144, train_wall=23, wall=0
2024-07-18 13:35:07 | INFO | train_inner | epoch 002:   3936 / 19564 loss=4.814, nll_loss=3.464, ppl=11.04, wps=14930.3, ups=4.33, wpb=3451.2, bsz=145.6, num_updates=23500, lr=0.000206284, gnorm=1.148, train_wall=23, wall=0
2024-07-18 13:35:30 | INFO | train_inner | epoch 002:   4036 / 19564 loss=4.752, nll_loss=3.394, ppl=10.51, wps=15128, ups=4.31, wpb=3510, bsz=164.6, num_updates=23600, lr=0.000205847, gnorm=1.122, train_wall=23, wall=0
2024-07-18 13:35:53 | INFO | train_inner | epoch 002:   4136 / 19564 loss=4.742, nll_loss=3.382, ppl=10.43, wps=15047.1, ups=4.34, wpb=3464.3, bsz=151.3, num_updates=23700, lr=0.000205412, gnorm=1.143, train_wall=23, wall=0
2024-07-18 13:36:17 | INFO | train_inner | epoch 002:   4236 / 19564 loss=4.75, nll_loss=3.391, ppl=10.49, wps=14885.4, ups=4.32, wpb=3444.7, bsz=135.4, num_updates=23800, lr=0.00020498, gnorm=1.133, train_wall=23, wall=0
2024-07-18 13:36:40 | INFO | train_inner | epoch 002:   4336 / 19564 loss=4.807, nll_loss=3.457, ppl=10.98, wps=15098.5, ups=4.36, wpb=3464.4, bsz=142.4, num_updates=23900, lr=0.000204551, gnorm=1.159, train_wall=23, wall=0
2024-07-18 13:37:03 | INFO | train_inner | epoch 002:   4436 / 19564 loss=4.795, nll_loss=3.443, ppl=10.88, wps=15060.3, ups=4.35, wpb=3459, bsz=140.6, num_updates=24000, lr=0.000204124, gnorm=1.153, train_wall=23, wall=0
2024-07-18 13:37:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:37:05 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.984 | nll_loss 3.558 | ppl 11.77 | wps 44500.4 | wpb 2872.6 | bsz 51.2 | num_updates 24000 | best_loss 12.094
2024-07-18 13:37:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:37:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_24000.pt (epoch 2 @ 24000 updates, score 4.984) (writing took 4.140349741093814 seconds)
2024-07-18 13:37:32 | INFO | train_inner | epoch 002:   4536 / 19564 loss=4.758, nll_loss=3.401, ppl=10.56, wps=11389.2, ups=3.38, wpb=3374.1, bsz=157.8, num_updates=24100, lr=0.0002037, gnorm=1.178, train_wall=22, wall=0
2024-07-18 13:37:55 | INFO | train_inner | epoch 002:   4636 / 19564 loss=4.767, nll_loss=3.411, ppl=10.64, wps=15061.9, ups=4.35, wpb=3464.1, bsz=154, num_updates=24200, lr=0.000203279, gnorm=1.151, train_wall=23, wall=0
2024-07-18 13:38:18 | INFO | train_inner | epoch 002:   4736 / 19564 loss=4.785, nll_loss=3.432, ppl=10.79, wps=15152.2, ups=4.36, wpb=3472.7, bsz=135.9, num_updates=24300, lr=0.00020286, gnorm=1.149, train_wall=23, wall=0
2024-07-18 13:38:41 | INFO | train_inner | epoch 002:   4836 / 19564 loss=4.785, nll_loss=3.432, ppl=10.79, wps=15313.9, ups=4.36, wpb=3510.7, bsz=142.9, num_updates=24400, lr=0.000202444, gnorm=1.14, train_wall=23, wall=0
2024-07-18 13:39:04 | INFO | train_inner | epoch 002:   4936 / 19564 loss=4.729, nll_loss=3.367, ppl=10.32, wps=15016.4, ups=4.37, wpb=3435.8, bsz=146.1, num_updates=24500, lr=0.000202031, gnorm=1.135, train_wall=23, wall=0
2024-07-18 13:39:27 | INFO | train_inner | epoch 002:   5036 / 19564 loss=4.811, nll_loss=3.462, ppl=11.02, wps=15194.9, ups=4.34, wpb=3500.1, bsz=159.8, num_updates=24600, lr=0.000201619, gnorm=1.153, train_wall=23, wall=0
2024-07-18 13:39:50 | INFO | train_inner | epoch 002:   5136 / 19564 loss=4.852, nll_loss=3.509, ppl=11.39, wps=14774.7, ups=4.39, wpb=3366.7, bsz=150.4, num_updates=24700, lr=0.000201211, gnorm=1.226, train_wall=23, wall=0
2024-07-18 13:40:13 | INFO | train_inner | epoch 002:   5236 / 19564 loss=4.772, nll_loss=3.416, ppl=10.68, wps=14905.7, ups=4.33, wpb=3441.4, bsz=143, num_updates=24800, lr=0.000200805, gnorm=1.154, train_wall=23, wall=0
2024-07-18 13:40:36 | INFO | train_inner | epoch 002:   5336 / 19564 loss=4.778, nll_loss=3.424, ppl=10.73, wps=14746, ups=4.35, wpb=3390.8, bsz=133.4, num_updates=24900, lr=0.000200401, gnorm=1.156, train_wall=23, wall=0
2024-07-18 13:40:59 | INFO | train_inner | epoch 002:   5436 / 19564 loss=4.765, nll_loss=3.41, ppl=10.63, wps=14717, ups=4.39, wpb=3349.6, bsz=137.9, num_updates=25000, lr=0.0002, gnorm=1.178, train_wall=23, wall=0
2024-07-18 13:40:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:41:01 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.902 | nll_loss 3.463 | ppl 11.03 | wps 44763 | wpb 2872.6 | bsz 51.2 | num_updates 25000 | best_loss 12.094
2024-07-18 13:41:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:41:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_25000.pt (epoch 2 @ 25000 updates, score 4.902) (writing took 8.204588037915528 seconds)
2024-07-18 13:41:33 | INFO | train_inner | epoch 002:   5536 / 19564 loss=4.833, nll_loss=3.487, ppl=11.21, wps=9867.8, ups=2.91, wpb=3387.2, bsz=140.2, num_updates=25100, lr=0.000199601, gnorm=1.203, train_wall=23, wall=0
2024-07-18 13:41:56 | INFO | train_inner | epoch 002:   5636 / 19564 loss=4.73, nll_loss=3.369, ppl=10.33, wps=15053.9, ups=4.37, wpb=3444.9, bsz=143.3, num_updates=25200, lr=0.000199205, gnorm=1.131, train_wall=23, wall=0
2024-07-18 13:42:19 | INFO | train_inner | epoch 002:   5736 / 19564 loss=4.882, nll_loss=3.543, ppl=11.66, wps=14978.2, ups=4.35, wpb=3440.7, bsz=128.2, num_updates=25300, lr=0.000198811, gnorm=1.18, train_wall=23, wall=0
2024-07-18 13:42:41 | INFO | train_inner | epoch 002:   5836 / 19564 loss=4.805, nll_loss=3.455, ppl=10.97, wps=15047.8, ups=4.39, wpb=3426.5, bsz=131, num_updates=25400, lr=0.000198419, gnorm=1.165, train_wall=23, wall=0
2024-07-18 13:43:04 | INFO | train_inner | epoch 002:   5936 / 19564 loss=4.781, nll_loss=3.429, ppl=10.77, wps=15070.9, ups=4.39, wpb=3432.3, bsz=151.9, num_updates=25500, lr=0.00019803, gnorm=1.167, train_wall=23, wall=0
2024-07-18 13:43:27 | INFO | train_inner | epoch 002:   6036 / 19564 loss=4.791, nll_loss=3.439, ppl=10.84, wps=15168.9, ups=4.36, wpb=3475.2, bsz=130.6, num_updates=25600, lr=0.000197642, gnorm=1.149, train_wall=23, wall=0
2024-07-18 13:43:50 | INFO | train_inner | epoch 002:   6136 / 19564 loss=4.777, nll_loss=3.423, ppl=10.73, wps=14913.3, ups=4.39, wpb=3399.4, bsz=135.2, num_updates=25700, lr=0.000197257, gnorm=1.187, train_wall=23, wall=0
2024-07-18 13:44:13 | INFO | train_inner | epoch 002:   6236 / 19564 loss=4.759, nll_loss=3.404, ppl=10.59, wps=14826, ups=4.38, wpb=3381.3, bsz=138.3, num_updates=25800, lr=0.000196875, gnorm=1.162, train_wall=23, wall=0
2024-07-18 13:44:36 | INFO | train_inner | epoch 002:   6336 / 19564 loss=4.659, nll_loss=3.289, ppl=9.77, wps=14678.4, ups=4.39, wpb=3345.3, bsz=147.7, num_updates=25900, lr=0.000196494, gnorm=1.118, train_wall=23, wall=0
2024-07-18 13:44:59 | INFO | train_inner | epoch 002:   6436 / 19564 loss=4.79, nll_loss=3.439, ppl=10.85, wps=14884.4, ups=4.35, wpb=3422.1, bsz=133.9, num_updates=26000, lr=0.000196116, gnorm=1.168, train_wall=23, wall=0
2024-07-18 13:44:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:45:01 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.872 | nll_loss 3.423 | ppl 10.73 | wps 44264.6 | wpb 2872.6 | bsz 51.2 | num_updates 26000 | best_loss 12.094
2024-07-18 13:45:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:45:07 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_26000.pt (epoch 2 @ 26000 updates, score 4.872) (writing took 5.6469467878341675 seconds)
2024-07-18 13:45:30 | INFO | train_inner | epoch 002:   6536 / 19564 loss=4.673, nll_loss=3.305, ppl=9.88, wps=10875.3, ups=3.17, wpb=3432.8, bsz=149.9, num_updates=26100, lr=0.00019574, gnorm=1.13, train_wall=23, wall=0
2024-07-18 13:45:53 | INFO | train_inner | epoch 002:   6636 / 19564 loss=4.704, nll_loss=3.342, ppl=10.14, wps=14874.3, ups=4.31, wpb=3447.8, bsz=149, num_updates=26200, lr=0.000195366, gnorm=1.144, train_wall=23, wall=0
2024-07-18 13:46:16 | INFO | train_inner | epoch 002:   6736 / 19564 loss=4.732, nll_loss=3.373, ppl=10.36, wps=15084.3, ups=4.33, wpb=3480.4, bsz=147.5, num_updates=26300, lr=0.000194994, gnorm=1.148, train_wall=23, wall=0
2024-07-18 13:46:39 | INFO | train_inner | epoch 002:   6836 / 19564 loss=4.73, nll_loss=3.371, ppl=10.34, wps=15143.9, ups=4.33, wpb=3495.1, bsz=138.7, num_updates=26400, lr=0.000194625, gnorm=1.146, train_wall=23, wall=0
2024-07-18 13:47:02 | INFO | train_inner | epoch 002:   6936 / 19564 loss=4.753, nll_loss=3.398, ppl=10.54, wps=14806.8, ups=4.37, wpb=3386.7, bsz=138, num_updates=26500, lr=0.000194257, gnorm=1.156, train_wall=23, wall=0
2024-07-18 13:47:25 | INFO | train_inner | epoch 002:   7036 / 19564 loss=4.69, nll_loss=3.325, ppl=10.02, wps=14920.5, ups=4.32, wpb=3456.4, bsz=145.8, num_updates=26600, lr=0.000193892, gnorm=1.126, train_wall=23, wall=0
2024-07-18 13:47:48 | INFO | train_inner | epoch 002:   7136 / 19564 loss=4.7, nll_loss=3.337, ppl=10.1, wps=14846.3, ups=4.38, wpb=3388.8, bsz=156.6, num_updates=26700, lr=0.000193528, gnorm=1.175, train_wall=23, wall=0
2024-07-18 13:48:11 | INFO | train_inner | epoch 002:   7236 / 19564 loss=4.761, nll_loss=3.407, ppl=10.61, wps=14932, ups=4.39, wpb=3405, bsz=149.6, num_updates=26800, lr=0.000193167, gnorm=1.155, train_wall=23, wall=0
2024-07-18 13:48:34 | INFO | train_inner | epoch 002:   7336 / 19564 loss=4.759, nll_loss=3.403, ppl=10.58, wps=15078.2, ups=4.36, wpb=3457.4, bsz=127.4, num_updates=26900, lr=0.000192807, gnorm=1.14, train_wall=23, wall=0
2024-07-18 13:48:57 | INFO | train_inner | epoch 002:   7436 / 19564 loss=4.756, nll_loss=3.402, ppl=10.57, wps=14915.6, ups=4.4, wpb=3392.5, bsz=150.4, num_updates=27000, lr=0.00019245, gnorm=1.191, train_wall=23, wall=0
2024-07-18 13:48:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:49:00 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.87 | nll_loss 3.429 | ppl 10.77 | wps 44280.4 | wpb 2872.6 | bsz 51.2 | num_updates 27000 | best_loss 12.094
2024-07-18 13:49:00 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:49:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_27000.pt (epoch 2 @ 27000 updates, score 4.87) (writing took 6.110371755436063 seconds)
2024-07-18 13:49:29 | INFO | train_inner | epoch 002:   7536 / 19564 loss=4.704, nll_loss=3.341, ppl=10.14, wps=10917, ups=3.11, wpb=3514.7, bsz=141.6, num_updates=27100, lr=0.000192095, gnorm=1.1, train_wall=23, wall=0
2024-07-18 13:49:52 | INFO | train_inner | epoch 002:   7636 / 19564 loss=4.679, nll_loss=3.314, ppl=9.94, wps=14949.6, ups=4.34, wpb=3447.2, bsz=149.2, num_updates=27200, lr=0.000191741, gnorm=1.135, train_wall=23, wall=0
2024-07-18 13:50:15 | INFO | train_inner | epoch 002:   7736 / 19564 loss=4.727, nll_loss=3.369, ppl=10.33, wps=15066.4, ups=4.41, wpb=3416.6, bsz=152.7, num_updates=27300, lr=0.00019139, gnorm=1.157, train_wall=22, wall=0
2024-07-18 13:50:37 | INFO | train_inner | epoch 002:   7836 / 19564 loss=4.731, nll_loss=3.374, ppl=10.37, wps=14816.5, ups=4.41, wpb=3361.9, bsz=134.2, num_updates=27400, lr=0.00019104, gnorm=1.172, train_wall=23, wall=0
2024-07-18 13:51:00 | INFO | train_inner | epoch 002:   7936 / 19564 loss=4.72, nll_loss=3.361, ppl=10.28, wps=15169, ups=4.35, wpb=3488.9, bsz=135.3, num_updates=27500, lr=0.000190693, gnorm=1.102, train_wall=23, wall=0
2024-07-18 13:51:23 | INFO | train_inner | epoch 002:   8036 / 19564 loss=4.714, nll_loss=3.355, ppl=10.23, wps=14812.9, ups=4.4, wpb=3363.6, bsz=141.9, num_updates=27600, lr=0.000190347, gnorm=1.19, train_wall=23, wall=0
2024-07-18 13:51:46 | INFO | train_inner | epoch 002:   8136 / 19564 loss=4.632, nll_loss=3.259, ppl=9.57, wps=15187.7, ups=4.32, wpb=3519.5, bsz=145.9, num_updates=27700, lr=0.000190003, gnorm=1.103, train_wall=23, wall=0
2024-07-18 13:52:09 | INFO | train_inner | epoch 002:   8236 / 19564 loss=4.757, nll_loss=3.403, ppl=10.58, wps=15091, ups=4.36, wpb=3460.6, bsz=133.6, num_updates=27800, lr=0.000189661, gnorm=1.155, train_wall=23, wall=0
2024-07-18 13:52:32 | INFO | train_inner | epoch 002:   8336 / 19564 loss=4.683, nll_loss=3.319, ppl=9.98, wps=14947.7, ups=4.33, wpb=3450.7, bsz=139.8, num_updates=27900, lr=0.000189321, gnorm=1.12, train_wall=23, wall=0
2024-07-18 13:52:55 | INFO | train_inner | epoch 002:   8436 / 19564 loss=4.752, nll_loss=3.399, ppl=10.55, wps=14867.5, ups=4.39, wpb=3384.6, bsz=146.6, num_updates=28000, lr=0.000188982, gnorm=1.177, train_wall=23, wall=0
2024-07-18 13:52:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:52:58 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.817 | nll_loss 3.35 | ppl 10.19 | wps 44310.4 | wpb 2872.6 | bsz 51.2 | num_updates 28000 | best_loss 12.094
2024-07-18 13:52:58 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:53:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_28000.pt (epoch 2 @ 28000 updates, score 4.817) (writing took 4.436625029891729 seconds)
2024-07-18 13:53:26 | INFO | train_inner | epoch 002:   8536 / 19564 loss=4.712, nll_loss=3.352, ppl=10.21, wps=11480.3, ups=3.29, wpb=3491.4, bsz=145.5, num_updates=28100, lr=0.000188646, gnorm=1.135, train_wall=23, wall=0
2024-07-18 13:53:48 | INFO | train_inner | epoch 002:   8636 / 19564 loss=4.659, nll_loss=3.292, ppl=9.79, wps=15092.5, ups=4.38, wpb=3449.1, bsz=146.3, num_updates=28200, lr=0.000188311, gnorm=1.127, train_wall=23, wall=0
2024-07-18 13:54:11 | INFO | train_inner | epoch 002:   8736 / 19564 loss=4.642, nll_loss=3.272, ppl=9.66, wps=15257, ups=4.33, wpb=3521.7, bsz=143.9, num_updates=28300, lr=0.000187978, gnorm=1.115, train_wall=23, wall=0
2024-07-18 13:54:34 | INFO | train_inner | epoch 002:   8836 / 19564 loss=4.676, nll_loss=3.312, ppl=9.93, wps=15031.9, ups=4.38, wpb=3432.8, bsz=137.9, num_updates=28400, lr=0.000187647, gnorm=1.174, train_wall=23, wall=0
2024-07-18 13:54:57 | INFO | train_inner | epoch 002:   8936 / 19564 loss=4.691, nll_loss=3.329, ppl=10.05, wps=15008.4, ups=4.31, wpb=3478.5, bsz=139.8, num_updates=28500, lr=0.000187317, gnorm=1.12, train_wall=23, wall=0
2024-07-18 13:55:21 | INFO | train_inner | epoch 002:   9036 / 19564 loss=4.661, nll_loss=3.294, ppl=9.81, wps=15162.4, ups=4.31, wpb=3520.1, bsz=135.4, num_updates=28600, lr=0.000186989, gnorm=1.106, train_wall=23, wall=0
2024-07-18 13:55:44 | INFO | train_inner | epoch 002:   9136 / 19564 loss=4.679, nll_loss=3.315, ppl=9.95, wps=14939.7, ups=4.32, wpb=3454.6, bsz=137.8, num_updates=28700, lr=0.000186663, gnorm=1.135, train_wall=23, wall=0
2024-07-18 13:56:07 | INFO | train_inner | epoch 002:   9236 / 19564 loss=4.728, nll_loss=3.371, ppl=10.35, wps=15064.7, ups=4.35, wpb=3461.9, bsz=137.5, num_updates=28800, lr=0.000186339, gnorm=1.142, train_wall=23, wall=0
2024-07-18 13:56:30 | INFO | train_inner | epoch 002:   9336 / 19564 loss=4.71, nll_loss=3.349, ppl=10.19, wps=14816.6, ups=4.4, wpb=3370.9, bsz=128, num_updates=28900, lr=0.000186016, gnorm=1.177, train_wall=23, wall=0
2024-07-18 13:56:52 | INFO | train_inner | epoch 002:   9436 / 19564 loss=4.576, nll_loss=3.199, ppl=9.18, wps=14887, ups=4.37, wpb=3403.5, bsz=152.8, num_updates=29000, lr=0.000185695, gnorm=1.127, train_wall=23, wall=0
2024-07-18 13:56:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:56:55 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.764 | nll_loss 3.309 | ppl 9.91 | wps 44487.2 | wpb 2872.6 | bsz 51.2 | num_updates 29000 | best_loss 12.094
2024-07-18 13:56:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:57:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_29000.pt (epoch 2 @ 29000 updates, score 4.764) (writing took 4.460609878413379 seconds)
2024-07-18 13:57:23 | INFO | train_inner | epoch 002:   9536 / 19564 loss=4.606, nll_loss=3.232, ppl=9.4, wps=11394.8, ups=3.28, wpb=3475.4, bsz=151.1, num_updates=29100, lr=0.000185376, gnorm=1.103, train_wall=23, wall=0
2024-07-18 13:57:46 | INFO | train_inner | epoch 002:   9636 / 19564 loss=4.678, nll_loss=3.315, ppl=9.95, wps=14931.1, ups=4.34, wpb=3440.3, bsz=131.3, num_updates=29200, lr=0.000185058, gnorm=1.154, train_wall=23, wall=0
2024-07-18 13:58:09 | INFO | train_inner | epoch 002:   9736 / 19564 loss=4.689, nll_loss=3.327, ppl=10.04, wps=15294.1, ups=4.36, wpb=3510.6, bsz=135.4, num_updates=29300, lr=0.000184742, gnorm=1.115, train_wall=23, wall=0
2024-07-18 13:58:32 | INFO | train_inner | epoch 002:   9836 / 19564 loss=4.633, nll_loss=3.264, ppl=9.61, wps=15065.8, ups=4.33, wpb=3476.8, bsz=152.2, num_updates=29400, lr=0.000184428, gnorm=1.115, train_wall=23, wall=0
2024-07-18 13:58:55 | INFO | train_inner | epoch 002:   9936 / 19564 loss=4.617, nll_loss=3.245, ppl=9.48, wps=14721.7, ups=4.37, wpb=3372.3, bsz=138.4, num_updates=29500, lr=0.000184115, gnorm=1.136, train_wall=23, wall=0
2024-07-18 13:59:18 | INFO | train_inner | epoch 002:  10036 / 19564 loss=4.664, nll_loss=3.299, ppl=9.84, wps=14721.8, ups=4.34, wpb=3392.6, bsz=128.5, num_updates=29600, lr=0.000183804, gnorm=1.143, train_wall=23, wall=0
2024-07-18 13:59:41 | INFO | train_inner | epoch 002:  10136 / 19564 loss=4.656, nll_loss=3.29, ppl=9.78, wps=14772, ups=4.36, wpb=3391.6, bsz=141.6, num_updates=29700, lr=0.000183494, gnorm=1.168, train_wall=23, wall=0
2024-07-18 14:00:04 | INFO | train_inner | epoch 002:  10236 / 19564 loss=4.685, nll_loss=3.322, ppl=10, wps=14877.2, ups=4.37, wpb=3406.7, bsz=134.6, num_updates=29800, lr=0.000183186, gnorm=1.147, train_wall=23, wall=0
2024-07-18 14:00:27 | INFO | train_inner | epoch 002:  10336 / 19564 loss=4.641, nll_loss=3.272, ppl=9.66, wps=14984.7, ups=4.33, wpb=3457.2, bsz=130.2, num_updates=29900, lr=0.000182879, gnorm=1.105, train_wall=23, wall=0
2024-07-18 14:00:50 | INFO | train_inner | epoch 002:  10436 / 19564 loss=4.638, nll_loss=3.27, ppl=9.64, wps=15200.4, ups=4.33, wpb=3512.8, bsz=139.4, num_updates=30000, lr=0.000182574, gnorm=1.135, train_wall=23, wall=0
2024-07-18 14:00:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:00:53 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.754 | nll_loss 3.299 | ppl 9.84 | wps 44540.8 | wpb 2872.6 | bsz 51.2 | num_updates 30000 | best_loss 12.094
2024-07-18 14:00:53 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:00:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_30000.pt (epoch 2 @ 30000 updates, score 4.754) (writing took 4.816586177796125 seconds)
2024-07-18 14:01:21 | INFO | train_inner | epoch 002:  10536 / 19564 loss=4.621, nll_loss=3.251, ppl=9.52, wps=11288.4, ups=3.26, wpb=3467.3, bsz=156.9, num_updates=30100, lr=0.000182271, gnorm=1.12, train_wall=23, wall=0
2024-07-18 14:01:44 | INFO | train_inner | epoch 002:  10636 / 19564 loss=4.565, nll_loss=3.187, ppl=9.11, wps=15068.5, ups=4.36, wpb=3455.8, bsz=152.3, num_updates=30200, lr=0.000181969, gnorm=1.128, train_wall=23, wall=0
2024-07-18 14:02:07 | INFO | train_inner | epoch 002:  10736 / 19564 loss=4.651, nll_loss=3.284, ppl=9.74, wps=15215.4, ups=4.32, wpb=3520.9, bsz=134.8, num_updates=30300, lr=0.000181668, gnorm=1.131, train_wall=23, wall=0
2024-07-18 14:02:30 | INFO | train_inner | epoch 002:  10836 / 19564 loss=4.623, nll_loss=3.253, ppl=9.53, wps=15214.8, ups=4.3, wpb=3538.6, bsz=139.8, num_updates=30400, lr=0.000181369, gnorm=1.094, train_wall=23, wall=0
2024-07-18 14:02:53 | INFO | train_inner | epoch 002:  10936 / 19564 loss=4.687, nll_loss=3.326, ppl=10.03, wps=14886.2, ups=4.34, wpb=3429.2, bsz=138.6, num_updates=30500, lr=0.000181071, gnorm=1.174, train_wall=23, wall=0
2024-07-18 14:03:16 | INFO | train_inner | epoch 002:  11036 / 19564 loss=4.63, nll_loss=3.262, ppl=9.59, wps=14705.3, ups=4.36, wpb=3374.5, bsz=144.7, num_updates=30600, lr=0.000180775, gnorm=1.173, train_wall=23, wall=0
2024-07-18 14:03:39 | INFO | train_inner | epoch 002:  11136 / 19564 loss=4.667, nll_loss=3.303, ppl=9.87, wps=14911.7, ups=4.36, wpb=3419.7, bsz=139.4, num_updates=30700, lr=0.000180481, gnorm=1.143, train_wall=23, wall=0
2024-07-18 14:04:02 | INFO | train_inner | epoch 002:  11236 / 19564 loss=4.636, nll_loss=3.269, ppl=9.64, wps=15190.1, ups=4.31, wpb=3522.9, bsz=164.4, num_updates=30800, lr=0.000180187, gnorm=1.131, train_wall=23, wall=0
2024-07-18 14:04:25 | INFO | train_inner | epoch 002:  11336 / 19564 loss=4.587, nll_loss=3.211, ppl=9.26, wps=15156.8, ups=4.31, wpb=3514.1, bsz=143, num_updates=30900, lr=0.000179896, gnorm=1.064, train_wall=23, wall=0
2024-07-18 14:04:48 | INFO | train_inner | epoch 002:  11436 / 19564 loss=4.642, nll_loss=3.276, ppl=9.69, wps=15046.6, ups=4.33, wpb=3471.7, bsz=148.1, num_updates=31000, lr=0.000179605, gnorm=1.141, train_wall=23, wall=0
2024-07-18 14:04:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:04:51 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.717 | nll_loss 3.253 | ppl 9.54 | wps 44502.9 | wpb 2872.6 | bsz 51.2 | num_updates 31000 | best_loss 12.094
2024-07-18 14:04:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:05:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_31000.pt (epoch 2 @ 31000 updates, score 4.717) (writing took 11.934023469686508 seconds)
2024-07-18 14:05:26 | INFO | train_inner | epoch 002:  11536 / 19564 loss=4.66, nll_loss=3.295, ppl=9.82, wps=9204.6, ups=2.64, wpb=3484.2, bsz=125.9, num_updates=31100, lr=0.000179316, gnorm=1.132, train_wall=23, wall=0
2024-07-18 14:05:49 | INFO | train_inner | epoch 002:  11636 / 19564 loss=4.69, nll_loss=3.33, ppl=10.06, wps=15074.5, ups=4.39, wpb=3435.7, bsz=132.6, num_updates=31200, lr=0.000179029, gnorm=1.165, train_wall=23, wall=0
2024-07-18 14:06:12 | INFO | train_inner | epoch 002:  11736 / 19564 loss=4.615, nll_loss=3.245, ppl=9.48, wps=15118.6, ups=4.33, wpb=3491.6, bsz=142.5, num_updates=31300, lr=0.000178743, gnorm=1.089, train_wall=23, wall=0
2024-07-18 14:06:35 | INFO | train_inner | epoch 002:  11836 / 19564 loss=4.567, nll_loss=3.19, ppl=9.12, wps=14694, ups=4.33, wpb=3392.6, bsz=147.4, num_updates=31400, lr=0.000178458, gnorm=1.138, train_wall=23, wall=0
2024-07-18 14:06:58 | INFO | train_inner | epoch 002:  11936 / 19564 loss=4.584, nll_loss=3.208, ppl=9.24, wps=15130.7, ups=4.3, wpb=3519, bsz=139, num_updates=31500, lr=0.000178174, gnorm=1.096, train_wall=23, wall=0
2024-07-18 14:07:21 | INFO | train_inner | epoch 002:  12036 / 19564 loss=4.631, nll_loss=3.266, ppl=9.62, wps=14796.5, ups=4.35, wpb=3401.8, bsz=160.2, num_updates=31600, lr=0.000177892, gnorm=1.171, train_wall=23, wall=0
2024-07-18 14:07:45 | INFO | train_inner | epoch 002:  12136 / 19564 loss=4.62, nll_loss=3.249, ppl=9.51, wps=15354.3, ups=4.34, wpb=3540.1, bsz=136.3, num_updates=31700, lr=0.000177611, gnorm=1.105, train_wall=23, wall=0
2024-07-18 14:08:07 | INFO | train_inner | epoch 002:  12236 / 19564 loss=4.647, nll_loss=3.281, ppl=9.72, wps=14806.6, ups=4.36, wpb=3396.1, bsz=152.2, num_updates=31800, lr=0.000177332, gnorm=1.157, train_wall=23, wall=0
2024-07-18 14:08:31 | INFO | train_inner | epoch 002:  12336 / 19564 loss=4.567, nll_loss=3.19, ppl=9.13, wps=15104.7, ups=4.31, wpb=3506, bsz=144.7, num_updates=31900, lr=0.000177054, gnorm=1.1, train_wall=23, wall=0
2024-07-18 14:08:54 | INFO | train_inner | epoch 002:  12436 / 19564 loss=4.592, nll_loss=3.219, ppl=9.31, wps=14956.3, ups=4.37, wpb=3426.1, bsz=151.4, num_updates=32000, lr=0.000176777, gnorm=1.141, train_wall=23, wall=0
2024-07-18 14:08:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:08:56 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.693 | nll_loss 3.229 | ppl 9.38 | wps 44269.5 | wpb 2872.6 | bsz 51.2 | num_updates 32000 | best_loss 12.094
2024-07-18 14:08:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:09:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_32000.pt (epoch 2 @ 32000 updates, score 4.693) (writing took 5.33074807561934 seconds)
2024-07-18 14:09:25 | INFO | train_inner | epoch 002:  12536 / 19564 loss=4.639, nll_loss=3.273, ppl=9.67, wps=10966.7, ups=3.2, wpb=3423.2, bsz=140.4, num_updates=32100, lr=0.000176501, gnorm=1.134, train_wall=23, wall=0
2024-07-18 14:09:48 | INFO | train_inner | epoch 002:  12636 / 19564 loss=4.7, nll_loss=3.343, ppl=10.14, wps=14886.4, ups=4.34, wpb=3430.3, bsz=134.4, num_updates=32200, lr=0.000176227, gnorm=1.173, train_wall=23, wall=0
2024-07-18 14:10:11 | INFO | train_inner | epoch 002:  12736 / 19564 loss=4.592, nll_loss=3.221, ppl=9.32, wps=14955.4, ups=4.35, wpb=3439, bsz=155.8, num_updates=32300, lr=0.000175954, gnorm=1.117, train_wall=23, wall=0
2024-07-18 14:10:34 | INFO | train_inner | epoch 002:  12836 / 19564 loss=4.686, nll_loss=3.326, ppl=10.03, wps=15173.6, ups=4.34, wpb=3499.6, bsz=130.6, num_updates=32400, lr=0.000175682, gnorm=1.126, train_wall=23, wall=0
2024-07-18 14:10:57 | INFO | train_inner | epoch 002:  12936 / 19564 loss=4.634, nll_loss=3.268, ppl=9.63, wps=15163.1, ups=4.33, wpb=3498.6, bsz=146.5, num_updates=32500, lr=0.000175412, gnorm=1.117, train_wall=23, wall=0
2024-07-18 14:11:20 | INFO | train_inner | epoch 002:  13036 / 19564 loss=4.583, nll_loss=3.209, ppl=9.25, wps=14896.1, ups=4.32, wpb=3448.1, bsz=133.5, num_updates=32600, lr=0.000175142, gnorm=1.099, train_wall=23, wall=0
2024-07-18 14:11:43 | INFO | train_inner | epoch 002:  13136 / 19564 loss=4.649, nll_loss=3.284, ppl=9.74, wps=15362.8, ups=4.32, wpb=3557.5, bsz=132.4, num_updates=32700, lr=0.000174874, gnorm=1.107, train_wall=23, wall=0
2024-07-18 14:12:06 | INFO | train_inner | epoch 002:  13236 / 19564 loss=4.594, nll_loss=3.223, ppl=9.34, wps=14850.8, ups=4.38, wpb=3387.8, bsz=153.6, num_updates=32800, lr=0.000174608, gnorm=1.148, train_wall=23, wall=0
2024-07-18 14:12:29 | INFO | train_inner | epoch 002:  13336 / 19564 loss=4.637, nll_loss=3.271, ppl=9.65, wps=15174.3, ups=4.34, wpb=3498.8, bsz=149.4, num_updates=32900, lr=0.000174342, gnorm=1.12, train_wall=23, wall=0
2024-07-18 14:12:52 | INFO | train_inner | epoch 002:  13436 / 19564 loss=4.558, nll_loss=3.181, ppl=9.07, wps=14826.6, ups=4.34, wpb=3417, bsz=148.3, num_updates=33000, lr=0.000174078, gnorm=1.127, train_wall=23, wall=0
2024-07-18 14:12:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:12:55 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.654 | nll_loss 3.173 | ppl 9.02 | wps 44312.8 | wpb 2872.6 | bsz 51.2 | num_updates 33000 | best_loss 12.094
2024-07-18 14:12:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:13:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_33000.pt (epoch 2 @ 33000 updates, score 4.654) (writing took 5.145638173446059 seconds)
2024-07-18 14:13:23 | INFO | train_inner | epoch 002:  13536 / 19564 loss=4.672, nll_loss=3.311, ppl=9.92, wps=11099, ups=3.24, wpb=3424.9, bsz=121.8, num_updates=33100, lr=0.000173814, gnorm=1.144, train_wall=23, wall=0
2024-07-18 14:13:46 | INFO | train_inner | epoch 002:  13636 / 19564 loss=4.562, nll_loss=3.186, ppl=9.1, wps=15046.8, ups=4.29, wpb=3506.6, bsz=157, num_updates=33200, lr=0.000173553, gnorm=1.095, train_wall=23, wall=0
2024-07-18 14:14:10 | INFO | train_inner | epoch 002:  13736 / 19564 loss=4.493, nll_loss=3.107, ppl=8.61, wps=14966.7, ups=4.3, wpb=3479.2, bsz=163, num_updates=33300, lr=0.000173292, gnorm=1.102, train_wall=23, wall=0
2024-07-18 14:14:33 | INFO | train_inner | epoch 002:  13836 / 19564 loss=4.565, nll_loss=3.189, ppl=9.12, wps=15088, ups=4.31, wpb=3500.3, bsz=144.7, num_updates=33400, lr=0.000173032, gnorm=1.107, train_wall=23, wall=0
2024-07-18 14:14:56 | INFO | train_inner | epoch 002:  13936 / 19564 loss=4.602, nll_loss=3.232, ppl=9.4, wps=14816.9, ups=4.36, wpb=3397.1, bsz=154.6, num_updates=33500, lr=0.000172774, gnorm=1.161, train_wall=23, wall=0
2024-07-18 14:15:19 | INFO | train_inner | epoch 002:  14036 / 19564 loss=4.601, nll_loss=3.23, ppl=9.38, wps=14904.6, ups=4.35, wpb=3426.2, bsz=135.8, num_updates=33600, lr=0.000172516, gnorm=1.113, train_wall=23, wall=0
2024-07-18 14:15:42 | INFO | train_inner | epoch 002:  14136 / 19564 loss=4.592, nll_loss=3.219, ppl=9.31, wps=14962.2, ups=4.31, wpb=3471.7, bsz=136.6, num_updates=33700, lr=0.00017226, gnorm=1.141, train_wall=23, wall=0
2024-07-18 14:16:05 | INFO | train_inner | epoch 002:  14236 / 19564 loss=4.561, nll_loss=3.184, ppl=9.09, wps=15138.2, ups=4.3, wpb=3517.2, bsz=130.1, num_updates=33800, lr=0.000172005, gnorm=1.093, train_wall=23, wall=0
2024-07-18 14:16:28 | INFO | train_inner | epoch 002:  14336 / 19564 loss=4.592, nll_loss=3.22, ppl=9.32, wps=15005.7, ups=4.35, wpb=3448.1, bsz=143.8, num_updates=33900, lr=0.000171751, gnorm=1.117, train_wall=23, wall=0
2024-07-18 14:16:51 | INFO | train_inner | epoch 002:  14436 / 19564 loss=4.562, nll_loss=3.186, ppl=9.1, wps=14969.6, ups=4.34, wpb=3445.4, bsz=145.4, num_updates=34000, lr=0.000171499, gnorm=1.105, train_wall=23, wall=0
2024-07-18 14:16:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:16:54 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.652 | nll_loss 3.185 | ppl 9.09 | wps 44135.8 | wpb 2872.6 | bsz 51.2 | num_updates 34000 | best_loss 12.094
2024-07-18 14:16:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:17:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_34000.pt (epoch 2 @ 34000 updates, score 4.652) (writing took 5.496683284640312 seconds)
2024-07-18 14:17:23 | INFO | train_inner | epoch 002:  14536 / 19564 loss=4.597, nll_loss=3.225, ppl=9.35, wps=11027.1, ups=3.18, wpb=3462.5, bsz=121.6, num_updates=34100, lr=0.000171247, gnorm=1.122, train_wall=23, wall=0
2024-07-18 14:17:45 | INFO | train_inner | epoch 002:  14636 / 19564 loss=4.581, nll_loss=3.206, ppl=9.23, wps=15110.5, ups=4.36, wpb=3462.7, bsz=123.7, num_updates=34200, lr=0.000170996, gnorm=1.13, train_wall=23, wall=0
2024-07-18 14:18:08 | INFO | train_inner | epoch 002:  14736 / 19564 loss=4.636, nll_loss=3.271, ppl=9.65, wps=14985.8, ups=4.4, wpb=3403.8, bsz=137.7, num_updates=34300, lr=0.000170747, gnorm=1.146, train_wall=23, wall=0
2024-07-18 14:18:31 | INFO | train_inner | epoch 002:  14836 / 19564 loss=4.581, nll_loss=3.208, ppl=9.24, wps=14851.7, ups=4.36, wpb=3405.8, bsz=130.6, num_updates=34400, lr=0.000170499, gnorm=1.13, train_wall=23, wall=0
2024-07-18 14:18:54 | INFO | train_inner | epoch 002:  14936 / 19564 loss=4.581, nll_loss=3.208, ppl=9.24, wps=14844.6, ups=4.37, wpb=3397.4, bsz=137.9, num_updates=34500, lr=0.000170251, gnorm=1.134, train_wall=23, wall=0
2024-07-18 14:19:17 | INFO | train_inner | epoch 002:  15036 / 19564 loss=4.539, nll_loss=3.161, ppl=8.94, wps=15128.7, ups=4.35, wpb=3479.4, bsz=148.7, num_updates=34600, lr=0.000170005, gnorm=1.087, train_wall=23, wall=0
2024-07-18 14:19:40 | INFO | train_inner | epoch 002:  15136 / 19564 loss=4.609, nll_loss=3.241, ppl=9.45, wps=14795.2, ups=4.39, wpb=3370.6, bsz=141, num_updates=34700, lr=0.00016976, gnorm=1.143, train_wall=23, wall=0
2024-07-18 14:20:02 | INFO | train_inner | epoch 002:  15236 / 19564 loss=4.669, nll_loss=3.308, ppl=9.91, wps=15011.4, ups=4.43, wpb=3389.4, bsz=126.2, num_updates=34800, lr=0.000169516, gnorm=1.179, train_wall=22, wall=0
2024-07-18 14:20:25 | INFO | train_inner | epoch 002:  15336 / 19564 loss=4.594, nll_loss=3.222, ppl=9.33, wps=15221.2, ups=4.36, wpb=3495, bsz=128.8, num_updates=34900, lr=0.000169273, gnorm=1.113, train_wall=23, wall=0
2024-07-18 14:20:48 | INFO | train_inner | epoch 002:  15436 / 19564 loss=4.524, nll_loss=3.142, ppl=8.83, wps=14869.8, ups=4.35, wpb=3415.4, bsz=142.6, num_updates=35000, lr=0.000169031, gnorm=1.118, train_wall=23, wall=0
2024-07-18 14:20:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:20:51 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.605 | nll_loss 3.132 | ppl 8.76 | wps 44426.3 | wpb 2872.6 | bsz 51.2 | num_updates 35000 | best_loss 12.094
2024-07-18 14:20:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:20:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_35000.pt (epoch 2 @ 35000 updates, score 4.605) (writing took 4.618441951461136 seconds)
2024-07-18 14:21:19 | INFO | train_inner | epoch 002:  15536 / 19564 loss=4.558, nll_loss=3.183, ppl=9.08, wps=11375.4, ups=3.24, wpb=3506.3, bsz=159, num_updates=35100, lr=0.00016879, gnorm=1.124, train_wall=23, wall=0
2024-07-18 14:21:42 | INFO | train_inner | epoch 002:  15636 / 19564 loss=4.593, nll_loss=3.223, ppl=9.34, wps=15304, ups=4.37, wpb=3504.3, bsz=141.9, num_updates=35200, lr=0.00016855, gnorm=1.126, train_wall=23, wall=0
2024-07-18 14:22:05 | INFO | train_inner | epoch 002:  15736 / 19564 loss=4.579, nll_loss=3.207, ppl=9.23, wps=14713.1, ups=4.38, wpb=3357.8, bsz=145.5, num_updates=35300, lr=0.000168311, gnorm=1.18, train_wall=23, wall=0
2024-07-18 14:22:28 | INFO | train_inner | epoch 002:  15836 / 19564 loss=4.584, nll_loss=3.211, ppl=9.26, wps=15125.3, ups=4.31, wpb=3507.2, bsz=123.3, num_updates=35400, lr=0.000168073, gnorm=1.114, train_wall=23, wall=0
2024-07-18 14:22:51 | INFO | train_inner | epoch 002:  15936 / 19564 loss=4.538, nll_loss=3.161, ppl=8.95, wps=15023.3, ups=4.27, wpb=3518.1, bsz=148.9, num_updates=35500, lr=0.000167836, gnorm=1.113, train_wall=23, wall=0
2024-07-18 14:23:14 | INFO | train_inner | epoch 002:  16036 / 19564 loss=4.534, nll_loss=3.156, ppl=8.91, wps=14619.4, ups=4.38, wpb=3334.8, bsz=144.3, num_updates=35600, lr=0.0001676, gnorm=1.168, train_wall=23, wall=0
2024-07-18 14:23:37 | INFO | train_inner | epoch 002:  16136 / 19564 loss=4.504, nll_loss=3.121, ppl=8.7, wps=14987.6, ups=4.33, wpb=3459.2, bsz=149.7, num_updates=35700, lr=0.000167365, gnorm=1.098, train_wall=23, wall=0
2024-07-18 14:24:00 | INFO | train_inner | epoch 002:  16236 / 19564 loss=4.563, nll_loss=3.189, ppl=9.12, wps=14987.2, ups=4.35, wpb=3441.4, bsz=150, num_updates=35800, lr=0.000167132, gnorm=1.12, train_wall=23, wall=0
2024-07-18 14:24:23 | INFO | train_inner | epoch 002:  16336 / 19564 loss=4.578, nll_loss=3.206, ppl=9.23, wps=14815.3, ups=4.37, wpb=3392.9, bsz=142.2, num_updates=35900, lr=0.000166899, gnorm=1.124, train_wall=23, wall=0
2024-07-18 14:24:46 | INFO | train_inner | epoch 002:  16436 / 19564 loss=4.569, nll_loss=3.195, ppl=9.16, wps=15040.2, ups=4.36, wpb=3445.8, bsz=140.5, num_updates=36000, lr=0.000166667, gnorm=1.118, train_wall=23, wall=0
2024-07-18 14:24:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:24:49 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.604 | nll_loss 3.117 | ppl 8.68 | wps 44140.7 | wpb 2872.6 | bsz 51.2 | num_updates 36000 | best_loss 12.094
2024-07-18 14:24:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:24:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_36000.pt (epoch 2 @ 36000 updates, score 4.604) (writing took 6.226667792536318 seconds)
2024-07-18 14:25:18 | INFO | train_inner | epoch 002:  16536 / 19564 loss=4.553, nll_loss=3.178, ppl=9.05, wps=10812.2, ups=3.11, wpb=3471.6, bsz=143.9, num_updates=36100, lr=0.000166436, gnorm=1.134, train_wall=23, wall=0
2024-07-18 14:25:41 | INFO | train_inner | epoch 002:  16636 / 19564 loss=4.568, nll_loss=3.195, ppl=9.16, wps=14611.7, ups=4.41, wpb=3315.3, bsz=142.6, num_updates=36200, lr=0.000166206, gnorm=1.156, train_wall=22, wall=0
2024-07-18 14:26:04 | INFO | train_inner | epoch 002:  16736 / 19564 loss=4.564, nll_loss=3.189, ppl=9.12, wps=15062.6, ups=4.3, wpb=3503.8, bsz=128.6, num_updates=36300, lr=0.000165977, gnorm=1.1, train_wall=23, wall=0
2024-07-18 14:26:27 | INFO | train_inner | epoch 002:  16836 / 19564 loss=4.562, nll_loss=3.188, ppl=9.12, wps=14990.6, ups=4.38, wpb=3420.1, bsz=153.3, num_updates=36400, lr=0.000165748, gnorm=1.144, train_wall=23, wall=0
2024-07-18 14:26:50 | INFO | train_inner | epoch 002:  16936 / 19564 loss=4.593, nll_loss=3.222, ppl=9.33, wps=14862, ups=4.36, wpb=3411.3, bsz=140.4, num_updates=36500, lr=0.000165521, gnorm=1.151, train_wall=23, wall=0
2024-07-18 14:27:13 | INFO | train_inner | epoch 002:  17036 / 19564 loss=4.58, nll_loss=3.208, ppl=9.24, wps=15149.3, ups=4.34, wpb=3490.3, bsz=135, num_updates=36600, lr=0.000165295, gnorm=1.143, train_wall=23, wall=0
2024-07-18 14:27:36 | INFO | train_inner | epoch 002:  17136 / 19564 loss=4.629, nll_loss=3.265, ppl=9.61, wps=14909.6, ups=4.42, wpb=3371.7, bsz=134.9, num_updates=36700, lr=0.00016507, gnorm=1.154, train_wall=22, wall=0
2024-07-18 14:27:59 | INFO | train_inner | epoch 002:  17236 / 19564 loss=4.574, nll_loss=3.201, ppl=9.2, wps=15273.9, ups=4.36, wpb=3500.8, bsz=144.3, num_updates=36800, lr=0.000164845, gnorm=1.132, train_wall=23, wall=0
2024-07-18 14:28:22 | INFO | train_inner | epoch 002:  17336 / 19564 loss=4.516, nll_loss=3.135, ppl=8.78, wps=15040, ups=4.34, wpb=3462.2, bsz=132.5, num_updates=36900, lr=0.000164622, gnorm=1.11, train_wall=23, wall=0
2024-07-18 14:28:45 | INFO | train_inner | epoch 002:  17436 / 19564 loss=4.531, nll_loss=3.153, ppl=8.89, wps=14877.2, ups=4.33, wpb=3432, bsz=148.6, num_updates=37000, lr=0.000164399, gnorm=1.155, train_wall=23, wall=0
2024-07-18 14:28:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:28:48 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.583 | nll_loss 3.101 | ppl 8.58 | wps 44368.4 | wpb 2872.6 | bsz 51.2 | num_updates 37000 | best_loss 12.094
2024-07-18 14:28:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:28:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_37000.pt (epoch 2 @ 37000 updates, score 4.583) (writing took 8.545703517273068 seconds)
2024-07-18 14:29:19 | INFO | train_inner | epoch 002:  17536 / 19564 loss=4.556, nll_loss=3.181, ppl=9.07, wps=10099.6, ups=2.89, wpb=3494.2, bsz=139, num_updates=37100, lr=0.000164177, gnorm=1.105, train_wall=23, wall=0
2024-07-18 14:29:42 | INFO | train_inner | epoch 002:  17636 / 19564 loss=4.458, nll_loss=3.07, ppl=8.4, wps=15062.6, ups=4.32, wpb=3487.9, bsz=161.9, num_updates=37200, lr=0.000163956, gnorm=1.068, train_wall=23, wall=0
2024-07-18 14:30:05 | INFO | train_inner | epoch 002:  17736 / 19564 loss=4.513, nll_loss=3.131, ppl=8.76, wps=14866.1, ups=4.35, wpb=3414.4, bsz=137.4, num_updates=37300, lr=0.000163737, gnorm=1.151, train_wall=23, wall=0
2024-07-18 14:30:28 | INFO | train_inner | epoch 002:  17836 / 19564 loss=4.551, nll_loss=3.176, ppl=9.04, wps=14810.3, ups=4.37, wpb=3392.2, bsz=139, num_updates=37400, lr=0.000163517, gnorm=1.147, train_wall=23, wall=0
2024-07-18 14:30:51 | INFO | train_inner | epoch 002:  17936 / 19564 loss=4.551, nll_loss=3.175, ppl=9.03, wps=14825.4, ups=4.32, wpb=3428.8, bsz=138.6, num_updates=37500, lr=0.000163299, gnorm=1.126, train_wall=23, wall=0
2024-07-18 14:31:15 | INFO | train_inner | epoch 002:  18036 / 19564 loss=4.504, nll_loss=3.122, ppl=8.71, wps=14997.7, ups=4.33, wpb=3467.5, bsz=147.5, num_updates=37600, lr=0.000163082, gnorm=1.092, train_wall=23, wall=0
2024-07-18 14:31:37 | INFO | train_inner | epoch 002:  18136 / 19564 loss=4.577, nll_loss=3.206, ppl=9.23, wps=14873, ups=4.36, wpb=3411.7, bsz=138, num_updates=37700, lr=0.000162866, gnorm=1.156, train_wall=23, wall=0
2024-07-18 14:32:00 | INFO | train_inner | epoch 002:  18236 / 19564 loss=4.541, nll_loss=3.164, ppl=8.97, wps=14834.6, ups=4.37, wpb=3395, bsz=137.6, num_updates=37800, lr=0.00016265, gnorm=1.155, train_wall=23, wall=0
2024-07-18 14:32:23 | INFO | train_inner | epoch 002:  18336 / 19564 loss=4.487, nll_loss=3.103, ppl=8.59, wps=14867.8, ups=4.34, wpb=3427.3, bsz=145.8, num_updates=37900, lr=0.000162435, gnorm=1.095, train_wall=23, wall=0
2024-07-18 14:32:46 | INFO | train_inner | epoch 002:  18436 / 19564 loss=4.552, nll_loss=3.178, ppl=9.05, wps=15001.5, ups=4.33, wpb=3464.6, bsz=148, num_updates=38000, lr=0.000162221, gnorm=1.143, train_wall=23, wall=0
2024-07-18 14:32:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:32:49 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.552 | nll_loss 3.064 | ppl 8.36 | wps 44511.9 | wpb 2872.6 | bsz 51.2 | num_updates 38000 | best_loss 12.094
2024-07-18 14:32:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:32:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_38000.pt (epoch 2 @ 38000 updates, score 4.552) (writing took 5.382974942214787 seconds)
2024-07-18 14:33:18 | INFO | train_inner | epoch 002:  18536 / 19564 loss=4.547, nll_loss=3.171, ppl=9.01, wps=10880.8, ups=3.2, wpb=3400.3, bsz=136.8, num_updates=38100, lr=0.000162008, gnorm=1.151, train_wall=23, wall=0
2024-07-18 14:33:41 | INFO | train_inner | epoch 002:  18636 / 19564 loss=4.507, nll_loss=3.125, ppl=8.72, wps=14911.4, ups=4.33, wpb=3447, bsz=128.8, num_updates=38200, lr=0.000161796, gnorm=1.127, train_wall=23, wall=0
2024-07-18 14:34:04 | INFO | train_inner | epoch 002:  18736 / 19564 loss=4.505, nll_loss=3.124, ppl=8.72, wps=15032.7, ups=4.33, wpb=3474.7, bsz=145.3, num_updates=38300, lr=0.000161585, gnorm=1.084, train_wall=23, wall=0
2024-07-18 14:34:27 | INFO | train_inner | epoch 002:  18836 / 19564 loss=4.556, nll_loss=3.182, ppl=9.08, wps=15145.6, ups=4.37, wpb=3463.3, bsz=136.2, num_updates=38400, lr=0.000161374, gnorm=1.133, train_wall=23, wall=0
2024-07-18 14:34:50 | INFO | train_inner | epoch 002:  18936 / 19564 loss=4.523, nll_loss=3.143, ppl=8.84, wps=14876.3, ups=4.32, wpb=3440.5, bsz=133.1, num_updates=38500, lr=0.000161165, gnorm=1.107, train_wall=23, wall=0
2024-07-18 14:35:13 | INFO | train_inner | epoch 002:  19036 / 19564 loss=4.545, nll_loss=3.17, ppl=9, wps=14978.7, ups=4.36, wpb=3436.9, bsz=140.1, num_updates=38600, lr=0.000160956, gnorm=1.13, train_wall=23, wall=0
2024-07-18 14:35:36 | INFO | train_inner | epoch 002:  19136 / 19564 loss=4.449, nll_loss=3.06, ppl=8.34, wps=14942, ups=4.33, wpb=3447.5, bsz=156.9, num_updates=38700, lr=0.000160748, gnorm=1.088, train_wall=23, wall=0
2024-07-18 14:35:59 | INFO | train_inner | epoch 002:  19236 / 19564 loss=4.492, nll_loss=3.11, ppl=8.63, wps=14838, ups=4.34, wpb=3417.4, bsz=136.9, num_updates=38800, lr=0.00016054, gnorm=1.127, train_wall=23, wall=0
2024-07-18 14:36:22 | INFO | train_inner | epoch 002:  19336 / 19564 loss=4.478, nll_loss=3.092, ppl=8.53, wps=14968, ups=4.34, wpb=3452.4, bsz=145.6, num_updates=38900, lr=0.000160334, gnorm=1.111, train_wall=23, wall=0
2024-07-18 14:36:45 | INFO | train_inner | epoch 002:  19436 / 19564 loss=4.537, nll_loss=3.161, ppl=8.94, wps=14948.2, ups=4.37, wpb=3424.2, bsz=143.1, num_updates=39000, lr=0.000160128, gnorm=1.133, train_wall=23, wall=0
2024-07-18 14:36:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:36:48 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.509 | nll_loss 3.023 | ppl 8.13 | wps 43964.7 | wpb 2872.6 | bsz 51.2 | num_updates 39000 | best_loss 12.094
2024-07-18 14:36:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:36:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_39000.pt (epoch 2 @ 39000 updates, score 4.509) (writing took 5.342639931477606 seconds)
2024-07-18 14:37:16 | INFO | train_inner | epoch 002:  19536 / 19564 loss=4.487, nll_loss=3.104, ppl=8.6, wps=11030.1, ups=3.19, wpb=3461.3, bsz=132.6, num_updates=39100, lr=0.000159923, gnorm=1.108, train_wall=23, wall=0
2024-07-18 14:37:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:37:26 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.513 | nll_loss 3.027 | ppl 8.15 | wps 44488.7 | wpb 2872.6 | bsz 51.2 | num_updates 39128 | best_loss 12.094
2024-07-18 14:37:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:37:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 2 @ 39128 updates, score 4.513) (writing took 4.666782381944358 seconds)
2024-07-18 14:37:30 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2024-07-18 14:37:30 | INFO | train | epoch 002 | loss 4.686 | nll_loss 3.323 | ppl 10.01 | wps 14395.9 | ups 4.18 | wpb 3446.5 | bsz 142.2 | num_updates 39128 | lr 0.000159866 | gnorm 1.14 | train_wall 4466 | wall 0
2024-07-18 14:37:31 | INFO | fairseq.trainer | begin training epoch 3
2024-07-18 14:37:47 | INFO | train_inner | epoch 003:     72 / 19564 loss=4.445, nll_loss=3.056, ppl=8.32, wps=11288.4, ups=3.25, wpb=3469.4, bsz=151.2, num_updates=39200, lr=0.000159719, gnorm=1.095, train_wall=23, wall=0
2024-07-18 14:38:10 | INFO | train_inner | epoch 003:    172 / 19564 loss=4.457, nll_loss=3.069, ppl=8.39, wps=14864, ups=4.38, wpb=3395.9, bsz=131.7, num_updates=39300, lr=0.000159516, gnorm=1.114, train_wall=23, wall=0
2024-07-18 14:38:33 | INFO | train_inner | epoch 003:    272 / 19564 loss=4.431, nll_loss=3.039, ppl=8.22, wps=14990.4, ups=4.34, wpb=3452.5, bsz=147.5, num_updates=39400, lr=0.000159313, gnorm=1.094, train_wall=23, wall=0
2024-07-18 14:38:56 | INFO | train_inner | epoch 003:    372 / 19564 loss=4.414, nll_loss=3.02, ppl=8.11, wps=14944.8, ups=4.33, wpb=3451.2, bsz=131.2, num_updates=39500, lr=0.000159111, gnorm=1.099, train_wall=23, wall=0
2024-07-18 14:39:19 | INFO | train_inner | epoch 003:    472 / 19564 loss=4.524, nll_loss=3.145, ppl=8.84, wps=15220.7, ups=4.38, wpb=3474.5, bsz=122.8, num_updates=39600, lr=0.00015891, gnorm=1.133, train_wall=23, wall=0
2024-07-18 14:39:42 | INFO | train_inner | epoch 003:    572 / 19564 loss=4.443, nll_loss=3.053, ppl=8.3, wps=15039.5, ups=4.33, wpb=3476.7, bsz=149.8, num_updates=39700, lr=0.00015871, gnorm=1.084, train_wall=23, wall=0
2024-07-18 14:40:05 | INFO | train_inner | epoch 003:    672 / 19564 loss=4.489, nll_loss=3.106, ppl=8.61, wps=15134.1, ups=4.36, wpb=3469.9, bsz=153.8, num_updates=39800, lr=0.000158511, gnorm=1.102, train_wall=23, wall=0
2024-07-18 14:40:28 | INFO | train_inner | epoch 003:    772 / 19564 loss=4.526, nll_loss=3.148, ppl=8.86, wps=15022.8, ups=4.39, wpb=3418.7, bsz=133.2, num_updates=39900, lr=0.000158312, gnorm=1.13, train_wall=23, wall=0
2024-07-18 14:40:51 | INFO | train_inner | epoch 003:    872 / 19564 loss=4.452, nll_loss=3.064, ppl=8.36, wps=14680.2, ups=4.37, wpb=3360.2, bsz=152.8, num_updates=40000, lr=0.000158114, gnorm=1.113, train_wall=23, wall=0
2024-07-18 14:40:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:40:54 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.525 | nll_loss 3.048 | ppl 8.27 | wps 44298.6 | wpb 2872.6 | bsz 51.2 | num_updates 40000 | best_loss 12.094
2024-07-18 14:40:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:40:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_40000.pt (epoch 3 @ 40000 updates, score 4.525) (writing took 5.502676257863641 seconds)
2024-07-18 14:41:22 | INFO | train_inner | epoch 003:    972 / 19564 loss=4.433, nll_loss=3.043, ppl=8.24, wps=11067.3, ups=3.15, wpb=3512.5, bsz=169.6, num_updates=40100, lr=0.000157917, gnorm=1.088, train_wall=23, wall=0
2024-07-18 14:41:46 | INFO | train_inner | epoch 003:   1072 / 19564 loss=4.56, nll_loss=3.187, ppl=9.11, wps=15015.6, ups=4.31, wpb=3482.7, bsz=132.6, num_updates=40200, lr=0.00015772, gnorm=1.146, train_wall=23, wall=0
2024-07-18 14:42:09 | INFO | train_inner | epoch 003:   1172 / 19564 loss=4.457, nll_loss=3.07, ppl=8.4, wps=14996.4, ups=4.31, wpb=3478.4, bsz=158.6, num_updates=40300, lr=0.000157524, gnorm=1.114, train_wall=23, wall=0
2024-07-18 14:42:32 | INFO | train_inner | epoch 003:   1272 / 19564 loss=4.441, nll_loss=3.05, ppl=8.28, wps=15284.7, ups=4.3, wpb=3555.9, bsz=140.6, num_updates=40400, lr=0.000157329, gnorm=1.074, train_wall=23, wall=0
2024-07-18 14:42:55 | INFO | train_inner | epoch 003:   1372 / 19564 loss=4.554, nll_loss=3.18, ppl=9.07, wps=14782.9, ups=4.41, wpb=3350.5, bsz=128.7, num_updates=40500, lr=0.000157135, gnorm=1.139, train_wall=22, wall=0
2024-07-18 14:43:18 | INFO | train_inner | epoch 003:   1472 / 19564 loss=4.489, nll_loss=3.106, ppl=8.61, wps=14959.8, ups=4.35, wpb=3437.4, bsz=128.3, num_updates=40600, lr=0.000156941, gnorm=1.105, train_wall=23, wall=0
2024-07-18 14:43:41 | INFO | train_inner | epoch 003:   1572 / 19564 loss=4.476, nll_loss=3.091, ppl=8.52, wps=14798.9, ups=4.37, wpb=3383.3, bsz=135.8, num_updates=40700, lr=0.000156748, gnorm=1.121, train_wall=23, wall=0
2024-07-18 14:44:03 | INFO | train_inner | epoch 003:   1672 / 19564 loss=4.455, nll_loss=3.067, ppl=8.38, wps=14828.5, ups=4.37, wpb=3390.1, bsz=146.4, num_updates=40800, lr=0.000156556, gnorm=1.147, train_wall=23, wall=0
2024-07-18 14:44:26 | INFO | train_inner | epoch 003:   1772 / 19564 loss=4.425, nll_loss=3.032, ppl=8.18, wps=15131.6, ups=4.36, wpb=3471.6, bsz=131.7, num_updates=40900, lr=0.000156365, gnorm=1.105, train_wall=23, wall=0
2024-07-18 14:44:49 | INFO | train_inner | epoch 003:   1872 / 19564 loss=4.465, nll_loss=3.079, ppl=8.45, wps=15020.8, ups=4.33, wpb=3470.3, bsz=151.2, num_updates=41000, lr=0.000156174, gnorm=1.094, train_wall=23, wall=0
2024-07-18 14:44:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:44:52 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.48 | nll_loss 2.986 | ppl 7.92 | wps 44084.1 | wpb 2872.6 | bsz 51.2 | num_updates 41000 | best_loss 12.094
2024-07-18 14:44:52 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:44:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_41000.pt (epoch 3 @ 41000 updates, score 4.48) (writing took 5.67163339164108 seconds)
2024-07-18 14:45:21 | INFO | train_inner | epoch 003:   1972 / 19564 loss=4.443, nll_loss=3.052, ppl=8.3, wps=10863.7, ups=3.17, wpb=3426.9, bsz=137.4, num_updates=41100, lr=0.000155984, gnorm=1.094, train_wall=23, wall=0
2024-07-18 14:45:44 | INFO | train_inner | epoch 003:   2072 / 19564 loss=4.456, nll_loss=3.068, ppl=8.39, wps=14964.2, ups=4.33, wpb=3457.7, bsz=143.6, num_updates=41200, lr=0.000155794, gnorm=1.121, train_wall=23, wall=0
2024-07-18 14:46:07 | INFO | train_inner | epoch 003:   2172 / 19564 loss=4.429, nll_loss=3.038, ppl=8.22, wps=14820.8, ups=4.37, wpb=3394.1, bsz=151.1, num_updates=41300, lr=0.000155606, gnorm=1.124, train_wall=23, wall=0
2024-07-18 14:46:30 | INFO | train_inner | epoch 003:   2272 / 19564 loss=4.399, nll_loss=3.004, ppl=8.02, wps=15161.1, ups=4.34, wpb=3491.2, bsz=147.6, num_updates=41400, lr=0.000155417, gnorm=1.074, train_wall=23, wall=0
2024-07-18 14:46:53 | INFO | train_inner | epoch 003:   2372 / 19564 loss=4.405, nll_loss=3.011, ppl=8.06, wps=14974.7, ups=4.35, wpb=3444.2, bsz=155.1, num_updates=41500, lr=0.00015523, gnorm=1.105, train_wall=23, wall=0
2024-07-18 14:47:16 | INFO | train_inner | epoch 003:   2472 / 19564 loss=4.443, nll_loss=3.054, ppl=8.31, wps=14959, ups=4.36, wpb=3427.9, bsz=141.5, num_updates=41600, lr=0.000155043, gnorm=1.171, train_wall=23, wall=0
2024-07-18 14:47:39 | INFO | train_inner | epoch 003:   2572 / 19564 loss=4.41, nll_loss=3.015, ppl=8.09, wps=15143.1, ups=4.33, wpb=3494.8, bsz=144.2, num_updates=41700, lr=0.000154857, gnorm=1.084, train_wall=23, wall=0
2024-07-18 14:48:02 | INFO | train_inner | epoch 003:   2672 / 19564 loss=4.48, nll_loss=3.096, ppl=8.55, wps=14998.1, ups=4.35, wpb=3445, bsz=149.6, num_updates=41800, lr=0.000154672, gnorm=1.14, train_wall=23, wall=0
2024-07-18 14:48:25 | INFO | train_inner | epoch 003:   2772 / 19564 loss=4.426, nll_loss=3.036, ppl=8.2, wps=14939.8, ups=4.33, wpb=3453.4, bsz=142.2, num_updates=41900, lr=0.000154487, gnorm=1.09, train_wall=23, wall=0
2024-07-18 14:48:48 | INFO | train_inner | epoch 003:   2872 / 19564 loss=4.467, nll_loss=3.081, ppl=8.46, wps=14963.3, ups=4.37, wpb=3423, bsz=133.3, num_updates=42000, lr=0.000154303, gnorm=1.101, train_wall=23, wall=0
2024-07-18 14:48:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:48:51 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.476 | nll_loss 2.981 | ppl 7.89 | wps 44437.5 | wpb 2872.6 | bsz 51.2 | num_updates 42000 | best_loss 12.094
2024-07-18 14:48:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:48:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_42000.pt (epoch 3 @ 42000 updates, score 4.476) (writing took 4.8247720608487725 seconds)
2024-07-18 14:49:19 | INFO | train_inner | epoch 003:   2972 / 19564 loss=4.442, nll_loss=3.053, ppl=8.3, wps=11378.3, ups=3.22, wpb=3530.4, bsz=145.1, num_updates=42100, lr=0.00015412, gnorm=1.096, train_wall=23, wall=0
2024-07-18 14:49:42 | INFO | train_inner | epoch 003:   3072 / 19564 loss=4.478, nll_loss=3.094, ppl=8.54, wps=14940.4, ups=4.35, wpb=3434, bsz=132.6, num_updates=42200, lr=0.000153937, gnorm=1.106, train_wall=23, wall=0
2024-07-18 14:50:05 | INFO | train_inner | epoch 003:   3172 / 19564 loss=4.484, nll_loss=3.102, ppl=8.59, wps=14376.3, ups=4.39, wpb=3272.7, bsz=140.6, num_updates=42300, lr=0.000153755, gnorm=1.217, train_wall=23, wall=0
2024-07-18 14:50:28 | INFO | train_inner | epoch 003:   3272 / 19564 loss=4.435, nll_loss=3.044, ppl=8.25, wps=15118.9, ups=4.31, wpb=3511.6, bsz=146.6, num_updates=42400, lr=0.000153574, gnorm=1.087, train_wall=23, wall=0
2024-07-18 14:50:51 | INFO | train_inner | epoch 003:   3372 / 19564 loss=4.46, nll_loss=3.073, ppl=8.42, wps=15174.1, ups=4.32, wpb=3509.9, bsz=149.4, num_updates=42500, lr=0.000153393, gnorm=1.097, train_wall=23, wall=0
2024-07-18 14:51:14 | INFO | train_inner | epoch 003:   3472 / 19564 loss=4.374, nll_loss=2.976, ppl=7.87, wps=15133.5, ups=4.31, wpb=3508, bsz=149, num_updates=42600, lr=0.000153213, gnorm=1.067, train_wall=23, wall=0
2024-07-18 14:51:37 | INFO | train_inner | epoch 003:   3572 / 19564 loss=4.46, nll_loss=3.074, ppl=8.42, wps=14768.4, ups=4.38, wpb=3371.9, bsz=139.8, num_updates=42700, lr=0.000153033, gnorm=1.125, train_wall=23, wall=0
2024-07-18 14:52:00 | INFO | train_inner | epoch 003:   3672 / 19564 loss=4.446, nll_loss=3.059, ppl=8.33, wps=14832.1, ups=4.34, wpb=3414, bsz=136.5, num_updates=42800, lr=0.000152854, gnorm=1.121, train_wall=23, wall=0
2024-07-18 14:52:23 | INFO | train_inner | epoch 003:   3772 / 19564 loss=4.452, nll_loss=3.064, ppl=8.37, wps=14711.3, ups=4.39, wpb=3354.8, bsz=140.1, num_updates=42900, lr=0.000152676, gnorm=1.149, train_wall=23, wall=0
2024-07-18 14:52:46 | INFO | train_inner | epoch 003:   3872 / 19564 loss=4.43, nll_loss=3.041, ppl=8.23, wps=14773, ups=4.38, wpb=3369.5, bsz=139.3, num_updates=43000, lr=0.000152499, gnorm=1.149, train_wall=23, wall=0
2024-07-18 14:52:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:52:49 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.473 | nll_loss 2.987 | ppl 7.93 | wps 44733.5 | wpb 2872.6 | bsz 51.2 | num_updates 43000 | best_loss 12.094
2024-07-18 14:52:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:52:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_43000.pt (epoch 3 @ 43000 updates, score 4.473) (writing took 5.67458866070956 seconds)
2024-07-18 14:53:17 | INFO | train_inner | epoch 003:   3972 / 19564 loss=4.495, nll_loss=3.113, ppl=8.65, wps=10701.6, ups=3.21, wpb=3336.4, bsz=138, num_updates=43100, lr=0.000152322, gnorm=1.169, train_wall=22, wall=0
2024-07-18 14:53:40 | INFO | train_inner | epoch 003:   4072 / 19564 loss=4.469, nll_loss=3.084, ppl=8.48, wps=15124.8, ups=4.36, wpb=3471.6, bsz=140.2, num_updates=43200, lr=0.000152145, gnorm=1.104, train_wall=23, wall=0
2024-07-18 14:54:03 | INFO | train_inner | epoch 003:   4172 / 19564 loss=4.384, nll_loss=2.988, ppl=7.93, wps=15128.2, ups=4.35, wpb=3477.9, bsz=145, num_updates=43300, lr=0.000151969, gnorm=1.075, train_wall=23, wall=0
2024-07-18 14:54:26 | INFO | train_inner | epoch 003:   4272 / 19564 loss=4.429, nll_loss=3.04, ppl=8.22, wps=15165.3, ups=4.33, wpb=3502.7, bsz=165.2, num_updates=43400, lr=0.000151794, gnorm=1.103, train_wall=23, wall=0
2024-07-18 14:54:49 | INFO | train_inner | epoch 003:   4372 / 19564 loss=4.511, nll_loss=3.132, ppl=8.77, wps=15152.4, ups=4.38, wpb=3463.4, bsz=127.4, num_updates=43500, lr=0.00015162, gnorm=1.114, train_wall=23, wall=0
2024-07-18 14:55:12 | INFO | train_inner | epoch 003:   4472 / 19564 loss=4.42, nll_loss=3.03, ppl=8.17, wps=14906.3, ups=4.38, wpb=3401.3, bsz=146.4, num_updates=43600, lr=0.000151446, gnorm=1.105, train_wall=23, wall=0
2024-07-18 14:55:35 | INFO | train_inner | epoch 003:   4572 / 19564 loss=4.361, nll_loss=2.962, ppl=7.79, wps=14864.5, ups=4.33, wpb=3435.2, bsz=161.1, num_updates=43700, lr=0.000151272, gnorm=1.086, train_wall=23, wall=0
2024-07-18 14:55:58 | INFO | train_inner | epoch 003:   4672 / 19564 loss=4.439, nll_loss=3.052, ppl=8.29, wps=15155.9, ups=4.35, wpb=3481.3, bsz=160.5, num_updates=43800, lr=0.000151099, gnorm=1.11, train_wall=23, wall=0
2024-07-18 14:56:21 | INFO | train_inner | epoch 003:   4772 / 19564 loss=4.431, nll_loss=3.041, ppl=8.23, wps=15083.6, ups=4.34, wpb=3473.3, bsz=140.7, num_updates=43900, lr=0.000150927, gnorm=1.092, train_wall=23, wall=0
2024-07-18 14:56:44 | INFO | train_inner | epoch 003:   4872 / 19564 loss=4.442, nll_loss=3.053, ppl=8.3, wps=14921.2, ups=4.34, wpb=3435.3, bsz=130, num_updates=44000, lr=0.000150756, gnorm=1.123, train_wall=23, wall=0
2024-07-18 14:56:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:56:47 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.446 | nll_loss 2.948 | ppl 7.72 | wps 44283.4 | wpb 2872.6 | bsz 51.2 | num_updates 44000 | best_loss 12.094
2024-07-18 14:56:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:56:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_44000.pt (epoch 3 @ 44000 updates, score 4.446) (writing took 6.183651463128626 seconds)
2024-07-18 14:57:16 | INFO | train_inner | epoch 003:   4972 / 19564 loss=4.466, nll_loss=3.082, ppl=8.47, wps=10479, ups=3.14, wpb=3341.6, bsz=137.5, num_updates=44100, lr=0.000150585, gnorm=1.128, train_wall=23, wall=0
2024-07-18 14:57:39 | INFO | train_inner | epoch 003:   5072 / 19564 loss=4.377, nll_loss=2.98, ppl=7.89, wps=14884.6, ups=4.35, wpb=3418.4, bsz=148.8, num_updates=44200, lr=0.000150414, gnorm=1.098, train_wall=23, wall=0
2024-07-18 14:58:02 | INFO | train_inner | epoch 003:   5172 / 19564 loss=4.463, nll_loss=3.077, ppl=8.44, wps=15197.6, ups=4.31, wpb=3523.3, bsz=130.6, num_updates=44300, lr=0.000150244, gnorm=1.095, train_wall=23, wall=0
2024-07-18 14:58:25 | INFO | train_inner | epoch 003:   5272 / 19564 loss=4.449, nll_loss=3.062, ppl=8.35, wps=14920.3, ups=4.34, wpb=3440.1, bsz=150.9, num_updates=44400, lr=0.000150075, gnorm=1.12, train_wall=23, wall=0
2024-07-18 14:58:48 | INFO | train_inner | epoch 003:   5372 / 19564 loss=4.421, nll_loss=3.032, ppl=8.18, wps=14989, ups=4.33, wpb=3463.6, bsz=160.9, num_updates=44500, lr=0.000149906, gnorm=1.14, train_wall=23, wall=0
2024-07-18 14:59:11 | INFO | train_inner | epoch 003:   5472 / 19564 loss=4.46, nll_loss=3.076, ppl=8.43, wps=15034.6, ups=4.34, wpb=3465.9, bsz=149, num_updates=44600, lr=0.000149738, gnorm=1.097, train_wall=23, wall=0
2024-07-18 14:59:34 | INFO | train_inner | epoch 003:   5572 / 19564 loss=4.441, nll_loss=3.055, ppl=8.31, wps=14969.1, ups=4.38, wpb=3421.3, bsz=153.8, num_updates=44700, lr=0.000149571, gnorm=1.128, train_wall=23, wall=0
2024-07-18 14:59:57 | INFO | train_inner | epoch 003:   5672 / 19564 loss=4.448, nll_loss=3.061, ppl=8.35, wps=15061.3, ups=4.35, wpb=3459, bsz=143.3, num_updates=44800, lr=0.000149404, gnorm=1.112, train_wall=23, wall=0
2024-07-18 15:00:20 | INFO | train_inner | epoch 003:   5772 / 19564 loss=4.454, nll_loss=3.068, ppl=8.39, wps=15022.5, ups=4.33, wpb=3470.2, bsz=145.3, num_updates=44900, lr=0.000149237, gnorm=1.129, train_wall=23, wall=0
2024-07-18 15:00:43 | INFO | train_inner | epoch 003:   5872 / 19564 loss=4.389, nll_loss=2.994, ppl=7.97, wps=15150, ups=4.33, wpb=3497.1, bsz=150.9, num_updates=45000, lr=0.000149071, gnorm=1.076, train_wall=23, wall=0
2024-07-18 15:00:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:00:46 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.423 | nll_loss 2.923 | ppl 7.58 | wps 44347.7 | wpb 2872.6 | bsz 51.2 | num_updates 45000 | best_loss 12.094
2024-07-18 15:00:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:00:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_45000.pt (epoch 3 @ 45000 updates, score 4.423) (writing took 5.801225719973445 seconds)
2024-07-18 15:01:15 | INFO | train_inner | epoch 003:   5972 / 19564 loss=4.441, nll_loss=3.055, ppl=8.31, wps=10927.1, ups=3.17, wpb=3447.9, bsz=156.7, num_updates=45100, lr=0.000148906, gnorm=1.178, train_wall=23, wall=0
2024-07-18 15:01:37 | INFO | train_inner | epoch 003:   6072 / 19564 loss=4.458, nll_loss=3.073, ppl=8.42, wps=15151.9, ups=4.39, wpb=3455.2, bsz=150.7, num_updates=45200, lr=0.000148741, gnorm=1.112, train_wall=23, wall=0
2024-07-18 15:02:00 | INFO | train_inner | epoch 003:   6172 / 19564 loss=4.507, nll_loss=3.128, ppl=8.75, wps=15210, ups=4.37, wpb=3483, bsz=144.7, num_updates=45300, lr=0.000148577, gnorm=1.112, train_wall=23, wall=0
2024-07-18 15:02:23 | INFO | train_inner | epoch 003:   6272 / 19564 loss=4.507, nll_loss=3.13, ppl=8.75, wps=14729.7, ups=4.41, wpb=3342.4, bsz=134.9, num_updates=45400, lr=0.000148413, gnorm=1.152, train_wall=23, wall=0
2024-07-18 15:02:46 | INFO | train_inner | epoch 003:   6372 / 19564 loss=4.448, nll_loss=3.062, ppl=8.35, wps=15073.9, ups=4.37, wpb=3449.1, bsz=145.8, num_updates=45500, lr=0.00014825, gnorm=1.14, train_wall=23, wall=0
2024-07-18 15:03:09 | INFO | train_inner | epoch 003:   6472 / 19564 loss=4.465, nll_loss=3.082, ppl=8.47, wps=14517.2, ups=4.38, wpb=3314.1, bsz=151, num_updates=45600, lr=0.000148087, gnorm=1.15, train_wall=23, wall=0
2024-07-18 15:03:32 | INFO | train_inner | epoch 003:   6572 / 19564 loss=4.407, nll_loss=3.015, ppl=8.08, wps=14930.2, ups=4.32, wpb=3458.6, bsz=148.4, num_updates=45700, lr=0.000147925, gnorm=1.087, train_wall=23, wall=0
2024-07-18 15:03:55 | INFO | train_inner | epoch 003:   6672 / 19564 loss=4.454, nll_loss=3.068, ppl=8.38, wps=15164.4, ups=4.36, wpb=3477.6, bsz=134, num_updates=45800, lr=0.000147764, gnorm=1.135, train_wall=23, wall=0
2024-07-18 15:04:18 | INFO | train_inner | epoch 003:   6772 / 19564 loss=4.439, nll_loss=3.052, ppl=8.3, wps=15014.7, ups=4.33, wpb=3468.6, bsz=144, num_updates=45900, lr=0.000147602, gnorm=1.098, train_wall=23, wall=0
2024-07-18 15:04:41 | INFO | train_inner | epoch 003:   6872 / 19564 loss=4.457, nll_loss=3.073, ppl=8.41, wps=14815.5, ups=4.33, wpb=3420.8, bsz=148.1, num_updates=46000, lr=0.000147442, gnorm=1.147, train_wall=23, wall=0
2024-07-18 15:04:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:04:44 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.425 | nll_loss 2.931 | ppl 7.62 | wps 44111.6 | wpb 2872.6 | bsz 51.2 | num_updates 46000 | best_loss 12.094
2024-07-18 15:04:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:04:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_46000.pt (epoch 3 @ 46000 updates, score 4.425) (writing took 6.000064462423325 seconds)
2024-07-18 15:05:13 | INFO | train_inner | epoch 003:   6972 / 19564 loss=4.421, nll_loss=3.031, ppl=8.17, wps=10850.1, ups=3.12, wpb=3475.9, bsz=137, num_updates=46100, lr=0.000147282, gnorm=1.076, train_wall=23, wall=0
2024-07-18 15:05:36 | INFO | train_inner | epoch 003:   7072 / 19564 loss=4.498, nll_loss=3.119, ppl=8.69, wps=14954.4, ups=4.36, wpb=3429.3, bsz=125.6, num_updates=46200, lr=0.000147122, gnorm=1.138, train_wall=23, wall=0
2024-07-18 15:05:59 | INFO | train_inner | epoch 003:   7172 / 19564 loss=4.444, nll_loss=3.057, ppl=8.32, wps=15162, ups=4.32, wpb=3508.9, bsz=138.6, num_updates=46300, lr=0.000146964, gnorm=1.098, train_wall=23, wall=0
2024-07-18 15:06:22 | INFO | train_inner | epoch 003:   7272 / 19564 loss=4.408, nll_loss=3.017, ppl=8.09, wps=15022.1, ups=4.3, wpb=3491.3, bsz=149.7, num_updates=46400, lr=0.000146805, gnorm=1.1, train_wall=23, wall=0
2024-07-18 15:06:45 | INFO | train_inner | epoch 003:   7372 / 19564 loss=4.456, nll_loss=3.071, ppl=8.4, wps=14908.8, ups=4.36, wpb=3419.8, bsz=138, num_updates=46500, lr=0.000146647, gnorm=1.148, train_wall=23, wall=0
2024-07-18 15:07:08 | INFO | train_inner | epoch 003:   7472 / 19564 loss=4.425, nll_loss=3.035, ppl=8.2, wps=15101.8, ups=4.34, wpb=3476.1, bsz=130.4, num_updates=46600, lr=0.00014649, gnorm=1.1, train_wall=23, wall=0
2024-07-18 15:07:31 | INFO | train_inner | epoch 003:   7572 / 19564 loss=4.368, nll_loss=2.971, ppl=7.84, wps=14990.6, ups=4.32, wpb=3471, bsz=148.1, num_updates=46700, lr=0.000146333, gnorm=1.091, train_wall=23, wall=0
2024-07-18 15:07:55 | INFO | train_inner | epoch 003:   7672 / 19564 loss=4.392, nll_loss=2.998, ppl=7.99, wps=14905.2, ups=4.32, wpb=3453.8, bsz=155, num_updates=46800, lr=0.000146176, gnorm=1.105, train_wall=23, wall=0
2024-07-18 15:08:18 | INFO | train_inner | epoch 003:   7772 / 19564 loss=4.438, nll_loss=3.051, ppl=8.29, wps=15208, ups=4.33, wpb=3511.2, bsz=139.3, num_updates=46900, lr=0.00014602, gnorm=1.094, train_wall=23, wall=0
2024-07-18 15:08:41 | INFO | train_inner | epoch 003:   7872 / 19564 loss=4.322, nll_loss=2.918, ppl=7.56, wps=14962.6, ups=4.32, wpb=3466.4, bsz=155.2, num_updates=47000, lr=0.000145865, gnorm=1.056, train_wall=23, wall=0
2024-07-18 15:08:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:08:44 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.399 | nll_loss 2.902 | ppl 7.47 | wps 44344.1 | wpb 2872.6 | bsz 51.2 | num_updates 47000 | best_loss 12.094
2024-07-18 15:08:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:08:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_47000.pt (epoch 3 @ 47000 updates, score 4.399) (writing took 4.954279362224042 seconds)
2024-07-18 15:09:12 | INFO | train_inner | epoch 003:   7972 / 19564 loss=4.394, nll_loss=3.002, ppl=8.01, wps=11134.3, ups=3.24, wpb=3439.9, bsz=157.8, num_updates=47100, lr=0.00014571, gnorm=1.138, train_wall=23, wall=0
2024-07-18 15:09:35 | INFO | train_inner | epoch 003:   8072 / 19564 loss=4.457, nll_loss=3.073, ppl=8.42, wps=14927.3, ups=4.35, wpb=3432.2, bsz=136.2, num_updates=47200, lr=0.000145556, gnorm=1.12, train_wall=23, wall=0
2024-07-18 15:09:58 | INFO | train_inner | epoch 003:   8172 / 19564 loss=4.36, nll_loss=2.962, ppl=7.79, wps=14945.9, ups=4.32, wpb=3462.5, bsz=161.9, num_updates=47300, lr=0.000145402, gnorm=1.107, train_wall=23, wall=0
2024-07-18 15:10:21 | INFO | train_inner | epoch 003:   8272 / 19564 loss=4.447, nll_loss=3.063, ppl=8.36, wps=14977.3, ups=4.35, wpb=3442.6, bsz=158, num_updates=47400, lr=0.000145248, gnorm=1.104, train_wall=23, wall=0
2024-07-18 15:10:44 | INFO | train_inner | epoch 003:   8372 / 19564 loss=4.434, nll_loss=3.045, ppl=8.26, wps=14987.2, ups=4.38, wpb=3425.2, bsz=133.7, num_updates=47500, lr=0.000145095, gnorm=1.133, train_wall=23, wall=0
2024-07-18 15:11:07 | INFO | train_inner | epoch 003:   8472 / 19564 loss=4.336, nll_loss=2.935, ppl=7.65, wps=15024.6, ups=4.32, wpb=3479.7, bsz=155.4, num_updates=47600, lr=0.000144943, gnorm=1.063, train_wall=23, wall=0
2024-07-18 15:11:30 | INFO | train_inner | epoch 003:   8572 / 19564 loss=4.457, nll_loss=3.073, ppl=8.41, wps=14771.4, ups=4.35, wpb=3393.9, bsz=145.4, num_updates=47700, lr=0.000144791, gnorm=1.19, train_wall=23, wall=0
2024-07-18 15:11:53 | INFO | train_inner | epoch 003:   8672 / 19564 loss=4.451, nll_loss=3.066, ppl=8.37, wps=14914, ups=4.38, wpb=3403, bsz=138.2, num_updates=47800, lr=0.000144639, gnorm=1.116, train_wall=23, wall=0
2024-07-18 15:12:16 | INFO | train_inner | epoch 003:   8772 / 19564 loss=4.422, nll_loss=3.033, ppl=8.19, wps=14737.5, ups=4.35, wpb=3386.8, bsz=134.6, num_updates=47900, lr=0.000144488, gnorm=1.122, train_wall=23, wall=0
2024-07-18 15:12:39 | INFO | train_inner | epoch 003:   8872 / 19564 loss=4.513, nll_loss=3.138, ppl=8.8, wps=14822.1, ups=4.31, wpb=3438.8, bsz=127.9, num_updates=48000, lr=0.000144338, gnorm=1.114, train_wall=23, wall=0
2024-07-18 15:12:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:12:42 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.386 | nll_loss 2.88 | ppl 7.36 | wps 42482.1 | wpb 2872.6 | bsz 51.2 | num_updates 48000 | best_loss 12.094
2024-07-18 15:12:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:12:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_48000.pt (epoch 3 @ 48000 updates, score 4.386) (writing took 5.2380291456356645 seconds)
2024-07-18 15:13:10 | INFO | train_inner | epoch 003:   8972 / 19564 loss=4.446, nll_loss=3.062, ppl=8.35, wps=10758, ups=3.17, wpb=3389.5, bsz=154.3, num_updates=48100, lr=0.000144187, gnorm=1.146, train_wall=23, wall=0
2024-07-18 15:13:34 | INFO | train_inner | epoch 003:   9072 / 19564 loss=4.448, nll_loss=3.063, ppl=8.35, wps=14761, ups=4.27, wpb=3456.3, bsz=133.8, num_updates=48200, lr=0.000144038, gnorm=1.088, train_wall=23, wall=0
2024-07-18 15:13:57 | INFO | train_inner | epoch 003:   9172 / 19564 loss=4.484, nll_loss=3.105, ppl=8.6, wps=14514.2, ups=4.4, wpb=3299.3, bsz=135.3, num_updates=48300, lr=0.000143889, gnorm=1.192, train_wall=23, wall=0
2024-07-18 15:14:20 | INFO | train_inner | epoch 003:   9272 / 19564 loss=4.375, nll_loss=2.979, ppl=7.89, wps=15031.5, ups=4.32, wpb=3480.7, bsz=142.2, num_updates=48400, lr=0.00014374, gnorm=1.061, train_wall=23, wall=0
2024-07-18 15:14:43 | INFO | train_inner | epoch 003:   9372 / 19564 loss=4.424, nll_loss=3.036, ppl=8.2, wps=14957, ups=4.34, wpb=3449.8, bsz=142, num_updates=48500, lr=0.000143592, gnorm=1.112, train_wall=23, wall=0
2024-07-18 15:15:06 | INFO | train_inner | epoch 003:   9472 / 19564 loss=4.442, nll_loss=3.056, ppl=8.32, wps=15284.1, ups=4.34, wpb=3518.3, bsz=133.6, num_updates=48600, lr=0.000143444, gnorm=1.094, train_wall=23, wall=0
2024-07-18 15:15:29 | INFO | train_inner | epoch 003:   9572 / 19564 loss=4.432, nll_loss=3.044, ppl=8.25, wps=15007.6, ups=4.31, wpb=3480.5, bsz=134.8, num_updates=48700, lr=0.000143296, gnorm=1.12, train_wall=23, wall=0
2024-07-18 15:15:52 | INFO | train_inner | epoch 003:   9672 / 19564 loss=4.335, nll_loss=2.934, ppl=7.64, wps=14890.2, ups=4.31, wpb=3456.2, bsz=140.2, num_updates=48800, lr=0.00014315, gnorm=1.089, train_wall=23, wall=0
2024-07-18 15:16:15 | INFO | train_inner | epoch 003:   9772 / 19564 loss=4.42, nll_loss=3.032, ppl=8.18, wps=14870.5, ups=4.34, wpb=3427.5, bsz=144.9, num_updates=48900, lr=0.000143003, gnorm=1.126, train_wall=23, wall=0
2024-07-18 15:16:38 | INFO | train_inner | epoch 003:   9872 / 19564 loss=4.377, nll_loss=2.982, ppl=7.9, wps=14748.6, ups=4.32, wpb=3411.7, bsz=146.2, num_updates=49000, lr=0.000142857, gnorm=1.098, train_wall=23, wall=0
2024-07-18 15:16:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:16:41 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.361 | nll_loss 2.864 | ppl 7.28 | wps 44028.3 | wpb 2872.6 | bsz 51.2 | num_updates 49000 | best_loss 12.094
2024-07-18 15:16:41 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:16:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_49000.pt (epoch 3 @ 49000 updates, score 4.361) (writing took 5.301799195818603 seconds)
2024-07-18 15:17:10 | INFO | train_inner | epoch 003:   9972 / 19564 loss=4.409, nll_loss=3.017, ppl=8.1, wps=10984.8, ups=3.19, wpb=3438.8, bsz=131.8, num_updates=49100, lr=0.000142712, gnorm=1.116, train_wall=23, wall=0
2024-07-18 15:17:33 | INFO | train_inner | epoch 003:  10072 / 19564 loss=4.45, nll_loss=3.065, ppl=8.37, wps=14773.1, ups=4.34, wpb=3406.6, bsz=129.4, num_updates=49200, lr=0.000142566, gnorm=1.15, train_wall=23, wall=0
2024-07-18 15:17:56 | INFO | train_inner | epoch 003:  10172 / 19564 loss=4.375, nll_loss=2.979, ppl=7.88, wps=14869, ups=4.34, wpb=3429.1, bsz=132.4, num_updates=49300, lr=0.000142422, gnorm=1.101, train_wall=23, wall=0
2024-07-18 15:18:19 | INFO | train_inner | epoch 003:  10272 / 19564 loss=4.413, nll_loss=3.024, ppl=8.13, wps=14668.1, ups=4.35, wpb=3375.2, bsz=137, num_updates=49400, lr=0.000142278, gnorm=1.122, train_wall=23, wall=0
2024-07-18 15:18:42 | INFO | train_inner | epoch 003:  10372 / 19564 loss=4.454, nll_loss=3.07, ppl=8.4, wps=14745.2, ups=4.37, wpb=3378, bsz=123.4, num_updates=49500, lr=0.000142134, gnorm=1.144, train_wall=23, wall=0
2024-07-18 15:19:05 | INFO | train_inner | epoch 003:  10472 / 19564 loss=4.386, nll_loss=2.993, ppl=7.96, wps=14897.1, ups=4.32, wpb=3445.2, bsz=146, num_updates=49600, lr=0.00014199, gnorm=1.085, train_wall=23, wall=0
2024-07-18 15:19:28 | INFO | train_inner | epoch 003:  10572 / 19564 loss=4.352, nll_loss=2.952, ppl=7.74, wps=15047.9, ups=4.27, wpb=3521.4, bsz=142, num_updates=49700, lr=0.000141848, gnorm=1.078, train_wall=23, wall=0
2024-07-18 15:19:51 | INFO | train_inner | epoch 003:  10672 / 19564 loss=4.401, nll_loss=3.009, ppl=8.05, wps=14781.9, ups=4.35, wpb=3397.9, bsz=140, num_updates=49800, lr=0.000141705, gnorm=1.185, train_wall=23, wall=0
2024-07-18 15:20:14 | INFO | train_inner | epoch 003:  10772 / 19564 loss=4.366, nll_loss=2.969, ppl=7.83, wps=15157.7, ups=4.34, wpb=3496.4, bsz=133.8, num_updates=49900, lr=0.000141563, gnorm=1.061, train_wall=23, wall=0
2024-07-18 15:20:38 | INFO | train_inner | epoch 003:  10872 / 19564 loss=4.367, nll_loss=2.971, ppl=7.84, wps=14944, ups=4.31, wpb=3470.4, bsz=143, num_updates=50000, lr=0.000141421, gnorm=1.107, train_wall=23, wall=0
2024-07-18 15:20:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:20:40 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.363 | nll_loss 2.849 | ppl 7.2 | wps 44137 | wpb 2872.6 | bsz 51.2 | num_updates 50000 | best_loss 12.094
2024-07-18 15:20:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:20:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_50000.pt (epoch 3 @ 50000 updates, score 4.363) (writing took 4.9048274559900165 seconds)
2024-07-18 15:21:08 | INFO | train_inner | epoch 003:  10972 / 19564 loss=4.467, nll_loss=3.086, ppl=8.49, wps=11159.5, ups=3.24, wpb=3440.7, bsz=124.2, num_updates=50100, lr=0.00014128, gnorm=1.114, train_wall=23, wall=0
2024-07-18 15:21:31 | INFO | train_inner | epoch 003:  11072 / 19564 loss=4.32, nll_loss=2.918, ppl=7.56, wps=14862.2, ups=4.33, wpb=3430.1, bsz=152.2, num_updates=50200, lr=0.000141139, gnorm=1.078, train_wall=23, wall=0
2024-07-18 15:21:54 | INFO | train_inner | epoch 003:  11172 / 19564 loss=4.38, nll_loss=2.987, ppl=7.93, wps=14956.2, ups=4.35, wpb=3440.9, bsz=154.8, num_updates=50300, lr=0.000140999, gnorm=1.102, train_wall=23, wall=0
2024-07-18 15:22:17 | INFO | train_inner | epoch 003:  11272 / 19564 loss=4.367, nll_loss=2.97, ppl=7.84, wps=14962, ups=4.38, wpb=3413.9, bsz=144.2, num_updates=50400, lr=0.000140859, gnorm=1.097, train_wall=23, wall=0
2024-07-18 15:22:40 | INFO | train_inner | epoch 003:  11372 / 19564 loss=4.419, nll_loss=3.032, ppl=8.18, wps=14780.7, ups=4.36, wpb=3388.8, bsz=143.9, num_updates=50500, lr=0.00014072, gnorm=1.199, train_wall=23, wall=0
2024-07-18 15:23:03 | INFO | train_inner | epoch 003:  11472 / 19564 loss=4.36, nll_loss=2.963, ppl=7.8, wps=14947.5, ups=4.33, wpb=3451.6, bsz=150.3, num_updates=50600, lr=0.00014058, gnorm=1.098, train_wall=23, wall=0
2024-07-18 15:23:26 | INFO | train_inner | epoch 003:  11572 / 19564 loss=4.391, nll_loss=2.998, ppl=7.99, wps=14871.7, ups=4.32, wpb=3442.2, bsz=135.4, num_updates=50700, lr=0.000140442, gnorm=1.097, train_wall=23, wall=0
2024-07-18 15:23:50 | INFO | train_inner | epoch 003:  11672 / 19564 loss=4.367, nll_loss=2.972, ppl=7.85, wps=14984, ups=4.32, wpb=3465.6, bsz=144.3, num_updates=50800, lr=0.000140303, gnorm=1.072, train_wall=23, wall=0
2024-07-18 15:24:13 | INFO | train_inner | epoch 003:  11772 / 19564 loss=4.299, nll_loss=2.895, ppl=7.44, wps=15049.8, ups=4.28, wpb=3514.8, bsz=160.6, num_updates=50900, lr=0.000140165, gnorm=1.062, train_wall=23, wall=0
2024-07-18 15:24:36 | INFO | train_inner | epoch 003:  11872 / 19564 loss=4.389, nll_loss=2.997, ppl=7.98, wps=15030.1, ups=4.32, wpb=3479.1, bsz=149.8, num_updates=51000, lr=0.000140028, gnorm=1.116, train_wall=23, wall=0
2024-07-18 15:24:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:24:39 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.359 | nll_loss 2.853 | ppl 7.22 | wps 44027.7 | wpb 2872.6 | bsz 51.2 | num_updates 51000 | best_loss 12.094
2024-07-18 15:24:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:24:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_51000.pt (epoch 3 @ 51000 updates, score 4.359) (writing took 5.81014496460557 seconds)
2024-07-18 15:25:08 | INFO | train_inner | epoch 003:  11972 / 19564 loss=4.28, nll_loss=2.873, ppl=7.32, wps=10712.6, ups=3.13, wpb=3424.1, bsz=153.2, num_updates=51100, lr=0.000139891, gnorm=1.095, train_wall=23, wall=0
2024-07-18 15:25:31 | INFO | train_inner | epoch 003:  12072 / 19564 loss=4.369, nll_loss=2.974, ppl=7.86, wps=15098.5, ups=4.3, wpb=3511.8, bsz=148.8, num_updates=51200, lr=0.000139754, gnorm=1.06, train_wall=23, wall=0
2024-07-18 15:25:54 | INFO | train_inner | epoch 003:  12172 / 19564 loss=4.369, nll_loss=2.974, ppl=7.86, wps=14779.5, ups=4.33, wpb=3417.2, bsz=142.2, num_updates=51300, lr=0.000139618, gnorm=1.097, train_wall=23, wall=0
2024-07-18 15:26:18 | INFO | train_inner | epoch 003:  12272 / 19564 loss=4.333, nll_loss=2.933, ppl=7.64, wps=14818.3, ups=4.3, wpb=3446.9, bsz=139.6, num_updates=51400, lr=0.000139482, gnorm=1.07, train_wall=23, wall=0
2024-07-18 15:26:41 | INFO | train_inner | epoch 003:  12372 / 19564 loss=4.372, nll_loss=2.978, ppl=7.88, wps=14952.5, ups=4.32, wpb=3460.2, bsz=137.6, num_updates=51500, lr=0.000139347, gnorm=1.108, train_wall=23, wall=0
2024-07-18 15:27:04 | INFO | train_inner | epoch 003:  12472 / 19564 loss=4.377, nll_loss=2.981, ppl=7.9, wps=15050.9, ups=4.35, wpb=3463.2, bsz=133.7, num_updates=51600, lr=0.000139212, gnorm=1.123, train_wall=23, wall=0
2024-07-18 15:27:27 | INFO | train_inner | epoch 003:  12572 / 19564 loss=4.388, nll_loss=2.997, ppl=7.98, wps=15242.3, ups=4.32, wpb=3524.5, bsz=138.8, num_updates=51700, lr=0.000139077, gnorm=1.074, train_wall=23, wall=0
2024-07-18 15:27:50 | INFO | train_inner | epoch 003:  12672 / 19564 loss=4.386, nll_loss=2.994, ppl=7.96, wps=15185, ups=4.33, wpb=3507.1, bsz=148.2, num_updates=51800, lr=0.000138943, gnorm=1.153, train_wall=23, wall=0
2024-07-18 15:28:13 | INFO | train_inner | epoch 003:  12772 / 19564 loss=4.323, nll_loss=2.921, ppl=7.57, wps=14939.9, ups=4.37, wpb=3420.7, bsz=149.5, num_updates=51900, lr=0.000138809, gnorm=1.115, train_wall=23, wall=0
2024-07-18 15:28:36 | INFO | train_inner | epoch 003:  12872 / 19564 loss=4.335, nll_loss=2.936, ppl=7.65, wps=14901, ups=4.35, wpb=3428.2, bsz=147.3, num_updates=52000, lr=0.000138675, gnorm=1.134, train_wall=23, wall=0
2024-07-18 15:28:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:28:39 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.341 | nll_loss 2.838 | ppl 7.15 | wps 44337.8 | wpb 2872.6 | bsz 51.2 | num_updates 52000 | best_loss 12.094
2024-07-18 15:28:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:28:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_52000.pt (epoch 3 @ 52000 updates, score 4.341) (writing took 7.336959281936288 seconds)
2024-07-18 15:29:09 | INFO | train_inner | epoch 003:  12972 / 19564 loss=4.371, nll_loss=2.977, ppl=7.87, wps=10179.7, ups=3.03, wpb=3356.8, bsz=149, num_updates=52100, lr=0.000138542, gnorm=1.129, train_wall=23, wall=0
2024-07-18 15:29:32 | INFO | train_inner | epoch 003:  13072 / 19564 loss=4.353, nll_loss=2.956, ppl=7.76, wps=15008, ups=4.39, wpb=3418, bsz=145.4, num_updates=52200, lr=0.000138409, gnorm=1.1, train_wall=23, wall=0
2024-07-18 15:29:55 | INFO | train_inner | epoch 003:  13172 / 19564 loss=4.339, nll_loss=2.939, ppl=7.67, wps=14948.8, ups=4.3, wpb=3472.8, bsz=145.9, num_updates=52300, lr=0.000138277, gnorm=1.118, train_wall=23, wall=0
2024-07-18 15:30:18 | INFO | train_inner | epoch 003:  13272 / 19564 loss=4.376, nll_loss=2.983, ppl=7.91, wps=14784.1, ups=4.35, wpb=3400.5, bsz=143.4, num_updates=52400, lr=0.000138145, gnorm=1.114, train_wall=23, wall=0
2024-07-18 15:30:41 | INFO | train_inner | epoch 003:  13372 / 19564 loss=4.36, nll_loss=2.964, ppl=7.8, wps=14774.4, ups=4.34, wpb=3405.4, bsz=146.6, num_updates=52500, lr=0.000138013, gnorm=1.101, train_wall=23, wall=0
2024-07-18 15:31:04 | INFO | train_inner | epoch 003:  13472 / 19564 loss=4.342, nll_loss=2.943, ppl=7.69, wps=14762.1, ups=4.33, wpb=3405.9, bsz=141.3, num_updates=52600, lr=0.000137882, gnorm=1.12, train_wall=23, wall=0
2024-07-18 15:31:27 | INFO | train_inner | epoch 003:  13572 / 19564 loss=4.375, nll_loss=2.982, ppl=7.9, wps=15286.8, ups=4.28, wpb=3573.7, bsz=145.1, num_updates=52700, lr=0.000137751, gnorm=1.056, train_wall=23, wall=0
2024-07-18 15:31:51 | INFO | train_inner | epoch 003:  13672 / 19564 loss=4.363, nll_loss=2.969, ppl=7.83, wps=14774.6, ups=4.3, wpb=3439.5, bsz=146.2, num_updates=52800, lr=0.00013762, gnorm=1.089, train_wall=23, wall=0
2024-07-18 15:32:14 | INFO | train_inner | epoch 003:  13772 / 19564 loss=4.418, nll_loss=3.031, ppl=8.17, wps=14893.5, ups=4.37, wpb=3411.4, bsz=139.1, num_updates=52900, lr=0.00013749, gnorm=1.13, train_wall=23, wall=0
2024-07-18 15:32:37 | INFO | train_inner | epoch 003:  13872 / 19564 loss=4.405, nll_loss=3.016, ppl=8.09, wps=14855.9, ups=4.29, wpb=3463.2, bsz=145.4, num_updates=53000, lr=0.000137361, gnorm=1.159, train_wall=23, wall=0
2024-07-18 15:32:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:32:40 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.324 | nll_loss 2.816 | ppl 7.04 | wps 44051.5 | wpb 2872.6 | bsz 51.2 | num_updates 53000 | best_loss 12.094
2024-07-18 15:32:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:32:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_53000.pt (epoch 3 @ 53000 updates, score 4.324) (writing took 5.358034356497228 seconds)
2024-07-18 15:33:08 | INFO | train_inner | epoch 003:  13972 / 19564 loss=4.32, nll_loss=2.919, ppl=7.56, wps=10911.8, ups=3.19, wpb=3425, bsz=152.2, num_updates=53100, lr=0.000137231, gnorm=1.091, train_wall=23, wall=0
2024-07-18 15:33:31 | INFO | train_inner | epoch 003:  14072 / 19564 loss=4.439, nll_loss=3.055, ppl=8.31, wps=14785.6, ups=4.41, wpb=3355.7, bsz=142.1, num_updates=53200, lr=0.000137102, gnorm=1.214, train_wall=23, wall=0
2024-07-18 15:33:54 | INFO | train_inner | epoch 003:  14172 / 19564 loss=4.352, nll_loss=2.955, ppl=7.75, wps=15056, ups=4.33, wpb=3473.5, bsz=137.7, num_updates=53300, lr=0.000136973, gnorm=1.096, train_wall=23, wall=0
2024-07-18 15:34:17 | INFO | train_inner | epoch 003:  14272 / 19564 loss=4.335, nll_loss=2.936, ppl=7.65, wps=14881.3, ups=4.33, wpb=3432.8, bsz=144.1, num_updates=53400, lr=0.000136845, gnorm=1.126, train_wall=23, wall=0
2024-07-18 15:34:40 | INFO | train_inner | epoch 003:  14372 / 19564 loss=4.348, nll_loss=2.95, ppl=7.73, wps=14744, ups=4.34, wpb=3397.4, bsz=133.2, num_updates=53500, lr=0.000136717, gnorm=1.127, train_wall=23, wall=0
2024-07-18 15:35:03 | INFO | train_inner | epoch 003:  14472 / 19564 loss=4.335, nll_loss=2.935, ppl=7.65, wps=14917.7, ups=4.34, wpb=3434.6, bsz=145, num_updates=53600, lr=0.00013659, gnorm=1.087, train_wall=23, wall=0
2024-07-18 15:35:27 | INFO | train_inner | epoch 003:  14572 / 19564 loss=4.348, nll_loss=2.951, ppl=7.73, wps=14905.9, ups=4.3, wpb=3465.1, bsz=125.4, num_updates=53700, lr=0.000136462, gnorm=1.109, train_wall=23, wall=0
2024-07-18 15:35:50 | INFO | train_inner | epoch 003:  14672 / 19564 loss=4.333, nll_loss=2.934, ppl=7.64, wps=14957, ups=4.26, wpb=3508.5, bsz=144.2, num_updates=53800, lr=0.000136335, gnorm=1.086, train_wall=23, wall=0
2024-07-18 15:36:13 | INFO | train_inner | epoch 003:  14772 / 19564 loss=4.346, nll_loss=2.949, ppl=7.72, wps=14509, ups=4.3, wpb=3370.5, bsz=139.8, num_updates=53900, lr=0.000136209, gnorm=1.121, train_wall=23, wall=0
2024-07-18 15:36:36 | INFO | train_inner | epoch 003:  14872 / 19564 loss=4.392, nll_loss=3.001, ppl=8, wps=14865.5, ups=4.33, wpb=3430.5, bsz=114.2, num_updates=54000, lr=0.000136083, gnorm=1.128, train_wall=23, wall=0
2024-07-18 15:36:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:36:39 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.312 | nll_loss 2.809 | ppl 7.01 | wps 44076.8 | wpb 2872.6 | bsz 51.2 | num_updates 54000 | best_loss 12.094
2024-07-18 15:36:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:36:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_54000.pt (epoch 3 @ 54000 updates, score 4.312) (writing took 6.130371197126806 seconds)
2024-07-18 15:37:09 | INFO | train_inner | epoch 003:  14972 / 19564 loss=4.399, nll_loss=3.009, ppl=8.05, wps=10535.9, ups=3.1, wpb=3395.7, bsz=132.3, num_updates=54100, lr=0.000135957, gnorm=1.155, train_wall=23, wall=0
2024-07-18 15:37:32 | INFO | train_inner | epoch 003:  15072 / 19564 loss=4.339, nll_loss=2.941, ppl=7.68, wps=14791.4, ups=4.29, wpb=3450.1, bsz=145.8, num_updates=54200, lr=0.000135831, gnorm=1.126, train_wall=23, wall=0
2024-07-18 15:37:55 | INFO | train_inner | epoch 003:  15172 / 19564 loss=4.328, nll_loss=2.928, ppl=7.61, wps=14991.3, ups=4.25, wpb=3524.5, bsz=137.8, num_updates=54300, lr=0.000135706, gnorm=1.055, train_wall=23, wall=0
2024-07-18 15:38:18 | INFO | train_inner | epoch 003:  15272 / 19564 loss=4.385, nll_loss=2.993, ppl=7.96, wps=15075.8, ups=4.34, wpb=3477.1, bsz=141, num_updates=54400, lr=0.000135582, gnorm=1.124, train_wall=23, wall=0
2024-07-18 15:38:42 | INFO | train_inner | epoch 003:  15372 / 19564 loss=4.322, nll_loss=2.922, ppl=7.58, wps=14818.2, ups=4.3, wpb=3443, bsz=144.8, num_updates=54500, lr=0.000135457, gnorm=1.104, train_wall=23, wall=0
2024-07-18 15:39:05 | INFO | train_inner | epoch 003:  15472 / 19564 loss=4.332, nll_loss=2.933, ppl=7.64, wps=14639.9, ups=4.33, wpb=3380, bsz=134.2, num_updates=54600, lr=0.000135333, gnorm=1.133, train_wall=23, wall=0
2024-07-18 15:39:28 | INFO | train_inner | epoch 003:  15572 / 19564 loss=4.37, nll_loss=2.976, ppl=7.87, wps=15048.1, ups=4.32, wpb=3479.5, bsz=139.4, num_updates=54700, lr=0.000135209, gnorm=1.117, train_wall=23, wall=0
2024-07-18 15:39:51 | INFO | train_inner | epoch 003:  15672 / 19564 loss=4.359, nll_loss=2.964, ppl=7.8, wps=14817.4, ups=4.37, wpb=3393.1, bsz=135.1, num_updates=54800, lr=0.000135086, gnorm=1.124, train_wall=23, wall=0
2024-07-18 15:40:14 | INFO | train_inner | epoch 003:  15772 / 19564 loss=4.365, nll_loss=2.971, ppl=7.84, wps=15054.6, ups=4.38, wpb=3438.7, bsz=150.2, num_updates=54900, lr=0.000134963, gnorm=1.112, train_wall=23, wall=0
2024-07-18 15:40:37 | INFO | train_inner | epoch 003:  15872 / 19564 loss=4.315, nll_loss=2.914, ppl=7.54, wps=15074.9, ups=4.31, wpb=3495.3, bsz=153.9, num_updates=55000, lr=0.00013484, gnorm=1.059, train_wall=23, wall=0
2024-07-18 15:40:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:40:40 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.301 | nll_loss 2.786 | ppl 6.9 | wps 44641.3 | wpb 2872.6 | bsz 51.2 | num_updates 55000 | best_loss 12.094
2024-07-18 15:40:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:40:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_55000.pt (epoch 3 @ 55000 updates, score 4.301) (writing took 13.931054826825857 seconds)
2024-07-18 15:41:17 | INFO | train_inner | epoch 003:  15972 / 19564 loss=4.4, nll_loss=3.011, ppl=8.06, wps=8712.8, ups=2.51, wpb=3468.8, bsz=141.4, num_updates=55100, lr=0.000134718, gnorm=1.106, train_wall=23, wall=0
2024-07-18 15:41:39 | INFO | train_inner | epoch 003:  16072 / 19564 loss=4.318, nll_loss=2.917, ppl=7.55, wps=14973.5, ups=4.37, wpb=3424.5, bsz=138.5, num_updates=55200, lr=0.000134595, gnorm=1.09, train_wall=23, wall=0
2024-07-18 15:42:02 | INFO | train_inner | epoch 003:  16172 / 19564 loss=4.382, nll_loss=2.99, ppl=7.95, wps=15056.3, ups=4.38, wpb=3437.2, bsz=129.4, num_updates=55300, lr=0.000134474, gnorm=1.096, train_wall=23, wall=0
2024-07-18 15:42:25 | INFO | train_inner | epoch 003:  16272 / 19564 loss=4.368, nll_loss=2.974, ppl=7.85, wps=15378.3, ups=4.34, wpb=3543.3, bsz=143.7, num_updates=55400, lr=0.000134352, gnorm=1.074, train_wall=23, wall=0
2024-07-18 15:42:49 | INFO | train_inner | epoch 003:  16372 / 19564 loss=4.32, nll_loss=2.919, ppl=7.56, wps=15170, ups=4.31, wpb=3522.1, bsz=146.9, num_updates=55500, lr=0.000134231, gnorm=1.088, train_wall=23, wall=0
2024-07-18 15:43:12 | INFO | train_inner | epoch 003:  16472 / 19564 loss=4.364, nll_loss=2.971, ppl=7.84, wps=15056.4, ups=4.31, wpb=3490.1, bsz=141.8, num_updates=55600, lr=0.00013411, gnorm=1.1, train_wall=23, wall=0
2024-07-18 15:43:35 | INFO | train_inner | epoch 003:  16572 / 19564 loss=4.415, nll_loss=3.028, ppl=8.16, wps=15040.6, ups=4.36, wpb=3453.5, bsz=140.9, num_updates=55700, lr=0.00013399, gnorm=1.16, train_wall=23, wall=0
2024-07-18 15:43:58 | INFO | train_inner | epoch 003:  16672 / 19564 loss=4.373, nll_loss=2.98, ppl=7.89, wps=14910.5, ups=4.36, wpb=3420, bsz=138.7, num_updates=55800, lr=0.00013387, gnorm=1.104, train_wall=23, wall=0
2024-07-18 15:44:21 | INFO | train_inner | epoch 003:  16772 / 19564 loss=4.409, nll_loss=3.021, ppl=8.12, wps=14963.4, ups=4.32, wpb=3467.6, bsz=141.8, num_updates=55900, lr=0.00013375, gnorm=1.11, train_wall=23, wall=0
2024-07-18 15:44:44 | INFO | train_inner | epoch 003:  16872 / 19564 loss=4.331, nll_loss=2.932, ppl=7.63, wps=14959.4, ups=4.35, wpb=3442.5, bsz=137, num_updates=56000, lr=0.000133631, gnorm=1.103, train_wall=23, wall=0
2024-07-18 15:44:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:44:47 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.292 | nll_loss 2.786 | ppl 6.9 | wps 44154.8 | wpb 2872.6 | bsz 51.2 | num_updates 56000 | best_loss 12.094
2024-07-18 15:44:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:44:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_56000.pt (epoch 3 @ 56000 updates, score 4.292) (writing took 5.405008736997843 seconds)
2024-07-18 15:45:15 | INFO | train_inner | epoch 003:  16972 / 19564 loss=4.359, nll_loss=2.965, ppl=7.81, wps=11305.8, ups=3.17, wpb=3563.6, bsz=136.1, num_updates=56100, lr=0.000133511, gnorm=1.073, train_wall=23, wall=0
2024-07-18 15:45:39 | INFO | train_inner | epoch 003:  17072 / 19564 loss=4.349, nll_loss=2.951, ppl=7.73, wps=14939.9, ups=4.32, wpb=3462.2, bsz=126.3, num_updates=56200, lr=0.000133393, gnorm=1.105, train_wall=23, wall=0
2024-07-18 15:46:01 | INFO | train_inner | epoch 003:  17172 / 19564 loss=4.415, nll_loss=3.028, ppl=8.16, wps=14581.4, ups=4.4, wpb=3315.2, bsz=124.2, num_updates=56300, lr=0.000133274, gnorm=1.167, train_wall=23, wall=0
2024-07-18 15:46:24 | INFO | train_inner | epoch 003:  17272 / 19564 loss=4.291, nll_loss=2.887, ppl=7.4, wps=14955.2, ups=4.37, wpb=3425.1, bsz=146.6, num_updates=56400, lr=0.000133156, gnorm=1.084, train_wall=23, wall=0
2024-07-18 15:46:47 | INFO | train_inner | epoch 003:  17372 / 19564 loss=4.318, nll_loss=2.918, ppl=7.56, wps=14874.2, ups=4.32, wpb=3442.8, bsz=137.8, num_updates=56500, lr=0.000133038, gnorm=1.102, train_wall=23, wall=0
2024-07-18 15:47:11 | INFO | train_inner | epoch 003:  17472 / 19564 loss=4.308, nll_loss=2.907, ppl=7.5, wps=15062.4, ups=4.31, wpb=3494.5, bsz=156.1, num_updates=56600, lr=0.00013292, gnorm=1.069, train_wall=23, wall=0
2024-07-18 15:47:34 | INFO | train_inner | epoch 003:  17572 / 19564 loss=4.405, nll_loss=3.017, ppl=8.09, wps=14812.7, ups=4.34, wpb=3416, bsz=128.5, num_updates=56700, lr=0.000132803, gnorm=1.114, train_wall=23, wall=0
2024-07-18 15:47:57 | INFO | train_inner | epoch 003:  17672 / 19564 loss=4.296, nll_loss=2.893, ppl=7.43, wps=15103.8, ups=4.27, wpb=3537.1, bsz=146.2, num_updates=56800, lr=0.000132686, gnorm=1.061, train_wall=23, wall=0
2024-07-18 15:48:20 | INFO | train_inner | epoch 003:  17772 / 19564 loss=4.26, nll_loss=2.852, ppl=7.22, wps=14886.2, ups=4.31, wpb=3450.3, bsz=146, num_updates=56900, lr=0.00013257, gnorm=1.069, train_wall=23, wall=0
2024-07-18 15:48:44 | INFO | train_inner | epoch 003:  17872 / 19564 loss=4.377, nll_loss=2.986, ppl=7.92, wps=14745.3, ups=4.28, wpb=3447.4, bsz=151.1, num_updates=57000, lr=0.000132453, gnorm=1.143, train_wall=23, wall=0
2024-07-18 15:48:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:48:46 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.285 | nll_loss 2.77 | ppl 6.82 | wps 44012.7 | wpb 2872.6 | bsz 51.2 | num_updates 57000 | best_loss 12.094
2024-07-18 15:48:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:48:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_57000.pt (epoch 3 @ 57000 updates, score 4.285) (writing took 5.378019756637514 seconds)
2024-07-18 15:49:15 | INFO | train_inner | epoch 003:  17972 / 19564 loss=4.416, nll_loss=3.03, ppl=8.17, wps=10945, ups=3.2, wpb=3418, bsz=137.5, num_updates=57100, lr=0.000132337, gnorm=1.151, train_wall=23, wall=0
2024-07-18 15:49:38 | INFO | train_inner | epoch 003:  18072 / 19564 loss=4.401, nll_loss=3.012, ppl=8.07, wps=14726.8, ups=4.32, wpb=3412.8, bsz=119.5, num_updates=57200, lr=0.000132221, gnorm=1.123, train_wall=23, wall=0
2024-07-18 15:50:01 | INFO | train_inner | epoch 003:  18172 / 19564 loss=4.315, nll_loss=2.914, ppl=7.54, wps=14921.7, ups=4.34, wpb=3437.9, bsz=149, num_updates=57300, lr=0.000132106, gnorm=1.078, train_wall=23, wall=0
2024-07-18 15:50:24 | INFO | train_inner | epoch 003:  18272 / 19564 loss=4.331, nll_loss=2.933, ppl=7.64, wps=15157.8, ups=4.31, wpb=3514.9, bsz=146.9, num_updates=57400, lr=0.000131991, gnorm=1.076, train_wall=23, wall=0
2024-07-18 15:50:47 | INFO | train_inner | epoch 003:  18372 / 19564 loss=4.37, nll_loss=2.977, ppl=7.87, wps=15169.4, ups=4.31, wpb=3516, bsz=133.3, num_updates=57500, lr=0.000131876, gnorm=1.095, train_wall=23, wall=0
2024-07-18 15:51:10 | INFO | train_inner | epoch 003:  18472 / 19564 loss=4.337, nll_loss=2.94, ppl=7.67, wps=14712.6, ups=4.35, wpb=3379.2, bsz=138.6, num_updates=57600, lr=0.000131762, gnorm=1.136, train_wall=23, wall=0
2024-07-18 15:51:34 | INFO | train_inner | epoch 003:  18572 / 19564 loss=4.338, nll_loss=2.94, ppl=7.68, wps=15066.4, ups=4.29, wpb=3509.3, bsz=130.7, num_updates=57700, lr=0.000131647, gnorm=1.073, train_wall=23, wall=0
2024-07-18 15:51:57 | INFO | train_inner | epoch 003:  18672 / 19564 loss=4.355, nll_loss=2.959, ppl=7.78, wps=14954.7, ups=4.3, wpb=3477.3, bsz=130.7, num_updates=57800, lr=0.000131533, gnorm=1.122, train_wall=23, wall=0
2024-07-18 15:52:20 | INFO | train_inner | epoch 003:  18772 / 19564 loss=4.318, nll_loss=2.918, ppl=7.56, wps=14599.5, ups=4.31, wpb=3387.5, bsz=143, num_updates=57900, lr=0.00013142, gnorm=1.155, train_wall=23, wall=0
2024-07-18 15:52:43 | INFO | train_inner | epoch 003:  18872 / 19564 loss=4.301, nll_loss=2.9, ppl=7.47, wps=15125.8, ups=4.29, wpb=3527.6, bsz=162.5, num_updates=58000, lr=0.000131306, gnorm=1.065, train_wall=23, wall=0
2024-07-18 15:52:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:52:46 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.268 | nll_loss 2.756 | ppl 6.76 | wps 43975.4 | wpb 2872.6 | bsz 51.2 | num_updates 58000 | best_loss 12.094
2024-07-18 15:52:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:52:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_58000.pt (epoch 3 @ 58000 updates, score 4.268) (writing took 6.652415853925049 seconds)
2024-07-18 15:53:16 | INFO | train_inner | epoch 003:  18972 / 19564 loss=4.313, nll_loss=2.912, ppl=7.53, wps=10482.9, ups=3.04, wpb=3450.3, bsz=141.8, num_updates=58100, lr=0.000131193, gnorm=1.114, train_wall=23, wall=0
2024-07-18 15:53:39 | INFO | train_inner | epoch 003:  19072 / 19564 loss=4.286, nll_loss=2.882, ppl=7.37, wps=14696.1, ups=4.32, wpb=3398.8, bsz=148.4, num_updates=58200, lr=0.000131081, gnorm=1.111, train_wall=23, wall=0
2024-07-18 15:54:03 | INFO | train_inner | epoch 003:  19172 / 19564 loss=4.275, nll_loss=2.868, ppl=7.3, wps=14874.1, ups=4.26, wpb=3493.5, bsz=139.8, num_updates=58300, lr=0.000130968, gnorm=1.068, train_wall=23, wall=0
2024-07-18 15:54:26 | INFO | train_inner | epoch 003:  19272 / 19564 loss=4.321, nll_loss=2.922, ppl=7.58, wps=15118.9, ups=4.27, wpb=3539.1, bsz=141.4, num_updates=58400, lr=0.000130856, gnorm=1.066, train_wall=23, wall=0
2024-07-18 15:54:49 | INFO | train_inner | epoch 003:  19372 / 19564 loss=4.423, nll_loss=3.039, ppl=8.22, wps=15245.8, ups=4.38, wpb=3484.5, bsz=137.4, num_updates=58500, lr=0.000130744, gnorm=1.126, train_wall=23, wall=0
2024-07-18 15:55:12 | INFO | train_inner | epoch 003:  19472 / 19564 loss=4.302, nll_loss=2.9, ppl=7.46, wps=14942.3, ups=4.3, wpb=3475.6, bsz=136.2, num_updates=58600, lr=0.000130632, gnorm=1.128, train_wall=23, wall=0
2024-07-18 15:55:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:55:36 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.252 | nll_loss 2.738 | ppl 6.67 | wps 44665.3 | wpb 2872.6 | bsz 51.2 | num_updates 58692 | best_loss 12.094
2024-07-18 15:55:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:55:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 3 @ 58692 updates, score 4.252) (writing took 6.015670662745833 seconds)
2024-07-18 15:55:42 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2024-07-18 15:55:42 | INFO | train | epoch 003 | loss 4.401 | nll_loss 3.009 | ppl 8.05 | wps 14370.5 | ups 4.17 | wpb 3446.5 | bsz 142.2 | num_updates 58692 | lr 0.00013053 | gnorm 1.111 | train_wall 4473 | wall 0
2024-07-18 15:55:43 | INFO | fairseq.trainer | begin training epoch 4
2024-07-18 15:55:45 | INFO | train_inner | epoch 004:      8 / 19564 loss=4.334, nll_loss=2.936, ppl=7.65, wps=10754.3, ups=3.12, wpb=3452.2, bsz=129.8, num_updates=58700, lr=0.000130521, gnorm=1.098, train_wall=23, wall=0
2024-07-18 15:56:07 | INFO | train_inner | epoch 004:    108 / 19564 loss=4.301, nll_loss=2.898, ppl=7.46, wps=14866.1, ups=4.39, wpb=3383.8, bsz=131.8, num_updates=58800, lr=0.00013041, gnorm=1.146, train_wall=23, wall=0
2024-07-18 15:56:30 | INFO | train_inner | epoch 004:    208 / 19564 loss=4.333, nll_loss=2.936, ppl=7.65, wps=15053.3, ups=4.32, wpb=3487.8, bsz=145.2, num_updates=58900, lr=0.000130299, gnorm=1.12, train_wall=23, wall=0
2024-07-18 15:56:54 | INFO | train_inner | epoch 004:    308 / 19564 loss=4.328, nll_loss=2.928, ppl=7.61, wps=14851.1, ups=4.32, wpb=3437.7, bsz=124.3, num_updates=59000, lr=0.000130189, gnorm=1.148, train_wall=23, wall=0
2024-07-18 15:56:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:56:57 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.253 | nll_loss 2.741 | ppl 6.69 | wps 43950.8 | wpb 2872.6 | bsz 51.2 | num_updates 59000 | best_loss 12.094
2024-07-18 15:56:57 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:57:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_59000.pt (epoch 4 @ 59000 updates, score 4.253) (writing took 5.354748369194567 seconds)
2024-07-18 15:57:25 | INFO | train_inner | epoch 004:    408 / 19564 loss=4.319, nll_loss=2.919, ppl=7.57, wps=10841.2, ups=3.19, wpb=3402.9, bsz=129.3, num_updates=59100, lr=0.000130079, gnorm=1.129, train_wall=23, wall=0
2024-07-18 15:57:48 | INFO | train_inner | epoch 004:    508 / 19564 loss=4.291, nll_loss=2.888, ppl=7.4, wps=14981.2, ups=4.31, wpb=3478.2, bsz=153.5, num_updates=59200, lr=0.000129969, gnorm=1.118, train_wall=23, wall=0
2024-07-18 15:58:12 | INFO | train_inner | epoch 004:    608 / 19564 loss=4.302, nll_loss=2.898, ppl=7.45, wps=15208.8, ups=4.29, wpb=3547.6, bsz=128.8, num_updates=59300, lr=0.000129859, gnorm=1.087, train_wall=23, wall=0
2024-07-18 15:58:35 | INFO | train_inner | epoch 004:    708 / 19564 loss=4.285, nll_loss=2.88, ppl=7.36, wps=14886.7, ups=4.32, wpb=3445.5, bsz=147.6, num_updates=59400, lr=0.00012975, gnorm=1.1, train_wall=23, wall=0
2024-07-18 15:58:58 | INFO | train_inner | epoch 004:    808 / 19564 loss=4.261, nll_loss=2.853, ppl=7.22, wps=15012.9, ups=4.37, wpb=3439, bsz=141.4, num_updates=59500, lr=0.000129641, gnorm=1.105, train_wall=23, wall=0
2024-07-18 15:59:20 | INFO | train_inner | epoch 004:    908 / 19564 loss=4.337, nll_loss=2.94, ppl=7.67, wps=14986.9, ups=4.38, wpb=3422.9, bsz=139.3, num_updates=59600, lr=0.000129532, gnorm=1.103, train_wall=23, wall=0
2024-07-18 15:59:44 | INFO | train_inner | epoch 004:   1008 / 19564 loss=4.325, nll_loss=2.926, ppl=7.6, wps=14881.1, ups=4.31, wpb=3452.7, bsz=135.2, num_updates=59700, lr=0.000129423, gnorm=1.121, train_wall=23, wall=0
2024-07-18 16:00:07 | INFO | train_inner | epoch 004:   1108 / 19564 loss=4.301, nll_loss=2.899, ppl=7.46, wps=14936.9, ups=4.32, wpb=3459.6, bsz=140, num_updates=59800, lr=0.000129315, gnorm=1.1, train_wall=23, wall=0
2024-07-18 16:00:30 | INFO | train_inner | epoch 004:   1208 / 19564 loss=4.298, nll_loss=2.896, ppl=7.44, wps=14912.8, ups=4.31, wpb=3456.3, bsz=144.6, num_updates=59900, lr=0.000129207, gnorm=1.115, train_wall=23, wall=0
2024-07-18 16:00:53 | INFO | train_inner | epoch 004:   1308 / 19564 loss=4.282, nll_loss=2.878, ppl=7.35, wps=14898.5, ups=4.34, wpb=3435.2, bsz=143.2, num_updates=60000, lr=0.000129099, gnorm=1.08, train_wall=23, wall=0
2024-07-18 16:00:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:00:56 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.249 | nll_loss 2.732 | ppl 6.64 | wps 44023.6 | wpb 2872.6 | bsz 51.2 | num_updates 60000 | best_loss 12.094
2024-07-18 16:00:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:01:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_60000.pt (epoch 4 @ 60000 updates, score 4.249) (writing took 4.4768792148679495 seconds)
2024-07-18 16:01:24 | INFO | train_inner | epoch 004:   1408 / 19564 loss=4.296, nll_loss=2.893, ppl=7.43, wps=11412.6, ups=3.28, wpb=3477.3, bsz=141.5, num_updates=60100, lr=0.000128992, gnorm=1.088, train_wall=23, wall=0
2024-07-18 16:01:47 | INFO | train_inner | epoch 004:   1508 / 19564 loss=4.283, nll_loss=2.879, ppl=7.36, wps=14859.5, ups=4.28, wpb=3468.4, bsz=147.2, num_updates=60200, lr=0.000128885, gnorm=1.093, train_wall=23, wall=0
2024-07-18 16:02:10 | INFO | train_inner | epoch 004:   1608 / 19564 loss=4.337, nll_loss=2.94, ppl=7.68, wps=15134.3, ups=4.33, wpb=3492.8, bsz=131.3, num_updates=60300, lr=0.000128778, gnorm=1.116, train_wall=23, wall=0
2024-07-18 16:02:33 | INFO | train_inner | epoch 004:   1708 / 19564 loss=4.288, nll_loss=2.884, ppl=7.38, wps=14868.3, ups=4.35, wpb=3421.9, bsz=139.8, num_updates=60400, lr=0.000128671, gnorm=1.117, train_wall=23, wall=0
2024-07-18 16:02:56 | INFO | train_inner | epoch 004:   1808 / 19564 loss=4.265, nll_loss=2.858, ppl=7.25, wps=15029.4, ups=4.32, wpb=3482.5, bsz=160.8, num_updates=60500, lr=0.000128565, gnorm=1.077, train_wall=23, wall=0
2024-07-18 16:03:19 | INFO | train_inner | epoch 004:   1908 / 19564 loss=4.293, nll_loss=2.89, ppl=7.41, wps=15105.7, ups=4.33, wpb=3487, bsz=141.9, num_updates=60600, lr=0.000128459, gnorm=1.076, train_wall=23, wall=0
2024-07-18 16:03:42 | INFO | train_inner | epoch 004:   2008 / 19564 loss=4.306, nll_loss=2.904, ppl=7.48, wps=14684.6, ups=4.36, wpb=3369, bsz=135.8, num_updates=60700, lr=0.000128353, gnorm=1.124, train_wall=23, wall=0
2024-07-18 16:04:05 | INFO | train_inner | epoch 004:   2108 / 19564 loss=4.316, nll_loss=2.916, ppl=7.55, wps=14838.8, ups=4.33, wpb=3424.3, bsz=131.5, num_updates=60800, lr=0.000128247, gnorm=1.109, train_wall=23, wall=0
2024-07-18 16:04:28 | INFO | train_inner | epoch 004:   2208 / 19564 loss=4.336, nll_loss=2.937, ppl=7.66, wps=15044.4, ups=4.35, wpb=3458.8, bsz=126.1, num_updates=60900, lr=0.000128142, gnorm=1.119, train_wall=23, wall=0
2024-07-18 16:04:51 | INFO | train_inner | epoch 004:   2308 / 19564 loss=4.284, nll_loss=2.88, ppl=7.36, wps=14720.6, ups=4.39, wpb=3352.2, bsz=143.4, num_updates=61000, lr=0.000128037, gnorm=1.128, train_wall=23, wall=0
2024-07-18 16:04:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:04:54 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.245 | nll_loss 2.73 | ppl 6.63 | wps 44351.7 | wpb 2872.6 | bsz 51.2 | num_updates 61000 | best_loss 12.094
2024-07-18 16:04:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:05:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_61000.pt (epoch 4 @ 61000 updates, score 4.245) (writing took 6.11082770023495 seconds)
2024-07-18 16:05:23 | INFO | train_inner | epoch 004:   2408 / 19564 loss=4.226, nll_loss=2.815, ppl=7.04, wps=10614.9, ups=3.11, wpb=3417.2, bsz=159.6, num_updates=61100, lr=0.000127932, gnorm=1.082, train_wall=23, wall=0
2024-07-18 16:05:46 | INFO | train_inner | epoch 004:   2508 / 19564 loss=4.302, nll_loss=2.9, ppl=7.47, wps=14823.6, ups=4.34, wpb=3418.5, bsz=148.5, num_updates=61200, lr=0.000127827, gnorm=1.128, train_wall=23, wall=0
2024-07-18 16:06:09 | INFO | train_inner | epoch 004:   2608 / 19564 loss=4.345, nll_loss=2.949, ppl=7.72, wps=14852.8, ups=4.33, wpb=3428.8, bsz=129.3, num_updates=61300, lr=0.000127723, gnorm=1.12, train_wall=23, wall=0
2024-07-18 16:06:32 | INFO | train_inner | epoch 004:   2708 / 19564 loss=4.323, nll_loss=2.923, ppl=7.58, wps=14618.2, ups=4.35, wpb=3360.8, bsz=135.6, num_updates=61400, lr=0.000127619, gnorm=1.139, train_wall=23, wall=0
2024-07-18 16:06:56 | INFO | train_inner | epoch 004:   2808 / 19564 loss=4.262, nll_loss=2.854, ppl=7.23, wps=15157.4, ups=4.29, wpb=3534.8, bsz=147.8, num_updates=61500, lr=0.000127515, gnorm=1.045, train_wall=23, wall=0
2024-07-18 16:07:19 | INFO | train_inner | epoch 004:   2908 / 19564 loss=4.271, nll_loss=2.866, ppl=7.29, wps=14906.6, ups=4.34, wpb=3432.2, bsz=143.2, num_updates=61600, lr=0.000127412, gnorm=1.122, train_wall=23, wall=0
2024-07-18 16:07:42 | INFO | train_inner | epoch 004:   3008 / 19564 loss=4.338, nll_loss=2.941, ppl=7.68, wps=14834.3, ups=4.39, wpb=3382.6, bsz=132.2, num_updates=61700, lr=0.000127309, gnorm=1.15, train_wall=23, wall=0
2024-07-18 16:08:05 | INFO | train_inner | epoch 004:   3108 / 19564 loss=4.302, nll_loss=2.901, ppl=7.47, wps=15075, ups=4.33, wpb=3479.6, bsz=145.1, num_updates=61800, lr=0.000127205, gnorm=1.08, train_wall=23, wall=0
2024-07-18 16:08:28 | INFO | train_inner | epoch 004:   3208 / 19564 loss=4.276, nll_loss=2.871, ppl=7.32, wps=15085.7, ups=4.34, wpb=3474.5, bsz=156.4, num_updates=61900, lr=0.000127103, gnorm=1.079, train_wall=23, wall=0
2024-07-18 16:08:51 | INFO | train_inner | epoch 004:   3308 / 19564 loss=4.339, nll_loss=2.941, ppl=7.68, wps=15229, ups=4.33, wpb=3518.2, bsz=129, num_updates=62000, lr=0.000127, gnorm=1.114, train_wall=23, wall=0
2024-07-18 16:08:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:08:54 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.233 | nll_loss 2.721 | ppl 6.59 | wps 44098 | wpb 2872.6 | bsz 51.2 | num_updates 62000 | best_loss 12.094
2024-07-18 16:08:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:08:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_62000.pt (epoch 4 @ 62000 updates, score 4.233) (writing took 4.195460746996105 seconds)
2024-07-18 16:09:21 | INFO | train_inner | epoch 004:   3408 / 19564 loss=4.304, nll_loss=2.902, ppl=7.47, wps=11432, ups=3.32, wpb=3441, bsz=134.6, num_updates=62100, lr=0.000126898, gnorm=1.122, train_wall=23, wall=0
2024-07-18 16:09:44 | INFO | train_inner | epoch 004:   3508 / 19564 loss=4.288, nll_loss=2.884, ppl=7.38, wps=15125.5, ups=4.37, wpb=3460.2, bsz=147.1, num_updates=62200, lr=0.000126796, gnorm=1.11, train_wall=23, wall=0
2024-07-18 16:10:06 | INFO | train_inner | epoch 004:   3608 / 19564 loss=4.378, nll_loss=2.987, ppl=7.93, wps=15026.8, ups=4.43, wpb=3395.7, bsz=132.9, num_updates=62300, lr=0.000126694, gnorm=1.129, train_wall=22, wall=0
2024-07-18 16:10:29 | INFO | train_inner | epoch 004:   3708 / 19564 loss=4.256, nll_loss=2.847, ppl=7.2, wps=15138.3, ups=4.36, wpb=3475.9, bsz=149.1, num_updates=62400, lr=0.000126592, gnorm=1.068, train_wall=23, wall=0
2024-07-18 16:10:52 | INFO | train_inner | epoch 004:   3808 / 19564 loss=4.261, nll_loss=2.854, ppl=7.23, wps=15223.4, ups=4.35, wpb=3500.2, bsz=139.8, num_updates=62500, lr=0.000126491, gnorm=1.114, train_wall=23, wall=0
2024-07-18 16:11:15 | INFO | train_inner | epoch 004:   3908 / 19564 loss=4.261, nll_loss=2.853, ppl=7.23, wps=14912.2, ups=4.33, wpb=3447.1, bsz=126.2, num_updates=62600, lr=0.00012639, gnorm=1.114, train_wall=23, wall=0
2024-07-18 16:11:38 | INFO | train_inner | epoch 004:   4008 / 19564 loss=4.263, nll_loss=2.856, ppl=7.24, wps=14965.7, ups=4.38, wpb=3420.4, bsz=149.4, num_updates=62700, lr=0.000126289, gnorm=1.123, train_wall=23, wall=0
2024-07-18 16:12:01 | INFO | train_inner | epoch 004:   4108 / 19564 loss=4.333, nll_loss=2.935, ppl=7.65, wps=14864.6, ups=4.33, wpb=3432.9, bsz=128.4, num_updates=62800, lr=0.000126189, gnorm=1.147, train_wall=23, wall=0
2024-07-18 16:12:24 | INFO | train_inner | epoch 004:   4208 / 19564 loss=4.261, nll_loss=2.855, ppl=7.24, wps=14739.6, ups=4.36, wpb=3381.9, bsz=148.4, num_updates=62900, lr=0.000126088, gnorm=1.125, train_wall=23, wall=0
2024-07-18 16:12:47 | INFO | train_inner | epoch 004:   4308 / 19564 loss=4.225, nll_loss=2.812, ppl=7.02, wps=15193.9, ups=4.33, wpb=3505.4, bsz=148.2, num_updates=63000, lr=0.000125988, gnorm=1.066, train_wall=23, wall=0
2024-07-18 16:12:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:12:50 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.236 | nll_loss 2.712 | ppl 6.55 | wps 44308.5 | wpb 2872.6 | bsz 51.2 | num_updates 63000 | best_loss 12.094
2024-07-18 16:12:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:12:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_63000.pt (epoch 4 @ 63000 updates, score 4.236) (writing took 4.477546949870884 seconds)
2024-07-18 16:13:18 | INFO | train_inner | epoch 004:   4408 / 19564 loss=4.328, nll_loss=2.929, ppl=7.62, wps=11451.9, ups=3.28, wpb=3493.4, bsz=133, num_updates=63100, lr=0.000125888, gnorm=1.129, train_wall=23, wall=0
2024-07-18 16:13:41 | INFO | train_inner | epoch 004:   4508 / 19564 loss=4.315, nll_loss=2.916, ppl=7.55, wps=14952.2, ups=4.34, wpb=3446.1, bsz=144.2, num_updates=63200, lr=0.000125789, gnorm=1.102, train_wall=23, wall=0
2024-07-18 16:14:04 | INFO | train_inner | epoch 004:   4608 / 19564 loss=4.329, nll_loss=2.932, ppl=7.63, wps=14861.8, ups=4.36, wpb=3406.9, bsz=134.5, num_updates=63300, lr=0.000125689, gnorm=1.105, train_wall=23, wall=0
2024-07-18 16:14:27 | INFO | train_inner | epoch 004:   4708 / 19564 loss=4.354, nll_loss=2.96, ppl=7.78, wps=15119.5, ups=4.34, wpb=3485.3, bsz=141.4, num_updates=63400, lr=0.00012559, gnorm=1.139, train_wall=23, wall=0
2024-07-18 16:14:50 | INFO | train_inner | epoch 004:   4808 / 19564 loss=4.233, nll_loss=2.822, ppl=7.07, wps=14908.4, ups=4.32, wpb=3450.5, bsz=145.8, num_updates=63500, lr=0.000125491, gnorm=1.089, train_wall=23, wall=0
2024-07-18 16:15:13 | INFO | train_inner | epoch 004:   4908 / 19564 loss=4.301, nll_loss=2.899, ppl=7.46, wps=14923.1, ups=4.34, wpb=3435, bsz=137.1, num_updates=63600, lr=0.000125392, gnorm=1.128, train_wall=23, wall=0
2024-07-18 16:15:36 | INFO | train_inner | epoch 004:   5008 / 19564 loss=4.265, nll_loss=2.86, ppl=7.26, wps=14617.6, ups=4.36, wpb=3353, bsz=157.2, num_updates=63700, lr=0.000125294, gnorm=1.166, train_wall=23, wall=0
2024-07-18 16:15:59 | INFO | train_inner | epoch 004:   5108 / 19564 loss=4.256, nll_loss=2.849, ppl=7.21, wps=14925.4, ups=4.35, wpb=3432.2, bsz=153, num_updates=63800, lr=0.000125196, gnorm=1.091, train_wall=23, wall=0
2024-07-18 16:16:22 | INFO | train_inner | epoch 004:   5208 / 19564 loss=4.253, nll_loss=2.845, ppl=7.19, wps=14727.1, ups=4.38, wpb=3363.7, bsz=149.6, num_updates=63900, lr=0.000125098, gnorm=1.124, train_wall=23, wall=0
2024-07-18 16:16:45 | INFO | train_inner | epoch 004:   5308 / 19564 loss=4.269, nll_loss=2.864, ppl=7.28, wps=14813.1, ups=4.32, wpb=3426.8, bsz=149.3, num_updates=64000, lr=0.000125, gnorm=1.112, train_wall=23, wall=0
2024-07-18 16:16:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:16:48 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.215 | nll_loss 2.698 | ppl 6.49 | wps 44383.4 | wpb 2872.6 | bsz 51.2 | num_updates 64000 | best_loss 12.094
2024-07-18 16:16:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:16:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_64000.pt (epoch 4 @ 64000 updates, score 4.215) (writing took 4.393712671473622 seconds)
2024-07-18 16:17:15 | INFO | train_inner | epoch 004:   5408 / 19564 loss=4.243, nll_loss=2.833, ppl=7.13, wps=11392.2, ups=3.3, wpb=3456.7, bsz=139.2, num_updates=64100, lr=0.000124902, gnorm=1.063, train_wall=23, wall=0
2024-07-18 16:17:38 | INFO | train_inner | epoch 004:   5508 / 19564 loss=4.235, nll_loss=2.826, ppl=7.09, wps=14986.3, ups=4.32, wpb=3465.9, bsz=149.9, num_updates=64200, lr=0.000124805, gnorm=1.077, train_wall=23, wall=0
2024-07-18 16:18:01 | INFO | train_inner | epoch 004:   5608 / 19564 loss=4.295, nll_loss=2.893, ppl=7.43, wps=15119.4, ups=4.36, wpb=3469.9, bsz=153.2, num_updates=64300, lr=0.000124708, gnorm=1.13, train_wall=23, wall=0
2024-07-18 16:18:24 | INFO | train_inner | epoch 004:   5708 / 19564 loss=4.265, nll_loss=2.859, ppl=7.26, wps=14794.7, ups=4.36, wpb=3395.4, bsz=134.6, num_updates=64400, lr=0.000124611, gnorm=1.115, train_wall=23, wall=0
2024-07-18 16:18:47 | INFO | train_inner | epoch 004:   5808 / 19564 loss=4.29, nll_loss=2.888, ppl=7.4, wps=14507.8, ups=4.37, wpb=3318.5, bsz=141.3, num_updates=64500, lr=0.000124515, gnorm=1.166, train_wall=23, wall=0
2024-07-18 16:19:10 | INFO | train_inner | epoch 004:   5908 / 19564 loss=4.276, nll_loss=2.87, ppl=7.31, wps=14960.3, ups=4.34, wpb=3449.8, bsz=128.8, num_updates=64600, lr=0.000124418, gnorm=1.094, train_wall=23, wall=0
2024-07-18 16:19:33 | INFO | train_inner | epoch 004:   6008 / 19564 loss=4.296, nll_loss=2.894, ppl=7.43, wps=14944.9, ups=4.34, wpb=3444.7, bsz=138.4, num_updates=64700, lr=0.000124322, gnorm=1.149, train_wall=23, wall=0
2024-07-18 16:19:56 | INFO | train_inner | epoch 004:   6108 / 19564 loss=4.312, nll_loss=2.912, ppl=7.53, wps=15179.3, ups=4.36, wpb=3484.7, bsz=138.4, num_updates=64800, lr=0.000124226, gnorm=1.109, train_wall=23, wall=0
2024-07-18 16:20:19 | INFO | train_inner | epoch 004:   6208 / 19564 loss=4.267, nll_loss=2.862, ppl=7.27, wps=15053.7, ups=4.36, wpb=3452.7, bsz=139.8, num_updates=64900, lr=0.00012413, gnorm=1.092, train_wall=23, wall=0
2024-07-18 16:20:42 | INFO | train_inner | epoch 004:   6308 / 19564 loss=4.285, nll_loss=2.882, ppl=7.37, wps=15339.2, ups=4.32, wpb=3553, bsz=156, num_updates=65000, lr=0.000124035, gnorm=1.074, train_wall=23, wall=0
2024-07-18 16:20:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:20:45 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.204 | nll_loss 2.689 | ppl 6.45 | wps 42442.1 | wpb 2872.6 | bsz 51.2 | num_updates 65000 | best_loss 12.094
2024-07-18 16:20:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:20:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_65000.pt (epoch 4 @ 65000 updates, score 4.204) (writing took 4.835887191817164 seconds)
2024-07-18 16:21:13 | INFO | train_inner | epoch 004:   6408 / 19564 loss=4.238, nll_loss=2.828, ppl=7.1, wps=11109.3, ups=3.21, wpb=3458.6, bsz=139.8, num_updates=65100, lr=0.000123939, gnorm=1.081, train_wall=23, wall=0
2024-07-18 16:21:37 | INFO | train_inner | epoch 004:   6508 / 19564 loss=4.231, nll_loss=2.82, ppl=7.06, wps=14771.7, ups=4.3, wpb=3432.7, bsz=155.3, num_updates=65200, lr=0.000123844, gnorm=1.103, train_wall=23, wall=0
2024-07-18 16:22:00 | INFO | train_inner | epoch 004:   6608 / 19564 loss=4.335, nll_loss=2.938, ppl=7.66, wps=15201.7, ups=4.36, wpb=3489.3, bsz=130.1, num_updates=65300, lr=0.000123749, gnorm=1.11, train_wall=23, wall=0
2024-07-18 16:22:23 | INFO | train_inner | epoch 004:   6708 / 19564 loss=4.343, nll_loss=2.949, ppl=7.72, wps=14809, ups=4.38, wpb=3383.1, bsz=145.2, num_updates=65400, lr=0.000123655, gnorm=1.19, train_wall=23, wall=0
2024-07-18 16:22:46 | INFO | train_inner | epoch 004:   6808 / 19564 loss=4.25, nll_loss=2.842, ppl=7.17, wps=15250.8, ups=4.29, wpb=3557.1, bsz=147.5, num_updates=65500, lr=0.00012356, gnorm=1.055, train_wall=23, wall=0
2024-07-18 16:23:09 | INFO | train_inner | epoch 004:   6908 / 19564 loss=4.256, nll_loss=2.85, ppl=7.21, wps=15031.8, ups=4.35, wpb=3454.7, bsz=164.6, num_updates=65600, lr=0.000123466, gnorm=1.114, train_wall=23, wall=0
2024-07-18 16:23:32 | INFO | train_inner | epoch 004:   7008 / 19564 loss=4.24, nll_loss=2.831, ppl=7.12, wps=15059.1, ups=4.34, wpb=3468.8, bsz=154.6, num_updates=65700, lr=0.000123372, gnorm=1.063, train_wall=23, wall=0
2024-07-18 16:23:55 | INFO | train_inner | epoch 004:   7108 / 19564 loss=4.297, nll_loss=2.896, ppl=7.44, wps=14989.9, ups=4.37, wpb=3428.2, bsz=135.3, num_updates=65800, lr=0.000123278, gnorm=1.126, train_wall=23, wall=0
2024-07-18 16:24:18 | INFO | train_inner | epoch 004:   7208 / 19564 loss=4.249, nll_loss=2.841, ppl=7.16, wps=15039, ups=4.36, wpb=3448, bsz=144.3, num_updates=65900, lr=0.000123185, gnorm=1.089, train_wall=23, wall=0
2024-07-18 16:24:41 | INFO | train_inner | epoch 004:   7308 / 19564 loss=4.262, nll_loss=2.857, ppl=7.24, wps=14894.3, ups=4.38, wpb=3402.6, bsz=148.2, num_updates=66000, lr=0.000123091, gnorm=1.113, train_wall=23, wall=0
2024-07-18 16:24:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:24:43 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.213 | nll_loss 2.694 | ppl 6.47 | wps 44174.4 | wpb 2872.6 | bsz 51.2 | num_updates 66000 | best_loss 12.094
2024-07-18 16:24:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:24:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_66000.pt (epoch 4 @ 66000 updates, score 4.213) (writing took 4.178398109041154 seconds)
2024-07-18 16:25:11 | INFO | train_inner | epoch 004:   7408 / 19564 loss=4.342, nll_loss=2.948, ppl=7.72, wps=11223.9, ups=3.33, wpb=3373.1, bsz=141.6, num_updates=66100, lr=0.000122998, gnorm=1.139, train_wall=23, wall=0
2024-07-18 16:25:34 | INFO | train_inner | epoch 004:   7508 / 19564 loss=4.206, nll_loss=2.791, ppl=6.92, wps=15146.1, ups=4.31, wpb=3513, bsz=151.6, num_updates=66200, lr=0.000122905, gnorm=1.051, train_wall=23, wall=0
2024-07-18 16:25:57 | INFO | train_inner | epoch 004:   7608 / 19564 loss=4.236, nll_loss=2.827, ppl=7.09, wps=15095.9, ups=4.32, wpb=3497, bsz=143, num_updates=66300, lr=0.000122813, gnorm=1.067, train_wall=23, wall=0
2024-07-18 16:26:20 | INFO | train_inner | epoch 004:   7708 / 19564 loss=4.279, nll_loss=2.876, ppl=7.34, wps=14867.9, ups=4.34, wpb=3427, bsz=158.7, num_updates=66400, lr=0.00012272, gnorm=1.121, train_wall=23, wall=0
2024-07-18 16:26:43 | INFO | train_inner | epoch 004:   7808 / 19564 loss=4.286, nll_loss=2.884, ppl=7.38, wps=14863, ups=4.37, wpb=3402.8, bsz=137.4, num_updates=66500, lr=0.000122628, gnorm=1.13, train_wall=23, wall=0
2024-07-18 16:27:06 | INFO | train_inner | epoch 004:   7908 / 19564 loss=4.27, nll_loss=2.866, ppl=7.29, wps=14834.1, ups=4.37, wpb=3393.9, bsz=149.4, num_updates=66600, lr=0.000122536, gnorm=1.135, train_wall=23, wall=0
2024-07-18 16:27:29 | INFO | train_inner | epoch 004:   8008 / 19564 loss=4.281, nll_loss=2.878, ppl=7.35, wps=14782.1, ups=4.37, wpb=3383.3, bsz=140.1, num_updates=66700, lr=0.000122444, gnorm=1.151, train_wall=23, wall=0
2024-07-18 16:27:52 | INFO | train_inner | epoch 004:   8108 / 19564 loss=4.304, nll_loss=2.904, ppl=7.48, wps=14748.9, ups=4.35, wpb=3392.1, bsz=137.5, num_updates=66800, lr=0.000122352, gnorm=1.115, train_wall=23, wall=0
2024-07-18 16:28:15 | INFO | train_inner | epoch 004:   8208 / 19564 loss=4.208, nll_loss=2.795, ppl=6.94, wps=14892.8, ups=4.36, wpb=3416.6, bsz=148.1, num_updates=66900, lr=0.000122261, gnorm=1.097, train_wall=23, wall=0
2024-07-18 16:28:38 | INFO | train_inner | epoch 004:   8308 / 19564 loss=4.252, nll_loss=2.845, ppl=7.18, wps=15098.6, ups=4.29, wpb=3521.8, bsz=152.7, num_updates=67000, lr=0.000122169, gnorm=1.072, train_wall=23, wall=0
2024-07-18 16:28:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:28:41 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.195 | nll_loss 2.674 | ppl 6.38 | wps 43838.9 | wpb 2872.6 | bsz 51.2 | num_updates 67000 | best_loss 12.094
2024-07-18 16:28:41 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:28:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_67000.pt (epoch 4 @ 67000 updates, score 4.195) (writing took 5.425078664906323 seconds)
2024-07-18 16:29:09 | INFO | train_inner | epoch 004:   8408 / 19564 loss=4.272, nll_loss=2.868, ppl=7.3, wps=10880.2, ups=3.18, wpb=3426.6, bsz=141.7, num_updates=67100, lr=0.000122078, gnorm=1.117, train_wall=23, wall=0
2024-07-18 16:29:32 | INFO | train_inner | epoch 004:   8508 / 19564 loss=4.287, nll_loss=2.884, ppl=7.38, wps=15019.9, ups=4.36, wpb=3441.8, bsz=141.1, num_updates=67200, lr=0.000121988, gnorm=1.149, train_wall=23, wall=0
2024-07-18 16:29:56 | INFO | train_inner | epoch 004:   8608 / 19564 loss=4.246, nll_loss=2.838, ppl=7.15, wps=15260.8, ups=4.31, wpb=3538.2, bsz=140.2, num_updates=67300, lr=0.000121897, gnorm=1.059, train_wall=23, wall=0
2024-07-18 16:30:18 | INFO | train_inner | epoch 004:   8708 / 19564 loss=4.305, nll_loss=2.907, ppl=7.5, wps=14830.1, ups=4.35, wpb=3406.7, bsz=145.7, num_updates=67400, lr=0.000121806, gnorm=1.142, train_wall=23, wall=0
2024-07-18 16:30:41 | INFO | train_inner | epoch 004:   8808 / 19564 loss=4.285, nll_loss=2.882, ppl=7.37, wps=15063.1, ups=4.38, wpb=3436.2, bsz=134.9, num_updates=67500, lr=0.000121716, gnorm=1.123, train_wall=23, wall=0
2024-07-18 16:31:04 | INFO | train_inner | epoch 004:   8908 / 19564 loss=4.259, nll_loss=2.852, ppl=7.22, wps=15031.5, ups=4.35, wpb=3456, bsz=140.8, num_updates=67600, lr=0.000121626, gnorm=1.088, train_wall=23, wall=0
2024-07-18 16:31:27 | INFO | train_inner | epoch 004:   9008 / 19564 loss=4.272, nll_loss=2.868, ppl=7.3, wps=15098.1, ups=4.34, wpb=3476.8, bsz=138.3, num_updates=67700, lr=0.000121536, gnorm=1.081, train_wall=23, wall=0
2024-07-18 16:31:50 | INFO | train_inner | epoch 004:   9108 / 19564 loss=4.249, nll_loss=2.842, ppl=7.17, wps=15258.9, ups=4.37, wpb=3493.8, bsz=138.2, num_updates=67800, lr=0.000121447, gnorm=1.084, train_wall=23, wall=0
2024-07-18 16:32:13 | INFO | train_inner | epoch 004:   9208 / 19564 loss=4.298, nll_loss=2.897, ppl=7.45, wps=14920.2, ups=4.34, wpb=3437.2, bsz=135, num_updates=67900, lr=0.000121357, gnorm=1.14, train_wall=23, wall=0
2024-07-18 16:32:36 | INFO | train_inner | epoch 004:   9308 / 19564 loss=4.289, nll_loss=2.889, ppl=7.41, wps=14772.3, ups=4.36, wpb=3387.9, bsz=148.9, num_updates=68000, lr=0.000121268, gnorm=1.139, train_wall=23, wall=0
2024-07-18 16:32:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:32:39 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.196 | nll_loss 2.668 | ppl 6.35 | wps 44233.3 | wpb 2872.6 | bsz 51.2 | num_updates 68000 | best_loss 12.094
2024-07-18 16:32:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:32:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_68000.pt (epoch 4 @ 68000 updates, score 4.196) (writing took 4.882698860019445 seconds)
2024-07-18 16:33:07 | INFO | train_inner | epoch 004:   9408 / 19564 loss=4.292, nll_loss=2.889, ppl=7.41, wps=11330.4, ups=3.23, wpb=3507.4, bsz=124.6, num_updates=68100, lr=0.000121179, gnorm=1.099, train_wall=23, wall=0
2024-07-18 16:33:30 | INFO | train_inner | epoch 004:   9508 / 19564 loss=4.211, nll_loss=2.799, ppl=6.96, wps=15036.1, ups=4.37, wpb=3440.5, bsz=154.2, num_updates=68200, lr=0.00012109, gnorm=1.083, train_wall=23, wall=0
2024-07-18 16:33:53 | INFO | train_inner | epoch 004:   9608 / 19564 loss=4.195, nll_loss=2.78, ppl=6.87, wps=15181.1, ups=4.29, wpb=3541.2, bsz=153.1, num_updates=68300, lr=0.000121001, gnorm=1.096, train_wall=23, wall=0
2024-07-18 16:34:16 | INFO | train_inner | epoch 004:   9708 / 19564 loss=4.274, nll_loss=2.869, ppl=7.31, wps=14910.9, ups=4.32, wpb=3449.9, bsz=136.7, num_updates=68400, lr=0.000120913, gnorm=1.087, train_wall=23, wall=0
2024-07-18 16:34:40 | INFO | train_inner | epoch 004:   9808 / 19564 loss=4.284, nll_loss=2.882, ppl=7.37, wps=14913.7, ups=4.33, wpb=3440.8, bsz=139.5, num_updates=68500, lr=0.000120824, gnorm=1.119, train_wall=23, wall=0
2024-07-18 16:35:03 | INFO | train_inner | epoch 004:   9908 / 19564 loss=4.284, nll_loss=2.883, ppl=7.37, wps=15043.4, ups=4.36, wpb=3453.8, bsz=139.4, num_updates=68600, lr=0.000120736, gnorm=1.115, train_wall=23, wall=0
2024-07-18 16:35:26 | INFO | train_inner | epoch 004:  10008 / 19564 loss=4.256, nll_loss=2.849, ppl=7.21, wps=14870.7, ups=4.29, wpb=3470.1, bsz=140.2, num_updates=68700, lr=0.000120648, gnorm=1.099, train_wall=23, wall=0
2024-07-18 16:35:49 | INFO | train_inner | epoch 004:  10108 / 19564 loss=4.23, nll_loss=2.82, ppl=7.06, wps=15105, ups=4.3, wpb=3510.8, bsz=148.3, num_updates=68800, lr=0.000120561, gnorm=1.09, train_wall=23, wall=0
2024-07-18 16:36:12 | INFO | train_inner | epoch 004:  10208 / 19564 loss=4.23, nll_loss=2.819, ppl=7.06, wps=14893.2, ups=4.31, wpb=3454.4, bsz=141.4, num_updates=68900, lr=0.000120473, gnorm=1.083, train_wall=23, wall=0
2024-07-18 16:36:36 | INFO | train_inner | epoch 004:  10308 / 19564 loss=4.237, nll_loss=2.828, ppl=7.1, wps=15054.9, ups=4.3, wpb=3498.3, bsz=146.5, num_updates=69000, lr=0.000120386, gnorm=1.088, train_wall=23, wall=0
2024-07-18 16:36:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:36:38 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.184 | nll_loss 2.661 | ppl 6.33 | wps 44459.8 | wpb 2872.6 | bsz 51.2 | num_updates 69000 | best_loss 12.094
2024-07-18 16:36:38 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:36:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_69000.pt (epoch 4 @ 69000 updates, score 4.184) (writing took 4.516418194398284 seconds)
2024-07-18 16:37:06 | INFO | train_inner | epoch 004:  10408 / 19564 loss=4.277, nll_loss=2.874, ppl=7.33, wps=11240.2, ups=3.29, wpb=3415.1, bsz=135.4, num_updates=69100, lr=0.000120299, gnorm=1.124, train_wall=23, wall=0
2024-07-18 16:37:29 | INFO | train_inner | epoch 004:  10508 / 19564 loss=4.227, nll_loss=2.818, ppl=7.05, wps=14845, ups=4.36, wpb=3405.8, bsz=163, num_updates=69200, lr=0.000120212, gnorm=1.118, train_wall=23, wall=0
2024-07-18 16:37:52 | INFO | train_inner | epoch 004:  10608 / 19564 loss=4.26, nll_loss=2.854, ppl=7.23, wps=14953.7, ups=4.32, wpb=3458.4, bsz=140, num_updates=69300, lr=0.000120125, gnorm=1.129, train_wall=23, wall=0
2024-07-18 16:38:15 | INFO | train_inner | epoch 004:  10708 / 19564 loss=4.218, nll_loss=2.807, ppl=7, wps=14837.7, ups=4.38, wpb=3386.3, bsz=152.7, num_updates=69400, lr=0.000120038, gnorm=1.127, train_wall=23, wall=0
2024-07-18 16:38:38 | INFO | train_inner | epoch 004:  10808 / 19564 loss=4.374, nll_loss=2.984, ppl=7.91, wps=14999, ups=4.37, wpb=3432.1, bsz=122.6, num_updates=69500, lr=0.000119952, gnorm=1.147, train_wall=23, wall=0
2024-07-18 16:39:01 | INFO | train_inner | epoch 004:  10908 / 19564 loss=4.253, nll_loss=2.847, ppl=7.19, wps=15180.1, ups=4.31, wpb=3522, bsz=153.8, num_updates=69600, lr=0.000119866, gnorm=1.095, train_wall=23, wall=0
2024-07-18 16:39:24 | INFO | train_inner | epoch 004:  11008 / 19564 loss=4.22, nll_loss=2.809, ppl=7.01, wps=14933.3, ups=4.32, wpb=3454.3, bsz=138.6, num_updates=69700, lr=0.00011978, gnorm=1.102, train_wall=23, wall=0
2024-07-18 16:39:47 | INFO | train_inner | epoch 004:  11108 / 19564 loss=4.254, nll_loss=2.848, ppl=7.2, wps=15019.9, ups=4.36, wpb=3445, bsz=142.3, num_updates=69800, lr=0.000119694, gnorm=1.117, train_wall=23, wall=0
2024-07-18 16:40:10 | INFO | train_inner | epoch 004:  11208 / 19564 loss=4.292, nll_loss=2.891, ppl=7.42, wps=15081, ups=4.33, wpb=3480.3, bsz=134.2, num_updates=69900, lr=0.000119608, gnorm=1.109, train_wall=23, wall=0
2024-07-18 16:40:33 | INFO | train_inner | epoch 004:  11308 / 19564 loss=4.265, nll_loss=2.86, ppl=7.26, wps=15012.1, ups=4.36, wpb=3445.5, bsz=129.3, num_updates=70000, lr=0.000119523, gnorm=1.128, train_wall=23, wall=0
2024-07-18 16:40:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:40:36 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.185 | nll_loss 2.662 | ppl 6.33 | wps 44139.7 | wpb 2872.6 | bsz 51.2 | num_updates 70000 | best_loss 12.094
2024-07-18 16:40:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:40:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_70000.pt (epoch 4 @ 70000 updates, score 4.185) (writing took 5.456083334051073 seconds)
2024-07-18 16:41:05 | INFO | train_inner | epoch 004:  11408 / 19564 loss=4.253, nll_loss=2.846, ppl=7.19, wps=10951.1, ups=3.16, wpb=3460.2, bsz=140.3, num_updates=70100, lr=0.000119438, gnorm=1.08, train_wall=23, wall=0
2024-07-18 16:41:28 | INFO | train_inner | epoch 004:  11508 / 19564 loss=4.225, nll_loss=2.815, ppl=7.04, wps=15055.5, ups=4.3, wpb=3502.2, bsz=155.4, num_updates=70200, lr=0.000119352, gnorm=1.072, train_wall=23, wall=0
2024-07-18 16:41:51 | INFO | train_inner | epoch 004:  11608 / 19564 loss=4.254, nll_loss=2.848, ppl=7.2, wps=15323.4, ups=4.35, wpb=3523.4, bsz=154.1, num_updates=70300, lr=0.000119268, gnorm=1.076, train_wall=23, wall=0
2024-07-18 16:42:14 | INFO | train_inner | epoch 004:  11708 / 19564 loss=4.206, nll_loss=2.793, ppl=6.93, wps=14968.1, ups=4.33, wpb=3453.1, bsz=144.6, num_updates=70400, lr=0.000119183, gnorm=1.075, train_wall=23, wall=0
2024-07-18 16:42:37 | INFO | train_inner | epoch 004:  11808 / 19564 loss=4.224, nll_loss=2.815, ppl=7.04, wps=14884.1, ups=4.32, wpb=3448.1, bsz=163.3, num_updates=70500, lr=0.000119098, gnorm=1.109, train_wall=23, wall=0
2024-07-18 16:43:00 | INFO | train_inner | epoch 004:  11908 / 19564 loss=4.262, nll_loss=2.858, ppl=7.25, wps=14572.4, ups=4.36, wpb=3344, bsz=153.7, num_updates=70600, lr=0.000119014, gnorm=1.159, train_wall=23, wall=0
2024-07-18 16:43:23 | INFO | train_inner | epoch 004:  12008 / 19564 loss=4.263, nll_loss=2.859, ppl=7.25, wps=14921.9, ups=4.36, wpb=3425.3, bsz=151, num_updates=70700, lr=0.00011893, gnorm=1.105, train_wall=23, wall=0
2024-07-18 16:43:46 | INFO | train_inner | epoch 004:  12108 / 19564 loss=4.238, nll_loss=2.83, ppl=7.11, wps=14888, ups=4.33, wpb=3439.8, bsz=136.1, num_updates=70800, lr=0.000118846, gnorm=1.105, train_wall=23, wall=0
2024-07-18 16:44:09 | INFO | train_inner | epoch 004:  12208 / 19564 loss=4.202, nll_loss=2.788, ppl=6.91, wps=15237, ups=4.31, wpb=3538.2, bsz=141.8, num_updates=70900, lr=0.000118762, gnorm=1.042, train_wall=23, wall=0
2024-07-18 16:44:32 | INFO | train_inner | epoch 004:  12308 / 19564 loss=4.329, nll_loss=2.934, ppl=7.64, wps=14849.3, ups=4.36, wpb=3402, bsz=124.7, num_updates=71000, lr=0.000118678, gnorm=1.162, train_wall=23, wall=0
2024-07-18 16:44:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:44:35 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.178 | nll_loss 2.652 | ppl 6.28 | wps 44429.5 | wpb 2872.6 | bsz 51.2 | num_updates 71000 | best_loss 12.094
2024-07-18 16:44:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:44:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_71000.pt (epoch 4 @ 71000 updates, score 4.178) (writing took 5.5502668507397175 seconds)
2024-07-18 16:45:04 | INFO | train_inner | epoch 004:  12408 / 19564 loss=4.21, nll_loss=2.798, ppl=6.95, wps=10963.9, ups=3.16, wpb=3466.6, bsz=154.1, num_updates=71100, lr=0.000118595, gnorm=1.078, train_wall=23, wall=0
2024-07-18 16:45:27 | INFO | train_inner | epoch 004:  12508 / 19564 loss=4.26, nll_loss=2.854, ppl=7.23, wps=15348.7, ups=4.3, wpb=3571.1, bsz=128, num_updates=71200, lr=0.000118511, gnorm=1.099, train_wall=23, wall=0
2024-07-18 16:45:50 | INFO | train_inner | epoch 004:  12608 / 19564 loss=4.273, nll_loss=2.869, ppl=7.31, wps=14759.2, ups=4.37, wpb=3379.7, bsz=140.6, num_updates=71300, lr=0.000118428, gnorm=1.149, train_wall=23, wall=0
2024-07-18 16:46:13 | INFO | train_inner | epoch 004:  12708 / 19564 loss=4.276, nll_loss=2.874, ppl=7.33, wps=14716.9, ups=4.34, wpb=3393.1, bsz=140.2, num_updates=71400, lr=0.000118345, gnorm=1.118, train_wall=23, wall=0
2024-07-18 16:46:36 | INFO | train_inner | epoch 004:  12808 / 19564 loss=4.264, nll_loss=2.859, ppl=7.26, wps=14830.2, ups=4.37, wpb=3389.8, bsz=146.5, num_updates=71500, lr=0.000118262, gnorm=1.143, train_wall=23, wall=0
2024-07-18 16:46:59 | INFO | train_inner | epoch 004:  12908 / 19564 loss=4.226, nll_loss=2.816, ppl=7.04, wps=14729.6, ups=4.36, wpb=3379, bsz=151.5, num_updates=71600, lr=0.00011818, gnorm=1.115, train_wall=23, wall=0
2024-07-18 16:47:22 | INFO | train_inner | epoch 004:  13008 / 19564 loss=4.214, nll_loss=2.802, ppl=6.98, wps=14869.8, ups=4.32, wpb=3441.4, bsz=142.6, num_updates=71700, lr=0.000118097, gnorm=1.093, train_wall=23, wall=0
2024-07-18 16:47:46 | INFO | train_inner | epoch 004:  13108 / 19564 loss=4.209, nll_loss=2.797, ppl=6.95, wps=14481.9, ups=4.22, wpb=3435.8, bsz=142.2, num_updates=71800, lr=0.000118015, gnorm=1.121, train_wall=24, wall=0
2024-07-18 16:48:09 | INFO | train_inner | epoch 004:  13208 / 19564 loss=4.197, nll_loss=2.784, ppl=6.89, wps=14845.4, ups=4.34, wpb=3417.8, bsz=151.9, num_updates=71900, lr=0.000117933, gnorm=1.087, train_wall=23, wall=0
2024-07-18 16:48:32 | INFO | train_inner | epoch 004:  13308 / 19564 loss=4.25, nll_loss=2.844, ppl=7.18, wps=14768.7, ups=4.3, wpb=3437.3, bsz=155.4, num_updates=72000, lr=0.000117851, gnorm=1.11, train_wall=23, wall=0
2024-07-18 16:48:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:48:35 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.167 | nll_loss 2.647 | ppl 6.26 | wps 44050.1 | wpb 2872.6 | bsz 51.2 | num_updates 72000 | best_loss 12.094
2024-07-18 16:48:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:48:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_72000.pt (epoch 4 @ 72000 updates, score 4.167) (writing took 5.828947556205094 seconds)
2024-07-18 16:49:04 | INFO | train_inner | epoch 004:  13408 / 19564 loss=4.237, nll_loss=2.828, ppl=7.1, wps=10759.8, ups=3.13, wpb=3440.1, bsz=143.1, num_updates=72100, lr=0.000117769, gnorm=1.133, train_wall=23, wall=0
2024-07-18 16:49:27 | INFO | train_inner | epoch 004:  13508 / 19564 loss=4.253, nll_loss=2.846, ppl=7.19, wps=14756.3, ups=4.3, wpb=3434.4, bsz=118.6, num_updates=72200, lr=0.000117688, gnorm=1.144, train_wall=23, wall=0
2024-07-18 16:49:50 | INFO | train_inner | epoch 004:  13608 / 19564 loss=4.321, nll_loss=2.924, ppl=7.59, wps=14566.6, ups=4.34, wpb=3354.4, bsz=133.3, num_updates=72300, lr=0.000117606, gnorm=1.172, train_wall=23, wall=0
2024-07-18 16:50:13 | INFO | train_inner | epoch 004:  13708 / 19564 loss=4.329, nll_loss=2.934, ppl=7.64, wps=15069.1, ups=4.33, wpb=3478.9, bsz=134.2, num_updates=72400, lr=0.000117525, gnorm=1.127, train_wall=23, wall=0
2024-07-18 16:50:37 | INFO | train_inner | epoch 004:  13808 / 19564 loss=4.263, nll_loss=2.86, ppl=7.26, wps=14870.2, ups=4.28, wpb=3472, bsz=141.8, num_updates=72500, lr=0.000117444, gnorm=1.086, train_wall=23, wall=0
2024-07-18 16:51:00 | INFO | train_inner | epoch 004:  13908 / 19564 loss=4.229, nll_loss=2.819, ppl=7.05, wps=15155.3, ups=4.3, wpb=3523.5, bsz=139.7, num_updates=72600, lr=0.000117363, gnorm=1.073, train_wall=23, wall=0
2024-07-18 16:51:23 | INFO | train_inner | epoch 004:  14008 / 19564 loss=4.273, nll_loss=2.871, ppl=7.31, wps=15048.7, ups=4.35, wpb=3459.1, bsz=128.5, num_updates=72700, lr=0.000117282, gnorm=1.108, train_wall=23, wall=0
2024-07-18 16:51:46 | INFO | train_inner | epoch 004:  14108 / 19564 loss=4.277, nll_loss=2.875, ppl=7.33, wps=14771.5, ups=4.33, wpb=3414.1, bsz=139.2, num_updates=72800, lr=0.000117202, gnorm=1.112, train_wall=23, wall=0
2024-07-18 16:52:10 | INFO | train_inner | epoch 004:  14208 / 19564 loss=4.191, nll_loss=2.777, ppl=6.86, wps=14867.9, ups=4.25, wpb=3497.6, bsz=148.2, num_updates=72900, lr=0.000117121, gnorm=1.062, train_wall=23, wall=0
2024-07-18 16:52:33 | INFO | train_inner | epoch 004:  14308 / 19564 loss=4.267, nll_loss=2.862, ppl=7.27, wps=14689.1, ups=4.36, wpb=3367, bsz=132.7, num_updates=73000, lr=0.000117041, gnorm=1.163, train_wall=23, wall=0
2024-07-18 16:52:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:52:35 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.165 | nll_loss 2.635 | ppl 6.21 | wps 44304.7 | wpb 2872.6 | bsz 51.2 | num_updates 73000 | best_loss 12.094
2024-07-18 16:52:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:52:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_73000.pt (epoch 4 @ 73000 updates, score 4.165) (writing took 8.351212543435395 seconds)
2024-07-18 16:53:07 | INFO | train_inner | epoch 004:  14408 / 19564 loss=4.227, nll_loss=2.818, ppl=7.05, wps=10051.1, ups=2.92, wpb=3447.8, bsz=144.5, num_updates=73100, lr=0.000116961, gnorm=1.107, train_wall=23, wall=0
2024-07-18 16:53:30 | INFO | train_inner | epoch 004:  14508 / 19564 loss=4.187, nll_loss=2.773, ppl=6.83, wps=14778.4, ups=4.31, wpb=3427.2, bsz=147.6, num_updates=73200, lr=0.000116881, gnorm=1.093, train_wall=23, wall=0
2024-07-18 16:53:53 | INFO | train_inner | epoch 004:  14608 / 19564 loss=4.328, nll_loss=2.932, ppl=7.63, wps=14993.8, ups=4.39, wpb=3414.8, bsz=115.8, num_updates=73300, lr=0.000116801, gnorm=1.143, train_wall=23, wall=0
2024-07-18 16:54:16 | INFO | train_inner | epoch 004:  14708 / 19564 loss=4.208, nll_loss=2.797, ppl=6.95, wps=15083.9, ups=4.31, wpb=3501.5, bsz=149.8, num_updates=73400, lr=0.000116722, gnorm=1.075, train_wall=23, wall=0
2024-07-18 16:54:40 | INFO | train_inner | epoch 004:  14808 / 19564 loss=4.229, nll_loss=2.82, ppl=7.06, wps=15251.9, ups=4.26, wpb=3583.6, bsz=153.2, num_updates=73500, lr=0.000116642, gnorm=1.083, train_wall=23, wall=0
2024-07-18 16:55:03 | INFO | train_inner | epoch 004:  14908 / 19564 loss=4.286, nll_loss=2.884, ppl=7.38, wps=15025.6, ups=4.34, wpb=3459.6, bsz=133.6, num_updates=73600, lr=0.000116563, gnorm=1.106, train_wall=23, wall=0
2024-07-18 16:55:26 | INFO | train_inner | epoch 004:  15008 / 19564 loss=4.263, nll_loss=2.86, ppl=7.26, wps=15018.1, ups=4.35, wpb=3455.9, bsz=154.5, num_updates=73700, lr=0.000116484, gnorm=1.11, train_wall=23, wall=0
2024-07-18 16:55:49 | INFO | train_inner | epoch 004:  15108 / 19564 loss=4.22, nll_loss=2.811, ppl=7.02, wps=14970.2, ups=4.35, wpb=3440.3, bsz=164.6, num_updates=73800, lr=0.000116405, gnorm=1.095, train_wall=23, wall=0
2024-07-18 16:56:11 | INFO | train_inner | epoch 004:  15208 / 19564 loss=4.227, nll_loss=2.819, ppl=7.06, wps=14618.1, ups=4.37, wpb=3348.6, bsz=148.7, num_updates=73900, lr=0.000116326, gnorm=1.117, train_wall=23, wall=0
2024-07-18 16:56:35 | INFO | train_inner | epoch 004:  15308 / 19564 loss=4.168, nll_loss=2.75, ppl=6.73, wps=15089.7, ups=4.31, wpb=3503, bsz=137.2, num_updates=74000, lr=0.000116248, gnorm=1.066, train_wall=23, wall=0
2024-07-18 16:56:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:56:38 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.157 | nll_loss 2.622 | ppl 6.16 | wps 44393.9 | wpb 2872.6 | bsz 51.2 | num_updates 74000 | best_loss 12.094
2024-07-18 16:56:38 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:56:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_74000.pt (epoch 4 @ 74000 updates, score 4.157) (writing took 7.6076854839921 seconds)
2024-07-18 16:57:08 | INFO | train_inner | epoch 004:  15408 / 19564 loss=4.308, nll_loss=2.91, ppl=7.52, wps=10229.1, ups=2.98, wpb=3429.1, bsz=139.9, num_updates=74100, lr=0.000116169, gnorm=1.128, train_wall=23, wall=0
2024-07-18 16:57:31 | INFO | train_inner | epoch 004:  15508 / 19564 loss=4.307, nll_loss=2.909, ppl=7.51, wps=15098.4, ups=4.38, wpb=3450.8, bsz=130.4, num_updates=74200, lr=0.000116091, gnorm=1.111, train_wall=23, wall=0
2024-07-18 16:57:54 | INFO | train_inner | epoch 004:  15608 / 19564 loss=4.215, nll_loss=2.805, ppl=6.99, wps=14693.8, ups=4.38, wpb=3357.4, bsz=152.7, num_updates=74300, lr=0.000116013, gnorm=1.138, train_wall=23, wall=0
2024-07-18 16:58:17 | INFO | train_inner | epoch 004:  15708 / 19564 loss=4.281, nll_loss=2.881, ppl=7.37, wps=14701.8, ups=4.39, wpb=3348.8, bsz=145, num_updates=74400, lr=0.000115935, gnorm=1.182, train_wall=23, wall=0
2024-07-18 16:58:40 | INFO | train_inner | epoch 004:  15808 / 19564 loss=4.234, nll_loss=2.827, ppl=7.09, wps=15413.3, ups=4.3, wpb=3582.4, bsz=162.2, num_updates=74500, lr=0.000115857, gnorm=1.078, train_wall=23, wall=0
2024-07-18 16:59:03 | INFO | train_inner | epoch 004:  15908 / 19564 loss=4.252, nll_loss=2.847, ppl=7.19, wps=14757.3, ups=4.36, wpb=3383.7, bsz=122.8, num_updates=74600, lr=0.000115779, gnorm=1.188, train_wall=23, wall=0
2024-07-18 16:59:26 | INFO | train_inner | epoch 004:  16008 / 19564 loss=4.243, nll_loss=2.836, ppl=7.14, wps=15019.3, ups=4.33, wpb=3466.1, bsz=133.9, num_updates=74700, lr=0.000115702, gnorm=1.105, train_wall=23, wall=0
2024-07-18 16:59:49 | INFO | train_inner | epoch 004:  16108 / 19564 loss=4.205, nll_loss=2.792, ppl=6.93, wps=15118.4, ups=4.33, wpb=3489.8, bsz=134.3, num_updates=74800, lr=0.000115624, gnorm=1.072, train_wall=23, wall=0
2024-07-18 17:00:12 | INFO | train_inner | epoch 004:  16208 / 19564 loss=4.325, nll_loss=2.93, ppl=7.62, wps=14928.4, ups=4.39, wpb=3400.4, bsz=123.6, num_updates=74900, lr=0.000115547, gnorm=1.159, train_wall=23, wall=0
2024-07-18 17:00:35 | INFO | train_inner | epoch 004:  16308 / 19564 loss=4.276, nll_loss=2.873, ppl=7.33, wps=14881.4, ups=4.37, wpb=3406.7, bsz=122.7, num_updates=75000, lr=0.00011547, gnorm=1.095, train_wall=23, wall=0
2024-07-18 17:00:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:00:38 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.138 | nll_loss 2.61 | ppl 6.11 | wps 44229.7 | wpb 2872.6 | bsz 51.2 | num_updates 75000 | best_loss 12.094
2024-07-18 17:00:38 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:00:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_75000.pt (epoch 4 @ 75000 updates, score 4.138) (writing took 6.334411328658462 seconds)
2024-07-18 17:01:07 | INFO | train_inner | epoch 004:  16408 / 19564 loss=4.223, nll_loss=2.815, ppl=7.04, wps=10892.7, ups=3.09, wpb=3529.7, bsz=149.7, num_updates=75100, lr=0.000115393, gnorm=1.096, train_wall=23, wall=0
2024-07-18 17:01:30 | INFO | train_inner | epoch 004:  16508 / 19564 loss=4.289, nll_loss=2.889, ppl=7.41, wps=15045.3, ups=4.37, wpb=3442.5, bsz=129.7, num_updates=75200, lr=0.000115316, gnorm=1.122, train_wall=23, wall=0
2024-07-18 17:01:53 | INFO | train_inner | epoch 004:  16608 / 19564 loss=4.261, nll_loss=2.856, ppl=7.24, wps=15030.3, ups=4.33, wpb=3471, bsz=133.8, num_updates=75300, lr=0.00011524, gnorm=1.094, train_wall=23, wall=0
2024-07-18 17:02:16 | INFO | train_inner | epoch 004:  16708 / 19564 loss=4.242, nll_loss=2.836, ppl=7.14, wps=14892.3, ups=4.36, wpb=3414, bsz=146.6, num_updates=75400, lr=0.000115163, gnorm=1.124, train_wall=23, wall=0
2024-07-18 17:02:39 | INFO | train_inner | epoch 004:  16808 / 19564 loss=4.258, nll_loss=2.854, ppl=7.23, wps=14856.4, ups=4.37, wpb=3397, bsz=135, num_updates=75500, lr=0.000115087, gnorm=1.13, train_wall=23, wall=0
2024-07-18 17:03:02 | INFO | train_inner | epoch 004:  16908 / 19564 loss=4.262, nll_loss=2.858, ppl=7.25, wps=14900.2, ups=4.37, wpb=3412.3, bsz=140.8, num_updates=75600, lr=0.000115011, gnorm=1.128, train_wall=23, wall=0
2024-07-18 17:03:25 | INFO | train_inner | epoch 004:  17008 / 19564 loss=4.265, nll_loss=2.862, ppl=7.27, wps=14809, ups=4.34, wpb=3408.5, bsz=132.1, num_updates=75700, lr=0.000114935, gnorm=1.146, train_wall=23, wall=0
2024-07-18 17:03:48 | INFO | train_inner | epoch 004:  17108 / 19564 loss=4.214, nll_loss=2.805, ppl=6.99, wps=14934.8, ups=4.33, wpb=3450.9, bsz=172.1, num_updates=75800, lr=0.000114859, gnorm=1.099, train_wall=23, wall=0
2024-07-18 17:04:11 | INFO | train_inner | epoch 004:  17208 / 19564 loss=4.243, nll_loss=2.836, ppl=7.14, wps=14976.9, ups=4.37, wpb=3425.9, bsz=132.4, num_updates=75900, lr=0.000114783, gnorm=1.098, train_wall=23, wall=0
2024-07-18 17:04:34 | INFO | train_inner | epoch 004:  17308 / 19564 loss=4.303, nll_loss=2.905, ppl=7.49, wps=14752.1, ups=4.37, wpb=3372.2, bsz=138.7, num_updates=76000, lr=0.000114708, gnorm=1.19, train_wall=23, wall=0
2024-07-18 17:04:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:04:37 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.157 | nll_loss 2.637 | ppl 6.22 | wps 44209.9 | wpb 2872.6 | bsz 51.2 | num_updates 76000 | best_loss 12.094
2024-07-18 17:04:37 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:04:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_76000.pt (epoch 4 @ 76000 updates, score 4.157) (writing took 7.050338045693934 seconds)
2024-07-18 17:05:07 | INFO | train_inner | epoch 004:  17408 / 19564 loss=4.233, nll_loss=2.826, ppl=7.09, wps=10567.6, ups=3.02, wpb=3497.2, bsz=149.7, num_updates=76100, lr=0.000114632, gnorm=1.064, train_wall=23, wall=0
2024-07-18 17:05:30 | INFO | train_inner | epoch 004:  17508 / 19564 loss=4.25, nll_loss=2.846, ppl=7.19, wps=15136.3, ups=4.38, wpb=3457.7, bsz=140.8, num_updates=76200, lr=0.000114557, gnorm=1.112, train_wall=23, wall=0
2024-07-18 17:05:53 | INFO | train_inner | epoch 004:  17608 / 19564 loss=4.203, nll_loss=2.791, ppl=6.92, wps=14759.8, ups=4.25, wpb=3474.5, bsz=146.4, num_updates=76300, lr=0.000114482, gnorm=1.097, train_wall=23, wall=0
2024-07-18 17:06:16 | INFO | train_inner | epoch 004:  17708 / 19564 loss=4.214, nll_loss=2.804, ppl=6.98, wps=14924.3, ups=4.33, wpb=3448.2, bsz=144.7, num_updates=76400, lr=0.000114407, gnorm=1.134, train_wall=23, wall=0
2024-07-18 17:06:39 | INFO | train_inner | epoch 004:  17808 / 19564 loss=4.231, nll_loss=2.823, ppl=7.07, wps=15141.9, ups=4.31, wpb=3512.2, bsz=140.1, num_updates=76500, lr=0.000114332, gnorm=1.081, train_wall=23, wall=0
2024-07-18 17:07:02 | INFO | train_inner | epoch 004:  17908 / 19564 loss=4.225, nll_loss=2.817, ppl=7.05, wps=15022.4, ups=4.34, wpb=3465.1, bsz=158.3, num_updates=76600, lr=0.000114258, gnorm=1.106, train_wall=23, wall=0
2024-07-18 17:07:26 | INFO | train_inner | epoch 004:  18008 / 19564 loss=4.317, nll_loss=2.92, ppl=7.57, wps=14970.2, ups=4.34, wpb=3450.2, bsz=126.6, num_updates=76700, lr=0.000114183, gnorm=1.167, train_wall=23, wall=0
2024-07-18 17:07:48 | INFO | train_inner | epoch 004:  18108 / 19564 loss=4.247, nll_loss=2.842, ppl=7.17, wps=14576.8, ups=4.37, wpb=3335.5, bsz=149.8, num_updates=76800, lr=0.000114109, gnorm=1.151, train_wall=23, wall=0
2024-07-18 17:08:11 | INFO | train_inner | epoch 004:  18208 / 19564 loss=4.249, nll_loss=2.844, ppl=7.18, wps=14739.6, ups=4.37, wpb=3373.7, bsz=139.1, num_updates=76900, lr=0.000114035, gnorm=1.107, train_wall=23, wall=0
2024-07-18 17:08:34 | INFO | train_inner | epoch 004:  18308 / 19564 loss=4.189, nll_loss=2.775, ppl=6.85, wps=14803.7, ups=4.32, wpb=3424.7, bsz=149.8, num_updates=77000, lr=0.000113961, gnorm=1.114, train_wall=23, wall=0
2024-07-18 17:08:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:08:37 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.133 | nll_loss 2.612 | ppl 6.11 | wps 43934.6 | wpb 2872.6 | bsz 51.2 | num_updates 77000 | best_loss 12.094
2024-07-18 17:08:37 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:08:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_77000.pt (epoch 4 @ 77000 updates, score 4.133) (writing took 5.181871797889471 seconds)
2024-07-18 17:09:06 | INFO | train_inner | epoch 004:  18408 / 19564 loss=4.309, nll_loss=2.912, ppl=7.53, wps=11134.2, ups=3.21, wpb=3469.7, bsz=134.2, num_updates=77100, lr=0.000113887, gnorm=1.124, train_wall=23, wall=0
2024-07-18 17:09:29 | INFO | train_inner | epoch 004:  18508 / 19564 loss=4.215, nll_loss=2.804, ppl=6.98, wps=15303.4, ups=4.34, wpb=3526.7, bsz=146.1, num_updates=77200, lr=0.000113813, gnorm=1.12, train_wall=23, wall=0
2024-07-18 17:09:52 | INFO | train_inner | epoch 004:  18608 / 19564 loss=4.276, nll_loss=2.874, ppl=7.33, wps=14707.3, ups=4.34, wpb=3390.5, bsz=128.7, num_updates=77300, lr=0.000113739, gnorm=1.135, train_wall=23, wall=0
2024-07-18 17:10:15 | INFO | train_inner | epoch 004:  18708 / 19564 loss=4.268, nll_loss=2.865, ppl=7.28, wps=15019.7, ups=4.32, wpb=3475.2, bsz=137.4, num_updates=77400, lr=0.000113666, gnorm=1.112, train_wall=23, wall=0
2024-07-18 17:10:38 | INFO | train_inner | epoch 004:  18808 / 19564 loss=4.215, nll_loss=2.806, ppl=6.99, wps=15076.4, ups=4.31, wpb=3501.4, bsz=158.6, num_updates=77500, lr=0.000113592, gnorm=1.073, train_wall=23, wall=0
2024-07-18 17:11:02 | INFO | train_inner | epoch 004:  18908 / 19564 loss=4.197, nll_loss=2.785, ppl=6.89, wps=14672.4, ups=4.26, wpb=3445.3, bsz=139.5, num_updates=77600, lr=0.000113519, gnorm=1.105, train_wall=23, wall=0
2024-07-18 17:11:25 | INFO | train_inner | epoch 004:  19008 / 19564 loss=4.318, nll_loss=2.923, ppl=7.58, wps=14950.7, ups=4.32, wpb=3456.9, bsz=128.9, num_updates=77700, lr=0.000113446, gnorm=1.117, train_wall=23, wall=0
2024-07-18 17:11:48 | INFO | train_inner | epoch 004:  19108 / 19564 loss=4.223, nll_loss=2.814, ppl=7.03, wps=14946.8, ups=4.27, wpb=3501.3, bsz=145.8, num_updates=77800, lr=0.000113373, gnorm=1.069, train_wall=23, wall=0
2024-07-18 17:12:12 | INFO | train_inner | epoch 004:  19208 / 19564 loss=4.225, nll_loss=2.816, ppl=7.04, wps=14804.9, ups=4.27, wpb=3471.2, bsz=134.3, num_updates=77900, lr=0.0001133, gnorm=1.104, train_wall=23, wall=0
2024-07-18 17:12:35 | INFO | train_inner | epoch 004:  19308 / 19564 loss=4.211, nll_loss=2.801, ppl=6.97, wps=14828.8, ups=4.32, wpb=3429.4, bsz=153.2, num_updates=78000, lr=0.000113228, gnorm=1.127, train_wall=23, wall=0
2024-07-18 17:12:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:12:38 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.126 | nll_loss 2.602 | ppl 6.07 | wps 43962 | wpb 2872.6 | bsz 51.2 | num_updates 78000 | best_loss 12.094
2024-07-18 17:12:38 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:12:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_78000.pt (epoch 4 @ 78000 updates, score 4.126) (writing took 5.907052963972092 seconds)
2024-07-18 17:13:06 | INFO | train_inner | epoch 004:  19408 / 19564 loss=4.28, nll_loss=2.88, ppl=7.36, wps=10794.8, ups=3.14, wpb=3435.2, bsz=144.8, num_updates=78100, lr=0.000113155, gnorm=1.108, train_wall=23, wall=0
2024-07-18 17:13:30 | INFO | train_inner | epoch 004:  19508 / 19564 loss=4.211, nll_loss=2.801, ppl=6.97, wps=15010.5, ups=4.33, wpb=3464.1, bsz=157.1, num_updates=78200, lr=0.000113083, gnorm=1.092, train_wall=23, wall=0
2024-07-18 17:13:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:13:45 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.125 | nll_loss 2.605 | ppl 6.08 | wps 44053.6 | wpb 2872.6 | bsz 51.2 | num_updates 78256 | best_loss 12.094
2024-07-18 17:13:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:13:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 4 @ 78256 updates, score 4.125) (writing took 6.758811978623271 seconds)
2024-07-18 17:13:52 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2024-07-18 17:13:52 | INFO | train | epoch 004 | loss 4.266 | nll_loss 2.862 | ppl 7.27 | wps 14377.6 | ups 4.17 | wpb 3446.5 | bsz 142.2 | num_updates 78256 | lr 0.000113042 | gnorm 1.11 | train_wall 4473 | wall 0
2024-07-18 17:13:52 | INFO | fairseq.trainer | begin training epoch 5
2024-07-18 17:14:03 | INFO | train_inner | epoch 005:     44 / 19564 loss=4.212, nll_loss=2.803, ppl=6.98, wps=10447.2, ups=3.03, wpb=3444.8, bsz=154.2, num_updates=78300, lr=0.000113011, gnorm=1.09, train_wall=23, wall=0
2024-07-18 17:14:26 | INFO | train_inner | epoch 005:    144 / 19564 loss=4.154, nll_loss=2.735, ppl=6.66, wps=15047.7, ups=4.34, wpb=3469.4, bsz=144.6, num_updates=78400, lr=0.000112938, gnorm=1.098, train_wall=23, wall=0
2024-07-18 17:14:48 | INFO | train_inner | epoch 005:    244 / 19564 loss=4.21, nll_loss=2.799, ppl=6.96, wps=14610.7, ups=4.39, wpb=3331.1, bsz=147, num_updates=78500, lr=0.000112867, gnorm=1.186, train_wall=23, wall=0
2024-07-18 17:15:12 | INFO | train_inner | epoch 005:    344 / 19564 loss=4.19, nll_loss=2.775, ppl=6.85, wps=15033.5, ups=4.31, wpb=3485.4, bsz=146.5, num_updates=78600, lr=0.000112795, gnorm=1.09, train_wall=23, wall=0
2024-07-18 17:15:34 | INFO | train_inner | epoch 005:    444 / 19564 loss=4.229, nll_loss=2.821, ppl=7.07, wps=14861.7, ups=4.4, wpb=3381, bsz=133.2, num_updates=78700, lr=0.000112723, gnorm=1.125, train_wall=23, wall=0
2024-07-18 17:15:58 | INFO | train_inner | epoch 005:    544 / 19564 loss=4.203, nll_loss=2.791, ppl=6.92, wps=14776.1, ups=4.29, wpb=3440.6, bsz=147.9, num_updates=78800, lr=0.000112651, gnorm=1.122, train_wall=23, wall=0
2024-07-18 17:16:21 | INFO | train_inner | epoch 005:    644 / 19564 loss=4.177, nll_loss=2.76, ppl=6.77, wps=14678.2, ups=4.32, wpb=3399, bsz=133.9, num_updates=78900, lr=0.00011258, gnorm=1.098, train_wall=23, wall=0
2024-07-18 17:16:44 | INFO | train_inner | epoch 005:    744 / 19564 loss=4.176, nll_loss=2.762, ppl=6.78, wps=14926, ups=4.3, wpb=3471.5, bsz=156.6, num_updates=79000, lr=0.000112509, gnorm=1.097, train_wall=23, wall=0
2024-07-18 17:16:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:16:47 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.139 | nll_loss 2.614 | ppl 6.12 | wps 43752.2 | wpb 2872.6 | bsz 51.2 | num_updates 79000 | best_loss 12.094
2024-07-18 17:16:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:16:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_79000.pt (epoch 5 @ 79000 updates, score 4.139) (writing took 7.269850852899253 seconds)
2024-07-18 17:17:17 | INFO | train_inner | epoch 005:    844 / 19564 loss=4.233, nll_loss=2.826, ppl=7.09, wps=10417.9, ups=2.99, wpb=3485.8, bsz=147.7, num_updates=79100, lr=0.000112438, gnorm=1.105, train_wall=23, wall=0
2024-07-18 17:17:40 | INFO | train_inner | epoch 005:    944 / 19564 loss=4.19, nll_loss=2.776, ppl=6.85, wps=14952.3, ups=4.37, wpb=3422.6, bsz=138, num_updates=79200, lr=0.000112367, gnorm=1.111, train_wall=23, wall=0
2024-07-18 17:18:04 | INFO | train_inner | epoch 005:   1044 / 19564 loss=4.167, nll_loss=2.75, ppl=6.73, wps=15155.4, ups=4.28, wpb=3537.7, bsz=156.8, num_updates=79300, lr=0.000112296, gnorm=1.074, train_wall=23, wall=0
2024-07-18 17:18:27 | INFO | train_inner | epoch 005:   1144 / 19564 loss=4.205, nll_loss=2.792, ppl=6.93, wps=14813.4, ups=4.33, wpb=3418.7, bsz=126.9, num_updates=79400, lr=0.000112225, gnorm=1.137, train_wall=23, wall=0
2024-07-18 17:18:50 | INFO | train_inner | epoch 005:   1244 / 19564 loss=4.207, nll_loss=2.796, ppl=6.94, wps=14756.1, ups=4.31, wpb=3424.4, bsz=148.2, num_updates=79500, lr=0.000112154, gnorm=1.095, train_wall=23, wall=0
2024-07-18 17:19:13 | INFO | train_inner | epoch 005:   1344 / 19564 loss=4.227, nll_loss=2.818, ppl=7.05, wps=15277.1, ups=4.3, wpb=3552.4, bsz=137, num_updates=79600, lr=0.000112084, gnorm=1.112, train_wall=23, wall=0
2024-07-18 17:19:36 | INFO | train_inner | epoch 005:   1444 / 19564 loss=4.187, nll_loss=2.774, ppl=6.84, wps=14870.6, ups=4.34, wpb=3430, bsz=158.8, num_updates=79700, lr=0.000112014, gnorm=1.097, train_wall=23, wall=0
2024-07-18 17:19:59 | INFO | train_inner | epoch 005:   1544 / 19564 loss=4.257, nll_loss=2.851, ppl=7.22, wps=14928.4, ups=4.36, wpb=3426.7, bsz=126, num_updates=79800, lr=0.000111943, gnorm=1.127, train_wall=23, wall=0
2024-07-18 17:20:22 | INFO | train_inner | epoch 005:   1644 / 19564 loss=4.168, nll_loss=2.751, ppl=6.73, wps=15010.7, ups=4.33, wpb=3463.2, bsz=141.2, num_updates=79900, lr=0.000111873, gnorm=1.09, train_wall=23, wall=0
2024-07-18 17:20:45 | INFO | train_inner | epoch 005:   1744 / 19564 loss=4.156, nll_loss=2.738, ppl=6.67, wps=14636.9, ups=4.34, wpb=3369.1, bsz=131.7, num_updates=80000, lr=0.000111803, gnorm=1.124, train_wall=23, wall=0
2024-07-18 17:20:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:20:48 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.13 | nll_loss 2.599 | ppl 6.06 | wps 44042.5 | wpb 2872.6 | bsz 51.2 | num_updates 80000 | best_loss 12.094
2024-07-18 17:20:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:20:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_80000.pt (epoch 5 @ 80000 updates, score 4.13) (writing took 6.296092006377876 seconds)
2024-07-18 17:21:18 | INFO | train_inner | epoch 005:   1844 / 19564 loss=4.142, nll_loss=2.722, ppl=6.6, wps=10667.4, ups=3.07, wpb=3473.4, bsz=156.6, num_updates=80100, lr=0.000111734, gnorm=1.08, train_wall=23, wall=0
2024-07-18 17:21:41 | INFO | train_inner | epoch 005:   1944 / 19564 loss=4.194, nll_loss=2.78, ppl=6.87, wps=15107.1, ups=4.34, wpb=3476.9, bsz=144.7, num_updates=80200, lr=0.000111664, gnorm=1.092, train_wall=23, wall=0
2024-07-18 17:22:04 | INFO | train_inner | epoch 005:   2044 / 19564 loss=4.181, nll_loss=2.767, ppl=6.81, wps=14333.1, ups=4.39, wpb=3263.7, bsz=144.7, num_updates=80300, lr=0.000111594, gnorm=1.152, train_wall=23, wall=0
2024-07-18 17:22:27 | INFO | train_inner | epoch 005:   2144 / 19564 loss=4.247, nll_loss=2.841, ppl=7.16, wps=14663, ups=4.34, wpb=3378.7, bsz=137, num_updates=80400, lr=0.000111525, gnorm=1.141, train_wall=23, wall=0
2024-07-18 17:22:50 | INFO | train_inner | epoch 005:   2244 / 19564 loss=4.204, nll_loss=2.793, ppl=6.93, wps=15209.3, ups=4.32, wpb=3523.6, bsz=159.8, num_updates=80500, lr=0.000111456, gnorm=1.095, train_wall=23, wall=0
2024-07-18 17:23:13 | INFO | train_inner | epoch 005:   2344 / 19564 loss=4.174, nll_loss=2.757, ppl=6.76, wps=14983.9, ups=4.3, wpb=3484.3, bsz=138.2, num_updates=80600, lr=0.000111386, gnorm=1.088, train_wall=23, wall=0
2024-07-18 17:23:37 | INFO | train_inner | epoch 005:   2444 / 19564 loss=4.139, nll_loss=2.718, ppl=6.58, wps=14914.3, ups=4.27, wpb=3492.9, bsz=148.2, num_updates=80700, lr=0.000111317, gnorm=1.1, train_wall=23, wall=0
2024-07-18 17:24:00 | INFO | train_inner | epoch 005:   2544 / 19564 loss=4.242, nll_loss=2.836, ppl=7.14, wps=14779.2, ups=4.31, wpb=3432.4, bsz=137.2, num_updates=80800, lr=0.000111249, gnorm=1.153, train_wall=23, wall=0
2024-07-18 17:24:23 | INFO | train_inner | epoch 005:   2644 / 19564 loss=4.201, nll_loss=2.789, ppl=6.91, wps=14956, ups=4.31, wpb=3472, bsz=128.3, num_updates=80900, lr=0.00011118, gnorm=1.093, train_wall=23, wall=0
2024-07-18 17:24:46 | INFO | train_inner | epoch 005:   2744 / 19564 loss=4.173, nll_loss=2.757, ppl=6.76, wps=14780.6, ups=4.3, wpb=3433.4, bsz=126.4, num_updates=81000, lr=0.000111111, gnorm=1.104, train_wall=23, wall=0
2024-07-18 17:24:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:24:49 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.117 | nll_loss 2.589 | ppl 6.02 | wps 43059.8 | wpb 2872.6 | bsz 51.2 | num_updates 81000 | best_loss 12.094
2024-07-18 17:24:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:24:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_81000.pt (epoch 5 @ 81000 updates, score 4.117) (writing took 5.677188587374985 seconds)
2024-07-18 17:25:18 | INFO | train_inner | epoch 005:   2844 / 19564 loss=4.187, nll_loss=2.771, ppl=6.83, wps=10837.5, ups=3.14, wpb=3450.8, bsz=129.2, num_updates=81100, lr=0.000111043, gnorm=1.119, train_wall=23, wall=0
2024-07-18 17:25:41 | INFO | train_inner | epoch 005:   2944 / 19564 loss=4.163, nll_loss=2.746, ppl=6.71, wps=14976.6, ups=4.31, wpb=3471.3, bsz=152.9, num_updates=81200, lr=0.000110974, gnorm=1.088, train_wall=23, wall=0
2024-07-18 17:26:05 | INFO | train_inner | epoch 005:   3044 / 19564 loss=4.137, nll_loss=2.718, ppl=6.58, wps=14662.4, ups=4.29, wpb=3419.9, bsz=163.7, num_updates=81300, lr=0.000110906, gnorm=1.099, train_wall=23, wall=0
2024-07-18 17:26:28 | INFO | train_inner | epoch 005:   3144 / 19564 loss=4.175, nll_loss=2.758, ppl=6.77, wps=15103.2, ups=4.27, wpb=3534.6, bsz=137.9, num_updates=81400, lr=0.000110838, gnorm=1.135, train_wall=23, wall=0
2024-07-18 17:26:51 | INFO | train_inner | epoch 005:   3244 / 19564 loss=4.209, nll_loss=2.799, ppl=6.96, wps=14863.7, ups=4.29, wpb=3462.3, bsz=148.1, num_updates=81500, lr=0.00011077, gnorm=1.125, train_wall=23, wall=0
2024-07-18 17:27:15 | INFO | train_inner | epoch 005:   3344 / 19564 loss=4.151, nll_loss=2.733, ppl=6.65, wps=14826.1, ups=4.26, wpb=3483.6, bsz=154.7, num_updates=81600, lr=0.000110702, gnorm=1.089, train_wall=23, wall=0
2024-07-18 17:27:38 | INFO | train_inner | epoch 005:   3444 / 19564 loss=4.212, nll_loss=2.801, ppl=6.97, wps=14944.2, ups=4.3, wpb=3473.8, bsz=139.1, num_updates=81700, lr=0.000110634, gnorm=1.125, train_wall=23, wall=0
2024-07-18 17:28:01 | INFO | train_inner | epoch 005:   3544 / 19564 loss=4.22, nll_loss=2.811, ppl=7.02, wps=14802.3, ups=4.28, wpb=3456.8, bsz=145.1, num_updates=81800, lr=0.000110566, gnorm=1.109, train_wall=23, wall=0
2024-07-18 17:28:25 | INFO | train_inner | epoch 005:   3644 / 19564 loss=4.063, nll_loss=2.633, ppl=6.2, wps=14848.7, ups=4.21, wpb=3529.6, bsz=160.6, num_updates=81900, lr=0.000110499, gnorm=1.039, train_wall=24, wall=0
2024-07-18 17:28:48 | INFO | train_inner | epoch 005:   3744 / 19564 loss=4.226, nll_loss=2.817, ppl=7.05, wps=14752, ups=4.35, wpb=3389.3, bsz=127.4, num_updates=82000, lr=0.000110432, gnorm=1.139, train_wall=23, wall=0
2024-07-18 17:28:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:28:51 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.118 | nll_loss 2.59 | ppl 6.02 | wps 44097.7 | wpb 2872.6 | bsz 51.2 | num_updates 82000 | best_loss 12.094
2024-07-18 17:28:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:28:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_82000.pt (epoch 5 @ 82000 updates, score 4.118) (writing took 6.669014303945005 seconds)
2024-07-18 17:29:21 | INFO | train_inner | epoch 005:   3844 / 19564 loss=4.176, nll_loss=2.762, ppl=6.78, wps=10479.3, ups=3.04, wpb=3445.7, bsz=155.4, num_updates=82100, lr=0.000110364, gnorm=1.096, train_wall=23, wall=0
2024-07-18 17:29:44 | INFO | train_inner | epoch 005:   3944 / 19564 loss=4.206, nll_loss=2.795, ppl=6.94, wps=15117.3, ups=4.32, wpb=3503, bsz=151, num_updates=82200, lr=0.000110297, gnorm=1.102, train_wall=23, wall=0
2024-07-18 17:30:07 | INFO | train_inner | epoch 005:   4044 / 19564 loss=4.229, nll_loss=2.821, ppl=7.07, wps=14827.1, ups=4.33, wpb=3421, bsz=132, num_updates=82300, lr=0.00011023, gnorm=1.137, train_wall=23, wall=0
2024-07-18 17:30:30 | INFO | train_inner | epoch 005:   4144 / 19564 loss=4.284, nll_loss=2.883, ppl=7.38, wps=14827, ups=4.33, wpb=3424.1, bsz=125.1, num_updates=82400, lr=0.000110163, gnorm=1.126, train_wall=23, wall=0
2024-07-18 17:30:54 | INFO | train_inner | epoch 005:   4244 / 19564 loss=4.157, nll_loss=2.739, ppl=6.68, wps=14794.9, ups=4.31, wpb=3435.6, bsz=149.7, num_updates=82500, lr=0.000110096, gnorm=1.084, train_wall=23, wall=0
2024-07-18 17:31:17 | INFO | train_inner | epoch 005:   4344 / 19564 loss=4.185, nll_loss=2.771, ppl=6.83, wps=15331.1, ups=4.29, wpb=3572.1, bsz=139.8, num_updates=82600, lr=0.00011003, gnorm=1.075, train_wall=23, wall=0
2024-07-18 17:31:40 | INFO | train_inner | epoch 005:   4444 / 19564 loss=4.247, nll_loss=2.842, ppl=7.17, wps=14771.8, ups=4.33, wpb=3414.7, bsz=130, num_updates=82700, lr=0.000109963, gnorm=1.175, train_wall=23, wall=0
2024-07-18 17:32:03 | INFO | train_inner | epoch 005:   4544 / 19564 loss=4.148, nll_loss=2.728, ppl=6.62, wps=14613, ups=4.3, wpb=3396.2, bsz=132.6, num_updates=82800, lr=0.000109897, gnorm=1.105, train_wall=23, wall=0
2024-07-18 17:32:26 | INFO | train_inner | epoch 005:   4644 / 19564 loss=4.143, nll_loss=2.723, ppl=6.6, wps=14973.5, ups=4.31, wpb=3470.4, bsz=150.2, num_updates=82900, lr=0.00010983, gnorm=1.09, train_wall=23, wall=0
2024-07-18 17:32:50 | INFO | train_inner | epoch 005:   4744 / 19564 loss=4.193, nll_loss=2.78, ppl=6.87, wps=14937.2, ups=4.26, wpb=3506.3, bsz=140.2, num_updates=83000, lr=0.000109764, gnorm=1.066, train_wall=23, wall=0
2024-07-18 17:32:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:32:53 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.104 | nll_loss 2.573 | ppl 5.95 | wps 43381.3 | wpb 2872.6 | bsz 51.2 | num_updates 83000 | best_loss 12.094
2024-07-18 17:32:53 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:32:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_83000.pt (epoch 5 @ 83000 updates, score 4.104) (writing took 5.866470104083419 seconds)
2024-07-18 17:33:22 | INFO | train_inner | epoch 005:   4844 / 19564 loss=4.187, nll_loss=2.774, ppl=6.84, wps=10711.6, ups=3.11, wpb=3446.1, bsz=141.7, num_updates=83100, lr=0.000109698, gnorm=1.103, train_wall=23, wall=0
2024-07-18 17:33:45 | INFO | train_inner | epoch 005:   4944 / 19564 loss=4.269, nll_loss=2.866, ppl=7.29, wps=14684.7, ups=4.35, wpb=3376.7, bsz=131.9, num_updates=83200, lr=0.000109632, gnorm=1.163, train_wall=23, wall=0
2024-07-18 17:34:08 | INFO | train_inner | epoch 005:   5044 / 19564 loss=4.139, nll_loss=2.717, ppl=6.58, wps=14878.9, ups=4.3, wpb=3457.3, bsz=135.9, num_updates=83300, lr=0.000109566, gnorm=1.095, train_wall=23, wall=0
2024-07-18 17:34:32 | INFO | train_inner | epoch 005:   5144 / 19564 loss=4.156, nll_loss=2.738, ppl=6.67, wps=15036.2, ups=4.24, wpb=3542.6, bsz=154.6, num_updates=83400, lr=0.000109501, gnorm=1.073, train_wall=23, wall=0
2024-07-18 17:34:55 | INFO | train_inner | epoch 005:   5244 / 19564 loss=4.188, nll_loss=2.774, ppl=6.84, wps=14774.4, ups=4.27, wpb=3456.3, bsz=132.5, num_updates=83500, lr=0.000109435, gnorm=1.141, train_wall=23, wall=0
2024-07-18 17:35:19 | INFO | train_inner | epoch 005:   5344 / 19564 loss=4.209, nll_loss=2.798, ppl=6.96, wps=15049.3, ups=4.24, wpb=3549.7, bsz=132, num_updates=83600, lr=0.00010937, gnorm=1.081, train_wall=23, wall=0
2024-07-18 17:35:42 | INFO | train_inner | epoch 005:   5444 / 19564 loss=4.158, nll_loss=2.741, ppl=6.68, wps=15087.2, ups=4.27, wpb=3530.2, bsz=142.3, num_updates=83700, lr=0.000109304, gnorm=1.078, train_wall=23, wall=0
2024-07-18 17:36:06 | INFO | train_inner | epoch 005:   5544 / 19564 loss=4.241, nll_loss=2.835, ppl=7.14, wps=14691.2, ups=4.26, wpb=3452.2, bsz=138.1, num_updates=83800, lr=0.000109239, gnorm=1.155, train_wall=23, wall=0
2024-07-18 17:36:30 | INFO | train_inner | epoch 005:   5644 / 19564 loss=4.119, nll_loss=2.697, ppl=6.48, wps=14738.3, ups=4.18, wpb=3528.3, bsz=166.1, num_updates=83900, lr=0.000109174, gnorm=1.072, train_wall=24, wall=0
2024-07-18 17:36:53 | INFO | train_inner | epoch 005:   5744 / 19564 loss=4.173, nll_loss=2.759, ppl=6.77, wps=14791.1, ups=4.24, wpb=3489.1, bsz=156.7, num_updates=84000, lr=0.000109109, gnorm=1.116, train_wall=23, wall=0
2024-07-18 17:36:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:36:56 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.102 | nll_loss 2.577 | ppl 5.97 | wps 43796.2 | wpb 2872.6 | bsz 51.2 | num_updates 84000 | best_loss 12.094
2024-07-18 17:36:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:37:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_84000.pt (epoch 5 @ 84000 updates, score 4.102) (writing took 6.5681989043951035 seconds)
2024-07-18 17:37:26 | INFO | train_inner | epoch 005:   5844 / 19564 loss=4.193, nll_loss=2.78, ppl=6.87, wps=10513.1, ups=3.06, wpb=3440.8, bsz=146, num_updates=84100, lr=0.000109044, gnorm=1.11, train_wall=23, wall=0
2024-07-18 17:37:49 | INFO | train_inner | epoch 005:   5944 / 19564 loss=4.159, nll_loss=2.741, ppl=6.69, wps=15202, ups=4.27, wpb=3562.9, bsz=141.8, num_updates=84200, lr=0.000108979, gnorm=1.076, train_wall=23, wall=0
2024-07-18 17:38:13 | INFO | train_inner | epoch 005:   6044 / 19564 loss=4.116, nll_loss=2.693, ppl=6.47, wps=14843.4, ups=4.2, wpb=3530.4, bsz=147.8, num_updates=84300, lr=0.000108915, gnorm=1.06, train_wall=24, wall=0
2024-07-18 17:38:37 | INFO | train_inner | epoch 005:   6144 / 19564 loss=4.15, nll_loss=2.731, ppl=6.64, wps=15011.7, ups=4.3, wpb=3492.4, bsz=141, num_updates=84400, lr=0.00010885, gnorm=1.092, train_wall=23, wall=0
2024-07-18 17:39:00 | INFO | train_inner | epoch 005:   6244 / 19564 loss=4.24, nll_loss=2.835, ppl=7.13, wps=14942.7, ups=4.35, wpb=3435.3, bsz=138.5, num_updates=84500, lr=0.000108786, gnorm=1.13, train_wall=23, wall=0
2024-07-18 17:39:23 | INFO | train_inner | epoch 005:   6344 / 19564 loss=4.234, nll_loss=2.827, ppl=7.1, wps=14704.8, ups=4.34, wpb=3389.2, bsz=139.7, num_updates=84600, lr=0.000108721, gnorm=1.153, train_wall=23, wall=0
2024-07-18 17:39:46 | INFO | train_inner | epoch 005:   6444 / 19564 loss=4.215, nll_loss=2.806, ppl=6.99, wps=15101.3, ups=4.35, wpb=3468.7, bsz=154.8, num_updates=84700, lr=0.000108657, gnorm=1.16, train_wall=23, wall=0
2024-07-18 17:40:09 | INFO | train_inner | epoch 005:   6544 / 19564 loss=4.152, nll_loss=2.732, ppl=6.65, wps=14941.8, ups=4.33, wpb=3453.1, bsz=128.8, num_updates=84800, lr=0.000108593, gnorm=1.09, train_wall=23, wall=0
2024-07-18 17:40:32 | INFO | train_inner | epoch 005:   6644 / 19564 loss=4.166, nll_loss=2.75, ppl=6.73, wps=14954.8, ups=4.32, wpb=3459.8, bsz=144.1, num_updates=84900, lr=0.000108529, gnorm=1.145, train_wall=23, wall=0
2024-07-18 17:40:55 | INFO | train_inner | epoch 005:   6744 / 19564 loss=4.208, nll_loss=2.797, ppl=6.95, wps=15137.2, ups=4.3, wpb=3517, bsz=140.4, num_updates=85000, lr=0.000108465, gnorm=1.084, train_wall=23, wall=0
2024-07-18 17:40:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:40:58 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.09 | nll_loss 2.564 | ppl 5.92 | wps 44168.5 | wpb 2872.6 | bsz 51.2 | num_updates 85000 | best_loss 12.094
2024-07-18 17:40:58 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:41:07 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_85000.pt (epoch 5 @ 85000 updates, score 4.09) (writing took 8.57826950121671 seconds)
2024-07-18 17:41:30 | INFO | train_inner | epoch 005:   6844 / 19564 loss=4.23, nll_loss=2.822, ppl=7.07, wps=9789.1, ups=2.9, wpb=3380.5, bsz=128.2, num_updates=85100, lr=0.000108401, gnorm=1.153, train_wall=23, wall=0
2024-07-18 17:41:52 | INFO | train_inner | epoch 005:   6944 / 19564 loss=4.215, nll_loss=2.806, ppl=7, wps=15187.7, ups=4.37, wpb=3476.3, bsz=143.8, num_updates=85200, lr=0.000108338, gnorm=1.103, train_wall=23, wall=0
2024-07-18 17:42:15 | INFO | train_inner | epoch 005:   7044 / 19564 loss=4.215, nll_loss=2.806, ppl=6.99, wps=15152.1, ups=4.34, wpb=3491.6, bsz=148.1, num_updates=85300, lr=0.000108274, gnorm=1.106, train_wall=23, wall=0
2024-07-18 17:42:39 | INFO | train_inner | epoch 005:   7144 / 19564 loss=4.131, nll_loss=2.71, ppl=6.54, wps=15207.8, ups=4.3, wpb=3532.8, bsz=134.6, num_updates=85400, lr=0.000108211, gnorm=1.062, train_wall=23, wall=0
2024-07-18 17:43:02 | INFO | train_inner | epoch 005:   7244 / 19564 loss=4.224, nll_loss=2.816, ppl=7.04, wps=14925.3, ups=4.38, wpb=3408.5, bsz=136.2, num_updates=85500, lr=0.000108148, gnorm=1.144, train_wall=23, wall=0
2024-07-18 17:43:25 | INFO | train_inner | epoch 005:   7344 / 19564 loss=4.162, nll_loss=2.746, ppl=6.71, wps=15015.7, ups=4.33, wpb=3464.8, bsz=166.7, num_updates=85600, lr=0.000108084, gnorm=1.104, train_wall=23, wall=0
2024-07-18 17:43:48 | INFO | train_inner | epoch 005:   7444 / 19564 loss=4.151, nll_loss=2.732, ppl=6.65, wps=14674.9, ups=4.35, wpb=3374.9, bsz=143, num_updates=85700, lr=0.000108021, gnorm=1.129, train_wall=23, wall=0
2024-07-18 17:44:11 | INFO | train_inner | epoch 005:   7544 / 19564 loss=4.228, nll_loss=2.821, ppl=7.07, wps=14862.8, ups=4.36, wpb=3411.2, bsz=133.6, num_updates=85800, lr=0.000107958, gnorm=1.13, train_wall=23, wall=0
2024-07-18 17:44:34 | INFO | train_inner | epoch 005:   7644 / 19564 loss=4.188, nll_loss=2.776, ppl=6.85, wps=15130.5, ups=4.31, wpb=3513.5, bsz=145.8, num_updates=85900, lr=0.000107896, gnorm=1.098, train_wall=23, wall=0
2024-07-18 17:44:57 | INFO | train_inner | epoch 005:   7744 / 19564 loss=4.17, nll_loss=2.754, ppl=6.74, wps=14960.6, ups=4.32, wpb=3461.3, bsz=143.1, num_updates=86000, lr=0.000107833, gnorm=1.11, train_wall=23, wall=0
2024-07-18 17:44:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:45:00 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.097 | nll_loss 2.57 | ppl 5.94 | wps 44187.3 | wpb 2872.6 | bsz 51.2 | num_updates 86000 | best_loss 12.094
2024-07-18 17:45:00 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:45:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_86000.pt (epoch 5 @ 86000 updates, score 4.097) (writing took 10.312878411263227 seconds)
2024-07-18 17:45:33 | INFO | train_inner | epoch 005:   7844 / 19564 loss=4.23, nll_loss=2.824, ppl=7.08, wps=9307.9, ups=2.76, wpb=3372.6, bsz=142.5, num_updates=86100, lr=0.00010777, gnorm=1.19, train_wall=23, wall=0
2024-07-18 17:45:56 | INFO | train_inner | epoch 005:   7944 / 19564 loss=4.152, nll_loss=2.735, ppl=6.66, wps=14924.4, ups=4.35, wpb=3429.7, bsz=144.3, num_updates=86200, lr=0.000107708, gnorm=1.116, train_wall=23, wall=0
2024-07-18 17:46:19 | INFO | train_inner | epoch 005:   8044 / 19564 loss=4.173, nll_loss=2.759, ppl=6.77, wps=15098.2, ups=4.31, wpb=3501.5, bsz=169.8, num_updates=86300, lr=0.000107645, gnorm=1.11, train_wall=23, wall=0
2024-07-18 17:46:42 | INFO | train_inner | epoch 005:   8144 / 19564 loss=4.234, nll_loss=2.827, ppl=7.1, wps=14726.9, ups=4.34, wpb=3395.7, bsz=119.6, num_updates=86400, lr=0.000107583, gnorm=1.134, train_wall=23, wall=0
2024-07-18 17:47:06 | INFO | train_inner | epoch 005:   8244 / 19564 loss=4.176, nll_loss=2.761, ppl=6.78, wps=15031.1, ups=4.32, wpb=3477.1, bsz=134.2, num_updates=86500, lr=0.000107521, gnorm=1.11, train_wall=23, wall=0
2024-07-18 17:47:28 | INFO | train_inner | epoch 005:   8344 / 19564 loss=4.218, nll_loss=2.808, ppl=7.01, wps=14861.9, ups=4.39, wpb=3386.4, bsz=127.1, num_updates=86600, lr=0.000107459, gnorm=1.147, train_wall=23, wall=0
2024-07-18 17:47:51 | INFO | train_inner | epoch 005:   8444 / 19564 loss=4.185, nll_loss=2.772, ppl=6.83, wps=15101, ups=4.33, wpb=3483.6, bsz=141.4, num_updates=86700, lr=0.000107397, gnorm=1.092, train_wall=23, wall=0
2024-07-18 17:48:15 | INFO | train_inner | epoch 005:   8544 / 19564 loss=4.157, nll_loss=2.74, ppl=6.68, wps=14977.6, ups=4.32, wpb=3469.6, bsz=151.2, num_updates=86800, lr=0.000107335, gnorm=1.097, train_wall=23, wall=0
2024-07-18 17:48:38 | INFO | train_inner | epoch 005:   8644 / 19564 loss=4.183, nll_loss=2.77, ppl=6.82, wps=15079, ups=4.3, wpb=3509.5, bsz=146.8, num_updates=86900, lr=0.000107273, gnorm=1.103, train_wall=23, wall=0
2024-07-18 17:49:01 | INFO | train_inner | epoch 005:   8744 / 19564 loss=4.181, nll_loss=2.767, ppl=6.81, wps=14797.7, ups=4.31, wpb=3432.7, bsz=134.3, num_updates=87000, lr=0.000107211, gnorm=1.129, train_wall=23, wall=0
2024-07-18 17:49:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:49:04 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.093 | nll_loss 2.562 | ppl 5.91 | wps 44485.2 | wpb 2872.6 | bsz 51.2 | num_updates 87000 | best_loss 12.094
2024-07-18 17:49:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:49:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_87000.pt (epoch 5 @ 87000 updates, score 4.093) (writing took 5.929731613956392 seconds)
2024-07-18 17:49:33 | INFO | train_inner | epoch 005:   8844 / 19564 loss=4.199, nll_loss=2.788, ppl=6.91, wps=10838.7, ups=3.15, wpb=3442.2, bsz=157.3, num_updates=87100, lr=0.00010715, gnorm=1.126, train_wall=23, wall=0
2024-07-18 17:49:56 | INFO | train_inner | epoch 005:   8944 / 19564 loss=4.196, nll_loss=2.785, ppl=6.89, wps=14852.7, ups=4.36, wpb=3404, bsz=142.3, num_updates=87200, lr=0.000107088, gnorm=1.138, train_wall=23, wall=0
2024-07-18 17:50:19 | INFO | train_inner | epoch 005:   9044 / 19564 loss=4.196, nll_loss=2.784, ppl=6.89, wps=14875.8, ups=4.37, wpb=3406.2, bsz=137, num_updates=87300, lr=0.000107027, gnorm=1.136, train_wall=23, wall=0
2024-07-18 17:50:42 | INFO | train_inner | epoch 005:   9144 / 19564 loss=4.186, nll_loss=2.773, ppl=6.84, wps=14911.5, ups=4.33, wpb=3440.6, bsz=147, num_updates=87400, lr=0.000106966, gnorm=1.112, train_wall=23, wall=0
2024-07-18 17:51:05 | INFO | train_inner | epoch 005:   9244 / 19564 loss=4.179, nll_loss=2.766, ppl=6.8, wps=15013, ups=4.3, wpb=3491.6, bsz=156.5, num_updates=87500, lr=0.000106904, gnorm=1.075, train_wall=23, wall=0
2024-07-18 17:51:28 | INFO | train_inner | epoch 005:   9344 / 19564 loss=4.178, nll_loss=2.765, ppl=6.8, wps=14685, ups=4.33, wpb=3388.9, bsz=142.9, num_updates=87600, lr=0.000106843, gnorm=1.144, train_wall=23, wall=0
2024-07-18 17:51:51 | INFO | train_inner | epoch 005:   9444 / 19564 loss=4.182, nll_loss=2.769, ppl=6.82, wps=14794.4, ups=4.36, wpb=3389.7, bsz=147.8, num_updates=87700, lr=0.000106783, gnorm=1.12, train_wall=23, wall=0
2024-07-18 17:52:14 | INFO | train_inner | epoch 005:   9544 / 19564 loss=4.206, nll_loss=2.796, ppl=6.94, wps=15183.2, ups=4.33, wpb=3509.4, bsz=139.2, num_updates=87800, lr=0.000106722, gnorm=1.128, train_wall=23, wall=0
2024-07-18 17:52:37 | INFO | train_inner | epoch 005:   9644 / 19564 loss=4.214, nll_loss=2.806, ppl=6.99, wps=14495.5, ups=4.34, wpb=3336.8, bsz=132.2, num_updates=87900, lr=0.000106661, gnorm=1.167, train_wall=23, wall=0
2024-07-18 17:53:00 | INFO | train_inner | epoch 005:   9744 / 19564 loss=4.242, nll_loss=2.836, ppl=7.14, wps=14771.5, ups=4.37, wpb=3383.2, bsz=131.4, num_updates=88000, lr=0.0001066, gnorm=1.156, train_wall=23, wall=0
2024-07-18 17:53:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:53:03 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.088 | nll_loss 2.556 | ppl 5.88 | wps 44592.5 | wpb 2872.6 | bsz 51.2 | num_updates 88000 | best_loss 12.094
2024-07-18 17:53:03 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:53:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_88000.pt (epoch 5 @ 88000 updates, score 4.088) (writing took 10.511827261187136 seconds)
2024-07-18 17:53:36 | INFO | train_inner | epoch 005:   9844 / 19564 loss=4.234, nll_loss=2.828, ppl=7.1, wps=9283.8, ups=2.75, wpb=3374.4, bsz=143.7, num_updates=88100, lr=0.00010654, gnorm=1.151, train_wall=23, wall=0
2024-07-18 17:53:59 | INFO | train_inner | epoch 005:   9944 / 19564 loss=4.185, nll_loss=2.772, ppl=6.83, wps=14878.4, ups=4.33, wpb=3438.5, bsz=131.1, num_updates=88200, lr=0.000106479, gnorm=1.124, train_wall=23, wall=0
2024-07-18 17:54:23 | INFO | train_inner | epoch 005:  10044 / 19564 loss=4.173, nll_loss=2.757, ppl=6.76, wps=15002.3, ups=4.23, wpb=3550, bsz=131, num_updates=88300, lr=0.000106419, gnorm=1.078, train_wall=23, wall=0
2024-07-18 17:54:47 | INFO | train_inner | epoch 005:  10144 / 19564 loss=4.183, nll_loss=2.771, ppl=6.82, wps=14571.3, ups=4.27, wpb=3412.2, bsz=143.9, num_updates=88400, lr=0.000106359, gnorm=1.122, train_wall=23, wall=0
2024-07-18 17:55:10 | INFO | train_inner | epoch 005:  10244 / 19564 loss=4.208, nll_loss=2.799, ppl=6.96, wps=14810.4, ups=4.29, wpb=3456.3, bsz=139.8, num_updates=88500, lr=0.000106299, gnorm=1.113, train_wall=23, wall=0
2024-07-18 17:55:33 | INFO | train_inner | epoch 005:  10344 / 19564 loss=4.174, nll_loss=2.761, ppl=6.78, wps=14758.5, ups=4.24, wpb=3482.7, bsz=138.5, num_updates=88600, lr=0.000106239, gnorm=1.11, train_wall=23, wall=0
2024-07-18 17:55:57 | INFO | train_inner | epoch 005:  10444 / 19564 loss=4.08, nll_loss=2.653, ppl=6.29, wps=14859.3, ups=4.2, wpb=3534.1, bsz=154.4, num_updates=88700, lr=0.000106179, gnorm=1.071, train_wall=24, wall=0
2024-07-18 17:56:20 | INFO | train_inner | epoch 005:  10544 / 19564 loss=4.204, nll_loss=2.794, ppl=6.94, wps=14350.7, ups=4.32, wpb=3322.6, bsz=138.4, num_updates=88800, lr=0.000106119, gnorm=1.164, train_wall=23, wall=0
2024-07-18 17:56:44 | INFO | train_inner | epoch 005:  10644 / 19564 loss=4.127, nll_loss=2.706, ppl=6.52, wps=14898.3, ups=4.28, wpb=3478.3, bsz=143.8, num_updates=88900, lr=0.000106059, gnorm=1.072, train_wall=23, wall=0
2024-07-18 17:57:07 | INFO | train_inner | epoch 005:  10744 / 19564 loss=4.246, nll_loss=2.841, ppl=7.17, wps=14637.5, ups=4.3, wpb=3403.6, bsz=125, num_updates=89000, lr=0.000106, gnorm=1.187, train_wall=23, wall=0
2024-07-18 17:57:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:57:10 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.09 | nll_loss 2.562 | ppl 5.91 | wps 43939.9 | wpb 2872.6 | bsz 51.2 | num_updates 89000 | best_loss 12.094
2024-07-18 17:57:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:57:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_89000.pt (epoch 5 @ 89000 updates, score 4.09) (writing took 6.527461878024042 seconds)
2024-07-18 17:57:40 | INFO | train_inner | epoch 005:  10844 / 19564 loss=4.183, nll_loss=2.77, ppl=6.82, wps=10548, ups=3.06, wpb=3450, bsz=141.5, num_updates=89100, lr=0.00010594, gnorm=1.117, train_wall=23, wall=0
2024-07-18 17:58:03 | INFO | train_inner | epoch 005:  10944 / 19564 loss=4.218, nll_loss=2.811, ppl=7.02, wps=14933.9, ups=4.35, wpb=3429.9, bsz=135.4, num_updates=89200, lr=0.000105881, gnorm=1.156, train_wall=23, wall=0
2024-07-18 17:58:26 | INFO | train_inner | epoch 005:  11044 / 19564 loss=4.127, nll_loss=2.707, ppl=6.53, wps=14661.7, ups=4.29, wpb=3420.8, bsz=155.7, num_updates=89300, lr=0.000105822, gnorm=1.137, train_wall=23, wall=0
2024-07-18 17:58:49 | INFO | train_inner | epoch 005:  11144 / 19564 loss=4.196, nll_loss=2.784, ppl=6.89, wps=14782.9, ups=4.27, wpb=3465.2, bsz=129.7, num_updates=89400, lr=0.000105762, gnorm=1.106, train_wall=23, wall=0
2024-07-18 17:59:13 | INFO | train_inner | epoch 005:  11244 / 19564 loss=4.211, nll_loss=2.803, ppl=6.98, wps=15005.6, ups=4.31, wpb=3479.9, bsz=132.8, num_updates=89500, lr=0.000105703, gnorm=1.132, train_wall=23, wall=0
2024-07-18 17:59:36 | INFO | train_inner | epoch 005:  11344 / 19564 loss=4.122, nll_loss=2.699, ppl=6.5, wps=14884.5, ups=4.29, wpb=3468.3, bsz=141.3, num_updates=89600, lr=0.000105644, gnorm=1.078, train_wall=23, wall=0
2024-07-18 17:59:59 | INFO | train_inner | epoch 005:  11444 / 19564 loss=4.165, nll_loss=2.75, ppl=6.73, wps=14878.2, ups=4.28, wpb=3473, bsz=139, num_updates=89700, lr=0.000105585, gnorm=1.102, train_wall=23, wall=0
2024-07-18 18:00:22 | INFO | train_inner | epoch 005:  11544 / 19564 loss=4.175, nll_loss=2.76, ppl=6.78, wps=14824.6, ups=4.37, wpb=3392, bsz=143.2, num_updates=89800, lr=0.000105527, gnorm=1.16, train_wall=23, wall=0
2024-07-18 18:00:46 | INFO | train_inner | epoch 005:  11644 / 19564 loss=4.169, nll_loss=2.755, ppl=6.75, wps=14643.5, ups=4.25, wpb=3446.8, bsz=145.4, num_updates=89900, lr=0.000105468, gnorm=1.137, train_wall=23, wall=0
2024-07-18 18:01:09 | INFO | train_inner | epoch 005:  11744 / 19564 loss=4.244, nll_loss=2.84, ppl=7.16, wps=14584.9, ups=4.36, wpb=3343.9, bsz=143, num_updates=90000, lr=0.000105409, gnorm=1.151, train_wall=23, wall=0
2024-07-18 18:01:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 18:01:12 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.07 | nll_loss 2.54 | ppl 5.82 | wps 43652.2 | wpb 2872.6 | bsz 51.2 | num_updates 90000 | best_loss 12.094
2024-07-18 18:01:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 18:01:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_90000.pt (epoch 5 @ 90000 updates, score 4.07) (writing took 6.560887734405696 seconds)
2024-07-18 18:01:42 | INFO | train_inner | epoch 005:  11844 / 19564 loss=4.236, nll_loss=2.832, ppl=7.12, wps=10565.1, ups=3.04, wpb=3473.7, bsz=153.9, num_updates=90100, lr=0.000105351, gnorm=1.13, train_wall=23, wall=0
2024-07-18 18:02:05 | INFO | train_inner | epoch 005:  11944 / 19564 loss=4.112, nll_loss=2.689, ppl=6.45, wps=14904.9, ups=4.23, wpb=3523.3, bsz=152.4, num_updates=90200, lr=0.000105292, gnorm=1.064, train_wall=23, wall=0
2024-07-18 18:02:28 | INFO | train_inner | epoch 005:  12044 / 19564 loss=4.156, nll_loss=2.739, ppl=6.68, wps=14754.1, ups=4.29, wpb=3441.7, bsz=141.6, num_updates=90300, lr=0.000105234, gnorm=1.101, train_wall=23, wall=0
2024-07-18 18:02:52 | INFO | train_inner | epoch 005:  12144 / 19564 loss=4.242, nll_loss=2.838, ppl=7.15, wps=14660.4, ups=4.28, wpb=3427.1, bsz=137.1, num_updates=90400, lr=0.000105176, gnorm=1.146, train_wall=23, wall=0
2024-07-18 18:03:15 | INFO | train_inner | epoch 005:  12244 / 19564 loss=4.218, nll_loss=2.809, ppl=7.01, wps=14467.2, ups=4.31, wpb=3357.7, bsz=118.6, num_updates=90500, lr=0.000105118, gnorm=1.178, train_wall=23, wall=0
2024-07-18 18:03:39 | INFO | train_inner | epoch 005:  12344 / 19564 loss=4.167, nll_loss=2.754, ppl=6.74, wps=14902.9, ups=4.24, wpb=3515.4, bsz=155.4, num_updates=90600, lr=0.00010506, gnorm=1.073, train_wall=23, wall=0
2024-07-18 18:04:02 | INFO | train_inner | epoch 005:  12444 / 19564 loss=4.222, nll_loss=2.814, ppl=7.03, wps=14732.3, ups=4.36, wpb=3380.9, bsz=129, num_updates=90700, lr=0.000105002, gnorm=1.152, train_wall=23, wall=0
2024-07-18 18:04:24 | INFO | train_inner | epoch 005:  12544 / 19564 loss=4.214, nll_loss=2.805, ppl=6.99, wps=14984.4, ups=4.37, wpb=3430, bsz=131.8, num_updates=90800, lr=0.000104944, gnorm=1.143, train_wall=23, wall=0
2024-07-18 18:04:47 | INFO | train_inner | epoch 005:  12644 / 19564 loss=4.168, nll_loss=2.753, ppl=6.74, wps=14715, ups=4.36, wpb=3373.6, bsz=138.4, num_updates=90900, lr=0.000104886, gnorm=1.117, train_wall=23, wall=0
2024-07-18 18:05:10 | INFO | train_inner | epoch 005:  12744 / 19564 loss=4.173, nll_loss=2.759, ppl=6.77, wps=14545.9, ups=4.38, wpb=3318.5, bsz=132.6, num_updates=91000, lr=0.000104828, gnorm=1.159, train_wall=23, wall=0
2024-07-18 18:05:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 18:05:13 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.064 | nll_loss 2.534 | ppl 5.79 | wps 43987.5 | wpb 2872.6 | bsz 51.2 | num_updates 91000 | best_loss 12.094
2024-07-18 18:05:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 18:05:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_91000.pt (epoch 5 @ 91000 updates, score 4.064) (writing took 5.05784008000046 seconds)
2024-07-18 18:05:41 | INFO | train_inner | epoch 005:  12844 / 19564 loss=4.204, nll_loss=2.793, ppl=6.93, wps=11014.3, ups=3.23, wpb=3406.4, bsz=133, num_updates=91100, lr=0.000104771, gnorm=1.146, train_wall=23, wall=0
2024-07-18 18:06:05 | INFO | train_inner | epoch 005:  12944 / 19564 loss=4.095, nll_loss=2.669, ppl=6.36, wps=15052.9, ups=4.26, wpb=3535.9, bsz=138.4, num_updates=91200, lr=0.000104713, gnorm=1.054, train_wall=23, wall=0
2024-07-18 18:06:28 | INFO | train_inner | epoch 005:  13044 / 19564 loss=4.154, nll_loss=2.737, ppl=6.67, wps=15104.6, ups=4.29, wpb=3519.5, bsz=153.5, num_updates=91300, lr=0.000104656, gnorm=1.121, train_wall=23, wall=0
2024-07-18 18:06:51 | INFO | train_inner | epoch 005:  13144 / 19564 loss=4.221, nll_loss=2.815, ppl=7.04, wps=14862.1, ups=4.37, wpb=3399.7, bsz=146.5, num_updates=91400, lr=0.000104599, gnorm=1.162, train_wall=23, wall=0
2024-07-18 18:07:14 | INFO | train_inner | epoch 005:  13244 / 19564 loss=4.225, nll_loss=2.818, ppl=7.05, wps=14839.5, ups=4.4, wpb=3369.8, bsz=148.5, num_updates=91500, lr=0.000104542, gnorm=1.187, train_wall=23, wall=0
2024-07-18 18:07:37 | INFO | train_inner | epoch 005:  13344 / 19564 loss=4.199, nll_loss=2.789, ppl=6.91, wps=14966.1, ups=4.29, wpb=3489.9, bsz=153.9, num_updates=91600, lr=0.000104485, gnorm=1.108, train_wall=23, wall=0
2024-07-18 18:08:00 | INFO | train_inner | epoch 005:  13444 / 19564 loss=4.198, nll_loss=2.788, ppl=6.91, wps=14841.7, ups=4.33, wpb=3426.5, bsz=143.7, num_updates=91700, lr=0.000104428, gnorm=1.145, train_wall=23, wall=0
2024-07-18 18:08:23 | INFO | train_inner | epoch 005:  13544 / 19564 loss=4.152, nll_loss=2.734, ppl=6.65, wps=14812.3, ups=4.3, wpb=3444.9, bsz=137.4, num_updates=91800, lr=0.000104371, gnorm=1.133, train_wall=23, wall=0
2024-07-18 18:08:47 | INFO | train_inner | epoch 005:  13644 / 19564 loss=4.18, nll_loss=2.767, ppl=6.81, wps=14964.1, ups=4.26, wpb=3513.8, bsz=145, num_updates=91900, lr=0.000104314, gnorm=1.135, train_wall=23, wall=0
2024-07-18 18:09:10 | INFO | train_inner | epoch 005:  13744 / 19564 loss=4.25, nll_loss=2.847, ppl=7.19, wps=14999.2, ups=4.29, wpb=3492.5, bsz=131.7, num_updates=92000, lr=0.000104257, gnorm=1.13, train_wall=23, wall=0
2024-07-18 18:09:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 18:09:13 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.052 | nll_loss 2.519 | ppl 5.73 | wps 43597.4 | wpb 2872.6 | bsz 51.2 | num_updates 92000 | best_loss 12.094
2024-07-18 18:09:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 18:09:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_92000.pt (epoch 5 @ 92000 updates, score 4.052) (writing took 5.508637824095786 seconds)
2024-07-18 18:09:42 | INFO | train_inner | epoch 005:  13844 / 19564 loss=4.175, nll_loss=2.762, ppl=6.78, wps=10874, ups=3.16, wpb=3437.7, bsz=136.9, num_updates=92100, lr=0.000104201, gnorm=1.108, train_wall=23, wall=0
2024-07-18 18:10:05 | INFO | train_inner | epoch 005:  13944 / 19564 loss=4.204, nll_loss=2.795, ppl=6.94, wps=14629.9, ups=4.3, wpb=3398.9, bsz=124.7, num_updates=92200, lr=0.000104144, gnorm=1.147, train_wall=23, wall=0
2024-07-18 18:10:28 | INFO | train_inner | epoch 005:  14044 / 19564 loss=4.167, nll_loss=2.752, ppl=6.74, wps=14678.7, ups=4.31, wpb=3404.6, bsz=139.4, num_updates=92300, lr=0.000104088, gnorm=1.105, train_wall=23, wall=0
2024-07-18 18:10:51 | INFO | train_inner | epoch 005:  14144 / 19564 loss=4.172, nll_loss=2.758, ppl=6.76, wps=14830.7, ups=4.29, wpb=3454.9, bsz=139.5, num_updates=92400, lr=0.000104031, gnorm=1.102, train_wall=23, wall=0
2024-07-18 18:11:15 | INFO | train_inner | epoch 005:  14244 / 19564 loss=4.139, nll_loss=2.721, ppl=6.6, wps=14597.1, ups=4.27, wpb=3420.8, bsz=152.9, num_updates=92500, lr=0.000103975, gnorm=1.129, train_wall=23, wall=0
2024-07-18 18:11:38 | INFO | train_inner | epoch 005:  14344 / 19564 loss=4.194, nll_loss=2.782, ppl=6.88, wps=14728, ups=4.25, wpb=3466.4, bsz=134.1, num_updates=92600, lr=0.000103919, gnorm=1.146, train_wall=23, wall=0
2024-07-18 18:12:02 | INFO | train_inner | epoch 005:  14444 / 19564 loss=4.173, nll_loss=2.76, ppl=6.78, wps=14897.4, ups=4.25, wpb=3501.6, bsz=147.4, num_updates=92700, lr=0.000103863, gnorm=1.09, train_wall=23, wall=0
2024-07-18 18:12:25 | INFO | train_inner | epoch 005:  14544 / 19564 loss=4.24, nll_loss=2.836, ppl=7.14, wps=14788, ups=4.3, wpb=3439.2, bsz=139, num_updates=92800, lr=0.000103807, gnorm=1.166, train_wall=23, wall=0
2024-07-18 18:12:48 | INFO | train_inner | epoch 005:  14644 / 19564 loss=4.197, nll_loss=2.787, ppl=6.9, wps=14750.9, ups=4.31, wpb=3424, bsz=127.8, num_updates=92900, lr=0.000103751, gnorm=1.111, train_wall=23, wall=0
2024-07-18 18:13:12 | INFO | train_inner | epoch 005:  14744 / 19564 loss=4.166, nll_loss=2.752, ppl=6.73, wps=15010.3, ups=4.3, wpb=3490.1, bsz=149.6, num_updates=93000, lr=0.000103695, gnorm=1.099, train_wall=23, wall=0
2024-07-18 18:13:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 18:13:14 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.053 | nll_loss 2.512 | ppl 5.71 | wps 44135 | wpb 2872.6 | bsz 51.2 | num_updates 93000 | best_loss 12.094
2024-07-18 18:13:14 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 18:13:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_93000.pt (epoch 5 @ 93000 updates, score 4.053) (writing took 5.201032225973904 seconds)
2024-07-18 18:13:43 | INFO | train_inner | epoch 005:  14844 / 19564 loss=4.23, nll_loss=2.824, ppl=7.08, wps=10719.3, ups=3.18, wpb=3367.1, bsz=124.6, num_updates=93100, lr=0.000103639, gnorm=1.155, train_wall=23, wall=0
2024-07-18 18:14:06 | INFO | train_inner | epoch 005:  14944 / 19564 loss=4.183, nll_loss=2.77, ppl=6.82, wps=14610.7, ups=4.28, wpb=3409.9, bsz=140.5, num_updates=93200, lr=0.000103584, gnorm=1.117, train_wall=23, wall=0
2024-07-18 18:14:30 | INFO | train_inner | epoch 005:  15044 / 19564 loss=4.17, nll_loss=2.757, ppl=6.76, wps=14556.3, ups=4.23, wpb=3439.5, bsz=160.1, num_updates=93300, lr=0.000103528, gnorm=1.153, train_wall=23, wall=0
2024-07-18 18:14:53 | INFO | train_inner | epoch 005:  15144 / 19564 loss=4.145, nll_loss=2.728, ppl=6.62, wps=14979, ups=4.31, wpb=3473, bsz=134.8, num_updates=93400, lr=0.000103473, gnorm=1.133, train_wall=23, wall=0
2024-07-18 18:15:16 | INFO | train_inner | epoch 005:  15244 / 19564 loss=4.231, nll_loss=2.826, ppl=7.09, wps=14702.5, ups=4.31, wpb=3409.7, bsz=143.9, num_updates=93500, lr=0.000103418, gnorm=1.163, train_wall=23, wall=0
2024-07-18 18:15:39 | INFO | train_inner | epoch 005:  15344 / 19564 loss=4.197, nll_loss=2.787, ppl=6.9, wps=14695.6, ups=4.36, wpb=3370.7, bsz=136.6, num_updates=93600, lr=0.000103362, gnorm=1.172, train_wall=23, wall=0
2024-07-18 18:16:03 | INFO | train_inner | epoch 005:  15444 / 19564 loss=4.172, nll_loss=2.759, ppl=6.77, wps=14701.9, ups=4.28, wpb=3436.7, bsz=138.9, num_updates=93700, lr=0.000103307, gnorm=1.101, train_wall=23, wall=0
2024-07-18 18:16:26 | INFO | train_inner | epoch 005:  15544 / 19564 loss=4.116, nll_loss=2.695, ppl=6.48, wps=14846.9, ups=4.29, wpb=3459.4, bsz=154.7, num_updates=93800, lr=0.000103252, gnorm=1.083, train_wall=23, wall=0
2024-07-18 18:16:49 | INFO | train_inner | epoch 005:  15644 / 19564 loss=4.184, nll_loss=2.772, ppl=6.83, wps=14556.9, ups=4.27, wpb=3406.5, bsz=148.4, num_updates=93900, lr=0.000103197, gnorm=1.139, train_wall=23, wall=0
2024-07-18 18:17:13 | INFO | train_inner | epoch 005:  15744 / 19564 loss=4.144, nll_loss=2.725, ppl=6.61, wps=14660.7, ups=4.27, wpb=3429.8, bsz=141.9, num_updates=94000, lr=0.000103142, gnorm=1.216, train_wall=23, wall=0
2024-07-18 18:17:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 18:17:16 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.057 | nll_loss 2.531 | ppl 5.78 | wps 43362.5 | wpb 2872.6 | bsz 51.2 | num_updates 94000 | best_loss 12.094
2024-07-18 18:17:16 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 18:17:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_94000.pt (epoch 5 @ 94000 updates, score 4.057) (writing took 6.553196388296783 seconds)
2024-07-18 18:17:45 | INFO | train_inner | epoch 005:  15844 / 19564 loss=4.201, nll_loss=2.791, ppl=6.92, wps=10301.9, ups=3.05, wpb=3378.9, bsz=136.3, num_updates=94100, lr=0.000103087, gnorm=1.174, train_wall=23, wall=0
2024-07-18 18:18:09 | INFO | train_inner | epoch 005:  15944 / 19564 loss=4.134, nll_loss=2.716, ppl=6.57, wps=14866.9, ups=4.21, wpb=3531.6, bsz=147.2, num_updates=94200, lr=0.000103033, gnorm=1.057, train_wall=24, wall=0
2024-07-18 18:18:32 | INFO | train_inner | epoch 005:  16044 / 19564 loss=4.253, nll_loss=2.851, ppl=7.22, wps=14834.7, ups=4.34, wpb=3419.1, bsz=135.1, num_updates=94300, lr=0.000102978, gnorm=1.142, train_wall=23, wall=0
2024-07-18 18:18:55 | INFO | train_inner | epoch 005:  16144 / 19564 loss=4.234, nll_loss=2.83, ppl=7.11, wps=14744.8, ups=4.33, wpb=3402.7, bsz=137.8, num_updates=94400, lr=0.000102923, gnorm=1.166, train_wall=23, wall=0
2024-07-18 18:19:19 | INFO | train_inner | epoch 005:  16244 / 19564 loss=4.156, nll_loss=2.74, ppl=6.68, wps=14752.4, ups=4.27, wpb=3454.9, bsz=142.6, num_updates=94500, lr=0.000102869, gnorm=1.1, train_wall=23, wall=0
2024-07-18 18:19:42 | INFO | train_inner | epoch 005:  16344 / 19564 loss=4.145, nll_loss=2.728, ppl=6.62, wps=14886.3, ups=4.29, wpb=3471.4, bsz=147.1, num_updates=94600, lr=0.000102815, gnorm=1.114, train_wall=23, wall=0
2024-07-18 18:20:05 | INFO | train_inner | epoch 005:  16444 / 19564 loss=4.209, nll_loss=2.802, ppl=6.97, wps=14630.7, ups=4.34, wpb=3374.5, bsz=157.4, num_updates=94700, lr=0.00010276, gnorm=1.189, train_wall=23, wall=0
2024-07-18 18:20:28 | INFO | train_inner | epoch 005:  16544 / 19564 loss=4.172, nll_loss=2.76, ppl=6.77, wps=14658.5, ups=4.3, wpb=3405.7, bsz=156.9, num_updates=94800, lr=0.000102706, gnorm=1.095, train_wall=23, wall=0
2024-07-18 18:20:52 | INFO | train_inner | epoch 005:  16644 / 19564 loss=4.127, nll_loss=2.708, ppl=6.53, wps=14766, ups=4.25, wpb=3471.2, bsz=155, num_updates=94900, lr=0.000102652, gnorm=1.092, train_wall=23, wall=0
2024-07-18 18:21:15 | INFO | train_inner | epoch 005:  16744 / 19564 loss=4.169, nll_loss=2.756, ppl=6.75, wps=14867.6, ups=4.27, wpb=3481.2, bsz=153.8, num_updates=95000, lr=0.000102598, gnorm=1.127, train_wall=23, wall=0
2024-07-18 18:21:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 18:21:18 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.047 | nll_loss 2.514 | ppl 5.71 | wps 43883.1 | wpb 2872.6 | bsz 51.2 | num_updates 95000 | best_loss 12.094
2024-07-18 18:21:18 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 18:21:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_95000.pt (epoch 5 @ 95000 updates, score 4.047) (writing took 5.731757218949497 seconds)
2024-07-18 18:21:47 | INFO | train_inner | epoch 005:  16844 / 19564 loss=4.228, nll_loss=2.822, ppl=7.07, wps=10372.9, ups=3.13, wpb=3317.2, bsz=129, num_updates=95100, lr=0.000102544, gnorm=1.182, train_wall=23, wall=0
2024-07-18 18:22:11 | INFO | train_inner | epoch 005:  16944 / 19564 loss=4.205, nll_loss=2.796, ppl=6.95, wps=14647, ups=4.29, wpb=3415.6, bsz=132.1, num_updates=95200, lr=0.00010249, gnorm=1.127, train_wall=23, wall=0
2024-07-18 18:22:34 | INFO | train_inner | epoch 005:  17044 / 19564 loss=4.143, nll_loss=2.726, ppl=6.61, wps=14549.1, ups=4.29, wpb=3388.7, bsz=143.8, num_updates=95300, lr=0.000102436, gnorm=1.125, train_wall=23, wall=0
2024-07-18 18:22:58 | INFO | train_inner | epoch 005:  17144 / 19564 loss=4.143, nll_loss=2.725, ppl=6.61, wps=14953.1, ups=4.22, wpb=3543.2, bsz=152.6, num_updates=95400, lr=0.000102383, gnorm=1.075, train_wall=23, wall=0
2024-07-18 18:23:21 | INFO | train_inner | epoch 005:  17244 / 19564 loss=4.147, nll_loss=2.73, ppl=6.63, wps=14764.6, ups=4.3, wpb=3435.9, bsz=128.1, num_updates=95500, lr=0.000102329, gnorm=1.161, train_wall=23, wall=0
2024-07-18 18:23:45 | INFO | train_inner | epoch 005:  17344 / 19564 loss=4.084, nll_loss=2.659, ppl=6.32, wps=14835.2, ups=4.23, wpb=3508.1, bsz=148.6, num_updates=95600, lr=0.000102275, gnorm=1.071, train_wall=23, wall=0
2024-07-18 18:24:08 | INFO | train_inner | epoch 005:  17444 / 19564 loss=4.155, nll_loss=2.739, ppl=6.68, wps=14698.8, ups=4.28, wpb=3433.6, bsz=138.7, num_updates=95700, lr=0.000102222, gnorm=1.133, train_wall=23, wall=0
2024-07-18 18:24:31 | INFO | train_inner | epoch 005:  17544 / 19564 loss=4.191, nll_loss=2.781, ppl=6.88, wps=14577.7, ups=4.24, wpb=3435.5, bsz=145.7, num_updates=95800, lr=0.000102169, gnorm=1.151, train_wall=23, wall=0
2024-07-18 18:24:55 | INFO | train_inner | epoch 005:  17644 / 19564 loss=4.195, nll_loss=2.785, ppl=6.89, wps=14975.7, ups=4.27, wpb=3507.8, bsz=151.3, num_updates=95900, lr=0.000102115, gnorm=1.105, train_wall=23, wall=0
2024-07-18 18:25:18 | INFO | train_inner | epoch 005:  17744 / 19564 loss=4.206, nll_loss=2.797, ppl=6.95, wps=15033, ups=4.26, wpb=3527.9, bsz=132.6, num_updates=96000, lr=0.000102062, gnorm=1.109, train_wall=23, wall=0
2024-07-18 18:25:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 18:25:21 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.042 | nll_loss 2.513 | ppl 5.71 | wps 43785.2 | wpb 2872.6 | bsz 51.2 | num_updates 96000 | best_loss 12.094
2024-07-18 18:25:21 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 18:25:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_96000.pt (epoch 5 @ 96000 updates, score 4.042) (writing took 6.53190837893635 seconds)
2024-07-18 18:25:51 | INFO | train_inner | epoch 005:  17844 / 19564 loss=4.166, nll_loss=2.752, ppl=6.74, wps=10496.1, ups=3.02, wpb=3473.5, bsz=149, num_updates=96100, lr=0.000102009, gnorm=1.131, train_wall=23, wall=0
2024-07-18 18:26:15 | INFO | train_inner | epoch 005:  17944 / 19564 loss=4.135, nll_loss=2.717, ppl=6.57, wps=14873.2, ups=4.27, wpb=3486.6, bsz=146.8, num_updates=96200, lr=0.000101956, gnorm=1.107, train_wall=23, wall=0
2024-07-18 18:26:38 | INFO | train_inner | epoch 005:  18044 / 19564 loss=4.099, nll_loss=2.678, ppl=6.4, wps=14809.3, ups=4.34, wpb=3412.7, bsz=161.4, num_updates=96300, lr=0.000101903, gnorm=1.132, train_wall=23, wall=0
2024-07-18 18:27:01 | INFO | train_inner | epoch 005:  18144 / 19564 loss=4.139, nll_loss=2.721, ppl=6.59, wps=14724.1, ups=4.29, wpb=3433.7, bsz=157, num_updates=96400, lr=0.00010185, gnorm=1.13, train_wall=23, wall=0
2024-07-18 18:27:24 | INFO | train_inner | epoch 005:  18244 / 19564 loss=4.165, nll_loss=2.75, ppl=6.73, wps=14550.4, ups=4.31, wpb=3378.5, bsz=132.9, num_updates=96500, lr=0.000101797, gnorm=1.153, train_wall=23, wall=0
2024-07-18 18:27:49 | INFO | train_inner | epoch 005:  18344 / 19564 loss=4.166, nll_loss=2.753, ppl=6.74, wps=14106, ups=4.12, wpb=3424.2, bsz=157.3, num_updates=96600, lr=0.000101745, gnorm=1.141, train_wall=24, wall=0
2024-07-18 18:28:13 | INFO | train_inner | epoch 005:  18444 / 19564 loss=4.168, nll_loss=2.754, ppl=6.75, wps=14235.3, ups=4.2, wpb=3385.8, bsz=142.9, num_updates=96700, lr=0.000101692, gnorm=1.146, train_wall=24, wall=0
2024-07-18 18:28:36 | INFO | train_inner | epoch 005:  18544 / 19564 loss=4.151, nll_loss=2.734, ppl=6.66, wps=14651.5, ups=4.19, wpb=3497.7, bsz=139.3, num_updates=96800, lr=0.000101639, gnorm=1.1, train_wall=24, wall=0
2024-07-18 18:29:01 | INFO | train_inner | epoch 005:  18644 / 19564 loss=4.105, nll_loss=2.683, ppl=6.42, wps=14457.1, ups=4.09, wpb=3531.5, bsz=145, num_updates=96900, lr=0.000101587, gnorm=1.074, train_wall=24, wall=0
2024-07-18 18:29:24 | INFO | train_inner | epoch 005:  18744 / 19564 loss=4.204, nll_loss=2.796, ppl=6.94, wps=14537.3, ups=4.27, wpb=3406.1, bsz=136.4, num_updates=97000, lr=0.000101535, gnorm=1.157, train_wall=23, wall=0
2024-07-18 18:29:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 18:29:27 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.044 | nll_loss 2.522 | ppl 5.74 | wps 43901.6 | wpb 2872.6 | bsz 51.2 | num_updates 97000 | best_loss 12.094
2024-07-18 18:29:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 18:29:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_97000.pt (epoch 5 @ 97000 updates, score 4.044) (writing took 7.578521201387048 seconds)
2024-07-18 18:29:58 | INFO | train_inner | epoch 005:  18844 / 19564 loss=4.209, nll_loss=2.8, ppl=6.97, wps=10042.3, ups=2.96, wpb=3394.6, bsz=126.5, num_updates=97100, lr=0.000101482, gnorm=1.128, train_wall=23, wall=0
2024-07-18 18:30:21 | INFO | train_inner | epoch 005:  18944 / 19564 loss=4.197, nll_loss=2.787, ppl=6.9, wps=14508.2, ups=4.28, wpb=3391.2, bsz=136.5, num_updates=97200, lr=0.00010143, gnorm=1.148, train_wall=23, wall=0
2024-07-18 18:30:45 | INFO | train_inner | epoch 005:  19044 / 19564 loss=4.138, nll_loss=2.721, ppl=6.59, wps=14986.4, ups=4.31, wpb=3479.1, bsz=156.1, num_updates=97300, lr=0.000101378, gnorm=1.109, train_wall=23, wall=0
2024-07-18 18:31:08 | INFO | train_inner | epoch 005:  19144 / 19564 loss=4.204, nll_loss=2.795, ppl=6.94, wps=14758.3, ups=4.32, wpb=3413.6, bsz=128.2, num_updates=97400, lr=0.000101326, gnorm=1.163, train_wall=23, wall=0
2024-07-18 18:31:31 | INFO | train_inner | epoch 005:  19244 / 19564 loss=4.154, nll_loss=2.738, ppl=6.67, wps=14718.7, ups=4.35, wpb=3381.9, bsz=152.3, num_updates=97500, lr=0.000101274, gnorm=1.186, train_wall=23, wall=0
2024-07-18 18:31:54 | INFO | train_inner | epoch 005:  19344 / 19564 loss=4.132, nll_loss=2.715, ppl=6.57, wps=15001, ups=4.26, wpb=3518.2, bsz=153.2, num_updates=97600, lr=0.000101222, gnorm=1.08, train_wall=23, wall=0
2024-07-18 18:32:17 | INFO | train_inner | epoch 005:  19444 / 19564 loss=4.146, nll_loss=2.729, ppl=6.63, wps=14829.1, ups=4.33, wpb=3421.5, bsz=138.6, num_updates=97700, lr=0.00010117, gnorm=1.146, train_wall=23, wall=0
2024-07-18 18:32:41 | INFO | train_inner | epoch 005:  19544 / 19564 loss=4.172, nll_loss=2.759, ppl=6.77, wps=14876.5, ups=4.29, wpb=3471.3, bsz=134.8, num_updates=97800, lr=0.000101118, gnorm=1.123, train_wall=23, wall=0
2024-07-18 18:32:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 18:32:48 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.045 | nll_loss 2.508 | ppl 5.69 | wps 43919.4 | wpb 2872.6 | bsz 51.2 | num_updates 97820 | best_loss 12.094
2024-07-18 18:32:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 18:32:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 5 @ 97820 updates, score 4.045) (writing took 5.879929142072797 seconds)
2024-07-18 18:32:54 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2024-07-18 18:32:54 | INFO | train | epoch 005 | loss 4.183 | nll_loss 2.77 | ppl 6.82 | wps 14218.6 | ups 4.13 | wpb 3446.5 | bsz 142.2 | num_updates 97820 | lr 0.000101108 | gnorm 1.12 | train_wall 4508 | wall 0
2024-07-18 18:32:54 | INFO | fairseq.trainer | begin training epoch 6
2024-07-18 18:33:13 | INFO | train_inner | epoch 006:     80 / 19564 loss=4.114, nll_loss=2.693, ppl=6.47, wps=10557, ups=3.06, wpb=3451.6, bsz=128.6, num_updates=97900, lr=0.000101067, gnorm=1.086, train_wall=23, wall=0
2024-07-18 18:33:37 | INFO | train_inner | epoch 006:    180 / 19564 loss=4.08, nll_loss=2.654, ppl=6.29, wps=14942.8, ups=4.26, wpb=3510.5, bsz=154.1, num_updates=98000, lr=0.000101015, gnorm=1.085, train_wall=23, wall=0
2024-07-18 18:33:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 18:33:40 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 4.031 | nll_loss 2.495 | ppl 5.64 | wps 44000.9 | wpb 2872.6 | bsz 51.2 | num_updates 98000 | best_loss 12.094
2024-07-18 18:33:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 18:33:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_98000.pt (epoch 6 @ 98000 updates, score 4.031) (writing took 6.750568460673094 seconds)
2024-07-18 18:34:09 | INFO | train_inner | epoch 006:    280 / 19564 loss=4.136, nll_loss=2.717, ppl=6.58, wps=10305.9, ups=3.07, wpb=3360, bsz=134.5, num_updates=98100, lr=0.000100964, gnorm=1.153, train_wall=23, wall=0
2024-07-18 18:34:33 | INFO | train_inner | epoch 006:    380 / 19564 loss=4.164, nll_loss=2.75, ppl=6.73, wps=14465.4, ups=4.21, wpb=3434.1, bsz=144.2, num_updates=98200, lr=0.000100912, gnorm=1.139, train_wall=24, wall=0
2024-07-18 18:34:56 | INFO | train_inner | epoch 006:    480 / 19564 loss=4.14, nll_loss=2.722, ppl=6.6, wps=14800.9, ups=4.31, wpb=3436.8, bsz=142.9, num_updates=98300, lr=0.000100861, gnorm=1.123, train_wall=23, wall=0
2024-07-18 18:35:20 | INFO | train_inner | epoch 006:    580 / 19564 loss=4.048, nll_loss=2.616, ppl=6.13, wps=14925.3, ups=4.3, wpb=3472.7, bsz=146.8, num_updates=98400, lr=0.00010081, gnorm=1.061, train_wall=23, wall=0
2024-07-18 18:35:43 | INFO | train_inner | epoch 006:    680 / 19564 loss=4.119, nll_loss=2.699, ppl=6.49, wps=14625.6, ups=4.29, wpb=3407.6, bsz=146.6, num_updates=98500, lr=0.000100759, gnorm=1.135, train_wall=23, wall=0
2024-07-18 18:36:06 | INFO | train_inner | epoch 006:    780 / 19564 loss=4.112, nll_loss=2.69, ppl=6.45, wps=14748.9, ups=4.32, wpb=3417.8, bsz=134.1, num_updates=98600, lr=0.000100707, gnorm=1.113, train_wall=23, wall=0
2024-07-18 18:36:29 | INFO | train_inner | epoch 006:    880 / 19564 loss=4.111, nll_loss=2.689, ppl=6.45, wps=15121.2, ups=4.32, wpb=3502.9, bsz=132.7, num_updates=98700, lr=0.000100656, gnorm=1.088, train_wall=23, wall=0
2024-07-18 18:36:52 | INFO | train_inner | epoch 006:    980 / 19564 loss=4.147, nll_loss=2.729, ppl=6.63, wps=14815.8, ups=4.34, wpb=3411.5, bsz=131.4, num_updates=98800, lr=0.000100605, gnorm=1.145, train_wall=23, wall=0
2024-07-18 18:37:15 | INFO | train_inner | epoch 006:   1080 / 19564 loss=4.141, nll_loss=2.722, ppl=6.6, wps=15272.3, ups=4.36, wpb=3505.5, bsz=129.7, num_updates=98900, lr=0.000100555, gnorm=1.099, train_wall=23, wall=0
2024-07-18 18:37:39 | INFO | train_inner | epoch 006:   1180 / 19564 loss=4.181, nll_loss=2.768, ppl=6.81, wps=14758.6, ups=4.31, wpb=3426.2, bsz=132.4, num_updates=99000, lr=0.000100504, gnorm=1.122, train_wall=23, wall=0
2024-07-18 18:37:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 18:37:41 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 4.031 | nll_loss 2.498 | ppl 5.65 | wps 43871.9 | wpb 2872.6 | bsz 51.2 | num_updates 99000 | best_loss 12.094
2024-07-18 18:37:41 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 18:37:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_99000.pt (epoch 6 @ 99000 updates, score 4.031) (writing took 6.162616303190589 seconds)
2024-07-18 18:38:11 | INFO | train_inner | epoch 006:   1280 / 19564 loss=4.11, nll_loss=2.688, ppl=6.44, wps=10619.7, ups=3.07, wpb=3461.2, bsz=139.2, num_updates=99100, lr=0.000100453, gnorm=1.115, train_wall=23, wall=0
2024-07-18 18:38:34 | INFO | train_inner | epoch 006:   1380 / 19564 loss=4.165, nll_loss=2.749, ppl=6.72, wps=14800.8, ups=4.32, wpb=3422.5, bsz=126.4, num_updates=99200, lr=0.000100402, gnorm=1.151, train_wall=23, wall=0
2024-07-18 18:38:58 | INFO | train_inner | epoch 006:   1480 / 19564 loss=4.131, nll_loss=2.711, ppl=6.55, wps=14948.2, ups=4.28, wpb=3492.3, bsz=147.1, num_updates=99300, lr=0.000100352, gnorm=1.095, train_wall=23, wall=0
2024-07-18 18:39:21 | INFO | train_inner | epoch 006:   1580 / 19564 loss=4.076, nll_loss=2.65, ppl=6.28, wps=15056.2, ups=4.3, wpb=3505.4, bsz=142.9, num_updates=99400, lr=0.000100301, gnorm=1.06, train_wall=23, wall=0
2024-07-18 18:39:44 | INFO | train_inner | epoch 006:   1680 / 19564 loss=4.114, nll_loss=2.693, ppl=6.47, wps=15041.3, ups=4.32, wpb=3482.3, bsz=147.4, num_updates=99500, lr=0.000100251, gnorm=1.122, train_wall=23, wall=0
2024-07-18 18:40:07 | INFO | train_inner | epoch 006:   1780 / 19564 loss=4.117, nll_loss=2.697, ppl=6.48, wps=14728.8, ups=4.31, wpb=3413.6, bsz=151.8, num_updates=99600, lr=0.000100201, gnorm=1.131, train_wall=23, wall=0
2024-07-18 18:40:31 | INFO | train_inner | epoch 006:   1880 / 19564 loss=4.164, nll_loss=2.749, ppl=6.72, wps=14841.5, ups=4.27, wpb=3472.4, bsz=143.7, num_updates=99700, lr=0.00010015, gnorm=1.11, train_wall=23, wall=0
2024-07-18 18:40:54 | INFO | train_inner | epoch 006:   1980 / 19564 loss=4.174, nll_loss=2.761, ppl=6.78, wps=14718.6, ups=4.36, wpb=3378.3, bsz=127.5, num_updates=99800, lr=0.0001001, gnorm=1.187, train_wall=23, wall=0
2024-07-18 18:41:17 | INFO | train_inner | epoch 006:   2080 / 19564 loss=4.144, nll_loss=2.727, ppl=6.62, wps=14848.3, ups=4.35, wpb=3410.1, bsz=148.7, num_updates=99900, lr=0.00010005, gnorm=1.155, train_wall=23, wall=0
2024-07-18 18:41:39 | INFO | train_inner | epoch 006:   2180 / 19564 loss=4.152, nll_loss=2.736, ppl=6.66, wps=14725.9, ups=4.37, wpb=3370.3, bsz=135.3, num_updates=100000, lr=0.0001, gnorm=1.165, train_wall=23, wall=0
2024-07-18 18:41:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 18:41:42 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 4.036 | nll_loss 2.509 | ppl 5.69 | wps 44160.5 | wpb 2872.6 | bsz 51.2 | num_updates 100000 | best_loss 12.094
2024-07-18 18:41:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 18:41:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_100000.pt (epoch 6 @ 100000 updates, score 4.036) (writing took 7.112832957878709 seconds)
2024-07-18 18:41:49 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2024-07-18 18:41:49 | INFO | train | epoch 006 | loss 4.129 | nll_loss 2.71 | ppl 6.54 | wps 14024.6 | ups 4.07 | wpb 3442.6 | bsz 139.4 | num_updates 100000 | lr 0.0001 | gnorm 1.12 | train_wall 502 | wall 0
2024-07-18 18:41:49 | INFO | fairseq_cli.train | done training in 21618.8 seconds
