2024-07-31 20:44:36 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/wmt22.sep.tokenized.de-en', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='de', srcdict=None, target_lang='en', task='translation', tensorboard_logdir=None, testpref='./data/wmt22.sep.tokenized.de-en/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='./data/wmt22.sep.tokenized.de-en/train', user_dir=None, validpref='./data/wmt22.sep.tokenized.de-en/valid', workers=8)
2024-07-31 20:45:05 | INFO | fairseq_cli.preprocess | [de] Dictionary: 8 types
2024-07-31 20:45:23 | INFO | fairseq_cli.preprocess | [de] ./data/wmt22.sep.tokenized.de-en/train.de: 2782552 sents, 2782552 tokens, 0.0% replaced by <unk>
2024-07-31 20:45:23 | INFO | fairseq_cli.preprocess | [de] Dictionary: 8 types
2024-07-31 20:45:23 | INFO | fairseq_cli.preprocess | [de] ./data/wmt22.sep.tokenized.de-en/valid.de: 2203 sents, 2203 tokens, 0.0% replaced by <unk>
2024-07-31 20:45:23 | INFO | fairseq_cli.preprocess | [de] Dictionary: 8 types
2024-07-31 20:45:23 | INFO | fairseq_cli.preprocess | [de] ./data/wmt22.sep.tokenized.de-en/test.de: 785 sents, 785 tokens, 0.0% replaced by <unk>
2024-07-31 20:45:23 | INFO | fairseq_cli.preprocess | [en] Dictionary: 9968 types
2024-07-31 20:46:46 | INFO | fairseq_cli.preprocess | [en] ./data/wmt22.sep.tokenized.de-en/train.en: 2782552 sents, 67426902 tokens, 0.0% replaced by <unk>
2024-07-31 20:46:46 | INFO | fairseq_cli.preprocess | [en] Dictionary: 9968 types
2024-07-31 20:46:46 | INFO | fairseq_cli.preprocess | [en] ./data/wmt22.sep.tokenized.de-en/valid.en: 2203 sents, 123520 tokens, 0.0% replaced by <unk>
2024-07-31 20:46:46 | INFO | fairseq_cli.preprocess | [en] Dictionary: 9968 types
2024-07-31 20:46:46 | INFO | fairseq_cli.preprocess | [en] ./data/wmt22.sep.tokenized.de-en/test.en: 785 sents, 51963 tokens, 0.0% replaced by <unk>
2024-07-31 20:46:46 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/wmt22.sep.tokenized.de-en
2024-07-31 20:46:49 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt22.sep.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=1000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=100, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-31 20:46:49 | INFO | fairseq.tasks.translation | [de] dictionary: 8 types
2024-07-31 20:46:49 | INFO | fairseq.tasks.translation | [en] dictionary: 9968 types
2024-07-31 20:46:49 | INFO | fairseq.data.data_utils | loaded 2203 examples from: data-bin/wmt22.sep.tokenized.de-en/valid.de-en.de
2024-07-31 20:46:49 | INFO | fairseq.data.data_utils | loaded 2203 examples from: data-bin/wmt22.sep.tokenized.de-en/valid.de-en.en
2024-07-31 20:46:49 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.de-en valid de-en 2203 examples
2024-07-31 20:46:50 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9968, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=9968, bias=False)
  )
)
2024-07-31 20:46:50 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-31 20:46:50 | INFO | fairseq_cli.train | model: transformer_iwslt_de_en (TransformerModel)
2024-07-31 20:46:50 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-31 20:46:50 | INFO | fairseq_cli.train | num. model params: 36651008 (num. trained: 36651008)
2024-07-31 20:46:58 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-31 20:46:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-31 20:46:58 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-31 20:46:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-31 20:46:58 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-31 20:46:58 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-31 20:46:58 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/checkpoint_last.pt
2024-07-31 20:46:58 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-31 20:46:58 | INFO | fairseq.data.data_utils | loaded 2782552 examples from: data-bin/wmt22.sep.tokenized.de-en/train.de-en.de
2024-07-31 20:46:58 | INFO | fairseq.data.data_utils | loaded 2782552 examples from: data-bin/wmt22.sep.tokenized.de-en/train.de-en.en
2024-07-31 20:46:58 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.de-en train de-en 2782552 examples
2024-07-31 20:47:01 | INFO | fairseq.trainer | begin training epoch 1
2024-07-31 20:47:19 | INFO | train_inner | epoch 001:    100 / 17024 loss=13.112, nll_loss=13.01, ppl=8249.22, wps=24344.9, ups=6.17, wpb=3944, bsz=143.8, num_updates=100, lr=1.25e-05, gnorm=2.458, train_wall=18, wall=21
2024-07-31 20:47:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-31 20:47:21 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.156 | nll_loss 11.919 | ppl 3872.9 | wps 95688.1 | wpb 3529.1 | bsz 62.9 | num_updates 100
2024-07-31 20:47:21 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 20:47:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_100.pt (epoch 1 @ 100 updates, score 12.156) (writing took 1.8491867240518332 seconds)
2024-07-31 20:47:38 | INFO | train_inner | epoch 001:    200 / 17024 loss=11.825, nll_loss=11.574, ppl=3048.62, wps=21062.8, ups=5.33, wpb=3951.9, bsz=155.4, num_updates=200, lr=2.5e-05, gnorm=1.368, train_wall=15, wall=40
2024-07-31 20:47:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 20:47:39 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.318 | nll_loss 10.997 | ppl 2043.33 | wps 95416.2 | wpb 3529.1 | bsz 62.9 | num_updates 200 | best_loss 11.318
2024-07-31 20:47:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 20:47:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_200.pt (epoch 1 @ 200 updates, score 11.318) (writing took 6.4333814131096005 seconds)
2024-07-31 20:48:01 | INFO | train_inner | epoch 001:    300 / 17024 loss=11.158, nll_loss=10.815, ppl=1802, wps=16968.7, ups=4.26, wpb=3985.6, bsz=188.7, num_updates=300, lr=3.75e-05, gnorm=1.223, train_wall=15, wall=64
2024-07-31 20:48:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 20:48:03 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.9 | nll_loss 10.497 | ppl 1444.95 | wps 96134.2 | wpb 3529.1 | bsz 62.9 | num_updates 300 | best_loss 10.9
2024-07-31 20:48:03 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 20:48:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_300.pt (epoch 1 @ 300 updates, score 10.9) (writing took 6.198304307647049 seconds)
2024-07-31 20:48:24 | INFO | train_inner | epoch 001:    400 / 17024 loss=10.857, nll_loss=10.443, ppl=1391.9, wps=17137.4, ups=4.34, wpb=3952, bsz=148.6, num_updates=400, lr=5e-05, gnorm=1.069, train_wall=15, wall=87
2024-07-31 20:48:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 20:48:26 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.883 | nll_loss 10.416 | ppl 1366.47 | wps 95786.6 | wpb 3529.1 | bsz 62.9 | num_updates 400 | best_loss 10.883
2024-07-31 20:48:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 20:48:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_400.pt (epoch 1 @ 400 updates, score 10.883) (writing took 5.738120147958398 seconds)
2024-07-31 20:48:47 | INFO | train_inner | epoch 001:    500 / 17024 loss=10.729, nll_loss=10.277, ppl=1240.63, wps=17414.6, ups=4.4, wpb=3954.6, bsz=154.6, num_updates=500, lr=6.25e-05, gnorm=1.094, train_wall=15, wall=109
2024-07-31 20:48:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 20:48:49 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.829 | nll_loss 10.346 | ppl 1301.64 | wps 93062.8 | wpb 3529.1 | bsz 62.9 | num_updates 500 | best_loss 10.829
2024-07-31 20:48:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 20:48:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_500.pt (epoch 1 @ 500 updates, score 10.829) (writing took 6.024112768471241 seconds)
2024-07-31 20:49:10 | INFO | train_inner | epoch 001:    600 / 17024 loss=10.665, nll_loss=10.201, ppl=1176.82, wps=17140.8, ups=4.32, wpb=3965.4, bsz=185.7, num_updates=600, lr=7.5e-05, gnorm=1.179, train_wall=15, wall=132
2024-07-31 20:49:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 20:49:12 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.546 | nll_loss 10.009 | ppl 1030.67 | wps 95944 | wpb 3529.1 | bsz 62.9 | num_updates 600 | best_loss 10.546
2024-07-31 20:49:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 20:49:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_600.pt (epoch 1 @ 600 updates, score 10.546) (writing took 5.669407622888684 seconds)
2024-07-31 20:49:33 | INFO | train_inner | epoch 001:    700 / 17024 loss=10.537, nll_loss=10.054, ppl=1063.05, wps=17452.2, ups=4.45, wpb=3923, bsz=150.2, num_updates=700, lr=8.75e-05, gnorm=1.091, train_wall=15, wall=155
2024-07-31 20:49:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 20:49:34 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.384 | nll_loss 9.818 | ppl 902.61 | wps 94024.1 | wpb 3529.1 | bsz 62.9 | num_updates 700 | best_loss 10.384
2024-07-31 20:49:34 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 20:49:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_700.pt (epoch 1 @ 700 updates, score 10.384) (writing took 6.026029612869024 seconds)
2024-07-31 20:49:56 | INFO | train_inner | epoch 001:    800 / 17024 loss=10.431, nll_loss=9.932, ppl=976.99, wps=17209.2, ups=4.33, wpb=3970.6, bsz=165.5, num_updates=800, lr=0.0001, gnorm=1.092, train_wall=15, wall=178
2024-07-31 20:49:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 20:49:57 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.353 | nll_loss 9.777 | ppl 877.36 | wps 95332.6 | wpb 3529.1 | bsz 62.9 | num_updates 800 | best_loss 10.353
2024-07-31 20:49:57 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 20:50:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_800.pt (epoch 1 @ 800 updates, score 10.353) (writing took 5.990948619320989 seconds)
2024-07-31 20:50:19 | INFO | train_inner | epoch 001:    900 / 17024 loss=10.313, nll_loss=9.797, ppl=889.62, wps=17050.7, ups=4.32, wpb=3946.6, bsz=148.2, num_updates=900, lr=0.0001125, gnorm=1.057, train_wall=16, wall=201
2024-07-31 20:50:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 20:50:20 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.17 | nll_loss 9.582 | ppl 766.48 | wps 95675.1 | wpb 3529.1 | bsz 62.9 | num_updates 900 | best_loss 10.17
2024-07-31 20:50:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 20:50:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_900.pt (epoch 1 @ 900 updates, score 10.17) (writing took 6.235905245877802 seconds)
2024-07-31 20:50:42 | INFO | train_inner | epoch 001:   1000 / 17024 loss=10.162, nll_loss=9.622, ppl=787.96, wps=16915.4, ups=4.28, wpb=3954, bsz=159, num_updates=1000, lr=0.000125, gnorm=1.076, train_wall=16, wall=225
2024-07-31 20:50:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 20:50:44 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.176 | nll_loss 9.561 | ppl 755.2 | wps 95679 | wpb 3529.1 | bsz 62.9 | num_updates 1000 | best_loss 10.17
2024-07-31 20:50:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 20:50:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 10.176) (writing took 4.660863118246198 seconds)
2024-07-31 20:50:48 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-31 20:50:48 | INFO | train | epoch 001 | loss 10.978 | nll_loss 10.572 | ppl 1522.46 | wps 17533.2 | ups 4.43 | wpb 3954.8 | bsz 160 | num_updates 1000 | lr 0.000125 | gnorm 1.271 | train_wall 157 | wall 231
2024-07-31 20:50:48 | INFO | fairseq_cli.train | done training in 227.8 seconds
2024-07-31 20:50:53 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt22.sep.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=10000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=500, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-31 20:50:53 | INFO | fairseq.tasks.translation | [de] dictionary: 8 types
2024-07-31 20:50:53 | INFO | fairseq.tasks.translation | [en] dictionary: 9968 types
2024-07-31 20:50:53 | INFO | fairseq.data.data_utils | loaded 2203 examples from: data-bin/wmt22.sep.tokenized.de-en/valid.de-en.de
2024-07-31 20:50:53 | INFO | fairseq.data.data_utils | loaded 2203 examples from: data-bin/wmt22.sep.tokenized.de-en/valid.de-en.en
2024-07-31 20:50:53 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.de-en valid de-en 2203 examples
2024-07-31 20:50:54 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9968, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=9968, bias=False)
  )
)
2024-07-31 20:50:54 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-31 20:50:54 | INFO | fairseq_cli.train | model: transformer_iwslt_de_en (TransformerModel)
2024-07-31 20:50:54 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-31 20:50:54 | INFO | fairseq_cli.train | num. model params: 36651008 (num. trained: 36651008)
2024-07-31 20:51:02 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-31 20:51:02 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-31 20:51:02 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-31 20:51:02 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-31 20:51:02 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-31 20:51:02 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-31 20:51:03 | INFO | fairseq.trainer | loaded checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 1000 updates)
2024-07-31 20:51:03 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-31 20:51:03 | INFO | fairseq.data.data_utils | loaded 2782552 examples from: data-bin/wmt22.sep.tokenized.de-en/train.de-en.de
2024-07-31 20:51:03 | INFO | fairseq.data.data_utils | loaded 2782552 examples from: data-bin/wmt22.sep.tokenized.de-en/train.de-en.en
2024-07-31 20:51:03 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.de-en train de-en 2782552 examples
2024-07-31 20:51:06 | INFO | fairseq.trainer | begin training epoch 1
2024-07-31 20:51:22 | INFO | train_inner | epoch 001:   1100 / 17024 loss=10.063, nll_loss=9.506, ppl=727.03, wps=19124.6, ups=4.82, wpb=3969.8, bsz=156.2, num_updates=1100, lr=0.0001375, gnorm=1.102, train_wall=16, wall=0
2024-07-31 20:51:38 | INFO | train_inner | epoch 001:   1200 / 17024 loss=9.957, nll_loss=9.383, ppl=667.72, wps=25409.7, ups=6.42, wpb=3958.4, bsz=150.1, num_updates=1200, lr=0.00015, gnorm=1.084, train_wall=15, wall=0
2024-07-31 20:51:54 | INFO | train_inner | epoch 001:   1300 / 17024 loss=9.839, nll_loss=9.246, ppl=607.06, wps=25328.6, ups=6.41, wpb=3950.2, bsz=141.4, num_updates=1300, lr=0.0001625, gnorm=1.08, train_wall=15, wall=0
2024-07-31 20:52:09 | INFO | train_inner | epoch 001:   1400 / 17024 loss=9.757, nll_loss=9.15, ppl=568.13, wps=25182.1, ups=6.35, wpb=3964, bsz=158.1, num_updates=1400, lr=0.000175, gnorm=1.099, train_wall=16, wall=0
2024-07-31 20:52:25 | INFO | train_inner | epoch 001:   1500 / 17024 loss=9.659, nll_loss=9.036, ppl=524.87, wps=25394.1, ups=6.4, wpb=3964.8, bsz=168.3, num_updates=1500, lr=0.0001875, gnorm=1.151, train_wall=15, wall=0
2024-07-31 20:52:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-31 20:52:26 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.559 | nll_loss 8.875 | ppl 469.53 | wps 95485.3 | wpb 3529.1 | bsz 62.9 | num_updates 1500 | best_loss 9.559
2024-07-31 20:52:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 20:52:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_1500.pt (epoch 1 @ 1500 updates, score 9.559) (writing took 6.329657522961497 seconds)
2024-07-31 20:52:48 | INFO | train_inner | epoch 001:   1600 / 17024 loss=9.574, nll_loss=8.936, ppl=489.86, wps=17071.7, ups=4.3, wpb=3967.7, bsz=161, num_updates=1600, lr=0.0002, gnorm=1.049, train_wall=15, wall=0
2024-07-31 20:53:04 | INFO | train_inner | epoch 001:   1700 / 17024 loss=9.502, nll_loss=8.853, ppl=462.41, wps=25587, ups=6.48, wpb=3950.7, bsz=148.6, num_updates=1700, lr=0.0002125, gnorm=1.043, train_wall=15, wall=0
2024-07-31 20:53:19 | INFO | train_inner | epoch 001:   1800 / 17024 loss=9.47, nll_loss=8.814, ppl=450.19, wps=25588.7, ups=6.43, wpb=3981.6, bsz=180.6, num_updates=1800, lr=0.000225, gnorm=1.09, train_wall=15, wall=0
2024-07-31 20:53:35 | INFO | train_inner | epoch 001:   1900 / 17024 loss=9.362, nll_loss=8.69, ppl=412.98, wps=25648.8, ups=6.47, wpb=3963.2, bsz=150.6, num_updates=1900, lr=0.0002375, gnorm=0.944, train_wall=15, wall=0
2024-07-31 20:53:50 | INFO | train_inner | epoch 001:   2000 / 17024 loss=9.325, nll_loss=8.647, ppl=400.79, wps=25781.4, ups=6.5, wpb=3965, bsz=165.1, num_updates=2000, lr=0.00025, gnorm=1.035, train_wall=15, wall=0
2024-07-31 20:53:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 20:53:51 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.337 | nll_loss 8.608 | ppl 390.2 | wps 96335 | wpb 3529.1 | bsz 62.9 | num_updates 2000 | best_loss 9.337
2024-07-31 20:53:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 20:53:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 9.337) (writing took 6.0061173206195235 seconds)
2024-07-31 20:54:13 | INFO | train_inner | epoch 001:   2100 / 17024 loss=9.294, nll_loss=8.61, ppl=390.64, wps=17355.6, ups=4.37, wpb=3973.4, bsz=177.3, num_updates=2100, lr=0.0002625, gnorm=1.027, train_wall=15, wall=0
2024-07-31 20:54:28 | INFO | train_inner | epoch 001:   2200 / 17024 loss=9.21, nll_loss=8.514, ppl=365.58, wps=25787.5, ups=6.5, wpb=3964.7, bsz=164.7, num_updates=2200, lr=0.000275, gnorm=0.947, train_wall=15, wall=0
2024-07-31 20:54:44 | INFO | train_inner | epoch 001:   2300 / 17024 loss=9.159, nll_loss=8.454, ppl=350.75, wps=25635.1, ups=6.5, wpb=3946.4, bsz=158.3, num_updates=2300, lr=0.0002875, gnorm=0.953, train_wall=15, wall=0
2024-07-31 20:54:59 | INFO | train_inner | epoch 001:   2400 / 17024 loss=9.115, nll_loss=8.402, ppl=338.36, wps=25727.5, ups=6.48, wpb=3967.9, bsz=169.9, num_updates=2400, lr=0.0003, gnorm=1.003, train_wall=15, wall=0
2024-07-31 20:55:15 | INFO | train_inner | epoch 001:   2500 / 17024 loss=9.033, nll_loss=8.31, ppl=317.33, wps=25548.8, ups=6.44, wpb=3965.5, bsz=163, num_updates=2500, lr=0.0003125, gnorm=0.928, train_wall=15, wall=0
2024-07-31 20:55:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 20:55:16 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.088 | nll_loss 8.313 | ppl 318.1 | wps 97346.5 | wpb 3529.1 | bsz 62.9 | num_updates 2500 | best_loss 9.088
2024-07-31 20:55:16 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 20:55:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_2500.pt (epoch 1 @ 2500 updates, score 9.088) (writing took 6.657210577279329 seconds)
2024-07-31 20:55:38 | INFO | train_inner | epoch 001:   2600 / 17024 loss=9.012, nll_loss=8.285, ppl=311.86, wps=16790.3, ups=4.25, wpb=3955.2, bsz=174.4, num_updates=2600, lr=0.000325, gnorm=0.959, train_wall=15, wall=0
2024-07-31 20:55:54 | INFO | train_inner | epoch 001:   2700 / 17024 loss=8.957, nll_loss=8.221, ppl=298.29, wps=25336.6, ups=6.43, wpb=3940.2, bsz=161.4, num_updates=2700, lr=0.0003375, gnorm=0.937, train_wall=15, wall=0
2024-07-31 20:56:09 | INFO | train_inner | epoch 001:   2800 / 17024 loss=8.888, nll_loss=8.142, ppl=282.41, wps=25485, ups=6.43, wpb=3966.2, bsz=168.2, num_updates=2800, lr=0.00035, gnorm=0.868, train_wall=15, wall=0
2024-07-31 20:56:25 | INFO | train_inner | epoch 001:   2900 / 17024 loss=8.854, nll_loss=8.101, ppl=274.62, wps=25746, ups=6.48, wpb=3970.4, bsz=189.6, num_updates=2900, lr=0.0003625, gnorm=0.948, train_wall=15, wall=0
2024-07-31 20:56:40 | INFO | train_inner | epoch 001:   3000 / 17024 loss=8.806, nll_loss=8.047, ppl=264.39, wps=25696.6, ups=6.48, wpb=3967.8, bsz=181, num_updates=3000, lr=0.000375, gnorm=0.879, train_wall=15, wall=0
2024-07-31 20:56:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 20:56:42 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.843 | nll_loss 8.034 | ppl 262.05 | wps 96418.3 | wpb 3529.1 | bsz 62.9 | num_updates 3000 | best_loss 8.843
2024-07-31 20:56:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 20:56:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_3000.pt (epoch 1 @ 3000 updates, score 8.843) (writing took 6.50623014383018 seconds)
2024-07-31 20:57:04 | INFO | train_inner | epoch 001:   3100 / 17024 loss=8.74, nll_loss=7.97, ppl=250.71, wps=17000, ups=4.28, wpb=3971.8, bsz=174, num_updates=3100, lr=0.0003875, gnorm=0.851, train_wall=15, wall=0
2024-07-31 20:57:19 | INFO | train_inner | epoch 001:   3200 / 17024 loss=8.723, nll_loss=7.95, ppl=247.26, wps=25684, ups=6.49, wpb=3954.7, bsz=154, num_updates=3200, lr=0.0004, gnorm=0.883, train_wall=15, wall=0
2024-07-31 20:57:35 | INFO | train_inner | epoch 001:   3300 / 17024 loss=8.671, nll_loss=7.89, ppl=237.19, wps=25328.8, ups=6.43, wpb=3940.5, bsz=165.4, num_updates=3300, lr=0.0004125, gnorm=0.898, train_wall=15, wall=0
2024-07-31 20:57:50 | INFO | train_inner | epoch 001:   3400 / 17024 loss=8.647, nll_loss=7.863, ppl=232.79, wps=25734.8, ups=6.47, wpb=3979, bsz=186.3, num_updates=3400, lr=0.000425, gnorm=0.898, train_wall=15, wall=0
2024-07-31 20:58:05 | INFO | train_inner | epoch 001:   3500 / 17024 loss=8.589, nll_loss=7.796, ppl=222.32, wps=25646.9, ups=6.46, wpb=3968.6, bsz=184.5, num_updates=3500, lr=0.0004375, gnorm=0.838, train_wall=15, wall=0
2024-07-31 20:58:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 20:58:07 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.638 | nll_loss 7.803 | ppl 223.4 | wps 95241.6 | wpb 3529.1 | bsz 62.9 | num_updates 3500 | best_loss 8.638
2024-07-31 20:58:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 20:58:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_3500.pt (epoch 1 @ 3500 updates, score 8.638) (writing took 6.852042496204376 seconds)
2024-07-31 20:58:29 | INFO | train_inner | epoch 001:   3600 / 17024 loss=8.514, nll_loss=7.709, ppl=209.31, wps=16752.2, ups=4.21, wpb=3978.2, bsz=166.4, num_updates=3600, lr=0.00045, gnorm=0.822, train_wall=15, wall=0
2024-07-31 20:58:45 | INFO | train_inner | epoch 001:   3700 / 17024 loss=8.484, nll_loss=7.676, ppl=204.44, wps=25736.5, ups=6.49, wpb=3968.2, bsz=172.5, num_updates=3700, lr=0.0004625, gnorm=0.817, train_wall=15, wall=0
2024-07-31 20:59:00 | INFO | train_inner | epoch 001:   3800 / 17024 loss=8.43, nll_loss=7.612, ppl=195.63, wps=25803.1, ups=6.55, wpb=3938.4, bsz=151.8, num_updates=3800, lr=0.000475, gnorm=0.815, train_wall=15, wall=0
2024-07-31 20:59:15 | INFO | train_inner | epoch 001:   3900 / 17024 loss=8.404, nll_loss=7.582, ppl=191.59, wps=25725.3, ups=6.51, wpb=3950.8, bsz=137.9, num_updates=3900, lr=0.0004875, gnorm=0.805, train_wall=15, wall=0
2024-07-31 20:59:31 | INFO | train_inner | epoch 001:   4000 / 17024 loss=8.393, nll_loss=7.569, ppl=189.89, wps=25662.9, ups=6.46, wpb=3969.8, bsz=160.2, num_updates=4000, lr=0.0005, gnorm=0.8, train_wall=15, wall=0
2024-07-31 20:59:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 20:59:32 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.509 | nll_loss 7.641 | ppl 199.57 | wps 96877 | wpb 3529.1 | bsz 62.9 | num_updates 4000 | best_loss 8.509
2024-07-31 20:59:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 20:59:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 8.509) (writing took 6.42638739105314 seconds)
2024-07-31 20:59:54 | INFO | train_inner | epoch 001:   4100 / 17024 loss=8.374, nll_loss=7.548, ppl=187.16, wps=17006.7, ups=4.28, wpb=3974, bsz=170.2, num_updates=4100, lr=0.000493865, gnorm=0.798, train_wall=15, wall=0
2024-07-31 21:00:10 | INFO | train_inner | epoch 001:   4200 / 17024 loss=8.323, nll_loss=7.49, ppl=179.72, wps=25648.5, ups=6.5, wpb=3943.7, bsz=149.4, num_updates=4200, lr=0.00048795, gnorm=0.783, train_wall=15, wall=0
2024-07-31 21:00:25 | INFO | train_inner | epoch 001:   4300 / 17024 loss=8.337, nll_loss=7.504, ppl=181.57, wps=25581.1, ups=6.45, wpb=3965.2, bsz=179, num_updates=4300, lr=0.000482243, gnorm=0.833, train_wall=15, wall=0
2024-07-31 21:00:40 | INFO | train_inner | epoch 001:   4400 / 17024 loss=8.303, nll_loss=7.465, ppl=176.72, wps=25463.3, ups=6.45, wpb=3944.9, bsz=166.6, num_updates=4400, lr=0.000476731, gnorm=0.815, train_wall=15, wall=0
2024-07-31 21:00:56 | INFO | train_inner | epoch 001:   4500 / 17024 loss=8.266, nll_loss=7.424, ppl=171.68, wps=25629.6, ups=6.5, wpb=3944.4, bsz=164.3, num_updates=4500, lr=0.000471405, gnorm=0.782, train_wall=15, wall=0
2024-07-31 21:00:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:00:57 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.404 | nll_loss 7.516 | ppl 183.08 | wps 97299.1 | wpb 3529.1 | bsz 62.9 | num_updates 4500 | best_loss 8.404
2024-07-31 21:00:57 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:01:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_4500.pt (epoch 1 @ 4500 updates, score 8.404) (writing took 6.1093601221218705 seconds)
2024-07-31 21:01:19 | INFO | train_inner | epoch 001:   4600 / 17024 loss=8.188, nll_loss=7.334, ppl=161.32, wps=17261.4, ups=4.37, wpb=3949, bsz=157.3, num_updates=4600, lr=0.000466252, gnorm=0.755, train_wall=15, wall=0
2024-07-31 21:01:34 | INFO | train_inner | epoch 001:   4700 / 17024 loss=8.159, nll_loss=7.301, ppl=157.65, wps=25615.2, ups=6.48, wpb=3951.5, bsz=149.4, num_updates=4700, lr=0.000461266, gnorm=0.759, train_wall=15, wall=0
2024-07-31 21:01:50 | INFO | train_inner | epoch 001:   4800 / 17024 loss=8.15, nll_loss=7.29, ppl=156.48, wps=25822.3, ups=6.53, wpb=3957.1, bsz=153.8, num_updates=4800, lr=0.000456435, gnorm=0.748, train_wall=15, wall=0
2024-07-31 21:02:05 | INFO | train_inner | epoch 001:   4900 / 17024 loss=8.157, nll_loss=7.298, ppl=157.41, wps=25706.6, ups=6.46, wpb=3980.1, bsz=173.8, num_updates=4900, lr=0.000451754, gnorm=0.748, train_wall=15, wall=0
2024-07-31 21:02:20 | INFO | train_inner | epoch 001:   5000 / 17024 loss=8.119, nll_loss=7.255, ppl=152.78, wps=25684.6, ups=6.46, wpb=3973, bsz=170.6, num_updates=5000, lr=0.000447214, gnorm=0.764, train_wall=15, wall=0
2024-07-31 21:02:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:02:22 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.26 | nll_loss 7.361 | ppl 164.34 | wps 94720.9 | wpb 3529.1 | bsz 62.9 | num_updates 5000 | best_loss 8.26
2024-07-31 21:02:22 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:02:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_5000.pt (epoch 1 @ 5000 updates, score 8.26) (writing took 6.40991650428623 seconds)
2024-07-31 21:02:44 | INFO | train_inner | epoch 001:   5100 / 17024 loss=8.079, nll_loss=7.209, ppl=147.99, wps=16980.2, ups=4.28, wpb=3969, bsz=166.9, num_updates=5100, lr=0.000442807, gnorm=0.729, train_wall=15, wall=0
2024-07-31 21:02:59 | INFO | train_inner | epoch 001:   5200 / 17024 loss=8.099, nll_loss=7.232, ppl=150.38, wps=25664, ups=6.46, wpb=3970, bsz=171.1, num_updates=5200, lr=0.000438529, gnorm=0.772, train_wall=15, wall=0
2024-07-31 21:03:15 | INFO | train_inner | epoch 001:   5300 / 17024 loss=8.051, nll_loss=7.176, ppl=144.63, wps=25615.5, ups=6.49, wpb=3945.4, bsz=157.8, num_updates=5300, lr=0.000434372, gnorm=0.742, train_wall=15, wall=0
2024-07-31 21:03:30 | INFO | train_inner | epoch 001:   5400 / 17024 loss=8.088, nll_loss=7.219, ppl=148.99, wps=25720.4, ups=6.53, wpb=3936.1, bsz=171.2, num_updates=5400, lr=0.000430331, gnorm=0.814, train_wall=15, wall=0
2024-07-31 21:03:45 | INFO | train_inner | epoch 001:   5500 / 17024 loss=8.034, nll_loss=7.157, ppl=142.73, wps=25675.4, ups=6.49, wpb=3955.4, bsz=166.2, num_updates=5500, lr=0.000426401, gnorm=0.729, train_wall=15, wall=0
2024-07-31 21:03:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:03:47 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.199 | nll_loss 7.283 | ppl 155.78 | wps 97815.9 | wpb 3529.1 | bsz 62.9 | num_updates 5500 | best_loss 8.199
2024-07-31 21:03:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:03:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_5500.pt (epoch 1 @ 5500 updates, score 8.199) (writing took 6.603312406688929 seconds)
2024-07-31 21:04:09 | INFO | train_inner | epoch 001:   5600 / 17024 loss=7.999, nll_loss=7.118, ppl=138.89, wps=16870, ups=4.26, wpb=3961.4, bsz=162, num_updates=5600, lr=0.000422577, gnorm=0.73, train_wall=15, wall=0
2024-07-31 21:04:24 | INFO | train_inner | epoch 001:   5700 / 17024 loss=7.997, nll_loss=7.114, ppl=138.57, wps=25705.7, ups=6.47, wpb=3972.7, bsz=177, num_updates=5700, lr=0.000418854, gnorm=0.739, train_wall=15, wall=0
2024-07-31 21:04:40 | INFO | train_inner | epoch 001:   5800 / 17024 loss=7.989, nll_loss=7.106, ppl=137.74, wps=25651.3, ups=6.48, wpb=3958.5, bsz=171.9, num_updates=5800, lr=0.000415227, gnorm=0.773, train_wall=15, wall=0
2024-07-31 21:04:55 | INFO | train_inner | epoch 001:   5900 / 17024 loss=7.962, nll_loss=7.073, ppl=134.69, wps=25660.6, ups=6.48, wpb=3958.4, bsz=154.7, num_updates=5900, lr=0.000411693, gnorm=0.729, train_wall=15, wall=0
2024-07-31 21:05:11 | INFO | train_inner | epoch 001:   6000 / 17024 loss=8, nll_loss=7.119, ppl=138.99, wps=25708, ups=6.48, wpb=3969.4, bsz=189.1, num_updates=6000, lr=0.000408248, gnorm=0.753, train_wall=15, wall=0
2024-07-31 21:05:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:05:12 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.137 | nll_loss 7.216 | ppl 148.65 | wps 94156 | wpb 3529.1 | bsz 62.9 | num_updates 6000 | best_loss 8.137
2024-07-31 21:05:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:05:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 8.137) (writing took 7.149337889626622 seconds)
2024-07-31 21:05:35 | INFO | train_inner | epoch 001:   6100 / 17024 loss=7.914, nll_loss=7.02, ppl=129.79, wps=16147.9, ups=4.08, wpb=3959.9, bsz=151.9, num_updates=6100, lr=0.000404888, gnorm=0.723, train_wall=16, wall=0
2024-07-31 21:05:51 | INFO | train_inner | epoch 001:   6200 / 17024 loss=7.896, nll_loss=6.998, ppl=127.86, wps=25503.4, ups=6.46, wpb=3947.8, bsz=157.1, num_updates=6200, lr=0.00040161, gnorm=0.733, train_wall=15, wall=0
2024-07-31 21:06:06 | INFO | train_inner | epoch 001:   6300 / 17024 loss=7.892, nll_loss=6.993, ppl=127.4, wps=25579.7, ups=6.42, wpb=3982.6, bsz=151.6, num_updates=6300, lr=0.00039841, gnorm=0.738, train_wall=15, wall=0
2024-07-31 21:06:22 | INFO | train_inner | epoch 001:   6400 / 17024 loss=7.889, nll_loss=6.991, ppl=127.23, wps=25749.3, ups=6.51, wpb=3958.1, bsz=158.5, num_updates=6400, lr=0.000395285, gnorm=0.745, train_wall=15, wall=0
2024-07-31 21:06:37 | INFO | train_inner | epoch 001:   6500 / 17024 loss=7.899, nll_loss=7.003, ppl=128.28, wps=25559.6, ups=6.47, wpb=3952.2, bsz=178.7, num_updates=6500, lr=0.000392232, gnorm=0.741, train_wall=15, wall=0
2024-07-31 21:06:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:06:38 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.083 | nll_loss 7.157 | ppl 142.7 | wps 95520 | wpb 3529.1 | bsz 62.9 | num_updates 6500 | best_loss 8.083
2024-07-31 21:06:38 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:06:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_6500.pt (epoch 1 @ 6500 updates, score 8.083) (writing took 6.8660476710647345 seconds)
2024-07-31 21:07:01 | INFO | train_inner | epoch 001:   6600 / 17024 loss=7.879, nll_loss=6.98, ppl=126.23, wps=16684.4, ups=4.21, wpb=3965.8, bsz=163.5, num_updates=6600, lr=0.000389249, gnorm=0.748, train_wall=15, wall=0
2024-07-31 21:07:16 | INFO | train_inner | epoch 001:   6700 / 17024 loss=7.873, nll_loss=6.972, ppl=125.55, wps=25494.9, ups=6.46, wpb=3947, bsz=152.1, num_updates=6700, lr=0.000386334, gnorm=0.766, train_wall=15, wall=0
2024-07-31 21:07:32 | INFO | train_inner | epoch 001:   6800 / 17024 loss=7.826, nll_loss=6.919, ppl=121, wps=25573.6, ups=6.41, wpb=3991, bsz=172.8, num_updates=6800, lr=0.000383482, gnorm=0.72, train_wall=15, wall=0
2024-07-31 21:07:47 | INFO | train_inner | epoch 001:   6900 / 17024 loss=7.846, nll_loss=6.941, ppl=122.88, wps=25509.4, ups=6.46, wpb=3948.1, bsz=160.3, num_updates=6900, lr=0.000380693, gnorm=0.738, train_wall=15, wall=0
2024-07-31 21:08:03 | INFO | train_inner | epoch 001:   7000 / 17024 loss=7.836, nll_loss=6.931, ppl=122, wps=25706.8, ups=6.46, wpb=3978.7, bsz=169.4, num_updates=7000, lr=0.000377964, gnorm=0.735, train_wall=15, wall=0
2024-07-31 21:08:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:08:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.011 | nll_loss 7.067 | ppl 134.11 | wps 95139.1 | wpb 3529.1 | bsz 62.9 | num_updates 7000 | best_loss 8.011
2024-07-31 21:08:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:08:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_7000.pt (epoch 1 @ 7000 updates, score 8.011) (writing took 6.903988689184189 seconds)
2024-07-31 21:08:27 | INFO | train_inner | epoch 001:   7100 / 17024 loss=7.806, nll_loss=6.896, ppl=119.1, wps=16357.7, ups=4.11, wpb=3976.3, bsz=169.5, num_updates=7100, lr=0.000375293, gnorm=0.745, train_wall=16, wall=0
2024-07-31 21:08:43 | INFO | train_inner | epoch 001:   7200 / 17024 loss=7.843, nll_loss=6.94, ppl=122.75, wps=25445.1, ups=6.38, wpb=3987.3, bsz=183.3, num_updates=7200, lr=0.000372678, gnorm=0.753, train_wall=15, wall=0
2024-07-31 21:08:58 | INFO | train_inner | epoch 001:   7300 / 17024 loss=7.783, nll_loss=6.869, ppl=116.87, wps=25597.7, ups=6.46, wpb=3961.7, bsz=150.6, num_updates=7300, lr=0.000370117, gnorm=0.723, train_wall=15, wall=0
2024-07-31 21:09:14 | INFO | train_inner | epoch 001:   7400 / 17024 loss=7.813, nll_loss=6.905, ppl=119.8, wps=25666.2, ups=6.44, wpb=3983.2, bsz=182.8, num_updates=7400, lr=0.000367607, gnorm=0.762, train_wall=15, wall=0
2024-07-31 21:09:30 | INFO | train_inner | epoch 001:   7500 / 17024 loss=7.804, nll_loss=6.893, ppl=118.86, wps=25222.9, ups=6.34, wpb=3975.6, bsz=174.6, num_updates=7500, lr=0.000365148, gnorm=0.777, train_wall=16, wall=0
2024-07-31 21:09:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:09:31 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.055 | nll_loss 7.113 | ppl 138.44 | wps 94678.3 | wpb 3529.1 | bsz 62.9 | num_updates 7500 | best_loss 8.011
2024-07-31 21:09:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:09:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_7500.pt (epoch 1 @ 7500 updates, score 8.055) (writing took 3.8552275858819485 seconds)
2024-07-31 21:09:50 | INFO | train_inner | epoch 001:   7600 / 17024 loss=7.756, nll_loss=6.839, ppl=114.5, wps=19074, ups=4.83, wpb=3947.4, bsz=152.7, num_updates=7600, lr=0.000362738, gnorm=0.745, train_wall=15, wall=0
2024-07-31 21:10:06 | INFO | train_inner | epoch 001:   7700 / 17024 loss=7.742, nll_loss=6.822, ppl=113.15, wps=25482.8, ups=6.47, wpb=3940.9, bsz=146.3, num_updates=7700, lr=0.000360375, gnorm=0.727, train_wall=15, wall=0
2024-07-31 21:10:21 | INFO | train_inner | epoch 001:   7800 / 17024 loss=7.766, nll_loss=6.849, ppl=115.31, wps=25685.3, ups=6.5, wpb=3950.4, bsz=163, num_updates=7800, lr=0.000358057, gnorm=0.752, train_wall=15, wall=0
2024-07-31 21:10:37 | INFO | train_inner | epoch 001:   7900 / 17024 loss=7.728, nll_loss=6.806, ppl=111.86, wps=25666.5, ups=6.5, wpb=3950.2, bsz=150, num_updates=7900, lr=0.000355784, gnorm=0.737, train_wall=15, wall=0
2024-07-31 21:10:52 | INFO | train_inner | epoch 001:   8000 / 17024 loss=7.711, nll_loss=6.787, ppl=110.39, wps=25686.4, ups=6.47, wpb=3968.6, bsz=149.8, num_updates=8000, lr=0.000353553, gnorm=0.732, train_wall=15, wall=0
2024-07-31 21:10:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:10:53 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.925 | nll_loss 6.974 | ppl 125.71 | wps 96093.5 | wpb 3529.1 | bsz 62.9 | num_updates 8000 | best_loss 7.925
2024-07-31 21:10:53 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:11:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 7.925) (writing took 6.815722559578717 seconds)
2024-07-31 21:11:16 | INFO | train_inner | epoch 001:   8100 / 17024 loss=7.75, nll_loss=6.833, ppl=114, wps=16693.6, ups=4.2, wpb=3977.2, bsz=185.4, num_updates=8100, lr=0.000351364, gnorm=0.758, train_wall=15, wall=0
2024-07-31 21:11:31 | INFO | train_inner | epoch 001:   8200 / 17024 loss=7.721, nll_loss=6.798, ppl=111.26, wps=25676.2, ups=6.47, wpb=3968.8, bsz=157.5, num_updates=8200, lr=0.000349215, gnorm=0.741, train_wall=15, wall=0
2024-07-31 21:11:47 | INFO | train_inner | epoch 001:   8300 / 17024 loss=7.713, nll_loss=6.79, ppl=110.64, wps=25815.9, ups=6.5, wpb=3972.6, bsz=167, num_updates=8300, lr=0.000347105, gnorm=0.749, train_wall=15, wall=0
2024-07-31 21:12:02 | INFO | train_inner | epoch 001:   8400 / 17024 loss=7.723, nll_loss=6.8, ppl=111.45, wps=24943.7, ups=6.33, wpb=3938.3, bsz=168.5, num_updates=8400, lr=0.000345033, gnorm=0.749, train_wall=16, wall=0
2024-07-31 21:12:18 | INFO | train_inner | epoch 001:   8500 / 17024 loss=7.711, nll_loss=6.786, ppl=110.38, wps=24819.9, ups=6.26, wpb=3962.6, bsz=164.2, num_updates=8500, lr=0.000342997, gnorm=0.754, train_wall=16, wall=0
2024-07-31 21:12:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:12:20 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.94 | nll_loss 6.982 | ppl 126.43 | wps 95428.8 | wpb 3529.1 | bsz 62.9 | num_updates 8500 | best_loss 7.925
2024-07-31 21:12:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:12:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_8500.pt (epoch 1 @ 8500 updates, score 7.94) (writing took 3.66433338355273 seconds)
2024-07-31 21:12:41 | INFO | train_inner | epoch 001:   8600 / 17024 loss=7.719, nll_loss=6.797, ppl=111.17, wps=17536, ups=4.45, wpb=3936.5, bsz=167.9, num_updates=8600, lr=0.000340997, gnorm=0.765, train_wall=17, wall=0
2024-07-31 21:12:56 | INFO | train_inner | epoch 001:   8700 / 17024 loss=7.68, nll_loss=6.751, ppl=107.73, wps=25596.1, ups=6.45, wpb=3969.3, bsz=162.5, num_updates=8700, lr=0.000339032, gnorm=0.739, train_wall=15, wall=0
2024-07-31 21:13:12 | INFO | train_inner | epoch 001:   8800 / 17024 loss=7.689, nll_loss=6.762, ppl=108.5, wps=25584.7, ups=6.45, wpb=3966.9, bsz=165.9, num_updates=8800, lr=0.0003371, gnorm=0.76, train_wall=15, wall=0
2024-07-31 21:13:27 | INFO | train_inner | epoch 001:   8900 / 17024 loss=7.708, nll_loss=6.784, ppl=110.18, wps=25472, ups=6.45, wpb=3947.9, bsz=173, num_updates=8900, lr=0.000335201, gnorm=0.758, train_wall=15, wall=0
2024-07-31 21:13:43 | INFO | train_inner | epoch 001:   9000 / 17024 loss=7.699, nll_loss=6.773, ppl=109.36, wps=25607.6, ups=6.46, wpb=3963.3, bsz=179.6, num_updates=9000, lr=0.000333333, gnorm=0.756, train_wall=15, wall=0
2024-07-31 21:13:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:13:44 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.883 | nll_loss 6.925 | ppl 121.49 | wps 95796 | wpb 3529.1 | bsz 62.9 | num_updates 9000 | best_loss 7.883
2024-07-31 21:13:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:13:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_9000.pt (epoch 1 @ 9000 updates, score 7.883) (writing took 6.463680465705693 seconds)
2024-07-31 21:14:06 | INFO | train_inner | epoch 001:   9100 / 17024 loss=7.639, nll_loss=6.704, ppl=104.25, wps=16947.1, ups=4.27, wpb=3970.2, bsz=162.1, num_updates=9100, lr=0.000331497, gnorm=0.75, train_wall=15, wall=0
2024-07-31 21:14:22 | INFO | train_inner | epoch 001:   9200 / 17024 loss=7.674, nll_loss=6.745, ppl=107.25, wps=25232.6, ups=6.34, wpb=3982.2, bsz=178.2, num_updates=9200, lr=0.00032969, gnorm=0.772, train_wall=16, wall=0
2024-07-31 21:14:37 | INFO | train_inner | epoch 001:   9300 / 17024 loss=7.633, nll_loss=6.696, ppl=103.71, wps=26030.5, ups=6.59, wpb=3952, bsz=146.6, num_updates=9300, lr=0.000327913, gnorm=0.733, train_wall=15, wall=0
2024-07-31 21:14:53 | INFO | train_inner | epoch 001:   9400 / 17024 loss=7.669, nll_loss=6.739, ppl=106.82, wps=25265, ups=6.34, wpb=3982.6, bsz=189.7, num_updates=9400, lr=0.000326164, gnorm=0.751, train_wall=16, wall=0
2024-07-31 21:15:09 | INFO | train_inner | epoch 001:   9500 / 17024 loss=7.649, nll_loss=6.715, ppl=105.09, wps=25436, ups=6.42, wpb=3964.6, bsz=171.4, num_updates=9500, lr=0.000324443, gnorm=0.77, train_wall=15, wall=0
2024-07-31 21:15:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:15:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.884 | nll_loss 6.919 | ppl 121.03 | wps 95139.9 | wpb 3529.1 | bsz 62.9 | num_updates 9500 | best_loss 7.883
2024-07-31 21:15:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:15:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_9500.pt (epoch 1 @ 9500 updates, score 7.884) (writing took 3.539788887836039 seconds)
2024-07-31 21:15:30 | INFO | train_inner | epoch 001:   9600 / 17024 loss=7.672, nll_loss=6.742, ppl=107.03, wps=18954.9, ups=4.77, wpb=3971.3, bsz=181.4, num_updates=9600, lr=0.000322749, gnorm=0.768, train_wall=16, wall=0
2024-07-31 21:15:45 | INFO | train_inner | epoch 001:   9700 / 17024 loss=7.665, nll_loss=6.735, ppl=106.49, wps=25874.9, ups=6.52, wpb=3967.8, bsz=186.8, num_updates=9700, lr=0.000321081, gnorm=0.766, train_wall=15, wall=0
2024-07-31 21:16:01 | INFO | train_inner | epoch 001:   9800 / 17024 loss=7.608, nll_loss=6.669, ppl=101.75, wps=25094.5, ups=6.32, wpb=3972.8, bsz=155.2, num_updates=9800, lr=0.000319438, gnorm=0.743, train_wall=16, wall=0
2024-07-31 21:16:16 | INFO | train_inner | epoch 001:   9900 / 17024 loss=7.608, nll_loss=6.669, ppl=101.73, wps=25549.3, ups=6.42, wpb=3982, bsz=165.8, num_updates=9900, lr=0.000317821, gnorm=0.739, train_wall=15, wall=0
2024-07-31 21:16:32 | INFO | train_inner | epoch 001:  10000 / 17024 loss=7.654, nll_loss=6.721, ppl=105.53, wps=25713.3, ups=6.5, wpb=3954.4, bsz=175.8, num_updates=10000, lr=0.000316228, gnorm=0.771, train_wall=15, wall=0
2024-07-31 21:16:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:16:33 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.85 | nll_loss 6.886 | ppl 118.25 | wps 92316.4 | wpb 3529.1 | bsz 62.9 | num_updates 10000 | best_loss 7.85
2024-07-31 21:16:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:16:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score 7.85) (writing took 6.550990914925933 seconds)
2024-07-31 21:16:40 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-31 21:16:40 | INFO | train | epoch 001 | loss 8.549 | nll_loss 7.754 | ppl 215.89 | wps 22542.8 | ups 5.69 | wpb 3961.8 | bsz 165.1 | num_updates 10000 | lr 0.000316228 | gnorm 0.865 | train_wall 1537 | wall 0
2024-07-31 21:16:40 | INFO | fairseq_cli.train | done training in 1533.6 seconds
2024-07-31 21:16:45 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt22.sep.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=100000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=1000, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-31 21:16:45 | INFO | fairseq.tasks.translation | [de] dictionary: 8 types
2024-07-31 21:16:45 | INFO | fairseq.tasks.translation | [en] dictionary: 9968 types
2024-07-31 21:16:45 | INFO | fairseq.data.data_utils | loaded 2203 examples from: data-bin/wmt22.sep.tokenized.de-en/valid.de-en.de
2024-07-31 21:16:45 | INFO | fairseq.data.data_utils | loaded 2203 examples from: data-bin/wmt22.sep.tokenized.de-en/valid.de-en.en
2024-07-31 21:16:45 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.de-en valid de-en 2203 examples
2024-07-31 21:16:45 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9968, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=9968, bias=False)
  )
)
2024-07-31 21:16:45 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-31 21:16:45 | INFO | fairseq_cli.train | model: transformer_iwslt_de_en (TransformerModel)
2024-07-31 21:16:45 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-31 21:16:45 | INFO | fairseq_cli.train | num. model params: 36651008 (num. trained: 36651008)
2024-07-31 21:16:54 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-31 21:16:54 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-31 21:16:54 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-31 21:16:54 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-31 21:16:54 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-31 21:16:54 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-31 21:16:55 | INFO | fairseq.trainer | loaded checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 10000 updates)
2024-07-31 21:16:55 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-31 21:16:55 | INFO | fairseq.data.data_utils | loaded 2782552 examples from: data-bin/wmt22.sep.tokenized.de-en/train.de-en.de
2024-07-31 21:16:55 | INFO | fairseq.data.data_utils | loaded 2782552 examples from: data-bin/wmt22.sep.tokenized.de-en/train.de-en.en
2024-07-31 21:16:55 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.de-en train de-en 2782552 examples
2024-07-31 21:16:58 | INFO | fairseq.trainer | begin training epoch 1
2024-07-31 21:17:15 | INFO | train_inner | epoch 001:  10100 / 17024 loss=7.6, nll_loss=6.659, ppl=101.04, wps=18756, ups=4.76, wpb=3941.2, bsz=141.4, num_updates=10100, lr=0.000314658, gnorm=0.742, train_wall=16, wall=0
2024-07-31 21:17:30 | INFO | train_inner | epoch 001:  10200 / 17024 loss=7.643, nll_loss=6.709, ppl=104.62, wps=25890.4, ups=6.54, wpb=3956.5, bsz=168.3, num_updates=10200, lr=0.000313112, gnorm=0.768, train_wall=15, wall=0
2024-07-31 21:17:46 | INFO | train_inner | epoch 001:  10300 / 17024 loss=7.587, nll_loss=6.644, ppl=100.03, wps=25814.3, ups=6.49, wpb=3975.2, bsz=165.8, num_updates=10300, lr=0.000311588, gnorm=0.759, train_wall=15, wall=0
2024-07-31 21:18:01 | INFO | train_inner | epoch 001:  10400 / 17024 loss=7.581, nll_loss=6.637, ppl=99.55, wps=25756.5, ups=6.53, wpb=3945.5, bsz=157.9, num_updates=10400, lr=0.000310087, gnorm=0.761, train_wall=15, wall=0
2024-07-31 21:18:16 | INFO | train_inner | epoch 001:  10500 / 17024 loss=7.653, nll_loss=6.721, ppl=105.46, wps=25576.2, ups=6.42, wpb=3983.1, bsz=179.4, num_updates=10500, lr=0.000308607, gnorm=0.785, train_wall=15, wall=0
2024-07-31 21:18:32 | INFO | train_inner | epoch 001:  10600 / 17024 loss=7.59, nll_loss=6.648, ppl=100.27, wps=24689.2, ups=6.25, wpb=3947.3, bsz=166.3, num_updates=10600, lr=0.000307148, gnorm=0.746, train_wall=16, wall=0
2024-07-31 21:18:48 | INFO | train_inner | epoch 001:  10700 / 17024 loss=7.596, nll_loss=6.656, ppl=100.83, wps=25381.2, ups=6.45, wpb=3934.6, bsz=155.8, num_updates=10700, lr=0.000305709, gnorm=0.776, train_wall=15, wall=0
2024-07-31 21:19:04 | INFO | train_inner | epoch 001:  10800 / 17024 loss=7.592, nll_loss=6.65, ppl=100.43, wps=24237.4, ups=6.1, wpb=3974.8, bsz=168.1, num_updates=10800, lr=0.00030429, gnorm=0.743, train_wall=16, wall=0
2024-07-31 21:19:20 | INFO | train_inner | epoch 001:  10900 / 17024 loss=7.572, nll_loss=6.626, ppl=98.79, wps=25837.8, ups=6.52, wpb=3964.3, bsz=166.2, num_updates=10900, lr=0.000302891, gnorm=0.756, train_wall=15, wall=0
2024-07-31 21:19:35 | INFO | train_inner | epoch 001:  11000 / 17024 loss=7.562, nll_loss=6.616, ppl=98.06, wps=25865.6, ups=6.56, wpb=3941.8, bsz=167.9, num_updates=11000, lr=0.000301511, gnorm=0.764, train_wall=15, wall=0
2024-07-31 21:19:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-31 21:19:36 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.836 | nll_loss 6.868 | ppl 116.83 | wps 94973.5 | wpb 3529.1 | bsz 62.9 | num_updates 11000 | best_loss 7.836
2024-07-31 21:19:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:19:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_11000.pt (epoch 1 @ 11000 updates, score 7.836) (writing took 6.895385331474245 seconds)
2024-07-31 21:19:59 | INFO | train_inner | epoch 001:  11100 / 17024 loss=7.556, nll_loss=6.609, ppl=97.63, wps=16802.6, ups=4.22, wpb=3983, bsz=160.3, num_updates=11100, lr=0.00030015, gnorm=0.756, train_wall=15, wall=0
2024-07-31 21:20:14 | INFO | train_inner | epoch 001:  11200 / 17024 loss=7.576, nll_loss=6.632, ppl=99.18, wps=25406.6, ups=6.43, wpb=3948.3, bsz=156.6, num_updates=11200, lr=0.000298807, gnorm=0.755, train_wall=15, wall=0
2024-07-31 21:20:30 | INFO | train_inner | epoch 001:  11300 / 17024 loss=7.579, nll_loss=6.636, ppl=99.45, wps=25681.7, ups=6.52, wpb=3939.6, bsz=165.8, num_updates=11300, lr=0.000297482, gnorm=0.78, train_wall=15, wall=0
2024-07-31 21:20:45 | INFO | train_inner | epoch 001:  11400 / 17024 loss=7.495, nll_loss=6.539, ppl=92.99, wps=25923.6, ups=6.54, wpb=3964.2, bsz=160.5, num_updates=11400, lr=0.000296174, gnorm=0.749, train_wall=15, wall=0
2024-07-31 21:21:00 | INFO | train_inner | epoch 001:  11500 / 17024 loss=7.511, nll_loss=6.557, ppl=94.16, wps=25767.2, ups=6.54, wpb=3937.3, bsz=139.2, num_updates=11500, lr=0.000294884, gnorm=0.751, train_wall=15, wall=0
2024-07-31 21:21:16 | INFO | train_inner | epoch 001:  11600 / 17024 loss=7.563, nll_loss=6.618, ppl=98.21, wps=25518.7, ups=6.42, wpb=3974.1, bsz=174, num_updates=11600, lr=0.00029361, gnorm=0.768, train_wall=15, wall=0
2024-07-31 21:21:31 | INFO | train_inner | epoch 001:  11700 / 17024 loss=7.538, nll_loss=6.588, ppl=96.18, wps=25223.6, ups=6.35, wpb=3972.2, bsz=171, num_updates=11700, lr=0.000292353, gnorm=0.762, train_wall=16, wall=0
2024-07-31 21:21:47 | INFO | train_inner | epoch 001:  11800 / 17024 loss=7.537, nll_loss=6.588, ppl=96.17, wps=26178.2, ups=6.59, wpb=3969.7, bsz=172.8, num_updates=11800, lr=0.000291111, gnorm=0.763, train_wall=15, wall=0
2024-07-31 21:22:02 | INFO | train_inner | epoch 001:  11900 / 17024 loss=7.5, nll_loss=6.544, ppl=93.28, wps=25614, ups=6.52, wpb=3926.6, bsz=140.4, num_updates=11900, lr=0.000289886, gnorm=0.764, train_wall=15, wall=0
2024-07-31 21:22:17 | INFO | train_inner | epoch 001:  12000 / 17024 loss=7.561, nll_loss=6.616, ppl=98.07, wps=25731.9, ups=6.47, wpb=3976, bsz=183.3, num_updates=12000, lr=0.000288675, gnorm=0.797, train_wall=15, wall=0
2024-07-31 21:22:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:22:19 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.752 | nll_loss 6.769 | ppl 109.04 | wps 97167.6 | wpb 3529.1 | bsz 62.9 | num_updates 12000 | best_loss 7.752
2024-07-31 21:22:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:22:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_12000.pt (epoch 1 @ 12000 updates, score 7.752) (writing took 6.391375488601625 seconds)
2024-07-31 21:22:41 | INFO | train_inner | epoch 001:  12100 / 17024 loss=7.51, nll_loss=6.556, ppl=94.12, wps=16887.8, ups=4.25, wpb=3969.7, bsz=152.8, num_updates=12100, lr=0.00028748, gnorm=0.755, train_wall=15, wall=0
2024-07-31 21:22:57 | INFO | train_inner | epoch 001:  12200 / 17024 loss=7.518, nll_loss=6.565, ppl=94.7, wps=25163, ups=6.35, wpb=3961.6, bsz=164.2, num_updates=12200, lr=0.000286299, gnorm=0.768, train_wall=16, wall=0
2024-07-31 21:23:12 | INFO | train_inner | epoch 001:  12300 / 17024 loss=7.525, nll_loss=6.573, ppl=95.23, wps=25796.4, ups=6.55, wpb=3936.6, bsz=159, num_updates=12300, lr=0.000285133, gnorm=0.776, train_wall=15, wall=0
2024-07-31 21:23:27 | INFO | train_inner | epoch 001:  12400 / 17024 loss=7.502, nll_loss=6.548, ppl=93.56, wps=25782.6, ups=6.5, wpb=3964.3, bsz=157.3, num_updates=12400, lr=0.000283981, gnorm=0.761, train_wall=15, wall=0
2024-07-31 21:23:43 | INFO | train_inner | epoch 001:  12500 / 17024 loss=7.48, nll_loss=6.522, ppl=91.91, wps=25748.6, ups=6.48, wpb=3972.2, bsz=174.1, num_updates=12500, lr=0.000282843, gnorm=0.773, train_wall=15, wall=0
2024-07-31 21:23:58 | INFO | train_inner | epoch 001:  12600 / 17024 loss=7.51, nll_loss=6.556, ppl=94.09, wps=25580.5, ups=6.49, wpb=3940.1, bsz=150.2, num_updates=12600, lr=0.000281718, gnorm=0.78, train_wall=15, wall=0
2024-07-31 21:24:14 | INFO | train_inner | epoch 001:  12700 / 17024 loss=7.55, nll_loss=6.603, ppl=97.18, wps=25655, ups=6.47, wpb=3965.9, bsz=176.2, num_updates=12700, lr=0.000280607, gnorm=0.795, train_wall=15, wall=0
2024-07-31 21:24:29 | INFO | train_inner | epoch 001:  12800 / 17024 loss=7.489, nll_loss=6.532, ppl=92.52, wps=25608, ups=6.47, wpb=3956.2, bsz=161.1, num_updates=12800, lr=0.000279508, gnorm=0.772, train_wall=15, wall=0
2024-07-31 21:24:45 | INFO | train_inner | epoch 001:  12900 / 17024 loss=7.489, nll_loss=6.532, ppl=92.54, wps=25282.8, ups=6.39, wpb=3955.7, bsz=168.2, num_updates=12900, lr=0.000278423, gnorm=0.77, train_wall=15, wall=0
2024-07-31 21:25:00 | INFO | train_inner | epoch 001:  13000 / 17024 loss=7.491, nll_loss=6.534, ppl=92.7, wps=25241.7, ups=6.38, wpb=3955.8, bsz=158.5, num_updates=13000, lr=0.00027735, gnorm=0.768, train_wall=15, wall=0
2024-07-31 21:25:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:25:02 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.755 | nll_loss 6.768 | ppl 108.97 | wps 92717.1 | wpb 3529.1 | bsz 62.9 | num_updates 13000 | best_loss 7.752
2024-07-31 21:25:02 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:25:05 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_13000.pt (epoch 1 @ 13000 updates, score 7.755) (writing took 3.344394078478217 seconds)
2024-07-31 21:25:21 | INFO | train_inner | epoch 001:  13100 / 17024 loss=7.467, nll_loss=6.507, ppl=90.92, wps=19390.2, ups=4.91, wpb=3949.2, bsz=135, num_updates=13100, lr=0.000276289, gnorm=0.769, train_wall=15, wall=0
2024-07-31 21:25:36 | INFO | train_inner | epoch 001:  13200 / 17024 loss=7.508, nll_loss=6.554, ppl=93.94, wps=25710.8, ups=6.44, wpb=3989.7, bsz=185.5, num_updates=13200, lr=0.000275241, gnorm=0.774, train_wall=15, wall=0
2024-07-31 21:25:52 | INFO | train_inner | epoch 001:  13300 / 17024 loss=7.494, nll_loss=6.538, ppl=92.92, wps=25590.6, ups=6.48, wpb=3947.8, bsz=152.2, num_updates=13300, lr=0.000274204, gnorm=0.77, train_wall=15, wall=0
2024-07-31 21:26:07 | INFO | train_inner | epoch 001:  13400 / 17024 loss=7.423, nll_loss=6.456, ppl=87.81, wps=25549, ups=6.46, wpb=3952.7, bsz=148.2, num_updates=13400, lr=0.000273179, gnorm=0.768, train_wall=15, wall=0
2024-07-31 21:26:23 | INFO | train_inner | epoch 001:  13500 / 17024 loss=7.464, nll_loss=6.504, ppl=90.74, wps=25666.8, ups=6.5, wpb=3949.1, bsz=166.1, num_updates=13500, lr=0.000272166, gnorm=0.768, train_wall=15, wall=0
2024-07-31 21:26:38 | INFO | train_inner | epoch 001:  13600 / 17024 loss=7.393, nll_loss=6.422, ppl=85.73, wps=25782.3, ups=6.54, wpb=3943.9, bsz=136.8, num_updates=13600, lr=0.000271163, gnorm=0.751, train_wall=15, wall=0
2024-07-31 21:26:53 | INFO | train_inner | epoch 001:  13700 / 17024 loss=7.489, nll_loss=6.532, ppl=92.56, wps=25700.3, ups=6.49, wpb=3961.8, bsz=165.7, num_updates=13700, lr=0.000270172, gnorm=0.805, train_wall=15, wall=0
2024-07-31 21:27:09 | INFO | train_inner | epoch 001:  13800 / 17024 loss=7.496, nll_loss=6.54, ppl=93.05, wps=25625.8, ups=6.47, wpb=3960.7, bsz=169.4, num_updates=13800, lr=0.000269191, gnorm=0.765, train_wall=15, wall=0
2024-07-31 21:27:24 | INFO | train_inner | epoch 001:  13900 / 17024 loss=7.426, nll_loss=6.46, ppl=88.03, wps=25755, ups=6.48, wpb=3971.8, bsz=157.4, num_updates=13900, lr=0.000268221, gnorm=0.769, train_wall=15, wall=0
2024-07-31 21:27:39 | INFO | train_inner | epoch 001:  14000 / 17024 loss=7.495, nll_loss=6.539, ppl=92.99, wps=25766, ups=6.51, wpb=3956.8, bsz=170.1, num_updates=14000, lr=0.000267261, gnorm=0.793, train_wall=15, wall=0
2024-07-31 21:27:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:27:41 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.674 | nll_loss 6.682 | ppl 102.65 | wps 97299.2 | wpb 3529.1 | bsz 62.9 | num_updates 14000 | best_loss 7.674
2024-07-31 21:27:41 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:27:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_14000.pt (epoch 1 @ 14000 updates, score 7.674) (writing took 5.511144729331136 seconds)
2024-07-31 21:28:02 | INFO | train_inner | epoch 001:  14100 / 17024 loss=7.461, nll_loss=6.501, ppl=90.57, wps=17709.2, ups=4.43, wpb=3994.3, bsz=166.3, num_updates=14100, lr=0.000266312, gnorm=0.764, train_wall=15, wall=0
2024-07-31 21:28:17 | INFO | train_inner | epoch 001:  14200 / 17024 loss=7.469, nll_loss=6.509, ppl=91.08, wps=25616.6, ups=6.47, wpb=3960.4, bsz=164.3, num_updates=14200, lr=0.000265372, gnorm=0.781, train_wall=15, wall=0
2024-07-31 21:28:33 | INFO | train_inner | epoch 001:  14300 / 17024 loss=7.47, nll_loss=6.511, ppl=91.18, wps=25537, ups=6.48, wpb=3938, bsz=162.9, num_updates=14300, lr=0.000264443, gnorm=0.799, train_wall=15, wall=0
2024-07-31 21:28:48 | INFO | train_inner | epoch 001:  14400 / 17024 loss=7.457, nll_loss=6.495, ppl=90.22, wps=25547.7, ups=6.42, wpb=3976.3, bsz=159.8, num_updates=14400, lr=0.000263523, gnorm=0.783, train_wall=15, wall=0
2024-07-31 21:29:04 | INFO | train_inner | epoch 001:  14500 / 17024 loss=7.433, nll_loss=6.467, ppl=88.47, wps=25571.3, ups=6.49, wpb=3942.1, bsz=149.8, num_updates=14500, lr=0.000262613, gnorm=0.767, train_wall=15, wall=0
2024-07-31 21:29:19 | INFO | train_inner | epoch 001:  14600 / 17024 loss=7.451, nll_loss=6.489, ppl=89.83, wps=25733.3, ups=6.46, wpb=3982.5, bsz=176.1, num_updates=14600, lr=0.000261712, gnorm=0.787, train_wall=15, wall=0
2024-07-31 21:29:35 | INFO | train_inner | epoch 001:  14700 / 17024 loss=7.421, nll_loss=6.452, ppl=87.56, wps=25607.3, ups=6.52, wpb=3929.5, bsz=137.7, num_updates=14700, lr=0.00026082, gnorm=0.785, train_wall=15, wall=0
2024-07-31 21:29:50 | INFO | train_inner | epoch 001:  14800 / 17024 loss=7.41, nll_loss=6.442, ppl=86.96, wps=25860.4, ups=6.51, wpb=3975.2, bsz=160.9, num_updates=14800, lr=0.000259938, gnorm=0.766, train_wall=15, wall=0
2024-07-31 21:30:05 | INFO | train_inner | epoch 001:  14900 / 17024 loss=7.433, nll_loss=6.467, ppl=88.49, wps=25603.6, ups=6.48, wpb=3948.2, bsz=154.7, num_updates=14900, lr=0.000259064, gnorm=0.786, train_wall=15, wall=0
2024-07-31 21:30:21 | INFO | train_inner | epoch 001:  15000 / 17024 loss=7.435, nll_loss=6.47, ppl=88.64, wps=25656.6, ups=6.45, wpb=3975.9, bsz=163.8, num_updates=15000, lr=0.000258199, gnorm=0.789, train_wall=15, wall=0
2024-07-31 21:30:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:30:22 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.674 | nll_loss 6.681 | ppl 102.6 | wps 94792.1 | wpb 3529.1 | bsz 62.9 | num_updates 15000 | best_loss 7.674
2024-07-31 21:30:22 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:30:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_15000.pt (epoch 1 @ 15000 updates, score 7.674) (writing took 5.581830286420882 seconds)
2024-07-31 21:30:43 | INFO | train_inner | epoch 001:  15100 / 17024 loss=7.395, nll_loss=6.424, ppl=85.84, wps=17651.4, ups=4.46, wpb=3961.6, bsz=148.3, num_updates=15100, lr=0.000257343, gnorm=0.768, train_wall=15, wall=0
2024-07-31 21:30:59 | INFO | train_inner | epoch 001:  15200 / 17024 loss=7.382, nll_loss=6.408, ppl=84.93, wps=25644.1, ups=6.48, wpb=3954.8, bsz=150.3, num_updates=15200, lr=0.000256495, gnorm=0.779, train_wall=15, wall=0
2024-07-31 21:31:14 | INFO | train_inner | epoch 001:  15300 / 17024 loss=7.435, nll_loss=6.471, ppl=88.69, wps=25825.1, ups=6.5, wpb=3973, bsz=165.4, num_updates=15300, lr=0.000255655, gnorm=0.776, train_wall=15, wall=0
2024-07-31 21:31:30 | INFO | train_inner | epoch 001:  15400 / 17024 loss=7.417, nll_loss=6.451, ppl=87.46, wps=25646.2, ups=6.47, wpb=3964.6, bsz=165.6, num_updates=15400, lr=0.000254824, gnorm=0.784, train_wall=15, wall=0
2024-07-31 21:31:45 | INFO | train_inner | epoch 001:  15500 / 17024 loss=7.443, nll_loss=6.479, ppl=89.22, wps=25749.9, ups=6.46, wpb=3983, bsz=178.9, num_updates=15500, lr=0.000254, gnorm=0.781, train_wall=15, wall=0
2024-07-31 21:32:01 | INFO | train_inner | epoch 001:  15600 / 17024 loss=7.454, nll_loss=6.493, ppl=90.06, wps=25702.7, ups=6.49, wpb=3957.9, bsz=173.4, num_updates=15600, lr=0.000253185, gnorm=0.781, train_wall=15, wall=0
2024-07-31 21:32:16 | INFO | train_inner | epoch 001:  15700 / 17024 loss=7.403, nll_loss=6.433, ppl=86.38, wps=25493.2, ups=6.47, wpb=3941.4, bsz=151.4, num_updates=15700, lr=0.000252377, gnorm=0.776, train_wall=15, wall=0
2024-07-31 21:32:32 | INFO | train_inner | epoch 001:  15800 / 17024 loss=7.41, nll_loss=6.441, ppl=86.89, wps=25663.4, ups=6.46, wpb=3972.6, bsz=170.2, num_updates=15800, lr=0.000251577, gnorm=0.82, train_wall=15, wall=0
2024-07-31 21:32:47 | INFO | train_inner | epoch 001:  15900 / 17024 loss=7.404, nll_loss=6.436, ppl=86.57, wps=25709.2, ups=6.47, wpb=3974.9, bsz=169.4, num_updates=15900, lr=0.000250785, gnorm=0.767, train_wall=15, wall=0
2024-07-31 21:33:02 | INFO | train_inner | epoch 001:  16000 / 17024 loss=7.375, nll_loss=6.401, ppl=84.52, wps=25747.5, ups=6.52, wpb=3949.6, bsz=149, num_updates=16000, lr=0.00025, gnorm=0.775, train_wall=15, wall=0
2024-07-31 21:33:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:33:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.624 | nll_loss 6.622 | ppl 98.51 | wps 96855.6 | wpb 3529.1 | bsz 62.9 | num_updates 16000 | best_loss 7.624
2024-07-31 21:33:04 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:33:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_16000.pt (epoch 1 @ 16000 updates, score 7.624) (writing took 4.631009194068611 seconds)
2024-07-31 21:33:24 | INFO | train_inner | epoch 001:  16100 / 17024 loss=7.41, nll_loss=6.441, ppl=86.88, wps=18484.2, ups=4.68, wpb=3950.2, bsz=159.2, num_updates=16100, lr=0.000249222, gnorm=0.785, train_wall=15, wall=0
2024-07-31 21:33:39 | INFO | train_inner | epoch 001:  16200 / 17024 loss=7.358, nll_loss=6.381, ppl=83.33, wps=25606.5, ups=6.49, wpb=3944.8, bsz=134.6, num_updates=16200, lr=0.000248452, gnorm=0.773, train_wall=15, wall=0
2024-07-31 21:33:54 | INFO | train_inner | epoch 001:  16300 / 17024 loss=7.457, nll_loss=6.497, ppl=90.3, wps=25755.1, ups=6.49, wpb=3965.5, bsz=187.7, num_updates=16300, lr=0.000247689, gnorm=0.836, train_wall=15, wall=0
2024-07-31 21:34:10 | INFO | train_inner | epoch 001:  16400 / 17024 loss=7.373, nll_loss=6.399, ppl=84.42, wps=25684.6, ups=6.48, wpb=3961.8, bsz=153.4, num_updates=16400, lr=0.000246932, gnorm=0.77, train_wall=15, wall=0
2024-07-31 21:34:25 | INFO | train_inner | epoch 001:  16500 / 17024 loss=7.403, nll_loss=6.434, ppl=86.46, wps=25640.8, ups=6.48, wpb=3958.5, bsz=167.6, num_updates=16500, lr=0.000246183, gnorm=0.782, train_wall=15, wall=0
2024-07-31 21:34:41 | INFO | train_inner | epoch 001:  16600 / 17024 loss=7.352, nll_loss=6.374, ppl=82.95, wps=25879, ups=6.53, wpb=3965.6, bsz=141.5, num_updates=16600, lr=0.00024544, gnorm=0.779, train_wall=15, wall=0
2024-07-31 21:34:56 | INFO | train_inner | epoch 001:  16700 / 17024 loss=7.377, nll_loss=6.404, ppl=84.66, wps=25702.7, ups=6.5, wpb=3952.7, bsz=154.5, num_updates=16700, lr=0.000244704, gnorm=0.804, train_wall=15, wall=0
2024-07-31 21:35:12 | INFO | train_inner | epoch 001:  16800 / 17024 loss=7.419, nll_loss=6.453, ppl=87.58, wps=25631.6, ups=6.47, wpb=3964.2, bsz=187.4, num_updates=16800, lr=0.000243975, gnorm=0.804, train_wall=15, wall=0
2024-07-31 21:35:27 | INFO | train_inner | epoch 001:  16900 / 17024 loss=7.376, nll_loss=6.402, ppl=84.57, wps=25771.6, ups=6.49, wpb=3973.9, bsz=158.7, num_updates=16900, lr=0.000243252, gnorm=0.794, train_wall=15, wall=0
2024-07-31 21:35:42 | INFO | train_inner | epoch 001:  17000 / 17024 loss=7.357, nll_loss=6.38, ppl=83.26, wps=25635, ups=6.51, wpb=3936.1, bsz=152.2, num_updates=17000, lr=0.000242536, gnorm=0.798, train_wall=15, wall=0
2024-07-31 21:35:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:35:44 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.639 | nll_loss 6.643 | ppl 99.92 | wps 97157.7 | wpb 3529.1 | bsz 62.9 | num_updates 17000 | best_loss 7.624
2024-07-31 21:35:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:35:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_17000.pt (epoch 1 @ 17000 updates, score 7.639) (writing took 3.0771091682836413 seconds)
2024-07-31 21:35:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:35:52 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.618 | nll_loss 6.618 | ppl 98.25 | wps 95568.5 | wpb 3529.1 | bsz 62.9 | num_updates 17024 | best_loss 7.618
2024-07-31 21:35:52 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:35:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_best.pt (epoch 1 @ 17024 updates, score 7.618) (writing took 5.295783108100295 seconds)
2024-07-31 21:35:57 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-31 21:35:57 | INFO | train | epoch 001 | loss 8.108 | nll_loss 7.245 | ppl 151.73 | wps 23308.9 | ups 5.89 | wpb 3960.7 | bsz 163.4 | num_updates 17024 | lr 0.000242365 | gnorm 0.828 | train_wall 2610 | wall 0
2024-07-31 21:35:57 | INFO | fairseq.trainer | begin training epoch 2
2024-07-31 21:36:09 | INFO | train_inner | epoch 002:     76 / 17024 loss=7.377, nll_loss=6.404, ppl=84.71, wps=14635.7, ups=3.69, wpb=3966.6, bsz=164.6, num_updates=17100, lr=0.000241825, gnorm=0.794, train_wall=15, wall=0
2024-07-31 21:36:25 | INFO | train_inner | epoch 002:    176 / 17024 loss=7.407, nll_loss=6.439, ppl=86.75, wps=25743.2, ups=6.47, wpb=3981.6, bsz=179, num_updates=17200, lr=0.000241121, gnorm=0.806, train_wall=15, wall=0
2024-07-31 21:36:40 | INFO | train_inner | epoch 002:    276 / 17024 loss=7.381, nll_loss=6.407, ppl=84.89, wps=25712.4, ups=6.51, wpb=3949.5, bsz=152.2, num_updates=17300, lr=0.000240424, gnorm=0.801, train_wall=15, wall=0
2024-07-31 21:36:56 | INFO | train_inner | epoch 002:    376 / 17024 loss=7.371, nll_loss=6.398, ppl=84.31, wps=25630.6, ups=6.46, wpb=3968.9, bsz=175, num_updates=17400, lr=0.000239732, gnorm=0.782, train_wall=15, wall=0
2024-07-31 21:37:11 | INFO | train_inner | epoch 002:    476 / 17024 loss=7.36, nll_loss=6.384, ppl=83.49, wps=25809.3, ups=6.52, wpb=3956.9, bsz=168.2, num_updates=17500, lr=0.000239046, gnorm=0.82, train_wall=15, wall=0
2024-07-31 21:37:26 | INFO | train_inner | epoch 002:    576 / 17024 loss=7.363, nll_loss=6.387, ppl=83.69, wps=25816.1, ups=6.5, wpb=3972.4, bsz=170, num_updates=17600, lr=0.000238366, gnorm=0.791, train_wall=15, wall=0
2024-07-31 21:37:42 | INFO | train_inner | epoch 002:    676 / 17024 loss=7.333, nll_loss=6.352, ppl=81.7, wps=25716.4, ups=6.48, wpb=3968.6, bsz=165.4, num_updates=17700, lr=0.000237691, gnorm=0.793, train_wall=15, wall=0
2024-07-31 21:37:57 | INFO | train_inner | epoch 002:    776 / 17024 loss=7.392, nll_loss=6.421, ppl=85.67, wps=25684.2, ups=6.46, wpb=3976.7, bsz=174.1, num_updates=17800, lr=0.000237023, gnorm=0.799, train_wall=15, wall=0
2024-07-31 21:38:13 | INFO | train_inner | epoch 002:    876 / 17024 loss=7.354, nll_loss=6.377, ppl=83.14, wps=25659.6, ups=6.51, wpb=3941.8, bsz=172.6, num_updates=17900, lr=0.00023636, gnorm=0.797, train_wall=15, wall=0
2024-07-31 21:38:28 | INFO | train_inner | epoch 002:    976 / 17024 loss=7.341, nll_loss=6.362, ppl=82.24, wps=25681.2, ups=6.51, wpb=3943.1, bsz=152.9, num_updates=18000, lr=0.000235702, gnorm=0.789, train_wall=15, wall=0
2024-07-31 21:38:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:38:29 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.6 | nll_loss 6.595 | ppl 96.7 | wps 96405.3 | wpb 3529.1 | bsz 62.9 | num_updates 18000 | best_loss 7.6
2024-07-31 21:38:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:38:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_18000.pt (epoch 2 @ 18000 updates, score 7.6) (writing took 5.941872810944915 seconds)
2024-07-31 21:38:51 | INFO | train_inner | epoch 002:   1076 / 17024 loss=7.324, nll_loss=6.341, ppl=81.05, wps=17309.8, ups=4.4, wpb=3931.3, bsz=141.7, num_updates=18100, lr=0.00023505, gnorm=0.797, train_wall=15, wall=0
2024-07-31 21:39:06 | INFO | train_inner | epoch 002:   1176 / 17024 loss=7.371, nll_loss=6.396, ppl=84.21, wps=25534, ups=6.48, wpb=3941.6, bsz=167.4, num_updates=18200, lr=0.000234404, gnorm=0.838, train_wall=15, wall=0
2024-07-31 21:39:22 | INFO | train_inner | epoch 002:   1276 / 17024 loss=7.388, nll_loss=6.416, ppl=85.42, wps=25560.1, ups=6.5, wpb=3934.4, bsz=174.4, num_updates=18300, lr=0.000233762, gnorm=0.813, train_wall=15, wall=0
2024-07-31 21:39:37 | INFO | train_inner | epoch 002:   1376 / 17024 loss=7.333, nll_loss=6.353, ppl=81.75, wps=25665.7, ups=6.49, wpb=3951.7, bsz=161.4, num_updates=18400, lr=0.000233126, gnorm=0.792, train_wall=15, wall=0
2024-07-31 21:39:52 | INFO | train_inner | epoch 002:   1476 / 17024 loss=7.314, nll_loss=6.331, ppl=80.48, wps=25727.6, ups=6.54, wpb=3931.7, bsz=149.8, num_updates=18500, lr=0.000232495, gnorm=0.816, train_wall=15, wall=0
2024-07-31 21:40:08 | INFO | train_inner | epoch 002:   1576 / 17024 loss=7.356, nll_loss=6.38, ppl=83.28, wps=25595.5, ups=6.5, wpb=3937.3, bsz=163, num_updates=18600, lr=0.000231869, gnorm=0.802, train_wall=15, wall=0
2024-07-31 21:40:23 | INFO | train_inner | epoch 002:   1676 / 17024 loss=7.311, nll_loss=6.327, ppl=80.26, wps=25662.8, ups=6.53, wpb=3930.5, bsz=142, num_updates=18700, lr=0.000231249, gnorm=0.786, train_wall=15, wall=0
2024-07-31 21:40:39 | INFO | train_inner | epoch 002:   1776 / 17024 loss=7.354, nll_loss=6.376, ppl=83.07, wps=25585.4, ups=6.44, wpb=3974.4, bsz=178.6, num_updates=18800, lr=0.000230633, gnorm=0.835, train_wall=15, wall=0
2024-07-31 21:40:54 | INFO | train_inner | epoch 002:   1876 / 17024 loss=7.33, nll_loss=6.35, ppl=81.56, wps=25692.2, ups=6.5, wpb=3955.4, bsz=161, num_updates=18900, lr=0.000230022, gnorm=0.81, train_wall=15, wall=0
2024-07-31 21:41:09 | INFO | train_inner | epoch 002:   1976 / 17024 loss=7.36, nll_loss=6.384, ppl=83.49, wps=25689.8, ups=6.53, wpb=3931.2, bsz=169.1, num_updates=19000, lr=0.000229416, gnorm=0.811, train_wall=15, wall=0
2024-07-31 21:41:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:41:11 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.623 | nll_loss 6.616 | ppl 98.09 | wps 96659.1 | wpb 3529.1 | bsz 62.9 | num_updates 19000 | best_loss 7.6
2024-07-31 21:41:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:41:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_19000.pt (epoch 2 @ 19000 updates, score 7.623) (writing took 3.3276173463091254 seconds)
2024-07-31 21:41:29 | INFO | train_inner | epoch 002:   2076 / 17024 loss=7.36, nll_loss=6.384, ppl=83.54, wps=19740.9, ups=4.95, wpb=3989.5, bsz=179.3, num_updates=19100, lr=0.000228814, gnorm=0.816, train_wall=15, wall=0
2024-07-31 21:41:45 | INFO | train_inner | epoch 002:   2176 / 17024 loss=7.312, nll_loss=6.329, ppl=80.4, wps=26067.6, ups=6.52, wpb=3996.9, bsz=176.8, num_updates=19200, lr=0.000228218, gnorm=0.773, train_wall=15, wall=0
2024-07-31 21:42:00 | INFO | train_inner | epoch 002:   2276 / 17024 loss=7.282, nll_loss=6.293, ppl=78.41, wps=25725.7, ups=6.52, wpb=3946.8, bsz=144, num_updates=19300, lr=0.000227626, gnorm=0.804, train_wall=15, wall=0
2024-07-31 21:42:15 | INFO | train_inner | epoch 002:   2376 / 17024 loss=7.328, nll_loss=6.347, ppl=81.42, wps=25844.4, ups=6.54, wpb=3952, bsz=168.7, num_updates=19400, lr=0.000227038, gnorm=0.801, train_wall=15, wall=0
2024-07-31 21:42:31 | INFO | train_inner | epoch 002:   2476 / 17024 loss=7.366, nll_loss=6.391, ppl=83.9, wps=25823.1, ups=6.53, wpb=3956.4, bsz=176, num_updates=19500, lr=0.000226455, gnorm=0.831, train_wall=15, wall=0
2024-07-31 21:42:46 | INFO | train_inner | epoch 002:   2576 / 17024 loss=7.258, nll_loss=6.266, ppl=76.97, wps=25780.3, ups=6.53, wpb=3946.9, bsz=141.9, num_updates=19600, lr=0.000225877, gnorm=0.78, train_wall=15, wall=0
2024-07-31 21:43:01 | INFO | train_inner | epoch 002:   2676 / 17024 loss=7.316, nll_loss=6.332, ppl=80.57, wps=25658.6, ups=6.48, wpb=3958.2, bsz=157.2, num_updates=19700, lr=0.000225303, gnorm=0.81, train_wall=15, wall=0
2024-07-31 21:43:17 | INFO | train_inner | epoch 002:   2776 / 17024 loss=7.337, nll_loss=6.358, ppl=82.01, wps=25623.3, ups=6.5, wpb=3942.8, bsz=159.5, num_updates=19800, lr=0.000224733, gnorm=0.806, train_wall=15, wall=0
2024-07-31 21:43:32 | INFO | train_inner | epoch 002:   2876 / 17024 loss=7.291, nll_loss=6.305, ppl=79.06, wps=25712, ups=6.49, wpb=3962.3, bsz=147.3, num_updates=19900, lr=0.000224168, gnorm=0.793, train_wall=15, wall=0
2024-07-31 21:43:48 | INFO | train_inner | epoch 002:   2976 / 17024 loss=7.307, nll_loss=6.322, ppl=80.01, wps=25711.8, ups=6.51, wpb=3949.3, bsz=150.4, num_updates=20000, lr=0.000223607, gnorm=0.814, train_wall=15, wall=0
2024-07-31 21:43:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:43:49 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.571 | nll_loss 6.561 | ppl 94.45 | wps 95582.7 | wpb 3529.1 | bsz 62.9 | num_updates 20000 | best_loss 7.571
2024-07-31 21:43:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:43:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_20000.pt (epoch 2 @ 20000 updates, score 7.571) (writing took 6.5766294887289405 seconds)
2024-07-31 21:44:11 | INFO | train_inner | epoch 002:   3076 / 17024 loss=7.286, nll_loss=6.299, ppl=78.74, wps=16954.3, ups=4.26, wpb=3981.2, bsz=160.8, num_updates=20100, lr=0.00022305, gnorm=0.796, train_wall=15, wall=0
2024-07-31 21:44:27 | INFO | train_inner | epoch 002:   3176 / 17024 loss=7.332, nll_loss=6.352, ppl=81.68, wps=25578.7, ups=6.47, wpb=3953.7, bsz=178.5, num_updates=20200, lr=0.000222497, gnorm=0.832, train_wall=15, wall=0
2024-07-31 21:44:42 | INFO | train_inner | epoch 002:   3276 / 17024 loss=7.356, nll_loss=6.379, ppl=83.26, wps=25717.5, ups=6.51, wpb=3951.2, bsz=174.5, num_updates=20300, lr=0.000221948, gnorm=0.846, train_wall=15, wall=0
2024-07-31 21:44:57 | INFO | train_inner | epoch 002:   3376 / 17024 loss=7.34, nll_loss=6.361, ppl=82.19, wps=25675.4, ups=6.46, wpb=3972.7, bsz=175, num_updates=20400, lr=0.000221404, gnorm=0.821, train_wall=15, wall=0
2024-07-31 21:45:13 | INFO | train_inner | epoch 002:   3476 / 17024 loss=7.319, nll_loss=6.337, ppl=80.82, wps=25722.8, ups=6.46, wpb=3980.2, bsz=175.4, num_updates=20500, lr=0.000220863, gnorm=0.806, train_wall=15, wall=0
2024-07-31 21:45:28 | INFO | train_inner | epoch 002:   3576 / 17024 loss=7.349, nll_loss=6.371, ppl=82.79, wps=25748.8, ups=6.44, wpb=3995.8, bsz=184.1, num_updates=20600, lr=0.000220326, gnorm=0.827, train_wall=15, wall=0
2024-07-31 21:45:44 | INFO | train_inner | epoch 002:   3676 / 17024 loss=7.297, nll_loss=6.311, ppl=79.41, wps=25773.8, ups=6.47, wpb=3982.9, bsz=159.3, num_updates=20700, lr=0.000219793, gnorm=0.795, train_wall=15, wall=0
2024-07-31 21:45:59 | INFO | train_inner | epoch 002:   3776 / 17024 loss=7.29, nll_loss=6.303, ppl=78.97, wps=25740.1, ups=6.5, wpb=3957.2, bsz=151.2, num_updates=20800, lr=0.000219265, gnorm=0.793, train_wall=15, wall=0
2024-07-31 21:46:15 | INFO | train_inner | epoch 002:   3876 / 17024 loss=7.258, nll_loss=6.266, ppl=76.97, wps=25622.2, ups=6.46, wpb=3966.9, bsz=149.9, num_updates=20900, lr=0.000218739, gnorm=0.786, train_wall=15, wall=0
2024-07-31 21:46:30 | INFO | train_inner | epoch 002:   3976 / 17024 loss=7.362, nll_loss=6.386, ppl=83.65, wps=25764.1, ups=6.48, wpb=3976.5, bsz=186, num_updates=21000, lr=0.000218218, gnorm=0.863, train_wall=15, wall=0
2024-07-31 21:46:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:46:32 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.564 | nll_loss 6.551 | ppl 93.74 | wps 95955.7 | wpb 3529.1 | bsz 62.9 | num_updates 21000 | best_loss 7.564
2024-07-31 21:46:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:46:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_21000.pt (epoch 2 @ 21000 updates, score 7.564) (writing took 7.426228864118457 seconds)
2024-07-31 21:46:54 | INFO | train_inner | epoch 002:   4076 / 17024 loss=7.297, nll_loss=6.311, ppl=79.41, wps=16376.2, ups=4.13, wpb=3967, bsz=161.4, num_updates=21100, lr=0.0002177, gnorm=0.801, train_wall=15, wall=0
2024-07-31 21:47:10 | INFO | train_inner | epoch 002:   4176 / 17024 loss=7.348, nll_loss=6.37, ppl=82.7, wps=25850.1, ups=6.5, wpb=3973.9, bsz=176, num_updates=21200, lr=0.000217186, gnorm=0.823, train_wall=15, wall=0
2024-07-31 21:47:25 | INFO | train_inner | epoch 002:   4276 / 17024 loss=7.301, nll_loss=6.315, ppl=79.62, wps=25582.6, ups=6.45, wpb=3966.3, bsz=154.9, num_updates=21300, lr=0.000216676, gnorm=0.813, train_wall=15, wall=0
2024-07-31 21:47:41 | INFO | train_inner | epoch 002:   4376 / 17024 loss=7.281, nll_loss=6.292, ppl=78.38, wps=25632.5, ups=6.47, wpb=3962.6, bsz=155.3, num_updates=21400, lr=0.000216169, gnorm=0.816, train_wall=15, wall=0
2024-07-31 21:47:56 | INFO | train_inner | epoch 002:   4476 / 17024 loss=7.256, nll_loss=6.265, ppl=76.89, wps=25595, ups=6.46, wpb=3959.4, bsz=152.2, num_updates=21500, lr=0.000215666, gnorm=0.793, train_wall=15, wall=0
2024-07-31 21:48:12 | INFO | train_inner | epoch 002:   4576 / 17024 loss=7.286, nll_loss=6.299, ppl=78.74, wps=25731.1, ups=6.48, wpb=3969.3, bsz=155.6, num_updates=21600, lr=0.000215166, gnorm=0.807, train_wall=15, wall=0
2024-07-31 21:48:27 | INFO | train_inner | epoch 002:   4676 / 17024 loss=7.282, nll_loss=6.295, ppl=78.51, wps=25721.4, ups=6.48, wpb=3967.1, bsz=162.1, num_updates=21700, lr=0.000214669, gnorm=0.83, train_wall=15, wall=0
2024-07-31 21:48:42 | INFO | train_inner | epoch 002:   4776 / 17024 loss=7.323, nll_loss=6.341, ppl=81.09, wps=25595.6, ups=6.47, wpb=3956.2, bsz=175.8, num_updates=21800, lr=0.000214176, gnorm=0.818, train_wall=15, wall=0
2024-07-31 21:48:58 | INFO | train_inner | epoch 002:   4876 / 17024 loss=7.297, nll_loss=6.311, ppl=79.4, wps=25602.9, ups=6.44, wpb=3978.5, bsz=165.4, num_updates=21900, lr=0.000213687, gnorm=0.813, train_wall=15, wall=0
2024-07-31 21:49:13 | INFO | train_inner | epoch 002:   4976 / 17024 loss=7.262, nll_loss=6.271, ppl=77.21, wps=25730.2, ups=6.48, wpb=3971.8, bsz=161.3, num_updates=22000, lr=0.000213201, gnorm=0.823, train_wall=15, wall=0
2024-07-31 21:49:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:49:15 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.524 | nll_loss 6.506 | ppl 90.87 | wps 97221.5 | wpb 3529.1 | bsz 62.9 | num_updates 22000 | best_loss 7.524
2024-07-31 21:49:15 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:49:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_22000.pt (epoch 2 @ 22000 updates, score 7.524) (writing took 8.091973382979631 seconds)
2024-07-31 21:49:38 | INFO | train_inner | epoch 002:   5076 / 17024 loss=7.25, nll_loss=6.257, ppl=76.47, wps=15857.5, ups=4.02, wpb=3944.4, bsz=149.4, num_updates=22100, lr=0.000212718, gnorm=0.805, train_wall=15, wall=0
2024-07-31 21:49:54 | INFO | train_inner | epoch 002:   5176 / 17024 loss=7.279, nll_loss=6.291, ppl=78.31, wps=25726.3, ups=6.5, wpb=3957.1, bsz=166, num_updates=22200, lr=0.000212238, gnorm=0.814, train_wall=15, wall=0
2024-07-31 21:50:09 | INFO | train_inner | epoch 002:   5276 / 17024 loss=7.261, nll_loss=6.27, ppl=77.17, wps=25679.5, ups=6.47, wpb=3971.7, bsz=166.2, num_updates=22300, lr=0.000211762, gnorm=0.811, train_wall=15, wall=0
2024-07-31 21:50:25 | INFO | train_inner | epoch 002:   5376 / 17024 loss=7.279, nll_loss=6.291, ppl=78.32, wps=25545.3, ups=6.44, wpb=3968, bsz=175.1, num_updates=22400, lr=0.000211289, gnorm=0.82, train_wall=15, wall=0
2024-07-31 21:50:40 | INFO | train_inner | epoch 002:   5476 / 17024 loss=7.322, nll_loss=6.34, ppl=80.99, wps=25642.8, ups=6.48, wpb=3958.4, bsz=182, num_updates=22500, lr=0.000210819, gnorm=0.834, train_wall=15, wall=0
2024-07-31 21:50:56 | INFO | train_inner | epoch 002:   5576 / 17024 loss=7.314, nll_loss=6.331, ppl=80.49, wps=25696, ups=6.47, wpb=3969, bsz=171.3, num_updates=22600, lr=0.000210352, gnorm=0.82, train_wall=15, wall=0
2024-07-31 21:51:11 | INFO | train_inner | epoch 002:   5676 / 17024 loss=7.296, nll_loss=6.311, ppl=79.38, wps=25655.7, ups=6.5, wpb=3948, bsz=166.5, num_updates=22700, lr=0.000209888, gnorm=0.827, train_wall=15, wall=0
2024-07-31 21:51:26 | INFO | train_inner | epoch 002:   5776 / 17024 loss=7.297, nll_loss=6.311, ppl=79.39, wps=25573.6, ups=6.49, wpb=3940.3, bsz=153.7, num_updates=22800, lr=0.000209427, gnorm=0.832, train_wall=15, wall=0
2024-07-31 21:51:42 | INFO | train_inner | epoch 002:   5876 / 17024 loss=7.312, nll_loss=6.33, ppl=80.43, wps=25704.2, ups=6.48, wpb=3968.8, bsz=177.2, num_updates=22900, lr=0.000208969, gnorm=0.848, train_wall=15, wall=0
2024-07-31 21:51:57 | INFO | train_inner | epoch 002:   5976 / 17024 loss=7.227, nll_loss=6.231, ppl=75.09, wps=25866.9, ups=6.54, wpb=3957.1, bsz=146.3, num_updates=23000, lr=0.000208514, gnorm=0.802, train_wall=15, wall=0
2024-07-31 21:51:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:51:59 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.529 | nll_loss 6.512 | ppl 91.26 | wps 96343.3 | wpb 3529.1 | bsz 62.9 | num_updates 23000 | best_loss 7.524
2024-07-31 21:51:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:52:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_23000.pt (epoch 2 @ 23000 updates, score 7.529) (writing took 4.082103282213211 seconds)
2024-07-31 21:52:18 | INFO | train_inner | epoch 002:   6076 / 17024 loss=7.249, nll_loss=6.256, ppl=76.43, wps=18858.1, ups=4.76, wpb=3960, bsz=163, num_updates=23100, lr=0.000208063, gnorm=0.81, train_wall=15, wall=0
2024-07-31 21:52:34 | INFO | train_inner | epoch 002:   6176 / 17024 loss=7.296, nll_loss=6.311, ppl=79.41, wps=25600.4, ups=6.44, wpb=3972.3, bsz=180.9, num_updates=23200, lr=0.000207614, gnorm=0.817, train_wall=15, wall=0
2024-07-31 21:52:49 | INFO | train_inner | epoch 002:   6276 / 17024 loss=7.286, nll_loss=6.299, ppl=78.74, wps=25521.9, ups=6.43, wpb=3970.2, bsz=171.4, num_updates=23300, lr=0.000207168, gnorm=0.816, train_wall=15, wall=0
2024-07-31 21:53:05 | INFO | train_inner | epoch 002:   6376 / 17024 loss=7.287, nll_loss=6.299, ppl=78.75, wps=25743.7, ups=6.51, wpb=3952.1, bsz=167.1, num_updates=23400, lr=0.000206725, gnorm=0.83, train_wall=15, wall=0
2024-07-31 21:53:20 | INFO | train_inner | epoch 002:   6476 / 17024 loss=7.248, nll_loss=6.254, ppl=76.32, wps=25705.7, ups=6.46, wpb=3976.6, bsz=153.4, num_updates=23500, lr=0.000206284, gnorm=0.808, train_wall=15, wall=0
2024-07-31 21:53:35 | INFO | train_inner | epoch 002:   6576 / 17024 loss=7.291, nll_loss=6.304, ppl=79.02, wps=25698.4, ups=6.49, wpb=3959.1, bsz=169.4, num_updates=23600, lr=0.000205847, gnorm=0.84, train_wall=15, wall=0
2024-07-31 21:53:51 | INFO | train_inner | epoch 002:   6676 / 17024 loss=7.239, nll_loss=6.246, ppl=75.89, wps=25564, ups=6.45, wpb=3963.3, bsz=165.4, num_updates=23700, lr=0.000205412, gnorm=0.811, train_wall=15, wall=0
2024-07-31 21:54:06 | INFO | train_inner | epoch 002:   6776 / 17024 loss=7.285, nll_loss=6.298, ppl=78.7, wps=25652.1, ups=6.48, wpb=3958.4, bsz=173.4, num_updates=23800, lr=0.00020498, gnorm=0.834, train_wall=15, wall=0
2024-07-31 21:54:22 | INFO | train_inner | epoch 002:   6876 / 17024 loss=7.267, nll_loss=6.277, ppl=77.57, wps=25683.8, ups=6.49, wpb=3958.7, bsz=164.5, num_updates=23900, lr=0.000204551, gnorm=0.824, train_wall=15, wall=0
2024-07-31 21:54:37 | INFO | train_inner | epoch 002:   6976 / 17024 loss=7.257, nll_loss=6.265, ppl=76.91, wps=25575, ups=6.49, wpb=3940.7, bsz=150.6, num_updates=24000, lr=0.000204124, gnorm=0.824, train_wall=15, wall=0
2024-07-31 21:54:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:54:39 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.516 | nll_loss 6.495 | ppl 90.22 | wps 92956.6 | wpb 3529.1 | bsz 62.9 | num_updates 24000 | best_loss 7.516
2024-07-31 21:54:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:54:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_24000.pt (epoch 2 @ 24000 updates, score 7.516) (writing took 9.24631324224174 seconds)
2024-07-31 21:55:03 | INFO | train_inner | epoch 002:   7076 / 17024 loss=7.249, nll_loss=6.256, ppl=76.41, wps=15099.8, ups=3.82, wpb=3952.6, bsz=152, num_updates=24100, lr=0.0002037, gnorm=0.809, train_wall=15, wall=0
2024-07-31 21:55:19 | INFO | train_inner | epoch 002:   7176 / 17024 loss=7.239, nll_loss=6.246, ppl=75.89, wps=25627.8, ups=6.45, wpb=3970.4, bsz=168.1, num_updates=24200, lr=0.000203279, gnorm=0.799, train_wall=15, wall=0
2024-07-31 21:55:34 | INFO | train_inner | epoch 002:   7276 / 17024 loss=7.197, nll_loss=6.197, ppl=73.34, wps=25600.6, ups=6.49, wpb=3945.4, bsz=145.4, num_updates=24300, lr=0.00020286, gnorm=0.808, train_wall=15, wall=0
2024-07-31 21:55:50 | INFO | train_inner | epoch 002:   7376 / 17024 loss=7.222, nll_loss=6.225, ppl=74.8, wps=25699, ups=6.47, wpb=3969.4, bsz=156.3, num_updates=24400, lr=0.000202444, gnorm=0.819, train_wall=15, wall=0
2024-07-31 21:56:05 | INFO | train_inner | epoch 002:   7476 / 17024 loss=7.207, nll_loss=6.207, ppl=73.88, wps=25717.1, ups=6.49, wpb=3963.3, bsz=144.4, num_updates=24500, lr=0.000202031, gnorm=0.81, train_wall=15, wall=0
2024-07-31 21:56:21 | INFO | train_inner | epoch 002:   7576 / 17024 loss=7.242, nll_loss=6.249, ppl=76.04, wps=25593, ups=6.47, wpb=3954.3, bsz=169.7, num_updates=24600, lr=0.000201619, gnorm=0.835, train_wall=15, wall=0
2024-07-31 21:56:36 | INFO | train_inner | epoch 002:   7676 / 17024 loss=7.288, nll_loss=6.302, ppl=78.91, wps=25605, ups=6.45, wpb=3970.1, bsz=175.4, num_updates=24700, lr=0.000201211, gnorm=0.838, train_wall=15, wall=0
2024-07-31 21:56:52 | INFO | train_inner | epoch 002:   7776 / 17024 loss=7.239, nll_loss=6.245, ppl=75.84, wps=25673.8, ups=6.49, wpb=3953, bsz=151.5, num_updates=24800, lr=0.000200805, gnorm=0.807, train_wall=15, wall=0
2024-07-31 21:57:07 | INFO | train_inner | epoch 002:   7876 / 17024 loss=7.262, nll_loss=6.271, ppl=77.25, wps=25691.9, ups=6.48, wpb=3963.9, bsz=164.7, num_updates=24900, lr=0.000200401, gnorm=0.831, train_wall=15, wall=0
2024-07-31 21:57:22 | INFO | train_inner | epoch 002:   7976 / 17024 loss=7.215, nll_loss=6.218, ppl=74.42, wps=25691.1, ups=6.5, wpb=3952.2, bsz=153.3, num_updates=25000, lr=0.0002, gnorm=0.816, train_wall=15, wall=0
2024-07-31 21:57:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 21:57:24 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.478 | nll_loss 6.451 | ppl 87.47 | wps 95172.2 | wpb 3529.1 | bsz 62.9 | num_updates 25000 | best_loss 7.478
2024-07-31 21:57:24 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 21:57:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_25000.pt (epoch 2 @ 25000 updates, score 7.478) (writing took 6.551824202761054 seconds)
2024-07-31 21:57:46 | INFO | train_inner | epoch 002:   8076 / 17024 loss=7.249, nll_loss=6.256, ppl=76.43, wps=16916.1, ups=4.26, wpb=3968.2, bsz=162.6, num_updates=25100, lr=0.000199601, gnorm=0.824, train_wall=15, wall=0
2024-07-31 21:58:01 | INFO | train_inner | epoch 002:   8176 / 17024 loss=7.229, nll_loss=6.233, ppl=75.22, wps=25749.5, ups=6.5, wpb=3961.3, bsz=151.9, num_updates=25200, lr=0.000199205, gnorm=0.826, train_wall=15, wall=0
2024-07-31 21:58:16 | INFO | train_inner | epoch 002:   8276 / 17024 loss=7.267, nll_loss=6.277, ppl=77.55, wps=25749.4, ups=6.54, wpb=3938.7, bsz=159.9, num_updates=25300, lr=0.000198811, gnorm=0.828, train_wall=15, wall=0
2024-07-31 21:58:32 | INFO | train_inner | epoch 002:   8376 / 17024 loss=7.244, nll_loss=6.25, ppl=76.11, wps=25779.4, ups=6.49, wpb=3971.8, bsz=160.9, num_updates=25400, lr=0.000198419, gnorm=0.816, train_wall=15, wall=0
2024-07-31 21:58:47 | INFO | train_inner | epoch 002:   8476 / 17024 loss=7.265, nll_loss=6.275, ppl=77.47, wps=25776.8, ups=6.49, wpb=3973.3, bsz=186.3, num_updates=25500, lr=0.00019803, gnorm=0.84, train_wall=15, wall=0
2024-07-31 21:59:03 | INFO | train_inner | epoch 002:   8576 / 17024 loss=7.252, nll_loss=6.26, ppl=76.65, wps=25561.4, ups=6.47, wpb=3949, bsz=165.4, num_updates=25600, lr=0.000197642, gnorm=0.824, train_wall=15, wall=0
2024-07-31 21:59:18 | INFO | train_inner | epoch 002:   8676 / 17024 loss=7.234, nll_loss=6.239, ppl=75.54, wps=25646.1, ups=6.5, wpb=3944.2, bsz=152.6, num_updates=25700, lr=0.000197257, gnorm=0.826, train_wall=15, wall=0
2024-07-31 21:59:33 | INFO | train_inner | epoch 002:   8776 / 17024 loss=7.225, nll_loss=6.229, ppl=74.99, wps=25749.4, ups=6.54, wpb=3939.6, bsz=155.7, num_updates=25800, lr=0.000196875, gnorm=0.828, train_wall=15, wall=0
2024-07-31 21:59:49 | INFO | train_inner | epoch 002:   8876 / 17024 loss=7.226, nll_loss=6.23, ppl=75.06, wps=25786.5, ups=6.48, wpb=3976.7, bsz=165, num_updates=25900, lr=0.000196494, gnorm=0.82, train_wall=15, wall=0
2024-07-31 22:00:04 | INFO | train_inner | epoch 002:   8976 / 17024 loss=7.221, nll_loss=6.224, ppl=74.75, wps=25786.3, ups=6.49, wpb=3974.3, bsz=158.9, num_updates=26000, lr=0.000196116, gnorm=0.813, train_wall=15, wall=0
2024-07-31 22:00:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:00:06 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.482 | nll_loss 6.46 | ppl 88.06 | wps 93921.1 | wpb 3529.1 | bsz 62.9 | num_updates 26000 | best_loss 7.478
2024-07-31 22:00:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:00:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_26000.pt (epoch 2 @ 26000 updates, score 7.482) (writing took 3.365318783558905 seconds)
2024-07-31 22:00:25 | INFO | train_inner | epoch 002:   9076 / 17024 loss=7.262, nll_loss=6.271, ppl=77.24, wps=19591.9, ups=4.92, wpb=3978.1, bsz=175.8, num_updates=26100, lr=0.00019574, gnorm=0.832, train_wall=15, wall=0
2024-07-31 22:00:40 | INFO | train_inner | epoch 002:   9176 / 17024 loss=7.277, nll_loss=6.289, ppl=78.18, wps=25647.9, ups=6.47, wpb=3961.6, bsz=169.7, num_updates=26200, lr=0.000195366, gnorm=0.856, train_wall=15, wall=0
2024-07-31 22:00:55 | INFO | train_inner | epoch 002:   9276 / 17024 loss=7.261, nll_loss=6.27, ppl=77.2, wps=25804.1, ups=6.49, wpb=3973.2, bsz=184.9, num_updates=26300, lr=0.000194994, gnorm=0.835, train_wall=15, wall=0
2024-07-31 22:01:11 | INFO | train_inner | epoch 002:   9376 / 17024 loss=7.217, nll_loss=6.219, ppl=74.5, wps=25725.1, ups=6.51, wpb=3954.5, bsz=162.6, num_updates=26400, lr=0.000194625, gnorm=0.823, train_wall=15, wall=0
2024-07-31 22:01:26 | INFO | train_inner | epoch 002:   9476 / 17024 loss=7.254, nll_loss=6.263, ppl=76.78, wps=25698.3, ups=6.46, wpb=3980.6, bsz=168.3, num_updates=26500, lr=0.000194257, gnorm=0.841, train_wall=15, wall=0
2024-07-31 22:01:42 | INFO | train_inner | epoch 002:   9576 / 17024 loss=7.24, nll_loss=6.246, ppl=75.88, wps=25709.7, ups=6.5, wpb=3956.8, bsz=158.1, num_updates=26600, lr=0.000193892, gnorm=0.837, train_wall=15, wall=0
2024-07-31 22:01:57 | INFO | train_inner | epoch 002:   9676 / 17024 loss=7.216, nll_loss=6.218, ppl=74.46, wps=25665, ups=6.48, wpb=3961.5, bsz=149.8, num_updates=26700, lr=0.000193528, gnorm=0.83, train_wall=15, wall=0
2024-07-31 22:02:13 | INFO | train_inner | epoch 002:   9776 / 17024 loss=7.267, nll_loss=6.278, ppl=77.58, wps=25635, ups=6.45, wpb=3973.2, bsz=177.7, num_updates=26800, lr=0.000193167, gnorm=0.839, train_wall=15, wall=0
2024-07-31 22:02:28 | INFO | train_inner | epoch 002:   9876 / 17024 loss=7.193, nll_loss=6.192, ppl=73.09, wps=25609.1, ups=6.45, wpb=3969.6, bsz=148.1, num_updates=26900, lr=0.000192807, gnorm=0.816, train_wall=15, wall=0
2024-07-31 22:02:44 | INFO | train_inner | epoch 002:   9976 / 17024 loss=7.231, nll_loss=6.235, ppl=75.33, wps=25638.1, ups=6.45, wpb=3976.5, bsz=168.4, num_updates=27000, lr=0.00019245, gnorm=0.844, train_wall=15, wall=0
2024-07-31 22:02:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:02:45 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.463 | nll_loss 6.434 | ppl 86.44 | wps 94645.6 | wpb 3529.1 | bsz 62.9 | num_updates 27000 | best_loss 7.463
2024-07-31 22:02:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:02:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_27000.pt (epoch 2 @ 27000 updates, score 7.463) (writing took 7.2164232125505805 seconds)
2024-07-31 22:03:08 | INFO | train_inner | epoch 002:  10076 / 17024 loss=7.223, nll_loss=6.227, ppl=74.89, wps=16424.5, ups=4.13, wpb=3975.2, bsz=165.3, num_updates=27100, lr=0.000192095, gnorm=0.837, train_wall=15, wall=0
2024-07-31 22:03:23 | INFO | train_inner | epoch 002:  10176 / 17024 loss=7.233, nll_loss=6.238, ppl=75.5, wps=25609.8, ups=6.48, wpb=3954.1, bsz=161.8, num_updates=27200, lr=0.000191741, gnorm=0.822, train_wall=15, wall=0
2024-07-31 22:03:39 | INFO | train_inner | epoch 002:  10276 / 17024 loss=7.198, nll_loss=6.198, ppl=73.39, wps=25564.6, ups=6.47, wpb=3951.4, bsz=150, num_updates=27300, lr=0.00019139, gnorm=0.826, train_wall=15, wall=0
2024-07-31 22:03:54 | INFO | train_inner | epoch 002:  10376 / 17024 loss=7.27, nll_loss=6.281, ppl=77.76, wps=25648.8, ups=6.44, wpb=3983.3, bsz=193.4, num_updates=27400, lr=0.00019104, gnorm=0.863, train_wall=15, wall=0
2024-07-31 22:04:10 | INFO | train_inner | epoch 002:  10476 / 17024 loss=7.272, nll_loss=6.284, ppl=77.92, wps=25583.7, ups=6.45, wpb=3966.7, bsz=180.5, num_updates=27500, lr=0.000190693, gnorm=0.833, train_wall=15, wall=0
2024-07-31 22:04:25 | INFO | train_inner | epoch 002:  10576 / 17024 loss=7.252, nll_loss=6.261, ppl=76.68, wps=25667.3, ups=6.45, wpb=3980.4, bsz=171.1, num_updates=27600, lr=0.000190347, gnorm=0.84, train_wall=15, wall=0
2024-07-31 22:04:41 | INFO | train_inner | epoch 002:  10676 / 17024 loss=7.177, nll_loss=6.173, ppl=72.17, wps=25778.9, ups=6.48, wpb=3977.6, bsz=151.8, num_updates=27700, lr=0.000190003, gnorm=0.805, train_wall=15, wall=0
2024-07-31 22:04:56 | INFO | train_inner | epoch 002:  10776 / 17024 loss=7.207, nll_loss=6.208, ppl=73.91, wps=25695.4, ups=6.47, wpb=3971.8, bsz=158.6, num_updates=27800, lr=0.000189661, gnorm=0.821, train_wall=15, wall=0
2024-07-31 22:05:12 | INFO | train_inner | epoch 002:  10876 / 17024 loss=7.213, nll_loss=6.215, ppl=74.29, wps=25486.5, ups=6.46, wpb=3946.8, bsz=162.7, num_updates=27900, lr=0.000189321, gnorm=0.835, train_wall=15, wall=0
2024-07-31 22:05:27 | INFO | train_inner | epoch 002:  10976 / 17024 loss=7.183, nll_loss=6.18, ppl=72.5, wps=25561.7, ups=6.48, wpb=3947.4, bsz=143.8, num_updates=28000, lr=0.000188982, gnorm=0.821, train_wall=15, wall=0
2024-07-31 22:05:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:05:28 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.433 | nll_loss 6.406 | ppl 84.81 | wps 95327.9 | wpb 3529.1 | bsz 62.9 | num_updates 28000 | best_loss 7.433
2024-07-31 22:05:28 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:05:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_28000.pt (epoch 2 @ 28000 updates, score 7.433) (writing took 7.134742518886924 seconds)
2024-07-31 22:05:51 | INFO | train_inner | epoch 002:  11076 / 17024 loss=7.188, nll_loss=6.186, ppl=72.82, wps=16426.4, ups=4.16, wpb=3945.5, bsz=146.1, num_updates=28100, lr=0.000188646, gnorm=0.837, train_wall=15, wall=0
2024-07-31 22:06:07 | INFO | train_inner | epoch 002:  11176 / 17024 loss=7.219, nll_loss=6.222, ppl=74.63, wps=25470.2, ups=6.48, wpb=3932.9, bsz=157.8, num_updates=28200, lr=0.000188311, gnorm=0.845, train_wall=15, wall=0
2024-07-31 22:06:22 | INFO | train_inner | epoch 002:  11276 / 17024 loss=7.175, nll_loss=6.172, ppl=72.09, wps=25493.1, ups=6.42, wpb=3969, bsz=160.4, num_updates=28300, lr=0.000187978, gnorm=0.815, train_wall=15, wall=0
2024-07-31 22:06:38 | INFO | train_inner | epoch 002:  11376 / 17024 loss=7.193, nll_loss=6.192, ppl=73.1, wps=25588, ups=6.41, wpb=3990, bsz=161.9, num_updates=28400, lr=0.000187647, gnorm=0.83, train_wall=15, wall=0
2024-07-31 22:06:53 | INFO | train_inner | epoch 002:  11476 / 17024 loss=7.214, nll_loss=6.216, ppl=74.34, wps=25398.1, ups=6.43, wpb=3949.1, bsz=158.5, num_updates=28500, lr=0.000187317, gnorm=0.825, train_wall=15, wall=0
2024-07-31 22:07:09 | INFO | train_inner | epoch 002:  11576 / 17024 loss=7.163, nll_loss=6.158, ppl=71.38, wps=25607.6, ups=6.46, wpb=3964.7, bsz=151.4, num_updates=28600, lr=0.000186989, gnorm=0.824, train_wall=15, wall=0
2024-07-31 22:07:24 | INFO | train_inner | epoch 002:  11676 / 17024 loss=7.199, nll_loss=6.198, ppl=73.43, wps=25467.2, ups=6.45, wpb=3947.4, bsz=150.2, num_updates=28700, lr=0.000186663, gnorm=0.859, train_wall=15, wall=0
2024-07-31 22:07:40 | INFO | train_inner | epoch 002:  11776 / 17024 loss=7.22, nll_loss=6.224, ppl=74.74, wps=25423, ups=6.41, wpb=3965.4, bsz=174.9, num_updates=28800, lr=0.000186339, gnorm=0.844, train_wall=15, wall=0
2024-07-31 22:07:55 | INFO | train_inner | epoch 002:  11876 / 17024 loss=7.251, nll_loss=6.259, ppl=76.58, wps=25349.1, ups=6.41, wpb=3954.4, bsz=169.3, num_updates=28900, lr=0.000186016, gnorm=0.863, train_wall=15, wall=0
2024-07-31 22:08:11 | INFO | train_inner | epoch 002:  11976 / 17024 loss=7.196, nll_loss=6.196, ppl=73.3, wps=25511.4, ups=6.45, wpb=3956.2, bsz=152.9, num_updates=29000, lr=0.000185695, gnorm=0.826, train_wall=15, wall=0
2024-07-31 22:08:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:08:12 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.436 | nll_loss 6.407 | ppl 84.84 | wps 96460 | wpb 3529.1 | bsz 62.9 | num_updates 29000 | best_loss 7.433
2024-07-31 22:08:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:08:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_29000.pt (epoch 2 @ 29000 updates, score 7.436) (writing took 3.690773967653513 seconds)
2024-07-31 22:08:32 | INFO | train_inner | epoch 002:  12076 / 17024 loss=7.218, nll_loss=6.222, ppl=74.63, wps=19161, ups=4.83, wpb=3963.1, bsz=173.7, num_updates=29100, lr=0.000185376, gnorm=0.842, train_wall=15, wall=0
2024-07-31 22:08:47 | INFO | train_inner | epoch 002:  12176 / 17024 loss=7.178, nll_loss=6.175, ppl=72.25, wps=25646.9, ups=6.46, wpb=3971.9, bsz=159.8, num_updates=29200, lr=0.000185058, gnorm=0.819, train_wall=15, wall=0
2024-07-31 22:09:03 | INFO | train_inner | epoch 002:  12276 / 17024 loss=7.232, nll_loss=6.237, ppl=75.41, wps=25414, ups=6.43, wpb=3952.8, bsz=168, num_updates=29300, lr=0.000184742, gnorm=0.852, train_wall=15, wall=0
2024-07-31 22:09:18 | INFO | train_inner | epoch 002:  12376 / 17024 loss=7.16, nll_loss=6.155, ppl=71.24, wps=25782.6, ups=6.51, wpb=3958.6, bsz=147.6, num_updates=29400, lr=0.000184428, gnorm=0.825, train_wall=15, wall=0
2024-07-31 22:09:34 | INFO | train_inner | epoch 002:  12476 / 17024 loss=7.257, nll_loss=6.266, ppl=76.94, wps=25484.9, ups=6.45, wpb=3953.9, bsz=183, num_updates=29500, lr=0.000184115, gnorm=0.878, train_wall=15, wall=0
2024-07-31 22:09:49 | INFO | train_inner | epoch 002:  12576 / 17024 loss=7.194, nll_loss=6.193, ppl=73.16, wps=25652.5, ups=6.48, wpb=3958.1, bsz=162.6, num_updates=29600, lr=0.000183804, gnorm=0.843, train_wall=15, wall=0
2024-07-31 22:10:04 | INFO | train_inner | epoch 002:  12676 / 17024 loss=7.219, nll_loss=6.222, ppl=74.63, wps=25652.4, ups=6.46, wpb=3971.8, bsz=171.7, num_updates=29700, lr=0.000183494, gnorm=0.846, train_wall=15, wall=0
2024-07-31 22:10:20 | INFO | train_inner | epoch 002:  12776 / 17024 loss=7.237, nll_loss=6.243, ppl=75.76, wps=25893.3, ups=6.54, wpb=3957.6, bsz=177.8, num_updates=29800, lr=0.000183186, gnorm=0.855, train_wall=15, wall=0
2024-07-31 22:10:35 | INFO | train_inner | epoch 002:  12876 / 17024 loss=7.168, nll_loss=6.162, ppl=71.62, wps=25769.9, ups=6.51, wpb=3959.8, bsz=154.9, num_updates=29900, lr=0.000182879, gnorm=0.837, train_wall=15, wall=0
2024-07-31 22:10:51 | INFO | train_inner | epoch 002:  12976 / 17024 loss=7.171, nll_loss=6.167, ppl=71.85, wps=25566.3, ups=6.47, wpb=3951.8, bsz=164.9, num_updates=30000, lr=0.000182574, gnorm=0.824, train_wall=15, wall=0
2024-07-31 22:10:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:10:52 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.438 | nll_loss 6.411 | ppl 85.1 | wps 95380.7 | wpb 3529.1 | bsz 62.9 | num_updates 30000 | best_loss 7.433
2024-07-31 22:10:52 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:10:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_30000.pt (epoch 2 @ 30000 updates, score 7.438) (writing took 3.6539855347946286 seconds)
2024-07-31 22:11:11 | INFO | train_inner | epoch 002:  13076 / 17024 loss=7.175, nll_loss=6.171, ppl=72.06, wps=19163.8, ups=4.86, wpb=3942.6, bsz=149.8, num_updates=30100, lr=0.000182271, gnorm=0.84, train_wall=15, wall=0
2024-07-31 22:11:26 | INFO | train_inner | epoch 002:  13176 / 17024 loss=7.228, nll_loss=6.232, ppl=75.18, wps=25679.1, ups=6.51, wpb=3944.6, bsz=169.8, num_updates=30200, lr=0.000181969, gnorm=0.842, train_wall=15, wall=0
2024-07-31 22:11:42 | INFO | train_inner | epoch 002:  13276 / 17024 loss=7.181, nll_loss=6.178, ppl=72.4, wps=25489.4, ups=6.44, wpb=3955.5, bsz=160.8, num_updates=30300, lr=0.000181668, gnorm=0.861, train_wall=15, wall=0
2024-07-31 22:11:58 | INFO | train_inner | epoch 002:  13376 / 17024 loss=7.184, nll_loss=6.182, ppl=72.6, wps=25534.2, ups=6.43, wpb=3968.8, bsz=166.2, num_updates=30400, lr=0.000181369, gnorm=0.841, train_wall=15, wall=0
2024-07-31 22:12:13 | INFO | train_inner | epoch 002:  13476 / 17024 loss=7.166, nll_loss=6.161, ppl=71.55, wps=25659.9, ups=6.45, wpb=3976.2, bsz=158.6, num_updates=30500, lr=0.000181071, gnorm=0.838, train_wall=15, wall=0
2024-07-31 22:12:28 | INFO | train_inner | epoch 002:  13576 / 17024 loss=7.203, nll_loss=6.204, ppl=73.72, wps=25519.5, ups=6.48, wpb=3938.3, bsz=164, num_updates=30600, lr=0.000180775, gnorm=0.874, train_wall=15, wall=0
2024-07-31 22:12:44 | INFO | train_inner | epoch 002:  13676 / 17024 loss=7.174, nll_loss=6.17, ppl=72.02, wps=25651.9, ups=6.5, wpb=3946, bsz=151.9, num_updates=30700, lr=0.000180481, gnorm=0.832, train_wall=15, wall=0
2024-07-31 22:12:59 | INFO | train_inner | epoch 002:  13776 / 17024 loss=7.203, nll_loss=6.203, ppl=73.67, wps=25628.7, ups=6.49, wpb=3948.4, bsz=162.1, num_updates=30800, lr=0.000180187, gnorm=0.854, train_wall=15, wall=0
2024-07-31 22:13:15 | INFO | train_inner | epoch 002:  13876 / 17024 loss=7.207, nll_loss=6.208, ppl=73.94, wps=25627, ups=6.47, wpb=3959.2, bsz=173.5, num_updates=30900, lr=0.000179896, gnorm=0.843, train_wall=15, wall=0
2024-07-31 22:13:30 | INFO | train_inner | epoch 002:  13976 / 17024 loss=7.16, nll_loss=6.154, ppl=71.2, wps=25652.8, ups=6.5, wpb=3948.1, bsz=152.6, num_updates=31000, lr=0.000179605, gnorm=0.834, train_wall=15, wall=0
2024-07-31 22:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:13:32 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.425 | nll_loss 6.394 | ppl 84.11 | wps 94943.3 | wpb 3529.1 | bsz 62.9 | num_updates 31000 | best_loss 7.425
2024-07-31 22:13:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:13:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_31000.pt (epoch 2 @ 31000 updates, score 7.425) (writing took 5.307099214754999 seconds)
2024-07-31 22:13:52 | INFO | train_inner | epoch 002:  14076 / 17024 loss=7.245, nll_loss=6.253, ppl=76.26, wps=17817.1, ups=4.48, wpb=3980, bsz=177.5, num_updates=31100, lr=0.000179316, gnorm=0.873, train_wall=15, wall=0
2024-07-31 22:14:08 | INFO | train_inner | epoch 002:  14176 / 17024 loss=7.187, nll_loss=6.185, ppl=72.76, wps=25582.1, ups=6.5, wpb=3934.2, bsz=152.3, num_updates=31200, lr=0.000179029, gnorm=0.849, train_wall=15, wall=0
2024-07-31 22:14:23 | INFO | train_inner | epoch 002:  14276 / 17024 loss=7.206, nll_loss=6.208, ppl=73.9, wps=25788.6, ups=6.5, wpb=3969.6, bsz=161.8, num_updates=31300, lr=0.000178743, gnorm=0.833, train_wall=15, wall=0
2024-07-31 22:14:39 | INFO | train_inner | epoch 002:  14376 / 17024 loss=7.252, nll_loss=6.261, ppl=76.69, wps=25633.8, ups=6.42, wpb=3993.5, bsz=195.4, num_updates=31400, lr=0.000178458, gnorm=0.865, train_wall=15, wall=0
2024-07-31 22:14:54 | INFO | train_inner | epoch 002:  14476 / 17024 loss=7.156, nll_loss=6.15, ppl=71, wps=25668.5, ups=6.52, wpb=3938.8, bsz=155.9, num_updates=31500, lr=0.000178174, gnorm=0.842, train_wall=15, wall=0
2024-07-31 22:15:09 | INFO | train_inner | epoch 002:  14576 / 17024 loss=7.234, nll_loss=6.239, ppl=75.55, wps=25611.7, ups=6.52, wpb=3927.9, bsz=168.8, num_updates=31600, lr=0.000177892, gnorm=0.885, train_wall=15, wall=0
2024-07-31 22:15:25 | INFO | train_inner | epoch 002:  14676 / 17024 loss=7.216, nll_loss=6.219, ppl=74.48, wps=25560.1, ups=6.46, wpb=3956.1, bsz=171.4, num_updates=31700, lr=0.000177611, gnorm=0.871, train_wall=15, wall=0
2024-07-31 22:15:40 | INFO | train_inner | epoch 002:  14776 / 17024 loss=7.166, nll_loss=6.161, ppl=71.57, wps=25720.1, ups=6.47, wpb=3976, bsz=165.7, num_updates=31800, lr=0.000177332, gnorm=0.831, train_wall=15, wall=0
2024-07-31 22:15:56 | INFO | train_inner | epoch 002:  14876 / 17024 loss=7.196, nll_loss=6.196, ppl=73.3, wps=25748, ups=6.49, wpb=3968.3, bsz=171.3, num_updates=31900, lr=0.000177054, gnorm=0.845, train_wall=15, wall=0
2024-07-31 22:16:11 | INFO | train_inner | epoch 002:  14976 / 17024 loss=7.181, nll_loss=6.179, ppl=72.45, wps=25599.3, ups=6.45, wpb=3969.7, bsz=164.2, num_updates=32000, lr=0.000176777, gnorm=0.831, train_wall=15, wall=0
2024-07-31 22:16:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:16:13 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.438 | nll_loss 6.407 | ppl 84.83 | wps 96940.5 | wpb 3529.1 | bsz 62.9 | num_updates 32000 | best_loss 7.425
2024-07-31 22:16:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:16:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_32000.pt (epoch 2 @ 32000 updates, score 7.438) (writing took 3.1350683802738786 seconds)
2024-07-31 22:16:31 | INFO | train_inner | epoch 002:  15076 / 17024 loss=7.174, nll_loss=6.17, ppl=72.03, wps=19855.7, ups=5.01, wpb=3965.8, bsz=161.4, num_updates=32100, lr=0.000176501, gnorm=0.835, train_wall=15, wall=0
2024-07-31 22:16:47 | INFO | train_inner | epoch 002:  15176 / 17024 loss=7.198, nll_loss=6.198, ppl=73.41, wps=25761.6, ups=6.48, wpb=3974.4, bsz=166, num_updates=32200, lr=0.000176227, gnorm=0.849, train_wall=15, wall=0
2024-07-31 22:17:02 | INFO | train_inner | epoch 002:  15276 / 17024 loss=7.155, nll_loss=6.148, ppl=70.92, wps=25624, ups=6.47, wpb=3959.6, bsz=152.8, num_updates=32300, lr=0.000175954, gnorm=0.841, train_wall=15, wall=0
2024-07-31 22:17:18 | INFO | train_inner | epoch 002:  15376 / 17024 loss=7.183, nll_loss=6.181, ppl=72.53, wps=25626.7, ups=6.46, wpb=3966.7, bsz=162.2, num_updates=32400, lr=0.000175682, gnorm=0.85, train_wall=15, wall=0
2024-07-31 22:17:33 | INFO | train_inner | epoch 002:  15476 / 17024 loss=7.147, nll_loss=6.139, ppl=70.48, wps=25672, ups=6.47, wpb=3967.3, bsz=154.2, num_updates=32500, lr=0.000175412, gnorm=0.834, train_wall=15, wall=0
2024-07-31 22:17:49 | INFO | train_inner | epoch 002:  15576 / 17024 loss=7.191, nll_loss=6.191, ppl=73.06, wps=25751.2, ups=6.49, wpb=3967.9, bsz=175.3, num_updates=32600, lr=0.000175142, gnorm=0.851, train_wall=15, wall=0
2024-07-31 22:18:04 | INFO | train_inner | epoch 002:  15676 / 17024 loss=7.165, nll_loss=6.161, ppl=71.54, wps=25634.3, ups=6.44, wpb=3978, bsz=166.6, num_updates=32700, lr=0.000174874, gnorm=0.838, train_wall=15, wall=0
2024-07-31 22:18:20 | INFO | train_inner | epoch 002:  15776 / 17024 loss=7.179, nll_loss=6.177, ppl=72.36, wps=25475.2, ups=6.44, wpb=3955, bsz=171.7, num_updates=32800, lr=0.000174608, gnorm=0.838, train_wall=15, wall=0
2024-07-31 22:18:35 | INFO | train_inner | epoch 002:  15876 / 17024 loss=7.222, nll_loss=6.226, ppl=74.87, wps=25674.8, ups=6.46, wpb=3972, bsz=178.8, num_updates=32900, lr=0.000174342, gnorm=0.863, train_wall=15, wall=0
2024-07-31 22:18:50 | INFO | train_inner | epoch 002:  15976 / 17024 loss=7.127, nll_loss=6.116, ppl=69.37, wps=25656.4, ups=6.5, wpb=3944.8, bsz=147.3, num_updates=33000, lr=0.000174078, gnorm=0.819, train_wall=15, wall=0
2024-07-31 22:18:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:18:52 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.404 | nll_loss 6.367 | ppl 82.55 | wps 96044 | wpb 3529.1 | bsz 62.9 | num_updates 33000 | best_loss 7.404
2024-07-31 22:18:52 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:18:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_33000.pt (epoch 2 @ 33000 updates, score 7.404) (writing took 5.261746618896723 seconds)
2024-07-31 22:19:13 | INFO | train_inner | epoch 002:  16076 / 17024 loss=7.171, nll_loss=6.166, ppl=71.82, wps=17879.6, ups=4.53, wpb=3950.6, bsz=148.3, num_updates=33100, lr=0.000173814, gnorm=0.864, train_wall=15, wall=0
2024-07-31 22:19:28 | INFO | train_inner | epoch 002:  16176 / 17024 loss=7.208, nll_loss=6.21, ppl=74.03, wps=25515.3, ups=6.44, wpb=3959.2, bsz=169.7, num_updates=33200, lr=0.000173553, gnorm=0.856, train_wall=15, wall=0
2024-07-31 22:19:43 | INFO | train_inner | epoch 002:  16276 / 17024 loss=7.167, nll_loss=6.163, ppl=71.64, wps=25768.1, ups=6.49, wpb=3971.2, bsz=157.6, num_updates=33300, lr=0.000173292, gnorm=0.84, train_wall=15, wall=0
2024-07-31 22:19:59 | INFO | train_inner | epoch 002:  16376 / 17024 loss=7.17, nll_loss=6.165, ppl=71.76, wps=25593.7, ups=6.49, wpb=3944.7, bsz=149.3, num_updates=33400, lr=0.000173032, gnorm=0.847, train_wall=15, wall=0
2024-07-31 22:20:14 | INFO | train_inner | epoch 002:  16476 / 17024 loss=7.116, nll_loss=6.104, ppl=68.79, wps=25505.4, ups=6.45, wpb=3954, bsz=155.6, num_updates=33500, lr=0.000172774, gnorm=0.831, train_wall=15, wall=0
2024-07-31 22:20:30 | INFO | train_inner | epoch 002:  16576 / 17024 loss=7.157, nll_loss=6.151, ppl=71.05, wps=25515.9, ups=6.45, wpb=3955, bsz=157.3, num_updates=33600, lr=0.000172516, gnorm=0.86, train_wall=15, wall=0
2024-07-31 22:20:45 | INFO | train_inner | epoch 002:  16676 / 17024 loss=7.223, nll_loss=6.227, ppl=74.89, wps=25645.6, ups=6.45, wpb=3973.3, bsz=174.1, num_updates=33700, lr=0.00017226, gnorm=0.865, train_wall=15, wall=0
2024-07-31 22:21:01 | INFO | train_inner | epoch 002:  16776 / 17024 loss=7.176, nll_loss=6.173, ppl=72.15, wps=25621.4, ups=6.48, wpb=3953.9, bsz=159.4, num_updates=33800, lr=0.000172005, gnorm=0.851, train_wall=15, wall=0
2024-07-31 22:21:16 | INFO | train_inner | epoch 002:  16876 / 17024 loss=7.177, nll_loss=6.174, ppl=72.23, wps=25602.5, ups=6.46, wpb=3963.8, bsz=163.7, num_updates=33900, lr=0.000171751, gnorm=0.843, train_wall=15, wall=0
2024-07-31 22:21:32 | INFO | train_inner | epoch 002:  16976 / 17024 loss=7.159, nll_loss=6.153, ppl=71.14, wps=25577.3, ups=6.47, wpb=3954.6, bsz=157.2, num_updates=34000, lr=0.000171499, gnorm=0.852, train_wall=15, wall=0
2024-07-31 22:21:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:21:33 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.417 | nll_loss 6.382 | ppl 83.41 | wps 95430.2 | wpb 3529.1 | bsz 62.9 | num_updates 34000 | best_loss 7.404
2024-07-31 22:21:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:21:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_34000.pt (epoch 2 @ 34000 updates, score 7.417) (writing took 3.219631837680936 seconds)
2024-07-31 22:21:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:21:45 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.409 | nll_loss 6.377 | ppl 83.14 | wps 96896.2 | wpb 3529.1 | bsz 62.9 | num_updates 34048 | best_loss 7.404
2024-07-31 22:21:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:21:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 2 @ 34048 updates, score 7.409) (writing took 2.597834183834493 seconds)
2024-07-31 22:21:48 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2024-07-31 22:21:48 | INFO | train | epoch 002 | loss 7.251 | nll_loss 6.259 | ppl 76.6 | wps 24514 | ups 6.19 | wpb 3960.7 | bsz 163.4 | num_updates 34048 | lr 0.000171378 | gnorm 0.827 | train_wall 2597 | wall 0
2024-07-31 22:21:48 | INFO | fairseq.trainer | begin training epoch 3
2024-07-31 22:21:56 | INFO | train_inner | epoch 003:     52 / 17024 loss=7.122, nll_loss=6.11, ppl=69.08, wps=16314.8, ups=4.11, wpb=3965, bsz=154.8, num_updates=34100, lr=0.000171247, gnorm=0.828, train_wall=15, wall=0
2024-07-31 22:22:12 | INFO | train_inner | epoch 003:    152 / 17024 loss=7.131, nll_loss=6.121, ppl=69.59, wps=25535.2, ups=6.41, wpb=3980.7, bsz=162.3, num_updates=34200, lr=0.000170996, gnorm=0.851, train_wall=15, wall=0
2024-07-31 22:22:27 | INFO | train_inner | epoch 003:    252 / 17024 loss=7.101, nll_loss=6.087, ppl=67.96, wps=25711.3, ups=6.55, wpb=3928, bsz=144.8, num_updates=34300, lr=0.000170747, gnorm=0.848, train_wall=15, wall=0
2024-07-31 22:22:42 | INFO | train_inner | epoch 003:    352 / 17024 loss=7.131, nll_loss=6.121, ppl=69.61, wps=25813.6, ups=6.52, wpb=3960.1, bsz=164.1, num_updates=34400, lr=0.000170499, gnorm=0.857, train_wall=15, wall=0
2024-07-31 22:22:58 | INFO | train_inner | epoch 003:    452 / 17024 loss=7.156, nll_loss=6.151, ppl=71.06, wps=25719, ups=6.43, wpb=4000.9, bsz=187.1, num_updates=34500, lr=0.000170251, gnorm=0.843, train_wall=15, wall=0
2024-07-31 22:23:13 | INFO | train_inner | epoch 003:    552 / 17024 loss=7.155, nll_loss=6.149, ppl=70.97, wps=25625.7, ups=6.49, wpb=3947.9, bsz=163.7, num_updates=34600, lr=0.000170005, gnorm=0.888, train_wall=15, wall=0
2024-07-31 22:23:29 | INFO | train_inner | epoch 003:    652 / 17024 loss=7.131, nll_loss=6.12, ppl=69.56, wps=25698.1, ups=6.5, wpb=3953, bsz=155.4, num_updates=34700, lr=0.00016976, gnorm=0.848, train_wall=15, wall=0
2024-07-31 22:23:44 | INFO | train_inner | epoch 003:    752 / 17024 loss=7.145, nll_loss=6.137, ppl=70.38, wps=25612.5, ups=6.5, wpb=3942.9, bsz=151.8, num_updates=34800, lr=0.000169516, gnorm=0.853, train_wall=15, wall=0
2024-07-31 22:23:59 | INFO | train_inner | epoch 003:    852 / 17024 loss=7.113, nll_loss=6.099, ppl=68.54, wps=25779.1, ups=6.56, wpb=3931.9, bsz=144.3, num_updates=34900, lr=0.000169273, gnorm=0.863, train_wall=15, wall=0
2024-07-31 22:24:15 | INFO | train_inner | epoch 003:    952 / 17024 loss=7.171, nll_loss=6.167, ppl=71.86, wps=25607, ups=6.48, wpb=3952.3, bsz=166.7, num_updates=35000, lr=0.000169031, gnorm=0.877, train_wall=15, wall=0
2024-07-31 22:24:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:24:16 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.399 | nll_loss 6.366 | ppl 82.5 | wps 96541.6 | wpb 3529.1 | bsz 62.9 | num_updates 35000 | best_loss 7.399
2024-07-31 22:24:16 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:24:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_35000.pt (epoch 3 @ 35000 updates, score 7.399) (writing took 6.542280470021069 seconds)
2024-07-31 22:24:38 | INFO | train_inner | epoch 003:   1052 / 17024 loss=7.162, nll_loss=6.157, ppl=71.34, wps=16907.1, ups=4.25, wpb=3978.4, bsz=172.4, num_updates=35100, lr=0.00016879, gnorm=0.844, train_wall=15, wall=0
2024-07-31 22:24:54 | INFO | train_inner | epoch 003:   1152 / 17024 loss=7.138, nll_loss=6.129, ppl=69.96, wps=25584.6, ups=6.46, wpb=3961.4, bsz=155.6, num_updates=35200, lr=0.00016855, gnorm=0.856, train_wall=15, wall=0
2024-07-31 22:25:09 | INFO | train_inner | epoch 003:   1252 / 17024 loss=7.137, nll_loss=6.128, ppl=69.92, wps=25710.4, ups=6.5, wpb=3955.6, bsz=150.6, num_updates=35300, lr=0.000168311, gnorm=0.852, train_wall=15, wall=0
2024-07-31 22:25:24 | INFO | train_inner | epoch 003:   1352 / 17024 loss=7.19, nll_loss=6.188, ppl=72.93, wps=25727.1, ups=6.51, wpb=3949.4, bsz=173.4, num_updates=35400, lr=0.000168073, gnorm=0.909, train_wall=15, wall=0
2024-07-31 22:25:40 | INFO | train_inner | epoch 003:   1452 / 17024 loss=7.182, nll_loss=6.179, ppl=72.44, wps=25562.6, ups=6.49, wpb=3940.4, bsz=179, num_updates=35500, lr=0.000167836, gnorm=0.926, train_wall=15, wall=0
2024-07-31 22:25:55 | INFO | train_inner | epoch 003:   1552 / 17024 loss=7.153, nll_loss=6.147, ppl=70.84, wps=25881, ups=6.52, wpb=3968.7, bsz=171.2, num_updates=35600, lr=0.0001676, gnorm=0.847, train_wall=15, wall=0
2024-07-31 22:26:11 | INFO | train_inner | epoch 003:   1652 / 17024 loss=7.125, nll_loss=6.114, ppl=69.24, wps=25560.3, ups=6.44, wpb=3968.4, bsz=159.8, num_updates=35700, lr=0.000167365, gnorm=0.861, train_wall=15, wall=0
2024-07-31 22:26:26 | INFO | train_inner | epoch 003:   1752 / 17024 loss=7.142, nll_loss=6.133, ppl=70.17, wps=25449.9, ups=6.41, wpb=3969.6, bsz=157.8, num_updates=35800, lr=0.000167132, gnorm=0.865, train_wall=15, wall=0
2024-07-31 22:26:42 | INFO | train_inner | epoch 003:   1852 / 17024 loss=7.11, nll_loss=6.096, ppl=68.42, wps=25487.3, ups=6.4, wpb=3984, bsz=160.2, num_updates=35900, lr=0.000166899, gnorm=0.832, train_wall=15, wall=0
2024-07-31 22:26:57 | INFO | train_inner | epoch 003:   1952 / 17024 loss=7.126, nll_loss=6.114, ppl=69.26, wps=25965.3, ups=6.53, wpb=3975.5, bsz=162.9, num_updates=36000, lr=0.000166667, gnorm=0.851, train_wall=15, wall=0
2024-07-31 22:26:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:26:59 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.41 | nll_loss 6.373 | ppl 82.9 | wps 94867 | wpb 3529.1 | bsz 62.9 | num_updates 36000 | best_loss 7.399
2024-07-31 22:26:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:27:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_36000.pt (epoch 3 @ 36000 updates, score 7.41) (writing took 3.1509213093668222 seconds)
2024-07-31 22:27:17 | INFO | train_inner | epoch 003:   2052 / 17024 loss=7.105, nll_loss=6.091, ppl=68.16, wps=19792.9, ups=4.99, wpb=3962.9, bsz=165.7, num_updates=36100, lr=0.000166436, gnorm=0.847, train_wall=15, wall=0
2024-07-31 22:27:33 | INFO | train_inner | epoch 003:   2152 / 17024 loss=7.152, nll_loss=6.145, ppl=70.77, wps=25848.7, ups=6.49, wpb=3985.7, bsz=173.8, num_updates=36200, lr=0.000166206, gnorm=0.843, train_wall=15, wall=0
2024-07-31 22:27:48 | INFO | train_inner | epoch 003:   2252 / 17024 loss=7.165, nll_loss=6.161, ppl=71.53, wps=25779.8, ups=6.5, wpb=3967.4, bsz=175.2, num_updates=36300, lr=0.000165977, gnorm=0.882, train_wall=15, wall=0
2024-07-31 22:28:04 | INFO | train_inner | epoch 003:   2352 / 17024 loss=7.172, nll_loss=6.168, ppl=71.91, wps=25610.7, ups=6.46, wpb=3967, bsz=176.7, num_updates=36400, lr=0.000165748, gnorm=0.871, train_wall=15, wall=0
2024-07-31 22:28:19 | INFO | train_inner | epoch 003:   2452 / 17024 loss=7.128, nll_loss=6.117, ppl=69.41, wps=25851.1, ups=6.53, wpb=3956.8, bsz=150.3, num_updates=36500, lr=0.000165521, gnorm=0.841, train_wall=15, wall=0
2024-07-31 22:28:34 | INFO | train_inner | epoch 003:   2552 / 17024 loss=7.163, nll_loss=6.157, ppl=71.38, wps=25666.8, ups=6.49, wpb=3954.6, bsz=169.9, num_updates=36600, lr=0.000165295, gnorm=0.875, train_wall=15, wall=0
2024-07-31 22:28:50 | INFO | train_inner | epoch 003:   2652 / 17024 loss=7.122, nll_loss=6.11, ppl=69.09, wps=25667.2, ups=6.5, wpb=3951.1, bsz=156, num_updates=36700, lr=0.00016507, gnorm=0.856, train_wall=15, wall=0
2024-07-31 22:29:05 | INFO | train_inner | epoch 003:   2752 / 17024 loss=7.15, nll_loss=6.142, ppl=70.61, wps=25529, ups=6.44, wpb=3962.7, bsz=158.4, num_updates=36800, lr=0.000164845, gnorm=0.862, train_wall=15, wall=0
2024-07-31 22:29:21 | INFO | train_inner | epoch 003:   2852 / 17024 loss=7.144, nll_loss=6.136, ppl=70.32, wps=25722.5, ups=6.49, wpb=3963.1, bsz=171.9, num_updates=36900, lr=0.000164622, gnorm=0.865, train_wall=15, wall=0
2024-07-31 22:29:36 | INFO | train_inner | epoch 003:   2952 / 17024 loss=7.122, nll_loss=6.111, ppl=69.11, wps=25723.4, ups=6.49, wpb=3966.5, bsz=156.1, num_updates=37000, lr=0.000164399, gnorm=0.854, train_wall=15, wall=0
2024-07-31 22:29:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:29:37 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.384 | nll_loss 6.343 | ppl 81.2 | wps 95474.8 | wpb 3529.1 | bsz 62.9 | num_updates 37000 | best_loss 7.384
2024-07-31 22:29:37 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:29:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_37000.pt (epoch 3 @ 37000 updates, score 7.384) (writing took 5.137864361517131 seconds)
2024-07-31 22:29:58 | INFO | train_inner | epoch 003:   3052 / 17024 loss=7.148, nll_loss=6.14, ppl=70.52, wps=18004, ups=4.54, wpb=3967.8, bsz=165.2, num_updates=37100, lr=0.000164177, gnorm=0.853, train_wall=15, wall=0
2024-07-31 22:30:14 | INFO | train_inner | epoch 003:   3152 / 17024 loss=7.161, nll_loss=6.156, ppl=71.29, wps=25383.2, ups=6.41, wpb=3957.4, bsz=170.7, num_updates=37200, lr=0.000163956, gnorm=0.872, train_wall=15, wall=0
2024-07-31 22:30:29 | INFO | train_inner | epoch 003:   3252 / 17024 loss=7.116, nll_loss=6.104, ppl=68.77, wps=25566.8, ups=6.47, wpb=3952.3, bsz=160.6, num_updates=37300, lr=0.000163737, gnorm=0.866, train_wall=15, wall=0
2024-07-31 22:30:45 | INFO | train_inner | epoch 003:   3352 / 17024 loss=7.144, nll_loss=6.136, ppl=70.34, wps=25671.5, ups=6.44, wpb=3983.8, bsz=183.7, num_updates=37400, lr=0.000163517, gnorm=0.861, train_wall=15, wall=0
2024-07-31 22:31:00 | INFO | train_inner | epoch 003:   3452 / 17024 loss=7.161, nll_loss=6.156, ppl=71.3, wps=25317.6, ups=6.39, wpb=3964, bsz=167.9, num_updates=37500, lr=0.000163299, gnorm=0.867, train_wall=15, wall=0
2024-07-31 22:31:16 | INFO | train_inner | epoch 003:   3552 / 17024 loss=7.085, nll_loss=6.068, ppl=67.09, wps=25491.6, ups=6.43, wpb=3961.9, bsz=149.1, num_updates=37600, lr=0.000163082, gnorm=0.843, train_wall=15, wall=0
2024-07-31 22:31:31 | INFO | train_inner | epoch 003:   3652 / 17024 loss=7.115, nll_loss=6.102, ppl=68.7, wps=25371.2, ups=6.43, wpb=3944, bsz=147.5, num_updates=37700, lr=0.000162866, gnorm=0.865, train_wall=15, wall=0
2024-07-31 22:31:47 | INFO | train_inner | epoch 003:   3752 / 17024 loss=7.139, nll_loss=6.131, ppl=70.06, wps=25671, ups=6.47, wpb=3968.2, bsz=167.9, num_updates=37800, lr=0.00016265, gnorm=0.862, train_wall=15, wall=0
2024-07-31 22:32:02 | INFO | train_inner | epoch 003:   3852 / 17024 loss=7.134, nll_loss=6.124, ppl=69.75, wps=25517.7, ups=6.51, wpb=3920.9, bsz=154.9, num_updates=37900, lr=0.000162435, gnorm=0.907, train_wall=15, wall=0
2024-07-31 22:32:18 | INFO | train_inner | epoch 003:   3952 / 17024 loss=7.137, nll_loss=6.127, ppl=69.9, wps=25858.7, ups=6.54, wpb=3951.8, bsz=159.5, num_updates=38000, lr=0.000162221, gnorm=0.87, train_wall=15, wall=0
2024-07-31 22:32:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:32:19 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.362 | nll_loss 6.322 | ppl 79.99 | wps 96355.3 | wpb 3529.1 | bsz 62.9 | num_updates 38000 | best_loss 7.362
2024-07-31 22:32:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:32:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_38000.pt (epoch 3 @ 38000 updates, score 7.362) (writing took 5.115477027371526 seconds)
2024-07-31 22:32:39 | INFO | train_inner | epoch 003:   4052 / 17024 loss=7.114, nll_loss=6.102, ppl=68.67, wps=18039.3, ups=4.55, wpb=3966.9, bsz=163.8, num_updates=38100, lr=0.000162008, gnorm=0.863, train_wall=15, wall=0
2024-07-31 22:32:55 | INFO | train_inner | epoch 003:   4152 / 17024 loss=7.105, nll_loss=6.091, ppl=68.16, wps=25578.9, ups=6.5, wpb=3936.3, bsz=156.2, num_updates=38200, lr=0.000161796, gnorm=0.88, train_wall=15, wall=0
2024-07-31 22:33:10 | INFO | train_inner | epoch 003:   4252 / 17024 loss=7.121, nll_loss=6.109, ppl=69.04, wps=25733, ups=6.54, wpb=3936.9, bsz=157, num_updates=38300, lr=0.000161585, gnorm=0.861, train_wall=15, wall=0
2024-07-31 22:33:26 | INFO | train_inner | epoch 003:   4352 / 17024 loss=7.128, nll_loss=6.117, ppl=69.39, wps=25571.6, ups=6.45, wpb=3965.9, bsz=170.3, num_updates=38400, lr=0.000161374, gnorm=0.893, train_wall=15, wall=0
2024-07-31 22:33:41 | INFO | train_inner | epoch 003:   4452 / 17024 loss=7.121, nll_loss=6.109, ppl=69.02, wps=25699.9, ups=6.51, wpb=3949.5, bsz=153.4, num_updates=38500, lr=0.000161165, gnorm=0.87, train_wall=15, wall=0
2024-07-31 22:33:57 | INFO | train_inner | epoch 003:   4552 / 17024 loss=7.167, nll_loss=6.163, ppl=71.67, wps=25603.7, ups=6.46, wpb=3964.9, bsz=181.1, num_updates=38600, lr=0.000160956, gnorm=0.868, train_wall=15, wall=0
2024-07-31 22:34:12 | INFO | train_inner | epoch 003:   4652 / 17024 loss=7.164, nll_loss=6.159, ppl=71.47, wps=25725.5, ups=6.49, wpb=3964.6, bsz=185.6, num_updates=38700, lr=0.000160748, gnorm=0.879, train_wall=15, wall=0
2024-07-31 22:34:27 | INFO | train_inner | epoch 003:   4752 / 17024 loss=7.112, nll_loss=6.099, ppl=68.53, wps=25603, ups=6.49, wpb=3946.5, bsz=158.1, num_updates=38800, lr=0.00016054, gnorm=0.865, train_wall=15, wall=0
2024-07-31 22:34:43 | INFO | train_inner | epoch 003:   4852 / 17024 loss=7.115, nll_loss=6.102, ppl=68.71, wps=25769.7, ups=6.5, wpb=3965.7, bsz=159.8, num_updates=38900, lr=0.000160334, gnorm=0.87, train_wall=15, wall=0
2024-07-31 22:34:58 | INFO | train_inner | epoch 003:   4952 / 17024 loss=7.14, nll_loss=6.132, ppl=70.13, wps=25675.1, ups=6.46, wpb=3971.6, bsz=175, num_updates=39000, lr=0.000160128, gnorm=0.865, train_wall=15, wall=0
2024-07-31 22:34:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:35:00 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.368 | nll_loss 6.329 | ppl 80.37 | wps 95997.8 | wpb 3529.1 | bsz 62.9 | num_updates 39000 | best_loss 7.362
2024-07-31 22:35:00 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:35:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_39000.pt (epoch 3 @ 39000 updates, score 7.368) (writing took 3.4460319532081485 seconds)
2024-07-31 22:35:19 | INFO | train_inner | epoch 003:   5052 / 17024 loss=7.097, nll_loss=6.082, ppl=67.75, wps=19486, ups=4.91, wpb=3970.6, bsz=151.8, num_updates=39100, lr=0.000159923, gnorm=0.843, train_wall=15, wall=0
2024-07-31 22:35:34 | INFO | train_inner | epoch 003:   5152 / 17024 loss=7.173, nll_loss=6.169, ppl=71.94, wps=25587.8, ups=6.47, wpb=3956.1, bsz=179.4, num_updates=39200, lr=0.000159719, gnorm=0.868, train_wall=15, wall=0
2024-07-31 22:35:49 | INFO | train_inner | epoch 003:   5252 / 17024 loss=7.105, nll_loss=6.09, ppl=68.12, wps=25704, ups=6.54, wpb=3929.4, bsz=147, num_updates=39300, lr=0.000159516, gnorm=0.868, train_wall=15, wall=0
2024-07-31 22:36:05 | INFO | train_inner | epoch 003:   5352 / 17024 loss=7.126, nll_loss=6.116, ppl=69.34, wps=25797.7, ups=6.48, wpb=3982.8, bsz=175.5, num_updates=39400, lr=0.000159313, gnorm=0.886, train_wall=15, wall=0
2024-07-31 22:36:20 | INFO | train_inner | epoch 003:   5452 / 17024 loss=7.122, nll_loss=6.111, ppl=69.11, wps=25678.7, ups=6.46, wpb=3977.8, bsz=158.4, num_updates=39500, lr=0.000159111, gnorm=0.844, train_wall=15, wall=0
2024-07-31 22:36:36 | INFO | train_inner | epoch 003:   5552 / 17024 loss=7.128, nll_loss=6.117, ppl=69.41, wps=25674.9, ups=6.51, wpb=3942.5, bsz=156.6, num_updates=39600, lr=0.00015891, gnorm=0.884, train_wall=15, wall=0
2024-07-31 22:36:51 | INFO | train_inner | epoch 003:   5652 / 17024 loss=7.153, nll_loss=6.146, ppl=70.82, wps=25512.7, ups=6.45, wpb=3958.5, bsz=174.2, num_updates=39700, lr=0.00015871, gnorm=0.914, train_wall=15, wall=0
2024-07-31 22:37:07 | INFO | train_inner | epoch 003:   5752 / 17024 loss=7.123, nll_loss=6.111, ppl=69.14, wps=25693.8, ups=6.49, wpb=3962, bsz=165.4, num_updates=39800, lr=0.000158511, gnorm=0.86, train_wall=15, wall=0
2024-07-31 22:37:22 | INFO | train_inner | epoch 003:   5852 / 17024 loss=7.153, nll_loss=6.147, ppl=70.84, wps=25464.8, ups=6.39, wpb=3983.8, bsz=174.7, num_updates=39900, lr=0.000158312, gnorm=0.883, train_wall=15, wall=0
2024-07-31 22:37:38 | INFO | train_inner | epoch 003:   5952 / 17024 loss=7.112, nll_loss=6.099, ppl=68.54, wps=25572.3, ups=6.47, wpb=3951, bsz=164.2, num_updates=40000, lr=0.000158114, gnorm=0.87, train_wall=15, wall=0
2024-07-31 22:37:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:37:39 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.352 | nll_loss 6.314 | ppl 79.54 | wps 96821.2 | wpb 3529.1 | bsz 62.9 | num_updates 40000 | best_loss 7.352
2024-07-31 22:37:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:37:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_40000.pt (epoch 3 @ 40000 updates, score 7.352) (writing took 5.747717031277716 seconds)
2024-07-31 22:38:00 | INFO | train_inner | epoch 003:   6052 / 17024 loss=7.13, nll_loss=6.121, ppl=69.58, wps=17526.1, ups=4.44, wpb=3944.9, bsz=170.1, num_updates=40100, lr=0.000157917, gnorm=0.867, train_wall=15, wall=0
2024-07-31 22:38:16 | INFO | train_inner | epoch 003:   6152 / 17024 loss=7.099, nll_loss=6.084, ppl=67.82, wps=25650.6, ups=6.46, wpb=3971, bsz=149.7, num_updates=40200, lr=0.00015772, gnorm=0.856, train_wall=15, wall=0
2024-07-31 22:38:31 | INFO | train_inner | epoch 003:   6252 / 17024 loss=7.143, nll_loss=6.135, ppl=70.27, wps=25702.6, ups=6.45, wpb=3982.8, bsz=180, num_updates=40300, lr=0.000157524, gnorm=0.897, train_wall=15, wall=0
2024-07-31 22:38:47 | INFO | train_inner | epoch 003:   6352 / 17024 loss=7.062, nll_loss=6.041, ppl=65.86, wps=25649.8, ups=6.48, wpb=3958, bsz=144.1, num_updates=40400, lr=0.000157329, gnorm=0.841, train_wall=15, wall=0
2024-07-31 22:39:02 | INFO | train_inner | epoch 003:   6452 / 17024 loss=7.123, nll_loss=6.112, ppl=69.15, wps=25550.3, ups=6.44, wpb=3969.7, bsz=166.6, num_updates=40500, lr=0.000157135, gnorm=0.88, train_wall=15, wall=0
2024-07-31 22:39:18 | INFO | train_inner | epoch 003:   6552 / 17024 loss=7.128, nll_loss=6.117, ppl=69.43, wps=25666.2, ups=6.46, wpb=3973.1, bsz=170.9, num_updates=40600, lr=0.000156941, gnorm=0.869, train_wall=15, wall=0
2024-07-31 22:39:33 | INFO | train_inner | epoch 003:   6652 / 17024 loss=7.132, nll_loss=6.122, ppl=69.66, wps=25545, ups=6.45, wpb=3960.1, bsz=166.9, num_updates=40700, lr=0.000156748, gnorm=0.86, train_wall=15, wall=0
2024-07-31 22:39:49 | INFO | train_inner | epoch 003:   6752 / 17024 loss=7.104, nll_loss=6.091, ppl=68.15, wps=25694.7, ups=6.46, wpb=3978.8, bsz=176.9, num_updates=40800, lr=0.000156556, gnorm=0.85, train_wall=15, wall=0
2024-07-31 22:40:04 | INFO | train_inner | epoch 003:   6852 / 17024 loss=7.13, nll_loss=6.119, ppl=69.51, wps=25815.5, ups=6.53, wpb=3955.5, bsz=169.8, num_updates=40900, lr=0.000156365, gnorm=0.878, train_wall=15, wall=0
2024-07-31 22:40:19 | INFO | train_inner | epoch 003:   6952 / 17024 loss=7.098, nll_loss=6.083, ppl=67.78, wps=25603.3, ups=6.43, wpb=3980.6, bsz=165.6, num_updates=41000, lr=0.000156174, gnorm=0.854, train_wall=15, wall=0
2024-07-31 22:40:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:40:21 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.358 | nll_loss 6.314 | ppl 79.57 | wps 96182.3 | wpb 3529.1 | bsz 62.9 | num_updates 41000 | best_loss 7.352
2024-07-31 22:40:21 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:40:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_41000.pt (epoch 3 @ 41000 updates, score 7.358) (writing took 3.155449381098151 seconds)
2024-07-31 22:40:40 | INFO | train_inner | epoch 003:   7052 / 17024 loss=7.13, nll_loss=6.119, ppl=69.5, wps=19754.2, ups=4.96, wpb=3980.6, bsz=172.5, num_updates=41100, lr=0.000155984, gnorm=0.884, train_wall=15, wall=0
2024-07-31 22:40:55 | INFO | train_inner | epoch 003:   7152 / 17024 loss=7.129, nll_loss=6.119, ppl=69.49, wps=25749.9, ups=6.53, wpb=3944.6, bsz=166.3, num_updates=41200, lr=0.000155794, gnorm=0.872, train_wall=15, wall=0
2024-07-31 22:41:10 | INFO | train_inner | epoch 003:   7252 / 17024 loss=7.13, nll_loss=6.119, ppl=69.52, wps=25627.3, ups=6.48, wpb=3956.1, bsz=165.2, num_updates=41300, lr=0.000155606, gnorm=0.87, train_wall=15, wall=0
2024-07-31 22:41:26 | INFO | train_inner | epoch 003:   7352 / 17024 loss=7.097, nll_loss=6.082, ppl=67.73, wps=25717.7, ups=6.47, wpb=3975.8, bsz=166.6, num_updates=41400, lr=0.000155417, gnorm=0.863, train_wall=15, wall=0
2024-07-31 22:41:41 | INFO | train_inner | epoch 003:   7452 / 17024 loss=7.123, nll_loss=6.111, ppl=69.14, wps=25466.9, ups=6.41, wpb=3973.3, bsz=162.2, num_updates=41500, lr=0.00015523, gnorm=0.878, train_wall=15, wall=0
2024-07-31 22:41:57 | INFO | train_inner | epoch 003:   7552 / 17024 loss=7.103, nll_loss=6.089, ppl=68.06, wps=25588.4, ups=6.46, wpb=3962.9, bsz=155.1, num_updates=41600, lr=0.000155043, gnorm=0.88, train_wall=15, wall=0
2024-07-31 22:42:12 | INFO | train_inner | epoch 003:   7652 / 17024 loss=7.147, nll_loss=6.139, ppl=70.48, wps=25413.6, ups=6.47, wpb=3926.9, bsz=160, num_updates=41700, lr=0.000154857, gnorm=0.876, train_wall=15, wall=0
2024-07-31 22:42:28 | INFO | train_inner | epoch 003:   7752 / 17024 loss=7.179, nll_loss=6.177, ppl=72.34, wps=25592.7, ups=6.45, wpb=3966.9, bsz=186.6, num_updates=41800, lr=0.000154672, gnorm=0.87, train_wall=15, wall=0
2024-07-31 22:42:43 | INFO | train_inner | epoch 003:   7852 / 17024 loss=7.083, nll_loss=6.066, ppl=67, wps=25651.2, ups=6.48, wpb=3956.8, bsz=155.4, num_updates=41900, lr=0.000154487, gnorm=0.859, train_wall=15, wall=0
2024-07-31 22:42:59 | INFO | train_inner | epoch 003:   7952 / 17024 loss=7.141, nll_loss=6.132, ppl=70.14, wps=25641.9, ups=6.48, wpb=3955.7, bsz=169.1, num_updates=42000, lr=0.000154303, gnorm=0.894, train_wall=15, wall=0
2024-07-31 22:42:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:43:00 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.363 | nll_loss 6.323 | ppl 80.06 | wps 95596.9 | wpb 3529.1 | bsz 62.9 | num_updates 42000 | best_loss 7.352
2024-07-31 22:43:00 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:43:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_42000.pt (epoch 3 @ 42000 updates, score 7.363) (writing took 2.9161473708227277 seconds)
2024-07-31 22:43:19 | INFO | train_inner | epoch 003:   8052 / 17024 loss=7.138, nll_loss=6.129, ppl=70, wps=20004.9, ups=5.05, wpb=3959.6, bsz=166.9, num_updates=42100, lr=0.00015412, gnorm=0.911, train_wall=15, wall=0
2024-07-31 22:43:34 | INFO | train_inner | epoch 003:   8152 / 17024 loss=7.128, nll_loss=6.117, ppl=69.43, wps=25679.2, ups=6.45, wpb=3979.4, bsz=171.4, num_updates=42200, lr=0.000153937, gnorm=0.856, train_wall=15, wall=0
2024-07-31 22:43:49 | INFO | train_inner | epoch 003:   8252 / 17024 loss=7.11, nll_loss=6.097, ppl=68.43, wps=25899.1, ups=6.53, wpb=3968.5, bsz=158, num_updates=42300, lr=0.000153755, gnorm=0.876, train_wall=15, wall=0
2024-07-31 22:44:05 | INFO | train_inner | epoch 003:   8352 / 17024 loss=7.076, nll_loss=6.058, ppl=66.62, wps=25727.9, ups=6.49, wpb=3964.2, bsz=153.4, num_updates=42400, lr=0.000153574, gnorm=0.877, train_wall=15, wall=0
2024-07-31 22:44:20 | INFO | train_inner | epoch 003:   8452 / 17024 loss=7.14, nll_loss=6.132, ppl=70.12, wps=25583.8, ups=6.44, wpb=3972.6, bsz=176.3, num_updates=42500, lr=0.000153393, gnorm=0.883, train_wall=15, wall=0
2024-07-31 22:44:36 | INFO | train_inner | epoch 003:   8552 / 17024 loss=7.124, nll_loss=6.113, ppl=69.22, wps=25582.9, ups=6.46, wpb=3961.9, bsz=172.2, num_updates=42600, lr=0.000153213, gnorm=0.857, train_wall=15, wall=0
2024-07-31 22:44:51 | INFO | train_inner | epoch 003:   8652 / 17024 loss=7.149, nll_loss=6.141, ppl=70.58, wps=25706.2, ups=6.49, wpb=3963.6, bsz=177.7, num_updates=42700, lr=0.000153033, gnorm=0.901, train_wall=15, wall=0
2024-07-31 22:45:07 | INFO | train_inner | epoch 003:   8752 / 17024 loss=7.069, nll_loss=6.05, ppl=66.27, wps=25550.4, ups=6.43, wpb=3971.4, bsz=146.2, num_updates=42800, lr=0.000152854, gnorm=0.85, train_wall=15, wall=0
2024-07-31 22:45:22 | INFO | train_inner | epoch 003:   8852 / 17024 loss=7.085, nll_loss=6.068, ppl=67.07, wps=25547.9, ups=6.44, wpb=3966.4, bsz=156.5, num_updates=42900, lr=0.000152676, gnorm=0.859, train_wall=15, wall=0
2024-07-31 22:45:38 | INFO | train_inner | epoch 003:   8952 / 17024 loss=7.131, nll_loss=6.121, ppl=69.59, wps=25645.9, ups=6.45, wpb=3974.8, bsz=187, num_updates=43000, lr=0.000152499, gnorm=0.884, train_wall=15, wall=0
2024-07-31 22:45:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:45:39 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.364 | nll_loss 6.323 | ppl 80.08 | wps 94819.5 | wpb 3529.1 | bsz 62.9 | num_updates 43000 | best_loss 7.352
2024-07-31 22:45:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:45:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_43000.pt (epoch 3 @ 43000 updates, score 7.364) (writing took 3.330459052696824 seconds)
2024-07-31 22:45:58 | INFO | train_inner | epoch 003:   9052 / 17024 loss=7.13, nll_loss=6.119, ppl=69.5, wps=19528.8, ups=4.93, wpb=3960, bsz=166.6, num_updates=43100, lr=0.000152322, gnorm=0.907, train_wall=15, wall=0
2024-07-31 22:46:14 | INFO | train_inner | epoch 003:   9152 / 17024 loss=7.108, nll_loss=6.095, ppl=68.35, wps=25646.4, ups=6.44, wpb=3983.8, bsz=168.3, num_updates=43200, lr=0.000152145, gnorm=0.868, train_wall=15, wall=0
2024-07-31 22:46:29 | INFO | train_inner | epoch 003:   9252 / 17024 loss=7.087, nll_loss=6.071, ppl=67.23, wps=25604.4, ups=6.44, wpb=3975, bsz=165.7, num_updates=43300, lr=0.000151969, gnorm=0.851, train_wall=15, wall=0
2024-07-31 22:46:45 | INFO | train_inner | epoch 003:   9352 / 17024 loss=7.083, nll_loss=6.065, ppl=66.95, wps=25568.7, ups=6.45, wpb=3963.4, bsz=153.4, num_updates=43400, lr=0.000151794, gnorm=0.861, train_wall=15, wall=0
2024-07-31 22:47:00 | INFO | train_inner | epoch 003:   9452 / 17024 loss=7.12, nll_loss=6.109, ppl=69.03, wps=25525, ups=6.47, wpb=3945.7, bsz=171.8, num_updates=43500, lr=0.00015162, gnorm=0.898, train_wall=15, wall=0
2024-07-31 22:47:15 | INFO | train_inner | epoch 003:   9552 / 17024 loss=7.111, nll_loss=6.098, ppl=68.51, wps=25656.9, ups=6.49, wpb=3954.9, bsz=162.4, num_updates=43600, lr=0.000151446, gnorm=0.881, train_wall=15, wall=0
2024-07-31 22:47:31 | INFO | train_inner | epoch 003:   9652 / 17024 loss=7.143, nll_loss=6.134, ppl=70.23, wps=25628.5, ups=6.48, wpb=3953.8, bsz=172.2, num_updates=43700, lr=0.000151272, gnorm=0.931, train_wall=15, wall=0
2024-07-31 22:47:46 | INFO | train_inner | epoch 003:   9752 / 17024 loss=7.113, nll_loss=6.101, ppl=68.63, wps=25731.3, ups=6.54, wpb=3937.2, bsz=163.4, num_updates=43800, lr=0.000151099, gnorm=0.887, train_wall=15, wall=0
2024-07-31 22:48:02 | INFO | train_inner | epoch 003:   9852 / 17024 loss=7.155, nll_loss=6.149, ppl=70.95, wps=25501.4, ups=6.45, wpb=3955.8, bsz=177.1, num_updates=43900, lr=0.000150927, gnorm=0.889, train_wall=15, wall=0
2024-07-31 22:48:17 | INFO | train_inner | epoch 003:   9952 / 17024 loss=7.094, nll_loss=6.077, ppl=67.52, wps=25528.1, ups=6.49, wpb=3933.2, bsz=152, num_updates=44000, lr=0.000150756, gnorm=0.884, train_wall=15, wall=0
2024-07-31 22:48:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:48:19 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.337 | nll_loss 6.298 | ppl 78.67 | wps 96940.7 | wpb 3529.1 | bsz 62.9 | num_updates 44000 | best_loss 7.337
2024-07-31 22:48:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:48:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_44000.pt (epoch 3 @ 44000 updates, score 7.337) (writing took 4.759094179607928 seconds)
2024-07-31 22:48:39 | INFO | train_inner | epoch 003:  10052 / 17024 loss=7.102, nll_loss=6.087, ppl=68, wps=18334.9, ups=4.62, wpb=3967.9, bsz=163.7, num_updates=44100, lr=0.000150585, gnorm=0.865, train_wall=15, wall=0
2024-07-31 22:48:54 | INFO | train_inner | epoch 003:  10152 / 17024 loss=7.127, nll_loss=6.116, ppl=69.37, wps=25641.1, ups=6.45, wpb=3973.9, bsz=179.4, num_updates=44200, lr=0.000150414, gnorm=0.902, train_wall=15, wall=0
2024-07-31 22:49:10 | INFO | train_inner | epoch 003:  10252 / 17024 loss=7.09, nll_loss=6.074, ppl=67.38, wps=25593.9, ups=6.45, wpb=3968.5, bsz=154.1, num_updates=44300, lr=0.000150244, gnorm=0.847, train_wall=15, wall=0
2024-07-31 22:49:25 | INFO | train_inner | epoch 003:  10352 / 17024 loss=7.073, nll_loss=6.055, ppl=66.5, wps=25754, ups=6.44, wpb=3997.4, bsz=173.1, num_updates=44400, lr=0.000150075, gnorm=0.851, train_wall=15, wall=0
2024-07-31 22:49:41 | INFO | train_inner | epoch 003:  10452 / 17024 loss=7.086, nll_loss=6.069, ppl=67.16, wps=25986.7, ups=6.52, wpb=3987.8, bsz=162.1, num_updates=44500, lr=0.000149906, gnorm=0.858, train_wall=15, wall=0
2024-07-31 22:49:56 | INFO | train_inner | epoch 003:  10552 / 17024 loss=7.11, nll_loss=6.097, ppl=68.45, wps=25499, ups=6.46, wpb=3946.6, bsz=171.4, num_updates=44600, lr=0.000149738, gnorm=0.893, train_wall=15, wall=0
2024-07-31 22:50:12 | INFO | train_inner | epoch 003:  10652 / 17024 loss=7.108, nll_loss=6.095, ppl=68.38, wps=25456.4, ups=6.43, wpb=3956.2, bsz=170.1, num_updates=44700, lr=0.000149571, gnorm=0.883, train_wall=15, wall=0
2024-07-31 22:50:27 | INFO | train_inner | epoch 003:  10752 / 17024 loss=7.072, nll_loss=6.053, ppl=66.39, wps=25682, ups=6.47, wpb=3969.4, bsz=151.4, num_updates=44800, lr=0.000149404, gnorm=0.886, train_wall=15, wall=0
2024-07-31 22:50:43 | INFO | train_inner | epoch 003:  10852 / 17024 loss=7.108, nll_loss=6.095, ppl=68.35, wps=25684.6, ups=6.49, wpb=3957.5, bsz=161.4, num_updates=44900, lr=0.000149237, gnorm=0.871, train_wall=15, wall=0
2024-07-31 22:50:58 | INFO | train_inner | epoch 003:  10952 / 17024 loss=7.083, nll_loss=6.066, ppl=67.01, wps=25542.9, ups=6.45, wpb=3962.8, bsz=160, num_updates=45000, lr=0.000149071, gnorm=0.874, train_wall=15, wall=0
2024-07-31 22:50:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:50:59 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.345 | nll_loss 6.301 | ppl 78.82 | wps 96349.9 | wpb 3529.1 | bsz 62.9 | num_updates 45000 | best_loss 7.337
2024-07-31 22:50:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:51:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_45000.pt (epoch 3 @ 45000 updates, score 7.345) (writing took 3.127730925567448 seconds)
2024-07-31 22:51:18 | INFO | train_inner | epoch 003:  11052 / 17024 loss=7.079, nll_loss=6.061, ppl=66.76, wps=19710.7, ups=4.97, wpb=3963, bsz=153.1, num_updates=45100, lr=0.000148906, gnorm=0.877, train_wall=15, wall=0
2024-07-31 22:51:34 | INFO | train_inner | epoch 003:  11152 / 17024 loss=7.086, nll_loss=6.07, ppl=67.16, wps=25566.9, ups=6.44, wpb=3971.8, bsz=162.9, num_updates=45200, lr=0.000148741, gnorm=0.868, train_wall=15, wall=0
2024-07-31 22:51:49 | INFO | train_inner | epoch 003:  11252 / 17024 loss=7.062, nll_loss=6.041, ppl=65.85, wps=25629.8, ups=6.47, wpb=3959.7, bsz=143.6, num_updates=45300, lr=0.000148577, gnorm=0.864, train_wall=15, wall=0
2024-07-31 22:52:05 | INFO | train_inner | epoch 003:  11352 / 17024 loss=7.063, nll_loss=6.042, ppl=65.91, wps=25678.9, ups=6.49, wpb=3958.8, bsz=142.2, num_updates=45400, lr=0.000148413, gnorm=0.873, train_wall=15, wall=0
2024-07-31 22:52:20 | INFO | train_inner | epoch 003:  11452 / 17024 loss=7.134, nll_loss=6.123, ppl=69.71, wps=25638.7, ups=6.44, wpb=3981.8, bsz=173.9, num_updates=45500, lr=0.00014825, gnorm=0.893, train_wall=15, wall=0
2024-07-31 22:52:36 | INFO | train_inner | epoch 003:  11552 / 17024 loss=7.069, nll_loss=6.05, ppl=66.24, wps=25669.2, ups=6.49, wpb=3955.6, bsz=156.7, num_updates=45600, lr=0.000148087, gnorm=0.885, train_wall=15, wall=0
2024-07-31 22:52:51 | INFO | train_inner | epoch 003:  11652 / 17024 loss=7.126, nll_loss=6.116, ppl=69.34, wps=25735, ups=6.47, wpb=3976, bsz=186.2, num_updates=45700, lr=0.000147925, gnorm=0.907, train_wall=15, wall=0
2024-07-31 22:53:06 | INFO | train_inner | epoch 003:  11752 / 17024 loss=7.095, nll_loss=6.079, ppl=67.59, wps=25618.2, ups=6.49, wpb=3949.1, bsz=148.9, num_updates=45800, lr=0.000147764, gnorm=0.874, train_wall=15, wall=0
2024-07-31 22:53:22 | INFO | train_inner | epoch 003:  11852 / 17024 loss=7.12, nll_loss=6.109, ppl=69.01, wps=25716.2, ups=6.47, wpb=3973.5, bsz=161.7, num_updates=45900, lr=0.000147602, gnorm=0.885, train_wall=15, wall=0
2024-07-31 22:53:37 | INFO | train_inner | epoch 003:  11952 / 17024 loss=7.126, nll_loss=6.115, ppl=69.31, wps=25618.2, ups=6.5, wpb=3938.8, bsz=156.8, num_updates=46000, lr=0.000147442, gnorm=0.903, train_wall=15, wall=0
2024-07-31 22:53:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:53:39 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.342 | nll_loss 6.299 | ppl 78.74 | wps 94194.2 | wpb 3529.1 | bsz 62.9 | num_updates 46000 | best_loss 7.337
2024-07-31 22:53:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:53:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_46000.pt (epoch 3 @ 46000 updates, score 7.342) (writing took 4.500332223251462 seconds)
2024-07-31 22:53:59 | INFO | train_inner | epoch 003:  12052 / 17024 loss=7.079, nll_loss=6.061, ppl=66.77, wps=18505.3, ups=4.65, wpb=3983.7, bsz=169.1, num_updates=46100, lr=0.000147282, gnorm=0.886, train_wall=15, wall=0
2024-07-31 22:54:14 | INFO | train_inner | epoch 003:  12152 / 17024 loss=7.077, nll_loss=6.058, ppl=66.61, wps=25606.6, ups=6.53, wpb=3923.6, bsz=149, num_updates=46200, lr=0.000147122, gnorm=0.877, train_wall=15, wall=0
2024-07-31 22:54:29 | INFO | train_inner | epoch 003:  12252 / 17024 loss=7.058, nll_loss=6.037, ppl=65.68, wps=25847.8, ups=6.54, wpb=3950.6, bsz=158.1, num_updates=46300, lr=0.000146964, gnorm=0.868, train_wall=15, wall=0
2024-07-31 22:54:45 | INFO | train_inner | epoch 003:  12352 / 17024 loss=7.088, nll_loss=6.071, ppl=67.25, wps=25814.3, ups=6.51, wpb=3967.2, bsz=154.6, num_updates=46400, lr=0.000146805, gnorm=0.869, train_wall=15, wall=0
2024-07-31 22:55:00 | INFO | train_inner | epoch 003:  12452 / 17024 loss=7.093, nll_loss=6.078, ppl=67.54, wps=25665.7, ups=6.47, wpb=3968.9, bsz=165.5, num_updates=46500, lr=0.000146647, gnorm=0.877, train_wall=15, wall=0
2024-07-31 22:55:16 | INFO | train_inner | epoch 003:  12552 / 17024 loss=7.058, nll_loss=6.037, ppl=65.66, wps=25495.6, ups=6.4, wpb=3984, bsz=168.8, num_updates=46600, lr=0.00014649, gnorm=0.872, train_wall=15, wall=0
2024-07-31 22:55:31 | INFO | train_inner | epoch 003:  12652 / 17024 loss=7.066, nll_loss=6.046, ppl=66.09, wps=25585.3, ups=6.46, wpb=3960.2, bsz=156.8, num_updates=46700, lr=0.000146333, gnorm=0.895, train_wall=15, wall=0
2024-07-31 22:55:47 | INFO | train_inner | epoch 003:  12752 / 17024 loss=7.119, nll_loss=6.107, ppl=68.93, wps=25661.6, ups=6.52, wpb=3937.2, bsz=163.2, num_updates=46800, lr=0.000146176, gnorm=0.915, train_wall=15, wall=0
2024-07-31 22:56:02 | INFO | train_inner | epoch 003:  12852 / 17024 loss=7.124, nll_loss=6.113, ppl=69.22, wps=25847, ups=6.57, wpb=3936, bsz=160.2, num_updates=46900, lr=0.00014602, gnorm=0.908, train_wall=15, wall=0
2024-07-31 22:56:17 | INFO | train_inner | epoch 003:  12952 / 17024 loss=7.056, nll_loss=6.035, ppl=65.57, wps=25728.3, ups=6.48, wpb=3972.9, bsz=162.2, num_updates=47000, lr=0.000145865, gnorm=0.873, train_wall=15, wall=0
2024-07-31 22:56:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:56:19 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.345 | nll_loss 6.3 | ppl 78.8 | wps 93911.7 | wpb 3529.1 | bsz 62.9 | num_updates 47000 | best_loss 7.337
2024-07-31 22:56:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:56:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_47000.pt (epoch 3 @ 47000 updates, score 7.345) (writing took 3.2022971492260695 seconds)
2024-07-31 22:56:37 | INFO | train_inner | epoch 003:  13052 / 17024 loss=7.07, nll_loss=6.051, ppl=66.29, wps=19779.4, ups=5.01, wpb=3946.1, bsz=144.3, num_updates=47100, lr=0.00014571, gnorm=0.88, train_wall=15, wall=0
2024-07-31 22:56:53 | INFO | train_inner | epoch 003:  13152 / 17024 loss=7.066, nll_loss=6.047, ppl=66.13, wps=25714.5, ups=6.51, wpb=3950.9, bsz=159, num_updates=47200, lr=0.000145556, gnorm=0.888, train_wall=15, wall=0
2024-07-31 22:57:08 | INFO | train_inner | epoch 003:  13252 / 17024 loss=7.089, nll_loss=6.073, ppl=67.34, wps=25631, ups=6.5, wpb=3946.1, bsz=156.8, num_updates=47300, lr=0.000145402, gnorm=0.884, train_wall=15, wall=0
2024-07-31 22:57:23 | INFO | train_inner | epoch 003:  13352 / 17024 loss=7.1, nll_loss=6.086, ppl=67.95, wps=25663.1, ups=6.49, wpb=3952.5, bsz=160.2, num_updates=47400, lr=0.000145248, gnorm=0.885, train_wall=15, wall=0
2024-07-31 22:57:39 | INFO | train_inner | epoch 003:  13452 / 17024 loss=7.054, nll_loss=6.032, ppl=65.44, wps=25634.9, ups=6.45, wpb=3974, bsz=158.5, num_updates=47500, lr=0.000145095, gnorm=0.89, train_wall=15, wall=0
2024-07-31 22:57:54 | INFO | train_inner | epoch 003:  13552 / 17024 loss=7.034, nll_loss=6.008, ppl=64.37, wps=25656.3, ups=6.5, wpb=3945.3, bsz=137.8, num_updates=47600, lr=0.000144943, gnorm=0.86, train_wall=15, wall=0
2024-07-31 22:58:10 | INFO | train_inner | epoch 003:  13652 / 17024 loss=7.119, nll_loss=6.108, ppl=68.98, wps=25652.3, ups=6.48, wpb=3961.6, bsz=174.7, num_updates=47700, lr=0.000144791, gnorm=0.93, train_wall=15, wall=0
2024-07-31 22:58:25 | INFO | train_inner | epoch 003:  13752 / 17024 loss=7.087, nll_loss=6.071, ppl=67.21, wps=25613.5, ups=6.46, wpb=3967.8, bsz=158.9, num_updates=47800, lr=0.000144639, gnorm=0.885, train_wall=15, wall=0
2024-07-31 22:58:41 | INFO | train_inner | epoch 003:  13852 / 17024 loss=7.123, nll_loss=6.113, ppl=69.22, wps=25548.2, ups=6.44, wpb=3967.8, bsz=180.4, num_updates=47900, lr=0.000144488, gnorm=0.909, train_wall=15, wall=0
2024-07-31 22:58:56 | INFO | train_inner | epoch 003:  13952 / 17024 loss=7.088, nll_loss=6.073, ppl=67.32, wps=25692.5, ups=6.47, wpb=3969.5, bsz=176.6, num_updates=48000, lr=0.000144338, gnorm=0.873, train_wall=15, wall=0
2024-07-31 22:58:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 22:58:58 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.338 | nll_loss 6.293 | ppl 78.41 | wps 95960.1 | wpb 3529.1 | bsz 62.9 | num_updates 48000 | best_loss 7.337
2024-07-31 22:58:58 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 22:59:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_48000.pt (epoch 3 @ 48000 updates, score 7.338) (writing took 2.8850018261000514 seconds)
2024-07-31 22:59:16 | INFO | train_inner | epoch 003:  14052 / 17024 loss=7.088, nll_loss=6.072, ppl=67.27, wps=20078, ups=5.05, wpb=3979.1, bsz=174.7, num_updates=48100, lr=0.000144187, gnorm=0.88, train_wall=15, wall=0
2024-07-31 22:59:31 | INFO | train_inner | epoch 003:  14152 / 17024 loss=7.058, nll_loss=6.037, ppl=65.68, wps=25631.4, ups=6.48, wpb=3954.4, bsz=150.1, num_updates=48200, lr=0.000144038, gnorm=0.874, train_wall=15, wall=0
2024-07-31 22:59:47 | INFO | train_inner | epoch 003:  14252 / 17024 loss=7.091, nll_loss=6.076, ppl=67.46, wps=25621.8, ups=6.47, wpb=3957.8, bsz=172.6, num_updates=48300, lr=0.000143889, gnorm=0.887, train_wall=15, wall=0
2024-07-31 23:00:02 | INFO | train_inner | epoch 003:  14352 / 17024 loss=7.059, nll_loss=6.038, ppl=65.7, wps=25657.8, ups=6.44, wpb=3984.9, bsz=161.6, num_updates=48400, lr=0.00014374, gnorm=0.874, train_wall=15, wall=0
2024-07-31 23:00:18 | INFO | train_inner | epoch 003:  14452 / 17024 loss=7.059, nll_loss=6.038, ppl=65.73, wps=25693.9, ups=6.46, wpb=3978.1, bsz=146.6, num_updates=48500, lr=0.000143592, gnorm=0.867, train_wall=15, wall=0
2024-07-31 23:00:33 | INFO | train_inner | epoch 003:  14552 / 17024 loss=7.091, nll_loss=6.075, ppl=67.41, wps=25633.3, ups=6.48, wpb=3956.9, bsz=165.4, num_updates=48600, lr=0.000143444, gnorm=0.886, train_wall=15, wall=0
2024-07-31 23:00:49 | INFO | train_inner | epoch 003:  14652 / 17024 loss=7.114, nll_loss=6.102, ppl=68.68, wps=25613.2, ups=6.44, wpb=3975.4, bsz=177.9, num_updates=48700, lr=0.000143296, gnorm=0.9, train_wall=15, wall=0
2024-07-31 23:01:04 | INFO | train_inner | epoch 003:  14752 / 17024 loss=7.062, nll_loss=6.043, ppl=65.93, wps=25377.5, ups=6.44, wpb=3943.6, bsz=163.8, num_updates=48800, lr=0.00014315, gnorm=0.877, train_wall=15, wall=0
2024-07-31 23:01:20 | INFO | train_inner | epoch 003:  14852 / 17024 loss=7.054, nll_loss=6.032, ppl=65.45, wps=25443.8, ups=6.45, wpb=3947.4, bsz=162.5, num_updates=48900, lr=0.000143003, gnorm=0.883, train_wall=15, wall=0
2024-07-31 23:01:35 | INFO | train_inner | epoch 003:  14952 / 17024 loss=7.039, nll_loss=6.016, ppl=64.69, wps=25586.3, ups=6.47, wpb=3956.9, bsz=154.1, num_updates=49000, lr=0.000142857, gnorm=0.873, train_wall=15, wall=0
2024-07-31 23:01:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:01:37 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.323 | nll_loss 6.278 | ppl 77.61 | wps 95295 | wpb 3529.1 | bsz 62.9 | num_updates 49000 | best_loss 7.323
2024-07-31 23:01:37 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:01:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_49000.pt (epoch 3 @ 49000 updates, score 7.323) (writing took 4.676214992068708 seconds)
2024-07-31 23:01:57 | INFO | train_inner | epoch 003:  15052 / 17024 loss=7.081, nll_loss=6.063, ppl=66.85, wps=18302.1, ups=4.68, wpb=3914.5, bsz=148.4, num_updates=49100, lr=0.000142712, gnorm=0.915, train_wall=15, wall=0
2024-07-31 23:02:12 | INFO | train_inner | epoch 003:  15152 / 17024 loss=7.104, nll_loss=6.09, ppl=68.13, wps=25674.3, ups=6.5, wpb=3947.7, bsz=164.2, num_updates=49200, lr=0.000142566, gnorm=0.898, train_wall=15, wall=0
2024-07-31 23:02:28 | INFO | train_inner | epoch 003:  15252 / 17024 loss=7.084, nll_loss=6.067, ppl=67.05, wps=25643.5, ups=6.48, wpb=3956.2, bsz=165.8, num_updates=49300, lr=0.000142422, gnorm=0.888, train_wall=15, wall=0
2024-07-31 23:02:43 | INFO | train_inner | epoch 003:  15352 / 17024 loss=7.106, nll_loss=6.093, ppl=68.26, wps=25672.5, ups=6.49, wpb=3954.3, bsz=170.2, num_updates=49400, lr=0.000142278, gnorm=0.911, train_wall=15, wall=0
2024-07-31 23:02:58 | INFO | train_inner | epoch 003:  15452 / 17024 loss=7.086, nll_loss=6.07, ppl=67.19, wps=25700.6, ups=6.51, wpb=3946.8, bsz=162.1, num_updates=49500, lr=0.000142134, gnorm=0.891, train_wall=15, wall=0
2024-07-31 23:03:14 | INFO | train_inner | epoch 003:  15552 / 17024 loss=7.057, nll_loss=6.036, ppl=65.62, wps=25736.2, ups=6.5, wpb=3960.1, bsz=151, num_updates=49600, lr=0.00014199, gnorm=0.876, train_wall=15, wall=0
2024-07-31 23:03:29 | INFO | train_inner | epoch 003:  15652 / 17024 loss=7.078, nll_loss=6.061, ppl=66.77, wps=25618.5, ups=6.45, wpb=3972.7, bsz=173.1, num_updates=49700, lr=0.000141848, gnorm=0.877, train_wall=15, wall=0
2024-07-31 23:03:45 | INFO | train_inner | epoch 003:  15752 / 17024 loss=7.083, nll_loss=6.065, ppl=66.95, wps=25357, ups=6.45, wpb=3931.6, bsz=159.8, num_updates=49800, lr=0.000141705, gnorm=0.925, train_wall=15, wall=0
2024-07-31 23:04:00 | INFO | train_inner | epoch 003:  15852 / 17024 loss=7.038, nll_loss=6.014, ppl=64.63, wps=25530.4, ups=6.41, wpb=3981.7, bsz=151.8, num_updates=49900, lr=0.000141563, gnorm=0.871, train_wall=15, wall=0
2024-07-31 23:04:16 | INFO | train_inner | epoch 003:  15952 / 17024 loss=7.068, nll_loss=6.049, ppl=66.22, wps=25498.2, ups=6.45, wpb=3955, bsz=165.5, num_updates=50000, lr=0.000141421, gnorm=0.89, train_wall=15, wall=0
2024-07-31 23:04:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:04:17 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.326 | nll_loss 6.281 | ppl 77.74 | wps 94569.8 | wpb 3529.1 | bsz 62.9 | num_updates 50000 | best_loss 7.323
2024-07-31 23:04:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:04:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_50000.pt (epoch 3 @ 50000 updates, score 7.326) (writing took 2.8854836113750935 seconds)
2024-07-31 23:04:36 | INFO | train_inner | epoch 003:  16052 / 17024 loss=7.053, nll_loss=6.031, ppl=65.39, wps=19859.1, ups=5.03, wpb=3946.7, bsz=158.7, num_updates=50100, lr=0.00014128, gnorm=0.899, train_wall=15, wall=0
2024-07-31 23:04:51 | INFO | train_inner | epoch 003:  16152 / 17024 loss=7.105, nll_loss=6.091, ppl=68.19, wps=25422.4, ups=6.41, wpb=3966.6, bsz=172.3, num_updates=50200, lr=0.000141139, gnorm=0.905, train_wall=15, wall=0
2024-07-31 23:05:07 | INFO | train_inner | epoch 003:  16252 / 17024 loss=7.087, nll_loss=6.071, ppl=67.23, wps=25177.7, ups=6.38, wpb=3944.8, bsz=167.4, num_updates=50300, lr=0.000140999, gnorm=0.91, train_wall=15, wall=0
2024-07-31 23:05:22 | INFO | train_inner | epoch 003:  16352 / 17024 loss=7.034, nll_loss=6.01, ppl=64.43, wps=25773.8, ups=6.52, wpb=3954, bsz=150.2, num_updates=50400, lr=0.000140859, gnorm=0.862, train_wall=15, wall=0
2024-07-31 23:05:38 | INFO | train_inner | epoch 003:  16452 / 17024 loss=7.092, nll_loss=6.077, ppl=67.5, wps=25475.9, ups=6.44, wpb=3955.6, bsz=175.3, num_updates=50500, lr=0.00014072, gnorm=0.894, train_wall=15, wall=0
2024-07-31 23:05:53 | INFO | train_inner | epoch 003:  16552 / 17024 loss=7.121, nll_loss=6.11, ppl=69.09, wps=25611.6, ups=6.46, wpb=3965.1, bsz=179.1, num_updates=50600, lr=0.00014058, gnorm=0.912, train_wall=15, wall=0
2024-07-31 23:06:09 | INFO | train_inner | epoch 003:  16652 / 17024 loss=7.043, nll_loss=6.02, ppl=64.91, wps=25994.4, ups=6.56, wpb=3962.5, bsz=154.8, num_updates=50700, lr=0.000140442, gnorm=0.875, train_wall=15, wall=0
2024-07-31 23:06:24 | INFO | train_inner | epoch 003:  16752 / 17024 loss=7.06, nll_loss=6.04, ppl=65.79, wps=25691, ups=6.52, wpb=3943, bsz=157.8, num_updates=50800, lr=0.000140303, gnorm=0.874, train_wall=15, wall=0
2024-07-31 23:06:39 | INFO | train_inner | epoch 003:  16852 / 17024 loss=7.096, nll_loss=6.081, ppl=67.68, wps=25808.1, ups=6.54, wpb=3944.2, bsz=161.8, num_updates=50900, lr=0.000140165, gnorm=0.898, train_wall=15, wall=0
2024-07-31 23:06:55 | INFO | train_inner | epoch 003:  16952 / 17024 loss=7.055, nll_loss=6.035, ppl=65.55, wps=25742.2, ups=6.47, wpb=3975.8, bsz=167.1, num_updates=51000, lr=0.000140028, gnorm=0.867, train_wall=15, wall=0
2024-07-31 23:06:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:06:56 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.31 | nll_loss 6.265 | ppl 76.91 | wps 96030.3 | wpb 3529.1 | bsz 62.9 | num_updates 51000 | best_loss 7.31
2024-07-31 23:06:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:07:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_51000.pt (epoch 3 @ 51000 updates, score 7.31) (writing took 4.578605837188661 seconds)
2024-07-31 23:07:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:07:13 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.31 | nll_loss 6.26 | ppl 76.65 | wps 94991.2 | wpb 3529.1 | bsz 62.9 | num_updates 51072 | best_loss 7.31
2024-07-31 23:07:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:07:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_best.pt (epoch 3 @ 51072 updates, score 7.31) (writing took 4.330217439681292 seconds)
2024-07-31 23:07:18 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2024-07-31 23:07:18 | INFO | train | epoch 003 | loss 7.109 | nll_loss 6.096 | ppl 68.41 | wps 24700.7 | ups 6.24 | wpb 3960.7 | bsz 163.4 | num_updates 51072 | lr 0.000139929 | gnorm 0.876 | train_wall 2598 | wall 0
2024-07-31 23:07:18 | INFO | fairseq.trainer | begin training epoch 4
2024-07-31 23:07:22 | INFO | train_inner | epoch 004:     28 / 17024 loss=7.026, nll_loss=6, ppl=64.01, wps=14433.4, ups=3.65, wpb=3954.4, bsz=151.3, num_updates=51100, lr=0.000139891, gnorm=0.884, train_wall=15, wall=0
2024-07-31 23:07:38 | INFO | train_inner | epoch 004:    128 / 17024 loss=7.097, nll_loss=6.082, ppl=67.76, wps=25653.3, ups=6.46, wpb=3971.1, bsz=178.6, num_updates=51200, lr=0.000139754, gnorm=0.931, train_wall=15, wall=0
2024-07-31 23:07:53 | INFO | train_inner | epoch 004:    228 / 17024 loss=7.026, nll_loss=6, ppl=64, wps=25596.4, ups=6.48, wpb=3951, bsz=142.2, num_updates=51300, lr=0.000139618, gnorm=0.865, train_wall=15, wall=0
2024-07-31 23:08:08 | INFO | train_inner | epoch 004:    328 / 17024 loss=7.018, nll_loss=5.991, ppl=63.6, wps=25632.9, ups=6.47, wpb=3960.8, bsz=157, num_updates=51400, lr=0.000139482, gnorm=0.909, train_wall=15, wall=0
2024-07-31 23:08:24 | INFO | train_inner | epoch 004:    428 / 17024 loss=7.02, nll_loss=5.994, ppl=63.71, wps=25542.2, ups=6.45, wpb=3962.4, bsz=157.8, num_updates=51500, lr=0.000139347, gnorm=0.88, train_wall=15, wall=0
2024-07-31 23:08:39 | INFO | train_inner | epoch 004:    528 / 17024 loss=7.055, nll_loss=6.034, ppl=65.54, wps=25703.2, ups=6.5, wpb=3955.5, bsz=162.9, num_updates=51600, lr=0.000139212, gnorm=0.89, train_wall=15, wall=0
2024-07-31 23:08:55 | INFO | train_inner | epoch 004:    628 / 17024 loss=7.006, nll_loss=5.977, ppl=63.01, wps=25638.8, ups=6.49, wpb=3951.3, bsz=152.6, num_updates=51700, lr=0.000139077, gnorm=0.899, train_wall=15, wall=0
2024-07-31 23:09:10 | INFO | train_inner | epoch 004:    728 / 17024 loss=7.084, nll_loss=6.067, ppl=67.05, wps=25666.5, ups=6.47, wpb=3966.1, bsz=171.5, num_updates=51800, lr=0.000138943, gnorm=0.926, train_wall=15, wall=0
2024-07-31 23:09:26 | INFO | train_inner | epoch 004:    828 / 17024 loss=7.061, nll_loss=6.041, ppl=65.82, wps=25531.8, ups=6.44, wpb=3965.9, bsz=166.2, num_updates=51900, lr=0.000138809, gnorm=0.892, train_wall=15, wall=0
2024-07-31 23:09:41 | INFO | train_inner | epoch 004:    928 / 17024 loss=7.065, nll_loss=6.045, ppl=66.04, wps=25431.8, ups=6.41, wpb=3970, bsz=175.1, num_updates=52000, lr=0.000138675, gnorm=0.893, train_wall=15, wall=0
2024-07-31 23:09:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:09:43 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.31 | nll_loss 6.262 | ppl 76.77 | wps 95513.1 | wpb 3529.1 | bsz 62.9 | num_updates 52000 | best_loss 7.31
2024-07-31 23:09:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:09:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_52000.pt (epoch 4 @ 52000 updates, score 7.31) (writing took 4.947969709523022 seconds)
2024-07-31 23:10:03 | INFO | train_inner | epoch 004:   1028 / 17024 loss=7.007, nll_loss=5.979, ppl=63.07, wps=17994.1, ups=4.58, wpb=3933, bsz=144.2, num_updates=52100, lr=0.000138542, gnorm=0.888, train_wall=15, wall=0
2024-07-31 23:10:19 | INFO | train_inner | epoch 004:   1128 / 17024 loss=7.07, nll_loss=6.051, ppl=66.32, wps=25457.9, ups=6.39, wpb=3982.5, bsz=183, num_updates=52200, lr=0.000138409, gnorm=0.918, train_wall=15, wall=0
2024-07-31 23:10:34 | INFO | train_inner | epoch 004:   1228 / 17024 loss=7.033, nll_loss=6.008, ppl=64.35, wps=25644.8, ups=6.44, wpb=3981.8, bsz=161.6, num_updates=52300, lr=0.000138277, gnorm=0.896, train_wall=15, wall=0
2024-07-31 23:10:50 | INFO | train_inner | epoch 004:   1328 / 17024 loss=7.111, nll_loss=6.098, ppl=68.49, wps=25561.1, ups=6.44, wpb=3970.6, bsz=183.8, num_updates=52400, lr=0.000138145, gnorm=0.914, train_wall=15, wall=0
2024-07-31 23:11:05 | INFO | train_inner | epoch 004:   1428 / 17024 loss=7.03, nll_loss=6.004, ppl=64.18, wps=25733.7, ups=6.5, wpb=3957.7, bsz=151.4, num_updates=52500, lr=0.000138013, gnorm=0.899, train_wall=15, wall=0
2024-07-31 23:11:21 | INFO | train_inner | epoch 004:   1528 / 17024 loss=7.037, nll_loss=6.012, ppl=64.55, wps=25680.4, ups=6.49, wpb=3954.2, bsz=155.2, num_updates=52600, lr=0.000137882, gnorm=0.919, train_wall=15, wall=0
2024-07-31 23:11:36 | INFO | train_inner | epoch 004:   1628 / 17024 loss=7.011, nll_loss=5.983, ppl=63.26, wps=25741.1, ups=6.5, wpb=3961.4, bsz=158.6, num_updates=52700, lr=0.000137751, gnorm=0.875, train_wall=15, wall=0
2024-07-31 23:11:52 | INFO | train_inner | epoch 004:   1728 / 17024 loss=7.039, nll_loss=6.014, ppl=64.62, wps=25635.3, ups=6.48, wpb=3953.3, bsz=149, num_updates=52800, lr=0.00013762, gnorm=0.902, train_wall=15, wall=0
2024-07-31 23:12:07 | INFO | train_inner | epoch 004:   1828 / 17024 loss=7.054, nll_loss=6.033, ppl=65.46, wps=25511.6, ups=6.44, wpb=3962.1, bsz=173.4, num_updates=52900, lr=0.00013749, gnorm=0.894, train_wall=15, wall=0
2024-07-31 23:12:23 | INFO | train_inner | epoch 004:   1928 / 17024 loss=7.072, nll_loss=6.053, ppl=66.39, wps=25503.2, ups=6.41, wpb=3976.8, bsz=175, num_updates=53000, lr=0.000137361, gnorm=0.926, train_wall=15, wall=0
2024-07-31 23:12:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:12:24 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.305 | nll_loss 6.258 | ppl 76.51 | wps 94708.4 | wpb 3529.1 | bsz 62.9 | num_updates 53000 | best_loss 7.305
2024-07-31 23:12:24 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:12:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_53000.pt (epoch 4 @ 53000 updates, score 7.305) (writing took 4.713164881803095 seconds)
2024-07-31 23:12:44 | INFO | train_inner | epoch 004:   2028 / 17024 loss=7.076, nll_loss=6.058, ppl=66.62, wps=18236, ups=4.58, wpb=3985.8, bsz=181.8, num_updates=53100, lr=0.000137231, gnorm=0.906, train_wall=15, wall=0
2024-07-31 23:13:00 | INFO | train_inner | epoch 004:   2128 / 17024 loss=7.035, nll_loss=6.011, ppl=64.47, wps=25622.2, ups=6.44, wpb=3979.7, bsz=162.1, num_updates=53200, lr=0.000137102, gnorm=0.877, train_wall=15, wall=0
2024-07-31 23:13:16 | INFO | train_inner | epoch 004:   2228 / 17024 loss=7.143, nll_loss=6.136, ppl=70.31, wps=25683.3, ups=6.45, wpb=3982.4, bsz=196, num_updates=53300, lr=0.000136973, gnorm=0.942, train_wall=15, wall=0
2024-07-31 23:13:31 | INFO | train_inner | epoch 004:   2328 / 17024 loss=7.091, nll_loss=6.075, ppl=67.42, wps=25739.5, ups=6.49, wpb=3963.6, bsz=179, num_updates=53400, lr=0.000136845, gnorm=0.907, train_wall=15, wall=0
2024-07-31 23:13:46 | INFO | train_inner | epoch 004:   2428 / 17024 loss=7.066, nll_loss=6.046, ppl=66.08, wps=25652.4, ups=6.46, wpb=3972.7, bsz=170.9, num_updates=53500, lr=0.000136717, gnorm=0.886, train_wall=15, wall=0
2024-07-31 23:14:02 | INFO | train_inner | epoch 004:   2528 / 17024 loss=7.095, nll_loss=6.079, ppl=67.6, wps=25786.9, ups=6.49, wpb=3973.4, bsz=170.1, num_updates=53600, lr=0.00013659, gnorm=0.917, train_wall=15, wall=0
2024-07-31 23:14:17 | INFO | train_inner | epoch 004:   2628 / 17024 loss=7.003, nll_loss=5.973, ppl=62.8, wps=25972, ups=6.54, wpb=3969.4, bsz=141, num_updates=53700, lr=0.000136462, gnorm=0.866, train_wall=15, wall=0
2024-07-31 23:14:33 | INFO | train_inner | epoch 004:   2728 / 17024 loss=7.031, nll_loss=6.005, ppl=64.24, wps=25684.2, ups=6.49, wpb=3959.6, bsz=158, num_updates=53800, lr=0.000136335, gnorm=0.893, train_wall=15, wall=0
2024-07-31 23:14:48 | INFO | train_inner | epoch 004:   2828 / 17024 loss=7.064, nll_loss=6.044, ppl=65.98, wps=25515.5, ups=6.45, wpb=3956.6, bsz=164.8, num_updates=53900, lr=0.000136209, gnorm=0.912, train_wall=15, wall=0
2024-07-31 23:15:04 | INFO | train_inner | epoch 004:   2928 / 17024 loss=7.041, nll_loss=6.017, ppl=64.78, wps=25536.5, ups=6.47, wpb=3949, bsz=161.9, num_updates=54000, lr=0.000136083, gnorm=0.904, train_wall=15, wall=0
2024-07-31 23:15:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:15:05 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.295 | nll_loss 6.246 | ppl 75.9 | wps 93512.6 | wpb 3529.1 | bsz 62.9 | num_updates 54000 | best_loss 7.295
2024-07-31 23:15:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:15:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_54000.pt (epoch 4 @ 54000 updates, score 7.295) (writing took 4.91634994931519 seconds)
2024-07-31 23:15:25 | INFO | train_inner | epoch 004:   3028 / 17024 loss=7.039, nll_loss=6.015, ppl=64.67, wps=17970.9, ups=4.57, wpb=3932.2, bsz=157.4, num_updates=54100, lr=0.000135957, gnorm=0.904, train_wall=15, wall=0
2024-07-31 23:15:41 | INFO | train_inner | epoch 004:   3128 / 17024 loss=7.06, nll_loss=6.039, ppl=65.74, wps=25350.2, ups=6.42, wpb=3951.5, bsz=159.4, num_updates=54200, lr=0.000135831, gnorm=0.905, train_wall=15, wall=0
2024-07-31 23:15:57 | INFO | train_inner | epoch 004:   3228 / 17024 loss=7.005, nll_loss=5.976, ppl=62.95, wps=25522.4, ups=6.43, wpb=3969, bsz=156.2, num_updates=54300, lr=0.000135706, gnorm=0.87, train_wall=15, wall=0
2024-07-31 23:16:12 | INFO | train_inner | epoch 004:   3328 / 17024 loss=7.018, nll_loss=5.99, ppl=63.55, wps=25590.2, ups=6.52, wpb=3927.6, bsz=142.2, num_updates=54400, lr=0.000135582, gnorm=0.924, train_wall=15, wall=0
2024-07-31 23:16:27 | INFO | train_inner | epoch 004:   3428 / 17024 loss=7.092, nll_loss=6.076, ppl=67.45, wps=25690, ups=6.46, wpb=3975.2, bsz=170.3, num_updates=54500, lr=0.000135457, gnorm=0.925, train_wall=15, wall=0
2024-07-31 23:16:43 | INFO | train_inner | epoch 004:   3528 / 17024 loss=7.057, nll_loss=6.036, ppl=65.63, wps=25676.7, ups=6.52, wpb=3938.6, bsz=156.4, num_updates=54600, lr=0.000135333, gnorm=0.907, train_wall=15, wall=0
2024-07-31 23:16:58 | INFO | train_inner | epoch 004:   3628 / 17024 loss=7.077, nll_loss=6.058, ppl=66.64, wps=25771.8, ups=6.49, wpb=3973.2, bsz=172.8, num_updates=54700, lr=0.000135209, gnorm=0.924, train_wall=15, wall=0
2024-07-31 23:17:13 | INFO | train_inner | epoch 004:   3728 / 17024 loss=7.03, nll_loss=6.005, ppl=64.21, wps=25701.2, ups=6.51, wpb=3948.1, bsz=153.4, num_updates=54800, lr=0.000135086, gnorm=0.901, train_wall=15, wall=0
2024-07-31 23:17:29 | INFO | train_inner | epoch 004:   3828 / 17024 loss=7.074, nll_loss=6.055, ppl=66.5, wps=25656.3, ups=6.44, wpb=3980.9, bsz=170.7, num_updates=54900, lr=0.000134963, gnorm=0.91, train_wall=15, wall=0
2024-07-31 23:17:44 | INFO | train_inner | epoch 004:   3928 / 17024 loss=7.045, nll_loss=6.022, ppl=65, wps=25918.1, ups=6.53, wpb=3966.7, bsz=171.7, num_updates=55000, lr=0.00013484, gnorm=0.902, train_wall=15, wall=0
2024-07-31 23:17:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:17:46 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.302 | nll_loss 6.256 | ppl 76.42 | wps 95191 | wpb 3529.1 | bsz 62.9 | num_updates 55000 | best_loss 7.295
2024-07-31 23:17:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:17:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_55000.pt (epoch 4 @ 55000 updates, score 7.302) (writing took 3.895872291177511 seconds)
2024-07-31 23:18:05 | INFO | train_inner | epoch 004:   4028 / 17024 loss=7.05, nll_loss=6.028, ppl=65.25, wps=18993.2, ups=4.79, wpb=3963.4, bsz=172.7, num_updates=55100, lr=0.000134718, gnorm=0.892, train_wall=15, wall=0
2024-07-31 23:18:21 | INFO | train_inner | epoch 004:   4128 / 17024 loss=7.036, nll_loss=6.011, ppl=64.51, wps=25649.7, ups=6.5, wpb=3944.8, bsz=153.2, num_updates=55200, lr=0.000134595, gnorm=0.901, train_wall=15, wall=0
2024-07-31 23:18:36 | INFO | train_inner | epoch 004:   4228 / 17024 loss=7.073, nll_loss=6.054, ppl=66.44, wps=25668.2, ups=6.5, wpb=3949.5, bsz=168.6, num_updates=55300, lr=0.000134474, gnorm=0.902, train_wall=15, wall=0
2024-07-31 23:18:51 | INFO | train_inner | epoch 004:   4328 / 17024 loss=7.058, nll_loss=6.037, ppl=65.68, wps=25476.5, ups=6.47, wpb=3939.3, bsz=165, num_updates=55400, lr=0.000134352, gnorm=0.907, train_wall=15, wall=0
2024-07-31 23:19:07 | INFO | train_inner | epoch 004:   4428 / 17024 loss=7.057, nll_loss=6.036, ppl=65.62, wps=25606.8, ups=6.48, wpb=3954.3, bsz=170.2, num_updates=55500, lr=0.000134231, gnorm=0.896, train_wall=15, wall=0
2024-07-31 23:19:22 | INFO | train_inner | epoch 004:   4528 / 17024 loss=7.014, nll_loss=5.987, ppl=63.41, wps=25579.1, ups=6.44, wpb=3969.7, bsz=167.4, num_updates=55600, lr=0.00013411, gnorm=0.904, train_wall=15, wall=0
2024-07-31 23:19:38 | INFO | train_inner | epoch 004:   4628 / 17024 loss=7.032, nll_loss=6.007, ppl=64.3, wps=25578.9, ups=6.5, wpb=3933.6, bsz=148.7, num_updates=55700, lr=0.00013399, gnorm=0.901, train_wall=15, wall=0
2024-07-31 23:19:53 | INFO | train_inner | epoch 004:   4728 / 17024 loss=7.054, nll_loss=6.032, ppl=65.45, wps=25551.8, ups=6.47, wpb=3947.2, bsz=156.6, num_updates=55800, lr=0.00013387, gnorm=0.907, train_wall=15, wall=0
2024-07-31 23:20:09 | INFO | train_inner | epoch 004:   4828 / 17024 loss=7.048, nll_loss=6.025, ppl=65.14, wps=25604.3, ups=6.44, wpb=3974.6, bsz=172.8, num_updates=55900, lr=0.00013375, gnorm=0.904, train_wall=15, wall=0
2024-07-31 23:20:24 | INFO | train_inner | epoch 004:   4928 / 17024 loss=7.04, nll_loss=6.016, ppl=64.73, wps=25540, ups=6.44, wpb=3966.6, bsz=158.4, num_updates=56000, lr=0.000133631, gnorm=0.896, train_wall=15, wall=0
2024-07-31 23:20:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:20:26 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.304 | nll_loss 6.258 | ppl 76.51 | wps 96295.2 | wpb 3529.1 | bsz 62.9 | num_updates 56000 | best_loss 7.295
2024-07-31 23:20:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:20:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_56000.pt (epoch 4 @ 56000 updates, score 7.304) (writing took 3.110543509013951 seconds)
2024-07-31 23:20:44 | INFO | train_inner | epoch 004:   5028 / 17024 loss=7.097, nll_loss=6.083, ppl=67.78, wps=19843.3, ups=5, wpb=3971.3, bsz=188.1, num_updates=56100, lr=0.000133511, gnorm=0.922, train_wall=15, wall=0
2024-07-31 23:21:00 | INFO | train_inner | epoch 004:   5128 / 17024 loss=7.058, nll_loss=6.037, ppl=65.67, wps=25551.1, ups=6.49, wpb=3936.6, bsz=168.9, num_updates=56200, lr=0.000133393, gnorm=0.907, train_wall=15, wall=0
2024-07-31 23:21:15 | INFO | train_inner | epoch 004:   5228 / 17024 loss=7.037, nll_loss=6.012, ppl=64.56, wps=25419.1, ups=6.44, wpb=3949.5, bsz=151.4, num_updates=56300, lr=0.000133274, gnorm=0.902, train_wall=15, wall=0
2024-07-31 23:21:31 | INFO | train_inner | epoch 004:   5328 / 17024 loss=6.987, nll_loss=5.955, ppl=62.03, wps=25621.3, ups=6.49, wpb=3945.3, bsz=140.8, num_updates=56400, lr=0.000133156, gnorm=0.883, train_wall=15, wall=0
2024-07-31 23:21:46 | INFO | train_inner | epoch 004:   5428 / 17024 loss=7.029, nll_loss=6.003, ppl=64.15, wps=25736.9, ups=6.54, wpb=3937.9, bsz=155.8, num_updates=56500, lr=0.000133038, gnorm=0.919, train_wall=15, wall=0
2024-07-31 23:22:01 | INFO | train_inner | epoch 004:   5528 / 17024 loss=7.068, nll_loss=6.048, ppl=66.18, wps=25498.8, ups=6.42, wpb=3971.7, bsz=173.4, num_updates=56600, lr=0.00013292, gnorm=0.936, train_wall=15, wall=0
2024-07-31 23:22:17 | INFO | train_inner | epoch 004:   5628 / 17024 loss=7.034, nll_loss=6.009, ppl=64.42, wps=25920.7, ups=6.52, wpb=3973, bsz=170.9, num_updates=56700, lr=0.000132803, gnorm=0.902, train_wall=15, wall=0
2024-07-31 23:22:32 | INFO | train_inner | epoch 004:   5728 / 17024 loss=6.988, nll_loss=5.957, ppl=62.11, wps=25663.4, ups=6.47, wpb=3968.9, bsz=147.1, num_updates=56800, lr=0.000132686, gnorm=0.874, train_wall=15, wall=0
2024-07-31 23:22:48 | INFO | train_inner | epoch 004:   5828 / 17024 loss=7.046, nll_loss=6.023, ppl=65.05, wps=25748.8, ups=6.5, wpb=3962.9, bsz=158.2, num_updates=56900, lr=0.00013257, gnorm=0.886, train_wall=15, wall=0
2024-07-31 23:23:03 | INFO | train_inner | epoch 004:   5928 / 17024 loss=6.999, nll_loss=5.969, ppl=62.65, wps=25638.4, ups=6.45, wpb=3972.8, bsz=147, num_updates=57000, lr=0.000132453, gnorm=0.88, train_wall=15, wall=0
2024-07-31 23:23:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:23:05 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.291 | nll_loss 6.243 | ppl 75.76 | wps 95488.7 | wpb 3529.1 | bsz 62.9 | num_updates 57000 | best_loss 7.291
2024-07-31 23:23:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:23:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_57000.pt (epoch 4 @ 57000 updates, score 7.291) (writing took 4.912686598487198 seconds)
2024-07-31 23:23:25 | INFO | train_inner | epoch 004:   6028 / 17024 loss=7.116, nll_loss=6.104, ppl=68.79, wps=18136.8, ups=4.6, wpb=3942.1, bsz=192.4, num_updates=57100, lr=0.000132337, gnorm=0.995, train_wall=15, wall=0
2024-07-31 23:23:40 | INFO | train_inner | epoch 004:   6128 / 17024 loss=7.005, nll_loss=5.975, ppl=62.92, wps=25555.3, ups=6.45, wpb=3963.7, bsz=153.7, num_updates=57200, lr=0.000132221, gnorm=0.887, train_wall=15, wall=0
2024-07-31 23:23:56 | INFO | train_inner | epoch 004:   6228 / 17024 loss=7.023, nll_loss=5.996, ppl=63.83, wps=25846.3, ups=6.55, wpb=3946.4, bsz=154.3, num_updates=57300, lr=0.000132106, gnorm=0.908, train_wall=15, wall=0
2024-07-31 23:24:11 | INFO | train_inner | epoch 004:   6328 / 17024 loss=7.086, nll_loss=6.068, ppl=67.11, wps=25621.8, ups=6.51, wpb=3937.4, bsz=169.7, num_updates=57400, lr=0.000131991, gnorm=0.973, train_wall=15, wall=0
2024-07-31 23:24:27 | INFO | train_inner | epoch 004:   6428 / 17024 loss=6.989, nll_loss=5.958, ppl=62.17, wps=25384.4, ups=6.44, wpb=3941.4, bsz=145.8, num_updates=57500, lr=0.000131876, gnorm=0.893, train_wall=15, wall=0
2024-07-31 23:24:42 | INFO | train_inner | epoch 004:   6528 / 17024 loss=7.051, nll_loss=6.029, ppl=65.32, wps=25320.6, ups=6.38, wpb=3968.7, bsz=171.4, num_updates=57600, lr=0.000131762, gnorm=0.911, train_wall=15, wall=0
2024-07-31 23:24:58 | INFO | train_inner | epoch 004:   6628 / 17024 loss=7.056, nll_loss=6.035, ppl=65.57, wps=25576.8, ups=6.43, wpb=3976.7, bsz=165, num_updates=57700, lr=0.000131647, gnorm=0.89, train_wall=15, wall=0
2024-07-31 23:25:13 | INFO | train_inner | epoch 004:   6728 / 17024 loss=7.006, nll_loss=5.977, ppl=62.99, wps=25653.6, ups=6.48, wpb=3957.6, bsz=159.2, num_updates=57800, lr=0.000131533, gnorm=0.919, train_wall=15, wall=0
2024-07-31 23:25:29 | INFO | train_inner | epoch 004:   6828 / 17024 loss=7.086, nll_loss=6.069, ppl=67.13, wps=25685.7, ups=6.51, wpb=3945.5, bsz=166.6, num_updates=57900, lr=0.00013142, gnorm=0.953, train_wall=15, wall=0
2024-07-31 23:25:44 | INFO | train_inner | epoch 004:   6928 / 17024 loss=7.047, nll_loss=6.024, ppl=65.08, wps=25687.5, ups=6.49, wpb=3958.8, bsz=165.4, num_updates=58000, lr=0.000131306, gnorm=0.91, train_wall=15, wall=0
2024-07-31 23:25:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:25:45 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.298 | nll_loss 6.249 | ppl 76.04 | wps 94739.1 | wpb 3529.1 | bsz 62.9 | num_updates 58000 | best_loss 7.291
2024-07-31 23:25:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:25:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_58000.pt (epoch 4 @ 58000 updates, score 7.298) (writing took 2.8051609294489026 seconds)
2024-07-31 23:26:04 | INFO | train_inner | epoch 004:   7028 / 17024 loss=7.046, nll_loss=6.023, ppl=65.03, wps=20086.7, ups=5.09, wpb=3946.5, bsz=164.3, num_updates=58100, lr=0.000131193, gnorm=0.911, train_wall=15, wall=0
2024-07-31 23:26:19 | INFO | train_inner | epoch 004:   7128 / 17024 loss=7.086, nll_loss=6.07, ppl=67.18, wps=25589.8, ups=6.44, wpb=3970.6, bsz=187.5, num_updates=58200, lr=0.000131081, gnorm=0.958, train_wall=15, wall=0
2024-07-31 23:26:35 | INFO | train_inner | epoch 004:   7228 / 17024 loss=7.037, nll_loss=6.013, ppl=64.58, wps=25690.4, ups=6.47, wpb=3970.7, bsz=160.2, num_updates=58300, lr=0.000130968, gnorm=0.889, train_wall=15, wall=0
2024-07-31 23:26:50 | INFO | train_inner | epoch 004:   7328 / 17024 loss=7.046, nll_loss=6.023, ppl=65.04, wps=25611.6, ups=6.46, wpb=3965.6, bsz=156.6, num_updates=58400, lr=0.000130856, gnorm=0.903, train_wall=15, wall=0
2024-07-31 23:27:05 | INFO | train_inner | epoch 004:   7428 / 17024 loss=7.054, nll_loss=6.032, ppl=65.44, wps=25737.1, ups=6.5, wpb=3958.6, bsz=167.4, num_updates=58500, lr=0.000130744, gnorm=0.915, train_wall=15, wall=0
2024-07-31 23:27:21 | INFO | train_inner | epoch 004:   7528 / 17024 loss=7.041, nll_loss=6.018, ppl=64.82, wps=25659.7, ups=6.49, wpb=3956.2, bsz=160.5, num_updates=58600, lr=0.000130632, gnorm=0.899, train_wall=15, wall=0
2024-07-31 23:27:36 | INFO | train_inner | epoch 004:   7628 / 17024 loss=7.032, nll_loss=6.007, ppl=64.31, wps=25746, ups=6.51, wpb=3954.3, bsz=159, num_updates=58700, lr=0.000130521, gnorm=0.912, train_wall=15, wall=0
2024-07-31 23:27:52 | INFO | train_inner | epoch 004:   7728 / 17024 loss=7.056, nll_loss=6.035, ppl=65.57, wps=25555.6, ups=6.47, wpb=3947.1, bsz=161, num_updates=58800, lr=0.00013041, gnorm=0.91, train_wall=15, wall=0
2024-07-31 23:28:07 | INFO | train_inner | epoch 004:   7828 / 17024 loss=7.033, nll_loss=6.009, ppl=64.38, wps=25724.9, ups=6.48, wpb=3968.8, bsz=156.6, num_updates=58900, lr=0.000130299, gnorm=0.888, train_wall=15, wall=0
2024-07-31 23:28:23 | INFO | train_inner | epoch 004:   7928 / 17024 loss=7.01, nll_loss=5.982, ppl=63.19, wps=25627.6, ups=6.49, wpb=3949.3, bsz=150.2, num_updates=59000, lr=0.000130189, gnorm=0.907, train_wall=15, wall=0
2024-07-31 23:28:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:28:24 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.292 | nll_loss 6.243 | ppl 75.77 | wps 93893.4 | wpb 3529.1 | bsz 62.9 | num_updates 59000 | best_loss 7.291
2024-07-31 23:28:24 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:28:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_59000.pt (epoch 4 @ 59000 updates, score 7.292) (writing took 3.3546778429299593 seconds)
2024-07-31 23:28:43 | INFO | train_inner | epoch 004:   8028 / 17024 loss=7.009, nll_loss=5.98, ppl=63.11, wps=19493.8, ups=4.92, wpb=3961.2, bsz=149.4, num_updates=59100, lr=0.000130079, gnorm=0.895, train_wall=15, wall=0
2024-07-31 23:28:58 | INFO | train_inner | epoch 004:   8128 / 17024 loss=7.087, nll_loss=6.07, ppl=67.19, wps=26052.5, ups=6.57, wpb=3964.8, bsz=177.1, num_updates=59200, lr=0.000129969, gnorm=0.932, train_wall=15, wall=0
2024-07-31 23:29:13 | INFO | train_inner | epoch 004:   8228 / 17024 loss=7.018, nll_loss=5.992, ppl=63.64, wps=25781.3, ups=6.53, wpb=3948.3, bsz=154.6, num_updates=59300, lr=0.000129859, gnorm=0.903, train_wall=15, wall=0
2024-07-31 23:29:29 | INFO | train_inner | epoch 004:   8328 / 17024 loss=7.059, nll_loss=6.038, ppl=65.71, wps=25528.9, ups=6.47, wpb=3944.8, bsz=175.4, num_updates=59400, lr=0.00012975, gnorm=0.932, train_wall=15, wall=0
2024-07-31 23:29:44 | INFO | train_inner | epoch 004:   8428 / 17024 loss=7.015, nll_loss=5.987, ppl=63.44, wps=25636.4, ups=6.51, wpb=3937.6, bsz=147.1, num_updates=59500, lr=0.000129641, gnorm=0.911, train_wall=15, wall=0
2024-07-31 23:30:00 | INFO | train_inner | epoch 004:   8528 / 17024 loss=7.05, nll_loss=6.028, ppl=65.26, wps=25560.7, ups=6.46, wpb=3953.8, bsz=164.4, num_updates=59600, lr=0.000129532, gnorm=0.933, train_wall=15, wall=0
2024-07-31 23:30:15 | INFO | train_inner | epoch 004:   8628 / 17024 loss=7.013, nll_loss=5.986, ppl=63.37, wps=25573.2, ups=6.46, wpb=3958.3, bsz=154.6, num_updates=59700, lr=0.000129423, gnorm=0.895, train_wall=15, wall=0
2024-07-31 23:30:31 | INFO | train_inner | epoch 004:   8728 / 17024 loss=7.008, nll_loss=5.981, ppl=63.16, wps=25592.6, ups=6.47, wpb=3953.3, bsz=152.7, num_updates=59800, lr=0.000129315, gnorm=0.891, train_wall=15, wall=0
2024-07-31 23:30:46 | INFO | train_inner | epoch 004:   8828 / 17024 loss=7.093, nll_loss=6.077, ppl=67.53, wps=25608.7, ups=6.44, wpb=3978.2, bsz=191.9, num_updates=59900, lr=0.000129207, gnorm=0.956, train_wall=15, wall=0
2024-07-31 23:31:02 | INFO | train_inner | epoch 004:   8928 / 17024 loss=7.025, nll_loss=6, ppl=64, wps=25805.3, ups=6.5, wpb=3968.1, bsz=161.6, num_updates=60000, lr=0.000129099, gnorm=0.895, train_wall=15, wall=0
2024-07-31 23:31:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:31:03 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.307 | nll_loss 6.261 | ppl 76.71 | wps 97236.6 | wpb 3529.1 | bsz 62.9 | num_updates 60000 | best_loss 7.291
2024-07-31 23:31:03 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:31:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_60000.pt (epoch 4 @ 60000 updates, score 7.307) (writing took 2.7591867288574576 seconds)
2024-07-31 23:31:21 | INFO | train_inner | epoch 004:   9028 / 17024 loss=7.082, nll_loss=6.065, ppl=66.93, wps=20291.1, ups=5.12, wpb=3961.8, bsz=186.9, num_updates=60100, lr=0.000128992, gnorm=0.934, train_wall=15, wall=0
2024-07-31 23:31:36 | INFO | train_inner | epoch 004:   9128 / 17024 loss=7.065, nll_loss=6.046, ppl=66.07, wps=25696.6, ups=6.48, wpb=3967.6, bsz=174.8, num_updates=60200, lr=0.000128885, gnorm=0.912, train_wall=15, wall=0
2024-07-31 23:31:52 | INFO | train_inner | epoch 004:   9228 / 17024 loss=7.038, nll_loss=6.015, ppl=64.65, wps=26008.9, ups=6.53, wpb=3981.1, bsz=173.4, num_updates=60300, lr=0.000128778, gnorm=0.921, train_wall=15, wall=0
2024-07-31 23:32:07 | INFO | train_inner | epoch 004:   9328 / 17024 loss=7.046, nll_loss=6.024, ppl=65.07, wps=25715.5, ups=6.49, wpb=3961.8, bsz=164.1, num_updates=60400, lr=0.000128671, gnorm=0.937, train_wall=15, wall=0
2024-07-31 23:32:23 | INFO | train_inner | epoch 004:   9428 / 17024 loss=7.029, nll_loss=6.004, ppl=64.19, wps=25689.6, ups=6.5, wpb=3951.8, bsz=164.7, num_updates=60500, lr=0.000128565, gnorm=0.923, train_wall=15, wall=0
2024-07-31 23:32:38 | INFO | train_inner | epoch 004:   9528 / 17024 loss=6.998, nll_loss=5.968, ppl=62.58, wps=25695.9, ups=6.51, wpb=3945.5, bsz=138.8, num_updates=60600, lr=0.000128459, gnorm=0.907, train_wall=15, wall=0
2024-07-31 23:32:53 | INFO | train_inner | epoch 004:   9628 / 17024 loss=7.026, nll_loss=6.001, ppl=64.04, wps=25841.4, ups=6.52, wpb=3965.4, bsz=165.8, num_updates=60700, lr=0.000128353, gnorm=0.915, train_wall=15, wall=0
2024-07-31 23:33:09 | INFO | train_inner | epoch 004:   9728 / 17024 loss=7.031, nll_loss=6.006, ppl=64.25, wps=25656.3, ups=6.45, wpb=3977.3, bsz=159.3, num_updates=60800, lr=0.000128247, gnorm=0.906, train_wall=15, wall=0
2024-07-31 23:33:24 | INFO | train_inner | epoch 004:   9828 / 17024 loss=7.035, nll_loss=6.011, ppl=64.5, wps=25612, ups=6.47, wpb=3957.8, bsz=162.5, num_updates=60900, lr=0.000128142, gnorm=0.92, train_wall=15, wall=0
2024-07-31 23:33:40 | INFO | train_inner | epoch 004:   9928 / 17024 loss=7.022, nll_loss=5.996, ppl=63.84, wps=25466.1, ups=6.46, wpb=3941.5, bsz=159, num_updates=61000, lr=0.000128037, gnorm=0.911, train_wall=15, wall=0
2024-07-31 23:33:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:33:41 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.294 | nll_loss 6.243 | ppl 75.72 | wps 96622.8 | wpb 3529.1 | bsz 62.9 | num_updates 61000 | best_loss 7.291
2024-07-31 23:33:41 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:33:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_61000.pt (epoch 4 @ 61000 updates, score 7.294) (writing took 2.7957370802760124 seconds)
2024-07-31 23:34:00 | INFO | train_inner | epoch 004:  10028 / 17024 loss=7.034, nll_loss=6.01, ppl=64.45, wps=20169.1, ups=5.05, wpb=3994.9, bsz=183.2, num_updates=61100, lr=0.000127932, gnorm=0.908, train_wall=15, wall=0
2024-07-31 23:34:15 | INFO | train_inner | epoch 004:  10128 / 17024 loss=7.057, nll_loss=6.036, ppl=65.62, wps=25804.3, ups=6.51, wpb=3961.3, bsz=166.9, num_updates=61200, lr=0.000127827, gnorm=0.922, train_wall=15, wall=0
2024-07-31 23:34:30 | INFO | train_inner | epoch 004:  10228 / 17024 loss=7.005, nll_loss=5.976, ppl=62.95, wps=25681.3, ups=6.49, wpb=3955.6, bsz=148.9, num_updates=61300, lr=0.000127723, gnorm=0.908, train_wall=15, wall=0
2024-07-31 23:34:46 | INFO | train_inner | epoch 004:  10328 / 17024 loss=7.002, nll_loss=5.972, ppl=62.79, wps=25584.5, ups=6.48, wpb=3951, bsz=153.5, num_updates=61400, lr=0.000127619, gnorm=0.916, train_wall=15, wall=0
2024-07-31 23:35:01 | INFO | train_inner | epoch 004:  10428 / 17024 loss=7.043, nll_loss=6.019, ppl=64.87, wps=25637.3, ups=6.51, wpb=3939.6, bsz=156.5, num_updates=61500, lr=0.000127515, gnorm=0.9, train_wall=15, wall=0
2024-07-31 23:35:17 | INFO | train_inner | epoch 004:  10528 / 17024 loss=7.014, nll_loss=5.987, ppl=63.42, wps=25508.7, ups=6.44, wpb=3958.1, bsz=151.9, num_updates=61600, lr=0.000127412, gnorm=0.905, train_wall=15, wall=0
2024-07-31 23:35:32 | INFO | train_inner | epoch 004:  10628 / 17024 loss=7.019, nll_loss=5.993, ppl=63.68, wps=25575, ups=6.48, wpb=3946.7, bsz=153.4, num_updates=61700, lr=0.000127309, gnorm=0.913, train_wall=15, wall=0
2024-07-31 23:35:48 | INFO | train_inner | epoch 004:  10728 / 17024 loss=6.964, nll_loss=5.929, ppl=60.93, wps=25433.4, ups=6.44, wpb=3946.2, bsz=139.9, num_updates=61800, lr=0.000127205, gnorm=0.9, train_wall=15, wall=0
2024-07-31 23:36:03 | INFO | train_inner | epoch 004:  10828 / 17024 loss=7.015, nll_loss=5.988, ppl=63.46, wps=25599.1, ups=6.44, wpb=3972.1, bsz=165.6, num_updates=61900, lr=0.000127103, gnorm=0.921, train_wall=15, wall=0
2024-07-31 23:36:19 | INFO | train_inner | epoch 004:  10928 / 17024 loss=7.023, nll_loss=5.997, ppl=63.86, wps=25680.3, ups=6.46, wpb=3975.4, bsz=164.3, num_updates=62000, lr=0.000127, gnorm=0.903, train_wall=15, wall=0
2024-07-31 23:36:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:36:20 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.278 | nll_loss 6.225 | ppl 74.82 | wps 94611.4 | wpb 3529.1 | bsz 62.9 | num_updates 62000 | best_loss 7.278
2024-07-31 23:36:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:36:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_62000.pt (epoch 4 @ 62000 updates, score 7.278) (writing took 4.688287124037743 seconds)
2024-07-31 23:36:40 | INFO | train_inner | epoch 004:  11028 / 17024 loss=7.043, nll_loss=6.02, ppl=64.89, wps=18372.2, ups=4.61, wpb=3986.7, bsz=172.2, num_updates=62100, lr=0.000126898, gnorm=0.918, train_wall=15, wall=0
2024-07-31 23:36:56 | INFO | train_inner | epoch 004:  11128 / 17024 loss=6.969, nll_loss=5.934, ppl=61.15, wps=25657.5, ups=6.5, wpb=3948.6, bsz=141.2, num_updates=62200, lr=0.000126796, gnorm=0.904, train_wall=15, wall=0
2024-07-31 23:37:11 | INFO | train_inner | epoch 004:  11228 / 17024 loss=7.044, nll_loss=6.021, ppl=64.93, wps=25710.3, ups=6.5, wpb=3952.5, bsz=166.8, num_updates=62300, lr=0.000126694, gnorm=0.909, train_wall=15, wall=0
2024-07-31 23:37:26 | INFO | train_inner | epoch 004:  11328 / 17024 loss=7.014, nll_loss=5.986, ppl=63.4, wps=25740.3, ups=6.46, wpb=3982.5, bsz=168.4, num_updates=62400, lr=0.000126592, gnorm=0.912, train_wall=15, wall=0
2024-07-31 23:37:42 | INFO | train_inner | epoch 004:  11428 / 17024 loss=7.049, nll_loss=6.027, ppl=65.21, wps=25726, ups=6.5, wpb=3955.2, bsz=169.4, num_updates=62500, lr=0.000126491, gnorm=0.964, train_wall=15, wall=0
2024-07-31 23:37:57 | INFO | train_inner | epoch 004:  11528 / 17024 loss=7.034, nll_loss=6.01, ppl=64.45, wps=25555.1, ups=6.43, wpb=3972.4, bsz=177, num_updates=62600, lr=0.00012639, gnorm=0.906, train_wall=15, wall=0
2024-07-31 23:38:13 | INFO | train_inner | epoch 004:  11628 / 17024 loss=6.998, nll_loss=5.968, ppl=62.61, wps=25726.1, ups=6.48, wpb=3971.6, bsz=154, num_updates=62700, lr=0.000126289, gnorm=0.908, train_wall=15, wall=0
2024-07-31 23:38:28 | INFO | train_inner | epoch 004:  11728 / 17024 loss=7.009, nll_loss=5.981, ppl=63.17, wps=25496.1, ups=6.43, wpb=3966.6, bsz=160.1, num_updates=62800, lr=0.000126189, gnorm=0.914, train_wall=15, wall=0
2024-07-31 23:38:44 | INFO | train_inner | epoch 004:  11828 / 17024 loss=7.039, nll_loss=6.015, ppl=64.68, wps=25557.7, ups=6.46, wpb=3955.3, bsz=163.5, num_updates=62900, lr=0.000126088, gnorm=0.925, train_wall=15, wall=0
2024-07-31 23:38:59 | INFO | train_inner | epoch 004:  11928 / 17024 loss=7.049, nll_loss=6.027, ppl=65.19, wps=25468.1, ups=6.43, wpb=3961.3, bsz=164.8, num_updates=63000, lr=0.000125988, gnorm=0.941, train_wall=15, wall=0
2024-07-31 23:38:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:39:01 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.272 | nll_loss 6.22 | ppl 74.55 | wps 95559.4 | wpb 3529.1 | bsz 62.9 | num_updates 63000 | best_loss 7.272
2024-07-31 23:39:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:39:07 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_63000.pt (epoch 4 @ 63000 updates, score 7.272) (writing took 5.704284977167845 seconds)
2024-07-31 23:39:22 | INFO | train_inner | epoch 004:  12028 / 17024 loss=7.052, nll_loss=6.031, ppl=65.38, wps=17627.3, ups=4.45, wpb=3962.3, bsz=165.4, num_updates=63100, lr=0.000125888, gnorm=0.916, train_wall=15, wall=0
2024-07-31 23:39:37 | INFO | train_inner | epoch 004:  12128 / 17024 loss=6.964, nll_loss=5.93, ppl=60.96, wps=25784.7, ups=6.49, wpb=3975.9, bsz=153.6, num_updates=63200, lr=0.000125789, gnorm=0.876, train_wall=15, wall=0
2024-07-31 23:39:53 | INFO | train_inner | epoch 004:  12228 / 17024 loss=7.008, nll_loss=5.979, ppl=63.07, wps=25692.6, ups=6.52, wpb=3942, bsz=150.6, num_updates=63300, lr=0.000125689, gnorm=0.922, train_wall=15, wall=0
2024-07-31 23:40:08 | INFO | train_inner | epoch 004:  12328 / 17024 loss=7.005, nll_loss=5.976, ppl=62.96, wps=25706.8, ups=6.48, wpb=3969.3, bsz=153, num_updates=63400, lr=0.00012559, gnorm=0.898, train_wall=15, wall=0
2024-07-31 23:40:23 | INFO | train_inner | epoch 004:  12428 / 17024 loss=7.034, nll_loss=6.01, ppl=64.45, wps=25923.8, ups=6.52, wpb=3979, bsz=172.2, num_updates=63500, lr=0.000125491, gnorm=0.929, train_wall=15, wall=0
2024-07-31 23:40:39 | INFO | train_inner | epoch 004:  12528 / 17024 loss=7.012, nll_loss=5.984, ppl=63.31, wps=25679.5, ups=6.45, wpb=3979.1, bsz=161.3, num_updates=63600, lr=0.000125392, gnorm=0.911, train_wall=15, wall=0
2024-07-31 23:40:54 | INFO | train_inner | epoch 004:  12628 / 17024 loss=7.005, nll_loss=5.976, ppl=62.96, wps=25791.4, ups=6.5, wpb=3969.6, bsz=161, num_updates=63700, lr=0.000125294, gnorm=0.907, train_wall=15, wall=0
2024-07-31 23:41:10 | INFO | train_inner | epoch 004:  12728 / 17024 loss=7.026, nll_loss=5.999, ppl=63.97, wps=25490.4, ups=6.43, wpb=3963.3, bsz=149.3, num_updates=63800, lr=0.000125196, gnorm=0.918, train_wall=15, wall=0
2024-07-31 23:41:25 | INFO | train_inner | epoch 004:  12828 / 17024 loss=7.037, nll_loss=6.013, ppl=64.59, wps=25607.2, ups=6.47, wpb=3955.8, bsz=155.5, num_updates=63900, lr=0.000125098, gnorm=0.93, train_wall=15, wall=0
2024-07-31 23:41:41 | INFO | train_inner | epoch 004:  12928 / 17024 loss=7.024, nll_loss=5.998, ppl=63.91, wps=25648.7, ups=6.49, wpb=3954.6, bsz=161.2, num_updates=64000, lr=0.000125, gnorm=0.939, train_wall=15, wall=0
2024-07-31 23:41:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:41:42 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.264 | nll_loss 6.21 | ppl 74.03 | wps 93920.7 | wpb 3529.1 | bsz 62.9 | num_updates 64000 | best_loss 7.264
2024-07-31 23:41:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:41:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_64000.pt (epoch 4 @ 64000 updates, score 7.264) (writing took 4.955772279761732 seconds)
2024-07-31 23:42:03 | INFO | train_inner | epoch 004:  13028 / 17024 loss=7.016, nll_loss=5.989, ppl=63.5, wps=18049.3, ups=4.55, wpb=3970.9, bsz=151.8, num_updates=64100, lr=0.000124902, gnorm=0.905, train_wall=15, wall=0
2024-07-31 23:42:18 | INFO | train_inner | epoch 004:  13128 / 17024 loss=7.058, nll_loss=6.037, ppl=65.68, wps=25643.7, ups=6.48, wpb=3956.4, bsz=170.9, num_updates=64200, lr=0.000124805, gnorm=0.963, train_wall=15, wall=0
2024-07-31 23:42:34 | INFO | train_inner | epoch 004:  13228 / 17024 loss=7.026, nll_loss=6.002, ppl=64.07, wps=25568.8, ups=6.47, wpb=3950.2, bsz=167, num_updates=64300, lr=0.000124708, gnorm=0.926, train_wall=15, wall=0
2024-07-31 23:42:49 | INFO | train_inner | epoch 004:  13328 / 17024 loss=7.059, nll_loss=6.039, ppl=65.74, wps=25719.7, ups=6.5, wpb=3959.7, bsz=180.6, num_updates=64400, lr=0.000124611, gnorm=0.952, train_wall=15, wall=0
2024-07-31 23:43:05 | INFO | train_inner | epoch 004:  13428 / 17024 loss=7.063, nll_loss=6.043, ppl=65.93, wps=25569.5, ups=6.44, wpb=3968.8, bsz=166.6, num_updates=64500, lr=0.000124515, gnorm=0.933, train_wall=15, wall=0
2024-07-31 23:43:20 | INFO | train_inner | epoch 004:  13528 / 17024 loss=7.074, nll_loss=6.056, ppl=66.53, wps=25785.9, ups=6.5, wpb=3968.9, bsz=180.6, num_updates=64600, lr=0.000124418, gnorm=0.935, train_wall=15, wall=0
2024-07-31 23:43:35 | INFO | train_inner | epoch 004:  13628 / 17024 loss=7.059, nll_loss=6.039, ppl=65.76, wps=25751.2, ups=6.47, wpb=3979.7, bsz=177, num_updates=64700, lr=0.000124322, gnorm=0.915, train_wall=15, wall=0
2024-07-31 23:43:51 | INFO | train_inner | epoch 004:  13728 / 17024 loss=6.993, nll_loss=5.962, ppl=62.35, wps=25618.2, ups=6.47, wpb=3957, bsz=150.5, num_updates=64800, lr=0.000124226, gnorm=0.903, train_wall=15, wall=0
2024-07-31 23:44:06 | INFO | train_inner | epoch 004:  13828 / 17024 loss=7.079, nll_loss=6.061, ppl=66.76, wps=25635.4, ups=6.47, wpb=3963, bsz=177.1, num_updates=64900, lr=0.00012413, gnorm=0.959, train_wall=15, wall=0
2024-07-31 23:44:22 | INFO | train_inner | epoch 004:  13928 / 17024 loss=7.033, nll_loss=6.009, ppl=64.42, wps=25711.3, ups=6.49, wpb=3963.5, bsz=172.6, num_updates=65000, lr=0.000124035, gnorm=0.926, train_wall=15, wall=0
2024-07-31 23:44:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:44:23 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.269 | nll_loss 6.22 | ppl 74.56 | wps 96588 | wpb 3529.1 | bsz 62.9 | num_updates 65000 | best_loss 7.264
2024-07-31 23:44:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:44:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_65000.pt (epoch 4 @ 65000 updates, score 7.269) (writing took 3.3382638739421964 seconds)
2024-07-31 23:44:42 | INFO | train_inner | epoch 004:  14028 / 17024 loss=6.999, nll_loss=5.969, ppl=62.64, wps=19627.8, ups=4.95, wpb=3965.2, bsz=160.7, num_updates=65100, lr=0.000123939, gnorm=0.922, train_wall=15, wall=0
2024-07-31 23:44:57 | INFO | train_inner | epoch 004:  14128 / 17024 loss=7.034, nll_loss=6.009, ppl=64.42, wps=25681.1, ups=6.49, wpb=3959.4, bsz=157.2, num_updates=65200, lr=0.000123844, gnorm=0.932, train_wall=15, wall=0
2024-07-31 23:45:13 | INFO | train_inner | epoch 004:  14228 / 17024 loss=7.079, nll_loss=6.062, ppl=66.83, wps=25545.8, ups=6.49, wpb=3938.4, bsz=173.5, num_updates=65300, lr=0.000123749, gnorm=0.95, train_wall=15, wall=0
2024-07-31 23:45:28 | INFO | train_inner | epoch 004:  14328 / 17024 loss=7.042, nll_loss=6.019, ppl=64.86, wps=25655.8, ups=6.46, wpb=3973.8, bsz=170.1, num_updates=65400, lr=0.000123655, gnorm=0.928, train_wall=15, wall=0
2024-07-31 23:45:44 | INFO | train_inner | epoch 004:  14428 / 17024 loss=7.046, nll_loss=6.024, ppl=65.06, wps=25721.5, ups=6.48, wpb=3968.5, bsz=170.1, num_updates=65500, lr=0.00012356, gnorm=0.936, train_wall=15, wall=0
2024-07-31 23:45:59 | INFO | train_inner | epoch 004:  14528 / 17024 loss=7.012, nll_loss=5.984, ppl=63.3, wps=25726.1, ups=6.47, wpb=3975.4, bsz=164.2, num_updates=65600, lr=0.000123466, gnorm=0.912, train_wall=15, wall=0
2024-07-31 23:46:15 | INFO | train_inner | epoch 004:  14628 / 17024 loss=7.043, nll_loss=6.021, ppl=64.92, wps=25687.6, ups=6.48, wpb=3964.3, bsz=174.1, num_updates=65700, lr=0.000123372, gnorm=0.954, train_wall=15, wall=0
2024-07-31 23:46:30 | INFO | train_inner | epoch 004:  14728 / 17024 loss=7.048, nll_loss=6.027, ppl=65.19, wps=25646.8, ups=6.49, wpb=3954.6, bsz=163.9, num_updates=65800, lr=0.000123278, gnorm=0.939, train_wall=15, wall=0
2024-07-31 23:46:45 | INFO | train_inner | epoch 004:  14828 / 17024 loss=7.039, nll_loss=6.015, ppl=64.69, wps=25677.7, ups=6.52, wpb=3938.2, bsz=167.6, num_updates=65900, lr=0.000123185, gnorm=0.977, train_wall=15, wall=0
2024-07-31 23:47:01 | INFO | train_inner | epoch 004:  14928 / 17024 loss=7.031, nll_loss=6.007, ppl=64.29, wps=25705.9, ups=6.52, wpb=3944.9, bsz=152.3, num_updates=66000, lr=0.000123091, gnorm=0.904, train_wall=15, wall=0
2024-07-31 23:47:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:47:02 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.257 | nll_loss 6.204 | ppl 73.74 | wps 94940.1 | wpb 3529.1 | bsz 62.9 | num_updates 66000 | best_loss 7.257
2024-07-31 23:47:02 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:47:07 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_66000.pt (epoch 4 @ 66000 updates, score 7.257) (writing took 4.961443050764501 seconds)
2024-07-31 23:47:23 | INFO | train_inner | epoch 004:  15028 / 17024 loss=7.043, nll_loss=6.021, ppl=64.92, wps=18053.3, ups=4.57, wpb=3947.3, bsz=166.1, num_updates=66100, lr=0.000122998, gnorm=0.947, train_wall=15, wall=0
2024-07-31 23:47:38 | INFO | train_inner | epoch 004:  15128 / 17024 loss=7.056, nll_loss=6.035, ppl=65.59, wps=25586.8, ups=6.45, wpb=3967.6, bsz=171.1, num_updates=66200, lr=0.000122905, gnorm=0.916, train_wall=15, wall=0
2024-07-31 23:47:54 | INFO | train_inner | epoch 004:  15228 / 17024 loss=6.987, nll_loss=5.956, ppl=62.08, wps=25575.9, ups=6.42, wpb=3981.1, bsz=165, num_updates=66300, lr=0.000122813, gnorm=0.892, train_wall=15, wall=0
2024-07-31 23:48:09 | INFO | train_inner | epoch 004:  15328 / 17024 loss=7.037, nll_loss=6.013, ppl=64.59, wps=25669.9, ups=6.46, wpb=3972, bsz=164.2, num_updates=66400, lr=0.00012272, gnorm=0.919, train_wall=15, wall=0
2024-07-31 23:48:24 | INFO | train_inner | epoch 004:  15428 / 17024 loss=7.026, nll_loss=6.001, ppl=64.05, wps=25633.6, ups=6.51, wpb=3938.9, bsz=163.7, num_updates=66500, lr=0.000122628, gnorm=0.945, train_wall=15, wall=0
2024-07-31 23:48:40 | INFO | train_inner | epoch 004:  15528 / 17024 loss=7.019, nll_loss=5.992, ppl=63.63, wps=25637.6, ups=6.47, wpb=3964.4, bsz=160, num_updates=66600, lr=0.000122536, gnorm=0.911, train_wall=15, wall=0
2024-07-31 23:48:55 | INFO | train_inner | epoch 004:  15628 / 17024 loss=7.011, nll_loss=5.984, ppl=63.3, wps=25520, ups=6.5, wpb=3923.9, bsz=161, num_updates=66700, lr=0.000122444, gnorm=0.926, train_wall=15, wall=0
2024-07-31 23:49:11 | INFO | train_inner | epoch 004:  15728 / 17024 loss=6.982, nll_loss=5.95, ppl=61.82, wps=25639.6, ups=6.46, wpb=3970.1, bsz=153, num_updates=66800, lr=0.000122352, gnorm=0.904, train_wall=15, wall=0
2024-07-31 23:49:26 | INFO | train_inner | epoch 004:  15828 / 17024 loss=7.059, nll_loss=6.039, ppl=65.75, wps=25631.7, ups=6.45, wpb=3973, bsz=187.1, num_updates=66900, lr=0.000122261, gnorm=0.96, train_wall=15, wall=0
2024-07-31 23:49:42 | INFO | train_inner | epoch 004:  15928 / 17024 loss=6.998, nll_loss=5.968, ppl=62.6, wps=25690.4, ups=6.46, wpb=3975.1, bsz=159.1, num_updates=67000, lr=0.000122169, gnorm=0.89, train_wall=15, wall=0
2024-07-31 23:49:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:49:43 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.258 | nll_loss 6.208 | ppl 73.94 | wps 96446.5 | wpb 3529.1 | bsz 62.9 | num_updates 67000 | best_loss 7.257
2024-07-31 23:49:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:49:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_67000.pt (epoch 4 @ 67000 updates, score 7.258) (writing took 3.6655934853479266 seconds)
2024-07-31 23:50:02 | INFO | train_inner | epoch 004:  16028 / 17024 loss=7.003, nll_loss=5.975, ppl=62.9, wps=19233.8, ups=4.88, wpb=3943.7, bsz=149.5, num_updates=67100, lr=0.000122078, gnorm=0.915, train_wall=15, wall=0
2024-07-31 23:50:18 | INFO | train_inner | epoch 004:  16128 / 17024 loss=7.026, nll_loss=6, ppl=64.01, wps=25480, ups=6.39, wpb=3986.3, bsz=163.3, num_updates=67200, lr=0.000121988, gnorm=0.91, train_wall=15, wall=0
2024-07-31 23:50:33 | INFO | train_inner | epoch 004:  16228 / 17024 loss=7.019, nll_loss=5.993, ppl=63.69, wps=25572.4, ups=6.43, wpb=3976.1, bsz=165, num_updates=67300, lr=0.000121897, gnorm=0.916, train_wall=15, wall=0
2024-07-31 23:50:49 | INFO | train_inner | epoch 004:  16328 / 17024 loss=7.046, nll_loss=6.024, ppl=65.09, wps=25695.2, ups=6.47, wpb=3969.4, bsz=183.8, num_updates=67400, lr=0.000121806, gnorm=0.941, train_wall=15, wall=0
2024-07-31 23:51:04 | INFO | train_inner | epoch 004:  16428 / 17024 loss=6.96, nll_loss=5.925, ppl=60.77, wps=25603.8, ups=6.45, wpb=3969.4, bsz=157, num_updates=67500, lr=0.000121716, gnorm=0.903, train_wall=15, wall=0
2024-07-31 23:51:20 | INFO | train_inner | epoch 004:  16528 / 17024 loss=6.984, nll_loss=5.951, ppl=61.88, wps=25662.4, ups=6.49, wpb=3952, bsz=145.8, num_updates=67600, lr=0.000121626, gnorm=0.919, train_wall=15, wall=0
2024-07-31 23:51:35 | INFO | train_inner | epoch 004:  16628 / 17024 loss=7.015, nll_loss=5.99, ppl=63.54, wps=25551.2, ups=6.46, wpb=3955.8, bsz=165, num_updates=67700, lr=0.000121536, gnorm=0.909, train_wall=15, wall=0
2024-07-31 23:51:51 | INFO | train_inner | epoch 004:  16728 / 17024 loss=7.004, nll_loss=5.976, ppl=62.92, wps=25748.1, ups=6.49, wpb=3965.5, bsz=160.6, num_updates=67800, lr=0.000121447, gnorm=0.917, train_wall=15, wall=0
2024-07-31 23:52:06 | INFO | train_inner | epoch 004:  16828 / 17024 loss=7.052, nll_loss=6.031, ppl=65.4, wps=25643.2, ups=6.46, wpb=3968.1, bsz=175.9, num_updates=67900, lr=0.000121357, gnorm=0.96, train_wall=15, wall=0
2024-07-31 23:52:22 | INFO | train_inner | epoch 004:  16928 / 17024 loss=7.034, nll_loss=6.01, ppl=64.45, wps=25819.1, ups=6.51, wpb=3966.2, bsz=177.3, num_updates=68000, lr=0.000121268, gnorm=0.92, train_wall=15, wall=0
2024-07-31 23:52:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:52:23 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.268 | nll_loss 6.216 | ppl 74.31 | wps 94245.7 | wpb 3529.1 | bsz 62.9 | num_updates 68000 | best_loss 7.257
2024-07-31 23:52:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:52:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_68000.pt (epoch 4 @ 68000 updates, score 7.268) (writing took 4.097895311191678 seconds)
2024-07-31 23:52:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:52:43 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.28 | nll_loss 6.232 | ppl 75.16 | wps 95239.2 | wpb 3529.1 | bsz 62.9 | num_updates 68096 | best_loss 7.257
2024-07-31 23:52:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:52:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 4 @ 68096 updates, score 7.28) (writing took 3.286032092757523 seconds)
2024-07-31 23:52:47 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2024-07-31 23:52:47 | INFO | train | epoch 004 | loss 7.037 | nll_loss 6.013 | ppl 64.59 | wps 24706.4 | ups 6.24 | wpb 3960.7 | bsz 163.4 | num_updates 68096 | lr 0.000121182 | gnorm 0.914 | train_wall 2598 | wall 0
2024-07-31 23:52:47 | INFO | fairseq.trainer | begin training epoch 5
2024-07-31 23:52:48 | INFO | train_inner | epoch 005:      4 / 17024 loss=7.009, nll_loss=5.981, ppl=63.16, wps=15171.5, ups=3.84, wpb=3952.1, bsz=164.3, num_updates=68100, lr=0.000121179, gnorm=0.931, train_wall=15, wall=0
2024-07-31 23:53:03 | INFO | train_inner | epoch 005:    104 / 17024 loss=7.045, nll_loss=6.024, ppl=65.09, wps=25588.5, ups=6.42, wpb=3987.4, bsz=194.2, num_updates=68200, lr=0.00012109, gnorm=0.932, train_wall=15, wall=0
2024-07-31 23:53:19 | INFO | train_inner | epoch 005:    204 / 17024 loss=6.994, nll_loss=5.964, ppl=62.43, wps=25635.8, ups=6.47, wpb=3963.8, bsz=169, num_updates=68300, lr=0.000121001, gnorm=0.924, train_wall=15, wall=0
2024-07-31 23:53:34 | INFO | train_inner | epoch 005:    304 / 17024 loss=6.991, nll_loss=5.96, ppl=62.25, wps=25563.7, ups=6.42, wpb=3979.3, bsz=165.4, num_updates=68400, lr=0.000120913, gnorm=0.933, train_wall=15, wall=0
2024-07-31 23:53:50 | INFO | train_inner | epoch 005:    404 / 17024 loss=7.019, nll_loss=5.993, ppl=63.68, wps=25493.3, ups=6.45, wpb=3951.6, bsz=164.9, num_updates=68500, lr=0.000120824, gnorm=0.939, train_wall=15, wall=0
2024-07-31 23:54:05 | INFO | train_inner | epoch 005:    504 / 17024 loss=7.025, nll_loss=6, ppl=63.98, wps=25627.2, ups=6.49, wpb=3951.1, bsz=176.2, num_updates=68600, lr=0.000120736, gnorm=0.943, train_wall=15, wall=0
2024-07-31 23:54:21 | INFO | train_inner | epoch 005:    604 / 17024 loss=6.958, nll_loss=5.922, ppl=60.64, wps=25766.8, ups=6.48, wpb=3974.6, bsz=155.4, num_updates=68700, lr=0.000120648, gnorm=0.898, train_wall=15, wall=0
2024-07-31 23:54:36 | INFO | train_inner | epoch 005:    704 / 17024 loss=7.033, nll_loss=6.009, ppl=64.39, wps=25725.2, ups=6.49, wpb=3966.4, bsz=174.3, num_updates=68800, lr=0.000120561, gnorm=0.982, train_wall=15, wall=0
2024-07-31 23:54:51 | INFO | train_inner | epoch 005:    804 / 17024 loss=6.975, nll_loss=5.942, ppl=61.46, wps=25822.7, ups=6.52, wpb=3962.1, bsz=158.4, num_updates=68900, lr=0.000120473, gnorm=0.904, train_wall=15, wall=0
2024-07-31 23:55:07 | INFO | train_inner | epoch 005:    904 / 17024 loss=6.99, nll_loss=5.958, ppl=62.18, wps=25657.6, ups=6.48, wpb=3960.8, bsz=163.1, num_updates=69000, lr=0.000120386, gnorm=0.929, train_wall=15, wall=0
2024-07-31 23:55:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:55:08 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.259 | nll_loss 6.208 | ppl 73.93 | wps 95819.6 | wpb 3529.1 | bsz 62.9 | num_updates 69000 | best_loss 7.257
2024-07-31 23:55:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:55:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_69000.pt (epoch 5 @ 69000 updates, score 7.259) (writing took 3.0103411311283708 seconds)
2024-07-31 23:55:27 | INFO | train_inner | epoch 005:   1004 / 17024 loss=7.08, nll_loss=6.063, ppl=66.83, wps=20069.4, ups=5.04, wpb=3979, bsz=199.1, num_updates=69100, lr=0.000120299, gnorm=1.014, train_wall=15, wall=0
2024-07-31 23:55:42 | INFO | train_inner | epoch 005:   1104 / 17024 loss=7.03, nll_loss=6.006, ppl=64.28, wps=25638.9, ups=6.48, wpb=3959, bsz=186.3, num_updates=69200, lr=0.000120212, gnorm=0.944, train_wall=15, wall=0
2024-07-31 23:55:58 | INFO | train_inner | epoch 005:   1204 / 17024 loss=6.985, nll_loss=5.954, ppl=61.97, wps=25728, ups=6.46, wpb=3983.1, bsz=167.4, num_updates=69300, lr=0.000120125, gnorm=0.904, train_wall=15, wall=0
2024-07-31 23:56:13 | INFO | train_inner | epoch 005:   1304 / 17024 loss=6.982, nll_loss=5.949, ppl=61.77, wps=25720.4, ups=6.48, wpb=3970.6, bsz=159.9, num_updates=69400, lr=0.000120038, gnorm=0.966, train_wall=15, wall=0
2024-07-31 23:56:28 | INFO | train_inner | epoch 005:   1404 / 17024 loss=6.984, nll_loss=5.953, ppl=61.94, wps=25649.9, ups=6.46, wpb=3969.1, bsz=163.4, num_updates=69500, lr=0.000119952, gnorm=0.902, train_wall=15, wall=0
2024-07-31 23:56:44 | INFO | train_inner | epoch 005:   1504 / 17024 loss=6.961, nll_loss=5.926, ppl=60.78, wps=25712.9, ups=6.49, wpb=3960.4, bsz=157.1, num_updates=69600, lr=0.000119866, gnorm=0.923, train_wall=15, wall=0
2024-07-31 23:56:59 | INFO | train_inner | epoch 005:   1604 / 17024 loss=6.994, nll_loss=5.964, ppl=62.4, wps=25675.2, ups=6.48, wpb=3962.6, bsz=161.4, num_updates=69700, lr=0.00011978, gnorm=0.929, train_wall=15, wall=0
2024-07-31 23:57:15 | INFO | train_inner | epoch 005:   1704 / 17024 loss=6.967, nll_loss=5.932, ppl=61.07, wps=25609.6, ups=6.48, wpb=3952.7, bsz=152.5, num_updates=69800, lr=0.000119694, gnorm=0.915, train_wall=15, wall=0
2024-07-31 23:57:30 | INFO | train_inner | epoch 005:   1804 / 17024 loss=6.969, nll_loss=5.933, ppl=61.12, wps=25668.9, ups=6.48, wpb=3961.7, bsz=157.4, num_updates=69900, lr=0.000119608, gnorm=0.928, train_wall=15, wall=0
2024-07-31 23:57:46 | INFO | train_inner | epoch 005:   1904 / 17024 loss=7.048, nll_loss=6.025, ppl=65.14, wps=25714.4, ups=6.48, wpb=3968.7, bsz=182.8, num_updates=70000, lr=0.000119523, gnorm=0.98, train_wall=15, wall=0
2024-07-31 23:57:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-31 23:57:47 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.263 | nll_loss 6.213 | ppl 74.18 | wps 96543.7 | wpb 3529.1 | bsz 62.9 | num_updates 70000 | best_loss 7.257
2024-07-31 23:57:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-31 23:57:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_70000.pt (epoch 5 @ 70000 updates, score 7.263) (writing took 3.1088940585032105 seconds)
2024-07-31 23:58:06 | INFO | train_inner | epoch 005:   2004 / 17024 loss=7.037, nll_loss=6.014, ppl=64.61, wps=19876.1, ups=4.99, wpb=3979.8, bsz=175.3, num_updates=70100, lr=0.000119438, gnorm=0.937, train_wall=15, wall=0
2024-07-31 23:58:21 | INFO | train_inner | epoch 005:   2104 / 17024 loss=7.021, nll_loss=5.994, ppl=63.75, wps=25706.7, ups=6.47, wpb=3974.1, bsz=164.4, num_updates=70200, lr=0.000119352, gnorm=0.935, train_wall=15, wall=0
2024-07-31 23:58:36 | INFO | train_inner | epoch 005:   2204 / 17024 loss=7.068, nll_loss=6.049, ppl=66.19, wps=25626, ups=6.49, wpb=3950.5, bsz=181.3, num_updates=70300, lr=0.000119268, gnorm=0.973, train_wall=15, wall=0
2024-07-31 23:58:52 | INFO | train_inner | epoch 005:   2304 / 17024 loss=6.986, nll_loss=5.955, ppl=62.02, wps=25648.2, ups=6.48, wpb=3956.9, bsz=165.9, num_updates=70400, lr=0.000119183, gnorm=0.915, train_wall=15, wall=0
2024-07-31 23:59:07 | INFO | train_inner | epoch 005:   2404 / 17024 loss=7.016, nll_loss=5.989, ppl=63.52, wps=25685.6, ups=6.49, wpb=3959.2, bsz=173.6, num_updates=70500, lr=0.000119098, gnorm=0.935, train_wall=15, wall=0
2024-07-31 23:59:23 | INFO | train_inner | epoch 005:   2504 / 17024 loss=6.97, nll_loss=5.935, ppl=61.19, wps=25861.8, ups=6.53, wpb=3959.5, bsz=151, num_updates=70600, lr=0.000119014, gnorm=0.917, train_wall=15, wall=0
2024-07-31 23:59:38 | INFO | train_inner | epoch 005:   2604 / 17024 loss=7.016, nll_loss=5.99, ppl=63.54, wps=25665.3, ups=6.47, wpb=3968.3, bsz=172.6, num_updates=70700, lr=0.00011893, gnorm=0.95, train_wall=15, wall=0
2024-07-31 23:59:54 | INFO | train_inner | epoch 005:   2704 / 17024 loss=7, nll_loss=5.97, ppl=62.68, wps=25594.9, ups=6.45, wpb=3966.7, bsz=156.2, num_updates=70800, lr=0.000118846, gnorm=0.962, train_wall=15, wall=0
2024-08-01 00:00:09 | INFO | train_inner | epoch 005:   2804 / 17024 loss=7.01, nll_loss=5.982, ppl=63.21, wps=25229.3, ups=6.34, wpb=3981.6, bsz=169.2, num_updates=70900, lr=0.000118762, gnorm=0.931, train_wall=16, wall=0
2024-08-01 00:00:25 | INFO | train_inner | epoch 005:   2904 / 17024 loss=7.001, nll_loss=5.972, ppl=62.75, wps=25553, ups=6.48, wpb=3946.4, bsz=163, num_updates=71000, lr=0.000118678, gnorm=0.939, train_wall=15, wall=0
2024-08-01 00:00:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:00:26 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.257 | nll_loss 6.207 | ppl 73.88 | wps 94871.4 | wpb 3529.1 | bsz 62.9 | num_updates 71000 | best_loss 7.257
2024-08-01 00:00:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:00:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_71000.pt (epoch 5 @ 71000 updates, score 7.257) (writing took 5.338105542585254 seconds)
2024-08-01 00:00:47 | INFO | train_inner | epoch 005:   3004 / 17024 loss=6.985, nll_loss=5.953, ppl=61.93, wps=17837.1, ups=4.5, wpb=3964.6, bsz=151, num_updates=71100, lr=0.000118595, gnorm=0.946, train_wall=15, wall=0
2024-08-01 00:01:02 | INFO | train_inner | epoch 005:   3104 / 17024 loss=7.001, nll_loss=5.971, ppl=62.72, wps=25558.6, ups=6.5, wpb=3929.1, bsz=148, num_updates=71200, lr=0.000118511, gnorm=0.956, train_wall=15, wall=0
2024-08-01 00:01:18 | INFO | train_inner | epoch 005:   3204 / 17024 loss=7.003, nll_loss=5.974, ppl=62.85, wps=25551.8, ups=6.46, wpb=3953.4, bsz=160.2, num_updates=71300, lr=0.000118428, gnorm=0.955, train_wall=15, wall=0
2024-08-01 00:01:33 | INFO | train_inner | epoch 005:   3304 / 17024 loss=6.966, nll_loss=5.93, ppl=60.98, wps=25787.9, ups=6.54, wpb=3946.1, bsz=147.9, num_updates=71400, lr=0.000118345, gnorm=0.923, train_wall=15, wall=0
2024-08-01 00:01:49 | INFO | train_inner | epoch 005:   3404 / 17024 loss=7.016, nll_loss=5.988, ppl=63.48, wps=25687.4, ups=6.53, wpb=3933.8, bsz=158.6, num_updates=71500, lr=0.000118262, gnorm=0.958, train_wall=15, wall=0
2024-08-01 00:02:04 | INFO | train_inner | epoch 005:   3504 / 17024 loss=6.996, nll_loss=5.966, ppl=62.49, wps=25735.1, ups=6.48, wpb=3970.4, bsz=158.2, num_updates=71600, lr=0.00011818, gnorm=0.938, train_wall=15, wall=0
2024-08-01 00:02:19 | INFO | train_inner | epoch 005:   3604 / 17024 loss=6.98, nll_loss=5.947, ppl=61.68, wps=25543.3, ups=6.44, wpb=3967.9, bsz=148.2, num_updates=71700, lr=0.000118097, gnorm=0.908, train_wall=15, wall=0
2024-08-01 00:02:35 | INFO | train_inner | epoch 005:   3704 / 17024 loss=7.038, nll_loss=6.014, ppl=64.63, wps=25611.7, ups=6.4, wpb=4002.3, bsz=189.8, num_updates=71800, lr=0.000118015, gnorm=0.953, train_wall=15, wall=0
2024-08-01 00:02:51 | INFO | train_inner | epoch 005:   3804 / 17024 loss=7.082, nll_loss=6.066, ppl=66.98, wps=25648.4, ups=6.45, wpb=3975.9, bsz=196.4, num_updates=71900, lr=0.000117933, gnorm=0.979, train_wall=15, wall=0
2024-08-01 00:03:06 | INFO | train_inner | epoch 005:   3904 / 17024 loss=7.002, nll_loss=5.972, ppl=62.79, wps=25481.1, ups=6.46, wpb=3946.9, bsz=161.9, num_updates=72000, lr=0.000117851, gnorm=0.937, train_wall=15, wall=0
2024-08-01 00:03:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:03:08 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.251 | nll_loss 6.199 | ppl 73.45 | wps 95486.4 | wpb 3529.1 | bsz 62.9 | num_updates 72000 | best_loss 7.251
2024-08-01 00:03:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:03:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_72000.pt (epoch 5 @ 72000 updates, score 7.251) (writing took 7.930843433365226 seconds)
2024-08-01 00:03:31 | INFO | train_inner | epoch 005:   4004 / 17024 loss=6.973, nll_loss=5.94, ppl=61.39, wps=15919.1, ups=4.02, wpb=3961.1, bsz=154.4, num_updates=72100, lr=0.000117769, gnorm=0.923, train_wall=15, wall=0
2024-08-01 00:03:46 | INFO | train_inner | epoch 005:   4104 / 17024 loss=7.04, nll_loss=6.017, ppl=64.75, wps=25477, ups=6.47, wpb=3939.1, bsz=188.2, num_updates=72200, lr=0.000117688, gnorm=0.997, train_wall=15, wall=0
2024-08-01 00:04:02 | INFO | train_inner | epoch 005:   4204 / 17024 loss=7.008, nll_loss=5.981, ppl=63.14, wps=25556.4, ups=6.47, wpb=3949, bsz=167, num_updates=72300, lr=0.000117606, gnorm=0.94, train_wall=15, wall=0
2024-08-01 00:04:17 | INFO | train_inner | epoch 005:   4304 / 17024 loss=6.996, nll_loss=5.966, ppl=62.51, wps=25516.8, ups=6.44, wpb=3959.6, bsz=167.4, num_updates=72400, lr=0.000117525, gnorm=0.929, train_wall=15, wall=0
2024-08-01 00:04:33 | INFO | train_inner | epoch 005:   4404 / 17024 loss=7.007, nll_loss=5.978, ppl=63.05, wps=25641.1, ups=6.51, wpb=3937.7, bsz=161.1, num_updates=72500, lr=0.000117444, gnorm=0.951, train_wall=15, wall=0
2024-08-01 00:04:48 | INFO | train_inner | epoch 005:   4504 / 17024 loss=7, nll_loss=5.971, ppl=62.73, wps=25624.5, ups=6.45, wpb=3970.1, bsz=173.8, num_updates=72600, lr=0.000117363, gnorm=0.927, train_wall=15, wall=0
2024-08-01 00:05:04 | INFO | train_inner | epoch 005:   4604 / 17024 loss=6.97, nll_loss=5.937, ppl=61.24, wps=25543.6, ups=6.44, wpb=3966.4, bsz=150.5, num_updates=72700, lr=0.000117282, gnorm=0.91, train_wall=15, wall=0
2024-08-01 00:05:19 | INFO | train_inner | epoch 005:   4704 / 17024 loss=6.992, nll_loss=5.962, ppl=62.34, wps=25628.3, ups=6.44, wpb=3980.5, bsz=171.8, num_updates=72800, lr=0.000117202, gnorm=0.934, train_wall=15, wall=0
2024-08-01 00:05:35 | INFO | train_inner | epoch 005:   4804 / 17024 loss=6.994, nll_loss=5.964, ppl=62.42, wps=25770, ups=6.46, wpb=3989.7, bsz=160.2, num_updates=72900, lr=0.000117121, gnorm=0.943, train_wall=15, wall=0
2024-08-01 00:05:50 | INFO | train_inner | epoch 005:   4904 / 17024 loss=6.998, nll_loss=5.968, ppl=62.58, wps=25568.5, ups=6.44, wpb=3968, bsz=163, num_updates=73000, lr=0.000117041, gnorm=0.928, train_wall=15, wall=0
2024-08-01 00:05:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:05:52 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.253 | nll_loss 6.2 | ppl 73.53 | wps 94292.5 | wpb 3529.1 | bsz 62.9 | num_updates 73000 | best_loss 7.251
2024-08-01 00:05:52 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:05:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_73000.pt (epoch 5 @ 73000 updates, score 7.253) (writing took 3.7488953936845064 seconds)
2024-08-01 00:06:11 | INFO | train_inner | epoch 005:   5004 / 17024 loss=7.004, nll_loss=5.975, ppl=62.88, wps=19076.8, ups=4.81, wpb=3967.6, bsz=171.5, num_updates=73100, lr=0.000116961, gnorm=0.963, train_wall=15, wall=0
2024-08-01 00:06:27 | INFO | train_inner | epoch 005:   5104 / 17024 loss=6.947, nll_loss=5.909, ppl=60.1, wps=25511.8, ups=6.44, wpb=3961.7, bsz=164, num_updates=73200, lr=0.000116881, gnorm=0.941, train_wall=15, wall=0
2024-08-01 00:06:42 | INFO | train_inner | epoch 005:   5204 / 17024 loss=6.97, nll_loss=5.936, ppl=61.22, wps=25793, ups=6.55, wpb=3937.5, bsz=152.1, num_updates=73300, lr=0.000116801, gnorm=0.94, train_wall=15, wall=0
2024-08-01 00:06:57 | INFO | train_inner | epoch 005:   5304 / 17024 loss=6.989, nll_loss=5.957, ppl=62.14, wps=25550.5, ups=6.48, wpb=3944.6, bsz=152.7, num_updates=73400, lr=0.000116722, gnorm=0.951, train_wall=15, wall=0
2024-08-01 00:07:13 | INFO | train_inner | epoch 005:   5404 / 17024 loss=6.992, nll_loss=5.962, ppl=62.36, wps=25803.1, ups=6.44, wpb=4007, bsz=179.3, num_updates=73500, lr=0.000116642, gnorm=0.926, train_wall=15, wall=0
2024-08-01 00:07:28 | INFO | train_inner | epoch 005:   5504 / 17024 loss=6.977, nll_loss=5.944, ppl=61.57, wps=25703.2, ups=6.52, wpb=3943.3, bsz=156.8, num_updates=73600, lr=0.000116563, gnorm=0.951, train_wall=15, wall=0
2024-08-01 00:07:44 | INFO | train_inner | epoch 005:   5604 / 17024 loss=6.951, nll_loss=5.914, ppl=60.3, wps=25679.6, ups=6.5, wpb=3950.2, bsz=142.2, num_updates=73700, lr=0.000116484, gnorm=0.923, train_wall=15, wall=0
2024-08-01 00:07:59 | INFO | train_inner | epoch 005:   5704 / 17024 loss=7.026, nll_loss=6.001, ppl=64.03, wps=25601.5, ups=6.43, wpb=3979.5, bsz=176.4, num_updates=73800, lr=0.000116405, gnorm=0.952, train_wall=15, wall=0
2024-08-01 00:08:14 | INFO | train_inner | epoch 005:   5804 / 17024 loss=6.983, nll_loss=5.951, ppl=61.87, wps=25931.1, ups=6.56, wpb=3953.7, bsz=159.6, num_updates=73900, lr=0.000116326, gnorm=0.935, train_wall=15, wall=0
2024-08-01 00:08:30 | INFO | train_inner | epoch 005:   5904 / 17024 loss=7.011, nll_loss=5.982, ppl=63.23, wps=25632.1, ups=6.5, wpb=3943.2, bsz=154.5, num_updates=74000, lr=0.000116248, gnorm=0.948, train_wall=15, wall=0
2024-08-01 00:08:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:08:31 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.246 | nll_loss 6.186 | ppl 72.81 | wps 95591.7 | wpb 3529.1 | bsz 62.9 | num_updates 74000 | best_loss 7.246
2024-08-01 00:08:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:08:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_74000.pt (epoch 5 @ 74000 updates, score 7.246) (writing took 4.858074954710901 seconds)
2024-08-01 00:08:51 | INFO | train_inner | epoch 005:   6004 / 17024 loss=6.931, nll_loss=5.89, ppl=59.32, wps=18163.9, ups=4.63, wpb=3926, bsz=133.4, num_updates=74100, lr=0.000116169, gnorm=0.913, train_wall=15, wall=0
2024-08-01 00:09:07 | INFO | train_inner | epoch 005:   6104 / 17024 loss=7.018, nll_loss=5.991, ppl=63.6, wps=25716.3, ups=6.49, wpb=3960.7, bsz=172.1, num_updates=74200, lr=0.000116091, gnorm=0.956, train_wall=15, wall=0
2024-08-01 00:09:22 | INFO | train_inner | epoch 005:   6204 / 17024 loss=6.998, nll_loss=5.969, ppl=62.62, wps=25668.7, ups=6.48, wpb=3958.9, bsz=163, num_updates=74300, lr=0.000116013, gnorm=0.944, train_wall=15, wall=0
2024-08-01 00:09:38 | INFO | train_inner | epoch 005:   6304 / 17024 loss=7.02, nll_loss=5.994, ppl=63.72, wps=25535.6, ups=6.54, wpb=3907.5, bsz=163, num_updates=74400, lr=0.000115935, gnorm=0.973, train_wall=15, wall=0
2024-08-01 00:09:53 | INFO | train_inner | epoch 005:   6404 / 17024 loss=6.972, nll_loss=5.938, ppl=61.31, wps=25655.3, ups=6.48, wpb=3957.8, bsz=151.8, num_updates=74500, lr=0.000115857, gnorm=0.929, train_wall=15, wall=0
2024-08-01 00:10:08 | INFO | train_inner | epoch 005:   6504 / 17024 loss=6.967, nll_loss=5.932, ppl=61.04, wps=25742.5, ups=6.52, wpb=3949.7, bsz=142.2, num_updates=74600, lr=0.000115779, gnorm=0.925, train_wall=15, wall=0
2024-08-01 00:10:24 | INFO | train_inner | epoch 005:   6604 / 17024 loss=7.006, nll_loss=5.977, ppl=62.97, wps=25501, ups=6.44, wpb=3961.4, bsz=165.9, num_updates=74700, lr=0.000115702, gnorm=0.939, train_wall=15, wall=0
2024-08-01 00:10:39 | INFO | train_inner | epoch 005:   6704 / 17024 loss=6.981, nll_loss=5.948, ppl=61.73, wps=25726.9, ups=6.51, wpb=3953.7, bsz=150, num_updates=74800, lr=0.000115624, gnorm=0.931, train_wall=15, wall=0
2024-08-01 00:10:55 | INFO | train_inner | epoch 005:   6804 / 17024 loss=6.912, nll_loss=5.868, ppl=58.42, wps=25619.7, ups=6.5, wpb=3938.7, bsz=137.7, num_updates=74900, lr=0.000115547, gnorm=0.916, train_wall=15, wall=0
2024-08-01 00:11:10 | INFO | train_inner | epoch 005:   6904 / 17024 loss=7, nll_loss=5.97, ppl=62.68, wps=25651.4, ups=6.49, wpb=3952, bsz=157.2, num_updates=75000, lr=0.00011547, gnorm=0.956, train_wall=15, wall=0
2024-08-01 00:11:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:11:11 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.235 | nll_loss 6.18 | ppl 72.5 | wps 95825.8 | wpb 3529.1 | bsz 62.9 | num_updates 75000 | best_loss 7.235
2024-08-01 00:11:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:11:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_75000.pt (epoch 5 @ 75000 updates, score 7.235) (writing took 4.713622708804905 seconds)
2024-08-01 00:11:32 | INFO | train_inner | epoch 005:   7004 / 17024 loss=6.989, nll_loss=5.958, ppl=62.16, wps=18362.9, ups=4.64, wpb=3959.6, bsz=152.6, num_updates=75100, lr=0.000115393, gnorm=0.925, train_wall=15, wall=0
2024-08-01 00:11:47 | INFO | train_inner | epoch 005:   7104 / 17024 loss=7.011, nll_loss=5.983, ppl=63.25, wps=25829.7, ups=6.52, wpb=3961.4, bsz=173.5, num_updates=75200, lr=0.000115316, gnorm=0.963, train_wall=15, wall=0
2024-08-01 00:12:02 | INFO | train_inner | epoch 005:   7204 / 17024 loss=6.982, nll_loss=5.95, ppl=61.83, wps=25718.2, ups=6.47, wpb=3974.2, bsz=157.4, num_updates=75300, lr=0.00011524, gnorm=0.95, train_wall=15, wall=0
2024-08-01 00:12:18 | INFO | train_inner | epoch 005:   7304 / 17024 loss=7, nll_loss=5.97, ppl=62.68, wps=25575.7, ups=6.46, wpb=3958.3, bsz=169.5, num_updates=75400, lr=0.000115163, gnorm=0.953, train_wall=15, wall=0
2024-08-01 00:12:33 | INFO | train_inner | epoch 005:   7404 / 17024 loss=6.93, nll_loss=5.89, ppl=59.28, wps=25768, ups=6.51, wpb=3958.7, bsz=142.2, num_updates=75500, lr=0.000115087, gnorm=0.916, train_wall=15, wall=0
2024-08-01 00:12:48 | INFO | train_inner | epoch 005:   7504 / 17024 loss=6.978, nll_loss=5.945, ppl=61.61, wps=25765.8, ups=6.53, wpb=3946.2, bsz=163, num_updates=75600, lr=0.000115011, gnorm=0.958, train_wall=15, wall=0
2024-08-01 00:13:04 | INFO | train_inner | epoch 005:   7604 / 17024 loss=6.962, nll_loss=5.928, ppl=60.87, wps=25445.5, ups=6.42, wpb=3962.4, bsz=159.4, num_updates=75700, lr=0.000114935, gnorm=0.926, train_wall=15, wall=0
2024-08-01 00:13:20 | INFO | train_inner | epoch 005:   7704 / 17024 loss=6.985, nll_loss=5.953, ppl=61.96, wps=25532.3, ups=6.46, wpb=3955.2, bsz=154.5, num_updates=75800, lr=0.000114859, gnorm=0.924, train_wall=15, wall=0
2024-08-01 00:13:35 | INFO | train_inner | epoch 005:   7804 / 17024 loss=7.029, nll_loss=6.004, ppl=64.17, wps=25638.8, ups=6.46, wpb=3971.4, bsz=171.1, num_updates=75900, lr=0.000114783, gnorm=0.988, train_wall=15, wall=0
2024-08-01 00:13:50 | INFO | train_inner | epoch 005:   7904 / 17024 loss=6.984, nll_loss=5.952, ppl=61.9, wps=25626.8, ups=6.49, wpb=3948.9, bsz=155.8, num_updates=76000, lr=0.000114708, gnorm=0.938, train_wall=15, wall=0
2024-08-01 00:13:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:13:52 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.236 | nll_loss 6.179 | ppl 72.43 | wps 94707.6 | wpb 3529.1 | bsz 62.9 | num_updates 76000 | best_loss 7.235
2024-08-01 00:13:52 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:13:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_76000.pt (epoch 5 @ 76000 updates, score 7.236) (writing took 3.078041799366474 seconds)
2024-08-01 00:14:10 | INFO | train_inner | epoch 005:   8004 / 17024 loss=6.941, nll_loss=5.903, ppl=59.83, wps=19737.9, ups=5, wpb=3946.1, bsz=145.4, num_updates=76100, lr=0.000114632, gnorm=0.924, train_wall=15, wall=0
2024-08-01 00:14:26 | INFO | train_inner | epoch 005:   8104 / 17024 loss=6.971, nll_loss=5.938, ppl=61.31, wps=25675, ups=6.52, wpb=3937.6, bsz=153, num_updates=76200, lr=0.000114557, gnorm=0.935, train_wall=15, wall=0
2024-08-01 00:14:41 | INFO | train_inner | epoch 005:   8204 / 17024 loss=6.988, nll_loss=5.956, ppl=62.09, wps=25714.7, ups=6.49, wpb=3961.9, bsz=155.4, num_updates=76300, lr=0.000114482, gnorm=0.942, train_wall=15, wall=0
2024-08-01 00:14:57 | INFO | train_inner | epoch 005:   8304 / 17024 loss=6.991, nll_loss=5.96, ppl=62.24, wps=25670.1, ups=6.51, wpb=3945.7, bsz=169.3, num_updates=76400, lr=0.000114407, gnorm=0.954, train_wall=15, wall=0
2024-08-01 00:15:12 | INFO | train_inner | epoch 005:   8404 / 17024 loss=6.934, nll_loss=5.894, ppl=59.48, wps=25558.8, ups=6.44, wpb=3966, bsz=142.5, num_updates=76500, lr=0.000114332, gnorm=0.927, train_wall=15, wall=0
2024-08-01 00:15:28 | INFO | train_inner | epoch 005:   8504 / 17024 loss=6.999, nll_loss=5.97, ppl=62.66, wps=25427.1, ups=6.44, wpb=3951.1, bsz=163.8, num_updates=76600, lr=0.000114258, gnorm=0.958, train_wall=15, wall=0
2024-08-01 00:15:43 | INFO | train_inner | epoch 005:   8604 / 17024 loss=6.97, nll_loss=5.937, ppl=61.25, wps=25784.1, ups=6.55, wpb=3938.8, bsz=147.6, num_updates=76700, lr=0.000114183, gnorm=0.924, train_wall=15, wall=0
2024-08-01 00:15:58 | INFO | train_inner | epoch 005:   8704 / 17024 loss=6.981, nll_loss=5.948, ppl=61.75, wps=25691.1, ups=6.48, wpb=3967.3, bsz=163, num_updates=76800, lr=0.000114109, gnorm=0.947, train_wall=15, wall=0
2024-08-01 00:16:14 | INFO | train_inner | epoch 005:   8804 / 17024 loss=6.989, nll_loss=5.957, ppl=62.13, wps=25810.3, ups=6.53, wpb=3950.3, bsz=159.8, num_updates=76900, lr=0.000114035, gnorm=0.952, train_wall=15, wall=0
2024-08-01 00:16:29 | INFO | train_inner | epoch 005:   8904 / 17024 loss=7.07, nll_loss=6.053, ppl=66.37, wps=25761.4, ups=6.46, wpb=3988, bsz=203, num_updates=77000, lr=0.000113961, gnorm=1.009, train_wall=15, wall=0
2024-08-01 00:16:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:16:31 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.256 | nll_loss 6.203 | ppl 73.67 | wps 94856.5 | wpb 3529.1 | bsz 62.9 | num_updates 77000 | best_loss 7.235
2024-08-01 00:16:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:16:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_77000.pt (epoch 5 @ 77000 updates, score 7.256) (writing took 3.0508721452206373 seconds)
2024-08-01 00:16:49 | INFO | train_inner | epoch 005:   9004 / 17024 loss=7.007, nll_loss=5.979, ppl=63.09, wps=19891.2, ups=5.03, wpb=3956.3, bsz=167.9, num_updates=77100, lr=0.000113887, gnorm=0.977, train_wall=15, wall=0
2024-08-01 00:17:04 | INFO | train_inner | epoch 005:   9104 / 17024 loss=7.01, nll_loss=5.983, ppl=63.25, wps=25755.9, ups=6.47, wpb=3982.4, bsz=167.4, num_updates=77200, lr=0.000113813, gnorm=0.925, train_wall=15, wall=0
2024-08-01 00:17:20 | INFO | train_inner | epoch 005:   9204 / 17024 loss=6.962, nll_loss=5.927, ppl=60.84, wps=25701.9, ups=6.51, wpb=3948, bsz=150.4, num_updates=77300, lr=0.000113739, gnorm=0.944, train_wall=15, wall=0
2024-08-01 00:17:35 | INFO | train_inner | epoch 005:   9304 / 17024 loss=6.987, nll_loss=5.955, ppl=62.06, wps=25732.4, ups=6.47, wpb=3976, bsz=164.3, num_updates=77400, lr=0.000113666, gnorm=0.953, train_wall=15, wall=0
2024-08-01 00:17:51 | INFO | train_inner | epoch 005:   9404 / 17024 loss=6.966, nll_loss=5.932, ppl=61.06, wps=25720.8, ups=6.52, wpb=3945.9, bsz=155.2, num_updates=77500, lr=0.000113592, gnorm=0.947, train_wall=15, wall=0
2024-08-01 00:18:06 | INFO | train_inner | epoch 005:   9504 / 17024 loss=6.955, nll_loss=5.918, ppl=60.46, wps=25712.7, ups=6.5, wpb=3953, bsz=146.3, num_updates=77600, lr=0.000113519, gnorm=0.921, train_wall=15, wall=0
2024-08-01 00:18:22 | INFO | train_inner | epoch 005:   9604 / 17024 loss=6.965, nll_loss=5.93, ppl=60.97, wps=25431, ups=6.44, wpb=3950.2, bsz=145.5, num_updates=77700, lr=0.000113446, gnorm=0.933, train_wall=15, wall=0
2024-08-01 00:18:37 | INFO | train_inner | epoch 005:   9704 / 17024 loss=6.978, nll_loss=5.945, ppl=61.61, wps=25546, ups=6.45, wpb=3961, bsz=163, num_updates=77800, lr=0.000113373, gnorm=0.947, train_wall=15, wall=0
2024-08-01 00:18:52 | INFO | train_inner | epoch 005:   9804 / 17024 loss=7.001, nll_loss=5.972, ppl=62.77, wps=25632.9, ups=6.48, wpb=3955.3, bsz=159.7, num_updates=77900, lr=0.0001133, gnorm=0.951, train_wall=15, wall=0
2024-08-01 00:19:08 | INFO | train_inner | epoch 005:   9904 / 17024 loss=7.028, nll_loss=6.004, ppl=64.16, wps=25635.8, ups=6.47, wpb=3963.7, bsz=175.4, num_updates=78000, lr=0.000113228, gnorm=0.978, train_wall=15, wall=0
2024-08-01 00:19:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:19:09 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.227 | nll_loss 6.172 | ppl 72.09 | wps 93733.1 | wpb 3529.1 | bsz 62.9 | num_updates 78000 | best_loss 7.227
2024-08-01 00:19:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:19:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_78000.pt (epoch 5 @ 78000 updates, score 7.227) (writing took 5.734440694563091 seconds)
2024-08-01 00:19:31 | INFO | train_inner | epoch 005:  10004 / 17024 loss=6.998, nll_loss=5.968, ppl=62.6, wps=17429.2, ups=4.41, wpb=3951.8, bsz=157.6, num_updates=78100, lr=0.000113155, gnorm=0.959, train_wall=15, wall=0
2024-08-01 00:19:46 | INFO | train_inner | epoch 005:  10104 / 17024 loss=7.029, nll_loss=6.004, ppl=64.17, wps=25762.9, ups=6.5, wpb=3963.7, bsz=176.9, num_updates=78200, lr=0.000113083, gnorm=0.962, train_wall=15, wall=0
2024-08-01 00:20:01 | INFO | train_inner | epoch 005:  10204 / 17024 loss=6.974, nll_loss=5.94, ppl=61.4, wps=25638.3, ups=6.49, wpb=3947.6, bsz=152.3, num_updates=78300, lr=0.000113011, gnorm=0.959, train_wall=15, wall=0
2024-08-01 00:20:17 | INFO | train_inner | epoch 005:  10304 / 17024 loss=6.998, nll_loss=5.969, ppl=62.62, wps=25508.7, ups=6.46, wpb=3950.8, bsz=167.8, num_updates=78400, lr=0.000112938, gnorm=0.949, train_wall=15, wall=0
2024-08-01 00:20:32 | INFO | train_inner | epoch 005:  10404 / 17024 loss=6.979, nll_loss=5.946, ppl=61.66, wps=25676, ups=6.49, wpb=3953.6, bsz=164.7, num_updates=78500, lr=0.000112867, gnorm=0.952, train_wall=15, wall=0
2024-08-01 00:20:48 | INFO | train_inner | epoch 005:  10504 / 17024 loss=6.927, nll_loss=5.888, ppl=59.2, wps=25718.2, ups=6.5, wpb=3956.5, bsz=143.8, num_updates=78600, lr=0.000112795, gnorm=0.916, train_wall=15, wall=0
2024-08-01 00:21:03 | INFO | train_inner | epoch 005:  10604 / 17024 loss=6.996, nll_loss=5.965, ppl=62.49, wps=25750.1, ups=6.54, wpb=3935.2, bsz=154.1, num_updates=78700, lr=0.000112723, gnorm=0.952, train_wall=15, wall=0
2024-08-01 00:21:18 | INFO | train_inner | epoch 005:  10704 / 17024 loss=7.035, nll_loss=6.012, ppl=64.52, wps=25724.4, ups=6.48, wpb=3969.3, bsz=184.6, num_updates=78800, lr=0.000112651, gnorm=0.954, train_wall=15, wall=0
2024-08-01 00:21:34 | INFO | train_inner | epoch 005:  10804 / 17024 loss=6.949, nll_loss=5.912, ppl=60.22, wps=25896.4, ups=6.58, wpb=3933.7, bsz=151.9, num_updates=78900, lr=0.00011258, gnorm=0.943, train_wall=15, wall=0
2024-08-01 00:21:49 | INFO | train_inner | epoch 005:  10904 / 17024 loss=6.981, nll_loss=5.949, ppl=61.77, wps=25671.9, ups=6.5, wpb=3948.6, bsz=154.6, num_updates=79000, lr=0.000112509, gnorm=0.954, train_wall=15, wall=0
2024-08-01 00:21:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:21:50 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.228 | nll_loss 6.169 | ppl 71.94 | wps 93786 | wpb 3529.1 | bsz 62.9 | num_updates 79000 | best_loss 7.227
2024-08-01 00:21:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:21:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_79000.pt (epoch 5 @ 79000 updates, score 7.228) (writing took 3.0764908203855157 seconds)
2024-08-01 00:22:09 | INFO | train_inner | epoch 005:  11004 / 17024 loss=7.007, nll_loss=5.98, ppl=63.1, wps=19784.8, ups=4.99, wpb=3962, bsz=173, num_updates=79100, lr=0.000112438, gnorm=0.959, train_wall=15, wall=0
2024-08-01 00:22:24 | INFO | train_inner | epoch 005:  11104 / 17024 loss=6.975, nll_loss=5.942, ppl=61.49, wps=25708, ups=6.49, wpb=3960.4, bsz=167.6, num_updates=79200, lr=0.000112367, gnorm=0.956, train_wall=15, wall=0
2024-08-01 00:22:40 | INFO | train_inner | epoch 005:  11204 / 17024 loss=6.936, nll_loss=5.896, ppl=59.55, wps=25547.4, ups=6.47, wpb=3950.8, bsz=145.4, num_updates=79300, lr=0.000112296, gnorm=0.934, train_wall=15, wall=0
2024-08-01 00:22:55 | INFO | train_inner | epoch 005:  11304 / 17024 loss=6.991, nll_loss=5.96, ppl=62.24, wps=25530, ups=6.44, wpb=3964.8, bsz=160.6, num_updates=79400, lr=0.000112225, gnorm=0.946, train_wall=15, wall=0
2024-08-01 00:23:11 | INFO | train_inner | epoch 005:  11404 / 17024 loss=6.972, nll_loss=5.938, ppl=61.33, wps=25621.3, ups=6.45, wpb=3973.9, bsz=152.9, num_updates=79500, lr=0.000112154, gnorm=0.93, train_wall=15, wall=0
2024-08-01 00:23:26 | INFO | train_inner | epoch 005:  11504 / 17024 loss=7.012, nll_loss=5.985, ppl=63.32, wps=25662.4, ups=6.44, wpb=3982.1, bsz=173.4, num_updates=79600, lr=0.000112084, gnorm=0.96, train_wall=15, wall=0
2024-08-01 00:23:42 | INFO | train_inner | epoch 005:  11604 / 17024 loss=6.982, nll_loss=5.95, ppl=61.82, wps=25583.9, ups=6.48, wpb=3948.5, bsz=161.4, num_updates=79700, lr=0.000112014, gnorm=0.95, train_wall=15, wall=0
2024-08-01 00:23:57 | INFO | train_inner | epoch 005:  11704 / 17024 loss=6.999, nll_loss=5.97, ppl=62.67, wps=25685.3, ups=6.47, wpb=3972.2, bsz=175.4, num_updates=79800, lr=0.000111943, gnorm=0.952, train_wall=15, wall=0
2024-08-01 00:24:13 | INFO | train_inner | epoch 005:  11804 / 17024 loss=7.02, nll_loss=5.994, ppl=63.75, wps=25547.5, ups=6.5, wpb=3932.1, bsz=157.7, num_updates=79900, lr=0.000111873, gnorm=0.963, train_wall=15, wall=0
2024-08-01 00:24:28 | INFO | train_inner | epoch 005:  11904 / 17024 loss=7.008, nll_loss=5.98, ppl=63.1, wps=25676.8, ups=6.46, wpb=3977, bsz=173.7, num_updates=80000, lr=0.000111803, gnorm=0.997, train_wall=15, wall=0
2024-08-01 00:24:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:24:30 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.23 | nll_loss 6.174 | ppl 72.22 | wps 92991.2 | wpb 3529.1 | bsz 62.9 | num_updates 80000 | best_loss 7.227
2024-08-01 00:24:30 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:24:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_80000.pt (epoch 5 @ 80000 updates, score 7.23) (writing took 3.1653498988598585 seconds)
2024-08-01 00:24:48 | INFO | train_inner | epoch 005:  12004 / 17024 loss=6.988, nll_loss=5.957, ppl=62.13, wps=19711.9, ups=4.96, wpb=3974.8, bsz=169.8, num_updates=80100, lr=0.000111734, gnorm=0.942, train_wall=15, wall=0
2024-08-01 00:25:04 | INFO | train_inner | epoch 005:  12104 / 17024 loss=7.003, nll_loss=5.974, ppl=62.84, wps=25604.3, ups=6.46, wpb=3962.3, bsz=162.2, num_updates=80200, lr=0.000111664, gnorm=0.951, train_wall=15, wall=0
2024-08-01 00:25:19 | INFO | train_inner | epoch 005:  12204 / 17024 loss=6.979, nll_loss=5.947, ppl=61.68, wps=25615.3, ups=6.49, wpb=3946.5, bsz=156.5, num_updates=80300, lr=0.000111594, gnorm=0.944, train_wall=15, wall=0
2024-08-01 00:25:35 | INFO | train_inner | epoch 005:  12304 / 17024 loss=6.981, nll_loss=5.95, ppl=61.81, wps=25748.2, ups=6.5, wpb=3962.8, bsz=175.4, num_updates=80400, lr=0.000111525, gnorm=0.941, train_wall=15, wall=0
2024-08-01 00:25:50 | INFO | train_inner | epoch 005:  12404 / 17024 loss=6.987, nll_loss=5.956, ppl=62.06, wps=25599.5, ups=6.47, wpb=3954.5, bsz=165.7, num_updates=80500, lr=0.000111456, gnorm=0.947, train_wall=15, wall=0
2024-08-01 00:26:06 | INFO | train_inner | epoch 005:  12504 / 17024 loss=6.996, nll_loss=5.966, ppl=62.5, wps=25662.9, ups=6.47, wpb=3968.8, bsz=153.4, num_updates=80600, lr=0.000111386, gnorm=0.963, train_wall=15, wall=0
2024-08-01 00:26:21 | INFO | train_inner | epoch 005:  12604 / 17024 loss=7.031, nll_loss=6.007, ppl=64.33, wps=25626, ups=6.44, wpb=3976.7, bsz=180.4, num_updates=80700, lr=0.000111317, gnorm=0.946, train_wall=15, wall=0
2024-08-01 00:26:37 | INFO | train_inner | epoch 005:  12704 / 17024 loss=6.973, nll_loss=5.94, ppl=61.38, wps=25704.8, ups=6.47, wpb=3975.3, bsz=160.9, num_updates=80800, lr=0.000111249, gnorm=0.929, train_wall=15, wall=0
2024-08-01 00:26:52 | INFO | train_inner | epoch 005:  12804 / 17024 loss=7.009, nll_loss=5.982, ppl=63.18, wps=25630.2, ups=6.45, wpb=3975.2, bsz=180.1, num_updates=80900, lr=0.00011118, gnorm=0.943, train_wall=15, wall=0
2024-08-01 00:27:08 | INFO | train_inner | epoch 005:  12904 / 17024 loss=7.028, nll_loss=6.002, ppl=64.11, wps=25679.7, ups=6.46, wpb=3973.3, bsz=179.9, num_updates=81000, lr=0.000111111, gnorm=0.999, train_wall=15, wall=0
2024-08-01 00:27:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:27:09 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.241 | nll_loss 6.186 | ppl 72.81 | wps 95896.5 | wpb 3529.1 | bsz 62.9 | num_updates 81000 | best_loss 7.227
2024-08-01 00:27:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:27:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_81000.pt (epoch 5 @ 81000 updates, score 7.241) (writing took 3.022782539948821 seconds)
2024-08-01 00:27:27 | INFO | train_inner | epoch 005:  13004 / 17024 loss=6.927, nll_loss=5.886, ppl=59.14, wps=19937.6, ups=5.05, wpb=3948.5, bsz=138.2, num_updates=81100, lr=0.000111043, gnorm=0.934, train_wall=15, wall=0
2024-08-01 00:27:43 | INFO | train_inner | epoch 005:  13104 / 17024 loss=7.005, nll_loss=5.977, ppl=62.99, wps=25615.5, ups=6.51, wpb=3933.9, bsz=162.8, num_updates=81200, lr=0.000110974, gnorm=0.955, train_wall=15, wall=0
2024-08-01 00:27:58 | INFO | train_inner | epoch 005:  13204 / 17024 loss=7.016, nll_loss=5.99, ppl=63.55, wps=25661.8, ups=6.46, wpb=3973.8, bsz=169.8, num_updates=81300, lr=0.000110906, gnorm=0.954, train_wall=15, wall=0
2024-08-01 00:28:14 | INFO | train_inner | epoch 005:  13304 / 17024 loss=6.947, nll_loss=5.91, ppl=60.13, wps=25626.8, ups=6.5, wpb=3944.6, bsz=149.4, num_updates=81400, lr=0.000110838, gnorm=0.937, train_wall=15, wall=0
2024-08-01 00:28:29 | INFO | train_inner | epoch 005:  13404 / 17024 loss=6.965, nll_loss=5.931, ppl=61, wps=25708.2, ups=6.47, wpb=3970.6, bsz=161.8, num_updates=81500, lr=0.00011077, gnorm=0.933, train_wall=15, wall=0
2024-08-01 00:28:44 | INFO | train_inner | epoch 005:  13504 / 17024 loss=7.026, nll_loss=6.001, ppl=64.06, wps=25641.5, ups=6.48, wpb=3956.2, bsz=176.3, num_updates=81600, lr=0.000110702, gnorm=0.978, train_wall=15, wall=0
2024-08-01 00:29:00 | INFO | train_inner | epoch 005:  13604 / 17024 loss=7.007, nll_loss=5.98, ppl=63.11, wps=25812.6, ups=6.5, wpb=3970.7, bsz=177.5, num_updates=81700, lr=0.000110634, gnorm=0.933, train_wall=15, wall=0
2024-08-01 00:29:15 | INFO | train_inner | epoch 005:  13704 / 17024 loss=6.994, nll_loss=5.963, ppl=62.4, wps=25711.1, ups=6.5, wpb=3954.7, bsz=164.6, num_updates=81800, lr=0.000110566, gnorm=0.971, train_wall=15, wall=0
2024-08-01 00:29:31 | INFO | train_inner | epoch 005:  13804 / 17024 loss=6.985, nll_loss=5.953, ppl=61.94, wps=25684.6, ups=6.45, wpb=3980.6, bsz=165.5, num_updates=81900, lr=0.000110499, gnorm=0.933, train_wall=15, wall=0
2024-08-01 00:29:46 | INFO | train_inner | epoch 005:  13904 / 17024 loss=7.013, nll_loss=5.986, ppl=63.39, wps=25692.9, ups=6.49, wpb=3961.7, bsz=166.5, num_updates=82000, lr=0.000110432, gnorm=0.982, train_wall=15, wall=0
2024-08-01 00:29:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:29:48 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.219 | nll_loss 6.163 | ppl 71.68 | wps 96154.9 | wpb 3529.1 | bsz 62.9 | num_updates 82000 | best_loss 7.219
2024-08-01 00:29:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:29:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_82000.pt (epoch 5 @ 82000 updates, score 7.219) (writing took 4.687151648104191 seconds)
2024-08-01 00:30:08 | INFO | train_inner | epoch 005:  14004 / 17024 loss=6.959, nll_loss=5.924, ppl=60.72, wps=18351.3, ups=4.63, wpb=3963, bsz=166.5, num_updates=82100, lr=0.000110364, gnorm=0.941, train_wall=15, wall=0
2024-08-01 00:30:23 | INFO | train_inner | epoch 005:  14104 / 17024 loss=6.929, nll_loss=5.889, ppl=59.26, wps=25608, ups=6.44, wpb=3976.8, bsz=151.9, num_updates=82200, lr=0.000110297, gnorm=0.914, train_wall=15, wall=0
2024-08-01 00:30:39 | INFO | train_inner | epoch 005:  14204 / 17024 loss=6.925, nll_loss=5.884, ppl=59.06, wps=25793.4, ups=6.5, wpb=3967.5, bsz=162.3, num_updates=82300, lr=0.00011023, gnorm=0.947, train_wall=15, wall=0
2024-08-01 00:30:54 | INFO | train_inner | epoch 005:  14304 / 17024 loss=7.025, nll_loss=6, ppl=63.98, wps=25597.7, ups=6.46, wpb=3961.1, bsz=180.7, num_updates=82400, lr=0.000110163, gnorm=0.997, train_wall=15, wall=0
2024-08-01 00:31:10 | INFO | train_inner | epoch 005:  14404 / 17024 loss=6.982, nll_loss=5.951, ppl=61.85, wps=25703.7, ups=6.5, wpb=3956.1, bsz=158.7, num_updates=82500, lr=0.000110096, gnorm=0.937, train_wall=15, wall=0
2024-08-01 00:31:25 | INFO | train_inner | epoch 005:  14504 / 17024 loss=6.96, nll_loss=5.924, ppl=60.73, wps=25695.3, ups=6.53, wpb=3933.7, bsz=135, num_updates=82600, lr=0.00011003, gnorm=0.944, train_wall=15, wall=0
2024-08-01 00:31:40 | INFO | train_inner | epoch 005:  14604 / 17024 loss=7.005, nll_loss=5.976, ppl=62.95, wps=25745.7, ups=6.46, wpb=3982.9, bsz=182.2, num_updates=82700, lr=0.000109963, gnorm=0.966, train_wall=15, wall=0
2024-08-01 00:31:56 | INFO | train_inner | epoch 005:  14704 / 17024 loss=7.016, nll_loss=5.99, ppl=63.56, wps=25879.7, ups=6.54, wpb=3956.4, bsz=178.4, num_updates=82800, lr=0.000109897, gnorm=0.946, train_wall=15, wall=0
2024-08-01 00:32:11 | INFO | train_inner | epoch 005:  14804 / 17024 loss=6.965, nll_loss=5.93, ppl=60.98, wps=25739.7, ups=6.49, wpb=3966, bsz=151, num_updates=82900, lr=0.00010983, gnorm=0.938, train_wall=15, wall=0
2024-08-01 00:32:26 | INFO | train_inner | epoch 005:  14904 / 17024 loss=6.976, nll_loss=5.944, ppl=61.54, wps=25752.9, ups=6.51, wpb=3956.1, bsz=168.1, num_updates=83000, lr=0.000109764, gnorm=0.958, train_wall=15, wall=0
2024-08-01 00:32:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:32:28 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.229 | nll_loss 6.174 | ppl 72.2 | wps 95427.5 | wpb 3529.1 | bsz 62.9 | num_updates 83000 | best_loss 7.219
2024-08-01 00:32:28 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:32:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_83000.pt (epoch 5 @ 83000 updates, score 7.229) (writing took 2.903733012266457 seconds)
2024-08-01 00:32:46 | INFO | train_inner | epoch 005:  15004 / 17024 loss=6.972, nll_loss=5.939, ppl=61.35, wps=19906.5, ups=5.05, wpb=3943.1, bsz=162.6, num_updates=83100, lr=0.000109698, gnorm=0.953, train_wall=15, wall=0
2024-08-01 00:33:02 | INFO | train_inner | epoch 005:  15104 / 17024 loss=6.976, nll_loss=5.943, ppl=61.52, wps=25682.8, ups=6.47, wpb=3968.9, bsz=158, num_updates=83200, lr=0.000109632, gnorm=0.943, train_wall=15, wall=0
2024-08-01 00:33:17 | INFO | train_inner | epoch 005:  15204 / 17024 loss=7.005, nll_loss=5.977, ppl=63, wps=25833.4, ups=6.49, wpb=3982.5, bsz=181, num_updates=83300, lr=0.000109566, gnorm=0.958, train_wall=15, wall=0
2024-08-01 00:33:33 | INFO | train_inner | epoch 005:  15304 / 17024 loss=6.954, nll_loss=5.919, ppl=60.49, wps=25613.7, ups=6.46, wpb=3967.1, bsz=156.9, num_updates=83400, lr=0.000109501, gnorm=0.946, train_wall=15, wall=0
2024-08-01 00:33:48 | INFO | train_inner | epoch 005:  15404 / 17024 loss=7.003, nll_loss=5.974, ppl=62.86, wps=25634.2, ups=6.46, wpb=3969.6, bsz=167.7, num_updates=83500, lr=0.000109435, gnorm=0.969, train_wall=15, wall=0
2024-08-01 00:34:04 | INFO | train_inner | epoch 005:  15504 / 17024 loss=6.959, nll_loss=5.924, ppl=60.71, wps=25553.4, ups=6.41, wpb=3985.2, bsz=163, num_updates=83600, lr=0.00010937, gnorm=0.927, train_wall=15, wall=0
2024-08-01 00:34:19 | INFO | train_inner | epoch 005:  15604 / 17024 loss=7.036, nll_loss=6.012, ppl=64.55, wps=25692.4, ups=6.47, wpb=3969.6, bsz=178.8, num_updates=83700, lr=0.000109304, gnorm=0.978, train_wall=15, wall=0
2024-08-01 00:34:35 | INFO | train_inner | epoch 005:  15704 / 17024 loss=6.997, nll_loss=5.968, ppl=62.62, wps=25599.7, ups=6.45, wpb=3969, bsz=171.8, num_updates=83800, lr=0.000109239, gnorm=0.957, train_wall=15, wall=0
2024-08-01 00:34:50 | INFO | train_inner | epoch 005:  15804 / 17024 loss=6.944, nll_loss=5.907, ppl=60.02, wps=25797, ups=6.52, wpb=3953.8, bsz=156.8, num_updates=83900, lr=0.000109174, gnorm=0.94, train_wall=15, wall=0
2024-08-01 00:35:05 | INFO | train_inner | epoch 005:  15904 / 17024 loss=6.995, nll_loss=5.965, ppl=62.46, wps=25588.6, ups=6.44, wpb=3975.8, bsz=177.8, num_updates=84000, lr=0.000109109, gnorm=0.985, train_wall=15, wall=0
2024-08-01 00:35:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:35:07 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.229 | nll_loss 6.172 | ppl 72.09 | wps 95944.5 | wpb 3529.1 | bsz 62.9 | num_updates 84000 | best_loss 7.219
2024-08-01 00:35:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:35:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_84000.pt (epoch 5 @ 84000 updates, score 7.229) (writing took 2.985402787104249 seconds)
2024-08-01 00:35:25 | INFO | train_inner | epoch 005:  16004 / 17024 loss=6.999, nll_loss=5.97, ppl=62.68, wps=19972.8, ups=5.02, wpb=3975.4, bsz=173.5, num_updates=84100, lr=0.000109044, gnorm=0.951, train_wall=15, wall=0
2024-08-01 00:35:41 | INFO | train_inner | epoch 005:  16104 / 17024 loss=6.954, nll_loss=5.918, ppl=60.45, wps=26037, ups=6.55, wpb=3976.6, bsz=163, num_updates=84200, lr=0.000108979, gnorm=0.955, train_wall=15, wall=0
2024-08-01 00:35:56 | INFO | train_inner | epoch 005:  16204 / 17024 loss=6.99, nll_loss=5.96, ppl=62.23, wps=25710.9, ups=6.48, wpb=3968, bsz=170, num_updates=84300, lr=0.000108915, gnorm=0.985, train_wall=15, wall=0
2024-08-01 00:36:11 | INFO | train_inner | epoch 005:  16304 / 17024 loss=6.979, nll_loss=5.947, ppl=61.69, wps=25609.3, ups=6.48, wpb=3953.2, bsz=155.2, num_updates=84400, lr=0.00010885, gnorm=0.944, train_wall=15, wall=0
2024-08-01 00:36:27 | INFO | train_inner | epoch 005:  16404 / 17024 loss=6.945, nll_loss=5.907, ppl=60.02, wps=25355.2, ups=6.42, wpb=3951, bsz=160.2, num_updates=84500, lr=0.000108786, gnorm=0.96, train_wall=15, wall=0
2024-08-01 00:36:42 | INFO | train_inner | epoch 005:  16504 / 17024 loss=6.987, nll_loss=5.956, ppl=62.09, wps=25583.9, ups=6.48, wpb=3947.8, bsz=153.3, num_updates=84600, lr=0.000108721, gnorm=0.967, train_wall=15, wall=0
2024-08-01 00:36:58 | INFO | train_inner | epoch 005:  16604 / 17024 loss=6.98, nll_loss=5.948, ppl=61.73, wps=25690.6, ups=6.47, wpb=3971.8, bsz=173.1, num_updates=84700, lr=0.000108657, gnorm=0.95, train_wall=15, wall=0
2024-08-01 00:37:13 | INFO | train_inner | epoch 005:  16704 / 17024 loss=6.981, nll_loss=5.949, ppl=61.79, wps=25785.9, ups=6.55, wpb=3935.5, bsz=162.1, num_updates=84800, lr=0.000108593, gnorm=0.962, train_wall=15, wall=0
2024-08-01 00:37:29 | INFO | train_inner | epoch 005:  16804 / 17024 loss=6.961, nll_loss=5.927, ppl=60.83, wps=25274.6, ups=6.37, wpb=3969.7, bsz=173.1, num_updates=84900, lr=0.000108529, gnorm=0.969, train_wall=16, wall=0
2024-08-01 00:37:44 | INFO | train_inner | epoch 005:  16904 / 17024 loss=7.016, nll_loss=5.99, ppl=63.54, wps=25502.8, ups=6.42, wpb=3969.9, bsz=168.3, num_updates=85000, lr=0.000108465, gnorm=0.993, train_wall=15, wall=0
2024-08-01 00:37:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:37:46 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.213 | nll_loss 6.16 | ppl 71.49 | wps 95694.5 | wpb 3529.1 | bsz 62.9 | num_updates 85000 | best_loss 7.213
2024-08-01 00:37:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:37:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_85000.pt (epoch 5 @ 85000 updates, score 7.213) (writing took 5.780951709486544 seconds)
2024-08-01 00:38:07 | INFO | train_inner | epoch 005:  17004 / 17024 loss=6.982, nll_loss=5.95, ppl=61.83, wps=17409.4, ups=4.38, wpb=3974.3, bsz=157.4, num_updates=85100, lr=0.000108401, gnorm=0.928, train_wall=15, wall=0
2024-08-01 00:38:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:38:12 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.23 | nll_loss 6.175 | ppl 72.25 | wps 96169.5 | wpb 3529.1 | bsz 62.9 | num_updates 85120 | best_loss 7.213
2024-08-01 00:38:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:38:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 5 @ 85120 updates, score 7.23) (writing took 2.662158329039812 seconds)
2024-08-01 00:38:14 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2024-08-01 00:38:14 | INFO | train | epoch 005 | loss 6.99 | nll_loss 5.96 | ppl 62.24 | wps 24718 | ups 6.24 | wpb 3960.7 | bsz 163.4 | num_updates 85120 | lr 0.000108389 | gnorm 0.946 | train_wall 2597 | wall 0
2024-08-01 00:38:15 | INFO | fairseq.trainer | begin training epoch 6
2024-08-01 00:38:27 | INFO | train_inner | epoch 006:     80 / 17024 loss=6.98, nll_loss=5.947, ppl=61.7, wps=19900.5, ups=5.05, wpb=3941, bsz=159.6, num_updates=85200, lr=0.000108338, gnorm=0.995, train_wall=15, wall=0
2024-08-01 00:38:43 | INFO | train_inner | epoch 006:    180 / 17024 loss=6.981, nll_loss=5.949, ppl=61.79, wps=25616, ups=6.46, wpb=3965.7, bsz=171.9, num_updates=85300, lr=0.000108274, gnorm=0.984, train_wall=15, wall=0
2024-08-01 00:38:58 | INFO | train_inner | epoch 006:    280 / 17024 loss=6.925, nll_loss=5.884, ppl=59.04, wps=25636.4, ups=6.5, wpb=3942.9, bsz=155.8, num_updates=85400, lr=0.000108211, gnorm=0.963, train_wall=15, wall=0
2024-08-01 00:39:13 | INFO | train_inner | epoch 006:    380 / 17024 loss=6.953, nll_loss=5.917, ppl=60.41, wps=25683.1, ups=6.52, wpb=3940.1, bsz=163.5, num_updates=85500, lr=0.000108148, gnorm=0.956, train_wall=15, wall=0
2024-08-01 00:39:29 | INFO | train_inner | epoch 006:    480 / 17024 loss=6.958, nll_loss=5.924, ppl=60.7, wps=25789.3, ups=6.52, wpb=3957.9, bsz=170.7, num_updates=85600, lr=0.000108084, gnorm=0.949, train_wall=15, wall=0
2024-08-01 00:39:44 | INFO | train_inner | epoch 006:    580 / 17024 loss=6.917, nll_loss=5.875, ppl=58.7, wps=25693.8, ups=6.49, wpb=3961.3, bsz=144.9, num_updates=85700, lr=0.000108021, gnorm=0.944, train_wall=15, wall=0
2024-08-01 00:40:00 | INFO | train_inner | epoch 006:    680 / 17024 loss=6.932, nll_loss=5.893, ppl=59.42, wps=25660.7, ups=6.47, wpb=3967, bsz=166.3, num_updates=85800, lr=0.000107958, gnorm=0.929, train_wall=15, wall=0
2024-08-01 00:40:15 | INFO | train_inner | epoch 006:    780 / 17024 loss=6.953, nll_loss=5.916, ppl=60.4, wps=25700.9, ups=6.52, wpb=3941.3, bsz=152.4, num_updates=85900, lr=0.000107896, gnorm=0.971, train_wall=15, wall=0
2024-08-01 00:40:30 | INFO | train_inner | epoch 006:    880 / 17024 loss=6.955, nll_loss=5.918, ppl=60.48, wps=25724.5, ups=6.48, wpb=3971.9, bsz=161.2, num_updates=86000, lr=0.000107833, gnorm=0.944, train_wall=15, wall=0
2024-08-01 00:40:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:40:32 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.218 | nll_loss 6.161 | ppl 71.58 | wps 96693.7 | wpb 3529.1 | bsz 62.9 | num_updates 86000 | best_loss 7.213
2024-08-01 00:40:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:40:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_86000.pt (epoch 6 @ 86000 updates, score 7.218) (writing took 3.2204322619363666 seconds)
2024-08-01 00:40:50 | INFO | train_inner | epoch 006:    980 / 17024 loss=6.937, nll_loss=5.898, ppl=59.63, wps=19677.8, ups=4.96, wpb=3963.6, bsz=155.5, num_updates=86100, lr=0.00010777, gnorm=0.952, train_wall=15, wall=0
2024-08-01 00:41:06 | INFO | train_inner | epoch 006:   1080 / 17024 loss=6.944, nll_loss=5.906, ppl=59.95, wps=25812, ups=6.53, wpb=3951.1, bsz=154.6, num_updates=86200, lr=0.000107708, gnorm=0.974, train_wall=15, wall=0
2024-08-01 00:41:21 | INFO | train_inner | epoch 006:   1180 / 17024 loss=6.93, nll_loss=5.89, ppl=59.31, wps=25744, ups=6.49, wpb=3968.7, bsz=148, num_updates=86300, lr=0.000107645, gnorm=0.934, train_wall=15, wall=0
2024-08-01 00:41:37 | INFO | train_inner | epoch 006:   1280 / 17024 loss=6.949, nll_loss=5.912, ppl=60.22, wps=25769.8, ups=6.5, wpb=3962.8, bsz=154, num_updates=86400, lr=0.000107583, gnorm=0.959, train_wall=15, wall=0
2024-08-01 00:41:52 | INFO | train_inner | epoch 006:   1380 / 17024 loss=6.994, nll_loss=5.964, ppl=62.42, wps=25719.1, ups=6.5, wpb=3957.3, bsz=168.6, num_updates=86500, lr=0.000107521, gnorm=0.976, train_wall=15, wall=0
2024-08-01 00:42:07 | INFO | train_inner | epoch 006:   1480 / 17024 loss=6.953, nll_loss=5.918, ppl=60.44, wps=25877.7, ups=6.53, wpb=3965.6, bsz=162.6, num_updates=86600, lr=0.000107459, gnorm=0.954, train_wall=15, wall=0
2024-08-01 00:42:23 | INFO | train_inner | epoch 006:   1580 / 17024 loss=6.936, nll_loss=5.895, ppl=59.53, wps=25748.5, ups=6.53, wpb=3945.4, bsz=152.8, num_updates=86700, lr=0.000107397, gnorm=0.978, train_wall=15, wall=0
2024-08-01 00:42:38 | INFO | train_inner | epoch 006:   1680 / 17024 loss=6.976, nll_loss=5.943, ppl=61.53, wps=25615.9, ups=6.49, wpb=3947.1, bsz=159.1, num_updates=86800, lr=0.000107335, gnorm=0.972, train_wall=15, wall=0
2024-08-01 00:42:53 | INFO | train_inner | epoch 006:   1780 / 17024 loss=6.991, nll_loss=5.961, ppl=62.29, wps=25928.8, ups=6.52, wpb=3975.8, bsz=170.5, num_updates=86900, lr=0.000107273, gnorm=0.97, train_wall=15, wall=0
2024-08-01 00:43:09 | INFO | train_inner | epoch 006:   1880 / 17024 loss=6.935, nll_loss=5.896, ppl=59.54, wps=25692.8, ups=6.49, wpb=3956.4, bsz=155.2, num_updates=87000, lr=0.000107211, gnorm=0.964, train_wall=15, wall=0
2024-08-01 00:43:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:43:10 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.21 | nll_loss 6.148 | ppl 70.89 | wps 94765.4 | wpb 3529.1 | bsz 62.9 | num_updates 87000 | best_loss 7.21
2024-08-01 00:43:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:43:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_87000.pt (epoch 6 @ 87000 updates, score 7.21) (writing took 5.129232789389789 seconds)
2024-08-01 00:43:31 | INFO | train_inner | epoch 006:   1980 / 17024 loss=7.007, nll_loss=5.979, ppl=63.06, wps=17902.7, ups=4.52, wpb=3965.1, bsz=179, num_updates=87100, lr=0.00010715, gnorm=0.991, train_wall=15, wall=0
2024-08-01 00:43:46 | INFO | train_inner | epoch 006:   2080 / 17024 loss=6.93, nll_loss=5.889, ppl=59.28, wps=25728.2, ups=6.58, wpb=3909.7, bsz=134.9, num_updates=87200, lr=0.000107088, gnorm=0.972, train_wall=15, wall=0
2024-08-01 00:44:02 | INFO | train_inner | epoch 006:   2180 / 17024 loss=6.954, nll_loss=5.918, ppl=60.46, wps=25209.6, ups=6.35, wpb=3969, bsz=173.1, num_updates=87300, lr=0.000107027, gnorm=0.973, train_wall=16, wall=0
2024-08-01 00:44:17 | INFO | train_inner | epoch 006:   2280 / 17024 loss=6.981, nll_loss=5.949, ppl=61.77, wps=25623.6, ups=6.43, wpb=3987.5, bsz=180.6, num_updates=87400, lr=0.000106966, gnorm=0.984, train_wall=15, wall=0
2024-08-01 00:44:33 | INFO | train_inner | epoch 006:   2380 / 17024 loss=6.967, nll_loss=5.933, ppl=61.09, wps=25586.7, ups=6.49, wpb=3943.1, bsz=155.3, num_updates=87500, lr=0.000106904, gnorm=0.964, train_wall=15, wall=0
2024-08-01 00:44:48 | INFO | train_inner | epoch 006:   2480 / 17024 loss=6.939, nll_loss=5.9, ppl=59.71, wps=25741.8, ups=6.48, wpb=3969.9, bsz=152.8, num_updates=87600, lr=0.000106843, gnorm=0.945, train_wall=15, wall=0
2024-08-01 00:45:04 | INFO | train_inner | epoch 006:   2580 / 17024 loss=7.024, nll_loss=5.999, ppl=63.95, wps=25741.3, ups=6.46, wpb=3984.6, bsz=193.8, num_updates=87700, lr=0.000106783, gnorm=1, train_wall=15, wall=0
2024-08-01 00:45:19 | INFO | train_inner | epoch 006:   2680 / 17024 loss=6.929, nll_loss=5.889, ppl=59.25, wps=25521.4, ups=6.48, wpb=3936.8, bsz=148.8, num_updates=87800, lr=0.000106722, gnorm=0.957, train_wall=15, wall=0
2024-08-01 00:45:35 | INFO | train_inner | epoch 006:   2780 / 17024 loss=6.964, nll_loss=5.93, ppl=60.95, wps=25720.1, ups=6.49, wpb=3963.3, bsz=160.4, num_updates=87900, lr=0.000106661, gnorm=0.944, train_wall=15, wall=0
2024-08-01 00:45:50 | INFO | train_inner | epoch 006:   2880 / 17024 loss=6.977, nll_loss=5.944, ppl=61.55, wps=25594.9, ups=6.48, wpb=3949.9, bsz=170, num_updates=88000, lr=0.0001066, gnorm=1.001, train_wall=15, wall=0
2024-08-01 00:45:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:45:51 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.231 | nll_loss 6.175 | ppl 72.27 | wps 95467.9 | wpb 3529.1 | bsz 62.9 | num_updates 88000 | best_loss 7.21
2024-08-01 00:45:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:45:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_88000.pt (epoch 6 @ 88000 updates, score 7.231) (writing took 2.9747597370296717 seconds)
2024-08-01 00:46:10 | INFO | train_inner | epoch 006:   2980 / 17024 loss=6.946, nll_loss=5.909, ppl=60.08, wps=19985.7, ups=5.02, wpb=3983.2, bsz=157.4, num_updates=88100, lr=0.00010654, gnorm=0.949, train_wall=15, wall=0
2024-08-01 00:46:25 | INFO | train_inner | epoch 006:   3080 / 17024 loss=6.961, nll_loss=5.925, ppl=60.76, wps=25527, ups=6.48, wpb=3937.2, bsz=160.2, num_updates=88200, lr=0.000106479, gnorm=1.004, train_wall=15, wall=0
2024-08-01 00:46:41 | INFO | train_inner | epoch 006:   3180 / 17024 loss=6.959, nll_loss=5.924, ppl=60.7, wps=25560.1, ups=6.43, wpb=3977.7, bsz=171.7, num_updates=88300, lr=0.000106419, gnorm=0.964, train_wall=15, wall=0
2024-08-01 00:46:56 | INFO | train_inner | epoch 006:   3280 / 17024 loss=6.977, nll_loss=5.944, ppl=61.56, wps=25687.2, ups=6.48, wpb=3963, bsz=173.3, num_updates=88400, lr=0.000106359, gnorm=1.019, train_wall=15, wall=0
2024-08-01 00:47:12 | INFO | train_inner | epoch 006:   3380 / 17024 loss=6.945, nll_loss=5.908, ppl=60.04, wps=25738.2, ups=6.52, wpb=3946.9, bsz=165.6, num_updates=88500, lr=0.000106299, gnorm=0.952, train_wall=15, wall=0
2024-08-01 00:47:27 | INFO | train_inner | epoch 006:   3480 / 17024 loss=6.998, nll_loss=5.969, ppl=62.62, wps=25765.7, ups=6.51, wpb=3959.2, bsz=167.9, num_updates=88600, lr=0.000106239, gnorm=1.017, train_wall=15, wall=0
2024-08-01 00:47:42 | INFO | train_inner | epoch 006:   3580 / 17024 loss=6.96, nll_loss=5.925, ppl=60.75, wps=25797.5, ups=6.5, wpb=3968.7, bsz=162.1, num_updates=88700, lr=0.000106179, gnorm=0.947, train_wall=15, wall=0
2024-08-01 00:47:58 | INFO | train_inner | epoch 006:   3680 / 17024 loss=6.959, nll_loss=5.923, ppl=60.66, wps=25681.7, ups=6.5, wpb=3953.3, bsz=156.7, num_updates=88800, lr=0.000106119, gnorm=0.978, train_wall=15, wall=0
2024-08-01 00:48:13 | INFO | train_inner | epoch 006:   3780 / 17024 loss=7.03, nll_loss=6.005, ppl=64.22, wps=25849.5, ups=6.55, wpb=3947.5, bsz=182.7, num_updates=88900, lr=0.000106059, gnorm=1.034, train_wall=15, wall=0
2024-08-01 00:48:28 | INFO | train_inner | epoch 006:   3880 / 17024 loss=6.936, nll_loss=5.897, ppl=59.59, wps=25663.7, ups=6.52, wpb=3938, bsz=157.3, num_updates=89000, lr=0.000106, gnorm=0.948, train_wall=15, wall=0
2024-08-01 00:48:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:48:30 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.211 | nll_loss 6.157 | ppl 71.35 | wps 96225.6 | wpb 3529.1 | bsz 62.9 | num_updates 89000 | best_loss 7.21
2024-08-01 00:48:30 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:48:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_89000.pt (epoch 6 @ 89000 updates, score 7.211) (writing took 2.889010907150805 seconds)
2024-08-01 00:48:48 | INFO | train_inner | epoch 006:   3980 / 17024 loss=6.949, nll_loss=5.912, ppl=60.19, wps=20124.1, ups=5.09, wpb=3951.3, bsz=151, num_updates=89100, lr=0.00010594, gnorm=0.957, train_wall=15, wall=0
2024-08-01 00:49:03 | INFO | train_inner | epoch 006:   4080 / 17024 loss=6.946, nll_loss=5.908, ppl=60.04, wps=25839.4, ups=6.51, wpb=3969.8, bsz=165.8, num_updates=89200, lr=0.000105881, gnorm=0.943, train_wall=15, wall=0
2024-08-01 00:49:19 | INFO | train_inner | epoch 006:   4180 / 17024 loss=6.945, nll_loss=5.907, ppl=60, wps=25692.5, ups=6.49, wpb=3955.8, bsz=154.5, num_updates=89300, lr=0.000105822, gnorm=0.956, train_wall=15, wall=0
2024-08-01 00:49:34 | INFO | train_inner | epoch 006:   4280 / 17024 loss=6.914, nll_loss=5.871, ppl=58.51, wps=25909.2, ups=6.57, wpb=3941.2, bsz=136.8, num_updates=89400, lr=0.000105762, gnorm=0.941, train_wall=15, wall=0
2024-08-01 00:49:50 | INFO | train_inner | epoch 006:   4380 / 17024 loss=6.937, nll_loss=5.898, ppl=59.65, wps=25657.2, ups=6.44, wpb=3982.7, bsz=168.3, num_updates=89500, lr=0.000105703, gnorm=0.943, train_wall=15, wall=0
2024-08-01 00:50:05 | INFO | train_inner | epoch 006:   4480 / 17024 loss=6.996, nll_loss=5.966, ppl=62.53, wps=25735, ups=6.5, wpb=3958.5, bsz=168.7, num_updates=89600, lr=0.000105644, gnorm=1, train_wall=15, wall=0
2024-08-01 00:50:20 | INFO | train_inner | epoch 006:   4580 / 17024 loss=6.971, nll_loss=5.938, ppl=61.29, wps=25612.8, ups=6.46, wpb=3964.4, bsz=171.1, num_updates=89700, lr=0.000105585, gnorm=0.971, train_wall=15, wall=0
2024-08-01 00:50:36 | INFO | train_inner | epoch 006:   4680 / 17024 loss=6.976, nll_loss=5.943, ppl=61.54, wps=25633.8, ups=6.48, wpb=3958.8, bsz=170.3, num_updates=89800, lr=0.000105527, gnorm=0.97, train_wall=15, wall=0
2024-08-01 00:50:51 | INFO | train_inner | epoch 006:   4780 / 17024 loss=6.928, nll_loss=5.887, ppl=59.18, wps=25675.9, ups=6.45, wpb=3979.2, bsz=157.9, num_updates=89900, lr=0.000105468, gnorm=0.953, train_wall=15, wall=0
2024-08-01 00:51:07 | INFO | train_inner | epoch 006:   4880 / 17024 loss=6.996, nll_loss=5.967, ppl=62.53, wps=25680.2, ups=6.46, wpb=3976.4, bsz=179.2, num_updates=90000, lr=0.000105409, gnorm=1.007, train_wall=15, wall=0
2024-08-01 00:51:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:51:08 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.209 | nll_loss 6.147 | ppl 70.88 | wps 95979.4 | wpb 3529.1 | bsz 62.9 | num_updates 90000 | best_loss 7.209
2024-08-01 00:51:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:51:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_90000.pt (epoch 6 @ 90000 updates, score 7.209) (writing took 5.22240100055933 seconds)
2024-08-01 00:51:29 | INFO | train_inner | epoch 006:   4980 / 17024 loss=6.947, nll_loss=5.91, ppl=60.12, wps=17886.6, ups=4.53, wpb=3950.5, bsz=155.6, num_updates=90100, lr=0.000105351, gnorm=0.969, train_wall=15, wall=0
2024-08-01 00:51:44 | INFO | train_inner | epoch 006:   5080 / 17024 loss=6.932, nll_loss=5.892, ppl=59.38, wps=25678.5, ups=6.51, wpb=3946.7, bsz=159, num_updates=90200, lr=0.000105292, gnorm=0.985, train_wall=15, wall=0
2024-08-01 00:52:00 | INFO | train_inner | epoch 006:   5180 / 17024 loss=7.019, nll_loss=5.993, ppl=63.68, wps=25707.8, ups=6.49, wpb=3960.9, bsz=178.1, num_updates=90300, lr=0.000105234, gnorm=1.005, train_wall=15, wall=0
2024-08-01 00:52:15 | INFO | train_inner | epoch 006:   5280 / 17024 loss=6.934, nll_loss=5.896, ppl=59.54, wps=25721.4, ups=6.47, wpb=3977.4, bsz=166, num_updates=90400, lr=0.000105176, gnorm=0.936, train_wall=15, wall=0
2024-08-01 00:52:31 | INFO | train_inner | epoch 006:   5380 / 17024 loss=6.974, nll_loss=5.94, ppl=61.4, wps=25598.9, ups=6.45, wpb=3965.9, bsz=160.4, num_updates=90500, lr=0.000105118, gnorm=0.99, train_wall=15, wall=0
2024-08-01 00:52:46 | INFO | train_inner | epoch 006:   5480 / 17024 loss=6.889, nll_loss=5.843, ppl=57.38, wps=25678, ups=6.51, wpb=3944.3, bsz=143.3, num_updates=90600, lr=0.00010506, gnorm=0.958, train_wall=15, wall=0
2024-08-01 00:53:01 | INFO | train_inner | epoch 006:   5580 / 17024 loss=6.936, nll_loss=5.898, ppl=59.61, wps=25778.8, ups=6.51, wpb=3961.7, bsz=165, num_updates=90700, lr=0.000105002, gnorm=0.957, train_wall=15, wall=0
2024-08-01 00:53:17 | INFO | train_inner | epoch 006:   5680 / 17024 loss=6.983, nll_loss=5.951, ppl=61.85, wps=25649.8, ups=6.47, wpb=3962.7, bsz=175.3, num_updates=90800, lr=0.000104944, gnorm=1.003, train_wall=15, wall=0
2024-08-01 00:53:32 | INFO | train_inner | epoch 006:   5780 / 17024 loss=6.936, nll_loss=5.897, ppl=59.6, wps=25641.5, ups=6.54, wpb=3919.4, bsz=151.5, num_updates=90900, lr=0.000104886, gnorm=0.972, train_wall=15, wall=0
2024-08-01 00:53:48 | INFO | train_inner | epoch 006:   5880 / 17024 loss=6.957, nll_loss=5.922, ppl=60.63, wps=25671.2, ups=6.5, wpb=3952.3, bsz=165.8, num_updates=91000, lr=0.000104828, gnorm=0.949, train_wall=15, wall=0
2024-08-01 00:53:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:53:49 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.208 | nll_loss 6.152 | ppl 71.11 | wps 96035.8 | wpb 3529.1 | bsz 62.9 | num_updates 91000 | best_loss 7.208
2024-08-01 00:53:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:53:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_91000.pt (epoch 6 @ 91000 updates, score 7.208) (writing took 5.629325964488089 seconds)
2024-08-01 00:54:10 | INFO | train_inner | epoch 006:   5980 / 17024 loss=6.961, nll_loss=5.927, ppl=60.85, wps=17639.3, ups=4.45, wpb=3966.2, bsz=175.2, num_updates=91100, lr=0.000104771, gnorm=0.957, train_wall=15, wall=0
2024-08-01 00:54:26 | INFO | train_inner | epoch 006:   6080 / 17024 loss=6.999, nll_loss=5.97, ppl=62.68, wps=25641.7, ups=6.43, wpb=3985.3, bsz=190, num_updates=91200, lr=0.000104713, gnorm=0.982, train_wall=15, wall=0
2024-08-01 00:54:41 | INFO | train_inner | epoch 006:   6180 / 17024 loss=6.96, nll_loss=5.925, ppl=60.76, wps=25730.1, ups=6.48, wpb=3970.1, bsz=163.8, num_updates=91300, lr=0.000104656, gnorm=0.974, train_wall=15, wall=0
2024-08-01 00:54:57 | INFO | train_inner | epoch 006:   6280 / 17024 loss=6.944, nll_loss=5.906, ppl=59.97, wps=25583.5, ups=6.45, wpb=3969.2, bsz=157.6, num_updates=91400, lr=0.000104599, gnorm=0.946, train_wall=15, wall=0
2024-08-01 00:55:12 | INFO | train_inner | epoch 006:   6380 / 17024 loss=6.99, nll_loss=5.96, ppl=62.24, wps=25449.2, ups=6.38, wpb=3990.5, bsz=182.1, num_updates=91500, lr=0.000104542, gnorm=0.978, train_wall=15, wall=0
2024-08-01 00:55:28 | INFO | train_inner | epoch 006:   6480 / 17024 loss=6.994, nll_loss=5.964, ppl=62.41, wps=25187.8, ups=6.39, wpb=3941.2, bsz=160.7, num_updates=91600, lr=0.000104485, gnorm=1.021, train_wall=15, wall=0
2024-08-01 00:55:43 | INFO | train_inner | epoch 006:   6580 / 17024 loss=6.998, nll_loss=5.968, ppl=62.59, wps=25392.2, ups=6.41, wpb=3959.6, bsz=185.4, num_updates=91700, lr=0.000104428, gnorm=1.035, train_wall=15, wall=0
2024-08-01 00:55:59 | INFO | train_inner | epoch 006:   6680 / 17024 loss=6.909, nll_loss=5.866, ppl=58.34, wps=25690.1, ups=6.5, wpb=3949.4, bsz=146.6, num_updates=91800, lr=0.000104371, gnorm=0.937, train_wall=15, wall=0
2024-08-01 00:56:14 | INFO | train_inner | epoch 006:   6780 / 17024 loss=6.954, nll_loss=5.917, ppl=60.44, wps=25548.1, ups=6.52, wpb=3918.9, bsz=150, num_updates=91900, lr=0.000104314, gnorm=0.974, train_wall=15, wall=0
2024-08-01 00:56:30 | INFO | train_inner | epoch 006:   6880 / 17024 loss=6.938, nll_loss=5.899, ppl=59.69, wps=25577.2, ups=6.49, wpb=3943.2, bsz=152.6, num_updates=92000, lr=0.000104257, gnorm=0.979, train_wall=15, wall=0
2024-08-01 00:56:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:56:31 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.211 | nll_loss 6.155 | ppl 71.24 | wps 94496.3 | wpb 3529.1 | bsz 62.9 | num_updates 92000 | best_loss 7.208
2024-08-01 00:56:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:56:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_92000.pt (epoch 6 @ 92000 updates, score 7.211) (writing took 2.9937987606972456 seconds)
2024-08-01 00:56:49 | INFO | train_inner | epoch 006:   6980 / 17024 loss=6.998, nll_loss=5.968, ppl=62.61, wps=19909.9, ups=5.02, wpb=3968.1, bsz=172.1, num_updates=92100, lr=0.000104201, gnorm=0.968, train_wall=15, wall=0
2024-08-01 00:57:05 | INFO | train_inner | epoch 006:   7080 / 17024 loss=6.972, nll_loss=5.939, ppl=61.37, wps=25691, ups=6.45, wpb=3984.8, bsz=177.2, num_updates=92200, lr=0.000104144, gnorm=0.957, train_wall=15, wall=0
2024-08-01 00:57:20 | INFO | train_inner | epoch 006:   7180 / 17024 loss=6.929, nll_loss=5.889, ppl=59.27, wps=25681, ups=6.47, wpb=3966.2, bsz=161.2, num_updates=92300, lr=0.000104088, gnorm=0.946, train_wall=15, wall=0
2024-08-01 00:57:36 | INFO | train_inner | epoch 006:   7280 / 17024 loss=6.961, nll_loss=5.925, ppl=60.76, wps=25591.5, ups=6.47, wpb=3954.5, bsz=155, num_updates=92400, lr=0.000104031, gnorm=0.976, train_wall=15, wall=0
2024-08-01 00:57:51 | INFO | train_inner | epoch 006:   7380 / 17024 loss=7.005, nll_loss=5.976, ppl=62.95, wps=25647.7, ups=6.49, wpb=3948.9, bsz=174.4, num_updates=92500, lr=0.000103975, gnorm=1.031, train_wall=15, wall=0
2024-08-01 00:58:07 | INFO | train_inner | epoch 006:   7480 / 17024 loss=6.942, nll_loss=5.904, ppl=59.87, wps=25763.2, ups=6.51, wpb=3959.6, bsz=159.8, num_updates=92600, lr=0.000103919, gnorm=0.984, train_wall=15, wall=0
2024-08-01 00:58:22 | INFO | train_inner | epoch 006:   7580 / 17024 loss=6.924, nll_loss=5.883, ppl=59.02, wps=25451.9, ups=6.43, wpb=3957.5, bsz=159.2, num_updates=92700, lr=0.000103863, gnorm=0.967, train_wall=15, wall=0
2024-08-01 00:58:38 | INFO | train_inner | epoch 006:   7680 / 17024 loss=6.982, nll_loss=5.95, ppl=61.81, wps=25693.4, ups=6.48, wpb=3967.8, bsz=169.3, num_updates=92800, lr=0.000103807, gnorm=0.975, train_wall=15, wall=0
2024-08-01 00:58:53 | INFO | train_inner | epoch 006:   7780 / 17024 loss=6.923, nll_loss=5.882, ppl=58.98, wps=25653.4, ups=6.51, wpb=3942.6, bsz=147.4, num_updates=92900, lr=0.000103751, gnorm=0.964, train_wall=15, wall=0
2024-08-01 00:59:08 | INFO | train_inner | epoch 006:   7880 / 17024 loss=6.976, nll_loss=5.943, ppl=61.52, wps=25576, ups=6.47, wpb=3955.2, bsz=161.2, num_updates=93000, lr=0.000103695, gnorm=0.979, train_wall=15, wall=0
2024-08-01 00:59:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 00:59:10 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.211 | nll_loss 6.153 | ppl 71.14 | wps 94309.7 | wpb 3529.1 | bsz 62.9 | num_updates 93000 | best_loss 7.208
2024-08-01 00:59:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 00:59:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_93000.pt (epoch 6 @ 93000 updates, score 7.211) (writing took 2.948213062249124 seconds)
2024-08-01 00:59:28 | INFO | train_inner | epoch 006:   7980 / 17024 loss=6.947, nll_loss=5.91, ppl=60.14, wps=19947.1, ups=5.02, wpb=3974.4, bsz=162.7, num_updates=93100, lr=0.000103639, gnorm=0.972, train_wall=15, wall=0
2024-08-01 00:59:44 | INFO | train_inner | epoch 006:   8080 / 17024 loss=6.947, nll_loss=5.91, ppl=60.13, wps=25765.2, ups=6.49, wpb=3967.2, bsz=158.4, num_updates=93200, lr=0.000103584, gnorm=0.976, train_wall=15, wall=0
2024-08-01 00:59:59 | INFO | train_inner | epoch 006:   8180 / 17024 loss=6.969, nll_loss=5.935, ppl=61.19, wps=25432.6, ups=6.42, wpb=3959.6, bsz=175.8, num_updates=93300, lr=0.000103528, gnorm=0.975, train_wall=15, wall=0
2024-08-01 01:00:15 | INFO | train_inner | epoch 006:   8280 / 17024 loss=6.994, nll_loss=5.964, ppl=62.43, wps=25706.7, ups=6.5, wpb=3954.2, bsz=173.2, num_updates=93400, lr=0.000103473, gnorm=0.974, train_wall=15, wall=0
2024-08-01 01:00:30 | INFO | train_inner | epoch 006:   8380 / 17024 loss=7, nll_loss=5.971, ppl=62.74, wps=25569.2, ups=6.51, wpb=3927.2, bsz=175, num_updates=93500, lr=0.000103418, gnorm=1.026, train_wall=15, wall=0
2024-08-01 01:00:46 | INFO | train_inner | epoch 006:   8480 / 17024 loss=6.951, nll_loss=5.915, ppl=60.33, wps=25720, ups=6.46, wpb=3979.4, bsz=167.6, num_updates=93600, lr=0.000103362, gnorm=0.96, train_wall=15, wall=0
2024-08-01 01:01:01 | INFO | train_inner | epoch 006:   8580 / 17024 loss=6.938, nll_loss=5.899, ppl=59.69, wps=25575.4, ups=6.49, wpb=3938.6, bsz=159.5, num_updates=93700, lr=0.000103307, gnorm=0.991, train_wall=15, wall=0
2024-08-01 01:01:17 | INFO | train_inner | epoch 006:   8680 / 17024 loss=6.961, nll_loss=5.925, ppl=60.77, wps=25590.4, ups=6.45, wpb=3969.8, bsz=167.4, num_updates=93800, lr=0.000103252, gnorm=0.966, train_wall=15, wall=0
2024-08-01 01:01:32 | INFO | train_inner | epoch 006:   8780 / 17024 loss=6.98, nll_loss=5.948, ppl=61.71, wps=25127.5, ups=6.38, wpb=3935.9, bsz=170.2, num_updates=93900, lr=0.000103197, gnorm=1.015, train_wall=15, wall=0
2024-08-01 01:01:47 | INFO | train_inner | epoch 006:   8880 / 17024 loss=6.95, nll_loss=5.913, ppl=60.25, wps=25807.3, ups=6.54, wpb=3947.1, bsz=154.6, num_updates=94000, lr=0.000103142, gnorm=0.962, train_wall=15, wall=0
2024-08-01 01:01:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 01:01:49 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.199 | nll_loss 6.142 | ppl 70.63 | wps 93953.8 | wpb 3529.1 | bsz 62.9 | num_updates 94000 | best_loss 7.199
2024-08-01 01:01:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 01:01:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_94000.pt (epoch 6 @ 94000 updates, score 7.199) (writing took 5.985207676887512 seconds)
2024-08-01 01:02:11 | INFO | train_inner | epoch 006:   8980 / 17024 loss=6.951, nll_loss=5.914, ppl=60.29, wps=16976.7, ups=4.29, wpb=3953.9, bsz=151.4, num_updates=94100, lr=0.000103087, gnorm=0.981, train_wall=16, wall=0
2024-08-01 01:02:26 | INFO | train_inner | epoch 006:   9080 / 17024 loss=6.948, nll_loss=5.911, ppl=60.17, wps=25308, ups=6.38, wpb=3968.8, bsz=168.1, num_updates=94200, lr=0.000103033, gnorm=0.974, train_wall=15, wall=0
2024-08-01 01:02:42 | INFO | train_inner | epoch 006:   9180 / 17024 loss=6.966, nll_loss=5.932, ppl=61.06, wps=25140.3, ups=6.32, wpb=3980.6, bsz=177, num_updates=94300, lr=0.000102978, gnorm=0.962, train_wall=16, wall=0
2024-08-01 01:02:58 | INFO | train_inner | epoch 006:   9280 / 17024 loss=6.963, nll_loss=5.929, ppl=60.91, wps=25275.2, ups=6.37, wpb=3965.2, bsz=170.6, num_updates=94400, lr=0.000102923, gnorm=0.975, train_wall=15, wall=0
2024-08-01 01:03:14 | INFO | train_inner | epoch 006:   9380 / 17024 loss=6.988, nll_loss=5.958, ppl=62.18, wps=25259.2, ups=6.33, wpb=3992.1, bsz=182.1, num_updates=94500, lr=0.000102869, gnorm=0.98, train_wall=16, wall=0
2024-08-01 01:03:30 | INFO | train_inner | epoch 006:   9480 / 17024 loss=6.974, nll_loss=5.941, ppl=61.46, wps=25058.1, ups=6.33, wpb=3957.2, bsz=174.1, num_updates=94600, lr=0.000102815, gnorm=0.972, train_wall=16, wall=0
2024-08-01 01:03:45 | INFO | train_inner | epoch 006:   9580 / 17024 loss=6.915, nll_loss=5.872, ppl=58.58, wps=25264.4, ups=6.37, wpb=3964.9, bsz=152.5, num_updates=94700, lr=0.00010276, gnorm=0.943, train_wall=15, wall=0
2024-08-01 01:04:01 | INFO | train_inner | epoch 006:   9680 / 17024 loss=6.963, nll_loss=5.928, ppl=60.89, wps=25307.5, ups=6.36, wpb=3979.6, bsz=173, num_updates=94800, lr=0.000102706, gnorm=0.971, train_wall=16, wall=0
2024-08-01 01:04:17 | INFO | train_inner | epoch 006:   9780 / 17024 loss=6.931, nll_loss=5.891, ppl=59.35, wps=25340.1, ups=6.37, wpb=3977.7, bsz=147.8, num_updates=94900, lr=0.000102652, gnorm=0.951, train_wall=15, wall=0
2024-08-01 01:04:32 | INFO | train_inner | epoch 006:   9880 / 17024 loss=6.957, nll_loss=5.921, ppl=60.59, wps=25210.1, ups=6.34, wpb=3974.2, bsz=165.4, num_updates=95000, lr=0.000102598, gnorm=0.958, train_wall=16, wall=0
2024-08-01 01:04:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 01:04:34 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.201 | nll_loss 6.139 | ppl 70.48 | wps 93712.6 | wpb 3529.1 | bsz 62.9 | num_updates 95000 | best_loss 7.199
2024-08-01 01:04:34 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 01:04:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_95000.pt (epoch 6 @ 95000 updates, score 7.201) (writing took 3.108916117809713 seconds)
2024-08-01 01:04:53 | INFO | train_inner | epoch 006:   9980 / 17024 loss=6.939, nll_loss=5.9, ppl=59.71, wps=19638.2, ups=4.93, wpb=3979.4, bsz=154.7, num_updates=95100, lr=0.000102544, gnorm=0.961, train_wall=15, wall=0
2024-08-01 01:05:08 | INFO | train_inner | epoch 006:  10080 / 17024 loss=6.939, nll_loss=5.901, ppl=59.74, wps=25250.2, ups=6.36, wpb=3969.7, bsz=165.4, num_updates=95200, lr=0.00010249, gnorm=0.974, train_wall=16, wall=0
2024-08-01 01:05:24 | INFO | train_inner | epoch 006:  10180 / 17024 loss=6.944, nll_loss=5.907, ppl=59.99, wps=25153.8, ups=6.35, wpb=3964.1, bsz=162.6, num_updates=95300, lr=0.000102436, gnorm=0.971, train_wall=16, wall=0
2024-08-01 01:05:40 | INFO | train_inner | epoch 006:  10280 / 17024 loss=6.964, nll_loss=5.93, ppl=60.96, wps=25413.9, ups=6.36, wpb=3993.2, bsz=169, num_updates=95400, lr=0.000102383, gnorm=0.979, train_wall=15, wall=0
2024-08-01 01:05:56 | INFO | train_inner | epoch 006:  10380 / 17024 loss=6.936, nll_loss=5.898, ppl=59.61, wps=25284, ups=6.41, wpb=3943.8, bsz=157.4, num_updates=95500, lr=0.000102329, gnorm=0.967, train_wall=15, wall=0
2024-08-01 01:06:11 | INFO | train_inner | epoch 006:  10480 / 17024 loss=6.982, nll_loss=5.95, ppl=61.84, wps=25402.8, ups=6.37, wpb=3986.2, bsz=168.8, num_updates=95600, lr=0.000102275, gnorm=0.981, train_wall=16, wall=0
2024-08-01 01:06:27 | INFO | train_inner | epoch 006:  10580 / 17024 loss=6.97, nll_loss=5.937, ppl=61.24, wps=25763.1, ups=6.49, wpb=3969.8, bsz=161.8, num_updates=95700, lr=0.000102222, gnorm=0.981, train_wall=15, wall=0
2024-08-01 01:06:42 | INFO | train_inner | epoch 006:  10680 / 17024 loss=6.943, nll_loss=5.904, ppl=59.89, wps=25923.8, ups=6.56, wpb=3953.5, bsz=153.8, num_updates=95800, lr=0.000102169, gnorm=0.981, train_wall=15, wall=0
2024-08-01 01:06:57 | INFO | train_inner | epoch 006:  10780 / 17024 loss=6.964, nll_loss=5.93, ppl=60.97, wps=25763.1, ups=6.45, wpb=3991.8, bsz=173.4, num_updates=95900, lr=0.000102115, gnorm=0.991, train_wall=15, wall=0
2024-08-01 01:07:13 | INFO | train_inner | epoch 006:  10880 / 17024 loss=6.963, nll_loss=5.929, ppl=60.91, wps=25670.4, ups=6.47, wpb=3965.9, bsz=163.6, num_updates=96000, lr=0.000102062, gnorm=0.988, train_wall=15, wall=0
2024-08-01 01:07:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 01:07:14 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.213 | nll_loss 6.156 | ppl 71.3 | wps 95117.8 | wpb 3529.1 | bsz 62.9 | num_updates 96000 | best_loss 7.199
2024-08-01 01:07:14 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 01:07:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_96000.pt (epoch 6 @ 96000 updates, score 7.213) (writing took 2.935308483429253 seconds)
2024-08-01 01:07:33 | INFO | train_inner | epoch 006:  10980 / 17024 loss=6.968, nll_loss=5.933, ppl=61.1, wps=19998.6, ups=5.06, wpb=3956, bsz=164, num_updates=96100, lr=0.000102009, gnorm=0.977, train_wall=15, wall=0
2024-08-01 01:07:48 | INFO | train_inner | epoch 006:  11080 / 17024 loss=6.94, nll_loss=5.901, ppl=59.77, wps=25506.4, ups=6.45, wpb=3954.3, bsz=151.3, num_updates=96200, lr=0.000101956, gnorm=0.991, train_wall=15, wall=0
2024-08-01 01:08:04 | INFO | train_inner | epoch 006:  11180 / 17024 loss=6.946, nll_loss=5.91, ppl=60.11, wps=25346.6, ups=6.4, wpb=3959.7, bsz=170, num_updates=96300, lr=0.000101903, gnorm=0.97, train_wall=15, wall=0
2024-08-01 01:08:19 | INFO | train_inner | epoch 006:  11280 / 17024 loss=6.976, nll_loss=5.943, ppl=61.53, wps=25744.5, ups=6.49, wpb=3968.6, bsz=186.2, num_updates=96400, lr=0.00010185, gnorm=0.984, train_wall=15, wall=0
2024-08-01 01:08:34 | INFO | train_inner | epoch 006:  11380 / 17024 loss=6.96, nll_loss=5.925, ppl=60.74, wps=25654.3, ups=6.51, wpb=3939.7, bsz=151.3, num_updates=96500, lr=0.000101797, gnorm=0.97, train_wall=15, wall=0
2024-08-01 01:08:50 | INFO | train_inner | epoch 006:  11480 / 17024 loss=6.904, nll_loss=5.861, ppl=58.1, wps=25610.7, ups=6.46, wpb=3965.7, bsz=148.5, num_updates=96600, lr=0.000101745, gnorm=0.941, train_wall=15, wall=0
2024-08-01 01:09:06 | INFO | train_inner | epoch 006:  11580 / 17024 loss=6.948, nll_loss=5.911, ppl=60.18, wps=25545.9, ups=6.43, wpb=3971.1, bsz=162, num_updates=96700, lr=0.000101692, gnorm=0.98, train_wall=15, wall=0
2024-08-01 01:09:21 | INFO | train_inner | epoch 006:  11680 / 17024 loss=6.971, nll_loss=5.937, ppl=61.26, wps=25653.7, ups=6.5, wpb=3945.2, bsz=157, num_updates=96800, lr=0.000101639, gnorm=1.016, train_wall=15, wall=0
2024-08-01 01:09:36 | INFO | train_inner | epoch 006:  11780 / 17024 loss=6.954, nll_loss=5.918, ppl=60.48, wps=25645.7, ups=6.48, wpb=3956.3, bsz=159, num_updates=96900, lr=0.000101587, gnorm=0.977, train_wall=15, wall=0
2024-08-01 01:09:52 | INFO | train_inner | epoch 006:  11880 / 17024 loss=7.008, nll_loss=5.98, ppl=63.13, wps=25731.9, ups=6.48, wpb=3969.5, bsz=187.5, num_updates=97000, lr=0.000101535, gnorm=1.002, train_wall=15, wall=0
2024-08-01 01:09:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 01:09:53 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.212 | nll_loss 6.152 | ppl 71.13 | wps 94942.8 | wpb 3529.1 | bsz 62.9 | num_updates 97000 | best_loss 7.199
2024-08-01 01:09:53 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 01:09:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_97000.pt (epoch 6 @ 97000 updates, score 7.212) (writing took 2.965582092292607 seconds)
2024-08-01 01:10:12 | INFO | train_inner | epoch 006:  11980 / 17024 loss=6.985, nll_loss=5.954, ppl=61.97, wps=19873, ups=5, wpb=3970.8, bsz=173.8, num_updates=97100, lr=0.000101482, gnorm=0.964, train_wall=15, wall=0
2024-08-01 01:10:27 | INFO | train_inner | epoch 006:  12080 / 17024 loss=6.983, nll_loss=5.952, ppl=61.9, wps=25734.2, ups=6.47, wpb=3975.3, bsz=179.8, num_updates=97200, lr=0.00010143, gnorm=0.992, train_wall=15, wall=0
2024-08-01 01:10:43 | INFO | train_inner | epoch 006:  12180 / 17024 loss=6.882, nll_loss=5.836, ppl=57.12, wps=25501.4, ups=6.48, wpb=3934.3, bsz=143.3, num_updates=97300, lr=0.000101378, gnorm=0.967, train_wall=15, wall=0
2024-08-01 01:10:58 | INFO | train_inner | epoch 006:  12280 / 17024 loss=6.973, nll_loss=5.939, ppl=61.34, wps=25771.6, ups=6.55, wpb=3935.4, bsz=159.1, num_updates=97400, lr=0.000101326, gnorm=1.01, train_wall=15, wall=0
2024-08-01 01:11:13 | INFO | train_inner | epoch 006:  12380 / 17024 loss=6.957, nll_loss=5.922, ppl=60.61, wps=25488.4, ups=6.42, wpb=3967.6, bsz=164, num_updates=97500, lr=0.000101274, gnorm=0.962, train_wall=15, wall=0
2024-08-01 01:11:29 | INFO | train_inner | epoch 006:  12480 / 17024 loss=6.953, nll_loss=5.917, ppl=60.41, wps=25595.7, ups=6.46, wpb=3961, bsz=158.6, num_updates=97600, lr=0.000101222, gnorm=0.969, train_wall=15, wall=0
2024-08-01 01:11:44 | INFO | train_inner | epoch 006:  12580 / 17024 loss=6.95, nll_loss=5.914, ppl=60.3, wps=25592.1, ups=6.46, wpb=3964.3, bsz=161.5, num_updates=97700, lr=0.00010117, gnorm=0.959, train_wall=15, wall=0
2024-08-01 01:12:00 | INFO | train_inner | epoch 006:  12680 / 17024 loss=6.928, nll_loss=5.888, ppl=59.23, wps=25726.3, ups=6.46, wpb=3980.3, bsz=151, num_updates=97800, lr=0.000101118, gnorm=0.949, train_wall=15, wall=0
2024-08-01 01:12:15 | INFO | train_inner | epoch 006:  12780 / 17024 loss=6.889, nll_loss=5.843, ppl=57.39, wps=25821.8, ups=6.5, wpb=3972.2, bsz=147.7, num_updates=97900, lr=0.000101067, gnorm=0.97, train_wall=15, wall=0
2024-08-01 01:12:31 | INFO | train_inner | epoch 006:  12880 / 17024 loss=6.967, nll_loss=5.933, ppl=61.1, wps=25623, ups=6.44, wpb=3977, bsz=169, num_updates=98000, lr=0.000101015, gnorm=0.998, train_wall=15, wall=0
2024-08-01 01:12:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 01:12:32 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.194 | nll_loss 6.133 | ppl 70.19 | wps 95543.7 | wpb 3529.1 | bsz 62.9 | num_updates 98000 | best_loss 7.194
2024-08-01 01:12:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 01:12:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_98000.pt (epoch 6 @ 98000 updates, score 7.194) (writing took 6.829070251435041 seconds)
2024-08-01 01:12:55 | INFO | train_inner | epoch 006:  12980 / 17024 loss=6.973, nll_loss=5.939, ppl=61.37, wps=16676.6, ups=4.2, wpb=3967.9, bsz=171, num_updates=98100, lr=0.000100964, gnorm=1.003, train_wall=15, wall=0
2024-08-01 01:13:10 | INFO | train_inner | epoch 006:  13080 / 17024 loss=6.938, nll_loss=5.9, ppl=59.7, wps=25655.4, ups=6.48, wpb=3958.1, bsz=155.3, num_updates=98200, lr=0.000100912, gnorm=0.972, train_wall=15, wall=0
2024-08-01 01:13:25 | INFO | train_inner | epoch 006:  13180 / 17024 loss=6.951, nll_loss=5.915, ppl=60.34, wps=25572.1, ups=6.46, wpb=3957.5, bsz=159.9, num_updates=98300, lr=0.000100861, gnorm=0.968, train_wall=15, wall=0
2024-08-01 01:13:41 | INFO | train_inner | epoch 006:  13280 / 17024 loss=6.995, nll_loss=5.966, ppl=62.49, wps=25638.6, ups=6.46, wpb=3966.6, bsz=176.3, num_updates=98400, lr=0.00010081, gnorm=1.02, train_wall=15, wall=0
2024-08-01 01:13:56 | INFO | train_inner | epoch 006:  13380 / 17024 loss=6.904, nll_loss=5.86, ppl=58.09, wps=25644.5, ups=6.5, wpb=3945.2, bsz=153.5, num_updates=98500, lr=0.000100759, gnorm=0.967, train_wall=15, wall=0
2024-08-01 01:14:12 | INFO | train_inner | epoch 006:  13480 / 17024 loss=6.961, nll_loss=5.926, ppl=60.78, wps=25756.2, ups=6.5, wpb=3963.7, bsz=161.2, num_updates=98600, lr=0.000100707, gnorm=1, train_wall=15, wall=0
2024-08-01 01:14:27 | INFO | train_inner | epoch 006:  13580 / 17024 loss=6.971, nll_loss=5.937, ppl=61.28, wps=25687.7, ups=6.52, wpb=3939.8, bsz=162.9, num_updates=98700, lr=0.000100656, gnorm=0.993, train_wall=15, wall=0
2024-08-01 01:14:43 | INFO | train_inner | epoch 006:  13680 / 17024 loss=6.967, nll_loss=5.933, ppl=61.08, wps=25770.1, ups=6.47, wpb=3980.5, bsz=169.8, num_updates=98800, lr=0.000100605, gnorm=1.009, train_wall=15, wall=0
2024-08-01 01:14:58 | INFO | train_inner | epoch 006:  13780 / 17024 loss=6.956, nll_loss=5.92, ppl=60.56, wps=25737.8, ups=6.53, wpb=3944, bsz=156.5, num_updates=98900, lr=0.000100555, gnorm=0.989, train_wall=15, wall=0
2024-08-01 01:15:13 | INFO | train_inner | epoch 006:  13880 / 17024 loss=6.966, nll_loss=5.932, ppl=61.04, wps=25687.6, ups=6.48, wpb=3962.9, bsz=161.6, num_updates=99000, lr=0.000100504, gnorm=1.018, train_wall=15, wall=0
2024-08-01 01:15:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 01:15:15 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.199 | nll_loss 6.141 | ppl 70.57 | wps 95174.3 | wpb 3529.1 | bsz 62.9 | num_updates 99000 | best_loss 7.194
2024-08-01 01:15:15 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 01:15:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_99000.pt (epoch 6 @ 99000 updates, score 7.199) (writing took 3.4908005194738507 seconds)
2024-08-01 01:15:34 | INFO | train_inner | epoch 006:  13980 / 17024 loss=6.967, nll_loss=5.933, ppl=61.08, wps=19502.2, ups=4.93, wpb=3955.3, bsz=159.3, num_updates=99100, lr=0.000100453, gnorm=0.961, train_wall=15, wall=0
2024-08-01 01:15:49 | INFO | train_inner | epoch 006:  14080 / 17024 loss=6.97, nll_loss=5.936, ppl=61.22, wps=25413.6, ups=6.44, wpb=3947.8, bsz=167.2, num_updates=99200, lr=0.000100402, gnorm=0.995, train_wall=15, wall=0
2024-08-01 01:16:04 | INFO | train_inner | epoch 006:  14180 / 17024 loss=6.946, nll_loss=5.909, ppl=60.09, wps=25857, ups=6.51, wpb=3971.2, bsz=160.3, num_updates=99300, lr=0.000100352, gnorm=0.973, train_wall=15, wall=0
2024-08-01 01:16:20 | INFO | train_inner | epoch 006:  14280 / 17024 loss=6.953, nll_loss=5.917, ppl=60.42, wps=25861.5, ups=6.5, wpb=3979.5, bsz=159.1, num_updates=99400, lr=0.000100301, gnorm=0.98, train_wall=15, wall=0
2024-08-01 01:16:35 | INFO | train_inner | epoch 006:  14380 / 17024 loss=6.911, nll_loss=5.868, ppl=58.42, wps=25799.5, ups=6.55, wpb=3938.4, bsz=142.6, num_updates=99500, lr=0.000100251, gnorm=0.976, train_wall=15, wall=0
2024-08-01 01:16:50 | INFO | train_inner | epoch 006:  14480 / 17024 loss=6.949, nll_loss=5.912, ppl=60.21, wps=25883.6, ups=6.52, wpb=3968.5, bsz=162.2, num_updates=99600, lr=0.000100201, gnorm=0.993, train_wall=15, wall=0
2024-08-01 01:17:06 | INFO | train_inner | epoch 006:  14580 / 17024 loss=7.042, nll_loss=6.019, ppl=64.86, wps=25753, ups=6.52, wpb=3947.2, bsz=181, num_updates=99700, lr=0.00010015, gnorm=1.044, train_wall=15, wall=0
2024-08-01 01:17:21 | INFO | train_inner | epoch 006:  14680 / 17024 loss=6.918, nll_loss=5.876, ppl=58.73, wps=25566.3, ups=6.49, wpb=3936.5, bsz=149.5, num_updates=99800, lr=0.0001001, gnorm=0.998, train_wall=15, wall=0
2024-08-01 01:17:37 | INFO | train_inner | epoch 006:  14780 / 17024 loss=6.964, nll_loss=5.93, ppl=60.96, wps=25748.9, ups=6.47, wpb=3980.2, bsz=171.9, num_updates=99900, lr=0.00010005, gnorm=0.988, train_wall=15, wall=0
2024-08-01 01:17:52 | INFO | train_inner | epoch 006:  14880 / 17024 loss=6.895, nll_loss=5.85, ppl=57.67, wps=25781.9, ups=6.5, wpb=3968.9, bsz=143.3, num_updates=100000, lr=0.0001, gnorm=0.954, train_wall=15, wall=0
2024-08-01 01:17:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-08-01 01:17:54 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.181 | nll_loss 6.119 | ppl 69.51 | wps 94114.4 | wpb 3529.1 | bsz 62.9 | num_updates 100000 | best_loss 7.181
2024-08-01 01:17:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-08-01 01:18:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_100000.pt (epoch 6 @ 100000 updates, score 7.181) (writing took 6.3819984793663025 seconds)
2024-08-01 01:18:00 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2024-08-01 01:18:00 | INFO | train | epoch 006 | loss 6.957 | nll_loss 5.922 | ppl 60.62 | wps 24701.1 | ups 6.24 | wpb 3960.4 | bsz 163.1 | num_updates 100000 | lr 0.0001 | gnorm 0.975 | train_wall 2273 | wall 0
2024-08-01 01:18:00 | INFO | fairseq_cli.train | done training in 14461.9 seconds
