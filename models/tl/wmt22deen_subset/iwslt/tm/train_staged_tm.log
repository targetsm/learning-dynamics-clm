2024-07-18 11:54:17 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/wmt22.sep.tokenized.de-en', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='de', srcdict=None, target_lang='en', task='translation', tensorboard_logdir=None, testpref='/local/home/ggabriel/ma/data/tl/wmt22deen/wmt22.sep.tokenized.de-en/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/local/home/ggabriel/ma/data/tl/wmt22deen/wmt22.sep.tokenized.de-en/train', user_dir=None, validpref='/local/home/ggabriel/ma/data/tl/wmt22deen/wmt22.sep.tokenized.de-en/valid', workers=8)
2024-07-18 11:55:11 | INFO | fairseq_cli.preprocess | [de] Dictionary: 9968 types
2024-07-18 11:56:29 | INFO | fairseq_cli.preprocess | [de] /local/home/ggabriel/ma/data/tl/wmt22deen/wmt22.sep.tokenized.de-en/train.de: 2782552 sents, 74615327 tokens, 0.0% replaced by <unk>
2024-07-18 11:56:29 | INFO | fairseq_cli.preprocess | [de] Dictionary: 9968 types
2024-07-18 11:56:29 | INFO | fairseq_cli.preprocess | [de] /local/home/ggabriel/ma/data/tl/wmt22deen/wmt22.sep.tokenized.de-en/valid.de: 2203 sents, 137910 tokens, 0.0% replaced by <unk>
2024-07-18 11:56:29 | INFO | fairseq_cli.preprocess | [de] Dictionary: 9968 types
2024-07-18 11:56:29 | INFO | fairseq_cli.preprocess | [de] /local/home/ggabriel/ma/data/tl/wmt22deen/wmt22.sep.tokenized.de-en/test.de: 785 sents, 57046 tokens, 0.0% replaced by <unk>
2024-07-18 11:56:29 | INFO | fairseq_cli.preprocess | [en] Dictionary: 9968 types
2024-07-18 11:57:41 | INFO | fairseq_cli.preprocess | [en] /local/home/ggabriel/ma/data/tl/wmt22deen/wmt22.sep.tokenized.de-en/train.en: 2782552 sents, 67426902 tokens, 0.0% replaced by <unk>
2024-07-18 11:57:41 | INFO | fairseq_cli.preprocess | [en] Dictionary: 9968 types
2024-07-18 11:57:42 | INFO | fairseq_cli.preprocess | [en] /local/home/ggabriel/ma/data/tl/wmt22deen/wmt22.sep.tokenized.de-en/valid.en: 2203 sents, 123520 tokens, 0.0% replaced by <unk>
2024-07-18 11:57:42 | INFO | fairseq_cli.preprocess | [en] Dictionary: 9968 types
2024-07-18 11:57:42 | INFO | fairseq_cli.preprocess | [en] /local/home/ggabriel/ma/data/tl/wmt22deen/wmt22.sep.tokenized.de-en/test.en: 785 sents, 51963 tokens, 0.0% replaced by <unk>
2024-07-18 11:57:42 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/wmt22.sep.tokenized.de-en
2024-07-18 11:57:45 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt22.sep.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=1000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=100, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-18 11:57:45 | INFO | fairseq.tasks.translation | [de] dictionary: 9968 types
2024-07-18 11:57:45 | INFO | fairseq.tasks.translation | [en] dictionary: 9968 types
2024-07-18 11:57:45 | INFO | fairseq.data.data_utils | loaded 2203 examples from: data-bin/wmt22.sep.tokenized.de-en/valid.de-en.de
2024-07-18 11:57:45 | INFO | fairseq.data.data_utils | loaded 2203 examples from: data-bin/wmt22.sep.tokenized.de-en/valid.de-en.en
2024-07-18 11:57:45 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.de-en valid de-en 2203 examples
2024-07-18 11:57:46 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9968, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9968, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=9968, bias=False)
  )
)
2024-07-18 11:57:46 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-18 11:57:46 | INFO | fairseq_cli.train | model: transformer_iwslt_de_en (TransformerModel)
2024-07-18 11:57:46 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-18 11:57:46 | INFO | fairseq_cli.train | num. model params: 41750528 (num. trained: 41750528)
2024-07-18 11:58:00 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-18 11:58:00 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-18 11:58:00 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-18 11:58:00 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-18 11:58:00 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-18 11:58:00 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-18 11:58:00 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/checkpoint_last.pt
2024-07-18 11:58:00 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-18 11:58:00 | INFO | fairseq.data.data_utils | loaded 2782552 examples from: data-bin/wmt22.sep.tokenized.de-en/train.de-en.de
2024-07-18 11:58:00 | INFO | fairseq.data.data_utils | loaded 2782552 examples from: data-bin/wmt22.sep.tokenized.de-en/train.de-en.en
2024-07-18 11:58:00 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.de-en train de-en 2782552 examples
2024-07-18 11:58:03 | INFO | fairseq.trainer | begin training epoch 1
2024-07-18 11:58:23 | INFO | train_inner | epoch 001:    100 / 19564 loss=12.98, nll_loss=12.862, ppl=7443.93, wps=18284.6, ups=5.27, wpb=3472.3, bsz=130, num_updates=100, lr=1.25e-05, gnorm=3.106, train_wall=20, wall=23
2024-07-18 11:58:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-18 11:58:25 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.134 | nll_loss 11.901 | ppl 3825.53 | wps 55879.1 | wpb 2872.6 | bsz 51.2 | num_updates 100
2024-07-18 11:58:25 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 11:58:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_100.pt (epoch 1 @ 100 updates, score 12.134) (writing took 1.9785230280831456 seconds)
2024-07-18 11:58:46 | INFO | train_inner | epoch 001:    200 / 19564 loss=11.73, nll_loss=11.468, ppl=2832.13, wps=15043.2, ups=4.35, wpb=3460.4, bsz=135.9, num_updates=200, lr=2.5e-05, gnorm=1.3, train_wall=19, wall=46
2024-07-18 11:58:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 11:58:48 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.402 | nll_loss 11.091 | ppl 2181.43 | wps 56208.6 | wpb 2872.6 | bsz 51.2 | num_updates 200 | best_loss 12.134
2024-07-18 11:58:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 11:58:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_200.pt (epoch 1 @ 200 updates, score 11.402) (writing took 2.9925093986094 seconds)
2024-07-18 11:59:10 | INFO | train_inner | epoch 001:    300 / 19564 loss=11.064, nll_loss=10.711, ppl=1676.11, wps=14266.2, ups=4.11, wpb=3468.5, bsz=137.4, num_updates=300, lr=3.75e-05, gnorm=1.611, train_wall=19, wall=71
2024-07-18 11:59:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 11:59:12 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.852 | nll_loss 10.448 | ppl 1396.7 | wps 55947.9 | wpb 2872.6 | bsz 51.2 | num_updates 300 | best_loss 12.134
2024-07-18 11:59:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 11:59:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_300.pt (epoch 1 @ 300 updates, score 10.852) (writing took 3.073329633101821 seconds)
2024-07-18 11:59:35 | INFO | train_inner | epoch 001:    400 / 19564 loss=10.665, nll_loss=10.228, ppl=1199.34, wps=14298, ups=4.09, wpb=3493.5, bsz=127.3, num_updates=400, lr=5e-05, gnorm=1.537, train_wall=19, wall=95
2024-07-18 11:59:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 11:59:37 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.729 | nll_loss 10.273 | ppl 1237.14 | wps 56067 | wpb 2872.6 | bsz 51.2 | num_updates 400 | best_loss 12.134
2024-07-18 11:59:37 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 11:59:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_400.pt (epoch 1 @ 400 updates, score 10.729) (writing took 9.558410647325218 seconds)
2024-07-18 12:00:06 | INFO | train_inner | epoch 001:    500 / 19564 loss=10.554, nll_loss=10.082, ppl=1083.54, wps=11130.9, ups=3.22, wpb=3455.4, bsz=161.1, num_updates=500, lr=6.25e-05, gnorm=1.625, train_wall=19, wall=126
2024-07-18 12:00:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:00:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.738 | nll_loss 10.253 | ppl 1219.96 | wps 55756.5 | wpb 2872.6 | bsz 51.2 | num_updates 500 | best_loss 12.134
2024-07-18 12:00:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:00:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_500.pt (epoch 1 @ 500 updates, score 10.738) (writing took 9.431595301255584 seconds)
2024-07-18 12:00:36 | INFO | train_inner | epoch 001:    600 / 19564 loss=10.523, nll_loss=10.041, ppl=1053.62, wps=11057.4, ups=3.26, wpb=3391.6, bsz=143, num_updates=600, lr=7.5e-05, gnorm=1.6, train_wall=19, wall=157
2024-07-18 12:00:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:00:39 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.418 | nll_loss 9.894 | ppl 951.3 | wps 56058.3 | wpb 2872.6 | bsz 51.2 | num_updates 600 | best_loss 12.134
2024-07-18 12:00:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:00:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_600.pt (epoch 1 @ 600 updates, score 10.418) (writing took 6.19358439091593 seconds)
2024-07-18 12:01:04 | INFO | train_inner | epoch 001:    700 / 19564 loss=10.365, nll_loss=9.861, ppl=929.66, wps=12515.9, ups=3.63, wpb=3451.4, bsz=127.6, num_updates=700, lr=8.75e-05, gnorm=1.389, train_wall=19, wall=184
2024-07-18 12:01:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:01:06 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.3 | nll_loss 9.742 | ppl 856.07 | wps 55429.6 | wpb 2872.6 | bsz 51.2 | num_updates 700 | best_loss 12.134
2024-07-18 12:01:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:01:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_700.pt (epoch 1 @ 700 updates, score 10.3) (writing took 4.843294710852206 seconds)
2024-07-18 12:01:30 | INFO | train_inner | epoch 001:    800 / 19564 loss=10.234, nll_loss=9.711, ppl=837.9, wps=13189.5, ups=3.79, wpb=3480.4, bsz=141.1, num_updates=800, lr=0.0001, gnorm=1.392, train_wall=19, wall=211
2024-07-18 12:01:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:01:33 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.13 | nll_loss 9.553 | ppl 751.29 | wps 55466.2 | wpb 2872.6 | bsz 51.2 | num_updates 800 | best_loss 12.134
2024-07-18 12:01:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:01:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_800.pt (epoch 1 @ 800 updates, score 10.13) (writing took 4.52682673279196 seconds)
2024-07-18 12:01:56 | INFO | train_inner | epoch 001:    900 / 19564 loss=10.059, nll_loss=9.51, ppl=728.95, wps=13203.6, ups=3.84, wpb=3436.1, bsz=157, num_updates=900, lr=0.0001125, gnorm=1.321, train_wall=19, wall=237
2024-07-18 12:01:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:01:59 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.093 | nll_loss 9.513 | ppl 730.76 | wps 55888.5 | wpb 2872.6 | bsz 51.2 | num_updates 900 | best_loss 12.134
2024-07-18 12:01:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:02:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_900.pt (epoch 1 @ 900 updates, score 10.093) (writing took 2.927055641077459 seconds)
2024-07-18 12:02:21 | INFO | train_inner | epoch 001:   1000 / 19564 loss=9.987, nll_loss=9.425, ppl=687.23, wps=14184.5, ups=4.07, wpb=3485.2, bsz=135.1, num_updates=1000, lr=0.000125, gnorm=1.431, train_wall=19, wall=261
2024-07-18 12:02:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:02:23 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.896 | nll_loss 9.313 | ppl 636.06 | wps 55355.4 | wpb 2872.6 | bsz 51.2 | num_updates 1000 | best_loss 12.134
2024-07-18 12:02:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:02:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 9.896) (writing took 5.95477238856256 seconds)
2024-07-18 12:02:29 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-18 12:02:29 | INFO | train | epoch 001 | loss 10.817 | nll_loss 10.391 | ppl 1342.64 | wps 13035.1 | ups 3.77 | wpb 3459.5 | bsz 139.6 | num_updates 1000 | lr 0.000125 | gnorm 1.631 | train_wall 190 | wall 270
2024-07-18 12:02:29 | INFO | fairseq_cli.train | done training in 266.5 seconds
2024-07-18 12:02:32 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt22.sep.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=10000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=500, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-18 12:02:32 | INFO | fairseq.tasks.translation | [de] dictionary: 9968 types
2024-07-18 12:02:32 | INFO | fairseq.tasks.translation | [en] dictionary: 9968 types
2024-07-18 12:02:32 | INFO | fairseq.data.data_utils | loaded 2203 examples from: data-bin/wmt22.sep.tokenized.de-en/valid.de-en.de
2024-07-18 12:02:32 | INFO | fairseq.data.data_utils | loaded 2203 examples from: data-bin/wmt22.sep.tokenized.de-en/valid.de-en.en
2024-07-18 12:02:32 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.de-en valid de-en 2203 examples
2024-07-18 12:02:32 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9968, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9968, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=9968, bias=False)
  )
)
2024-07-18 12:02:32 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-18 12:02:32 | INFO | fairseq_cli.train | model: transformer_iwslt_de_en (TransformerModel)
2024-07-18 12:02:32 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-18 12:02:32 | INFO | fairseq_cli.train | num. model params: 41750528 (num. trained: 41750528)
2024-07-18 12:02:38 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-18 12:02:38 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-18 12:02:38 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-18 12:02:38 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-18 12:02:38 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-18 12:02:38 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-18 12:02:39 | INFO | fairseq.trainer | loaded checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 1000 updates)
2024-07-18 12:02:39 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-18 12:02:39 | INFO | fairseq.data.data_utils | loaded 2782552 examples from: data-bin/wmt22.sep.tokenized.de-en/train.de-en.de
2024-07-18 12:02:39 | INFO | fairseq.data.data_utils | loaded 2782552 examples from: data-bin/wmt22.sep.tokenized.de-en/train.de-en.en
2024-07-18 12:02:39 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.de-en train de-en 2782552 examples
2024-07-18 12:02:42 | INFO | fairseq.trainer | begin training epoch 1
2024-07-18 12:03:02 | INFO | train_inner | epoch 001:   1100 / 19564 loss=9.854, nll_loss=9.272, ppl=618.22, wps=13520.6, ups=3.9, wpb=3470.4, bsz=132.9, num_updates=1100, lr=0.0001375, gnorm=1.371, train_wall=20, wall=0
2024-07-18 12:03:22 | INFO | train_inner | epoch 001:   1200 / 19564 loss=9.672, nll_loss=9.06, ppl=533.76, wps=17779.5, ups=5.15, wpb=3455.1, bsz=148.4, num_updates=1200, lr=0.00015, gnorm=1.42, train_wall=19, wall=0
2024-07-18 12:03:41 | INFO | train_inner | epoch 001:   1300 / 19564 loss=9.627, nll_loss=9.006, ppl=514.26, wps=17803.4, ups=5.16, wpb=3447.1, bsz=130.7, num_updates=1300, lr=0.0001625, gnorm=1.327, train_wall=19, wall=0
2024-07-18 12:04:01 | INFO | train_inner | epoch 001:   1400 / 19564 loss=9.509, nll_loss=8.868, ppl=467.36, wps=17425.2, ups=5.17, wpb=3371.5, bsz=154.4, num_updates=1400, lr=0.000175, gnorm=1.477, train_wall=19, wall=0
2024-07-18 12:04:20 | INFO | train_inner | epoch 001:   1500 / 19564 loss=9.375, nll_loss=8.714, ppl=419.82, wps=17403.4, ups=5.06, wpb=3436.6, bsz=146.6, num_updates=1500, lr=0.0001875, gnorm=1.247, train_wall=20, wall=0
2024-07-18 12:04:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-18 12:04:23 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.466 | nll_loss 8.766 | ppl 435.32 | wps 55662.2 | wpb 2872.6 | bsz 51.2 | num_updates 1500 | best_loss 12.134
2024-07-18 12:04:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:04:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_1500.pt (epoch 1 @ 1500 updates, score 9.466) (writing took 3.8492326363921165 seconds)
2024-07-18 12:04:46 | INFO | train_inner | epoch 001:   1600 / 19564 loss=9.232, nll_loss=8.547, ppl=374.01, wps=13534.1, ups=3.85, wpb=3511.6, bsz=145.8, num_updates=1600, lr=0.0002, gnorm=1.34, train_wall=20, wall=0
2024-07-18 12:05:06 | INFO | train_inner | epoch 001:   1700 / 19564 loss=9.15, nll_loss=8.452, ppl=350.1, wps=17761.5, ups=5.16, wpb=3442.8, bsz=150.1, num_updates=1700, lr=0.0002125, gnorm=1.264, train_wall=19, wall=0
2024-07-18 12:05:26 | INFO | train_inner | epoch 001:   1800 / 19564 loss=9.079, nll_loss=8.368, ppl=330.4, wps=17199.1, ups=5, wpb=3440.4, bsz=134.2, num_updates=1800, lr=0.000225, gnorm=1.232, train_wall=20, wall=0
2024-07-18 12:05:45 | INFO | train_inner | epoch 001:   1900 / 19564 loss=9.018, nll_loss=8.295, ppl=314.15, wps=17718.9, ups=5.15, wpb=3438.6, bsz=149.8, num_updates=1900, lr=0.0002375, gnorm=1.245, train_wall=19, wall=0
2024-07-18 12:06:05 | INFO | train_inner | epoch 001:   2000 / 19564 loss=8.963, nll_loss=8.229, ppl=300.12, wps=17481.7, ups=5.12, wpb=3416.2, bsz=140, num_updates=2000, lr=0.00025, gnorm=1.286, train_wall=19, wall=0
2024-07-18 12:06:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:06:07 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.251 | nll_loss 8.52 | ppl 366.97 | wps 55824.2 | wpb 2872.6 | bsz 51.2 | num_updates 2000 | best_loss 12.134
2024-07-18 12:06:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:06:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 9.251) (writing took 3.214974844828248 seconds)
2024-07-18 12:06:30 | INFO | train_inner | epoch 001:   2100 / 19564 loss=8.866, nll_loss=8.117, ppl=277.72, wps=13884.8, ups=3.98, wpb=3488.3, bsz=145.5, num_updates=2100, lr=0.0002625, gnorm=1.154, train_wall=19, wall=0
2024-07-18 12:06:49 | INFO | train_inner | epoch 001:   2200 / 19564 loss=8.81, nll_loss=8.052, ppl=265.34, wps=17768.9, ups=5.16, wpb=3441.6, bsz=151.7, num_updates=2200, lr=0.000275, gnorm=1.221, train_wall=19, wall=0
2024-07-18 12:07:09 | INFO | train_inner | epoch 001:   2300 / 19564 loss=8.777, nll_loss=8.012, ppl=258.21, wps=17517.8, ups=5.12, wpb=3424.2, bsz=136.8, num_updates=2300, lr=0.0002875, gnorm=1.142, train_wall=19, wall=0
2024-07-18 12:07:28 | INFO | train_inner | epoch 001:   2400 / 19564 loss=8.649, nll_loss=7.865, ppl=233.18, wps=17684.5, ups=5.07, wpb=3490.1, bsz=159, num_updates=2400, lr=0.0003, gnorm=1.136, train_wall=20, wall=0
2024-07-18 12:07:47 | INFO | train_inner | epoch 001:   2500 / 19564 loss=8.622, nll_loss=7.833, ppl=228.07, wps=18128.9, ups=5.24, wpb=3461.4, bsz=147.8, num_updates=2500, lr=0.0003125, gnorm=1.154, train_wall=19, wall=0
2024-07-18 12:07:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:07:50 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.937 | nll_loss 8.153 | ppl 284.65 | wps 55448.9 | wpb 2872.6 | bsz 51.2 | num_updates 2500 | best_loss 12.134
2024-07-18 12:07:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:07:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_2500.pt (epoch 1 @ 2500 updates, score 8.937) (writing took 3.0950353713706136 seconds)
2024-07-18 12:08:12 | INFO | train_inner | epoch 001:   2600 / 19564 loss=8.606, nll_loss=7.813, ppl=224.86, wps=13700.1, ups=4.02, wpb=3404, bsz=146.8, num_updates=2600, lr=0.000325, gnorm=1.173, train_wall=19, wall=0
2024-07-18 12:08:32 | INFO | train_inner | epoch 001:   2700 / 19564 loss=8.613, nll_loss=7.822, ppl=226.25, wps=17017.8, ups=5.15, wpb=3303.6, bsz=156.4, num_updates=2700, lr=0.0003375, gnorm=1.212, train_wall=19, wall=0
2024-07-18 12:08:51 | INFO | train_inner | epoch 001:   2800 / 19564 loss=8.437, nll_loss=7.618, ppl=196.46, wps=17777.6, ups=5.08, wpb=3498.2, bsz=140.9, num_updates=2800, lr=0.00035, gnorm=1.032, train_wall=19, wall=0
2024-07-18 12:09:11 | INFO | train_inner | epoch 001:   2900 / 19564 loss=8.474, nll_loss=7.659, ppl=202.17, wps=17380.5, ups=5.1, wpb=3405.5, bsz=139.1, num_updates=2900, lr=0.0003625, gnorm=1.131, train_wall=19, wall=0
2024-07-18 12:09:30 | INFO | train_inner | epoch 001:   3000 / 19564 loss=8.33, nll_loss=7.495, ppl=180.36, wps=17715.4, ups=5.14, wpb=3449.5, bsz=155, num_updates=3000, lr=0.000375, gnorm=1.112, train_wall=19, wall=0
2024-07-18 12:09:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:09:33 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.809 | nll_loss 7.998 | ppl 255.72 | wps 55357 | wpb 2872.6 | bsz 51.2 | num_updates 3000 | best_loss 12.134
2024-07-18 12:09:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:09:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_3000.pt (epoch 1 @ 3000 updates, score 8.809) (writing took 3.7515202881768346 seconds)
2024-07-18 12:09:56 | INFO | train_inner | epoch 001:   3100 / 19564 loss=8.381, nll_loss=7.551, ppl=187.48, wps=13635.1, ups=3.96, wpb=3440.4, bsz=133.9, num_updates=3100, lr=0.0003875, gnorm=1.141, train_wall=19, wall=0
2024-07-18 12:10:15 | INFO | train_inner | epoch 001:   3200 / 19564 loss=8.266, nll_loss=7.419, ppl=171.09, wps=17800.9, ups=5.07, wpb=3512.1, bsz=158.6, num_updates=3200, lr=0.0004, gnorm=1.134, train_wall=20, wall=0
2024-07-18 12:10:35 | INFO | train_inner | epoch 001:   3300 / 19564 loss=8.254, nll_loss=7.404, ppl=169.36, wps=17872, ups=5.12, wpb=3487.9, bsz=143.7, num_updates=3300, lr=0.0004125, gnorm=1.094, train_wall=19, wall=0
2024-07-18 12:10:54 | INFO | train_inner | epoch 001:   3400 / 19564 loss=8.302, nll_loss=7.458, ppl=175.79, wps=17404.2, ups=5.13, wpb=3389.8, bsz=135.8, num_updates=3400, lr=0.000425, gnorm=1.145, train_wall=19, wall=0
2024-07-18 12:11:14 | INFO | train_inner | epoch 001:   3500 / 19564 loss=8.196, nll_loss=7.338, ppl=161.79, wps=17412.9, ups=5.17, wpb=3370.5, bsz=139.7, num_updates=3500, lr=0.0004375, gnorm=1.116, train_wall=19, wall=0
2024-07-18 12:11:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:11:16 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.534 | nll_loss 7.679 | ppl 204.91 | wps 55257.6 | wpb 2872.6 | bsz 51.2 | num_updates 3500 | best_loss 12.134
2024-07-18 12:11:16 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:11:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_3500.pt (epoch 1 @ 3500 updates, score 8.534) (writing took 4.429615089669824 seconds)
2024-07-18 12:11:40 | INFO | train_inner | epoch 001:   3600 / 19564 loss=8.115, nll_loss=7.244, ppl=151.56, wps=13067.6, ups=3.81, wpb=3427.4, bsz=136.9, num_updates=3600, lr=0.00045, gnorm=1.11, train_wall=19, wall=0
2024-07-18 12:11:59 | INFO | train_inner | epoch 001:   3700 / 19564 loss=8.111, nll_loss=7.237, ppl=150.87, wps=17486.4, ups=5.18, wpb=3375.7, bsz=125.6, num_updates=3700, lr=0.0004625, gnorm=1.085, train_wall=19, wall=0
2024-07-18 12:12:19 | INFO | train_inner | epoch 001:   3800 / 19564 loss=8.038, nll_loss=7.154, ppl=142.41, wps=17260.2, ups=5.17, wpb=3341.5, bsz=138.2, num_updates=3800, lr=0.000475, gnorm=1.156, train_wall=19, wall=0
2024-07-18 12:12:38 | INFO | train_inner | epoch 001:   3900 / 19564 loss=7.986, nll_loss=7.093, ppl=136.55, wps=17589.9, ups=5.18, wpb=3392.5, bsz=130.8, num_updates=3900, lr=0.0004875, gnorm=1.126, train_wall=19, wall=0
2024-07-18 12:12:57 | INFO | train_inner | epoch 001:   4000 / 19564 loss=7.845, nll_loss=6.931, ppl=122.06, wps=17668.6, ups=5.18, wpb=3411.4, bsz=162.5, num_updates=4000, lr=0.0005, gnorm=1.154, train_wall=19, wall=0
2024-07-18 12:12:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:13:00 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.332 | nll_loss 7.454 | ppl 175.33 | wps 55549.9 | wpb 2872.6 | bsz 51.2 | num_updates 4000 | best_loss 12.134
2024-07-18 12:13:00 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:13:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 8.332) (writing took 4.010305131785572 seconds)
2024-07-18 12:13:23 | INFO | train_inner | epoch 001:   4100 / 19564 loss=7.89, nll_loss=6.981, ppl=126.36, wps=13322.7, ups=3.87, wpb=3438.8, bsz=128.1, num_updates=4100, lr=0.000493865, gnorm=1.068, train_wall=19, wall=0
2024-07-18 12:13:42 | INFO | train_inner | epoch 001:   4200 / 19564 loss=7.849, nll_loss=6.934, ppl=122.3, wps=17767.4, ups=5.19, wpb=3421.6, bsz=120.7, num_updates=4200, lr=0.00048795, gnorm=1.108, train_wall=19, wall=0
2024-07-18 12:14:02 | INFO | train_inner | epoch 001:   4300 / 19564 loss=7.647, nll_loss=6.704, ppl=104.27, wps=17954.2, ups=5.1, wpb=3521.3, bsz=146.3, num_updates=4300, lr=0.000482243, gnorm=1.1, train_wall=19, wall=0
2024-07-18 12:14:21 | INFO | train_inner | epoch 001:   4400 / 19564 loss=7.667, nll_loss=6.724, ppl=105.75, wps=17823.1, ups=5.15, wpb=3463.8, bsz=132.4, num_updates=4400, lr=0.000476731, gnorm=1.096, train_wall=19, wall=0
2024-07-18 12:14:41 | INFO | train_inner | epoch 001:   4500 / 19564 loss=7.604, nll_loss=6.654, ppl=100.72, wps=17234.3, ups=5.1, wpb=3381.8, bsz=139.2, num_updates=4500, lr=0.000471405, gnorm=1.122, train_wall=19, wall=0
2024-07-18 12:14:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:14:43 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.952 | nll_loss 6.993 | ppl 127.37 | wps 55644.3 | wpb 2872.6 | bsz 51.2 | num_updates 4500 | best_loss 12.134
2024-07-18 12:14:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:14:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_4500.pt (epoch 1 @ 4500 updates, score 7.952) (writing took 3.554957169108093 seconds)
2024-07-18 12:15:07 | INFO | train_inner | epoch 001:   4600 / 19564 loss=7.495, nll_loss=6.529, ppl=92.34, wps=13623.2, ups=3.9, wpb=3492.1, bsz=140.2, num_updates=4600, lr=0.000466252, gnorm=1.089, train_wall=20, wall=0
2024-07-18 12:15:26 | INFO | train_inner | epoch 001:   4700 / 19564 loss=7.467, nll_loss=6.495, ppl=90.18, wps=17375.5, ups=5.05, wpb=3438.3, bsz=140.8, num_updates=4700, lr=0.000461266, gnorm=1.142, train_wall=20, wall=0
2024-07-18 12:15:46 | INFO | train_inner | epoch 001:   4800 / 19564 loss=7.357, nll_loss=6.369, ppl=82.63, wps=17789.9, ups=5.08, wpb=3504.1, bsz=154.2, num_updates=4800, lr=0.000456435, gnorm=1.155, train_wall=20, wall=0
2024-07-18 12:16:06 | INFO | train_inner | epoch 001:   4900 / 19564 loss=7.303, nll_loss=6.305, ppl=79.05, wps=17903.6, ups=5.05, wpb=3547.3, bsz=136.9, num_updates=4900, lr=0.000451754, gnorm=1.105, train_wall=20, wall=0
2024-07-18 12:16:26 | INFO | train_inner | epoch 001:   5000 / 19564 loss=7.293, nll_loss=6.294, ppl=78.47, wps=17565, ups=5.06, wpb=3469, bsz=132.6, num_updates=5000, lr=0.000447214, gnorm=1.136, train_wall=20, wall=0
2024-07-18 12:16:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:16:28 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.714 | nll_loss 6.708 | ppl 104.54 | wps 55108.2 | wpb 2872.6 | bsz 51.2 | num_updates 5000 | best_loss 12.134
2024-07-18 12:16:28 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:16:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_5000.pt (epoch 1 @ 5000 updates, score 7.714) (writing took 6.129643677733839 seconds)
2024-07-18 12:16:54 | INFO | train_inner | epoch 001:   5100 / 19564 loss=7.287, nll_loss=6.286, ppl=78.03, wps=12393.5, ups=3.59, wpb=3455.8, bsz=127.3, num_updates=5100, lr=0.000442807, gnorm=1.131, train_wall=19, wall=0
2024-07-18 12:17:13 | INFO | train_inner | epoch 001:   5200 / 19564 loss=7.22, nll_loss=6.21, ppl=74.03, wps=17442.9, ups=5.16, wpb=3378.8, bsz=142.3, num_updates=5200, lr=0.000438529, gnorm=1.206, train_wall=19, wall=0
2024-07-18 12:17:33 | INFO | train_inner | epoch 001:   5300 / 19564 loss=6.994, nll_loss=5.949, ppl=61.79, wps=17726.7, ups=5.11, wpb=3471.3, bsz=150.4, num_updates=5300, lr=0.000434372, gnorm=1.173, train_wall=19, wall=0
2024-07-18 12:17:52 | INFO | train_inner | epoch 001:   5400 / 19564 loss=7.058, nll_loss=6.022, ppl=64.99, wps=17653.4, ups=5.14, wpb=3436, bsz=134.6, num_updates=5400, lr=0.000430331, gnorm=1.19, train_wall=19, wall=0
2024-07-18 12:18:12 | INFO | train_inner | epoch 001:   5500 / 19564 loss=7.043, nll_loss=6.004, ppl=64.19, wps=17473.8, ups=5.1, wpb=3428.4, bsz=132.5, num_updates=5500, lr=0.000426401, gnorm=1.191, train_wall=19, wall=0
2024-07-18 12:18:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:18:14 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.429 | nll_loss 6.393 | ppl 84.04 | wps 55344.5 | wpb 2872.6 | bsz 51.2 | num_updates 5500 | best_loss 12.134
2024-07-18 12:18:14 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:18:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_5500.pt (epoch 1 @ 5500 updates, score 7.429) (writing took 3.2972628232091665 seconds)
2024-07-18 12:18:37 | INFO | train_inner | epoch 001:   5600 / 19564 loss=7, nll_loss=5.955, ppl=62.02, wps=13647.7, ups=4, wpb=3415.3, bsz=149.5, num_updates=5600, lr=0.000422577, gnorm=1.25, train_wall=19, wall=0
2024-07-18 12:18:56 | INFO | train_inner | epoch 001:   5700 / 19564 loss=6.907, nll_loss=5.848, ppl=57.58, wps=18052.6, ups=5.11, wpb=3534.9, bsz=143.6, num_updates=5700, lr=0.000418854, gnorm=1.191, train_wall=19, wall=0
2024-07-18 12:19:16 | INFO | train_inner | epoch 001:   5800 / 19564 loss=6.821, nll_loss=5.748, ppl=53.76, wps=17460.9, ups=4.99, wpb=3496.3, bsz=145, num_updates=5800, lr=0.000415227, gnorm=1.17, train_wall=20, wall=0
2024-07-18 12:19:36 | INFO | train_inner | epoch 001:   5900 / 19564 loss=6.727, nll_loss=5.641, ppl=49.89, wps=17734.1, ups=5.11, wpb=3469.8, bsz=154.8, num_updates=5900, lr=0.000411693, gnorm=1.207, train_wall=19, wall=0
2024-07-18 12:19:55 | INFO | train_inner | epoch 001:   6000 / 19564 loss=6.744, nll_loss=5.659, ppl=50.52, wps=17731.9, ups=5.17, wpb=3428.1, bsz=143.4, num_updates=6000, lr=0.000408248, gnorm=1.228, train_wall=19, wall=0
2024-07-18 12:19:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:19:58 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.184 | nll_loss 6.095 | ppl 68.38 | wps 55302.1 | wpb 2872.6 | bsz 51.2 | num_updates 6000 | best_loss 12.134
2024-07-18 12:19:58 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:20:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 7.184) (writing took 4.125676239840686 seconds)
2024-07-18 12:20:21 | INFO | train_inner | epoch 001:   6100 / 19564 loss=6.584, nll_loss=5.476, ppl=44.52, wps=13306, ups=3.83, wpb=3470.6, bsz=163.8, num_updates=6100, lr=0.000404888, gnorm=1.233, train_wall=19, wall=0
2024-07-18 12:20:41 | INFO | train_inner | epoch 001:   6200 / 19564 loss=6.626, nll_loss=5.522, ppl=45.96, wps=17642.1, ups=5.12, wpb=3448.4, bsz=133.8, num_updates=6200, lr=0.00040161, gnorm=1.219, train_wall=19, wall=0
2024-07-18 12:21:01 | INFO | train_inner | epoch 001:   6300 / 19564 loss=6.518, nll_loss=5.399, ppl=42.21, wps=17176.9, ups=5.01, wpb=3427.9, bsz=147.8, num_updates=6300, lr=0.00039841, gnorm=1.242, train_wall=20, wall=0
2024-07-18 12:21:20 | INFO | train_inner | epoch 001:   6400 / 19564 loss=6.62, nll_loss=5.516, ppl=45.75, wps=17437, ups=5.17, wpb=3370.9, bsz=135, num_updates=6400, lr=0.000395285, gnorm=1.272, train_wall=19, wall=0
2024-07-18 12:21:39 | INFO | train_inner | epoch 001:   6500 / 19564 loss=6.531, nll_loss=5.414, ppl=42.63, wps=17678.2, ups=5.16, wpb=3423.7, bsz=130.3, num_updates=6500, lr=0.000392232, gnorm=1.271, train_wall=19, wall=0
2024-07-18 12:21:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:21:42 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.978 | nll_loss 5.861 | ppl 58.12 | wps 55536.3 | wpb 2872.6 | bsz 51.2 | num_updates 6500 | best_loss 12.134
2024-07-18 12:21:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:21:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_6500.pt (epoch 1 @ 6500 updates, score 6.978) (writing took 3.363183069974184 seconds)
2024-07-18 12:22:05 | INFO | train_inner | epoch 001:   6600 / 19564 loss=6.428, nll_loss=5.294, ppl=39.24, wps=13725, ups=3.97, wpb=3456.9, bsz=150.5, num_updates=6600, lr=0.000389249, gnorm=1.248, train_wall=19, wall=0
2024-07-18 12:22:24 | INFO | train_inner | epoch 001:   6700 / 19564 loss=6.334, nll_loss=5.187, ppl=36.43, wps=17759.5, ups=5.13, wpb=3460.6, bsz=146.6, num_updates=6700, lr=0.000386334, gnorm=1.228, train_wall=19, wall=0
2024-07-18 12:22:44 | INFO | train_inner | epoch 001:   6800 / 19564 loss=6.324, nll_loss=5.176, ppl=36.14, wps=17467.5, ups=5.14, wpb=3400, bsz=145.2, num_updates=6800, lr=0.000383482, gnorm=1.273, train_wall=19, wall=0
2024-07-18 12:23:03 | INFO | train_inner | epoch 001:   6900 / 19564 loss=6.34, nll_loss=5.193, ppl=36.59, wps=17999.8, ups=5.14, wpb=3501.9, bsz=132.8, num_updates=6900, lr=0.000380693, gnorm=1.248, train_wall=19, wall=0
2024-07-18 12:23:22 | INFO | train_inner | epoch 001:   7000 / 19564 loss=6.293, nll_loss=5.138, ppl=35.22, wps=17695, ups=5.18, wpb=3414.3, bsz=133, num_updates=7000, lr=0.000377964, gnorm=1.291, train_wall=19, wall=0
2024-07-18 12:23:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:23:25 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.722 | nll_loss 5.555 | ppl 47.01 | wps 55075.6 | wpb 2872.6 | bsz 51.2 | num_updates 7000 | best_loss 12.134
2024-07-18 12:23:25 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:23:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_7000.pt (epoch 1 @ 7000 updates, score 6.722) (writing took 3.5599252451211214 seconds)
2024-07-18 12:23:47 | INFO | train_inner | epoch 001:   7100 / 19564 loss=6.327, nll_loss=5.177, ppl=36.18, wps=13474.5, ups=3.98, wpb=3384.2, bsz=126.8, num_updates=7100, lr=0.000375293, gnorm=1.296, train_wall=19, wall=0
2024-07-18 12:24:07 | INFO | train_inner | epoch 001:   7200 / 19564 loss=6.236, nll_loss=5.074, ppl=33.67, wps=17702.5, ups=5.13, wpb=3453.7, bsz=132.5, num_updates=7200, lr=0.000372678, gnorm=1.287, train_wall=19, wall=0
2024-07-18 12:24:26 | INFO | train_inner | epoch 001:   7300 / 19564 loss=6.212, nll_loss=5.046, ppl=33.04, wps=17547.3, ups=5.18, wpb=3389.7, bsz=127.6, num_updates=7300, lr=0.000370117, gnorm=1.305, train_wall=19, wall=0
2024-07-18 12:24:46 | INFO | train_inner | epoch 001:   7400 / 19564 loss=6.069, nll_loss=4.882, ppl=29.49, wps=17544, ups=5.12, wpb=3429.9, bsz=143.8, num_updates=7400, lr=0.000367607, gnorm=1.277, train_wall=19, wall=0
2024-07-18 12:25:05 | INFO | train_inner | epoch 001:   7500 / 19564 loss=6.136, nll_loss=4.958, ppl=31.08, wps=17787.8, ups=5.17, wpb=3443.2, bsz=151.7, num_updates=7500, lr=0.000365148, gnorm=1.369, train_wall=19, wall=0
2024-07-18 12:25:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:25:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.569 | nll_loss 5.367 | ppl 41.28 | wps 55259.8 | wpb 2872.6 | bsz 51.2 | num_updates 7500 | best_loss 12.134
2024-07-18 12:25:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:25:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_7500.pt (epoch 1 @ 7500 updates, score 6.569) (writing took 3.9568302668631077 seconds)
2024-07-18 12:25:31 | INFO | train_inner | epoch 001:   7600 / 19564 loss=5.965, nll_loss=4.762, ppl=27.14, wps=13311, ups=3.86, wpb=3446.7, bsz=142.3, num_updates=7600, lr=0.000362738, gnorm=1.255, train_wall=19, wall=0
2024-07-18 12:25:51 | INFO | train_inner | epoch 001:   7700 / 19564 loss=6.108, nll_loss=4.926, ppl=30.4, wps=17634.4, ups=5.09, wpb=3466.6, bsz=136.2, num_updates=7700, lr=0.000360375, gnorm=1.232, train_wall=19, wall=0
2024-07-18 12:26:10 | INFO | train_inner | epoch 001:   7800 / 19564 loss=5.859, nll_loss=4.639, ppl=24.92, wps=17846.2, ups=5.11, wpb=3489.4, bsz=158.5, num_updates=7800, lr=0.000358057, gnorm=1.227, train_wall=19, wall=0
2024-07-18 12:26:30 | INFO | train_inner | epoch 001:   7900 / 19564 loss=5.894, nll_loss=4.681, ppl=25.65, wps=17479.9, ups=5.11, wpb=3422.8, bsz=147.4, num_updates=7900, lr=0.000355784, gnorm=1.3, train_wall=19, wall=0
2024-07-18 12:26:49 | INFO | train_inner | epoch 001:   8000 / 19564 loss=5.953, nll_loss=4.749, ppl=26.88, wps=17362.7, ups=5.18, wpb=3354.8, bsz=141, num_updates=8000, lr=0.000353553, gnorm=1.282, train_wall=19, wall=0
2024-07-18 12:26:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:26:52 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.366 | nll_loss 5.156 | ppl 35.65 | wps 55257.2 | wpb 2872.6 | bsz 51.2 | num_updates 8000 | best_loss 12.134
2024-07-18 12:26:52 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:26:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 6.366) (writing took 3.0933911129832268 seconds)
2024-07-18 12:27:14 | INFO | train_inner | epoch 001:   8100 / 19564 loss=5.868, nll_loss=4.651, ppl=25.12, wps=13995.1, ups=4.01, wpb=3490.7, bsz=146, num_updates=8100, lr=0.000351364, gnorm=1.233, train_wall=19, wall=0
2024-07-18 12:27:34 | INFO | train_inner | epoch 001:   8200 / 19564 loss=5.911, nll_loss=4.699, ppl=25.98, wps=17266.1, ups=5.07, wpb=3408.7, bsz=137.4, num_updates=8200, lr=0.000349215, gnorm=1.294, train_wall=20, wall=0
2024-07-18 12:27:53 | INFO | train_inner | epoch 001:   8300 / 19564 loss=5.803, nll_loss=4.576, ppl=23.85, wps=17931.7, ups=5.14, wpb=3491.9, bsz=143, num_updates=8300, lr=0.000347105, gnorm=1.216, train_wall=19, wall=0
2024-07-18 12:28:13 | INFO | train_inner | epoch 001:   8400 / 19564 loss=5.754, nll_loss=4.521, ppl=22.95, wps=18182.4, ups=5.1, wpb=3563.4, bsz=151.5, num_updates=8400, lr=0.000345033, gnorm=1.225, train_wall=19, wall=0
2024-07-18 12:28:32 | INFO | train_inner | epoch 001:   8500 / 19564 loss=5.76, nll_loss=4.527, ppl=23.06, wps=17636.2, ups=5.17, wpb=3412.6, bsz=156.9, num_updates=8500, lr=0.000342997, gnorm=1.264, train_wall=19, wall=0
2024-07-18 12:28:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:28:35 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.249 | nll_loss 5 | ppl 31.99 | wps 55546 | wpb 2872.6 | bsz 51.2 | num_updates 8500 | best_loss 12.134
2024-07-18 12:28:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:28:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_8500.pt (epoch 1 @ 8500 updates, score 6.249) (writing took 3.16229063924402 seconds)
2024-07-18 12:28:58 | INFO | train_inner | epoch 001:   8600 / 19564 loss=5.704, nll_loss=4.463, ppl=22.06, wps=13868.3, ups=3.95, wpb=3513.1, bsz=157.5, num_updates=8600, lr=0.000340997, gnorm=1.232, train_wall=20, wall=0
2024-07-18 12:29:17 | INFO | train_inner | epoch 001:   8700 / 19564 loss=5.758, nll_loss=4.525, ppl=23.02, wps=17739.1, ups=5.18, wpb=3423.1, bsz=149.6, num_updates=8700, lr=0.000339032, gnorm=1.252, train_wall=19, wall=0
2024-07-18 12:29:36 | INFO | train_inner | epoch 001:   8800 / 19564 loss=5.709, nll_loss=4.469, ppl=22.14, wps=17805.7, ups=5.12, wpb=3480, bsz=151.8, num_updates=8800, lr=0.0003371, gnorm=1.249, train_wall=19, wall=0
2024-07-18 12:29:56 | INFO | train_inner | epoch 001:   8900 / 19564 loss=5.715, nll_loss=4.475, ppl=22.24, wps=17921.7, ups=5.13, wpb=3494.8, bsz=142.5, num_updates=8900, lr=0.000335201, gnorm=1.263, train_wall=19, wall=0
2024-07-18 12:30:16 | INFO | train_inner | epoch 001:   9000 / 19564 loss=5.686, nll_loss=4.443, ppl=21.75, wps=17859.6, ups=5.11, wpb=3492.3, bsz=140.2, num_updates=9000, lr=0.000333333, gnorm=1.224, train_wall=19, wall=0
2024-07-18 12:30:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:30:18 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.155 | nll_loss 4.894 | ppl 29.73 | wps 54932.4 | wpb 2872.6 | bsz 51.2 | num_updates 9000 | best_loss 12.134
2024-07-18 12:30:18 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:30:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_9000.pt (epoch 1 @ 9000 updates, score 6.155) (writing took 3.161461455747485 seconds)
2024-07-18 12:30:40 | INFO | train_inner | epoch 001:   9100 / 19564 loss=5.778, nll_loss=4.55, ppl=23.42, wps=13535.6, ups=4.04, wpb=3348.3, bsz=146.9, num_updates=9100, lr=0.000331497, gnorm=1.291, train_wall=19, wall=0
2024-07-18 12:31:00 | INFO | train_inner | epoch 001:   9200 / 19564 loss=5.76, nll_loss=4.529, ppl=23.09, wps=17562, ups=5.18, wpb=3392.5, bsz=135.1, num_updates=9200, lr=0.00032969, gnorm=1.292, train_wall=19, wall=0
2024-07-18 12:31:19 | INFO | train_inner | epoch 001:   9300 / 19564 loss=5.708, nll_loss=4.468, ppl=22.14, wps=17697.2, ups=5.13, wpb=3446.4, bsz=133.7, num_updates=9300, lr=0.000327913, gnorm=1.243, train_wall=19, wall=0
2024-07-18 12:31:39 | INFO | train_inner | epoch 001:   9400 / 19564 loss=5.6, nll_loss=4.344, ppl=20.31, wps=17690.2, ups=5.01, wpb=3532.6, bsz=149.8, num_updates=9400, lr=0.000326164, gnorm=1.201, train_wall=20, wall=0
2024-07-18 12:31:58 | INFO | train_inner | epoch 001:   9500 / 19564 loss=5.667, nll_loss=4.422, ppl=21.43, wps=17789, ups=5.18, wpb=3431.6, bsz=127.5, num_updates=9500, lr=0.000324443, gnorm=1.246, train_wall=19, wall=0
2024-07-18 12:31:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:32:01 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.003 | nll_loss 4.719 | ppl 26.34 | wps 55362.9 | wpb 2872.6 | bsz 51.2 | num_updates 9500 | best_loss 12.134
2024-07-18 12:32:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:32:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_9500.pt (epoch 1 @ 9500 updates, score 6.003) (writing took 3.09025065228343 seconds)
2024-07-18 12:32:23 | INFO | train_inner | epoch 001:   9600 / 19564 loss=5.605, nll_loss=4.35, ppl=20.4, wps=13861, ups=4.04, wpb=3428.9, bsz=137.1, num_updates=9600, lr=0.000322749, gnorm=1.269, train_wall=19, wall=0
2024-07-18 12:32:43 | INFO | train_inner | epoch 001:   9700 / 19564 loss=5.586, nll_loss=4.329, ppl=20.1, wps=17099.3, ups=5.02, wpb=3408, bsz=147.2, num_updates=9700, lr=0.000321081, gnorm=1.271, train_wall=20, wall=0
2024-07-18 12:33:03 | INFO | train_inner | epoch 001:   9800 / 19564 loss=5.642, nll_loss=4.394, ppl=21.02, wps=17080.5, ups=5.01, wpb=3411.9, bsz=132.9, num_updates=9800, lr=0.000319438, gnorm=1.288, train_wall=20, wall=0
2024-07-18 12:33:22 | INFO | train_inner | epoch 001:   9900 / 19564 loss=5.536, nll_loss=4.271, ppl=19.31, wps=17823.3, ups=5.13, wpb=3474.1, bsz=140.2, num_updates=9900, lr=0.000317821, gnorm=1.205, train_wall=19, wall=0
2024-07-18 12:33:42 | INFO | train_inner | epoch 001:  10000 / 19564 loss=5.497, nll_loss=4.227, ppl=18.73, wps=17970, ups=5.1, wpb=3524.8, bsz=151.4, num_updates=10000, lr=0.000316228, gnorm=1.261, train_wall=19, wall=0
2024-07-18 12:33:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:33:44 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.919 | nll_loss 4.628 | ppl 24.72 | wps 55740.9 | wpb 2872.6 | bsz 51.2 | num_updates 10000 | best_loss 12.134
2024-07-18 12:33:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:33:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score 5.919) (writing took 3.205302885733545 seconds)
2024-07-18 12:33:48 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-18 12:33:48 | INFO | train | epoch 001 | loss 7.541 | nll_loss 6.586 | ppl 96.04 | wps 16192.2 | ups 4.7 | wpb 3445.6 | bsz 142.1 | num_updates 10000 | lr 0.000316228 | gnorm 1.257 | train_wall 1930 | wall 0
2024-07-18 12:33:48 | INFO | fairseq_cli.train | done training in 1865.2 seconds
2024-07-18 12:33:50 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt22.sep.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=100000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=1000, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-07-18 12:33:50 | INFO | fairseq.tasks.translation | [de] dictionary: 9968 types
2024-07-18 12:33:50 | INFO | fairseq.tasks.translation | [en] dictionary: 9968 types
2024-07-18 12:33:50 | INFO | fairseq.data.data_utils | loaded 2203 examples from: data-bin/wmt22.sep.tokenized.de-en/valid.de-en.de
2024-07-18 12:33:50 | INFO | fairseq.data.data_utils | loaded 2203 examples from: data-bin/wmt22.sep.tokenized.de-en/valid.de-en.en
2024-07-18 12:33:50 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.de-en valid de-en 2203 examples
2024-07-18 12:33:51 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9968, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9968, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=9968, bias=False)
  )
)
2024-07-18 12:33:51 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-07-18 12:33:51 | INFO | fairseq_cli.train | model: transformer_iwslt_de_en (TransformerModel)
2024-07-18 12:33:51 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-07-18 12:33:51 | INFO | fairseq_cli.train | num. model params: 41750528 (num. trained: 41750528)
2024-07-18 12:33:57 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-07-18 12:33:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-18 12:33:57 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN Xp                                
2024-07-18 12:33:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-07-18 12:33:57 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-07-18 12:33:57 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-07-18 12:33:58 | INFO | fairseq.trainer | loaded checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 10000 updates)
2024-07-18 12:33:58 | INFO | fairseq.trainer | loading train data for epoch 1
2024-07-18 12:33:58 | INFO | fairseq.data.data_utils | loaded 2782552 examples from: data-bin/wmt22.sep.tokenized.de-en/train.de-en.de
2024-07-18 12:33:58 | INFO | fairseq.data.data_utils | loaded 2782552 examples from: data-bin/wmt22.sep.tokenized.de-en/train.de-en.en
2024-07-18 12:33:58 | INFO | fairseq.tasks.translation | data-bin/wmt22.sep.tokenized.de-en train de-en 2782552 examples
2024-07-18 12:34:01 | INFO | fairseq.trainer | begin training epoch 1
2024-07-18 12:34:21 | INFO | train_inner | epoch 001:  10100 / 19564 loss=5.594, nll_loss=4.34, ppl=20.25, wps=13817.8, ups=4.04, wpb=3421.2, bsz=143.8, num_updates=10100, lr=0.000314658, gnorm=1.224, train_wall=19, wall=0
2024-07-18 12:34:40 | INFO | train_inner | epoch 001:  10200 / 19564 loss=5.522, nll_loss=4.256, ppl=19.11, wps=17868.8, ups=5.22, wpb=3420.4, bsz=132.2, num_updates=10200, lr=0.000313112, gnorm=1.234, train_wall=19, wall=0
2024-07-18 12:34:59 | INFO | train_inner | epoch 001:  10300 / 19564 loss=5.603, nll_loss=4.349, ppl=20.38, wps=17702, ups=5.12, wpb=3458.6, bsz=138.9, num_updates=10300, lr=0.000311588, gnorm=1.259, train_wall=19, wall=0
2024-07-18 12:35:19 | INFO | train_inner | epoch 001:  10400 / 19564 loss=5.484, nll_loss=4.213, ppl=18.55, wps=17755.7, ups=5.19, wpb=3423.8, bsz=141.6, num_updates=10400, lr=0.000310087, gnorm=1.222, train_wall=19, wall=0
2024-07-18 12:35:38 | INFO | train_inner | epoch 001:  10500 / 19564 loss=5.569, nll_loss=4.311, ppl=19.85, wps=17611.5, ups=5.24, wpb=3359.4, bsz=142.2, num_updates=10500, lr=0.000308607, gnorm=1.265, train_wall=19, wall=0
2024-07-18 12:35:57 | INFO | train_inner | epoch 001:  10600 / 19564 loss=5.448, nll_loss=4.173, ppl=18.04, wps=17717, ups=5.13, wpb=3451.5, bsz=151, num_updates=10600, lr=0.000307148, gnorm=1.217, train_wall=19, wall=0
2024-07-18 12:36:17 | INFO | train_inner | epoch 001:  10700 / 19564 loss=5.495, nll_loss=4.226, ppl=18.72, wps=17579.5, ups=5.15, wpb=3416.7, bsz=133.4, num_updates=10700, lr=0.000305709, gnorm=1.258, train_wall=19, wall=0
2024-07-18 12:36:36 | INFO | train_inner | epoch 001:  10800 / 19564 loss=5.465, nll_loss=4.191, ppl=18.27, wps=17710.6, ups=5.17, wpb=3428.5, bsz=119.5, num_updates=10800, lr=0.00030429, gnorm=1.228, train_wall=19, wall=0
2024-07-18 12:36:56 | INFO | train_inner | epoch 001:  10900 / 19564 loss=5.359, nll_loss=4.069, ppl=16.79, wps=17507.3, ups=5, wpb=3500.4, bsz=150, num_updates=10900, lr=0.000302891, gnorm=1.206, train_wall=20, wall=0
2024-07-18 12:37:15 | INFO | train_inner | epoch 001:  11000 / 19564 loss=5.488, nll_loss=4.219, ppl=18.63, wps=18006.6, ups=5.24, wpb=3438.7, bsz=141.5, num_updates=11000, lr=0.000301511, gnorm=1.279, train_wall=19, wall=0
2024-07-18 12:37:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
/local/home/ggabriel/ma/alti/fairseq/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-07-18 12:37:17 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.793 | nll_loss 4.474 | ppl 22.22 | wps 55182.4 | wpb 2872.6 | bsz 51.2 | num_updates 11000 | best_loss 12.134
2024-07-18 12:37:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:37:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_11000.pt (epoch 1 @ 11000 updates, score 5.793) (writing took 3.998345489613712 seconds)
2024-07-18 12:37:41 | INFO | train_inner | epoch 001:  11100 / 19564 loss=5.379, nll_loss=4.094, ppl=17.07, wps=13475.4, ups=3.88, wpb=3470.3, bsz=144.4, num_updates=11100, lr=0.00030015, gnorm=1.237, train_wall=19, wall=0
2024-07-18 12:38:00 | INFO | train_inner | epoch 001:  11200 / 19564 loss=5.365, nll_loss=4.079, ppl=16.9, wps=17873.7, ups=5.18, wpb=3453.6, bsz=150, num_updates=11200, lr=0.000298807, gnorm=1.211, train_wall=19, wall=0
2024-07-18 12:38:19 | INFO | train_inner | epoch 001:  11300 / 19564 loss=5.358, nll_loss=4.07, ppl=16.79, wps=17926.3, ups=5.17, wpb=3469.5, bsz=148.2, num_updates=11300, lr=0.000297482, gnorm=1.224, train_wall=19, wall=0
2024-07-18 12:38:39 | INFO | train_inner | epoch 001:  11400 / 19564 loss=5.393, nll_loss=4.111, ppl=17.28, wps=18180.8, ups=5.16, wpb=3521.4, bsz=151.4, num_updates=11400, lr=0.000296174, gnorm=1.182, train_wall=19, wall=0
2024-07-18 12:38:58 | INFO | train_inner | epoch 001:  11500 / 19564 loss=5.421, nll_loss=4.144, ppl=17.68, wps=17986.8, ups=5.2, wpb=3456, bsz=138.8, num_updates=11500, lr=0.000294884, gnorm=1.234, train_wall=19, wall=0
2024-07-18 12:39:17 | INFO | train_inner | epoch 001:  11600 / 19564 loss=5.353, nll_loss=4.065, ppl=16.74, wps=18073.9, ups=5.26, wpb=3437.1, bsz=130.8, num_updates=11600, lr=0.00029361, gnorm=1.212, train_wall=19, wall=0
2024-07-18 12:39:37 | INFO | train_inner | epoch 001:  11700 / 19564 loss=5.36, nll_loss=4.073, ppl=16.83, wps=17728.3, ups=5.12, wpb=3463, bsz=147.7, num_updates=11700, lr=0.000292353, gnorm=1.235, train_wall=19, wall=0
2024-07-18 12:39:56 | INFO | train_inner | epoch 001:  11800 / 19564 loss=5.296, nll_loss=3.999, ppl=15.99, wps=17932.2, ups=5.09, wpb=3524.3, bsz=144.2, num_updates=11800, lr=0.000291111, gnorm=1.166, train_wall=19, wall=0
2024-07-18 12:40:16 | INFO | train_inner | epoch 001:  11900 / 19564 loss=5.327, nll_loss=4.037, ppl=16.42, wps=17993.3, ups=5.16, wpb=3485.5, bsz=150.2, num_updates=11900, lr=0.000289886, gnorm=1.202, train_wall=19, wall=0
2024-07-18 12:40:35 | INFO | train_inner | epoch 001:  12000 / 19564 loss=5.35, nll_loss=4.063, ppl=16.71, wps=18052, ups=5.17, wpb=3494.6, bsz=148.8, num_updates=12000, lr=0.000288675, gnorm=1.201, train_wall=19, wall=0
2024-07-18 12:40:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:40:37 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.597 | nll_loss 4.254 | ppl 19.08 | wps 55615.7 | wpb 2872.6 | bsz 51.2 | num_updates 12000 | best_loss 12.134
2024-07-18 12:40:37 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:40:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_12000.pt (epoch 1 @ 12000 updates, score 5.597) (writing took 4.083747954107821 seconds)
2024-07-18 12:41:01 | INFO | train_inner | epoch 001:  12100 / 19564 loss=5.287, nll_loss=3.99, ppl=15.89, wps=13301.2, ups=3.87, wpb=3435.5, bsz=139.9, num_updates=12100, lr=0.00028748, gnorm=1.194, train_wall=19, wall=0
2024-07-18 12:41:20 | INFO | train_inner | epoch 001:  12200 / 19564 loss=5.296, nll_loss=4, ppl=16, wps=17853.7, ups=5.15, wpb=3464.2, bsz=141.9, num_updates=12200, lr=0.000286299, gnorm=1.195, train_wall=19, wall=0
2024-07-18 12:41:40 | INFO | train_inner | epoch 001:  12300 / 19564 loss=5.241, nll_loss=3.938, ppl=15.32, wps=18143.5, ups=5.11, wpb=3548.5, bsz=162.3, num_updates=12300, lr=0.000285133, gnorm=1.172, train_wall=19, wall=0
2024-07-18 12:41:59 | INFO | train_inner | epoch 001:  12400 / 19564 loss=5.249, nll_loss=3.948, ppl=15.44, wps=17850.6, ups=5.16, wpb=3461.2, bsz=140.4, num_updates=12400, lr=0.000283981, gnorm=1.181, train_wall=19, wall=0
2024-07-18 12:42:18 | INFO | train_inner | epoch 001:  12500 / 19564 loss=5.259, nll_loss=3.96, ppl=15.56, wps=17911.6, ups=5.19, wpb=3453.3, bsz=160.8, num_updates=12500, lr=0.000282843, gnorm=1.189, train_wall=19, wall=0
2024-07-18 12:42:38 | INFO | train_inner | epoch 001:  12600 / 19564 loss=5.223, nll_loss=3.919, ppl=15.13, wps=18039.3, ups=5.17, wpb=3489.3, bsz=153.6, num_updates=12600, lr=0.000281718, gnorm=1.18, train_wall=19, wall=0
2024-07-18 12:42:57 | INFO | train_inner | epoch 001:  12700 / 19564 loss=5.241, nll_loss=3.941, ppl=15.35, wps=17502.3, ups=5.21, wpb=3360.9, bsz=152.8, num_updates=12700, lr=0.000280607, gnorm=1.262, train_wall=19, wall=0
2024-07-18 12:43:16 | INFO | train_inner | epoch 001:  12800 / 19564 loss=5.251, nll_loss=3.95, ppl=15.46, wps=17716.6, ups=5.13, wpb=3451.1, bsz=159.3, num_updates=12800, lr=0.000279508, gnorm=1.225, train_wall=19, wall=0
2024-07-18 12:43:36 | INFO | train_inner | epoch 001:  12900 / 19564 loss=5.232, nll_loss=3.93, ppl=15.24, wps=17754.1, ups=5.2, wpb=3414.2, bsz=157, num_updates=12900, lr=0.000278423, gnorm=1.201, train_wall=19, wall=0
2024-07-18 12:43:55 | INFO | train_inner | epoch 001:  13000 / 19564 loss=5.284, nll_loss=3.989, ppl=15.87, wps=17666.3, ups=5.18, wpb=3409.3, bsz=130.8, num_updates=13000, lr=0.00027735, gnorm=1.195, train_wall=19, wall=0
2024-07-18 12:43:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:43:57 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.52 | nll_loss 4.166 | ppl 17.95 | wps 54085.3 | wpb 2872.6 | bsz 51.2 | num_updates 13000 | best_loss 12.134
2024-07-18 12:43:57 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:44:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_13000.pt (epoch 1 @ 13000 updates, score 5.52) (writing took 3.128091448917985 seconds)
2024-07-18 12:44:20 | INFO | train_inner | epoch 001:  13100 / 19564 loss=5.206, nll_loss=3.9, ppl=14.93, wps=13500.7, ups=3.96, wpb=3410.9, bsz=141, num_updates=13100, lr=0.000276289, gnorm=1.207, train_wall=20, wall=0
2024-07-18 12:44:40 | INFO | train_inner | epoch 001:  13200 / 19564 loss=5.166, nll_loss=3.853, ppl=14.45, wps=17981.7, ups=5.09, wpb=3531.6, bsz=147.7, num_updates=13200, lr=0.000275241, gnorm=1.184, train_wall=19, wall=0
2024-07-18 12:44:59 | INFO | train_inner | epoch 001:  13300 / 19564 loss=5.144, nll_loss=3.829, ppl=14.21, wps=17795.5, ups=5.14, wpb=3462.9, bsz=159.8, num_updates=13300, lr=0.000274204, gnorm=1.198, train_wall=19, wall=0
2024-07-18 12:45:19 | INFO | train_inner | epoch 001:  13400 / 19564 loss=5.269, nll_loss=3.972, ppl=15.7, wps=17739.1, ups=5.17, wpb=3427.9, bsz=127.6, num_updates=13400, lr=0.000273179, gnorm=1.216, train_wall=19, wall=0
2024-07-18 12:45:38 | INFO | train_inner | epoch 001:  13500 / 19564 loss=5.173, nll_loss=3.863, ppl=14.55, wps=17773.2, ups=5.19, wpb=3426.7, bsz=153.8, num_updates=13500, lr=0.000272166, gnorm=1.206, train_wall=19, wall=0
2024-07-18 12:45:57 | INFO | train_inner | epoch 001:  13600 / 19564 loss=5.264, nll_loss=3.969, ppl=15.66, wps=17351.8, ups=5.21, wpb=3327.7, bsz=148.2, num_updates=13600, lr=0.000271163, gnorm=1.246, train_wall=19, wall=0
2024-07-18 12:46:16 | INFO | train_inner | epoch 001:  13700 / 19564 loss=5.243, nll_loss=3.943, ppl=15.38, wps=17878.8, ups=5.2, wpb=3440.5, bsz=135.8, num_updates=13700, lr=0.000270172, gnorm=1.218, train_wall=19, wall=0
2024-07-18 12:46:36 | INFO | train_inner | epoch 001:  13800 / 19564 loss=5.225, nll_loss=3.922, ppl=15.16, wps=17816.1, ups=5.19, wpb=3433.5, bsz=140.6, num_updates=13800, lr=0.000269191, gnorm=1.221, train_wall=19, wall=0
2024-07-18 12:46:55 | INFO | train_inner | epoch 001:  13900 / 19564 loss=5.167, nll_loss=3.857, ppl=14.49, wps=17263, ups=5.08, wpb=3395.4, bsz=147, num_updates=13900, lr=0.000268221, gnorm=1.205, train_wall=19, wall=0
2024-07-18 12:47:15 | INFO | train_inner | epoch 001:  14000 / 19564 loss=5.228, nll_loss=3.927, ppl=15.21, wps=17822, ups=5.19, wpb=3434.8, bsz=143.6, num_updates=14000, lr=0.000267261, gnorm=1.199, train_wall=19, wall=0
2024-07-18 12:47:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:47:17 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.455 | nll_loss 4.089 | ppl 17.02 | wps 55011.9 | wpb 2872.6 | bsz 51.2 | num_updates 14000 | best_loss 12.134
2024-07-18 12:47:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:47:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_14000.pt (epoch 1 @ 14000 updates, score 5.455) (writing took 3.5821014810353518 seconds)
2024-07-18 12:47:40 | INFO | train_inner | epoch 001:  14100 / 19564 loss=5.198, nll_loss=3.892, ppl=14.84, wps=13683.5, ups=3.95, wpb=3462, bsz=135.2, num_updates=14100, lr=0.000266312, gnorm=1.197, train_wall=19, wall=0
2024-07-18 12:47:59 | INFO | train_inner | epoch 001:  14200 / 19564 loss=5.182, nll_loss=3.874, ppl=14.67, wps=17958.3, ups=5.18, wpb=3464.1, bsz=145.9, num_updates=14200, lr=0.000265372, gnorm=1.235, train_wall=19, wall=0
2024-07-18 12:48:19 | INFO | train_inner | epoch 001:  14300 / 19564 loss=5.151, nll_loss=3.838, ppl=14.3, wps=17333.3, ups=5.15, wpb=3368, bsz=141.1, num_updates=14300, lr=0.000264443, gnorm=1.236, train_wall=19, wall=0
2024-07-18 12:48:38 | INFO | train_inner | epoch 001:  14400 / 19564 loss=5.146, nll_loss=3.833, ppl=14.25, wps=17413.5, ups=5.07, wpb=3437.4, bsz=144.2, num_updates=14400, lr=0.000263523, gnorm=1.159, train_wall=20, wall=0
2024-07-18 12:48:58 | INFO | train_inner | epoch 001:  14500 / 19564 loss=5.155, nll_loss=3.844, ppl=14.36, wps=17782.8, ups=5.22, wpb=3408.2, bsz=142.5, num_updates=14500, lr=0.000262613, gnorm=1.187, train_wall=19, wall=0
2024-07-18 12:49:16 | INFO | train_inner | epoch 001:  14600 / 19564 loss=5.21, nll_loss=3.906, ppl=14.99, wps=18065.4, ups=5.28, wpb=3421.9, bsz=131.1, num_updates=14600, lr=0.000261712, gnorm=1.207, train_wall=19, wall=0
2024-07-18 12:49:36 | INFO | train_inner | epoch 001:  14700 / 19564 loss=5.162, nll_loss=3.852, ppl=14.44, wps=17702.3, ups=5.18, wpb=3415.7, bsz=134.3, num_updates=14700, lr=0.00026082, gnorm=1.208, train_wall=19, wall=0
2024-07-18 12:49:55 | INFO | train_inner | epoch 001:  14800 / 19564 loss=5.061, nll_loss=3.737, ppl=13.34, wps=17890.3, ups=5.16, wpb=3463.8, bsz=158.6, num_updates=14800, lr=0.000259938, gnorm=1.151, train_wall=19, wall=0
2024-07-18 12:50:15 | INFO | train_inner | epoch 001:  14900 / 19564 loss=5.076, nll_loss=3.753, ppl=13.48, wps=17588.5, ups=5.15, wpb=3414.4, bsz=142.2, num_updates=14900, lr=0.000259064, gnorm=1.159, train_wall=19, wall=0
2024-07-18 12:50:34 | INFO | train_inner | epoch 001:  15000 / 19564 loss=5.124, nll_loss=3.807, ppl=14, wps=17950.5, ups=5.1, wpb=3517.2, bsz=141.4, num_updates=15000, lr=0.000258199, gnorm=1.179, train_wall=19, wall=0
2024-07-18 12:50:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:50:36 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.332 | nll_loss 3.944 | ppl 15.39 | wps 55373 | wpb 2872.6 | bsz 51.2 | num_updates 15000 | best_loss 12.134
2024-07-18 12:50:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:50:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_15000.pt (epoch 1 @ 15000 updates, score 5.332) (writing took 3.8132872926071286 seconds)
2024-07-18 12:51:00 | INFO | train_inner | epoch 001:  15100 / 19564 loss=5.112, nll_loss=3.795, ppl=13.88, wps=13362.4, ups=3.92, wpb=3408.4, bsz=155.4, num_updates=15100, lr=0.000257343, gnorm=1.183, train_wall=19, wall=0
2024-07-18 12:51:19 | INFO | train_inner | epoch 001:  15200 / 19564 loss=5.223, nll_loss=3.923, ppl=15.16, wps=17764, ups=5.19, wpb=3421.7, bsz=131.3, num_updates=15200, lr=0.000256495, gnorm=1.229, train_wall=19, wall=0
2024-07-18 12:51:38 | INFO | train_inner | epoch 001:  15300 / 19564 loss=5.16, nll_loss=3.849, ppl=14.41, wps=18064.1, ups=5.16, wpb=3502.3, bsz=130.8, num_updates=15300, lr=0.000255655, gnorm=1.176, train_wall=19, wall=0
2024-07-18 12:51:58 | INFO | train_inner | epoch 001:  15400 / 19564 loss=5.012, nll_loss=3.681, ppl=12.83, wps=18103.8, ups=5.16, wpb=3511.8, bsz=175.4, num_updates=15400, lr=0.000254824, gnorm=1.149, train_wall=19, wall=0
2024-07-18 12:52:17 | INFO | train_inner | epoch 001:  15500 / 19564 loss=5.081, nll_loss=3.76, ppl=13.55, wps=17943.1, ups=5.15, wpb=3481.9, bsz=152.6, num_updates=15500, lr=0.000254, gnorm=1.189, train_wall=19, wall=0
2024-07-18 12:52:37 | INFO | train_inner | epoch 001:  15600 / 19564 loss=5.097, nll_loss=3.779, ppl=13.72, wps=18346, ups=5.15, wpb=3562.3, bsz=141.1, num_updates=15600, lr=0.000253185, gnorm=1.15, train_wall=19, wall=0
2024-07-18 12:52:56 | INFO | train_inner | epoch 001:  15700 / 19564 loss=5.101, nll_loss=3.783, ppl=13.77, wps=17722.2, ups=5.09, wpb=3484.5, bsz=141, num_updates=15700, lr=0.000252377, gnorm=1.191, train_wall=19, wall=0
2024-07-18 12:53:16 | INFO | train_inner | epoch 001:  15800 / 19564 loss=5.092, nll_loss=3.773, ppl=13.67, wps=17960.6, ups=5.15, wpb=3485, bsz=128.7, num_updates=15800, lr=0.000251577, gnorm=1.181, train_wall=19, wall=0
2024-07-18 12:53:35 | INFO | train_inner | epoch 001:  15900 / 19564 loss=5.087, nll_loss=3.768, ppl=13.62, wps=17888.2, ups=5.15, wpb=3476.8, bsz=148.9, num_updates=15900, lr=0.000250785, gnorm=1.167, train_wall=19, wall=0
2024-07-18 12:53:55 | INFO | train_inner | epoch 001:  16000 / 19564 loss=5.01, nll_loss=3.679, ppl=12.81, wps=17761.5, ups=5.09, wpb=3487.4, bsz=147.9, num_updates=16000, lr=0.00025, gnorm=1.15, train_wall=19, wall=0
2024-07-18 12:53:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:53:57 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.242 | nll_loss 3.852 | ppl 14.44 | wps 54774.4 | wpb 2872.6 | bsz 51.2 | num_updates 16000 | best_loss 12.134
2024-07-18 12:53:57 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:54:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_16000.pt (epoch 1 @ 16000 updates, score 5.242) (writing took 3.403607629239559 seconds)
2024-07-18 12:54:20 | INFO | train_inner | epoch 001:  16100 / 19564 loss=5.056, nll_loss=3.731, ppl=13.28, wps=13530.2, ups=3.92, wpb=3450.6, bsz=126.9, num_updates=16100, lr=0.000249222, gnorm=1.177, train_wall=20, wall=0
2024-07-18 12:54:40 | INFO | train_inner | epoch 001:  16200 / 19564 loss=5.045, nll_loss=3.721, ppl=13.18, wps=17732, ups=5.14, wpb=3448.8, bsz=154.6, num_updates=16200, lr=0.000248452, gnorm=1.172, train_wall=19, wall=0
2024-07-18 12:54:59 | INFO | train_inner | epoch 001:  16300 / 19564 loss=5.136, nll_loss=3.825, ppl=14.17, wps=17871.7, ups=5.13, wpb=3483.6, bsz=140.9, num_updates=16300, lr=0.000247689, gnorm=1.21, train_wall=19, wall=0
2024-07-18 12:55:19 | INFO | train_inner | epoch 001:  16400 / 19564 loss=5.074, nll_loss=3.754, ppl=13.49, wps=17280.1, ups=5.06, wpb=3412.8, bsz=134, num_updates=16400, lr=0.000246932, gnorm=1.181, train_wall=20, wall=0
2024-07-18 12:55:38 | INFO | train_inner | epoch 001:  16500 / 19564 loss=5.05, nll_loss=3.726, ppl=13.23, wps=17585.3, ups=5.18, wpb=3397.6, bsz=150.4, num_updates=16500, lr=0.000246183, gnorm=1.187, train_wall=19, wall=0
2024-07-18 12:55:57 | INFO | train_inner | epoch 001:  16600 / 19564 loss=5.108, nll_loss=3.792, ppl=13.85, wps=17622.9, ups=5.2, wpb=3391.8, bsz=132.5, num_updates=16600, lr=0.00024544, gnorm=1.208, train_wall=19, wall=0
2024-07-18 12:56:17 | INFO | train_inner | epoch 001:  16700 / 19564 loss=5.052, nll_loss=3.728, ppl=13.25, wps=17905.5, ups=5.2, wpb=3444.4, bsz=140, num_updates=16700, lr=0.000244704, gnorm=1.177, train_wall=19, wall=0
2024-07-18 12:56:36 | INFO | train_inner | epoch 001:  16800 / 19564 loss=5.099, nll_loss=3.782, ppl=13.75, wps=17984.2, ups=5.2, wpb=3455.5, bsz=145, num_updates=16800, lr=0.000243975, gnorm=1.193, train_wall=19, wall=0
2024-07-18 12:56:55 | INFO | train_inner | epoch 001:  16900 / 19564 loss=5.072, nll_loss=3.751, ppl=13.46, wps=17720.4, ups=5.17, wpb=3430.1, bsz=132.7, num_updates=16900, lr=0.000243252, gnorm=1.179, train_wall=19, wall=0
2024-07-18 12:57:15 | INFO | train_inner | epoch 001:  17000 / 19564 loss=5.101, nll_loss=3.785, ppl=13.78, wps=17689.8, ups=5.15, wpb=3437.6, bsz=127, num_updates=17000, lr=0.000242536, gnorm=1.193, train_wall=19, wall=0
2024-07-18 12:57:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 12:57:17 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.184 | nll_loss 3.783 | ppl 13.77 | wps 55136.5 | wpb 2872.6 | bsz 51.2 | num_updates 17000 | best_loss 12.134
2024-07-18 12:57:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 12:57:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_17000.pt (epoch 1 @ 17000 updates, score 5.184) (writing took 3.4833313450217247 seconds)
2024-07-18 12:57:40 | INFO | train_inner | epoch 001:  17100 / 19564 loss=5.045, nll_loss=3.721, ppl=13.18, wps=13557, ups=3.95, wpb=3434.7, bsz=133.3, num_updates=17100, lr=0.000241825, gnorm=1.179, train_wall=19, wall=0
2024-07-18 12:57:59 | INFO | train_inner | epoch 001:  17200 / 19564 loss=5.053, nll_loss=3.729, ppl=13.26, wps=17766.2, ups=5.14, wpb=3458.5, bsz=132.9, num_updates=17200, lr=0.000241121, gnorm=1.179, train_wall=19, wall=0
2024-07-18 12:58:19 | INFO | train_inner | epoch 001:  17300 / 19564 loss=4.959, nll_loss=3.623, ppl=12.32, wps=17719.5, ups=5.14, wpb=3444.1, bsz=152.3, num_updates=17300, lr=0.000240424, gnorm=1.179, train_wall=19, wall=0
2024-07-18 12:58:38 | INFO | train_inner | epoch 001:  17400 / 19564 loss=5.088, nll_loss=3.772, ppl=13.66, wps=17678, ups=5.18, wpb=3410.9, bsz=137.8, num_updates=17400, lr=0.000239732, gnorm=1.21, train_wall=19, wall=0
2024-07-18 12:58:58 | INFO | train_inner | epoch 001:  17500 / 19564 loss=4.981, nll_loss=3.647, ppl=12.53, wps=17588.6, ups=5.03, wpb=3494.8, bsz=131.4, num_updates=17500, lr=0.000239046, gnorm=1.157, train_wall=20, wall=0
2024-07-18 12:59:18 | INFO | train_inner | epoch 001:  17600 / 19564 loss=5.005, nll_loss=3.675, ppl=12.77, wps=17502.6, ups=5.12, wpb=3417.2, bsz=129.8, num_updates=17600, lr=0.000238366, gnorm=1.185, train_wall=19, wall=0
2024-07-18 12:59:37 | INFO | train_inner | epoch 001:  17700 / 19564 loss=5.034, nll_loss=3.708, ppl=13.06, wps=17879, ups=5.11, wpb=3497.3, bsz=120.3, num_updates=17700, lr=0.000237691, gnorm=1.179, train_wall=19, wall=0
2024-07-18 12:59:57 | INFO | train_inner | epoch 001:  17800 / 19564 loss=4.992, nll_loss=3.661, ppl=12.65, wps=17348.3, ups=5.1, wpb=3402, bsz=145.8, num_updates=17800, lr=0.000237023, gnorm=1.179, train_wall=19, wall=0
2024-07-18 13:00:16 | INFO | train_inner | epoch 001:  17900 / 19564 loss=5.044, nll_loss=3.719, ppl=13.17, wps=17827, ups=5.1, wpb=3494.1, bsz=117.6, num_updates=17900, lr=0.00023636, gnorm=1.196, train_wall=19, wall=0
2024-07-18 13:00:36 | INFO | train_inner | epoch 001:  18000 / 19564 loss=4.952, nll_loss=3.616, ppl=12.26, wps=17432.2, ups=5.09, wpb=3425.4, bsz=139, num_updates=18000, lr=0.000235702, gnorm=1.162, train_wall=19, wall=0
2024-07-18 13:00:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:00:38 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.135 | nll_loss 3.728 | ppl 13.25 | wps 54767.3 | wpb 2872.6 | bsz 51.2 | num_updates 18000 | best_loss 12.134
2024-07-18 13:00:38 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:00:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_18000.pt (epoch 1 @ 18000 updates, score 5.135) (writing took 3.554361338727176 seconds)
2024-07-18 13:01:02 | INFO | train_inner | epoch 001:  18100 / 19564 loss=4.976, nll_loss=3.643, ppl=12.49, wps=13149.9, ups=3.86, wpb=3406.9, bsz=134.6, num_updates=18100, lr=0.00023505, gnorm=1.153, train_wall=20, wall=0
2024-07-18 13:01:21 | INFO | train_inner | epoch 001:  18200 / 19564 loss=4.972, nll_loss=3.639, ppl=12.46, wps=17629.7, ups=5.14, wpb=3432.7, bsz=146.2, num_updates=18200, lr=0.000234404, gnorm=1.18, train_wall=19, wall=0
2024-07-18 13:01:41 | INFO | train_inner | epoch 001:  18300 / 19564 loss=4.981, nll_loss=3.65, ppl=12.56, wps=17490.3, ups=5.06, wpb=3459.8, bsz=149.4, num_updates=18300, lr=0.000233762, gnorm=1.171, train_wall=20, wall=0
2024-07-18 13:02:01 | INFO | train_inner | epoch 001:  18400 / 19564 loss=4.902, nll_loss=3.56, ppl=11.8, wps=17615.9, ups=5.13, wpb=3431.9, bsz=155.1, num_updates=18400, lr=0.000233126, gnorm=1.156, train_wall=19, wall=0
2024-07-18 13:02:20 | INFO | train_inner | epoch 001:  18500 / 19564 loss=4.94, nll_loss=3.603, ppl=12.15, wps=17655.5, ups=5.14, wpb=3431.9, bsz=141.4, num_updates=18500, lr=0.000232495, gnorm=1.226, train_wall=19, wall=0
2024-07-18 13:02:40 | INFO | train_inner | epoch 001:  18600 / 19564 loss=4.971, nll_loss=3.64, ppl=12.46, wps=17345.3, ups=5.07, wpb=3424.4, bsz=150.3, num_updates=18600, lr=0.000231869, gnorm=1.193, train_wall=20, wall=0
2024-07-18 13:02:59 | INFO | train_inner | epoch 001:  18700 / 19564 loss=4.994, nll_loss=3.666, ppl=12.69, wps=17692, ups=5.13, wpb=3450.1, bsz=137.8, num_updates=18700, lr=0.000231249, gnorm=1.171, train_wall=19, wall=0
2024-07-18 13:03:19 | INFO | train_inner | epoch 001:  18800 / 19564 loss=4.971, nll_loss=3.639, ppl=12.46, wps=17499.8, ups=5.06, wpb=3455.8, bsz=142.8, num_updates=18800, lr=0.000230633, gnorm=1.179, train_wall=20, wall=0
2024-07-18 13:03:39 | INFO | train_inner | epoch 001:  18900 / 19564 loss=4.938, nll_loss=3.6, ppl=12.12, wps=17959.2, ups=5.12, wpb=3506.6, bsz=139.9, num_updates=18900, lr=0.000230022, gnorm=1.156, train_wall=19, wall=0
2024-07-18 13:03:58 | INFO | train_inner | epoch 001:  19000 / 19564 loss=4.916, nll_loss=3.576, ppl=11.92, wps=17803.7, ups=5.07, wpb=3510.8, bsz=135.3, num_updates=19000, lr=0.000229416, gnorm=1.145, train_wall=20, wall=0
2024-07-18 13:03:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:04:01 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.094 | nll_loss 3.678 | ppl 12.8 | wps 54583.5 | wpb 2872.6 | bsz 51.2 | num_updates 19000 | best_loss 12.134
2024-07-18 13:04:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:04:05 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_1_19000.pt (epoch 1 @ 19000 updates, score 5.094) (writing took 3.845261247828603 seconds)
2024-07-18 13:04:24 | INFO | train_inner | epoch 001:  19100 / 19564 loss=4.953, nll_loss=3.618, ppl=12.28, wps=13399, ups=3.91, wpb=3430.4, bsz=133, num_updates=19100, lr=0.000228814, gnorm=1.206, train_wall=19, wall=0
2024-07-18 13:04:43 | INFO | train_inner | epoch 001:  19200 / 19564 loss=4.932, nll_loss=3.595, ppl=12.08, wps=17416.1, ups=5.13, wpb=3393.7, bsz=143.4, num_updates=19200, lr=0.000228218, gnorm=1.194, train_wall=19, wall=0
2024-07-18 13:05:03 | INFO | train_inner | epoch 001:  19300 / 19564 loss=4.913, nll_loss=3.573, ppl=11.9, wps=17563.4, ups=5.17, wpb=3398.8, bsz=145.8, num_updates=19300, lr=0.000227626, gnorm=1.188, train_wall=19, wall=0
2024-07-18 13:05:22 | INFO | train_inner | epoch 001:  19400 / 19564 loss=4.938, nll_loss=3.602, ppl=12.14, wps=17940.3, ups=5.14, wpb=3488.3, bsz=148, num_updates=19400, lr=0.000227038, gnorm=1.155, train_wall=19, wall=0
2024-07-18 13:05:42 | INFO | train_inner | epoch 001:  19500 / 19564 loss=4.94, nll_loss=3.603, ppl=12.15, wps=17536.4, ups=5.12, wpb=3423.1, bsz=132.8, num_updates=19500, lr=0.000226455, gnorm=1.189, train_wall=19, wall=0
2024-07-18 13:05:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:05:56 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.077 | nll_loss 3.654 | ppl 12.59 | wps 54828 | wpb 2872.6 | bsz 51.2 | num_updates 19564 | best_loss 12.134
2024-07-18 13:05:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:05:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 19564 updates, score 5.077) (writing took 2.7146322829648852 seconds)
2024-07-18 13:05:59 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-07-18 13:05:59 | INFO | train | epoch 001 | loss 6.38 | nll_loss 5.251 | ppl 38.08 | wps 16666.3 | ups 4.84 | wpb 3446.5 | bsz 142.2 | num_updates 19564 | lr 0.000226085 | gnorm 1.227 | train_wall 3772 | wall 0
2024-07-18 13:05:59 | INFO | fairseq.trainer | begin training epoch 2
2024-07-18 13:06:06 | INFO | train_inner | epoch 002:     36 / 19564 loss=4.998, nll_loss=3.671, ppl=12.74, wps=13697.4, ups=4.07, wpb=3368.4, bsz=135.8, num_updates=19600, lr=0.000225877, gnorm=1.189, train_wall=19, wall=0
2024-07-18 13:06:26 | INFO | train_inner | epoch 002:    136 / 19564 loss=4.874, nll_loss=3.528, ppl=11.54, wps=18033.8, ups=5.1, wpb=3538.6, bsz=150.3, num_updates=19700, lr=0.000225303, gnorm=1.142, train_wall=19, wall=0
2024-07-18 13:06:45 | INFO | train_inner | epoch 002:    236 / 19564 loss=4.932, nll_loss=3.596, ppl=12.09, wps=17517.8, ups=5.16, wpb=3394.6, bsz=148.8, num_updates=19800, lr=0.000224733, gnorm=1.216, train_wall=19, wall=0
2024-07-18 13:07:05 | INFO | train_inner | epoch 002:    336 / 19564 loss=4.888, nll_loss=3.545, ppl=11.67, wps=17622, ups=5.04, wpb=3495.1, bsz=158.8, num_updates=19900, lr=0.000224168, gnorm=1.141, train_wall=20, wall=0
2024-07-18 13:07:25 | INFO | train_inner | epoch 002:    436 / 19564 loss=4.862, nll_loss=3.515, ppl=11.43, wps=17574.8, ups=5.13, wpb=3427.3, bsz=150.8, num_updates=20000, lr=0.000223607, gnorm=1.176, train_wall=19, wall=0
2024-07-18 13:07:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:07:27 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 5.064 | nll_loss 3.644 | ppl 12.5 | wps 55255.3 | wpb 2872.6 | bsz 51.2 | num_updates 20000 | best_loss 12.134
2024-07-18 13:07:27 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:07:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_20000.pt (epoch 2 @ 20000 updates, score 5.064) (writing took 3.7889420920982957 seconds)
2024-07-18 13:07:50 | INFO | train_inner | epoch 002:    536 / 19564 loss=4.832, nll_loss=3.482, ppl=11.17, wps=13075, ups=3.89, wpb=3362.9, bsz=145.2, num_updates=20100, lr=0.00022305, gnorm=1.16, train_wall=19, wall=0
2024-07-18 13:08:10 | INFO | train_inner | epoch 002:    636 / 19564 loss=4.941, nll_loss=3.604, ppl=12.16, wps=17701.3, ups=5.18, wpb=3417.4, bsz=120.5, num_updates=20200, lr=0.000222497, gnorm=1.18, train_wall=19, wall=0
2024-07-18 13:08:29 | INFO | train_inner | epoch 002:    736 / 19564 loss=4.756, nll_loss=3.395, ppl=10.52, wps=17616.8, ups=5.15, wpb=3420.6, bsz=163.4, num_updates=20300, lr=0.000221948, gnorm=1.153, train_wall=19, wall=0
2024-07-18 13:08:49 | INFO | train_inner | epoch 002:    836 / 19564 loss=4.896, nll_loss=3.554, ppl=11.74, wps=17844.1, ups=5.07, wpb=3519.3, bsz=145, num_updates=20400, lr=0.000221404, gnorm=1.177, train_wall=20, wall=0
2024-07-18 13:09:08 | INFO | train_inner | epoch 002:    936 / 19564 loss=4.883, nll_loss=3.538, ppl=11.61, wps=18171.5, ups=5.16, wpb=3520.8, bsz=129.4, num_updates=20500, lr=0.000220863, gnorm=1.131, train_wall=19, wall=0
2024-07-18 13:09:28 | INFO | train_inner | epoch 002:   1036 / 19564 loss=4.936, nll_loss=3.6, ppl=12.13, wps=17526.9, ups=5.1, wpb=3436.7, bsz=136.6, num_updates=20600, lr=0.000220326, gnorm=1.198, train_wall=19, wall=0
2024-07-18 13:09:47 | INFO | train_inner | epoch 002:   1136 / 19564 loss=4.871, nll_loss=3.527, ppl=11.52, wps=17696.1, ups=5.11, wpb=3463.2, bsz=154.4, num_updates=20700, lr=0.000219793, gnorm=1.203, train_wall=19, wall=0
2024-07-18 13:10:07 | INFO | train_inner | epoch 002:   1236 / 19564 loss=4.918, nll_loss=3.581, ppl=11.97, wps=17396.1, ups=5.16, wpb=3372.3, bsz=147, num_updates=20800, lr=0.000219265, gnorm=1.188, train_wall=19, wall=0
2024-07-18 13:10:26 | INFO | train_inner | epoch 002:   1336 / 19564 loss=4.898, nll_loss=3.556, ppl=11.76, wps=17949.9, ups=5.12, wpb=3506.7, bsz=140.5, num_updates=20900, lr=0.000218739, gnorm=1.148, train_wall=19, wall=0
2024-07-18 13:10:46 | INFO | train_inner | epoch 002:   1436 / 19564 loss=4.948, nll_loss=3.615, ppl=12.25, wps=17617.1, ups=5.2, wpb=3390.4, bsz=139, num_updates=21000, lr=0.000218218, gnorm=1.199, train_wall=19, wall=0
2024-07-18 13:10:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:10:48 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.997 | nll_loss 3.566 | ppl 11.85 | wps 55286.1 | wpb 2872.6 | bsz 51.2 | num_updates 21000 | best_loss 12.134
2024-07-18 13:10:48 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:10:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_21000.pt (epoch 2 @ 21000 updates, score 4.997) (writing took 4.47070084232837 seconds)
2024-07-18 13:11:12 | INFO | train_inner | epoch 002:   1536 / 19564 loss=4.872, nll_loss=3.526, ppl=11.52, wps=13157.7, ups=3.75, wpb=3509.6, bsz=136.7, num_updates=21100, lr=0.0002177, gnorm=1.127, train_wall=20, wall=0
2024-07-18 13:11:32 | INFO | train_inner | epoch 002:   1636 / 19564 loss=4.861, nll_loss=3.516, ppl=11.44, wps=17522.9, ups=5.19, wpb=3375.5, bsz=140.9, num_updates=21200, lr=0.000217186, gnorm=1.195, train_wall=19, wall=0
2024-07-18 13:11:51 | INFO | train_inner | epoch 002:   1736 / 19564 loss=4.844, nll_loss=3.495, ppl=11.28, wps=17918.1, ups=5.15, wpb=3479.4, bsz=153.1, num_updates=21300, lr=0.000216676, gnorm=1.139, train_wall=19, wall=0
2024-07-18 13:12:11 | INFO | train_inner | epoch 002:   1836 / 19564 loss=4.794, nll_loss=3.439, ppl=10.85, wps=17682.1, ups=5.07, wpb=3484.4, bsz=152.6, num_updates=21400, lr=0.000216169, gnorm=1.124, train_wall=20, wall=0
2024-07-18 13:12:30 | INFO | train_inner | epoch 002:   1936 / 19564 loss=4.927, nll_loss=3.591, ppl=12.05, wps=17143.7, ups=5.12, wpb=3346.9, bsz=132.6, num_updates=21500, lr=0.000215666, gnorm=1.171, train_wall=19, wall=0
2024-07-18 13:12:50 | INFO | train_inner | epoch 002:   2036 / 19564 loss=4.84, nll_loss=3.491, ppl=11.24, wps=18039.2, ups=5.15, wpb=3503.3, bsz=133.1, num_updates=21600, lr=0.000215166, gnorm=1.113, train_wall=19, wall=0
2024-07-18 13:13:09 | INFO | train_inner | epoch 002:   2136 / 19564 loss=4.863, nll_loss=3.517, ppl=11.45, wps=17863.7, ups=5.12, wpb=3490.3, bsz=135.4, num_updates=21700, lr=0.000214669, gnorm=1.167, train_wall=19, wall=0
2024-07-18 13:13:29 | INFO | train_inner | epoch 002:   2236 / 19564 loss=4.8, nll_loss=3.446, ppl=10.9, wps=17779.3, ups=5.13, wpb=3468.8, bsz=164.6, num_updates=21800, lr=0.000214176, gnorm=1.173, train_wall=19, wall=0
2024-07-18 13:13:48 | INFO | train_inner | epoch 002:   2336 / 19564 loss=4.847, nll_loss=3.499, ppl=11.31, wps=17743, ups=5.14, wpb=3452.5, bsz=142.2, num_updates=21900, lr=0.000213687, gnorm=1.156, train_wall=19, wall=0
2024-07-18 13:14:08 | INFO | train_inner | epoch 002:   2436 / 19564 loss=4.834, nll_loss=3.486, ppl=11.2, wps=17302.5, ups=5.15, wpb=3362.7, bsz=145.7, num_updates=22000, lr=0.000213201, gnorm=1.17, train_wall=19, wall=0
2024-07-18 13:14:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:14:10 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.953 | nll_loss 3.513 | ppl 11.41 | wps 55085.6 | wpb 2872.6 | bsz 51.2 | num_updates 22000 | best_loss 12.134
2024-07-18 13:14:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:14:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_22000.pt (epoch 2 @ 22000 updates, score 4.953) (writing took 4.717434725724161 seconds)
2024-07-18 13:14:35 | INFO | train_inner | epoch 002:   2536 / 19564 loss=4.744, nll_loss=3.382, ppl=10.42, wps=12721.6, ups=3.69, wpb=3443.1, bsz=144.3, num_updates=22100, lr=0.000212718, gnorm=1.152, train_wall=20, wall=0
2024-07-18 13:14:54 | INFO | train_inner | epoch 002:   2636 / 19564 loss=4.804, nll_loss=3.45, ppl=10.93, wps=17600.7, ups=5.17, wpb=3405.6, bsz=129, num_updates=22200, lr=0.000212238, gnorm=1.146, train_wall=19, wall=0
2024-07-18 13:15:13 | INFO | train_inner | epoch 002:   2736 / 19564 loss=4.804, nll_loss=3.451, ppl=10.94, wps=17653.2, ups=5.13, wpb=3443.3, bsz=139.1, num_updates=22300, lr=0.000211762, gnorm=1.175, train_wall=19, wall=0
2024-07-18 13:15:33 | INFO | train_inner | epoch 002:   2836 / 19564 loss=4.826, nll_loss=3.476, ppl=11.13, wps=17721.9, ups=5.08, wpb=3490.4, bsz=145, num_updates=22400, lr=0.000211289, gnorm=1.164, train_wall=20, wall=0
2024-07-18 13:15:53 | INFO | train_inner | epoch 002:   2936 / 19564 loss=4.857, nll_loss=3.512, ppl=11.41, wps=17896.6, ups=5.1, wpb=3508.1, bsz=136.2, num_updates=22500, lr=0.000210819, gnorm=1.139, train_wall=19, wall=0
2024-07-18 13:16:12 | INFO | train_inner | epoch 002:   3036 / 19564 loss=4.811, nll_loss=3.458, ppl=10.99, wps=17627.2, ups=5.18, wpb=3403, bsz=140.5, num_updates=22600, lr=0.000210352, gnorm=1.17, train_wall=19, wall=0
2024-07-18 13:16:32 | INFO | train_inner | epoch 002:   3136 / 19564 loss=4.758, nll_loss=3.399, ppl=10.55, wps=17693.4, ups=5.11, wpb=3460.2, bsz=146.3, num_updates=22700, lr=0.000209888, gnorm=1.119, train_wall=19, wall=0
2024-07-18 13:16:51 | INFO | train_inner | epoch 002:   3236 / 19564 loss=4.844, nll_loss=3.498, ppl=11.3, wps=17913.7, ups=5.15, wpb=3479.5, bsz=147.1, num_updates=22800, lr=0.000209427, gnorm=1.163, train_wall=19, wall=0
2024-07-18 13:17:11 | INFO | train_inner | epoch 002:   3336 / 19564 loss=4.784, nll_loss=3.428, ppl=10.76, wps=17478.2, ups=5.13, wpb=3409.4, bsz=143.4, num_updates=22900, lr=0.000208969, gnorm=1.142, train_wall=19, wall=0
2024-07-18 13:17:30 | INFO | train_inner | epoch 002:   3436 / 19564 loss=4.713, nll_loss=3.346, ppl=10.17, wps=17844, ups=5.08, wpb=3513.6, bsz=141.6, num_updates=23000, lr=0.000208514, gnorm=1.152, train_wall=19, wall=0
2024-07-18 13:17:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:17:33 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.918 | nll_loss 3.483 | ppl 11.18 | wps 54834.8 | wpb 2872.6 | bsz 51.2 | num_updates 23000 | best_loss 12.134
2024-07-18 13:17:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:17:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_23000.pt (epoch 2 @ 23000 updates, score 4.918) (writing took 3.142384571954608 seconds)
2024-07-18 13:17:55 | INFO | train_inner | epoch 002:   3536 / 19564 loss=4.817, nll_loss=3.467, ppl=11.06, wps=13722.1, ups=3.99, wpb=3435.6, bsz=142.7, num_updates=23100, lr=0.000208063, gnorm=1.182, train_wall=19, wall=0
2024-07-18 13:18:15 | INFO | train_inner | epoch 002:   3636 / 19564 loss=4.755, nll_loss=3.395, ppl=10.52, wps=17149.1, ups=5.08, wpb=3372.6, bsz=146, num_updates=23200, lr=0.000207614, gnorm=1.169, train_wall=19, wall=0
2024-07-18 13:18:35 | INFO | train_inner | epoch 002:   3736 / 19564 loss=4.777, nll_loss=3.42, ppl=10.71, wps=17891.1, ups=5.09, wpb=3512.9, bsz=138, num_updates=23300, lr=0.000207168, gnorm=1.125, train_wall=19, wall=0
2024-07-18 13:18:54 | INFO | train_inner | epoch 002:   3836 / 19564 loss=4.85, nll_loss=3.503, ppl=11.34, wps=18086.6, ups=5.13, wpb=3523, bsz=140.4, num_updates=23400, lr=0.000206725, gnorm=1.141, train_wall=19, wall=0
2024-07-18 13:19:14 | INFO | train_inner | epoch 002:   3936 / 19564 loss=4.799, nll_loss=3.447, ppl=10.91, wps=17309.4, ups=5.02, wpb=3451.2, bsz=145.6, num_updates=23500, lr=0.000206284, gnorm=1.157, train_wall=20, wall=0
2024-07-18 13:19:34 | INFO | train_inner | epoch 002:   4036 / 19564 loss=4.742, nll_loss=3.382, ppl=10.43, wps=17962.9, ups=5.12, wpb=3510, bsz=164.6, num_updates=23600, lr=0.000205847, gnorm=1.127, train_wall=19, wall=0
2024-07-18 13:19:53 | INFO | train_inner | epoch 002:   4136 / 19564 loss=4.728, nll_loss=3.366, ppl=10.31, wps=17688.6, ups=5.11, wpb=3464.3, bsz=151.3, num_updates=23700, lr=0.000205412, gnorm=1.139, train_wall=19, wall=0
2024-07-18 13:20:13 | INFO | train_inner | epoch 002:   4236 / 19564 loss=4.745, nll_loss=3.384, ppl=10.44, wps=17506.5, ups=5.08, wpb=3444.7, bsz=135.4, num_updates=23800, lr=0.00020498, gnorm=1.139, train_wall=19, wall=0
2024-07-18 13:20:32 | INFO | train_inner | epoch 002:   4336 / 19564 loss=4.793, nll_loss=3.44, ppl=10.85, wps=17696.8, ups=5.11, wpb=3464.4, bsz=142.4, num_updates=23900, lr=0.000204551, gnorm=1.16, train_wall=19, wall=0
2024-07-18 13:20:52 | INFO | train_inner | epoch 002:   4436 / 19564 loss=4.79, nll_loss=3.436, ppl=10.82, wps=17650.6, ups=5.1, wpb=3459, bsz=140.6, num_updates=24000, lr=0.000204124, gnorm=1.156, train_wall=19, wall=0
2024-07-18 13:20:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:20:54 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.889 | nll_loss 3.444 | ppl 10.89 | wps 55296.7 | wpb 2872.6 | bsz 51.2 | num_updates 24000 | best_loss 12.134
2024-07-18 13:20:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:20:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_24000.pt (epoch 2 @ 24000 updates, score 4.889) (writing took 3.461599183268845 seconds)
2024-07-18 13:21:17 | INFO | train_inner | epoch 002:   4536 / 19564 loss=4.746, nll_loss=3.388, ppl=10.47, wps=13409.9, ups=3.97, wpb=3374.1, bsz=157.8, num_updates=24100, lr=0.0002037, gnorm=1.185, train_wall=19, wall=0
2024-07-18 13:21:37 | INFO | train_inner | epoch 002:   4636 / 19564 loss=4.764, nll_loss=3.407, ppl=10.61, wps=17791.7, ups=5.14, wpb=3464.1, bsz=154, num_updates=24200, lr=0.000203279, gnorm=1.152, train_wall=19, wall=0
2024-07-18 13:21:57 | INFO | train_inner | epoch 002:   4736 / 19564 loss=4.78, nll_loss=3.426, ppl=10.75, wps=17364, ups=5, wpb=3472.7, bsz=135.9, num_updates=24300, lr=0.00020286, gnorm=1.14, train_wall=20, wall=0
2024-07-18 13:22:16 | INFO | train_inner | epoch 002:   4836 / 19564 loss=4.778, nll_loss=3.423, ppl=10.72, wps=17984.4, ups=5.12, wpb=3510.7, bsz=142.9, num_updates=24400, lr=0.000202444, gnorm=1.137, train_wall=19, wall=0
2024-07-18 13:22:36 | INFO | train_inner | epoch 002:   4936 / 19564 loss=4.73, nll_loss=3.368, ppl=10.32, wps=17684.7, ups=5.15, wpb=3435.8, bsz=146.1, num_updates=24500, lr=0.000202031, gnorm=1.171, train_wall=19, wall=0
2024-07-18 13:22:55 | INFO | train_inner | epoch 002:   5036 / 19564 loss=4.814, nll_loss=3.466, ppl=11.05, wps=17887.5, ups=5.11, wpb=3500.1, bsz=159.8, num_updates=24600, lr=0.000201619, gnorm=1.145, train_wall=19, wall=0
2024-07-18 13:23:15 | INFO | train_inner | epoch 002:   5136 / 19564 loss=4.84, nll_loss=3.496, ppl=11.28, wps=17077.7, ups=5.07, wpb=3366.7, bsz=150.4, num_updates=24700, lr=0.000201211, gnorm=1.243, train_wall=20, wall=0
2024-07-18 13:23:34 | INFO | train_inner | epoch 002:   5236 / 19564 loss=4.766, nll_loss=3.41, ppl=10.63, wps=17507.3, ups=5.09, wpb=3441.4, bsz=143, num_updates=24800, lr=0.000200805, gnorm=1.157, train_wall=19, wall=0
2024-07-18 13:23:54 | INFO | train_inner | epoch 002:   5336 / 19564 loss=4.778, nll_loss=3.423, ppl=10.73, wps=17300.1, ups=5.1, wpb=3390.8, bsz=133.4, num_updates=24900, lr=0.000200401, gnorm=1.157, train_wall=19, wall=0
2024-07-18 13:24:13 | INFO | train_inner | epoch 002:   5436 / 19564 loss=4.772, nll_loss=3.417, ppl=10.68, wps=17444.6, ups=5.21, wpb=3349.6, bsz=137.9, num_updates=25000, lr=0.0002, gnorm=1.172, train_wall=19, wall=0
2024-07-18 13:24:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:24:16 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.826 | nll_loss 3.378 | ppl 10.39 | wps 54670.4 | wpb 2872.6 | bsz 51.2 | num_updates 25000 | best_loss 12.134
2024-07-18 13:24:16 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:24:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_25000.pt (epoch 2 @ 25000 updates, score 4.826) (writing took 3.3788928724825382 seconds)
2024-07-18 13:24:38 | INFO | train_inner | epoch 002:   5536 / 19564 loss=4.842, nll_loss=3.497, ppl=11.29, wps=13476.1, ups=3.98, wpb=3387.2, bsz=140.2, num_updates=25100, lr=0.000199601, gnorm=1.202, train_wall=19, wall=0
2024-07-18 13:24:58 | INFO | train_inner | epoch 002:   5636 / 19564 loss=4.733, nll_loss=3.372, ppl=10.35, wps=17623.2, ups=5.12, wpb=3444.9, bsz=143.3, num_updates=25200, lr=0.000199205, gnorm=1.137, train_wall=19, wall=0
2024-07-18 13:25:18 | INFO | train_inner | epoch 002:   5736 / 19564 loss=4.883, nll_loss=3.545, ppl=11.67, wps=17523.9, ups=5.09, wpb=3440.7, bsz=128.2, num_updates=25300, lr=0.000198811, gnorm=1.194, train_wall=19, wall=0
2024-07-18 13:25:37 | INFO | train_inner | epoch 002:   5836 / 19564 loss=4.806, nll_loss=3.456, ppl=10.97, wps=17685.5, ups=5.16, wpb=3426.5, bsz=131, num_updates=25400, lr=0.000198419, gnorm=1.156, train_wall=19, wall=0
2024-07-18 13:25:57 | INFO | train_inner | epoch 002:   5936 / 19564 loss=4.782, nll_loss=3.429, ppl=10.77, wps=17580.9, ups=5.12, wpb=3432.3, bsz=151.9, num_updates=25500, lr=0.00019803, gnorm=1.159, train_wall=19, wall=0
2024-07-18 13:26:16 | INFO | train_inner | epoch 002:   6036 / 19564 loss=4.793, nll_loss=3.44, ppl=10.85, wps=17853.7, ups=5.14, wpb=3475.2, bsz=130.6, num_updates=25600, lr=0.000197642, gnorm=1.151, train_wall=19, wall=0
2024-07-18 13:26:35 | INFO | train_inner | epoch 002:   6136 / 19564 loss=4.785, nll_loss=3.431, ppl=10.78, wps=17676.1, ups=5.2, wpb=3399.4, bsz=135.2, num_updates=25700, lr=0.000197257, gnorm=1.185, train_wall=19, wall=0
2024-07-18 13:26:55 | INFO | train_inner | epoch 002:   6236 / 19564 loss=4.762, nll_loss=3.406, ppl=10.6, wps=17383.1, ups=5.14, wpb=3381.3, bsz=138.3, num_updates=25800, lr=0.000196875, gnorm=1.17, train_wall=19, wall=0
2024-07-18 13:27:14 | INFO | train_inner | epoch 002:   6336 / 19564 loss=4.665, nll_loss=3.294, ppl=9.81, wps=17260.3, ups=5.16, wpb=3345.3, bsz=147.7, num_updates=25900, lr=0.000196494, gnorm=1.138, train_wall=19, wall=0
2024-07-18 13:27:33 | INFO | train_inner | epoch 002:   6436 / 19564 loss=4.795, nll_loss=3.444, ppl=10.88, wps=17845.8, ups=5.21, wpb=3422.1, bsz=133.9, num_updates=26000, lr=0.000196116, gnorm=1.176, train_wall=19, wall=0
2024-07-18 13:27:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:27:36 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.815 | nll_loss 3.352 | ppl 10.21 | wps 54812.3 | wpb 2872.6 | bsz 51.2 | num_updates 26000 | best_loss 12.134
2024-07-18 13:27:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:27:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_26000.pt (epoch 2 @ 26000 updates, score 4.815) (writing took 3.62018059194088 seconds)
2024-07-18 13:27:58 | INFO | train_inner | epoch 002:   6536 / 19564 loss=4.685, nll_loss=3.318, ppl=9.97, wps=13600.6, ups=3.96, wpb=3432.8, bsz=149.9, num_updates=26100, lr=0.00019574, gnorm=1.155, train_wall=19, wall=0
2024-07-18 13:28:18 | INFO | train_inner | epoch 002:   6636 / 19564 loss=4.71, nll_loss=3.348, ppl=10.18, wps=17673.3, ups=5.13, wpb=3447.8, bsz=149, num_updates=26200, lr=0.000195366, gnorm=1.165, train_wall=19, wall=0
2024-07-18 13:28:37 | INFO | train_inner | epoch 002:   6736 / 19564 loss=4.746, nll_loss=3.387, ppl=10.46, wps=17845.5, ups=5.13, wpb=3480.4, bsz=147.5, num_updates=26300, lr=0.000194994, gnorm=1.153, train_wall=19, wall=0
2024-07-18 13:28:57 | INFO | train_inner | epoch 002:   6836 / 19564 loss=4.746, nll_loss=3.388, ppl=10.47, wps=17674.7, ups=5.06, wpb=3495.1, bsz=138.7, num_updates=26400, lr=0.000194625, gnorm=1.15, train_wall=20, wall=0
2024-07-18 13:29:17 | INFO | train_inner | epoch 002:   6936 / 19564 loss=4.765, nll_loss=3.411, ppl=10.64, wps=17276.3, ups=5.1, wpb=3386.7, bsz=138, num_updates=26500, lr=0.000194257, gnorm=1.165, train_wall=19, wall=0
2024-07-18 13:29:37 | INFO | train_inner | epoch 002:   7036 / 19564 loss=4.7, nll_loss=3.335, ppl=10.09, wps=17221.1, ups=4.98, wpb=3456.4, bsz=145.8, num_updates=26600, lr=0.000193892, gnorm=1.138, train_wall=20, wall=0
2024-07-18 13:29:57 | INFO | train_inner | epoch 002:   7136 / 19564 loss=4.71, nll_loss=3.347, ppl=10.18, wps=17195.9, ups=5.07, wpb=3388.8, bsz=156.6, num_updates=26700, lr=0.000193528, gnorm=1.175, train_wall=20, wall=0
2024-07-18 13:30:17 | INFO | train_inner | epoch 002:   7236 / 19564 loss=4.776, nll_loss=3.423, ppl=10.73, wps=16943.7, ups=4.98, wpb=3405, bsz=149.6, num_updates=26800, lr=0.000193167, gnorm=1.172, train_wall=20, wall=0
2024-07-18 13:30:36 | INFO | train_inner | epoch 002:   7336 / 19564 loss=4.773, nll_loss=3.419, ppl=10.69, wps=17560.8, ups=5.08, wpb=3457.4, bsz=127.4, num_updates=26900, lr=0.000192807, gnorm=1.146, train_wall=19, wall=0
2024-07-18 13:30:57 | INFO | train_inner | epoch 002:   7436 / 19564 loss=4.768, nll_loss=3.414, ppl=10.66, wps=16891.6, ups=4.98, wpb=3392.5, bsz=150.4, num_updates=27000, lr=0.00019245, gnorm=1.197, train_wall=20, wall=0
2024-07-18 13:30:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:30:59 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.799 | nll_loss 3.346 | ppl 10.17 | wps 54333.8 | wpb 2872.6 | bsz 51.2 | num_updates 27000 | best_loss 12.134
2024-07-18 13:30:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:31:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_27000.pt (epoch 2 @ 27000 updates, score 4.799) (writing took 3.1214833939448 seconds)
2024-07-18 13:31:22 | INFO | train_inner | epoch 002:   7536 / 19564 loss=4.722, nll_loss=3.361, ppl=10.28, wps=13871.9, ups=3.95, wpb=3514.7, bsz=141.6, num_updates=27100, lr=0.000192095, gnorm=1.113, train_wall=20, wall=0
2024-07-18 13:31:41 | INFO | train_inner | epoch 002:   7636 / 19564 loss=4.697, nll_loss=3.333, ppl=10.08, wps=17629.5, ups=5.11, wpb=3447.2, bsz=149.2, num_updates=27200, lr=0.000191741, gnorm=1.134, train_wall=19, wall=0
2024-07-18 13:32:01 | INFO | train_inner | epoch 002:   7736 / 19564 loss=4.746, nll_loss=3.389, ppl=10.48, wps=17613.3, ups=5.16, wpb=3416.6, bsz=152.7, num_updates=27300, lr=0.00019139, gnorm=1.163, train_wall=19, wall=0
2024-07-18 13:32:21 | INFO | train_inner | epoch 002:   7836 / 19564 loss=4.749, nll_loss=3.392, ppl=10.5, wps=16933.5, ups=5.04, wpb=3361.9, bsz=134.2, num_updates=27400, lr=0.00019104, gnorm=1.191, train_wall=20, wall=0
2024-07-18 13:32:40 | INFO | train_inner | epoch 002:   7936 / 19564 loss=4.744, nll_loss=3.387, ppl=10.46, wps=17887.1, ups=5.13, wpb=3488.9, bsz=135.3, num_updates=27500, lr=0.000190693, gnorm=1.118, train_wall=19, wall=0
2024-07-18 13:33:00 | INFO | train_inner | epoch 002:   8036 / 19564 loss=4.738, nll_loss=3.381, ppl=10.42, wps=17090.7, ups=5.08, wpb=3363.6, bsz=141.9, num_updates=27600, lr=0.000190347, gnorm=1.213, train_wall=19, wall=0
2024-07-18 13:33:19 | INFO | train_inner | epoch 002:   8136 / 19564 loss=4.654, nll_loss=3.283, ppl=9.73, wps=18012.8, ups=5.12, wpb=3519.5, bsz=145.9, num_updates=27700, lr=0.000190003, gnorm=1.127, train_wall=19, wall=0
2024-07-18 13:33:39 | INFO | train_inner | epoch 002:   8236 / 19564 loss=4.776, nll_loss=3.423, ppl=10.73, wps=17868.6, ups=5.16, wpb=3460.6, bsz=133.6, num_updates=27800, lr=0.000189661, gnorm=1.159, train_wall=19, wall=0
2024-07-18 13:33:58 | INFO | train_inner | epoch 002:   8336 / 19564 loss=4.697, nll_loss=3.334, ppl=10.09, wps=17714.2, ups=5.13, wpb=3450.7, bsz=139.8, num_updates=27900, lr=0.000189321, gnorm=1.128, train_wall=19, wall=0
2024-07-18 13:34:18 | INFO | train_inner | epoch 002:   8436 / 19564 loss=4.767, nll_loss=3.415, ppl=10.66, wps=17401.3, ups=5.14, wpb=3384.6, bsz=146.6, num_updates=28000, lr=0.000188982, gnorm=1.182, train_wall=19, wall=0
2024-07-18 13:34:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:34:20 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.76 | nll_loss 3.287 | ppl 9.76 | wps 55154.3 | wpb 2872.6 | bsz 51.2 | num_updates 28000 | best_loss 12.134
2024-07-18 13:34:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:34:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_28000.pt (epoch 2 @ 28000 updates, score 4.76) (writing took 3.815081376582384 seconds)
2024-07-18 13:34:43 | INFO | train_inner | epoch 002:   8536 / 19564 loss=4.735, nll_loss=3.377, ppl=10.39, wps=13592.7, ups=3.89, wpb=3491.4, bsz=145.5, num_updates=28100, lr=0.000188646, gnorm=1.154, train_wall=19, wall=0
2024-07-18 13:35:03 | INFO | train_inner | epoch 002:   8636 / 19564 loss=4.679, nll_loss=3.314, ppl=9.95, wps=17515.6, ups=5.08, wpb=3449.1, bsz=146.3, num_updates=28200, lr=0.000188311, gnorm=1.139, train_wall=20, wall=0
2024-07-18 13:35:23 | INFO | train_inner | epoch 002:   8736 / 19564 loss=4.66, nll_loss=3.29, ppl=9.78, wps=18049.9, ups=5.13, wpb=3521.7, bsz=143.9, num_updates=28300, lr=0.000187978, gnorm=1.109, train_wall=19, wall=0
2024-07-18 13:35:42 | INFO | train_inner | epoch 002:   8836 / 19564 loss=4.699, nll_loss=3.336, ppl=10.1, wps=17658.3, ups=5.14, wpb=3432.8, bsz=137.9, num_updates=28400, lr=0.000187647, gnorm=1.18, train_wall=19, wall=0
2024-07-18 13:36:02 | INFO | train_inner | epoch 002:   8936 / 19564 loss=4.713, nll_loss=3.351, ppl=10.21, wps=17845.1, ups=5.13, wpb=3478.5, bsz=139.8, num_updates=28500, lr=0.000187317, gnorm=1.129, train_wall=19, wall=0
2024-07-18 13:36:21 | INFO | train_inner | epoch 002:   9036 / 19564 loss=4.679, nll_loss=3.313, ppl=9.94, wps=17930, ups=5.09, wpb=3520.1, bsz=135.4, num_updates=28600, lr=0.000186989, gnorm=1.109, train_wall=19, wall=0
2024-07-18 13:36:41 | INFO | train_inner | epoch 002:   9136 / 19564 loss=4.694, nll_loss=3.331, ppl=10.06, wps=17700.7, ups=5.12, wpb=3454.6, bsz=137.8, num_updates=28700, lr=0.000186663, gnorm=1.15, train_wall=19, wall=0
2024-07-18 13:37:00 | INFO | train_inner | epoch 002:   9236 / 19564 loss=4.754, nll_loss=3.4, ppl=10.55, wps=17509.2, ups=5.06, wpb=3461.9, bsz=137.5, num_updates=28800, lr=0.000186339, gnorm=1.167, train_wall=20, wall=0
2024-07-18 13:37:19 | INFO | train_inner | epoch 002:   9336 / 19564 loss=4.735, nll_loss=3.377, ppl=10.39, wps=17675.9, ups=5.24, wpb=3370.9, bsz=128, num_updates=28900, lr=0.000186016, gnorm=1.192, train_wall=19, wall=0
2024-07-18 13:37:39 | INFO | train_inner | epoch 002:   9436 / 19564 loss=4.599, nll_loss=3.223, ppl=9.34, wps=17503.2, ups=5.14, wpb=3403.5, bsz=152.8, num_updates=29000, lr=0.000185695, gnorm=1.133, train_wall=19, wall=0
2024-07-18 13:37:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:37:41 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.722 | nll_loss 3.257 | ppl 9.56 | wps 54686.8 | wpb 2872.6 | bsz 51.2 | num_updates 29000 | best_loss 12.134
2024-07-18 13:37:41 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:37:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_29000.pt (epoch 2 @ 29000 updates, score 4.722) (writing took 3.501598007977009 seconds)
2024-07-18 13:38:04 | INFO | train_inner | epoch 002:   9536 / 19564 loss=4.635, nll_loss=3.264, ppl=9.61, wps=13694.8, ups=3.94, wpb=3475.4, bsz=151.1, num_updates=29100, lr=0.000185376, gnorm=1.128, train_wall=19, wall=0
2024-07-18 13:38:24 | INFO | train_inner | epoch 002:   9636 / 19564 loss=4.703, nll_loss=3.342, ppl=10.14, wps=17843.4, ups=5.19, wpb=3440.3, bsz=131.3, num_updates=29200, lr=0.000185058, gnorm=1.181, train_wall=19, wall=0
2024-07-18 13:38:43 | INFO | train_inner | epoch 002:   9736 / 19564 loss=4.723, nll_loss=3.364, ppl=10.29, wps=17645.7, ups=5.03, wpb=3510.6, bsz=135.4, num_updates=29300, lr=0.000184742, gnorm=1.129, train_wall=20, wall=0
2024-07-18 13:39:03 | INFO | train_inner | epoch 002:   9836 / 19564 loss=4.66, nll_loss=3.293, ppl=9.8, wps=17445.3, ups=5.02, wpb=3476.8, bsz=152.2, num_updates=29400, lr=0.000184428, gnorm=1.119, train_wall=20, wall=0
2024-07-18 13:39:23 | INFO | train_inner | epoch 002:   9936 / 19564 loss=4.644, nll_loss=3.275, ppl=9.68, wps=17417.7, ups=5.16, wpb=3372.3, bsz=138.4, num_updates=29500, lr=0.000184115, gnorm=1.167, train_wall=19, wall=0
2024-07-18 13:39:42 | INFO | train_inner | epoch 002:  10036 / 19564 loss=4.691, nll_loss=3.327, ppl=10.03, wps=17307.2, ups=5.1, wpb=3392.6, bsz=128.5, num_updates=29600, lr=0.000183804, gnorm=1.161, train_wall=19, wall=0
2024-07-18 13:40:02 | INFO | train_inner | epoch 002:  10136 / 19564 loss=4.686, nll_loss=3.323, ppl=10.01, wps=17562.1, ups=5.18, wpb=3391.6, bsz=141.6, num_updates=29700, lr=0.000183494, gnorm=1.164, train_wall=19, wall=0
2024-07-18 13:40:21 | INFO | train_inner | epoch 002:  10236 / 19564 loss=4.708, nll_loss=3.347, ppl=10.17, wps=17319.3, ups=5.08, wpb=3406.7, bsz=134.6, num_updates=29800, lr=0.000183186, gnorm=1.166, train_wall=19, wall=0
2024-07-18 13:40:41 | INFO | train_inner | epoch 002:  10336 / 19564 loss=4.674, nll_loss=3.308, ppl=9.9, wps=17383.8, ups=5.03, wpb=3457.2, bsz=130.2, num_updates=29900, lr=0.000182879, gnorm=1.124, train_wall=20, wall=0
2024-07-18 13:41:01 | INFO | train_inner | epoch 002:  10436 / 19564 loss=4.672, nll_loss=3.306, ppl=9.89, wps=17927.5, ups=5.1, wpb=3512.8, bsz=139.4, num_updates=30000, lr=0.000182574, gnorm=1.153, train_wall=19, wall=0
2024-07-18 13:41:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:41:03 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.723 | nll_loss 3.263 | ppl 9.6 | wps 54237.4 | wpb 2872.6 | bsz 51.2 | num_updates 30000 | best_loss 12.134
2024-07-18 13:41:03 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:41:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_30000.pt (epoch 2 @ 30000 updates, score 4.723) (writing took 7.646847788244486 seconds)
2024-07-18 13:41:31 | INFO | train_inner | epoch 002:  10536 / 19564 loss=4.653, nll_loss=3.285, ppl=9.75, wps=11508.9, ups=3.32, wpb=3467.3, bsz=156.9, num_updates=30100, lr=0.000182271, gnorm=1.128, train_wall=20, wall=0
2024-07-18 13:41:51 | INFO | train_inner | epoch 002:  10636 / 19564 loss=4.6, nll_loss=3.224, ppl=9.35, wps=17655.6, ups=5.11, wpb=3455.8, bsz=152.3, num_updates=30200, lr=0.000181969, gnorm=1.137, train_wall=19, wall=0
2024-07-18 13:42:10 | INFO | train_inner | epoch 002:  10736 / 19564 loss=4.677, nll_loss=3.311, ppl=9.93, wps=18044.4, ups=5.12, wpb=3520.9, bsz=134.8, num_updates=30300, lr=0.000181668, gnorm=1.136, train_wall=19, wall=0
2024-07-18 13:42:30 | INFO | train_inner | epoch 002:  10836 / 19564 loss=4.657, nll_loss=3.289, ppl=9.78, wps=17856.5, ups=5.05, wpb=3538.6, bsz=139.8, num_updates=30400, lr=0.000181369, gnorm=1.115, train_wall=20, wall=0
2024-07-18 13:42:49 | INFO | train_inner | epoch 002:  10936 / 19564 loss=4.718, nll_loss=3.359, ppl=10.26, wps=17711.9, ups=5.17, wpb=3429.2, bsz=138.6, num_updates=30500, lr=0.000181071, gnorm=1.179, train_wall=19, wall=0
2024-07-18 13:43:09 | INFO | train_inner | epoch 002:  11036 / 19564 loss=4.659, nll_loss=3.293, ppl=9.8, wps=17439.1, ups=5.17, wpb=3374.5, bsz=144.7, num_updates=30600, lr=0.000180775, gnorm=1.181, train_wall=19, wall=0
2024-07-18 13:43:28 | INFO | train_inner | epoch 002:  11136 / 19564 loss=4.7, nll_loss=3.339, ppl=10.12, wps=17633.9, ups=5.16, wpb=3419.7, bsz=139.4, num_updates=30700, lr=0.000180481, gnorm=1.156, train_wall=19, wall=0
2024-07-18 13:43:48 | INFO | train_inner | epoch 002:  11236 / 19564 loss=4.68, nll_loss=3.317, ppl=9.97, wps=17869.8, ups=5.07, wpb=3522.9, bsz=164.4, num_updates=30800, lr=0.000180187, gnorm=1.163, train_wall=20, wall=0
2024-07-18 13:44:07 | INFO | train_inner | epoch 002:  11336 / 19564 loss=4.622, nll_loss=3.25, ppl=9.51, wps=17922.8, ups=5.1, wpb=3514.1, bsz=143, num_updates=30900, lr=0.000179896, gnorm=1.101, train_wall=19, wall=0
2024-07-18 13:44:27 | INFO | train_inner | epoch 002:  11436 / 19564 loss=4.683, nll_loss=3.321, ppl=10, wps=17593.8, ups=5.07, wpb=3471.7, bsz=148.1, num_updates=31000, lr=0.000179605, gnorm=1.161, train_wall=20, wall=0
2024-07-18 13:44:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:44:29 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.692 | nll_loss 3.225 | ppl 9.35 | wps 55001.2 | wpb 2872.6 | bsz 51.2 | num_updates 31000 | best_loss 12.134
2024-07-18 13:44:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:44:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_31000.pt (epoch 2 @ 31000 updates, score 4.692) (writing took 4.985471942462027 seconds)
2024-07-18 13:44:54 | INFO | train_inner | epoch 002:  11536 / 19564 loss=4.699, nll_loss=3.337, ppl=10.11, wps=12827, ups=3.68, wpb=3484.2, bsz=125.9, num_updates=31100, lr=0.000179316, gnorm=1.133, train_wall=20, wall=0
2024-07-18 13:45:14 | INFO | train_inner | epoch 002:  11636 / 19564 loss=4.726, nll_loss=3.369, ppl=10.33, wps=17716.7, ups=5.16, wpb=3435.7, bsz=132.6, num_updates=31200, lr=0.000179029, gnorm=1.165, train_wall=19, wall=0
2024-07-18 13:45:33 | INFO | train_inner | epoch 002:  11736 / 19564 loss=4.648, nll_loss=3.28, ppl=9.71, wps=17669.1, ups=5.06, wpb=3491.6, bsz=142.5, num_updates=31300, lr=0.000178743, gnorm=1.112, train_wall=20, wall=0
2024-07-18 13:45:53 | INFO | train_inner | epoch 002:  11836 / 19564 loss=4.601, nll_loss=3.226, ppl=9.36, wps=17044.6, ups=5.02, wpb=3392.6, bsz=147.4, num_updates=31400, lr=0.000178458, gnorm=1.151, train_wall=20, wall=0
2024-07-18 13:46:13 | INFO | train_inner | epoch 002:  11936 / 19564 loss=4.624, nll_loss=3.252, ppl=9.53, wps=17412.2, ups=4.95, wpb=3519, bsz=139, num_updates=31500, lr=0.000178174, gnorm=1.106, train_wall=20, wall=0
2024-07-18 13:46:33 | INFO | train_inner | epoch 002:  12036 / 19564 loss=4.661, nll_loss=3.297, ppl=9.83, wps=17297.5, ups=5.08, wpb=3401.8, bsz=160.2, num_updates=31600, lr=0.000177892, gnorm=1.185, train_wall=19, wall=0
2024-07-18 13:46:53 | INFO | train_inner | epoch 002:  12136 / 19564 loss=4.664, nll_loss=3.298, ppl=9.83, wps=17649.7, ups=4.99, wpb=3540.1, bsz=136.3, num_updates=31700, lr=0.000177611, gnorm=1.134, train_wall=20, wall=0
2024-07-18 13:47:13 | INFO | train_inner | epoch 002:  12236 / 19564 loss=4.68, nll_loss=3.318, ppl=9.97, wps=17057.2, ups=5.02, wpb=3396.1, bsz=152.2, num_updates=31800, lr=0.000177332, gnorm=1.158, train_wall=20, wall=0
2024-07-18 13:47:33 | INFO | train_inner | epoch 002:  12336 / 19564 loss=4.605, nll_loss=3.231, ppl=9.39, wps=17283.7, ups=4.93, wpb=3506, bsz=144.7, num_updates=31900, lr=0.000177054, gnorm=1.121, train_wall=20, wall=0
2024-07-18 13:47:53 | INFO | train_inner | epoch 002:  12436 / 19564 loss=4.63, nll_loss=3.261, ppl=9.59, wps=17585, ups=5.13, wpb=3426.1, bsz=151.4, num_updates=32000, lr=0.000176777, gnorm=1.171, train_wall=19, wall=0
2024-07-18 13:47:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:47:55 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.652 | nll_loss 3.184 | ppl 9.09 | wps 53769.6 | wpb 2872.6 | bsz 51.2 | num_updates 32000 | best_loss 12.134
2024-07-18 13:47:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:48:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_32000.pt (epoch 2 @ 32000 updates, score 4.652) (writing took 4.4222138449549675 seconds)
2024-07-18 13:48:19 | INFO | train_inner | epoch 002:  12536 / 19564 loss=4.672, nll_loss=3.308, ppl=9.9, wps=12949.2, ups=3.78, wpb=3423.2, bsz=140.4, num_updates=32100, lr=0.000176501, gnorm=1.143, train_wall=19, wall=0
2024-07-18 13:48:39 | INFO | train_inner | epoch 002:  12636 / 19564 loss=4.74, nll_loss=3.386, ppl=10.46, wps=17545.8, ups=5.11, wpb=3430.3, bsz=134.4, num_updates=32200, lr=0.000176227, gnorm=1.187, train_wall=19, wall=0
2024-07-18 13:48:59 | INFO | train_inner | epoch 002:  12736 / 19564 loss=4.634, nll_loss=3.266, ppl=9.62, wps=17271.8, ups=5.02, wpb=3439, bsz=155.8, num_updates=32300, lr=0.000175954, gnorm=1.132, train_wall=20, wall=0
2024-07-18 13:49:19 | INFO | train_inner | epoch 002:  12836 / 19564 loss=4.727, nll_loss=3.37, ppl=10.34, wps=17630.1, ups=5.04, wpb=3499.6, bsz=130.6, num_updates=32400, lr=0.000175682, gnorm=1.147, train_wall=20, wall=0
2024-07-18 13:49:38 | INFO | train_inner | epoch 002:  12936 / 19564 loss=4.673, nll_loss=3.31, ppl=9.91, wps=17662.1, ups=5.05, wpb=3498.6, bsz=146.5, num_updates=32500, lr=0.000175412, gnorm=1.12, train_wall=20, wall=0
2024-07-18 13:49:59 | INFO | train_inner | epoch 002:  13036 / 19564 loss=4.625, nll_loss=3.255, ppl=9.55, wps=17135.6, ups=4.97, wpb=3448.1, bsz=133.5, num_updates=32600, lr=0.000175142, gnorm=1.113, train_wall=20, wall=0
2024-07-18 13:50:18 | INFO | train_inner | epoch 002:  13136 / 19564 loss=4.691, nll_loss=3.329, ppl=10.05, wps=18012.9, ups=5.06, wpb=3557.5, bsz=132.4, num_updates=32700, lr=0.000174874, gnorm=1.118, train_wall=20, wall=0
2024-07-18 13:50:38 | INFO | train_inner | epoch 002:  13236 / 19564 loss=4.632, nll_loss=3.264, ppl=9.6, wps=17091.2, ups=5.04, wpb=3387.8, bsz=153.6, num_updates=32800, lr=0.000174608, gnorm=1.162, train_wall=20, wall=0
2024-07-18 13:50:58 | INFO | train_inner | epoch 002:  13336 / 19564 loss=4.674, nll_loss=3.311, ppl=9.92, wps=17607, ups=5.03, wpb=3498.8, bsz=149.4, num_updates=32900, lr=0.000174342, gnorm=1.133, train_wall=20, wall=0
2024-07-18 13:51:18 | INFO | train_inner | epoch 002:  13436 / 19564 loss=4.596, nll_loss=3.222, ppl=9.33, wps=17217.3, ups=5.04, wpb=3417, bsz=148.3, num_updates=33000, lr=0.000174078, gnorm=1.126, train_wall=20, wall=0
2024-07-18 13:51:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:51:20 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.633 | nll_loss 3.151 | ppl 8.88 | wps 54143.1 | wpb 2872.6 | bsz 51.2 | num_updates 33000 | best_loss 12.134
2024-07-18 13:51:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:51:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_33000.pt (epoch 2 @ 33000 updates, score 4.633) (writing took 3.4956647101789713 seconds)
2024-07-18 13:51:43 | INFO | train_inner | epoch 002:  13536 / 19564 loss=4.717, nll_loss=3.36, ppl=10.26, wps=13513.6, ups=3.95, wpb=3424.9, bsz=121.8, num_updates=33100, lr=0.000173814, gnorm=1.171, train_wall=19, wall=0
2024-07-18 13:52:03 | INFO | train_inner | epoch 002:  13636 / 19564 loss=4.607, nll_loss=3.235, ppl=9.42, wps=17668.4, ups=5.04, wpb=3506.6, bsz=157, num_updates=33200, lr=0.000173553, gnorm=1.115, train_wall=20, wall=0
2024-07-18 13:52:23 | INFO | train_inner | epoch 002:  13736 / 19564 loss=4.53, nll_loss=3.146, ppl=8.85, wps=17534, ups=5.04, wpb=3479.2, bsz=163, num_updates=33300, lr=0.000173292, gnorm=1.127, train_wall=20, wall=0
2024-07-18 13:52:43 | INFO | train_inner | epoch 002:  13836 / 19564 loss=4.608, nll_loss=3.236, ppl=9.42, wps=17634.3, ups=5.04, wpb=3500.3, bsz=144.7, num_updates=33400, lr=0.000173032, gnorm=1.121, train_wall=20, wall=0
2024-07-18 13:53:02 | INFO | train_inner | epoch 002:  13936 / 19564 loss=4.646, nll_loss=3.279, ppl=9.71, wps=17282.5, ups=5.09, wpb=3397.1, bsz=154.6, num_updates=33500, lr=0.000172774, gnorm=1.182, train_wall=19, wall=0
2024-07-18 13:53:22 | INFO | train_inner | epoch 002:  14036 / 19564 loss=4.643, nll_loss=3.275, ppl=9.68, wps=17505.9, ups=5.11, wpb=3426.2, bsz=135.8, num_updates=33600, lr=0.000172516, gnorm=1.123, train_wall=19, wall=0
2024-07-18 13:53:42 | INFO | train_inner | epoch 002:  14136 / 19564 loss=4.635, nll_loss=3.266, ppl=9.62, wps=17688.7, ups=5.1, wpb=3471.7, bsz=136.6, num_updates=33700, lr=0.00017226, gnorm=1.179, train_wall=19, wall=0
2024-07-18 13:54:02 | INFO | train_inner | epoch 002:  14236 / 19564 loss=4.606, nll_loss=3.233, ppl=9.4, wps=17682.6, ups=5.03, wpb=3517.2, bsz=130.1, num_updates=33800, lr=0.000172005, gnorm=1.108, train_wall=20, wall=0
2024-07-18 13:54:21 | INFO | train_inner | epoch 002:  14336 / 19564 loss=4.634, nll_loss=3.266, ppl=9.62, wps=17451.5, ups=5.06, wpb=3448.1, bsz=143.8, num_updates=33900, lr=0.000171751, gnorm=1.128, train_wall=20, wall=0
2024-07-18 13:54:41 | INFO | train_inner | epoch 002:  14436 / 19564 loss=4.61, nll_loss=3.238, ppl=9.43, wps=17570.3, ups=5.1, wpb=3445.4, bsz=145.4, num_updates=34000, lr=0.000171499, gnorm=1.13, train_wall=19, wall=0
2024-07-18 13:54:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:54:43 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.614 | nll_loss 3.141 | ppl 8.82 | wps 54050 | wpb 2872.6 | bsz 51.2 | num_updates 34000 | best_loss 12.134
2024-07-18 13:54:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:54:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_34000.pt (epoch 2 @ 34000 updates, score 4.614) (writing took 3.448870064690709 seconds)
2024-07-18 13:55:06 | INFO | train_inner | epoch 002:  14536 / 19564 loss=4.645, nll_loss=3.277, ppl=9.7, wps=13575.1, ups=3.92, wpb=3462.5, bsz=121.6, num_updates=34100, lr=0.000171247, gnorm=1.162, train_wall=19, wall=0
2024-07-18 13:55:26 | INFO | train_inner | epoch 002:  14636 / 19564 loss=4.626, nll_loss=3.255, ppl=9.55, wps=17708.7, ups=5.11, wpb=3462.7, bsz=123.7, num_updates=34200, lr=0.000170996, gnorm=1.131, train_wall=19, wall=0
2024-07-18 13:55:45 | INFO | train_inner | epoch 002:  14736 / 19564 loss=4.687, nll_loss=3.327, ppl=10.03, wps=17538.3, ups=5.15, wpb=3403.8, bsz=137.7, num_updates=34300, lr=0.000170747, gnorm=1.17, train_wall=19, wall=0
2024-07-18 13:56:05 | INFO | train_inner | epoch 002:  14836 / 19564 loss=4.627, nll_loss=3.257, ppl=9.56, wps=17180.8, ups=5.04, wpb=3405.8, bsz=130.6, num_updates=34400, lr=0.000170499, gnorm=1.157, train_wall=20, wall=0
2024-07-18 13:56:25 | INFO | train_inner | epoch 002:  14936 / 19564 loss=4.629, nll_loss=3.26, ppl=9.58, wps=17506.5, ups=5.15, wpb=3397.4, bsz=137.9, num_updates=34500, lr=0.000170251, gnorm=1.152, train_wall=19, wall=0
2024-07-18 13:56:44 | INFO | train_inner | epoch 002:  15036 / 19564 loss=4.587, nll_loss=3.212, ppl=9.27, wps=17740.1, ups=5.1, wpb=3479.4, bsz=148.7, num_updates=34600, lr=0.000170005, gnorm=1.108, train_wall=19, wall=0
2024-07-18 13:57:04 | INFO | train_inner | epoch 002:  15136 / 19564 loss=4.65, nll_loss=3.285, ppl=9.75, wps=17349.4, ups=5.15, wpb=3370.6, bsz=141, num_updates=34700, lr=0.00016976, gnorm=1.169, train_wall=19, wall=0
2024-07-18 13:57:23 | INFO | train_inner | epoch 002:  15236 / 19564 loss=4.715, nll_loss=3.358, ppl=10.25, wps=17496.1, ups=5.16, wpb=3389.4, bsz=126.2, num_updates=34800, lr=0.000169516, gnorm=1.183, train_wall=19, wall=0
2024-07-18 13:57:43 | INFO | train_inner | epoch 002:  15336 / 19564 loss=4.641, nll_loss=3.273, ppl=9.67, wps=17785.2, ups=5.09, wpb=3495, bsz=128.8, num_updates=34900, lr=0.000169273, gnorm=1.135, train_wall=19, wall=0
2024-07-18 13:58:02 | INFO | train_inner | epoch 002:  15436 / 19564 loss=4.568, nll_loss=3.19, ppl=9.13, wps=17350.4, ups=5.08, wpb=3415.4, bsz=142.6, num_updates=35000, lr=0.000169031, gnorm=1.153, train_wall=19, wall=0
2024-07-18 13:58:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 13:58:05 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.601 | nll_loss 3.123 | ppl 8.71 | wps 54038.1 | wpb 2872.6 | bsz 51.2 | num_updates 35000 | best_loss 12.134
2024-07-18 13:58:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 13:58:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_35000.pt (epoch 2 @ 35000 updates, score 4.601) (writing took 4.051285669207573 seconds)
2024-07-18 13:58:29 | INFO | train_inner | epoch 002:  15536 / 19564 loss=4.605, nll_loss=3.233, ppl=9.4, wps=13248.9, ups=3.78, wpb=3506.3, bsz=159, num_updates=35100, lr=0.00016879, gnorm=1.145, train_wall=20, wall=0
2024-07-18 13:58:48 | INFO | train_inner | epoch 002:  15636 / 19564 loss=4.643, nll_loss=3.278, ppl=9.7, wps=17910.5, ups=5.11, wpb=3504.3, bsz=141.9, num_updates=35200, lr=0.00016855, gnorm=1.155, train_wall=19, wall=0
2024-07-18 13:59:08 | INFO | train_inner | epoch 002:  15736 / 19564 loss=4.624, nll_loss=3.256, ppl=9.55, wps=17174.4, ups=5.11, wpb=3357.8, bsz=145.5, num_updates=35300, lr=0.000168311, gnorm=1.197, train_wall=19, wall=0
2024-07-18 13:59:28 | INFO | train_inner | epoch 002:  15836 / 19564 loss=4.634, nll_loss=3.265, ppl=9.61, wps=17740.3, ups=5.06, wpb=3507.2, bsz=123.3, num_updates=35400, lr=0.000168073, gnorm=1.127, train_wall=20, wall=0
2024-07-18 13:59:48 | INFO | train_inner | epoch 002:  15936 / 19564 loss=4.586, nll_loss=3.213, ppl=9.27, wps=17625, ups=5.01, wpb=3518.1, bsz=148.9, num_updates=35500, lr=0.000167836, gnorm=1.133, train_wall=20, wall=0
2024-07-18 14:00:07 | INFO | train_inner | epoch 002:  16036 / 19564 loss=4.573, nll_loss=3.197, ppl=9.17, wps=17075, ups=5.12, wpb=3334.8, bsz=144.3, num_updates=35600, lr=0.0001676, gnorm=1.175, train_wall=19, wall=0
2024-07-18 14:00:27 | INFO | train_inner | epoch 002:  16136 / 19564 loss=4.55, nll_loss=3.17, ppl=9, wps=17507.1, ups=5.06, wpb=3459.2, bsz=149.7, num_updates=35700, lr=0.000167365, gnorm=1.123, train_wall=20, wall=0
2024-07-18 14:00:47 | INFO | train_inner | epoch 002:  16236 / 19564 loss=4.613, nll_loss=3.243, ppl=9.47, wps=17561.3, ups=5.1, wpb=3441.4, bsz=150, num_updates=35800, lr=0.000167132, gnorm=1.138, train_wall=19, wall=0
2024-07-18 14:01:06 | INFO | train_inner | epoch 002:  16336 / 19564 loss=4.629, nll_loss=3.262, ppl=9.59, wps=17484.1, ups=5.15, wpb=3392.9, bsz=142.2, num_updates=35900, lr=0.000166899, gnorm=1.148, train_wall=19, wall=0
2024-07-18 14:01:26 | INFO | train_inner | epoch 002:  16436 / 19564 loss=4.616, nll_loss=3.246, ppl=9.49, wps=17597.4, ups=5.11, wpb=3445.8, bsz=140.5, num_updates=36000, lr=0.000166667, gnorm=1.145, train_wall=19, wall=0
2024-07-18 14:01:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:01:28 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.588 | nll_loss 3.094 | ppl 8.54 | wps 53833.8 | wpb 2872.6 | bsz 51.2 | num_updates 36000 | best_loss 12.134
2024-07-18 14:01:28 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:01:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_36000.pt (epoch 2 @ 36000 updates, score 4.588) (writing took 4.006439029239118 seconds)
2024-07-18 14:01:52 | INFO | train_inner | epoch 002:  16536 / 19564 loss=4.607, nll_loss=3.236, ppl=9.42, wps=13195.7, ups=3.8, wpb=3471.6, bsz=143.9, num_updates=36100, lr=0.000166436, gnorm=1.165, train_wall=20, wall=0
2024-07-18 14:02:11 | INFO | train_inner | epoch 002:  16636 / 19564 loss=4.611, nll_loss=3.24, ppl=9.44, wps=16983.9, ups=5.12, wpb=3315.3, bsz=142.6, num_updates=36200, lr=0.000166206, gnorm=1.185, train_wall=19, wall=0
2024-07-18 14:02:31 | INFO | train_inner | epoch 002:  16736 / 19564 loss=4.617, nll_loss=3.246, ppl=9.49, wps=17770.4, ups=5.07, wpb=3503.8, bsz=128.6, num_updates=36300, lr=0.000165977, gnorm=1.127, train_wall=20, wall=0
2024-07-18 14:02:50 | INFO | train_inner | epoch 002:  16836 / 19564 loss=4.606, nll_loss=3.236, ppl=9.42, wps=17642, ups=5.16, wpb=3420.1, bsz=153.3, num_updates=36400, lr=0.000165748, gnorm=1.195, train_wall=19, wall=0
2024-07-18 14:03:10 | INFO | train_inner | epoch 002:  16936 / 19564 loss=4.644, nll_loss=3.278, ppl=9.7, wps=17333.1, ups=5.08, wpb=3411.3, bsz=140.4, num_updates=36500, lr=0.000165521, gnorm=1.171, train_wall=19, wall=0
2024-07-18 14:03:30 | INFO | train_inner | epoch 002:  17036 / 19564 loss=4.632, nll_loss=3.264, ppl=9.61, wps=17746.6, ups=5.08, wpb=3490.3, bsz=135, num_updates=36600, lr=0.000165295, gnorm=1.16, train_wall=19, wall=0
2024-07-18 14:03:49 | INFO | train_inner | epoch 002:  17136 / 19564 loss=4.68, nll_loss=3.32, ppl=9.99, wps=17216.2, ups=5.11, wpb=3371.7, bsz=134.9, num_updates=36700, lr=0.00016507, gnorm=1.18, train_wall=19, wall=0
2024-07-18 14:04:09 | INFO | train_inner | epoch 002:  17236 / 19564 loss=4.627, nll_loss=3.259, ppl=9.57, wps=17624.5, ups=5.03, wpb=3500.8, bsz=144.3, num_updates=36800, lr=0.000164845, gnorm=1.149, train_wall=20, wall=0
2024-07-18 14:04:29 | INFO | train_inner | epoch 002:  17336 / 19564 loss=4.57, nll_loss=3.193, ppl=9.15, wps=17667, ups=5.1, wpb=3462.2, bsz=132.5, num_updates=36900, lr=0.000164622, gnorm=1.13, train_wall=19, wall=0
2024-07-18 14:04:48 | INFO | train_inner | epoch 002:  17436 / 19564 loss=4.588, nll_loss=3.215, ppl=9.28, wps=17490.3, ups=5.1, wpb=3432, bsz=148.6, num_updates=37000, lr=0.000164399, gnorm=1.171, train_wall=19, wall=0
2024-07-18 14:04:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:04:51 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.584 | nll_loss 3.103 | ppl 8.59 | wps 53975 | wpb 2872.6 | bsz 51.2 | num_updates 37000 | best_loss 12.134
2024-07-18 14:04:51 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:05:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_37000.pt (epoch 2 @ 37000 updates, score 4.584) (writing took 9.942706909961998 seconds)
2024-07-18 14:05:21 | INFO | train_inner | epoch 002:  17536 / 19564 loss=4.609, nll_loss=3.238, ppl=9.44, wps=10856.7, ups=3.11, wpb=3494.2, bsz=139, num_updates=37100, lr=0.000164177, gnorm=1.145, train_wall=20, wall=0
2024-07-18 14:05:41 | INFO | train_inner | epoch 002:  17636 / 19564 loss=4.513, nll_loss=3.129, ppl=8.75, wps=17546.6, ups=5.03, wpb=3487.9, bsz=161.9, num_updates=37200, lr=0.000163956, gnorm=1.091, train_wall=20, wall=0
2024-07-18 14:06:00 | INFO | train_inner | epoch 002:  17736 / 19564 loss=4.562, nll_loss=3.185, ppl=9.09, wps=17387.6, ups=5.09, wpb=3414.4, bsz=137.4, num_updates=37300, lr=0.000163737, gnorm=1.163, train_wall=19, wall=0
2024-07-18 14:06:20 | INFO | train_inner | epoch 002:  17836 / 19564 loss=4.602, nll_loss=3.231, ppl=9.39, wps=17338.2, ups=5.11, wpb=3392.2, bsz=139, num_updates=37400, lr=0.000163517, gnorm=1.164, train_wall=19, wall=0
2024-07-18 14:06:39 | INFO | train_inner | epoch 002:  17936 / 19564 loss=4.603, nll_loss=3.231, ppl=9.39, wps=17426.8, ups=5.08, wpb=3428.8, bsz=138.6, num_updates=37500, lr=0.000163299, gnorm=1.137, train_wall=19, wall=0
2024-07-18 14:06:59 | INFO | train_inner | epoch 002:  18036 / 19564 loss=4.559, nll_loss=3.182, ppl=9.07, wps=17550.2, ups=5.06, wpb=3467.5, bsz=147.5, num_updates=37600, lr=0.000163082, gnorm=1.127, train_wall=20, wall=0
2024-07-18 14:07:19 | INFO | train_inner | epoch 002:  18136 / 19564 loss=4.633, nll_loss=3.266, ppl=9.62, wps=17527.9, ups=5.14, wpb=3411.7, bsz=138, num_updates=37700, lr=0.000162866, gnorm=1.179, train_wall=19, wall=0
2024-07-18 14:07:38 | INFO | train_inner | epoch 002:  18236 / 19564 loss=4.592, nll_loss=3.221, ppl=9.32, wps=17445.3, ups=5.14, wpb=3395, bsz=137.6, num_updates=37800, lr=0.00016265, gnorm=1.17, train_wall=19, wall=0
2024-07-18 14:07:58 | INFO | train_inner | epoch 002:  18336 / 19564 loss=4.543, nll_loss=3.163, ppl=8.96, wps=17551.7, ups=5.12, wpb=3427.3, bsz=145.8, num_updates=37900, lr=0.000162435, gnorm=1.111, train_wall=19, wall=0
2024-07-18 14:08:17 | INFO | train_inner | epoch 002:  18436 / 19564 loss=4.603, nll_loss=3.233, ppl=9.4, wps=17634.7, ups=5.09, wpb=3464.6, bsz=148, num_updates=38000, lr=0.000162221, gnorm=1.152, train_wall=19, wall=0
2024-07-18 14:08:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:08:20 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.56 | nll_loss 3.069 | ppl 8.39 | wps 54318.1 | wpb 2872.6 | bsz 51.2 | num_updates 38000 | best_loss 12.134
2024-07-18 14:08:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:08:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_38000.pt (epoch 2 @ 38000 updates, score 4.56) (writing took 3.890003868378699 seconds)
2024-07-18 14:08:43 | INFO | train_inner | epoch 002:  18536 / 19564 loss=4.6, nll_loss=3.228, ppl=9.37, wps=13191.6, ups=3.88, wpb=3400.3, bsz=136.8, num_updates=38100, lr=0.000162008, gnorm=1.171, train_wall=19, wall=0
2024-07-18 14:09:03 | INFO | train_inner | epoch 002:  18636 / 19564 loss=4.559, nll_loss=3.182, ppl=9.07, wps=17348.6, ups=5.03, wpb=3447, bsz=128.8, num_updates=38200, lr=0.000161796, gnorm=1.136, train_wall=20, wall=0
2024-07-18 14:09:23 | INFO | train_inner | epoch 002:  18736 / 19564 loss=4.564, nll_loss=3.187, ppl=9.11, wps=17515, ups=5.04, wpb=3474.7, bsz=145.3, num_updates=38300, lr=0.000161585, gnorm=1.113, train_wall=20, wall=0
2024-07-18 14:09:43 | INFO | train_inner | epoch 002:  18836 / 19564 loss=4.608, nll_loss=3.238, ppl=9.43, wps=17534.4, ups=5.06, wpb=3463.3, bsz=136.2, num_updates=38400, lr=0.000161374, gnorm=1.158, train_wall=20, wall=0
2024-07-18 14:10:02 | INFO | train_inner | epoch 002:  18936 / 19564 loss=4.579, nll_loss=3.205, ppl=9.22, wps=17310.1, ups=5.03, wpb=3440.5, bsz=133.1, num_updates=38500, lr=0.000161165, gnorm=1.161, train_wall=20, wall=0
2024-07-18 14:10:22 | INFO | train_inner | epoch 002:  19036 / 19564 loss=4.601, nll_loss=3.23, ppl=9.38, wps=17398, ups=5.06, wpb=3436.9, bsz=140.1, num_updates=38600, lr=0.000160956, gnorm=1.163, train_wall=20, wall=0
2024-07-18 14:10:42 | INFO | train_inner | epoch 002:  19136 / 19564 loss=4.497, nll_loss=3.112, ppl=8.65, wps=17403.4, ups=5.05, wpb=3447.5, bsz=156.9, num_updates=38700, lr=0.000160748, gnorm=1.109, train_wall=20, wall=0
2024-07-18 14:11:02 | INFO | train_inner | epoch 002:  19236 / 19564 loss=4.544, nll_loss=3.165, ppl=8.97, wps=17431.8, ups=5.1, wpb=3417.4, bsz=136.9, num_updates=38800, lr=0.00016054, gnorm=1.148, train_wall=19, wall=0
2024-07-18 14:11:21 | INFO | train_inner | epoch 002:  19336 / 19564 loss=4.532, nll_loss=3.151, ppl=8.88, wps=17578.9, ups=5.09, wpb=3452.4, bsz=145.6, num_updates=38900, lr=0.000160334, gnorm=1.14, train_wall=19, wall=0
2024-07-18 14:11:41 | INFO | train_inner | epoch 002:  19436 / 19564 loss=4.588, nll_loss=3.215, ppl=9.29, wps=17244.1, ups=5.04, wpb=3424.2, bsz=143.1, num_updates=39000, lr=0.000160128, gnorm=1.158, train_wall=20, wall=0
2024-07-18 14:11:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:11:43 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.52 | nll_loss 3.035 | ppl 8.2 | wps 53894.8 | wpb 2872.6 | bsz 51.2 | num_updates 39000 | best_loss 12.134
2024-07-18 14:11:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:11:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_2_39000.pt (epoch 2 @ 39000 updates, score 4.52) (writing took 4.256620125845075 seconds)
2024-07-18 14:12:08 | INFO | train_inner | epoch 002:  19536 / 19564 loss=4.544, nll_loss=3.166, ppl=8.97, wps=13034, ups=3.77, wpb=3461.3, bsz=132.6, num_updates=39100, lr=0.000159923, gnorm=1.135, train_wall=20, wall=0
2024-07-18 14:12:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:12:16 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.531 | nll_loss 3.039 | ppl 8.22 | wps 54084.9 | wpb 2872.6 | bsz 51.2 | num_updates 39128 | best_loss 12.134
2024-07-18 14:12:16 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:12:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 2 @ 39128 updates, score 4.531) (writing took 3.696982386521995 seconds)
2024-07-18 14:12:19 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2024-07-18 14:12:19 | INFO | train | epoch 002 | loss 4.705 | nll_loss 3.343 | ppl 10.15 | wps 16941.1 | ups 4.92 | wpb 3446.5 | bsz 142.2 | num_updates 39128 | lr 0.000159866 | gnorm 1.152 | train_wall 3801 | wall 0
2024-07-18 14:12:19 | INFO | fairseq.trainer | begin training epoch 3
2024-07-18 14:12:33 | INFO | train_inner | epoch 003:     72 / 19564 loss=4.507, nll_loss=3.123, ppl=8.71, wps=13460.6, ups=3.88, wpb=3469.4, bsz=151.2, num_updates=39200, lr=0.000159719, gnorm=1.128, train_wall=19, wall=0
2024-07-18 14:12:53 | INFO | train_inner | epoch 003:    172 / 19564 loss=4.516, nll_loss=3.133, ppl=8.77, wps=17305.1, ups=5.1, wpb=3395.9, bsz=131.7, num_updates=39300, lr=0.000159516, gnorm=1.141, train_wall=19, wall=0
2024-07-18 14:13:13 | INFO | train_inner | epoch 003:    272 / 19564 loss=4.488, nll_loss=3.101, ppl=8.58, wps=17496.1, ups=5.07, wpb=3452.5, bsz=147.5, num_updates=39400, lr=0.000159313, gnorm=1.118, train_wall=20, wall=0
2024-07-18 14:13:32 | INFO | train_inner | epoch 003:    372 / 19564 loss=4.48, nll_loss=3.091, ppl=8.52, wps=17487.6, ups=5.07, wpb=3451.2, bsz=131.2, num_updates=39500, lr=0.000159111, gnorm=1.126, train_wall=20, wall=0
2024-07-18 14:13:52 | INFO | train_inner | epoch 003:    472 / 19564 loss=4.585, nll_loss=3.212, ppl=9.26, wps=17761.2, ups=5.11, wpb=3474.5, bsz=122.8, num_updates=39600, lr=0.00015891, gnorm=1.147, train_wall=19, wall=0
2024-07-18 14:14:12 | INFO | train_inner | epoch 003:    572 / 19564 loss=4.501, nll_loss=3.117, ppl=8.67, wps=17772.1, ups=5.11, wpb=3476.7, bsz=149.8, num_updates=39700, lr=0.00015871, gnorm=1.118, train_wall=19, wall=0
2024-07-18 14:14:31 | INFO | train_inner | epoch 003:    672 / 19564 loss=4.552, nll_loss=3.174, ppl=9.03, wps=17782.5, ups=5.12, wpb=3469.9, bsz=153.8, num_updates=39800, lr=0.000158511, gnorm=1.147, train_wall=19, wall=0
2024-07-18 14:14:50 | INFO | train_inner | epoch 003:    772 / 19564 loss=4.581, nll_loss=3.207, ppl=9.24, wps=17689.5, ups=5.17, wpb=3418.7, bsz=133.2, num_updates=39900, lr=0.000158312, gnorm=1.151, train_wall=19, wall=0
2024-07-18 14:15:10 | INFO | train_inner | epoch 003:    872 / 19564 loss=4.516, nll_loss=3.135, ppl=8.78, wps=17077.7, ups=5.08, wpb=3360.2, bsz=152.8, num_updates=40000, lr=0.000158114, gnorm=1.152, train_wall=19, wall=0
2024-07-18 14:15:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:15:12 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.546 | nll_loss 3.07 | ppl 8.4 | wps 55180.3 | wpb 2872.6 | bsz 51.2 | num_updates 40000 | best_loss 12.134
2024-07-18 14:15:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:15:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_40000.pt (epoch 3 @ 40000 updates, score 4.546) (writing took 4.2681918032467365 seconds)
2024-07-18 14:15:36 | INFO | train_inner | epoch 003:    972 / 19564 loss=4.493, nll_loss=3.108, ppl=8.62, wps=13349, ups=3.8, wpb=3512.5, bsz=169.6, num_updates=40100, lr=0.000157917, gnorm=1.111, train_wall=19, wall=0
2024-07-18 14:15:56 | INFO | train_inner | epoch 003:   1072 / 19564 loss=4.619, nll_loss=3.25, ppl=9.52, wps=17771, ups=5.1, wpb=3482.7, bsz=132.6, num_updates=40200, lr=0.00015772, gnorm=1.184, train_wall=19, wall=0
2024-07-18 14:16:16 | INFO | train_inner | epoch 003:   1172 / 19564 loss=4.519, nll_loss=3.137, ppl=8.8, wps=17766.9, ups=5.11, wpb=3478.4, bsz=158.6, num_updates=40300, lr=0.000157524, gnorm=1.131, train_wall=19, wall=0
2024-07-18 14:16:36 | INFO | train_inner | epoch 003:   1272 / 19564 loss=4.505, nll_loss=3.12, ppl=8.7, wps=17814.1, ups=5.01, wpb=3555.9, bsz=140.6, num_updates=40400, lr=0.000157329, gnorm=1.1, train_wall=20, wall=0
2024-07-18 14:16:55 | INFO | train_inner | epoch 003:   1372 / 19564 loss=4.619, nll_loss=3.25, ppl=9.52, wps=17207.2, ups=5.14, wpb=3350.5, bsz=128.7, num_updates=40500, lr=0.000157135, gnorm=1.166, train_wall=19, wall=0
2024-07-18 14:17:15 | INFO | train_inner | epoch 003:   1472 / 19564 loss=4.555, nll_loss=3.178, ppl=9.05, wps=17400.2, ups=5.06, wpb=3437.4, bsz=128.3, num_updates=40600, lr=0.000156941, gnorm=1.146, train_wall=20, wall=0
2024-07-18 14:17:34 | INFO | train_inner | epoch 003:   1572 / 19564 loss=4.542, nll_loss=3.163, ppl=8.96, wps=17462.2, ups=5.16, wpb=3383.3, bsz=135.8, num_updates=40700, lr=0.000156748, gnorm=1.159, train_wall=19, wall=0
2024-07-18 14:17:54 | INFO | train_inner | epoch 003:   1672 / 19564 loss=4.512, nll_loss=3.129, ppl=8.75, wps=17388.1, ups=5.13, wpb=3390.1, bsz=146.4, num_updates=40800, lr=0.000156556, gnorm=1.188, train_wall=19, wall=0
2024-07-18 14:18:13 | INFO | train_inner | epoch 003:   1772 / 19564 loss=4.489, nll_loss=3.102, ppl=8.59, wps=17706, ups=5.1, wpb=3471.6, bsz=131.7, num_updates=40900, lr=0.000156365, gnorm=1.141, train_wall=19, wall=0
2024-07-18 14:18:33 | INFO | train_inner | epoch 003:   1872 / 19564 loss=4.525, nll_loss=3.144, ppl=8.84, wps=17647.3, ups=5.09, wpb=3470.3, bsz=151.2, num_updates=41000, lr=0.000156174, gnorm=1.115, train_wall=19, wall=0
2024-07-18 14:18:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:18:35 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.503 | nll_loss 3.011 | ppl 8.06 | wps 54103.5 | wpb 2872.6 | bsz 51.2 | num_updates 41000 | best_loss 12.134
2024-07-18 14:18:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:18:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_41000.pt (epoch 3 @ 41000 updates, score 4.503) (writing took 4.464828155934811 seconds)
2024-07-18 14:19:00 | INFO | train_inner | epoch 003:   1972 / 19564 loss=4.515, nll_loss=3.132, ppl=8.77, wps=12838.3, ups=3.75, wpb=3426.9, bsz=137.4, num_updates=41100, lr=0.000155984, gnorm=1.147, train_wall=20, wall=0
2024-07-18 14:19:20 | INFO | train_inner | epoch 003:   2072 / 19564 loss=4.515, nll_loss=3.133, ppl=8.77, wps=17418.7, ups=5.04, wpb=3457.7, bsz=143.6, num_updates=41200, lr=0.000155794, gnorm=1.13, train_wall=20, wall=0
2024-07-18 14:19:39 | INFO | train_inner | epoch 003:   2172 / 19564 loss=4.49, nll_loss=3.104, ppl=8.6, wps=17359.4, ups=5.11, wpb=3394.1, bsz=151.1, num_updates=41300, lr=0.000155606, gnorm=1.156, train_wall=19, wall=0
2024-07-18 14:19:59 | INFO | train_inner | epoch 003:   2272 / 19564 loss=4.463, nll_loss=3.073, ppl=8.42, wps=17856, ups=5.11, wpb=3491.2, bsz=147.6, num_updates=41400, lr=0.000155417, gnorm=1.126, train_wall=19, wall=0
2024-07-18 14:20:18 | INFO | train_inner | epoch 003:   2372 / 19564 loss=4.469, nll_loss=3.08, ppl=8.46, wps=17644.2, ups=5.12, wpb=3444.2, bsz=155.1, num_updates=41500, lr=0.00015523, gnorm=1.115, train_wall=19, wall=0
2024-07-18 14:20:38 | INFO | train_inner | epoch 003:   2472 / 19564 loss=4.51, nll_loss=3.127, ppl=8.73, wps=17411.1, ups=5.08, wpb=3427.9, bsz=141.5, num_updates=41600, lr=0.000155043, gnorm=1.179, train_wall=19, wall=0
2024-07-18 14:20:58 | INFO | train_inner | epoch 003:   2572 / 19564 loss=4.473, nll_loss=3.085, ppl=8.48, wps=17711.9, ups=5.07, wpb=3494.8, bsz=144.2, num_updates=41700, lr=0.000154857, gnorm=1.119, train_wall=20, wall=0
2024-07-18 14:21:17 | INFO | train_inner | epoch 003:   2672 / 19564 loss=4.541, nll_loss=3.163, ppl=8.95, wps=17524.7, ups=5.09, wpb=3445, bsz=149.6, num_updates=41800, lr=0.000154672, gnorm=1.178, train_wall=19, wall=0
2024-07-18 14:21:37 | INFO | train_inner | epoch 003:   2772 / 19564 loss=4.488, nll_loss=3.103, ppl=8.59, wps=17554.1, ups=5.08, wpb=3453.4, bsz=142.2, num_updates=41900, lr=0.000154487, gnorm=1.128, train_wall=19, wall=0
2024-07-18 14:21:57 | INFO | train_inner | epoch 003:   2872 / 19564 loss=4.534, nll_loss=3.153, ppl=8.89, wps=17331, ups=5.06, wpb=3423, bsz=133.3, num_updates=42000, lr=0.000154303, gnorm=1.135, train_wall=20, wall=0
2024-07-18 14:21:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:21:59 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.495 | nll_loss 3 | ppl 8 | wps 54189.4 | wpb 2872.6 | bsz 51.2 | num_updates 42000 | best_loss 12.134
2024-07-18 14:21:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:22:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_42000.pt (epoch 3 @ 42000 updates, score 4.495) (writing took 3.933423408307135 seconds)
2024-07-18 14:22:23 | INFO | train_inner | epoch 003:   2972 / 19564 loss=4.506, nll_loss=3.123, ppl=8.71, wps=13519.2, ups=3.83, wpb=3530.4, bsz=145.1, num_updates=42100, lr=0.00015412, gnorm=1.13, train_wall=20, wall=0
2024-07-18 14:22:43 | INFO | train_inner | epoch 003:   3072 / 19564 loss=4.545, nll_loss=3.167, ppl=8.98, wps=17307.8, ups=5.04, wpb=3434, bsz=132.6, num_updates=42200, lr=0.000153937, gnorm=1.143, train_wall=20, wall=0
2024-07-18 14:23:02 | INFO | train_inner | epoch 003:   3172 / 19564 loss=4.549, nll_loss=3.174, ppl=9.02, wps=16835.6, ups=5.14, wpb=3272.7, bsz=140.6, num_updates=42300, lr=0.000153755, gnorm=1.237, train_wall=19, wall=0
2024-07-18 14:23:22 | INFO | train_inner | epoch 003:   3272 / 19564 loss=4.501, nll_loss=3.116, ppl=8.67, wps=17660.7, ups=5.03, wpb=3511.6, bsz=146.6, num_updates=42400, lr=0.000153574, gnorm=1.12, train_wall=20, wall=0
2024-07-18 14:23:42 | INFO | train_inner | epoch 003:   3372 / 19564 loss=4.531, nll_loss=3.152, ppl=8.89, wps=17878.7, ups=5.09, wpb=3509.9, bsz=149.4, num_updates=42500, lr=0.000153393, gnorm=1.138, train_wall=19, wall=0
2024-07-18 14:24:01 | INFO | train_inner | epoch 003:   3472 / 19564 loss=4.439, nll_loss=3.046, ppl=8.26, wps=17599.6, ups=5.02, wpb=3508, bsz=149, num_updates=42600, lr=0.000153213, gnorm=1.109, train_wall=20, wall=0
2024-07-18 14:24:21 | INFO | train_inner | epoch 003:   3572 / 19564 loss=4.526, nll_loss=3.147, ppl=8.86, wps=17040.9, ups=5.05, wpb=3371.9, bsz=139.8, num_updates=42700, lr=0.000153033, gnorm=1.161, train_wall=20, wall=0
2024-07-18 14:24:41 | INFO | train_inner | epoch 003:   3672 / 19564 loss=4.509, nll_loss=3.127, ppl=8.73, wps=17354.6, ups=5.08, wpb=3414, bsz=136.5, num_updates=42800, lr=0.000152854, gnorm=1.15, train_wall=19, wall=0
2024-07-18 14:25:01 | INFO | train_inner | epoch 003:   3772 / 19564 loss=4.521, nll_loss=3.139, ppl=8.81, wps=17114.3, ups=5.1, wpb=3354.8, bsz=140.1, num_updates=42900, lr=0.000152676, gnorm=1.181, train_wall=19, wall=0
2024-07-18 14:25:21 | INFO | train_inner | epoch 003:   3872 / 19564 loss=4.496, nll_loss=3.112, ppl=8.65, wps=16795.2, ups=4.98, wpb=3369.5, bsz=139.3, num_updates=43000, lr=0.000152499, gnorm=1.197, train_wall=20, wall=0
2024-07-18 14:25:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:25:23 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.505 | nll_loss 3.017 | ppl 8.09 | wps 54019.8 | wpb 2872.6 | bsz 51.2 | num_updates 43000 | best_loss 12.134
2024-07-18 14:25:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:25:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_43000.pt (epoch 3 @ 43000 updates, score 4.505) (writing took 3.97838026098907 seconds)
2024-07-18 14:25:46 | INFO | train_inner | epoch 003:   3972 / 19564 loss=4.563, nll_loss=3.188, ppl=9.11, wps=12957.8, ups=3.88, wpb=3336.4, bsz=138, num_updates=43100, lr=0.000152322, gnorm=1.185, train_wall=19, wall=0
2024-07-18 14:26:06 | INFO | train_inner | epoch 003:   4072 / 19564 loss=4.539, nll_loss=3.16, ppl=8.94, wps=17696.5, ups=5.1, wpb=3471.6, bsz=140.2, num_updates=43200, lr=0.000152145, gnorm=1.125, train_wall=19, wall=0
2024-07-18 14:26:26 | INFO | train_inner | epoch 003:   4172 / 19564 loss=4.449, nll_loss=3.058, ppl=8.33, wps=17676.4, ups=5.08, wpb=3477.9, bsz=145, num_updates=43300, lr=0.000151969, gnorm=1.109, train_wall=19, wall=0
2024-07-18 14:26:45 | INFO | train_inner | epoch 003:   4272 / 19564 loss=4.494, nll_loss=3.111, ppl=8.64, wps=17855.7, ups=5.1, wpb=3502.7, bsz=165.2, num_updates=43400, lr=0.000151794, gnorm=1.124, train_wall=19, wall=0
2024-07-18 14:27:05 | INFO | train_inner | epoch 003:   4372 / 19564 loss=4.578, nll_loss=3.205, ppl=9.22, wps=17759.6, ups=5.13, wpb=3463.4, bsz=127.4, num_updates=43500, lr=0.00015162, gnorm=1.141, train_wall=19, wall=0
2024-07-18 14:27:24 | INFO | train_inner | epoch 003:   4472 / 19564 loss=4.488, nll_loss=3.103, ppl=8.59, wps=17482.6, ups=5.14, wpb=3401.3, bsz=146.4, num_updates=43600, lr=0.000151446, gnorm=1.134, train_wall=19, wall=0
2024-07-18 14:27:44 | INFO | train_inner | epoch 003:   4572 / 19564 loss=4.428, nll_loss=3.035, ppl=8.19, wps=17558.6, ups=5.11, wpb=3435.2, bsz=161.1, num_updates=43700, lr=0.000151272, gnorm=1.118, train_wall=19, wall=0
2024-07-18 14:28:03 | INFO | train_inner | epoch 003:   4672 / 19564 loss=4.507, nll_loss=3.127, ppl=8.73, wps=17694.8, ups=5.08, wpb=3481.3, bsz=160.5, num_updates=43800, lr=0.000151099, gnorm=1.147, train_wall=19, wall=0
2024-07-18 14:28:23 | INFO | train_inner | epoch 003:   4772 / 19564 loss=4.497, nll_loss=3.112, ppl=8.65, wps=17640.6, ups=5.08, wpb=3473.3, bsz=140.7, num_updates=43900, lr=0.000150927, gnorm=1.115, train_wall=19, wall=0
2024-07-18 14:28:43 | INFO | train_inner | epoch 003:   4872 / 19564 loss=4.51, nll_loss=3.127, ppl=8.74, wps=17559.5, ups=5.11, wpb=3435.3, bsz=130, num_updates=44000, lr=0.000150756, gnorm=1.163, train_wall=19, wall=0
2024-07-18 14:28:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:28:45 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.473 | nll_loss 2.975 | ppl 7.86 | wps 53804.9 | wpb 2872.6 | bsz 51.2 | num_updates 44000 | best_loss 12.134
2024-07-18 14:28:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:28:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_44000.pt (epoch 3 @ 44000 updates, score 4.473) (writing took 4.243278653360903 seconds)
2024-07-18 14:29:09 | INFO | train_inner | epoch 003:   4972 / 19564 loss=4.529, nll_loss=3.15, ppl=8.88, wps=12727.7, ups=3.81, wpb=3341.6, bsz=137.5, num_updates=44100, lr=0.000150585, gnorm=1.15, train_wall=19, wall=0
2024-07-18 14:29:29 | INFO | train_inner | epoch 003:   5072 / 19564 loss=4.448, nll_loss=3.058, ppl=8.33, wps=17455.6, ups=5.11, wpb=3418.4, bsz=148.8, num_updates=44200, lr=0.000150414, gnorm=1.136, train_wall=19, wall=0
2024-07-18 14:29:48 | INFO | train_inner | epoch 003:   5172 / 19564 loss=4.531, nll_loss=3.151, ppl=8.88, wps=17717.8, ups=5.03, wpb=3523.3, bsz=130.6, num_updates=44300, lr=0.000150244, gnorm=1.133, train_wall=20, wall=0
2024-07-18 14:30:08 | INFO | train_inner | epoch 003:   5272 / 19564 loss=4.519, nll_loss=3.139, ppl=8.81, wps=17474.1, ups=5.08, wpb=3440.1, bsz=150.9, num_updates=44400, lr=0.000150075, gnorm=1.177, train_wall=19, wall=0
2024-07-18 14:30:28 | INFO | train_inner | epoch 003:   5372 / 19564 loss=4.488, nll_loss=3.103, ppl=8.59, wps=17655.6, ups=5.1, wpb=3463.6, bsz=160.9, num_updates=44500, lr=0.000149906, gnorm=1.168, train_wall=19, wall=0
2024-07-18 14:30:48 | INFO | train_inner | epoch 003:   5472 / 19564 loss=4.532, nll_loss=3.154, ppl=8.9, wps=17384.4, ups=5.02, wpb=3465.9, bsz=149, num_updates=44600, lr=0.000149738, gnorm=1.14, train_wall=20, wall=0
2024-07-18 14:31:07 | INFO | train_inner | epoch 003:   5572 / 19564 loss=4.508, nll_loss=3.127, ppl=8.73, wps=17529.5, ups=5.12, wpb=3421.3, bsz=153.8, num_updates=44700, lr=0.000149571, gnorm=1.158, train_wall=19, wall=0
2024-07-18 14:31:27 | INFO | train_inner | epoch 003:   5672 / 19564 loss=4.519, nll_loss=3.139, ppl=8.81, wps=17514.2, ups=5.06, wpb=3459, bsz=143.3, num_updates=44800, lr=0.000149404, gnorm=1.146, train_wall=20, wall=0
2024-07-18 14:31:47 | INFO | train_inner | epoch 003:   5772 / 19564 loss=4.524, nll_loss=3.145, ppl=8.84, wps=17411.2, ups=5.02, wpb=3470.2, bsz=145.3, num_updates=44900, lr=0.000149237, gnorm=1.157, train_wall=20, wall=0
2024-07-18 14:32:07 | INFO | train_inner | epoch 003:   5872 / 19564 loss=4.458, nll_loss=3.069, ppl=8.39, wps=17656.3, ups=5.05, wpb=3497.1, bsz=150.9, num_updates=45000, lr=0.000149071, gnorm=1.128, train_wall=20, wall=0
2024-07-18 14:32:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:32:09 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.461 | nll_loss 2.963 | ppl 7.8 | wps 54230.5 | wpb 2872.6 | bsz 51.2 | num_updates 45000 | best_loss 12.134
2024-07-18 14:32:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:32:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_45000.pt (epoch 3 @ 45000 updates, score 4.461) (writing took 3.857437073253095 seconds)
2024-07-18 14:32:33 | INFO | train_inner | epoch 003:   5972 / 19564 loss=4.512, nll_loss=3.132, ppl=8.77, wps=13362.6, ups=3.88, wpb=3447.9, bsz=156.7, num_updates=45100, lr=0.000148906, gnorm=1.195, train_wall=19, wall=0
2024-07-18 14:32:52 | INFO | train_inner | epoch 003:   6072 / 19564 loss=4.529, nll_loss=3.152, ppl=8.89, wps=17732.6, ups=5.13, wpb=3455.2, bsz=150.7, num_updates=45200, lr=0.000148741, gnorm=1.148, train_wall=19, wall=0
2024-07-18 14:33:12 | INFO | train_inner | epoch 003:   6172 / 19564 loss=4.577, nll_loss=3.205, ppl=9.22, wps=17787.5, ups=5.11, wpb=3483, bsz=144.7, num_updates=45300, lr=0.000148577, gnorm=1.13, train_wall=19, wall=0
2024-07-18 14:33:31 | INFO | train_inner | epoch 003:   6272 / 19564 loss=4.576, nll_loss=3.204, ppl=9.22, wps=17300.2, ups=5.18, wpb=3342.4, bsz=134.9, num_updates=45400, lr=0.000148413, gnorm=1.185, train_wall=19, wall=0
2024-07-18 14:33:51 | INFO | train_inner | epoch 003:   6372 / 19564 loss=4.515, nll_loss=3.134, ppl=8.78, wps=17487.1, ups=5.07, wpb=3449.1, bsz=145.8, num_updates=45500, lr=0.00014825, gnorm=1.179, train_wall=19, wall=0
2024-07-18 14:34:10 | INFO | train_inner | epoch 003:   6472 / 19564 loss=4.532, nll_loss=3.155, ppl=8.91, wps=17055.7, ups=5.15, wpb=3314.1, bsz=151, num_updates=45600, lr=0.000148087, gnorm=1.186, train_wall=19, wall=0
2024-07-18 14:34:30 | INFO | train_inner | epoch 003:   6572 / 19564 loss=4.474, nll_loss=3.086, ppl=8.49, wps=17282.3, ups=5, wpb=3458.6, bsz=148.4, num_updates=45700, lr=0.000147925, gnorm=1.137, train_wall=20, wall=0
2024-07-18 14:34:50 | INFO | train_inner | epoch 003:   6672 / 19564 loss=4.532, nll_loss=3.153, ppl=8.89, wps=17790.7, ups=5.12, wpb=3477.6, bsz=134, num_updates=45800, lr=0.000147764, gnorm=1.135, train_wall=19, wall=0
2024-07-18 14:35:09 | INFO | train_inner | epoch 003:   6772 / 19564 loss=4.505, nll_loss=3.123, ppl=8.71, wps=17493.7, ups=5.04, wpb=3468.6, bsz=144, num_updates=45900, lr=0.000147602, gnorm=1.119, train_wall=20, wall=0
2024-07-18 14:35:29 | INFO | train_inner | epoch 003:   6872 / 19564 loss=4.528, nll_loss=3.151, ppl=8.88, wps=17509.1, ups=5.12, wpb=3420.8, bsz=148.1, num_updates=46000, lr=0.000147442, gnorm=1.215, train_wall=19, wall=0
2024-07-18 14:35:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:35:31 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.458 | nll_loss 2.966 | ppl 7.82 | wps 53866.7 | wpb 2872.6 | bsz 51.2 | num_updates 46000 | best_loss 12.134
2024-07-18 14:35:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:35:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_46000.pt (epoch 3 @ 46000 updates, score 4.458) (writing took 4.090829132124782 seconds)
2024-07-18 14:35:55 | INFO | train_inner | epoch 003:   6972 / 19564 loss=4.496, nll_loss=3.113, ppl=8.65, wps=13202.4, ups=3.8, wpb=3475.9, bsz=137, num_updates=46100, lr=0.000147282, gnorm=1.114, train_wall=20, wall=0
2024-07-18 14:36:15 | INFO | train_inner | epoch 003:   7072 / 19564 loss=4.568, nll_loss=3.194, ppl=9.15, wps=17605.1, ups=5.13, wpb=3429.3, bsz=125.6, num_updates=46200, lr=0.000147122, gnorm=1.199, train_wall=19, wall=0
2024-07-18 14:36:34 | INFO | train_inner | epoch 003:   7172 / 19564 loss=4.513, nll_loss=3.132, ppl=8.77, wps=17884.4, ups=5.1, wpb=3508.9, bsz=138.6, num_updates=46300, lr=0.000146964, gnorm=1.125, train_wall=19, wall=0
2024-07-18 14:36:54 | INFO | train_inner | epoch 003:   7272 / 19564 loss=4.482, nll_loss=3.098, ppl=8.56, wps=17828, ups=5.11, wpb=3491.3, bsz=149.7, num_updates=46400, lr=0.000146805, gnorm=1.131, train_wall=19, wall=0
2024-07-18 14:37:14 | INFO | train_inner | epoch 003:   7372 / 19564 loss=4.527, nll_loss=3.148, ppl=8.86, wps=17384.7, ups=5.08, wpb=3419.8, bsz=138, num_updates=46500, lr=0.000146647, gnorm=1.163, train_wall=19, wall=0
2024-07-18 14:37:33 | INFO | train_inner | epoch 003:   7472 / 19564 loss=4.498, nll_loss=3.115, ppl=8.66, wps=17758.4, ups=5.11, wpb=3476.1, bsz=130.4, num_updates=46600, lr=0.00014649, gnorm=1.131, train_wall=19, wall=0
2024-07-18 14:37:53 | INFO | train_inner | epoch 003:   7572 / 19564 loss=4.439, nll_loss=3.048, ppl=8.27, wps=17560.7, ups=5.06, wpb=3471, bsz=148.1, num_updates=46700, lr=0.000146333, gnorm=1.124, train_wall=20, wall=0
2024-07-18 14:38:14 | INFO | train_inner | epoch 003:   7672 / 19564 loss=4.461, nll_loss=3.074, ppl=8.42, wps=16649.7, ups=4.82, wpb=3453.8, bsz=155, num_updates=46800, lr=0.000146176, gnorm=1.146, train_wall=21, wall=0
2024-07-18 14:38:34 | INFO | train_inner | epoch 003:   7772 / 19564 loss=4.509, nll_loss=3.128, ppl=8.74, wps=17587, ups=5.01, wpb=3511.2, bsz=139.3, num_updates=46900, lr=0.00014602, gnorm=1.121, train_wall=20, wall=0
2024-07-18 14:38:53 | INFO | train_inner | epoch 003:   7872 / 19564 loss=4.389, nll_loss=2.991, ppl=7.95, wps=17537.2, ups=5.06, wpb=3466.4, bsz=155.2, num_updates=47000, lr=0.000145865, gnorm=1.077, train_wall=20, wall=0
2024-07-18 14:38:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:38:56 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.438 | nll_loss 2.939 | ppl 7.67 | wps 54173.2 | wpb 2872.6 | bsz 51.2 | num_updates 47000 | best_loss 12.134
2024-07-18 14:38:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:39:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_47000.pt (epoch 3 @ 47000 updates, score 4.438) (writing took 5.162580185569823 seconds)
2024-07-18 14:39:21 | INFO | train_inner | epoch 003:   7972 / 19564 loss=4.462, nll_loss=3.075, ppl=8.43, wps=12518.3, ups=3.64, wpb=3439.9, bsz=157.8, num_updates=47100, lr=0.00014571, gnorm=1.165, train_wall=20, wall=0
2024-07-18 14:39:41 | INFO | train_inner | epoch 003:   8072 / 19564 loss=4.53, nll_loss=3.153, ppl=8.89, wps=17222.2, ups=5.02, wpb=3432.2, bsz=136.2, num_updates=47200, lr=0.000145556, gnorm=1.141, train_wall=20, wall=0
2024-07-18 14:40:01 | INFO | train_inner | epoch 003:   8172 / 19564 loss=4.428, nll_loss=3.036, ppl=8.2, wps=17614.5, ups=5.09, wpb=3462.5, bsz=161.9, num_updates=47300, lr=0.000145402, gnorm=1.133, train_wall=19, wall=0
2024-07-18 14:40:21 | INFO | train_inner | epoch 003:   8272 / 19564 loss=4.518, nll_loss=3.139, ppl=8.81, wps=17112.6, ups=4.97, wpb=3442.6, bsz=158, num_updates=47400, lr=0.000145248, gnorm=1.138, train_wall=20, wall=0
2024-07-18 14:40:40 | INFO | train_inner | epoch 003:   8372 / 19564 loss=4.501, nll_loss=3.119, ppl=8.69, wps=17404.5, ups=5.08, wpb=3425.2, bsz=133.7, num_updates=47500, lr=0.000145095, gnorm=1.165, train_wall=19, wall=0
2024-07-18 14:41:00 | INFO | train_inner | epoch 003:   8472 / 19564 loss=4.406, nll_loss=3.01, ppl=8.06, wps=17657.2, ups=5.07, wpb=3479.7, bsz=155.4, num_updates=47600, lr=0.000144943, gnorm=1.096, train_wall=20, wall=0
2024-07-18 14:41:20 | INFO | train_inner | epoch 003:   8572 / 19564 loss=4.528, nll_loss=3.15, ppl=8.88, wps=17398.7, ups=5.13, wpb=3393.9, bsz=145.4, num_updates=47700, lr=0.000144791, gnorm=1.226, train_wall=19, wall=0
2024-07-18 14:41:39 | INFO | train_inner | epoch 003:   8672 / 19564 loss=4.519, nll_loss=3.14, ppl=8.81, wps=17448.9, ups=5.13, wpb=3403, bsz=138.2, num_updates=47800, lr=0.000144639, gnorm=1.147, train_wall=19, wall=0
2024-07-18 14:41:59 | INFO | train_inner | epoch 003:   8772 / 19564 loss=4.494, nll_loss=3.111, ppl=8.64, wps=17176, ups=5.07, wpb=3386.8, bsz=134.6, num_updates=47900, lr=0.000144488, gnorm=1.152, train_wall=19, wall=0
2024-07-18 14:42:18 | INFO | train_inner | epoch 003:   8872 / 19564 loss=4.587, nll_loss=3.218, ppl=9.31, wps=17598.7, ups=5.12, wpb=3438.8, bsz=127.9, num_updates=48000, lr=0.000144338, gnorm=1.152, train_wall=19, wall=0
2024-07-18 14:42:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:42:21 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.444 | nll_loss 2.937 | ppl 7.66 | wps 54300.9 | wpb 2872.6 | bsz 51.2 | num_updates 48000 | best_loss 12.134
2024-07-18 14:42:21 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:42:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_48000.pt (epoch 3 @ 48000 updates, score 4.444) (writing took 3.68800144828856 seconds)
2024-07-18 14:42:44 | INFO | train_inner | epoch 003:   8972 / 19564 loss=4.518, nll_loss=3.139, ppl=8.81, wps=13314.9, ups=3.93, wpb=3389.5, bsz=154.3, num_updates=48100, lr=0.000144187, gnorm=1.174, train_wall=19, wall=0
2024-07-18 14:43:03 | INFO | train_inner | epoch 003:   9072 / 19564 loss=4.527, nll_loss=3.148, ppl=8.86, wps=17704.4, ups=5.12, wpb=3456.3, bsz=133.8, num_updates=48200, lr=0.000144038, gnorm=1.131, train_wall=19, wall=0
2024-07-18 14:43:23 | INFO | train_inner | epoch 003:   9172 / 19564 loss=4.552, nll_loss=3.179, ppl=9.06, wps=17045.1, ups=5.17, wpb=3299.3, bsz=135.3, num_updates=48300, lr=0.000143889, gnorm=1.235, train_wall=19, wall=0
2024-07-18 14:43:43 | INFO | train_inner | epoch 003:   9272 / 19564 loss=4.445, nll_loss=3.056, ppl=8.32, wps=17384, ups=4.99, wpb=3480.7, bsz=142.2, num_updates=48400, lr=0.00014374, gnorm=1.103, train_wall=20, wall=0
2024-07-18 14:44:03 | INFO | train_inner | epoch 003:   9372 / 19564 loss=4.495, nll_loss=3.112, ppl=8.64, wps=17362.3, ups=5.03, wpb=3449.8, bsz=142, num_updates=48500, lr=0.000143592, gnorm=1.162, train_wall=20, wall=0
2024-07-18 14:44:22 | INFO | train_inner | epoch 003:   9472 / 19564 loss=4.515, nll_loss=3.136, ppl=8.79, wps=17677.8, ups=5.02, wpb=3518.3, bsz=133.6, num_updates=48600, lr=0.000143444, gnorm=1.131, train_wall=20, wall=0
2024-07-18 14:44:43 | INFO | train_inner | epoch 003:   9572 / 19564 loss=4.506, nll_loss=3.126, ppl=8.73, wps=17163.3, ups=4.93, wpb=3480.5, bsz=134.8, num_updates=48700, lr=0.000143296, gnorm=1.15, train_wall=20, wall=0
2024-07-18 14:45:03 | INFO | train_inner | epoch 003:   9672 / 19564 loss=4.399, nll_loss=3.002, ppl=8.01, wps=17406.1, ups=5.04, wpb=3456.2, bsz=140.2, num_updates=48800, lr=0.00014315, gnorm=1.114, train_wall=20, wall=0
2024-07-18 14:45:22 | INFO | train_inner | epoch 003:   9772 / 19564 loss=4.497, nll_loss=3.115, ppl=8.67, wps=17614.1, ups=5.14, wpb=3427.5, bsz=144.9, num_updates=48900, lr=0.000143003, gnorm=1.165, train_wall=19, wall=0
2024-07-18 14:45:42 | INFO | train_inner | epoch 003:   9872 / 19564 loss=4.447, nll_loss=3.058, ppl=8.33, wps=17278.2, ups=5.06, wpb=3411.7, bsz=146.2, num_updates=49000, lr=0.000142857, gnorm=1.147, train_wall=20, wall=0
2024-07-18 14:45:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:45:44 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.413 | nll_loss 2.911 | ppl 7.52 | wps 54265.3 | wpb 2872.6 | bsz 51.2 | num_updates 49000 | best_loss 12.134
2024-07-18 14:45:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:45:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_49000.pt (epoch 3 @ 49000 updates, score 4.413) (writing took 4.156371891498566 seconds)
2024-07-18 14:46:08 | INFO | train_inner | epoch 003:   9972 / 19564 loss=4.487, nll_loss=3.103, ppl=8.59, wps=13006.1, ups=3.78, wpb=3438.8, bsz=131.8, num_updates=49100, lr=0.000142712, gnorm=1.142, train_wall=20, wall=0
2024-07-18 14:46:28 | INFO | train_inner | epoch 003:  10072 / 19564 loss=4.518, nll_loss=3.139, ppl=8.81, wps=17343.3, ups=5.09, wpb=3406.6, bsz=129.4, num_updates=49200, lr=0.000142566, gnorm=1.175, train_wall=19, wall=0
2024-07-18 14:46:48 | INFO | train_inner | epoch 003:  10172 / 19564 loss=4.446, nll_loss=3.055, ppl=8.31, wps=17476.9, ups=5.1, wpb=3429.1, bsz=132.4, num_updates=49300, lr=0.000142422, gnorm=1.129, train_wall=19, wall=0
2024-07-18 14:47:07 | INFO | train_inner | epoch 003:  10272 / 19564 loss=4.489, nll_loss=3.106, ppl=8.61, wps=17254.9, ups=5.11, wpb=3375.2, bsz=137, num_updates=49400, lr=0.000142278, gnorm=1.173, train_wall=19, wall=0
2024-07-18 14:47:27 | INFO | train_inner | epoch 003:  10372 / 19564 loss=4.531, nll_loss=3.153, ppl=8.9, wps=17258.3, ups=5.11, wpb=3378, bsz=123.4, num_updates=49500, lr=0.000142134, gnorm=1.169, train_wall=19, wall=0
2024-07-18 14:47:46 | INFO | train_inner | epoch 003:  10472 / 19564 loss=4.456, nll_loss=3.069, ppl=8.39, wps=17534.4, ups=5.09, wpb=3445.2, bsz=146, num_updates=49600, lr=0.00014199, gnorm=1.122, train_wall=19, wall=0
2024-07-18 14:48:07 | INFO | train_inner | epoch 003:  10572 / 19564 loss=4.426, nll_loss=3.033, ppl=8.18, wps=17210.4, ups=4.89, wpb=3521.4, bsz=142, num_updates=49700, lr=0.000141848, gnorm=1.12, train_wall=20, wall=0
2024-07-18 14:48:27 | INFO | train_inner | epoch 003:  10672 / 19564 loss=4.472, nll_loss=3.086, ppl=8.49, wps=17183.8, ups=5.06, wpb=3397.9, bsz=140, num_updates=49800, lr=0.000141705, gnorm=1.231, train_wall=20, wall=0
2024-07-18 14:48:46 | INFO | train_inner | epoch 003:  10772 / 19564 loss=4.443, nll_loss=3.052, ppl=8.29, wps=17843.9, ups=5.1, wpb=3496.4, bsz=133.8, num_updates=49900, lr=0.000141563, gnorm=1.099, train_wall=19, wall=0
2024-07-18 14:49:06 | INFO | train_inner | epoch 003:  10872 / 19564 loss=4.441, nll_loss=3.051, ppl=8.29, wps=17466.7, ups=5.03, wpb=3470.4, bsz=143, num_updates=50000, lr=0.000141421, gnorm=1.156, train_wall=20, wall=0
2024-07-18 14:49:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:49:08 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.42 | nll_loss 2.911 | ppl 7.52 | wps 53520.9 | wpb 2872.6 | bsz 51.2 | num_updates 50000 | best_loss 12.134
2024-07-18 14:49:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:49:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_50000.pt (epoch 3 @ 50000 updates, score 4.42) (writing took 3.5301251569762826 seconds)
2024-07-18 14:49:32 | INFO | train_inner | epoch 003:  10972 / 19564 loss=4.544, nll_loss=3.169, ppl=8.99, wps=13385.4, ups=3.89, wpb=3440.7, bsz=124.2, num_updates=50100, lr=0.00014128, gnorm=1.149, train_wall=20, wall=0
2024-07-18 14:49:51 | INFO | train_inner | epoch 003:  11072 / 19564 loss=4.387, nll_loss=2.99, ppl=7.94, wps=17372.9, ups=5.06, wpb=3430.1, bsz=152.2, num_updates=50200, lr=0.000141139, gnorm=1.1, train_wall=20, wall=0
2024-07-18 14:50:11 | INFO | train_inner | epoch 003:  11172 / 19564 loss=4.453, nll_loss=3.066, ppl=8.38, wps=17530.2, ups=5.09, wpb=3440.9, bsz=154.8, num_updates=50300, lr=0.000140999, gnorm=1.139, train_wall=19, wall=0
2024-07-18 14:50:31 | INFO | train_inner | epoch 003:  11272 / 19564 loss=4.443, nll_loss=3.053, ppl=8.3, wps=17422.9, ups=5.1, wpb=3413.9, bsz=144.2, num_updates=50400, lr=0.000140859, gnorm=1.148, train_wall=19, wall=0
2024-07-18 14:50:50 | INFO | train_inner | epoch 003:  11372 / 19564 loss=4.491, nll_loss=3.109, ppl=8.63, wps=17415, ups=5.14, wpb=3388.8, bsz=143.9, num_updates=50500, lr=0.00014072, gnorm=1.176, train_wall=19, wall=0
2024-07-18 14:51:10 | INFO | train_inner | epoch 003:  11472 / 19564 loss=4.435, nll_loss=3.044, ppl=8.25, wps=17793.1, ups=5.16, wpb=3451.6, bsz=150.3, num_updates=50600, lr=0.00014058, gnorm=1.128, train_wall=19, wall=0
2024-07-18 14:51:29 | INFO | train_inner | epoch 003:  11572 / 19564 loss=4.469, nll_loss=3.083, ppl=8.48, wps=17267.2, ups=5.02, wpb=3442.2, bsz=135.4, num_updates=50700, lr=0.000140442, gnorm=1.149, train_wall=20, wall=0
2024-07-18 14:51:49 | INFO | train_inner | epoch 003:  11672 / 19564 loss=4.441, nll_loss=3.052, ppl=8.29, wps=17544.1, ups=5.06, wpb=3465.6, bsz=144.3, num_updates=50800, lr=0.000140303, gnorm=1.123, train_wall=20, wall=0
2024-07-18 14:52:09 | INFO | train_inner | epoch 003:  11772 / 19564 loss=4.374, nll_loss=2.976, ppl=7.87, wps=17623.3, ups=5.01, wpb=3514.8, bsz=160.6, num_updates=50900, lr=0.000140165, gnorm=1.089, train_wall=20, wall=0
2024-07-18 14:52:29 | INFO | train_inner | epoch 003:  11872 / 19564 loss=4.465, nll_loss=3.08, ppl=8.46, wps=17612.8, ups=5.06, wpb=3479.1, bsz=149.8, num_updates=51000, lr=0.000140028, gnorm=1.157, train_wall=20, wall=0
2024-07-18 14:52:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:52:31 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.405 | nll_loss 2.9 | ppl 7.47 | wps 53926.6 | wpb 2872.6 | bsz 51.2 | num_updates 51000 | best_loss 12.134
2024-07-18 14:52:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:52:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_51000.pt (epoch 3 @ 51000 updates, score 4.405) (writing took 4.728472778573632 seconds)
2024-07-18 14:52:56 | INFO | train_inner | epoch 003:  11972 / 19564 loss=4.349, nll_loss=2.948, ppl=7.71, wps=12674.1, ups=3.7, wpb=3424.1, bsz=153.2, num_updates=51100, lr=0.000139891, gnorm=1.13, train_wall=20, wall=0
2024-07-18 14:53:16 | INFO | train_inner | epoch 003:  12072 / 19564 loss=4.445, nll_loss=3.056, ppl=8.32, wps=17691.3, ups=5.04, wpb=3511.8, bsz=148.8, num_updates=51200, lr=0.000139754, gnorm=1.093, train_wall=20, wall=0
2024-07-18 14:53:35 | INFO | train_inner | epoch 003:  12172 / 19564 loss=4.444, nll_loss=3.055, ppl=8.31, wps=17371, ups=5.08, wpb=3417.2, bsz=142.2, num_updates=51300, lr=0.000139618, gnorm=1.139, train_wall=19, wall=0
2024-07-18 14:53:56 | INFO | train_inner | epoch 003:  12272 / 19564 loss=4.407, nll_loss=3.012, ppl=8.07, wps=17175.7, ups=4.98, wpb=3446.9, bsz=139.6, num_updates=51400, lr=0.000139482, gnorm=1.102, train_wall=20, wall=0
2024-07-18 14:54:15 | INFO | train_inner | epoch 003:  12372 / 19564 loss=4.444, nll_loss=3.055, ppl=8.31, wps=17679.1, ups=5.11, wpb=3460.2, bsz=137.6, num_updates=51500, lr=0.000139347, gnorm=1.137, train_wall=19, wall=0
2024-07-18 14:54:35 | INFO | train_inner | epoch 003:  12472 / 19564 loss=4.449, nll_loss=3.06, ppl=8.34, wps=17621.3, ups=5.09, wpb=3463.2, bsz=133.7, num_updates=51600, lr=0.000139212, gnorm=1.149, train_wall=19, wall=0
2024-07-18 14:54:55 | INFO | train_inner | epoch 003:  12572 / 19564 loss=4.469, nll_loss=3.083, ppl=8.48, wps=17728.9, ups=5.03, wpb=3524.5, bsz=138.8, num_updates=51700, lr=0.000139077, gnorm=1.117, train_wall=20, wall=0
2024-07-18 14:55:14 | INFO | train_inner | epoch 003:  12672 / 19564 loss=4.464, nll_loss=3.079, ppl=8.45, wps=17949.5, ups=5.12, wpb=3507.1, bsz=148.2, num_updates=51800, lr=0.000138943, gnorm=1.173, train_wall=19, wall=0
2024-07-18 14:55:34 | INFO | train_inner | epoch 003:  12772 / 19564 loss=4.4, nll_loss=3.004, ppl=8.02, wps=17647.1, ups=5.16, wpb=3420.7, bsz=149.5, num_updates=51900, lr=0.000138809, gnorm=1.132, train_wall=19, wall=0
2024-07-18 14:55:53 | INFO | train_inner | epoch 003:  12872 / 19564 loss=4.41, nll_loss=3.017, ppl=8.09, wps=17472.8, ups=5.1, wpb=3428.2, bsz=147.3, num_updates=52000, lr=0.000138675, gnorm=1.176, train_wall=19, wall=0
2024-07-18 14:55:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:55:56 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.391 | nll_loss 2.887 | ppl 7.4 | wps 54004 | wpb 2872.6 | bsz 51.2 | num_updates 52000 | best_loss 12.134
2024-07-18 14:55:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:56:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_52000.pt (epoch 3 @ 52000 updates, score 4.391) (writing took 5.348164797760546 seconds)
2024-07-18 14:56:20 | INFO | train_inner | epoch 003:  12972 / 19564 loss=4.44, nll_loss=3.051, ppl=8.29, wps=12378.7, ups=3.69, wpb=3356.8, bsz=149, num_updates=52100, lr=0.000138542, gnorm=1.151, train_wall=19, wall=0
2024-07-18 14:56:40 | INFO | train_inner | epoch 003:  13072 / 19564 loss=4.431, nll_loss=3.042, ppl=8.23, wps=17542.2, ups=5.13, wpb=3418, bsz=145.4, num_updates=52200, lr=0.000138409, gnorm=1.154, train_wall=19, wall=0
2024-07-18 14:57:00 | INFO | train_inner | epoch 003:  13172 / 19564 loss=4.414, nll_loss=3.021, ppl=8.12, wps=17498.1, ups=5.04, wpb=3472.8, bsz=145.9, num_updates=52300, lr=0.000138277, gnorm=1.137, train_wall=20, wall=0
2024-07-18 14:57:19 | INFO | train_inner | epoch 003:  13272 / 19564 loss=4.451, nll_loss=3.064, ppl=8.36, wps=17360.6, ups=5.11, wpb=3400.5, bsz=143.4, num_updates=52400, lr=0.000138145, gnorm=1.146, train_wall=19, wall=0
2024-07-18 14:57:39 | INFO | train_inner | epoch 003:  13372 / 19564 loss=4.436, nll_loss=3.047, ppl=8.27, wps=17400.8, ups=5.11, wpb=3405.4, bsz=146.6, num_updates=52500, lr=0.000138013, gnorm=1.132, train_wall=19, wall=0
2024-07-18 14:57:59 | INFO | train_inner | epoch 003:  13472 / 19564 loss=4.416, nll_loss=3.024, ppl=8.13, wps=17173.5, ups=5.04, wpb=3405.9, bsz=141.3, num_updates=52600, lr=0.000137882, gnorm=1.154, train_wall=20, wall=0
2024-07-18 14:58:18 | INFO | train_inner | epoch 003:  13572 / 19564 loss=4.449, nll_loss=3.061, ppl=8.35, wps=18244.2, ups=5.11, wpb=3573.7, bsz=145.1, num_updates=52700, lr=0.000137751, gnorm=1.083, train_wall=19, wall=0
2024-07-18 14:58:38 | INFO | train_inner | epoch 003:  13672 / 19564 loss=4.439, nll_loss=3.051, ppl=8.29, wps=17362.1, ups=5.05, wpb=3439.5, bsz=146.2, num_updates=52800, lr=0.00013762, gnorm=1.134, train_wall=20, wall=0
2024-07-18 14:58:58 | INFO | train_inner | epoch 003:  13772 / 19564 loss=4.499, nll_loss=3.118, ppl=8.68, wps=17430.5, ups=5.11, wpb=3411.4, bsz=139.1, num_updates=52900, lr=0.00013749, gnorm=1.171, train_wall=19, wall=0
2024-07-18 14:59:17 | INFO | train_inner | epoch 003:  13872 / 19564 loss=4.479, nll_loss=3.096, ppl=8.55, wps=17824.3, ups=5.15, wpb=3463.2, bsz=145.4, num_updates=53000, lr=0.000137361, gnorm=1.181, train_wall=19, wall=0
2024-07-18 14:59:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 14:59:19 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.374 | nll_loss 2.868 | ppl 7.3 | wps 53794.4 | wpb 2872.6 | bsz 51.2 | num_updates 53000 | best_loss 12.134
2024-07-18 14:59:19 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 14:59:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_53000.pt (epoch 3 @ 53000 updates, score 4.374) (writing took 3.5003531901165843 seconds)
2024-07-18 14:59:43 | INFO | train_inner | epoch 003:  13972 / 19564 loss=4.399, nll_loss=3.005, ppl=8.03, wps=13345, ups=3.9, wpb=3425, bsz=152.2, num_updates=53100, lr=0.000137231, gnorm=1.113, train_wall=20, wall=0
2024-07-18 15:00:02 | INFO | train_inner | epoch 003:  14072 / 19564 loss=4.517, nll_loss=3.14, ppl=8.81, wps=16983, ups=5.06, wpb=3355.7, bsz=142.1, num_updates=53200, lr=0.000137102, gnorm=1.212, train_wall=20, wall=0
2024-07-18 15:00:22 | INFO | train_inner | epoch 003:  14172 / 19564 loss=4.43, nll_loss=3.04, ppl=8.22, wps=17514.6, ups=5.04, wpb=3473.5, bsz=137.7, num_updates=53300, lr=0.000136973, gnorm=1.134, train_wall=20, wall=0
2024-07-18 15:00:42 | INFO | train_inner | epoch 003:  14272 / 19564 loss=4.41, nll_loss=3.016, ppl=8.09, wps=17367.1, ups=5.06, wpb=3432.8, bsz=144.1, num_updates=53400, lr=0.000136845, gnorm=1.163, train_wall=20, wall=0
2024-07-18 15:01:02 | INFO | train_inner | epoch 003:  14372 / 19564 loss=4.423, nll_loss=3.031, ppl=8.18, wps=17427.7, ups=5.13, wpb=3397.4, bsz=133.2, num_updates=53500, lr=0.000136717, gnorm=1.156, train_wall=19, wall=0
2024-07-18 15:01:21 | INFO | train_inner | epoch 003:  14472 / 19564 loss=4.416, nll_loss=3.024, ppl=8.13, wps=17406.6, ups=5.07, wpb=3434.6, bsz=145, num_updates=53600, lr=0.00013659, gnorm=1.141, train_wall=20, wall=0
2024-07-18 15:01:41 | INFO | train_inner | epoch 003:  14572 / 19564 loss=4.423, nll_loss=3.032, ppl=8.18, wps=17208.9, ups=4.97, wpb=3465.1, bsz=125.4, num_updates=53700, lr=0.000136462, gnorm=1.136, train_wall=20, wall=0
2024-07-18 15:02:01 | INFO | train_inner | epoch 003:  14672 / 19564 loss=4.414, nll_loss=3.022, ppl=8.12, wps=17705, ups=5.05, wpb=3508.5, bsz=144.2, num_updates=53800, lr=0.000136335, gnorm=1.102, train_wall=20, wall=0
2024-07-18 15:02:21 | INFO | train_inner | epoch 003:  14772 / 19564 loss=4.418, nll_loss=3.027, ppl=8.15, wps=16802.7, ups=4.99, wpb=3370.5, bsz=139.8, num_updates=53900, lr=0.000136209, gnorm=1.142, train_wall=20, wall=0
2024-07-18 15:02:41 | INFO | train_inner | epoch 003:  14872 / 19564 loss=4.468, nll_loss=3.082, ppl=8.47, wps=17465.6, ups=5.09, wpb=3430.5, bsz=114.2, num_updates=54000, lr=0.000136083, gnorm=1.149, train_wall=19, wall=0
2024-07-18 15:02:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:02:43 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.356 | nll_loss 2.857 | ppl 7.24 | wps 53973 | wpb 2872.6 | bsz 51.2 | num_updates 54000 | best_loss 12.134
2024-07-18 15:02:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:02:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_54000.pt (epoch 3 @ 54000 updates, score 4.356) (writing took 3.5958238765597343 seconds)
2024-07-18 15:03:06 | INFO | train_inner | epoch 003:  14972 / 19564 loss=4.476, nll_loss=3.093, ppl=8.53, wps=13291.5, ups=3.91, wpb=3395.7, bsz=132.3, num_updates=54100, lr=0.000135957, gnorm=1.197, train_wall=19, wall=0
2024-07-18 15:03:26 | INFO | train_inner | epoch 003:  15072 / 19564 loss=4.418, nll_loss=3.027, ppl=8.15, wps=17422.5, ups=5.05, wpb=3450.1, bsz=145.8, num_updates=54200, lr=0.000135831, gnorm=1.148, train_wall=20, wall=0
2024-07-18 15:03:46 | INFO | train_inner | epoch 003:  15172 / 19564 loss=4.406, nll_loss=3.012, ppl=8.07, wps=17667.9, ups=5.01, wpb=3524.5, bsz=137.8, num_updates=54300, lr=0.000135706, gnorm=1.103, train_wall=20, wall=0
2024-07-18 15:04:06 | INFO | train_inner | epoch 003:  15272 / 19564 loss=4.462, nll_loss=3.076, ppl=8.43, wps=17808.7, ups=5.12, wpb=3477.1, bsz=141, num_updates=54400, lr=0.000135582, gnorm=1.153, train_wall=19, wall=0
2024-07-18 15:04:25 | INFO | train_inner | epoch 003:  15372 / 19564 loss=4.407, nll_loss=3.014, ppl=8.08, wps=17574.7, ups=5.1, wpb=3443, bsz=144.8, num_updates=54500, lr=0.000135457, gnorm=1.143, train_wall=19, wall=0
2024-07-18 15:04:45 | INFO | train_inner | epoch 003:  15472 / 19564 loss=4.41, nll_loss=3.017, ppl=8.09, wps=17257.5, ups=5.11, wpb=3380, bsz=134.2, num_updates=54600, lr=0.000135333, gnorm=1.157, train_wall=19, wall=0
2024-07-18 15:05:05 | INFO | train_inner | epoch 003:  15572 / 19564 loss=4.454, nll_loss=3.068, ppl=8.38, wps=17552.2, ups=5.04, wpb=3479.5, bsz=139.4, num_updates=54700, lr=0.000135209, gnorm=1.15, train_wall=20, wall=0
2024-07-18 15:05:24 | INFO | train_inner | epoch 003:  15672 / 19564 loss=4.435, nll_loss=3.046, ppl=8.26, wps=17256.4, ups=5.09, wpb=3393.1, bsz=135.1, num_updates=54800, lr=0.000135086, gnorm=1.152, train_wall=19, wall=0
2024-07-18 15:05:44 | INFO | train_inner | epoch 003:  15772 / 19564 loss=4.447, nll_loss=3.061, ppl=8.34, wps=17479.3, ups=5.08, wpb=3438.7, bsz=150.2, num_updates=54900, lr=0.000134963, gnorm=1.159, train_wall=19, wall=0
2024-07-18 15:06:04 | INFO | train_inner | epoch 003:  15872 / 19564 loss=4.389, nll_loss=2.995, ppl=7.97, wps=17475.9, ups=5, wpb=3495.3, bsz=153.9, num_updates=55000, lr=0.00013484, gnorm=1.11, train_wall=20, wall=0
2024-07-18 15:06:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:06:07 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.365 | nll_loss 2.854 | ppl 7.23 | wps 53619.5 | wpb 2872.6 | bsz 51.2 | num_updates 55000 | best_loss 12.134
2024-07-18 15:06:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:06:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_55000.pt (epoch 3 @ 55000 updates, score 4.365) (writing took 3.7423421554267406 seconds)
2024-07-18 15:06:30 | INFO | train_inner | epoch 003:  15972 / 19564 loss=4.477, nll_loss=3.095, ppl=8.54, wps=13423.4, ups=3.87, wpb=3468.8, bsz=141.4, num_updates=55100, lr=0.000134718, gnorm=1.159, train_wall=19, wall=0
2024-07-18 15:06:50 | INFO | train_inner | epoch 003:  16072 / 19564 loss=4.395, nll_loss=3, ppl=8, wps=17445, ups=5.09, wpb=3424.5, bsz=138.5, num_updates=55200, lr=0.000134595, gnorm=1.121, train_wall=19, wall=0
2024-07-18 15:07:09 | INFO | train_inner | epoch 003:  16172 / 19564 loss=4.463, nll_loss=3.077, ppl=8.44, wps=17510, ups=5.09, wpb=3437.2, bsz=129.4, num_updates=55300, lr=0.000134474, gnorm=1.133, train_wall=19, wall=0
2024-07-18 15:07:29 | INFO | train_inner | epoch 003:  16272 / 19564 loss=4.451, nll_loss=3.065, ppl=8.37, wps=17898.1, ups=5.05, wpb=3543.3, bsz=143.7, num_updates=55400, lr=0.000134352, gnorm=1.114, train_wall=20, wall=0
2024-07-18 15:07:49 | INFO | train_inner | epoch 003:  16372 / 19564 loss=4.398, nll_loss=3.004, ppl=8.02, wps=17588.5, ups=4.99, wpb=3522.1, bsz=146.9, num_updates=55500, lr=0.000134231, gnorm=1.121, train_wall=20, wall=0
2024-07-18 15:08:09 | INFO | train_inner | epoch 003:  16472 / 19564 loss=4.445, nll_loss=3.058, ppl=8.33, wps=17379.4, ups=4.98, wpb=3490.1, bsz=141.8, num_updates=55600, lr=0.00013411, gnorm=1.14, train_wall=20, wall=0
2024-07-18 15:08:29 | INFO | train_inner | epoch 003:  16572 / 19564 loss=4.488, nll_loss=3.108, ppl=8.62, wps=17795.8, ups=5.15, wpb=3453.5, bsz=140.9, num_updates=55700, lr=0.00013399, gnorm=1.186, train_wall=19, wall=0
2024-07-18 15:08:49 | INFO | train_inner | epoch 003:  16672 / 19564 loss=4.454, nll_loss=3.068, ppl=8.39, wps=16880.6, ups=4.94, wpb=3420, bsz=138.7, num_updates=55800, lr=0.00013387, gnorm=1.154, train_wall=20, wall=0
2024-07-18 15:09:09 | INFO | train_inner | epoch 003:  16772 / 19564 loss=4.492, nll_loss=3.112, ppl=8.64, wps=17435.3, ups=5.03, wpb=3467.6, bsz=141.8, num_updates=55900, lr=0.00013375, gnorm=1.15, train_wall=20, wall=0
2024-07-18 15:09:29 | INFO | train_inner | epoch 003:  16872 / 19564 loss=4.412, nll_loss=3.02, ppl=8.11, wps=17319.9, ups=5.03, wpb=3442.5, bsz=137, num_updates=56000, lr=0.000133631, gnorm=1.158, train_wall=20, wall=0
2024-07-18 15:09:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:09:31 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.348 | nll_loss 2.843 | ppl 7.18 | wps 54157.4 | wpb 2872.6 | bsz 51.2 | num_updates 56000 | best_loss 12.134
2024-07-18 15:09:31 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:09:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_56000.pt (epoch 3 @ 56000 updates, score 4.348) (writing took 3.815461496822536 seconds)
2024-07-18 15:09:55 | INFO | train_inner | epoch 003:  16972 / 19564 loss=4.444, nll_loss=3.057, ppl=8.32, wps=13675.6, ups=3.84, wpb=3563.6, bsz=136.1, num_updates=56100, lr=0.000133511, gnorm=1.099, train_wall=20, wall=0
2024-07-18 15:10:14 | INFO | train_inner | epoch 003:  17072 / 19564 loss=4.429, nll_loss=3.038, ppl=8.21, wps=17592.4, ups=5.08, wpb=3462.2, bsz=126.3, num_updates=56200, lr=0.000133393, gnorm=1.144, train_wall=19, wall=0
2024-07-18 15:10:34 | INFO | train_inner | epoch 003:  17172 / 19564 loss=4.499, nll_loss=3.12, ppl=8.69, wps=17198.3, ups=5.19, wpb=3315.2, bsz=124.2, num_updates=56300, lr=0.000133274, gnorm=1.199, train_wall=19, wall=0
2024-07-18 15:10:53 | INFO | train_inner | epoch 003:  17272 / 19564 loss=4.373, nll_loss=2.976, ppl=7.87, wps=17493.6, ups=5.11, wpb=3425.1, bsz=146.6, num_updates=56400, lr=0.000133156, gnorm=1.125, train_wall=19, wall=0
2024-07-18 15:11:13 | INFO | train_inner | epoch 003:  17372 / 19564 loss=4.398, nll_loss=3.004, ppl=8.02, wps=17215.9, ups=5, wpb=3442.8, bsz=137.8, num_updates=56500, lr=0.000133038, gnorm=1.141, train_wall=20, wall=0
2024-07-18 15:11:33 | INFO | train_inner | epoch 003:  17472 / 19564 loss=4.389, nll_loss=2.996, ppl=7.98, wps=17683.2, ups=5.06, wpb=3494.5, bsz=156.1, num_updates=56600, lr=0.00013292, gnorm=1.11, train_wall=20, wall=0
2024-07-18 15:11:53 | INFO | train_inner | epoch 003:  17572 / 19564 loss=4.487, nll_loss=3.105, ppl=8.6, wps=17383.5, ups=5.09, wpb=3416, bsz=128.5, num_updates=56700, lr=0.000132803, gnorm=1.156, train_wall=19, wall=0
2024-07-18 15:12:12 | INFO | train_inner | epoch 003:  17672 / 19564 loss=4.376, nll_loss=2.98, ppl=7.89, wps=17797.4, ups=5.03, wpb=3537.1, bsz=146.2, num_updates=56800, lr=0.000132686, gnorm=1.117, train_wall=20, wall=0
2024-07-18 15:12:33 | INFO | train_inner | epoch 003:  17772 / 19564 loss=4.339, nll_loss=2.938, ppl=7.66, wps=17165.1, ups=4.97, wpb=3450.3, bsz=146, num_updates=56900, lr=0.00013257, gnorm=1.105, train_wall=20, wall=0
2024-07-18 15:12:52 | INFO | train_inner | epoch 003:  17872 / 19564 loss=4.455, nll_loss=3.07, ppl=8.4, wps=17315.9, ups=5.02, wpb=3447.4, bsz=151.1, num_updates=57000, lr=0.000132453, gnorm=1.169, train_wall=20, wall=0
2024-07-18 15:12:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:12:55 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.333 | nll_loss 2.822 | ppl 7.07 | wps 53946.2 | wpb 2872.6 | bsz 51.2 | num_updates 57000 | best_loss 12.134
2024-07-18 15:12:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:13:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_57000.pt (epoch 3 @ 57000 updates, score 4.333) (writing took 5.948141903616488 seconds)
2024-07-18 15:13:20 | INFO | train_inner | epoch 003:  17972 / 19564 loss=4.495, nll_loss=3.115, ppl=8.67, wps=12258.2, ups=3.59, wpb=3418, bsz=137.5, num_updates=57100, lr=0.000132337, gnorm=1.189, train_wall=19, wall=0
2024-07-18 15:13:40 | INFO | train_inner | epoch 003:  18072 / 19564 loss=4.486, nll_loss=3.104, ppl=8.6, wps=17183.6, ups=5.03, wpb=3412.8, bsz=119.5, num_updates=57200, lr=0.000132221, gnorm=1.179, train_wall=20, wall=0
2024-07-18 15:14:00 | INFO | train_inner | epoch 003:  18172 / 19564 loss=4.394, nll_loss=3, ppl=8, wps=17511.4, ups=5.09, wpb=3437.9, bsz=149, num_updates=57300, lr=0.000132106, gnorm=1.12, train_wall=19, wall=0
2024-07-18 15:14:20 | INFO | train_inner | epoch 003:  18272 / 19564 loss=4.412, nll_loss=3.021, ppl=8.11, wps=17756.5, ups=5.05, wpb=3514.9, bsz=146.9, num_updates=57400, lr=0.000131991, gnorm=1.111, train_wall=20, wall=0
2024-07-18 15:14:40 | INFO | train_inner | epoch 003:  18372 / 19564 loss=4.451, nll_loss=3.065, ppl=8.37, wps=17399, ups=4.95, wpb=3516, bsz=133.3, num_updates=57500, lr=0.000131876, gnorm=1.137, train_wall=20, wall=0
2024-07-18 15:14:59 | INFO | train_inner | epoch 003:  18472 / 19564 loss=4.417, nll_loss=3.027, ppl=8.15, wps=17452.6, ups=5.16, wpb=3379.2, bsz=138.6, num_updates=57600, lr=0.000131762, gnorm=1.186, train_wall=19, wall=0
2024-07-18 15:15:19 | INFO | train_inner | epoch 003:  18572 / 19564 loss=4.418, nll_loss=3.027, ppl=8.15, wps=17607.3, ups=5.02, wpb=3509.3, bsz=130.7, num_updates=57700, lr=0.000131647, gnorm=1.11, train_wall=20, wall=0
2024-07-18 15:15:39 | INFO | train_inner | epoch 003:  18672 / 19564 loss=4.441, nll_loss=3.052, ppl=8.29, wps=17867.7, ups=5.14, wpb=3477.3, bsz=130.7, num_updates=57800, lr=0.000131533, gnorm=1.16, train_wall=19, wall=0
2024-07-18 15:15:58 | INFO | train_inner | epoch 003:  18772 / 19564 loss=4.396, nll_loss=3.003, ppl=8.02, wps=17539.6, ups=5.18, wpb=3387.5, bsz=143, num_updates=57900, lr=0.00013142, gnorm=1.163, train_wall=19, wall=0
2024-07-18 15:16:18 | INFO | train_inner | epoch 003:  18872 / 19564 loss=4.382, nll_loss=2.988, ppl=7.94, wps=17847.3, ups=5.06, wpb=3527.6, bsz=162.5, num_updates=58000, lr=0.000131306, gnorm=1.108, train_wall=20, wall=0
2024-07-18 15:16:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:16:20 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.332 | nll_loss 2.824 | ppl 7.08 | wps 54987.5 | wpb 2872.6 | bsz 51.2 | num_updates 58000 | best_loss 12.134
2024-07-18 15:16:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:16:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_3_58000.pt (epoch 3 @ 58000 updates, score 4.332) (writing took 4.921460027806461 seconds)
2024-07-18 15:16:45 | INFO | train_inner | epoch 003:  18972 / 19564 loss=4.397, nll_loss=3.003, ppl=8.02, wps=12824.1, ups=3.72, wpb=3450.3, bsz=141.8, num_updates=58100, lr=0.000131193, gnorm=1.143, train_wall=19, wall=0
2024-07-18 15:17:04 | INFO | train_inner | epoch 003:  19072 / 19564 loss=4.367, nll_loss=2.97, ppl=7.84, wps=17432.2, ups=5.13, wpb=3398.8, bsz=148.4, num_updates=58200, lr=0.000131081, gnorm=1.162, train_wall=19, wall=0
2024-07-18 15:17:24 | INFO | train_inner | epoch 003:  19172 / 19564 loss=4.349, nll_loss=2.948, ppl=7.72, wps=17645.4, ups=5.05, wpb=3493.5, bsz=139.8, num_updates=58300, lr=0.000130968, gnorm=1.095, train_wall=20, wall=0
2024-07-18 15:17:44 | INFO | train_inner | epoch 003:  19272 / 19564 loss=4.403, nll_loss=3.01, ppl=8.05, wps=18023.4, ups=5.09, wpb=3539.1, bsz=141.4, num_updates=58400, lr=0.000130856, gnorm=1.122, train_wall=19, wall=0
2024-07-18 15:18:03 | INFO | train_inner | epoch 003:  19372 / 19564 loss=4.502, nll_loss=3.124, ppl=8.72, wps=17889.1, ups=5.13, wpb=3484.5, bsz=137.4, num_updates=58500, lr=0.000130744, gnorm=1.158, train_wall=19, wall=0
2024-07-18 15:18:23 | INFO | train_inner | epoch 003:  19472 / 19564 loss=4.378, nll_loss=2.981, ppl=7.9, wps=17620.2, ups=5.07, wpb=3475.6, bsz=136.2, num_updates=58600, lr=0.000130632, gnorm=1.148, train_wall=20, wall=0
2024-07-18 15:18:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:18:43 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.303 | nll_loss 2.791 | ppl 6.92 | wps 54803.7 | wpb 2872.6 | bsz 51.2 | num_updates 58692 | best_loss 12.134
2024-07-18 15:18:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:18:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 3 @ 58692 updates, score 4.303) (writing took 2.950554635375738 seconds)
2024-07-18 15:18:46 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2024-07-18 15:18:46 | INFO | train | epoch 003 | loss 4.473 | nll_loss 3.087 | ppl 8.5 | wps 16913.6 | ups 4.91 | wpb 3446.5 | bsz 142.2 | num_updates 58692 | lr 0.00013053 | gnorm 1.145 | train_wall 3814 | wall 0
2024-07-18 15:18:46 | INFO | fairseq.trainer | begin training epoch 4
2024-07-18 15:18:48 | INFO | train_inner | epoch 004:      8 / 19564 loss=4.415, nll_loss=3.024, ppl=8.13, wps=13823.8, ups=4, wpb=3452.2, bsz=129.8, num_updates=58700, lr=0.000130521, gnorm=1.142, train_wall=19, wall=0
2024-07-18 15:19:07 | INFO | train_inner | epoch 004:    108 / 19564 loss=4.39, nll_loss=2.995, ppl=7.97, wps=17461.7, ups=5.16, wpb=3383.8, bsz=131.8, num_updates=58800, lr=0.00013041, gnorm=1.187, train_wall=19, wall=0
2024-07-18 15:19:27 | INFO | train_inner | epoch 004:    208 / 19564 loss=4.416, nll_loss=3.025, ppl=8.14, wps=17638.2, ups=5.06, wpb=3487.8, bsz=145.2, num_updates=58900, lr=0.000130299, gnorm=1.162, train_wall=20, wall=0
2024-07-18 15:19:47 | INFO | train_inner | epoch 004:    308 / 19564 loss=4.413, nll_loss=3.021, ppl=8.11, wps=17206.5, ups=5.01, wpb=3437.7, bsz=124.3, num_updates=59000, lr=0.000130189, gnorm=1.157, train_wall=20, wall=0
2024-07-18 15:19:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:19:49 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.304 | nll_loss 2.791 | ppl 6.92 | wps 54062.4 | wpb 2872.6 | bsz 51.2 | num_updates 59000 | best_loss 12.134
2024-07-18 15:19:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:19:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_59000.pt (epoch 4 @ 59000 updates, score 4.304) (writing took 4.604000902734697 seconds)
2024-07-18 15:20:14 | INFO | train_inner | epoch 004:    408 / 19564 loss=4.402, nll_loss=3.01, ppl=8.05, wps=12704.6, ups=3.73, wpb=3402.9, bsz=129.3, num_updates=59100, lr=0.000130079, gnorm=1.161, train_wall=20, wall=0
2024-07-18 15:20:33 | INFO | train_inner | epoch 004:    508 / 19564 loss=4.379, nll_loss=2.984, ppl=7.91, wps=17610.4, ups=5.06, wpb=3478.2, bsz=153.5, num_updates=59200, lr=0.000129969, gnorm=1.153, train_wall=20, wall=0
2024-07-18 15:20:53 | INFO | train_inner | epoch 004:    608 / 19564 loss=4.387, nll_loss=2.991, ppl=7.95, wps=18061.7, ups=5.09, wpb=3547.6, bsz=128.8, num_updates=59300, lr=0.000129859, gnorm=1.124, train_wall=19, wall=0
2024-07-18 15:21:12 | INFO | train_inner | epoch 004:    708 / 19564 loss=4.366, nll_loss=2.968, ppl=7.82, wps=17689.5, ups=5.13, wpb=3445.5, bsz=147.6, num_updates=59400, lr=0.00012975, gnorm=1.144, train_wall=19, wall=0
2024-07-18 15:21:32 | INFO | train_inner | epoch 004:    808 / 19564 loss=4.346, nll_loss=2.945, ppl=7.7, wps=17689.1, ups=5.14, wpb=3439, bsz=141.4, num_updates=59500, lr=0.000129641, gnorm=1.153, train_wall=19, wall=0
2024-07-18 15:21:51 | INFO | train_inner | epoch 004:    908 / 19564 loss=4.426, nll_loss=3.037, ppl=8.21, wps=17735.8, ups=5.18, wpb=3422.9, bsz=139.3, num_updates=59600, lr=0.000129532, gnorm=1.147, train_wall=19, wall=0
2024-07-18 15:22:11 | INFO | train_inner | epoch 004:   1008 / 19564 loss=4.413, nll_loss=3.022, ppl=8.12, wps=17721.7, ups=5.13, wpb=3452.7, bsz=135.2, num_updates=59700, lr=0.000129423, gnorm=1.172, train_wall=19, wall=0
2024-07-18 15:22:30 | INFO | train_inner | epoch 004:   1108 / 19564 loss=4.387, nll_loss=2.992, ppl=7.96, wps=17721.6, ups=5.12, wpb=3459.6, bsz=140, num_updates=59800, lr=0.000129315, gnorm=1.135, train_wall=19, wall=0
2024-07-18 15:22:50 | INFO | train_inner | epoch 004:   1208 / 19564 loss=4.388, nll_loss=2.992, ppl=7.96, wps=17484.5, ups=5.06, wpb=3456.3, bsz=144.6, num_updates=59900, lr=0.000129207, gnorm=1.178, train_wall=20, wall=0
2024-07-18 15:23:09 | INFO | train_inner | epoch 004:   1308 / 19564 loss=4.368, nll_loss=2.971, ppl=7.84, wps=17711.4, ups=5.16, wpb=3435.2, bsz=143.2, num_updates=60000, lr=0.000129099, gnorm=1.116, train_wall=19, wall=0
2024-07-18 15:23:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:23:12 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.311 | nll_loss 2.797 | ppl 6.95 | wps 54328.7 | wpb 2872.6 | bsz 51.2 | num_updates 60000 | best_loss 12.134
2024-07-18 15:23:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:23:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_60000.pt (epoch 4 @ 60000 updates, score 4.311) (writing took 5.745826623402536 seconds)
2024-07-18 15:23:37 | INFO | train_inner | epoch 004:   1408 / 19564 loss=4.38, nll_loss=2.985, ppl=7.91, wps=12616.9, ups=3.63, wpb=3477.3, bsz=141.5, num_updates=60100, lr=0.000128992, gnorm=1.127, train_wall=19, wall=0
2024-07-18 15:23:57 | INFO | train_inner | epoch 004:   1508 / 19564 loss=4.371, nll_loss=2.975, ppl=7.86, wps=17745.2, ups=5.12, wpb=3468.4, bsz=147.2, num_updates=60200, lr=0.000128885, gnorm=1.136, train_wall=19, wall=0
2024-07-18 15:24:16 | INFO | train_inner | epoch 004:   1608 / 19564 loss=4.428, nll_loss=3.039, ppl=8.22, wps=17997.3, ups=5.15, wpb=3492.8, bsz=131.3, num_updates=60300, lr=0.000128778, gnorm=1.125, train_wall=19, wall=0
2024-07-18 15:24:36 | INFO | train_inner | epoch 004:   1708 / 19564 loss=4.375, nll_loss=2.978, ppl=7.88, wps=17466, ups=5.1, wpb=3421.9, bsz=139.8, num_updates=60400, lr=0.000128671, gnorm=1.15, train_wall=19, wall=0
2024-07-18 15:24:55 | INFO | train_inner | epoch 004:   1808 / 19564 loss=4.354, nll_loss=2.954, ppl=7.75, wps=17806.2, ups=5.11, wpb=3482.5, bsz=160.8, num_updates=60500, lr=0.000128565, gnorm=1.129, train_wall=19, wall=0
2024-07-18 15:25:15 | INFO | train_inner | epoch 004:   1908 / 19564 loss=4.385, nll_loss=2.991, ppl=7.95, wps=17820.1, ups=5.11, wpb=3487, bsz=141.9, num_updates=60600, lr=0.000128459, gnorm=1.129, train_wall=19, wall=0
2024-07-18 15:25:34 | INFO | train_inner | epoch 004:   2008 / 19564 loss=4.395, nll_loss=3.001, ppl=8, wps=17359.7, ups=5.15, wpb=3369, bsz=135.8, num_updates=60700, lr=0.000128353, gnorm=1.157, train_wall=19, wall=0
2024-07-18 15:25:54 | INFO | train_inner | epoch 004:   2108 / 19564 loss=4.403, nll_loss=3.01, ppl=8.05, wps=17437.3, ups=5.09, wpb=3424.3, bsz=131.5, num_updates=60800, lr=0.000128247, gnorm=1.153, train_wall=19, wall=0
2024-07-18 15:26:13 | INFO | train_inner | epoch 004:   2208 / 19564 loss=4.427, nll_loss=3.037, ppl=8.21, wps=17563.1, ups=5.08, wpb=3458.8, bsz=126.1, num_updates=60900, lr=0.000128142, gnorm=1.164, train_wall=20, wall=0
2024-07-18 15:26:33 | INFO | train_inner | epoch 004:   2308 / 19564 loss=4.37, nll_loss=2.974, ppl=7.85, wps=17393.2, ups=5.19, wpb=3352.2, bsz=143.4, num_updates=61000, lr=0.000128037, gnorm=1.175, train_wall=19, wall=0
2024-07-18 15:26:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:26:35 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.302 | nll_loss 2.792 | ppl 6.93 | wps 54885.1 | wpb 2872.6 | bsz 51.2 | num_updates 61000 | best_loss 12.134
2024-07-18 15:26:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:26:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_61000.pt (epoch 4 @ 61000 updates, score 4.302) (writing took 5.413860141299665 seconds)
2024-07-18 15:27:00 | INFO | train_inner | epoch 004:   2408 / 19564 loss=4.312, nll_loss=2.907, ppl=7.5, wps=12567.1, ups=3.68, wpb=3417.2, bsz=159.6, num_updates=61100, lr=0.000127932, gnorm=1.125, train_wall=19, wall=0
2024-07-18 15:27:20 | INFO | train_inner | epoch 004:   2508 / 19564 loss=4.389, nll_loss=2.996, ppl=7.98, wps=17290.2, ups=5.06, wpb=3418.5, bsz=148.5, num_updates=61200, lr=0.000127827, gnorm=1.173, train_wall=20, wall=0
2024-07-18 15:27:39 | INFO | train_inner | epoch 004:   2608 / 19564 loss=4.436, nll_loss=3.048, ppl=8.27, wps=17567.8, ups=5.12, wpb=3428.8, bsz=129.3, num_updates=61300, lr=0.000127723, gnorm=1.157, train_wall=19, wall=0
2024-07-18 15:27:59 | INFO | train_inner | epoch 004:   2708 / 19564 loss=4.403, nll_loss=3.01, ppl=8.06, wps=16937.5, ups=5.04, wpb=3360.8, bsz=135.6, num_updates=61400, lr=0.000127619, gnorm=1.179, train_wall=20, wall=0
2024-07-18 15:28:19 | INFO | train_inner | epoch 004:   2808 / 19564 loss=4.345, nll_loss=2.946, ppl=7.7, wps=17889, ups=5.06, wpb=3534.8, bsz=147.8, num_updates=61500, lr=0.000127515, gnorm=1.111, train_wall=20, wall=0
2024-07-18 15:28:38 | INFO | train_inner | epoch 004:   2908 / 19564 loss=4.353, nll_loss=2.954, ppl=7.75, wps=17561.7, ups=5.12, wpb=3432.2, bsz=143.2, num_updates=61600, lr=0.000127412, gnorm=1.162, train_wall=19, wall=0
2024-07-18 15:28:58 | INFO | train_inner | epoch 004:   3008 / 19564 loss=4.428, nll_loss=3.04, ppl=8.22, wps=17563, ups=5.19, wpb=3382.6, bsz=132.2, num_updates=61700, lr=0.000127309, gnorm=1.197, train_wall=19, wall=0
2024-07-18 15:29:17 | INFO | train_inner | epoch 004:   3108 / 19564 loss=4.39, nll_loss=2.996, ppl=7.98, wps=17899, ups=5.14, wpb=3479.6, bsz=145.1, num_updates=61800, lr=0.000127205, gnorm=1.131, train_wall=19, wall=0
2024-07-18 15:29:37 | INFO | train_inner | epoch 004:   3208 / 19564 loss=4.364, nll_loss=2.968, ppl=7.82, wps=17793.6, ups=5.12, wpb=3474.5, bsz=156.4, num_updates=61900, lr=0.000127103, gnorm=1.128, train_wall=19, wall=0
2024-07-18 15:29:56 | INFO | train_inner | epoch 004:   3308 / 19564 loss=4.425, nll_loss=3.035, ppl=8.2, wps=17914.2, ups=5.09, wpb=3518.2, bsz=129, num_updates=62000, lr=0.000127, gnorm=1.136, train_wall=19, wall=0
2024-07-18 15:29:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:29:59 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.293 | nll_loss 2.781 | ppl 6.87 | wps 54551.1 | wpb 2872.6 | bsz 51.2 | num_updates 62000 | best_loss 12.134
2024-07-18 15:29:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:30:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_62000.pt (epoch 4 @ 62000 updates, score 4.293) (writing took 4.61195254418999 seconds)
2024-07-18 15:30:23 | INFO | train_inner | epoch 004:   3408 / 19564 loss=4.393, nll_loss=2.999, ppl=7.99, wps=12932.1, ups=3.76, wpb=3441, bsz=134.6, num_updates=62100, lr=0.000126898, gnorm=1.158, train_wall=19, wall=0
2024-07-18 15:30:42 | INFO | train_inner | epoch 004:   3508 / 19564 loss=4.375, nll_loss=2.979, ppl=7.89, wps=17794.9, ups=5.14, wpb=3460.2, bsz=147.1, num_updates=62200, lr=0.000126796, gnorm=1.158, train_wall=19, wall=0
2024-07-18 15:31:02 | INFO | train_inner | epoch 004:   3608 / 19564 loss=4.467, nll_loss=3.083, ppl=8.47, wps=17492.9, ups=5.15, wpb=3395.7, bsz=132.9, num_updates=62300, lr=0.000126694, gnorm=1.183, train_wall=19, wall=0
2024-07-18 15:31:21 | INFO | train_inner | epoch 004:   3708 / 19564 loss=4.348, nll_loss=2.949, ppl=7.72, wps=17777.1, ups=5.11, wpb=3475.9, bsz=149.1, num_updates=62400, lr=0.000126592, gnorm=1.102, train_wall=19, wall=0
2024-07-18 15:31:41 | INFO | train_inner | epoch 004:   3808 / 19564 loss=4.347, nll_loss=2.947, ppl=7.71, wps=17830, ups=5.09, wpb=3500.2, bsz=139.8, num_updates=62500, lr=0.000126491, gnorm=1.169, train_wall=19, wall=0
2024-07-18 15:32:00 | INFO | train_inner | epoch 004:   3908 / 19564 loss=4.349, nll_loss=2.949, ppl=7.72, wps=17575.2, ups=5.1, wpb=3447.1, bsz=126.2, num_updates=62600, lr=0.00012639, gnorm=1.157, train_wall=19, wall=0
2024-07-18 15:32:20 | INFO | train_inner | epoch 004:   4008 / 19564 loss=4.347, nll_loss=2.947, ppl=7.71, wps=17574, ups=5.14, wpb=3420.4, bsz=149.4, num_updates=62700, lr=0.000126289, gnorm=1.162, train_wall=19, wall=0
2024-07-18 15:32:39 | INFO | train_inner | epoch 004:   4108 / 19564 loss=4.42, nll_loss=3.03, ppl=8.17, wps=17523.8, ups=5.1, wpb=3432.9, bsz=128.4, num_updates=62800, lr=0.000126189, gnorm=1.189, train_wall=19, wall=0
2024-07-18 15:32:59 | INFO | train_inner | epoch 004:   4208 / 19564 loss=4.341, nll_loss=2.941, ppl=7.68, wps=17413.5, ups=5.15, wpb=3381.9, bsz=148.4, num_updates=62900, lr=0.000126088, gnorm=1.179, train_wall=19, wall=0
2024-07-18 15:33:19 | INFO | train_inner | epoch 004:   4308 / 19564 loss=4.315, nll_loss=2.911, ppl=7.52, wps=17777, ups=5.07, wpb=3505.4, bsz=148.2, num_updates=63000, lr=0.000125988, gnorm=1.102, train_wall=20, wall=0
2024-07-18 15:33:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:33:21 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.303 | nll_loss 2.782 | ppl 6.88 | wps 54923 | wpb 2872.6 | bsz 51.2 | num_updates 63000 | best_loss 12.134
2024-07-18 15:33:21 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:33:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_63000.pt (epoch 4 @ 63000 updates, score 4.303) (writing took 4.843745433725417 seconds)
2024-07-18 15:33:46 | INFO | train_inner | epoch 004:   4408 / 19564 loss=4.419, nll_loss=3.028, ppl=8.16, wps=12969.3, ups=3.71, wpb=3493.4, bsz=133, num_updates=63100, lr=0.000125888, gnorm=1.164, train_wall=20, wall=0
2024-07-18 15:34:05 | INFO | train_inner | epoch 004:   4508 / 19564 loss=4.402, nll_loss=3.011, ppl=8.06, wps=17745.9, ups=5.15, wpb=3446.1, bsz=144.2, num_updates=63200, lr=0.000125789, gnorm=1.151, train_wall=19, wall=0
2024-07-18 15:34:25 | INFO | train_inner | epoch 004:   4608 / 19564 loss=4.417, nll_loss=3.027, ppl=8.15, wps=17362.3, ups=5.1, wpb=3406.9, bsz=134.5, num_updates=63300, lr=0.000125689, gnorm=1.152, train_wall=19, wall=0
2024-07-18 15:34:44 | INFO | train_inner | epoch 004:   4708 / 19564 loss=4.445, nll_loss=3.059, ppl=8.34, wps=17591.8, ups=5.05, wpb=3485.3, bsz=141.4, num_updates=63400, lr=0.00012559, gnorm=1.198, train_wall=20, wall=0
2024-07-18 15:35:04 | INFO | train_inner | epoch 004:   4808 / 19564 loss=4.322, nll_loss=2.919, ppl=7.56, wps=17512.8, ups=5.08, wpb=3450.5, bsz=145.8, num_updates=63500, lr=0.000125491, gnorm=1.147, train_wall=20, wall=0
2024-07-18 15:35:24 | INFO | train_inner | epoch 004:   4908 / 19564 loss=4.388, nll_loss=2.994, ppl=7.97, wps=17458.7, ups=5.08, wpb=3435, bsz=137.1, num_updates=63600, lr=0.000125392, gnorm=1.162, train_wall=19, wall=0
2024-07-18 15:35:43 | INFO | train_inner | epoch 004:   5008 / 19564 loss=4.351, nll_loss=2.954, ppl=7.75, wps=17146.2, ups=5.11, wpb=3353, bsz=157.2, num_updates=63700, lr=0.000125294, gnorm=1.21, train_wall=19, wall=0
2024-07-18 15:36:03 | INFO | train_inner | epoch 004:   5108 / 19564 loss=4.338, nll_loss=2.938, ppl=7.66, wps=17442.6, ups=5.08, wpb=3432.2, bsz=153, num_updates=63800, lr=0.000125196, gnorm=1.134, train_wall=19, wall=0
2024-07-18 15:36:23 | INFO | train_inner | epoch 004:   5208 / 19564 loss=4.339, nll_loss=2.937, ppl=7.66, wps=17051, ups=5.07, wpb=3363.7, bsz=149.6, num_updates=63900, lr=0.000125098, gnorm=1.167, train_wall=20, wall=0
2024-07-18 15:36:42 | INFO | train_inner | epoch 004:   5308 / 19564 loss=4.357, nll_loss=2.96, ppl=7.78, wps=17446.6, ups=5.09, wpb=3426.8, bsz=149.3, num_updates=64000, lr=0.000125, gnorm=1.158, train_wall=19, wall=0
2024-07-18 15:36:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:36:45 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.295 | nll_loss 2.782 | ppl 6.88 | wps 54099 | wpb 2872.6 | bsz 51.2 | num_updates 64000 | best_loss 12.134
2024-07-18 15:36:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:36:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_64000.pt (epoch 4 @ 64000 updates, score 4.295) (writing took 6.679577169939876 seconds)
2024-07-18 15:37:11 | INFO | train_inner | epoch 004:   5408 / 19564 loss=4.333, nll_loss=2.932, ppl=7.63, wps=11916.1, ups=3.45, wpb=3456.7, bsz=139.2, num_updates=64100, lr=0.000124902, gnorm=1.115, train_wall=20, wall=0
2024-07-18 15:37:31 | INFO | train_inner | epoch 004:   5508 / 19564 loss=4.321, nll_loss=2.919, ppl=7.56, wps=17678.6, ups=5.1, wpb=3465.9, bsz=149.9, num_updates=64200, lr=0.000124805, gnorm=1.125, train_wall=19, wall=0
2024-07-18 15:37:51 | INFO | train_inner | epoch 004:   5608 / 19564 loss=4.383, nll_loss=2.99, ppl=7.94, wps=17661.2, ups=5.09, wpb=3469.9, bsz=153.2, num_updates=64300, lr=0.000124708, gnorm=1.175, train_wall=19, wall=0
2024-07-18 15:38:10 | INFO | train_inner | epoch 004:   5708 / 19564 loss=4.35, nll_loss=2.951, ppl=7.73, wps=17283, ups=5.09, wpb=3395.4, bsz=134.6, num_updates=64400, lr=0.000124611, gnorm=1.147, train_wall=19, wall=0
2024-07-18 15:38:30 | INFO | train_inner | epoch 004:   5808 / 19564 loss=4.379, nll_loss=2.985, ppl=7.92, wps=16997.1, ups=5.12, wpb=3318.5, bsz=141.3, num_updates=64500, lr=0.000124515, gnorm=1.205, train_wall=19, wall=0
2024-07-18 15:38:50 | INFO | train_inner | epoch 004:   5908 / 19564 loss=4.37, nll_loss=2.972, ppl=7.85, wps=17282.8, ups=5.01, wpb=3449.8, bsz=128.8, num_updates=64600, lr=0.000124418, gnorm=1.129, train_wall=20, wall=0
2024-07-18 15:39:09 | INFO | train_inner | epoch 004:   6008 / 19564 loss=4.383, nll_loss=2.989, ppl=7.94, wps=17653.7, ups=5.12, wpb=3444.7, bsz=138.4, num_updates=64700, lr=0.000124322, gnorm=1.179, train_wall=19, wall=0
2024-07-18 15:39:29 | INFO | train_inner | epoch 004:   6108 / 19564 loss=4.401, nll_loss=3.009, ppl=8.05, wps=17772.6, ups=5.1, wpb=3484.7, bsz=138.4, num_updates=64800, lr=0.000124226, gnorm=1.154, train_wall=19, wall=0
2024-07-18 15:39:48 | INFO | train_inner | epoch 004:   6208 / 19564 loss=4.352, nll_loss=2.954, ppl=7.75, wps=17627.3, ups=5.11, wpb=3452.7, bsz=139.8, num_updates=64900, lr=0.00012413, gnorm=1.136, train_wall=19, wall=0
2024-07-18 15:40:08 | INFO | train_inner | epoch 004:   6308 / 19564 loss=4.374, nll_loss=2.979, ppl=7.88, wps=18061.5, ups=5.08, wpb=3553, bsz=156, num_updates=65000, lr=0.000124035, gnorm=1.126, train_wall=19, wall=0
2024-07-18 15:40:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:40:11 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.278 | nll_loss 2.761 | ppl 6.78 | wps 54874.1 | wpb 2872.6 | bsz 51.2 | num_updates 65000 | best_loss 12.134
2024-07-18 15:40:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:40:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_65000.pt (epoch 4 @ 65000 updates, score 4.278) (writing took 6.395114284940064 seconds)
2024-07-18 15:40:37 | INFO | train_inner | epoch 004:   6408 / 19564 loss=4.33, nll_loss=2.928, ppl=7.61, wps=12037.4, ups=3.48, wpb=3458.6, bsz=139.8, num_updates=65100, lr=0.000123939, gnorm=1.134, train_wall=20, wall=0
2024-07-18 15:40:57 | INFO | train_inner | epoch 004:   6508 / 19564 loss=4.317, nll_loss=2.915, ppl=7.54, wps=17441.7, ups=5.08, wpb=3432.7, bsz=155.3, num_updates=65200, lr=0.000123844, gnorm=1.149, train_wall=19, wall=0
2024-07-18 15:41:16 | INFO | train_inner | epoch 004:   6608 / 19564 loss=4.425, nll_loss=3.036, ppl=8.2, wps=17845.3, ups=5.11, wpb=3489.3, bsz=130.1, num_updates=65300, lr=0.000123749, gnorm=1.159, train_wall=19, wall=0
2024-07-18 15:41:35 | INFO | train_inner | epoch 004:   6708 / 19564 loss=4.428, nll_loss=3.04, ppl=8.23, wps=17573.9, ups=5.19, wpb=3383.1, bsz=145.2, num_updates=65400, lr=0.000123655, gnorm=1.222, train_wall=19, wall=0
2024-07-18 15:41:55 | INFO | train_inner | epoch 004:   6808 / 19564 loss=4.336, nll_loss=2.934, ppl=7.64, wps=17709.2, ups=4.98, wpb=3557.1, bsz=147.5, num_updates=65500, lr=0.00012356, gnorm=1.097, train_wall=20, wall=0
2024-07-18 15:42:15 | INFO | train_inner | epoch 004:   6908 / 19564 loss=4.344, nll_loss=2.945, ppl=7.7, wps=17645.2, ups=5.11, wpb=3454.7, bsz=164.6, num_updates=65600, lr=0.000123466, gnorm=1.159, train_wall=19, wall=0
2024-07-18 15:42:34 | INFO | train_inner | epoch 004:   7008 / 19564 loss=4.323, nll_loss=2.921, ppl=7.57, wps=17847.3, ups=5.15, wpb=3468.8, bsz=154.6, num_updates=65700, lr=0.000123372, gnorm=1.119, train_wall=19, wall=0
2024-07-18 15:42:54 | INFO | train_inner | epoch 004:   7108 / 19564 loss=4.392, nll_loss=2.999, ppl=7.99, wps=17188.6, ups=5.01, wpb=3428.2, bsz=135.3, num_updates=65800, lr=0.000123278, gnorm=1.193, train_wall=20, wall=0
2024-07-18 15:43:14 | INFO | train_inner | epoch 004:   7208 / 19564 loss=4.332, nll_loss=2.93, ppl=7.62, wps=17755.2, ups=5.15, wpb=3448, bsz=144.3, num_updates=65900, lr=0.000123185, gnorm=1.135, train_wall=19, wall=0
2024-07-18 15:43:33 | INFO | train_inner | epoch 004:   7308 / 19564 loss=4.348, nll_loss=2.95, ppl=7.73, wps=17384.2, ups=5.11, wpb=3402.6, bsz=148.2, num_updates=66000, lr=0.000123091, gnorm=1.145, train_wall=19, wall=0
2024-07-18 15:43:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:43:36 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.282 | nll_loss 2.766 | ppl 6.8 | wps 54431.4 | wpb 2872.6 | bsz 51.2 | num_updates 66000 | best_loss 12.134
2024-07-18 15:43:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:43:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_66000.pt (epoch 4 @ 66000 updates, score 4.282) (writing took 3.8882346311584115 seconds)
2024-07-18 15:43:59 | INFO | train_inner | epoch 004:   7408 / 19564 loss=4.432, nll_loss=3.045, ppl=8.25, wps=13100.2, ups=3.88, wpb=3373.1, bsz=141.6, num_updates=66100, lr=0.000122998, gnorm=1.179, train_wall=19, wall=0
2024-07-18 15:44:19 | INFO | train_inner | epoch 004:   7508 / 19564 loss=4.295, nll_loss=2.888, ppl=7.4, wps=17811.9, ups=5.07, wpb=3513, bsz=151.6, num_updates=66200, lr=0.000122905, gnorm=1.093, train_wall=20, wall=0
2024-07-18 15:44:39 | INFO | train_inner | epoch 004:   7608 / 19564 loss=4.322, nll_loss=2.92, ppl=7.57, wps=17826.3, ups=5.1, wpb=3497, bsz=143, num_updates=66300, lr=0.000122813, gnorm=1.114, train_wall=19, wall=0
2024-07-18 15:44:58 | INFO | train_inner | epoch 004:   7708 / 19564 loss=4.363, nll_loss=2.968, ppl=7.82, wps=17542.9, ups=5.12, wpb=3427, bsz=158.7, num_updates=66400, lr=0.00012272, gnorm=1.157, train_wall=19, wall=0
2024-07-18 15:45:17 | INFO | train_inner | epoch 004:   7808 / 19564 loss=4.375, nll_loss=2.98, ppl=7.89, wps=17497.5, ups=5.14, wpb=3402.8, bsz=137.4, num_updates=66500, lr=0.000122628, gnorm=1.147, train_wall=19, wall=0
2024-07-18 15:45:37 | INFO | train_inner | epoch 004:   7908 / 19564 loss=4.353, nll_loss=2.956, ppl=7.76, wps=17387.5, ups=5.12, wpb=3393.9, bsz=149.4, num_updates=66600, lr=0.000122536, gnorm=1.169, train_wall=19, wall=0
2024-07-18 15:45:57 | INFO | train_inner | epoch 004:   8008 / 19564 loss=4.37, nll_loss=2.975, ppl=7.86, wps=17276.6, ups=5.11, wpb=3383.3, bsz=140.1, num_updates=66700, lr=0.000122444, gnorm=1.191, train_wall=19, wall=0
2024-07-18 15:46:16 | INFO | train_inner | epoch 004:   8108 / 19564 loss=4.389, nll_loss=2.996, ppl=7.98, wps=17260.2, ups=5.09, wpb=3392.1, bsz=137.5, num_updates=66800, lr=0.000122352, gnorm=1.157, train_wall=19, wall=0
2024-07-18 15:46:36 | INFO | train_inner | epoch 004:   8208 / 19564 loss=4.29, nll_loss=2.883, ppl=7.37, wps=17530.4, ups=5.13, wpb=3416.6, bsz=148.1, num_updates=66900, lr=0.000122261, gnorm=1.135, train_wall=19, wall=0
2024-07-18 15:46:56 | INFO | train_inner | epoch 004:   8308 / 19564 loss=4.34, nll_loss=2.941, ppl=7.68, wps=17725.4, ups=5.03, wpb=3521.8, bsz=152.7, num_updates=67000, lr=0.000122169, gnorm=1.118, train_wall=20, wall=0
2024-07-18 15:46:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:46:58 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.269 | nll_loss 2.747 | ppl 6.71 | wps 54563.8 | wpb 2872.6 | bsz 51.2 | num_updates 67000 | best_loss 12.134
2024-07-18 15:46:58 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:47:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_67000.pt (epoch 4 @ 67000 updates, score 4.269) (writing took 4.391782432794571 seconds)
2024-07-18 15:47:22 | INFO | train_inner | epoch 004:   8408 / 19564 loss=4.361, nll_loss=2.965, ppl=7.81, wps=12997.5, ups=3.79, wpb=3426.6, bsz=141.7, num_updates=67100, lr=0.000122078, gnorm=1.159, train_wall=19, wall=0
2024-07-18 15:47:41 | INFO | train_inner | epoch 004:   8508 / 19564 loss=4.371, nll_loss=2.975, ppl=7.86, wps=17694.5, ups=5.14, wpb=3441.8, bsz=141.1, num_updates=67200, lr=0.000121988, gnorm=1.175, train_wall=19, wall=0
2024-07-18 15:48:01 | INFO | train_inner | epoch 004:   8608 / 19564 loss=4.334, nll_loss=2.933, ppl=7.64, wps=17943.7, ups=5.07, wpb=3538.2, bsz=140.2, num_updates=67300, lr=0.000121897, gnorm=1.11, train_wall=20, wall=0
2024-07-18 15:48:21 | INFO | train_inner | epoch 004:   8708 / 19564 loss=4.396, nll_loss=3.005, ppl=8.03, wps=17290.9, ups=5.08, wpb=3406.7, bsz=145.7, num_updates=67400, lr=0.000121806, gnorm=1.205, train_wall=20, wall=0
2024-07-18 15:48:40 | INFO | train_inner | epoch 004:   8808 / 19564 loss=4.376, nll_loss=2.981, ppl=7.9, wps=17659.4, ups=5.14, wpb=3436.2, bsz=134.9, num_updates=67500, lr=0.000121716, gnorm=1.152, train_wall=19, wall=0
2024-07-18 15:49:00 | INFO | train_inner | epoch 004:   8908 / 19564 loss=4.352, nll_loss=2.954, ppl=7.75, wps=17683.9, ups=5.12, wpb=3456, bsz=140.8, num_updates=67600, lr=0.000121626, gnorm=1.144, train_wall=19, wall=0
2024-07-18 15:49:19 | INFO | train_inner | epoch 004:   9008 / 19564 loss=4.362, nll_loss=2.966, ppl=7.81, wps=17726, ups=5.1, wpb=3476.8, bsz=138.3, num_updates=67700, lr=0.000121536, gnorm=1.134, train_wall=19, wall=0
2024-07-18 15:49:39 | INFO | train_inner | epoch 004:   9108 / 19564 loss=4.34, nll_loss=2.941, ppl=7.68, wps=17665.9, ups=5.06, wpb=3493.8, bsz=138.2, num_updates=67800, lr=0.000121447, gnorm=1.122, train_wall=20, wall=0
2024-07-18 15:49:59 | INFO | train_inner | epoch 004:   9208 / 19564 loss=4.389, nll_loss=2.995, ppl=7.97, wps=17673.6, ups=5.14, wpb=3437.2, bsz=135, num_updates=67900, lr=0.000121357, gnorm=1.172, train_wall=19, wall=0
2024-07-18 15:50:18 | INFO | train_inner | epoch 004:   9308 / 19564 loss=4.378, nll_loss=2.984, ppl=7.91, wps=17387.9, ups=5.13, wpb=3387.9, bsz=148.9, num_updates=68000, lr=0.000121268, gnorm=1.198, train_wall=19, wall=0
2024-07-18 15:50:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:50:21 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.276 | nll_loss 2.752 | ppl 6.74 | wps 54527.7 | wpb 2872.6 | bsz 51.2 | num_updates 68000 | best_loss 12.134
2024-07-18 15:50:21 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:50:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_68000.pt (epoch 4 @ 68000 updates, score 4.276) (writing took 4.607128792442381 seconds)
2024-07-18 15:50:45 | INFO | train_inner | epoch 004:   9408 / 19564 loss=4.379, nll_loss=2.983, ppl=7.91, wps=13185.5, ups=3.76, wpb=3507.4, bsz=124.6, num_updates=68100, lr=0.000121179, gnorm=1.142, train_wall=19, wall=0
2024-07-18 15:51:04 | INFO | train_inner | epoch 004:   9508 / 19564 loss=4.296, nll_loss=2.891, ppl=7.42, wps=17474.8, ups=5.08, wpb=3440.5, bsz=154.2, num_updates=68200, lr=0.00012109, gnorm=1.133, train_wall=19, wall=0
2024-07-18 15:51:25 | INFO | train_inner | epoch 004:   9608 / 19564 loss=4.285, nll_loss=2.878, ppl=7.35, wps=17663.5, ups=4.99, wpb=3541.2, bsz=153.1, num_updates=68300, lr=0.000121001, gnorm=1.112, train_wall=20, wall=0
2024-07-18 15:51:44 | INFO | train_inner | epoch 004:   9708 / 19564 loss=4.358, nll_loss=2.96, ppl=7.78, wps=17618.6, ups=5.11, wpb=3449.9, bsz=136.7, num_updates=68400, lr=0.000120913, gnorm=1.137, train_wall=19, wall=0
2024-07-18 15:52:04 | INFO | train_inner | epoch 004:   9808 / 19564 loss=4.373, nll_loss=2.978, ppl=7.88, wps=17518.9, ups=5.09, wpb=3440.8, bsz=139.5, num_updates=68500, lr=0.000120824, gnorm=1.177, train_wall=19, wall=0
2024-07-18 15:52:23 | INFO | train_inner | epoch 004:   9908 / 19564 loss=4.373, nll_loss=2.979, ppl=7.88, wps=17659.6, ups=5.11, wpb=3453.8, bsz=139.4, num_updates=68600, lr=0.000120736, gnorm=1.156, train_wall=19, wall=0
2024-07-18 15:52:43 | INFO | train_inner | epoch 004:  10008 / 19564 loss=4.341, nll_loss=2.942, ppl=7.68, wps=17684.5, ups=5.1, wpb=3470.1, bsz=140.2, num_updates=68700, lr=0.000120648, gnorm=1.141, train_wall=19, wall=0
2024-07-18 15:53:03 | INFO | train_inner | epoch 004:  10108 / 19564 loss=4.321, nll_loss=2.92, ppl=7.57, wps=17752.1, ups=5.06, wpb=3510.8, bsz=148.3, num_updates=68800, lr=0.000120561, gnorm=1.129, train_wall=20, wall=0
2024-07-18 15:53:22 | INFO | train_inner | epoch 004:  10208 / 19564 loss=4.315, nll_loss=2.911, ppl=7.52, wps=17473.2, ups=5.06, wpb=3454.4, bsz=141.4, num_updates=68900, lr=0.000120473, gnorm=1.131, train_wall=20, wall=0
2024-07-18 15:53:42 | INFO | train_inner | epoch 004:  10308 / 19564 loss=4.325, nll_loss=2.924, ppl=7.59, wps=17611, ups=5.03, wpb=3498.3, bsz=146.5, num_updates=69000, lr=0.000120386, gnorm=1.133, train_wall=20, wall=0
2024-07-18 15:53:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:53:45 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.259 | nll_loss 2.74 | ppl 6.68 | wps 54697.2 | wpb 2872.6 | bsz 51.2 | num_updates 69000 | best_loss 12.134
2024-07-18 15:53:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:53:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_69000.pt (epoch 4 @ 69000 updates, score 4.259) (writing took 3.889767029322684 seconds)
2024-07-18 15:54:08 | INFO | train_inner | epoch 004:  10408 / 19564 loss=4.367, nll_loss=2.972, ppl=7.84, wps=13167.9, ups=3.86, wpb=3415.1, bsz=135.4, num_updates=69100, lr=0.000120299, gnorm=1.182, train_wall=19, wall=0
2024-07-18 15:54:28 | INFO | train_inner | epoch 004:  10508 / 19564 loss=4.317, nll_loss=2.915, ppl=7.54, wps=17574, ups=5.16, wpb=3405.8, bsz=163, num_updates=69200, lr=0.000120212, gnorm=1.154, train_wall=19, wall=0
2024-07-18 15:54:48 | INFO | train_inner | epoch 004:  10608 / 19564 loss=4.347, nll_loss=2.949, ppl=7.72, wps=17381.6, ups=5.03, wpb=3458.4, bsz=140, num_updates=69300, lr=0.000120125, gnorm=1.163, train_wall=20, wall=0
2024-07-18 15:55:07 | INFO | train_inner | epoch 004:  10708 / 19564 loss=4.304, nll_loss=2.9, ppl=7.46, wps=17359.6, ups=5.13, wpb=3386.3, bsz=152.7, num_updates=69400, lr=0.000120038, gnorm=1.152, train_wall=19, wall=0
2024-07-18 15:55:27 | INFO | train_inner | epoch 004:  10808 / 19564 loss=4.471, nll_loss=3.09, ppl=8.51, wps=17600.4, ups=5.13, wpb=3432.1, bsz=122.6, num_updates=69500, lr=0.000119952, gnorm=1.176, train_wall=19, wall=0
2024-07-18 15:55:46 | INFO | train_inner | epoch 004:  10908 / 19564 loss=4.34, nll_loss=2.94, ppl=7.68, wps=17703.6, ups=5.03, wpb=3522, bsz=153.8, num_updates=69600, lr=0.000119866, gnorm=1.123, train_wall=20, wall=0
2024-07-18 15:56:06 | INFO | train_inner | epoch 004:  11008 / 19564 loss=4.308, nll_loss=2.903, ppl=7.48, wps=17663.3, ups=5.11, wpb=3454.3, bsz=138.6, num_updates=69700, lr=0.00011978, gnorm=1.157, train_wall=19, wall=0
2024-07-18 15:56:26 | INFO | train_inner | epoch 004:  11108 / 19564 loss=4.345, nll_loss=2.946, ppl=7.71, wps=17435.4, ups=5.06, wpb=3445, bsz=142.3, num_updates=69800, lr=0.000119694, gnorm=1.14, train_wall=20, wall=0
2024-07-18 15:56:46 | INFO | train_inner | epoch 004:  11208 / 19564 loss=4.385, nll_loss=2.992, ppl=7.96, wps=17459.5, ups=5.02, wpb=3480.3, bsz=134.2, num_updates=69900, lr=0.000119608, gnorm=1.144, train_wall=20, wall=0
2024-07-18 15:57:05 | INFO | train_inner | epoch 004:  11308 / 19564 loss=4.358, nll_loss=2.961, ppl=7.79, wps=17680.4, ups=5.13, wpb=3445.5, bsz=129.3, num_updates=70000, lr=0.000119523, gnorm=1.149, train_wall=19, wall=0
2024-07-18 15:57:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 15:57:08 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.264 | nll_loss 2.747 | ppl 6.71 | wps 54743.4 | wpb 2872.6 | bsz 51.2 | num_updates 70000 | best_loss 12.134
2024-07-18 15:57:08 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 15:57:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_70000.pt (epoch 4 @ 70000 updates, score 4.264) (writing took 3.5603691367432475 seconds)
2024-07-18 15:57:31 | INFO | train_inner | epoch 004:  11408 / 19564 loss=4.339, nll_loss=2.94, ppl=7.68, wps=13536.6, ups=3.91, wpb=3460.2, bsz=140.3, num_updates=70100, lr=0.000119438, gnorm=1.114, train_wall=19, wall=0
2024-07-18 15:57:51 | INFO | train_inner | epoch 004:  11508 / 19564 loss=4.315, nll_loss=2.912, ppl=7.53, wps=17667.6, ups=5.04, wpb=3502.2, bsz=155.4, num_updates=70200, lr=0.000119352, gnorm=1.123, train_wall=20, wall=0
2024-07-18 15:58:10 | INFO | train_inner | epoch 004:  11608 / 19564 loss=4.344, nll_loss=2.945, ppl=7.7, wps=17944.2, ups=5.09, wpb=3523.4, bsz=154.1, num_updates=70300, lr=0.000119268, gnorm=1.129, train_wall=19, wall=0
2024-07-18 15:58:30 | INFO | train_inner | epoch 004:  11708 / 19564 loss=4.296, nll_loss=2.891, ppl=7.42, wps=17766.4, ups=5.15, wpb=3453.1, bsz=144.6, num_updates=70400, lr=0.000119183, gnorm=1.112, train_wall=19, wall=0
2024-07-18 15:58:49 | INFO | train_inner | epoch 004:  11808 / 19564 loss=4.313, nll_loss=2.911, ppl=7.52, wps=17491.1, ups=5.07, wpb=3448.1, bsz=163.3, num_updates=70500, lr=0.000119098, gnorm=1.166, train_wall=20, wall=0
2024-07-18 15:59:09 | INFO | train_inner | epoch 004:  11908 / 19564 loss=4.351, nll_loss=2.954, ppl=7.75, wps=17231.6, ups=5.15, wpb=3344, bsz=153.7, num_updates=70600, lr=0.000119014, gnorm=1.225, train_wall=19, wall=0
2024-07-18 15:59:28 | INFO | train_inner | epoch 004:  12008 / 19564 loss=4.346, nll_loss=2.948, ppl=7.72, wps=17565.6, ups=5.13, wpb=3425.3, bsz=151, num_updates=70700, lr=0.00011893, gnorm=1.154, train_wall=19, wall=0
2024-07-18 15:59:48 | INFO | train_inner | epoch 004:  12108 / 19564 loss=4.325, nll_loss=2.925, ppl=7.59, wps=17586.3, ups=5.11, wpb=3439.8, bsz=136.1, num_updates=70800, lr=0.000118846, gnorm=1.154, train_wall=19, wall=0
2024-07-18 16:00:08 | INFO | train_inner | epoch 004:  12208 / 19564 loss=4.296, nll_loss=2.89, ppl=7.41, wps=17912.6, ups=5.06, wpb=3538.2, bsz=141.8, num_updates=70900, lr=0.000118762, gnorm=1.085, train_wall=20, wall=0
2024-07-18 16:00:28 | INFO | train_inner | epoch 004:  12308 / 19564 loss=4.422, nll_loss=3.034, ppl=8.19, wps=17060.4, ups=5.01, wpb=3402, bsz=124.7, num_updates=71000, lr=0.000118678, gnorm=1.215, train_wall=20, wall=0
2024-07-18 16:00:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:00:30 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.251 | nll_loss 2.729 | ppl 6.63 | wps 54199.2 | wpb 2872.6 | bsz 51.2 | num_updates 71000 | best_loss 12.134
2024-07-18 16:00:30 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:00:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_71000.pt (epoch 4 @ 71000 updates, score 4.251) (writing took 4.551121315918863 seconds)
2024-07-18 16:00:54 | INFO | train_inner | epoch 004:  12408 / 19564 loss=4.299, nll_loss=2.895, ppl=7.44, wps=12891.3, ups=3.72, wpb=3466.6, bsz=154.1, num_updates=71100, lr=0.000118595, gnorm=1.132, train_wall=20, wall=0
2024-07-18 16:01:14 | INFO | train_inner | epoch 004:  12508 / 19564 loss=4.347, nll_loss=2.948, ppl=7.72, wps=17904.9, ups=5.01, wpb=3571.1, bsz=128, num_updates=71200, lr=0.000118511, gnorm=1.125, train_wall=20, wall=0
2024-07-18 16:01:34 | INFO | train_inner | epoch 004:  12608 / 19564 loss=4.365, nll_loss=2.968, ppl=7.83, wps=17121.9, ups=5.07, wpb=3379.7, bsz=140.6, num_updates=71300, lr=0.000118428, gnorm=1.205, train_wall=20, wall=0
2024-07-18 16:01:54 | INFO | train_inner | epoch 004:  12708 / 19564 loss=4.362, nll_loss=2.966, ppl=7.81, wps=17438.1, ups=5.14, wpb=3393.1, bsz=140.2, num_updates=71400, lr=0.000118345, gnorm=1.166, train_wall=19, wall=0
2024-07-18 16:02:13 | INFO | train_inner | epoch 004:  12808 / 19564 loss=4.352, nll_loss=2.955, ppl=7.76, wps=17084.8, ups=5.04, wpb=3389.8, bsz=146.5, num_updates=71500, lr=0.000118262, gnorm=1.189, train_wall=20, wall=0
2024-07-18 16:02:33 | INFO | train_inner | epoch 004:  12908 / 19564 loss=4.311, nll_loss=2.908, ppl=7.51, wps=17339.2, ups=5.13, wpb=3379, bsz=151.5, num_updates=71600, lr=0.00011818, gnorm=1.149, train_wall=19, wall=0
2024-07-18 16:02:53 | INFO | train_inner | epoch 004:  13008 / 19564 loss=4.301, nll_loss=2.897, ppl=7.45, wps=17463.5, ups=5.07, wpb=3441.4, bsz=142.6, num_updates=71700, lr=0.000118097, gnorm=1.159, train_wall=20, wall=0
2024-07-18 16:03:12 | INFO | train_inner | epoch 004:  13108 / 19564 loss=4.295, nll_loss=2.89, ppl=7.41, wps=17632.1, ups=5.13, wpb=3435.8, bsz=142.2, num_updates=71800, lr=0.000118015, gnorm=1.164, train_wall=19, wall=0
2024-07-18 16:03:32 | INFO | train_inner | epoch 004:  13208 / 19564 loss=4.291, nll_loss=2.886, ppl=7.39, wps=17324.5, ups=5.07, wpb=3417.8, bsz=151.9, num_updates=71900, lr=0.000117933, gnorm=1.127, train_wall=20, wall=0
2024-07-18 16:03:51 | INFO | train_inner | epoch 004:  13308 / 19564 loss=4.339, nll_loss=2.94, ppl=7.68, wps=17549.6, ups=5.11, wpb=3437.3, bsz=155.4, num_updates=72000, lr=0.000117851, gnorm=1.144, train_wall=19, wall=0
2024-07-18 16:03:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:03:54 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.236 | nll_loss 2.717 | ppl 6.58 | wps 54039.2 | wpb 2872.6 | bsz 51.2 | num_updates 72000 | best_loss 12.134
2024-07-18 16:03:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:03:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_72000.pt (epoch 4 @ 72000 updates, score 4.236) (writing took 3.3371356735005975 seconds)
2024-07-18 16:04:17 | INFO | train_inner | epoch 004:  13408 / 19564 loss=4.327, nll_loss=2.927, ppl=7.6, wps=13589.1, ups=3.95, wpb=3440.1, bsz=143.1, num_updates=72100, lr=0.000117769, gnorm=1.183, train_wall=19, wall=0
2024-07-18 16:04:36 | INFO | train_inner | epoch 004:  13508 / 19564 loss=4.343, nll_loss=2.943, ppl=7.69, wps=17420.9, ups=5.07, wpb=3434.4, bsz=118.6, num_updates=72200, lr=0.000117688, gnorm=1.182, train_wall=20, wall=0
2024-07-18 16:04:56 | INFO | train_inner | epoch 004:  13608 / 19564 loss=4.414, nll_loss=3.026, ppl=8.14, wps=17145.1, ups=5.11, wpb=3354.4, bsz=133.3, num_updates=72300, lr=0.000117606, gnorm=1.204, train_wall=19, wall=0
2024-07-18 16:05:16 | INFO | train_inner | epoch 004:  13708 / 19564 loss=4.424, nll_loss=3.038, ppl=8.21, wps=17732.2, ups=5.1, wpb=3478.9, bsz=134.2, num_updates=72400, lr=0.000117525, gnorm=1.156, train_wall=19, wall=0
2024-07-18 16:05:36 | INFO | train_inner | epoch 004:  13808 / 19564 loss=4.349, nll_loss=2.953, ppl=7.74, wps=17409.2, ups=5.01, wpb=3472, bsz=141.8, num_updates=72500, lr=0.000117444, gnorm=1.116, train_wall=20, wall=0
2024-07-18 16:05:55 | INFO | train_inner | epoch 004:  13908 / 19564 loss=4.314, nll_loss=2.911, ppl=7.52, wps=17963.4, ups=5.1, wpb=3523.5, bsz=139.7, num_updates=72600, lr=0.000117363, gnorm=1.116, train_wall=19, wall=0
2024-07-18 16:06:15 | INFO | train_inner | epoch 004:  14008 / 19564 loss=4.368, nll_loss=2.974, ppl=7.86, wps=17276.6, ups=4.99, wpb=3459.1, bsz=128.5, num_updates=72700, lr=0.000117282, gnorm=1.172, train_wall=20, wall=0
2024-07-18 16:06:35 | INFO | train_inner | epoch 004:  14108 / 19564 loss=4.365, nll_loss=2.971, ppl=7.84, wps=17478.1, ups=5.12, wpb=3414.1, bsz=139.2, num_updates=72800, lr=0.000117202, gnorm=1.145, train_wall=19, wall=0
2024-07-18 16:06:55 | INFO | train_inner | epoch 004:  14208 / 19564 loss=4.276, nll_loss=2.868, ppl=7.3, wps=17560.9, ups=5.02, wpb=3497.6, bsz=148.2, num_updates=72900, lr=0.000117121, gnorm=1.09, train_wall=20, wall=0
2024-07-18 16:07:15 | INFO | train_inner | epoch 004:  14308 / 19564 loss=4.352, nll_loss=2.955, ppl=7.75, wps=16703.7, ups=4.96, wpb=3367, bsz=132.7, num_updates=73000, lr=0.000117041, gnorm=1.179, train_wall=20, wall=0
2024-07-18 16:07:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:07:17 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.232 | nll_loss 2.702 | ppl 6.51 | wps 54005.7 | wpb 2872.6 | bsz 51.2 | num_updates 73000 | best_loss 12.134
2024-07-18 16:07:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:07:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_73000.pt (epoch 4 @ 73000 updates, score 4.232) (writing took 3.335464778356254 seconds)
2024-07-18 16:07:40 | INFO | train_inner | epoch 004:  14408 / 19564 loss=4.317, nll_loss=2.916, ppl=7.55, wps=13600.1, ups=3.94, wpb=3447.8, bsz=144.5, num_updates=73100, lr=0.000116961, gnorm=1.148, train_wall=19, wall=0
2024-07-18 16:08:00 | INFO | train_inner | epoch 004:  14508 / 19564 loss=4.277, nll_loss=2.87, ppl=7.31, wps=17260.8, ups=5.04, wpb=3427.2, bsz=147.6, num_updates=73200, lr=0.000116881, gnorm=1.135, train_wall=20, wall=0
2024-07-18 16:08:19 | INFO | train_inner | epoch 004:  14608 / 19564 loss=4.416, nll_loss=3.027, ppl=8.15, wps=17651.5, ups=5.17, wpb=3414.8, bsz=115.8, num_updates=73300, lr=0.000116801, gnorm=1.198, train_wall=19, wall=0
2024-07-18 16:08:39 | INFO | train_inner | epoch 004:  14708 / 19564 loss=4.295, nll_loss=2.89, ppl=7.41, wps=17653, ups=5.04, wpb=3501.5, bsz=149.8, num_updates=73400, lr=0.000116722, gnorm=1.119, train_wall=20, wall=0
2024-07-18 16:08:59 | INFO | train_inner | epoch 004:  14808 / 19564 loss=4.319, nll_loss=2.917, ppl=7.55, wps=17721.3, ups=4.95, wpb=3583.6, bsz=153.2, num_updates=73500, lr=0.000116642, gnorm=1.099, train_wall=20, wall=0
2024-07-18 16:09:19 | INFO | train_inner | epoch 004:  14908 / 19564 loss=4.376, nll_loss=2.983, ppl=7.9, wps=17682.6, ups=5.11, wpb=3459.6, bsz=133.6, num_updates=73600, lr=0.000116563, gnorm=1.139, train_wall=19, wall=0
2024-07-18 16:09:39 | INFO | train_inner | epoch 004:  15008 / 19564 loss=4.353, nll_loss=2.958, ppl=7.77, wps=17480.4, ups=5.06, wpb=3455.9, bsz=154.5, num_updates=73700, lr=0.000116484, gnorm=1.158, train_wall=20, wall=0
2024-07-18 16:09:59 | INFO | train_inner | epoch 004:  15108 / 19564 loss=4.309, nll_loss=2.907, ppl=7.5, wps=17319.3, ups=5.03, wpb=3440.3, bsz=164.6, num_updates=73800, lr=0.000116405, gnorm=1.131, train_wall=20, wall=0
2024-07-18 16:10:18 | INFO | train_inner | epoch 004:  15208 / 19564 loss=4.316, nll_loss=2.915, ppl=7.54, wps=16913.9, ups=5.05, wpb=3348.6, bsz=148.7, num_updates=73900, lr=0.000116326, gnorm=1.181, train_wall=20, wall=0
2024-07-18 16:10:38 | INFO | train_inner | epoch 004:  15308 / 19564 loss=4.258, nll_loss=2.847, ppl=7.2, wps=17721.5, ups=5.06, wpb=3503, bsz=137.2, num_updates=74000, lr=0.000116248, gnorm=1.099, train_wall=20, wall=0
2024-07-18 16:10:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:10:41 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.227 | nll_loss 2.699 | ppl 6.49 | wps 53953.7 | wpb 2872.6 | bsz 51.2 | num_updates 74000 | best_loss 12.134
2024-07-18 16:10:41 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:10:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_74000.pt (epoch 4 @ 74000 updates, score 4.227) (writing took 4.988979883491993 seconds)
2024-07-18 16:11:05 | INFO | train_inner | epoch 004:  15408 / 19564 loss=4.4, nll_loss=3.011, ppl=8.06, wps=12597.5, ups=3.67, wpb=3429.1, bsz=139.9, num_updates=74100, lr=0.000116169, gnorm=1.188, train_wall=20, wall=0
2024-07-18 16:11:25 | INFO | train_inner | epoch 004:  15508 / 19564 loss=4.401, nll_loss=3.011, ppl=8.06, wps=17759.5, ups=5.15, wpb=3450.8, bsz=130.4, num_updates=74200, lr=0.000116091, gnorm=1.165, train_wall=19, wall=0
2024-07-18 16:11:44 | INFO | train_inner | epoch 004:  15608 / 19564 loss=4.301, nll_loss=2.898, ppl=7.45, wps=17124.1, ups=5.1, wpb=3357.4, bsz=152.7, num_updates=74300, lr=0.000116013, gnorm=1.188, train_wall=19, wall=0
2024-07-18 16:12:04 | INFO | train_inner | epoch 004:  15708 / 19564 loss=4.372, nll_loss=2.979, ppl=7.88, wps=17229, ups=5.14, wpb=3348.8, bsz=145, num_updates=74400, lr=0.000115935, gnorm=1.229, train_wall=19, wall=0
2024-07-18 16:12:24 | INFO | train_inner | epoch 004:  15808 / 19564 loss=4.327, nll_loss=2.927, ppl=7.6, wps=18023.7, ups=5.03, wpb=3582.4, bsz=162.2, num_updates=74500, lr=0.000115857, gnorm=1.117, train_wall=20, wall=0
2024-07-18 16:12:44 | INFO | train_inner | epoch 004:  15908 / 19564 loss=4.342, nll_loss=2.944, ppl=7.69, wps=17122.1, ups=5.06, wpb=3383.7, bsz=122.8, num_updates=74600, lr=0.000115779, gnorm=1.219, train_wall=20, wall=0
2024-07-18 16:13:03 | INFO | train_inner | epoch 004:  16008 / 19564 loss=4.333, nll_loss=2.935, ppl=7.65, wps=17594.7, ups=5.08, wpb=3466.1, bsz=133.9, num_updates=74700, lr=0.000115702, gnorm=1.149, train_wall=19, wall=0
2024-07-18 16:13:23 | INFO | train_inner | epoch 004:  16108 / 19564 loss=4.301, nll_loss=2.896, ppl=7.44, wps=17687, ups=5.07, wpb=3489.8, bsz=134.3, num_updates=74800, lr=0.000115624, gnorm=1.121, train_wall=20, wall=0
2024-07-18 16:13:43 | INFO | train_inner | epoch 004:  16208 / 19564 loss=4.42, nll_loss=3.032, ppl=8.18, wps=17366.3, ups=5.11, wpb=3400.4, bsz=123.6, num_updates=74900, lr=0.000115547, gnorm=1.19, train_wall=19, wall=0
2024-07-18 16:14:02 | INFO | train_inner | epoch 004:  16308 / 19564 loss=4.372, nll_loss=2.977, ppl=7.88, wps=17299.9, ups=5.08, wpb=3406.7, bsz=122.7, num_updates=75000, lr=0.00011547, gnorm=1.146, train_wall=19, wall=0
2024-07-18 16:14:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:14:05 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.209 | nll_loss 2.688 | ppl 6.44 | wps 54165.5 | wpb 2872.6 | bsz 51.2 | num_updates 75000 | best_loss 12.134
2024-07-18 16:14:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:14:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_75000.pt (epoch 4 @ 75000 updates, score 4.209) (writing took 3.272683847695589 seconds)
2024-07-18 16:14:28 | INFO | train_inner | epoch 004:  16408 / 19564 loss=4.315, nll_loss=2.914, ppl=7.54, wps=13810.6, ups=3.91, wpb=3529.7, bsz=149.7, num_updates=75100, lr=0.000115393, gnorm=1.144, train_wall=20, wall=0
2024-07-18 16:14:47 | INFO | train_inner | epoch 004:  16508 / 19564 loss=4.376, nll_loss=2.983, ppl=7.9, wps=17662.6, ups=5.13, wpb=3442.5, bsz=129.7, num_updates=75200, lr=0.000115316, gnorm=1.145, train_wall=19, wall=0
2024-07-18 16:15:07 | INFO | train_inner | epoch 004:  16608 / 19564 loss=4.353, nll_loss=2.956, ppl=7.76, wps=17895.7, ups=5.16, wpb=3471, bsz=133.8, num_updates=75300, lr=0.00011524, gnorm=1.135, train_wall=19, wall=0
2024-07-18 16:15:26 | INFO | train_inner | epoch 004:  16708 / 19564 loss=4.33, nll_loss=2.931, ppl=7.63, wps=17393.8, ups=5.09, wpb=3414, bsz=146.6, num_updates=75400, lr=0.000115163, gnorm=1.176, train_wall=19, wall=0
2024-07-18 16:15:46 | INFO | train_inner | epoch 004:  16808 / 19564 loss=4.349, nll_loss=2.953, ppl=7.74, wps=17269.1, ups=5.08, wpb=3397, bsz=135, num_updates=75500, lr=0.000115087, gnorm=1.183, train_wall=19, wall=0
2024-07-18 16:16:06 | INFO | train_inner | epoch 004:  16908 / 19564 loss=4.353, nll_loss=2.957, ppl=7.76, wps=17314, ups=5.07, wpb=3412.3, bsz=140.8, num_updates=75600, lr=0.000115011, gnorm=1.167, train_wall=20, wall=0
2024-07-18 16:16:25 | INFO | train_inner | epoch 004:  17008 / 19564 loss=4.361, nll_loss=2.966, ppl=7.81, wps=17429.1, ups=5.11, wpb=3408.5, bsz=132.1, num_updates=75700, lr=0.000114935, gnorm=1.186, train_wall=19, wall=0
2024-07-18 16:16:45 | INFO | train_inner | epoch 004:  17108 / 19564 loss=4.304, nll_loss=2.903, ppl=7.48, wps=17616.9, ups=5.1, wpb=3450.9, bsz=172.1, num_updates=75800, lr=0.000114859, gnorm=1.152, train_wall=19, wall=0
2024-07-18 16:17:04 | INFO | train_inner | epoch 004:  17208 / 19564 loss=4.336, nll_loss=2.937, ppl=7.66, wps=17640.9, ups=5.15, wpb=3425.9, bsz=132.4, num_updates=75900, lr=0.000114783, gnorm=1.144, train_wall=19, wall=0
2024-07-18 16:17:24 | INFO | train_inner | epoch 004:  17308 / 19564 loss=4.393, nll_loss=3.003, ppl=8.01, wps=17320.5, ups=5.14, wpb=3372.2, bsz=138.7, num_updates=76000, lr=0.000114708, gnorm=1.217, train_wall=19, wall=0
2024-07-18 16:17:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:17:26 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.214 | nll_loss 2.697 | ppl 6.49 | wps 54146.1 | wpb 2872.6 | bsz 51.2 | num_updates 76000 | best_loss 12.134
2024-07-18 16:17:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:17:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_76000.pt (epoch 4 @ 76000 updates, score 4.214) (writing took 3.2401054548099637 seconds)
2024-07-18 16:17:49 | INFO | train_inner | epoch 004:  17408 / 19564 loss=4.323, nll_loss=2.923, ppl=7.58, wps=13818.4, ups=3.95, wpb=3497.2, bsz=149.7, num_updates=76100, lr=0.000114632, gnorm=1.109, train_wall=19, wall=0
2024-07-18 16:18:09 | INFO | train_inner | epoch 004:  17508 / 19564 loss=4.34, nll_loss=2.942, ppl=7.69, wps=17595.6, ups=5.09, wpb=3457.7, bsz=140.8, num_updates=76200, lr=0.000114557, gnorm=1.154, train_wall=19, wall=0
2024-07-18 16:18:28 | INFO | train_inner | epoch 004:  17608 / 19564 loss=4.289, nll_loss=2.885, ppl=7.38, wps=17625, ups=5.07, wpb=3474.5, bsz=146.4, num_updates=76300, lr=0.000114482, gnorm=1.139, train_wall=20, wall=0
2024-07-18 16:18:48 | INFO | train_inner | epoch 004:  17708 / 19564 loss=4.309, nll_loss=2.907, ppl=7.5, wps=17540.5, ups=5.09, wpb=3448.2, bsz=144.7, num_updates=76400, lr=0.000114407, gnorm=1.174, train_wall=19, wall=0
2024-07-18 16:19:08 | INFO | train_inner | epoch 004:  17808 / 19564 loss=4.327, nll_loss=2.927, ppl=7.6, wps=17231.6, ups=4.91, wpb=3512.2, bsz=140.1, num_updates=76500, lr=0.000114332, gnorm=1.14, train_wall=20, wall=0
2024-07-18 16:19:28 | INFO | train_inner | epoch 004:  17908 / 19564 loss=4.313, nll_loss=2.913, ppl=7.53, wps=17614.4, ups=5.08, wpb=3465.1, bsz=158.3, num_updates=76600, lr=0.000114258, gnorm=1.153, train_wall=19, wall=0
2024-07-18 16:19:48 | INFO | train_inner | epoch 004:  18008 / 19564 loss=4.406, nll_loss=3.016, ppl=8.09, wps=17131.3, ups=4.97, wpb=3450.2, bsz=126.6, num_updates=76700, lr=0.000114183, gnorm=1.196, train_wall=20, wall=0
2024-07-18 16:20:08 | INFO | train_inner | epoch 004:  18108 / 19564 loss=4.335, nll_loss=2.938, ppl=7.66, wps=17111.4, ups=5.13, wpb=3335.5, bsz=149.8, num_updates=76800, lr=0.000114109, gnorm=1.211, train_wall=19, wall=0
2024-07-18 16:20:27 | INFO | train_inner | epoch 004:  18208 / 19564 loss=4.342, nll_loss=2.944, ppl=7.7, wps=17172.7, ups=5.09, wpb=3373.7, bsz=139.1, num_updates=76900, lr=0.000114035, gnorm=1.166, train_wall=19, wall=0
2024-07-18 16:20:47 | INFO | train_inner | epoch 004:  18308 / 19564 loss=4.282, nll_loss=2.876, ppl=7.34, wps=17127.7, ups=5, wpb=3424.7, bsz=149.8, num_updates=77000, lr=0.000113961, gnorm=1.164, train_wall=20, wall=0
2024-07-18 16:20:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:20:50 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.213 | nll_loss 2.689 | ppl 6.45 | wps 53823.2 | wpb 2872.6 | bsz 51.2 | num_updates 77000 | best_loss 12.134
2024-07-18 16:20:50 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:20:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_77000.pt (epoch 4 @ 77000 updates, score 4.213) (writing took 3.560766371898353 seconds)
2024-07-18 16:21:13 | INFO | train_inner | epoch 004:  18408 / 19564 loss=4.401, nll_loss=3.011, ppl=8.06, wps=13316.6, ups=3.84, wpb=3469.7, bsz=134.2, num_updates=77100, lr=0.000113887, gnorm=1.161, train_wall=20, wall=0
2024-07-18 16:21:33 | INFO | train_inner | epoch 004:  18508 / 19564 loss=4.304, nll_loss=2.9, ppl=7.47, wps=18182.5, ups=5.16, wpb=3526.7, bsz=146.1, num_updates=77200, lr=0.000113813, gnorm=1.134, train_wall=19, wall=0
2024-07-18 16:21:53 | INFO | train_inner | epoch 004:  18608 / 19564 loss=4.374, nll_loss=2.981, ppl=7.9, wps=17004, ups=5.02, wpb=3390.5, bsz=128.7, num_updates=77300, lr=0.000113739, gnorm=1.176, train_wall=20, wall=0
2024-07-18 16:22:13 | INFO | train_inner | epoch 004:  18708 / 19564 loss=4.36, nll_loss=2.964, ppl=7.8, wps=17517.8, ups=5.04, wpb=3475.2, bsz=137.4, num_updates=77400, lr=0.000113666, gnorm=1.146, train_wall=20, wall=0
2024-07-18 16:22:32 | INFO | train_inner | epoch 004:  18808 / 19564 loss=4.305, nll_loss=2.903, ppl=7.48, wps=17647.1, ups=5.04, wpb=3501.4, bsz=158.6, num_updates=77500, lr=0.000113592, gnorm=1.114, train_wall=20, wall=0
2024-07-18 16:22:52 | INFO | train_inner | epoch 004:  18908 / 19564 loss=4.29, nll_loss=2.886, ppl=7.39, wps=17489.6, ups=5.08, wpb=3445.3, bsz=139.5, num_updates=77600, lr=0.000113519, gnorm=1.159, train_wall=19, wall=0
2024-07-18 16:23:12 | INFO | train_inner | epoch 004:  19008 / 19564 loss=4.408, nll_loss=3.02, ppl=8.11, wps=17384.7, ups=5.03, wpb=3456.9, bsz=128.9, num_updates=77700, lr=0.000113446, gnorm=1.174, train_wall=20, wall=0
2024-07-18 16:23:32 | INFO | train_inner | epoch 004:  19108 / 19564 loss=4.318, nll_loss=2.917, ppl=7.55, wps=17356, ups=4.96, wpb=3501.3, bsz=145.8, num_updates=77800, lr=0.000113373, gnorm=1.126, train_wall=20, wall=0
2024-07-18 16:23:52 | INFO | train_inner | epoch 004:  19208 / 19564 loss=4.315, nll_loss=2.914, ppl=7.54, wps=17484.4, ups=5.04, wpb=3471.2, bsz=134.3, num_updates=77900, lr=0.0001133, gnorm=1.148, train_wall=20, wall=0
2024-07-18 16:24:12 | INFO | train_inner | epoch 004:  19308 / 19564 loss=4.302, nll_loss=2.9, ppl=7.46, wps=17199.1, ups=5.02, wpb=3429.4, bsz=153.2, num_updates=78000, lr=0.000113228, gnorm=1.17, train_wall=20, wall=0
2024-07-18 16:24:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:24:14 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.199 | nll_loss 2.679 | ppl 6.41 | wps 53951.7 | wpb 2872.6 | bsz 51.2 | num_updates 78000 | best_loss 12.134
2024-07-18 16:24:14 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:24:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_4_78000.pt (epoch 4 @ 78000 updates, score 4.199) (writing took 3.2888870760798454 seconds)
2024-07-18 16:24:38 | INFO | train_inner | epoch 004:  19408 / 19564 loss=4.372, nll_loss=2.98, ppl=7.89, wps=13443.3, ups=3.91, wpb=3435.2, bsz=144.8, num_updates=78100, lr=0.000113155, gnorm=1.159, train_wall=20, wall=0
2024-07-18 16:24:57 | INFO | train_inner | epoch 004:  19508 / 19564 loss=4.301, nll_loss=2.899, ppl=7.46, wps=17536.9, ups=5.06, wpb=3464.1, bsz=157.1, num_updates=78200, lr=0.000113083, gnorm=1.139, train_wall=20, wall=0
2024-07-18 16:25:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:25:11 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.213 | nll_loss 2.692 | ppl 6.46 | wps 53952.5 | wpb 2872.6 | bsz 51.2 | num_updates 78256 | best_loss 12.134
2024-07-18 16:25:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:25:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 4 @ 78256 updates, score 4.213) (writing took 3.626441149972379 seconds)
2024-07-18 16:25:14 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2024-07-18 16:25:14 | INFO | train | epoch 004 | loss 4.355 | nll_loss 2.958 | ppl 7.77 | wps 16905 | ups 4.91 | wpb 3446.5 | bsz 142.2 | num_updates 78256 | lr 0.000113042 | gnorm 1.153 | train_wall 3808 | wall 0
2024-07-18 16:25:14 | INFO | fairseq.trainer | begin training epoch 5
2024-07-18 16:25:23 | INFO | train_inner | epoch 005:     44 / 19564 loss=4.308, nll_loss=2.907, ppl=7.5, wps=13330, ups=3.87, wpb=3444.8, bsz=154.2, num_updates=78300, lr=0.000113011, gnorm=1.133, train_wall=19, wall=0
2024-07-18 16:25:43 | INFO | train_inner | epoch 005:    144 / 19564 loss=4.253, nll_loss=2.843, ppl=7.17, wps=17611.6, ups=5.08, wpb=3469.4, bsz=144.6, num_updates=78400, lr=0.000112938, gnorm=1.153, train_wall=20, wall=0
2024-07-18 16:26:02 | INFO | train_inner | epoch 005:    244 / 19564 loss=4.305, nll_loss=2.903, ppl=7.48, wps=17214.9, ups=5.17, wpb=3331.1, bsz=147, num_updates=78500, lr=0.000112867, gnorm=1.22, train_wall=19, wall=0
2024-07-18 16:26:22 | INFO | train_inner | epoch 005:    344 / 19564 loss=4.283, nll_loss=2.877, ppl=7.35, wps=17499.5, ups=5.02, wpb=3485.4, bsz=146.5, num_updates=78600, lr=0.000112795, gnorm=1.133, train_wall=20, wall=0
2024-07-18 16:26:42 | INFO | train_inner | epoch 005:    444 / 19564 loss=4.326, nll_loss=2.927, ppl=7.61, wps=17264.2, ups=5.11, wpb=3381, bsz=133.2, num_updates=78700, lr=0.000112723, gnorm=1.167, train_wall=19, wall=0
2024-07-18 16:27:01 | INFO | train_inner | epoch 005:    544 / 19564 loss=4.295, nll_loss=2.892, ppl=7.42, wps=17438.8, ups=5.07, wpb=3440.6, bsz=147.9, num_updates=78800, lr=0.000112651, gnorm=1.179, train_wall=20, wall=0
2024-07-18 16:27:21 | INFO | train_inner | epoch 005:    644 / 19564 loss=4.27, nll_loss=2.861, ppl=7.27, wps=17252.8, ups=5.08, wpb=3399, bsz=133.9, num_updates=78900, lr=0.00011258, gnorm=1.152, train_wall=19, wall=0
2024-07-18 16:27:41 | INFO | train_inner | epoch 005:    744 / 19564 loss=4.273, nll_loss=2.867, ppl=7.29, wps=17527.3, ups=5.05, wpb=3471.5, bsz=156.6, num_updates=79000, lr=0.000112509, gnorm=1.15, train_wall=20, wall=0
2024-07-18 16:27:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:27:43 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.212 | nll_loss 2.687 | ppl 6.44 | wps 53835.6 | wpb 2872.6 | bsz 51.2 | num_updates 79000 | best_loss 12.134
2024-07-18 16:27:43 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:27:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_79000.pt (epoch 5 @ 79000 updates, score 4.212) (writing took 4.086710484698415 seconds)
2024-07-18 16:28:07 | INFO | train_inner | epoch 005:    844 / 19564 loss=4.33, nll_loss=2.932, ppl=7.63, wps=13242.7, ups=3.8, wpb=3485.8, bsz=147.7, num_updates=79100, lr=0.000112438, gnorm=1.16, train_wall=20, wall=0
2024-07-18 16:28:27 | INFO | train_inner | epoch 005:    944 / 19564 loss=4.289, nll_loss=2.884, ppl=7.38, wps=17651.3, ups=5.16, wpb=3422.6, bsz=138, num_updates=79200, lr=0.000112367, gnorm=1.179, train_wall=19, wall=0
2024-07-18 16:28:47 | INFO | train_inner | epoch 005:   1044 / 19564 loss=4.263, nll_loss=2.854, ppl=7.23, wps=17623.9, ups=4.98, wpb=3537.7, bsz=156.8, num_updates=79300, lr=0.000112296, gnorm=1.12, train_wall=20, wall=0
2024-07-18 16:29:06 | INFO | train_inner | epoch 005:   1144 / 19564 loss=4.3, nll_loss=2.895, ppl=7.44, wps=17646, ups=5.16, wpb=3418.7, bsz=126.9, num_updates=79400, lr=0.000112225, gnorm=1.179, train_wall=19, wall=0
2024-07-18 16:29:26 | INFO | train_inner | epoch 005:   1244 / 19564 loss=4.299, nll_loss=2.896, ppl=7.45, wps=17375.6, ups=5.07, wpb=3424.4, bsz=148.2, num_updates=79500, lr=0.000112154, gnorm=1.138, train_wall=20, wall=0
2024-07-18 16:29:46 | INFO | train_inner | epoch 005:   1344 / 19564 loss=4.323, nll_loss=2.921, ppl=7.58, wps=17729.1, ups=4.99, wpb=3552.4, bsz=137, num_updates=79600, lr=0.000112084, gnorm=1.141, train_wall=20, wall=0
2024-07-18 16:30:05 | INFO | train_inner | epoch 005:   1444 / 19564 loss=4.284, nll_loss=2.879, ppl=7.36, wps=17579.3, ups=5.13, wpb=3430, bsz=158.8, num_updates=79700, lr=0.000112014, gnorm=1.148, train_wall=19, wall=0
2024-07-18 16:30:25 | INFO | train_inner | epoch 005:   1544 / 19564 loss=4.352, nll_loss=2.955, ppl=7.75, wps=17254.9, ups=5.04, wpb=3426.7, bsz=126, num_updates=79800, lr=0.000111943, gnorm=1.186, train_wall=20, wall=0
2024-07-18 16:30:45 | INFO | train_inner | epoch 005:   1644 / 19564 loss=4.263, nll_loss=2.854, ppl=7.23, wps=17639.1, ups=5.09, wpb=3463.2, bsz=141.2, num_updates=79900, lr=0.000111873, gnorm=1.129, train_wall=19, wall=0
2024-07-18 16:31:05 | INFO | train_inner | epoch 005:   1744 / 19564 loss=4.253, nll_loss=2.843, ppl=7.17, wps=16759.6, ups=4.97, wpb=3369.1, bsz=131.7, num_updates=80000, lr=0.000111803, gnorm=1.16, train_wall=20, wall=0
2024-07-18 16:31:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:31:07 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.2 | nll_loss 2.672 | ppl 6.37 | wps 53416.8 | wpb 2872.6 | bsz 51.2 | num_updates 80000 | best_loss 12.134
2024-07-18 16:31:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:31:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_80000.pt (epoch 5 @ 80000 updates, score 4.2) (writing took 3.624070566147566 seconds)
2024-07-18 16:31:31 | INFO | train_inner | epoch 005:   1844 / 19564 loss=4.238, nll_loss=2.826, ppl=7.09, wps=13130.3, ups=3.78, wpb=3473.4, bsz=156.6, num_updates=80100, lr=0.000111734, gnorm=1.134, train_wall=20, wall=0
2024-07-18 16:31:51 | INFO | train_inner | epoch 005:   1944 / 19564 loss=4.29, nll_loss=2.885, ppl=7.39, wps=17746.5, ups=5.1, wpb=3476.9, bsz=144.7, num_updates=80200, lr=0.000111664, gnorm=1.14, train_wall=19, wall=0
2024-07-18 16:32:11 | INFO | train_inner | epoch 005:   2044 / 19564 loss=4.272, nll_loss=2.865, ppl=7.29, wps=16692.3, ups=5.11, wpb=3263.7, bsz=144.7, num_updates=80300, lr=0.000111594, gnorm=1.186, train_wall=19, wall=0
2024-07-18 16:32:31 | INFO | train_inner | epoch 005:   2144 / 19564 loss=4.34, nll_loss=2.942, ppl=7.69, wps=16816.3, ups=4.98, wpb=3378.7, bsz=137, num_updates=80400, lr=0.000111525, gnorm=1.194, train_wall=20, wall=0
2024-07-18 16:32:50 | INFO | train_inner | epoch 005:   2244 / 19564 loss=4.3, nll_loss=2.897, ppl=7.45, wps=17990.7, ups=5.11, wpb=3523.6, bsz=159.8, num_updates=80500, lr=0.000111456, gnorm=1.144, train_wall=19, wall=0
2024-07-18 16:33:10 | INFO | train_inner | epoch 005:   2344 / 19564 loss=4.271, nll_loss=2.863, ppl=7.27, wps=17636.1, ups=5.06, wpb=3484.3, bsz=138.2, num_updates=80600, lr=0.000111386, gnorm=1.131, train_wall=20, wall=0
2024-07-18 16:33:30 | INFO | train_inner | epoch 005:   2444 / 19564 loss=4.23, nll_loss=2.816, ppl=7.04, wps=17388.4, ups=4.98, wpb=3492.9, bsz=148.2, num_updates=80700, lr=0.000111317, gnorm=1.147, train_wall=20, wall=0
2024-07-18 16:33:50 | INFO | train_inner | epoch 005:   2544 / 19564 loss=4.335, nll_loss=2.937, ppl=7.66, wps=17513.3, ups=5.1, wpb=3432.4, bsz=137.2, num_updates=80800, lr=0.000111249, gnorm=1.207, train_wall=19, wall=0
2024-07-18 16:34:09 | INFO | train_inner | epoch 005:   2644 / 19564 loss=4.298, nll_loss=2.894, ppl=7.44, wps=17712, ups=5.1, wpb=3472, bsz=128.3, num_updates=80900, lr=0.00011118, gnorm=1.131, train_wall=19, wall=0
2024-07-18 16:34:30 | INFO | train_inner | epoch 005:   2744 / 19564 loss=4.269, nll_loss=2.86, ppl=7.26, wps=16692.5, ups=4.86, wpb=3433.4, bsz=126.4, num_updates=81000, lr=0.000111111, gnorm=1.145, train_wall=20, wall=0
2024-07-18 16:34:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:34:32 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.196 | nll_loss 2.668 | ppl 6.36 | wps 54138.5 | wpb 2872.6 | bsz 51.2 | num_updates 81000 | best_loss 12.134
2024-07-18 16:34:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:34:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_81000.pt (epoch 5 @ 81000 updates, score 4.196) (writing took 4.004066529683769 seconds)
2024-07-18 16:34:56 | INFO | train_inner | epoch 005:   2844 / 19564 loss=4.283, nll_loss=2.876, ppl=7.34, wps=13227.1, ups=3.83, wpb=3450.8, bsz=129.2, num_updates=81100, lr=0.000111043, gnorm=1.153, train_wall=19, wall=0
2024-07-18 16:35:16 | INFO | train_inner | epoch 005:   2944 / 19564 loss=4.252, nll_loss=2.843, ppl=7.17, wps=17711.4, ups=5.1, wpb=3471.3, bsz=152.9, num_updates=81200, lr=0.000110974, gnorm=1.14, train_wall=19, wall=0
2024-07-18 16:35:35 | INFO | train_inner | epoch 005:   3044 / 19564 loss=4.23, nll_loss=2.819, ppl=7.06, wps=17381.4, ups=5.08, wpb=3419.9, bsz=163.7, num_updates=81300, lr=0.000110906, gnorm=1.154, train_wall=19, wall=0
2024-07-18 16:35:55 | INFO | train_inner | epoch 005:   3144 / 19564 loss=4.271, nll_loss=2.862, ppl=7.27, wps=17693.3, ups=5.01, wpb=3534.6, bsz=137.9, num_updates=81400, lr=0.000110838, gnorm=1.132, train_wall=20, wall=0
2024-07-18 16:36:15 | INFO | train_inner | epoch 005:   3244 / 19564 loss=4.307, nll_loss=2.905, ppl=7.49, wps=17512.7, ups=5.06, wpb=3462.3, bsz=148.1, num_updates=81500, lr=0.00011077, gnorm=1.172, train_wall=20, wall=0
2024-07-18 16:36:35 | INFO | train_inner | epoch 005:   3344 / 19564 loss=4.249, nll_loss=2.839, ppl=7.16, wps=17413.6, ups=5, wpb=3483.6, bsz=154.7, num_updates=81600, lr=0.000110702, gnorm=1.135, train_wall=20, wall=0
2024-07-18 16:36:54 | INFO | train_inner | epoch 005:   3444 / 19564 loss=4.308, nll_loss=2.906, ppl=7.5, wps=17832.8, ups=5.13, wpb=3473.8, bsz=139.1, num_updates=81700, lr=0.000110634, gnorm=1.142, train_wall=19, wall=0
2024-07-18 16:37:14 | INFO | train_inner | epoch 005:   3544 / 19564 loss=4.313, nll_loss=2.912, ppl=7.53, wps=17604.2, ups=5.09, wpb=3456.8, bsz=145.1, num_updates=81800, lr=0.000110566, gnorm=1.147, train_wall=19, wall=0
2024-07-18 16:37:34 | INFO | train_inner | epoch 005:   3644 / 19564 loss=4.152, nll_loss=2.728, ppl=6.63, wps=17434.5, ups=4.94, wpb=3529.6, bsz=160.6, num_updates=81900, lr=0.000110499, gnorm=1.075, train_wall=20, wall=0
2024-07-18 16:37:54 | INFO | train_inner | epoch 005:   3744 / 19564 loss=4.324, nll_loss=2.924, ppl=7.59, wps=17319, ups=5.11, wpb=3389.3, bsz=127.4, num_updates=82000, lr=0.000110432, gnorm=1.202, train_wall=19, wall=0
2024-07-18 16:37:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:37:56 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.195 | nll_loss 2.663 | ppl 6.33 | wps 53836 | wpb 2872.6 | bsz 51.2 | num_updates 82000 | best_loss 12.134
2024-07-18 16:37:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:38:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_82000.pt (epoch 5 @ 82000 updates, score 4.195) (writing took 4.417147750966251 seconds)
2024-07-18 16:38:20 | INFO | train_inner | epoch 005:   3844 / 19564 loss=4.267, nll_loss=2.86, ppl=7.26, wps=13007.3, ups=3.77, wpb=3445.7, bsz=155.4, num_updates=82100, lr=0.000110364, gnorm=1.129, train_wall=19, wall=0
2024-07-18 16:38:40 | INFO | train_inner | epoch 005:   3944 / 19564 loss=4.3, nll_loss=2.898, ppl=7.45, wps=17714.5, ups=5.06, wpb=3503, bsz=151, num_updates=82200, lr=0.000110297, gnorm=1.15, train_wall=20, wall=0
2024-07-18 16:39:00 | INFO | train_inner | epoch 005:   4044 / 19564 loss=4.326, nll_loss=2.926, ppl=7.6, wps=17346.2, ups=5.07, wpb=3421, bsz=132, num_updates=82300, lr=0.00011023, gnorm=1.174, train_wall=20, wall=0
2024-07-18 16:39:20 | INFO | train_inner | epoch 005:   4144 / 19564 loss=4.379, nll_loss=2.987, ppl=7.93, wps=17478, ups=5.1, wpb=3424.1, bsz=125.1, num_updates=82400, lr=0.000110163, gnorm=1.187, train_wall=19, wall=0
2024-07-18 16:39:39 | INFO | train_inner | epoch 005:   4244 / 19564 loss=4.25, nll_loss=2.839, ppl=7.16, wps=17523.4, ups=5.1, wpb=3435.6, bsz=149.7, num_updates=82500, lr=0.000110096, gnorm=1.138, train_wall=19, wall=0
2024-07-18 16:39:59 | INFO | train_inner | epoch 005:   4344 / 19564 loss=4.28, nll_loss=2.874, ppl=7.33, wps=17997.6, ups=5.04, wpb=3572.1, bsz=139.8, num_updates=82600, lr=0.00011003, gnorm=1.108, train_wall=20, wall=0
2024-07-18 16:40:18 | INFO | train_inner | epoch 005:   4444 / 19564 loss=4.342, nll_loss=2.946, ppl=7.7, wps=17551.5, ups=5.14, wpb=3414.7, bsz=130, num_updates=82700, lr=0.000109963, gnorm=1.21, train_wall=19, wall=0
2024-07-18 16:40:38 | INFO | train_inner | epoch 005:   4544 / 19564 loss=4.243, nll_loss=2.831, ppl=7.12, wps=17517.2, ups=5.16, wpb=3396.2, bsz=132.6, num_updates=82800, lr=0.000109897, gnorm=1.164, train_wall=19, wall=0
2024-07-18 16:40:58 | INFO | train_inner | epoch 005:   4644 / 19564 loss=4.236, nll_loss=2.823, ppl=7.08, wps=17460, ups=5.03, wpb=3470.4, bsz=150.2, num_updates=82900, lr=0.00010983, gnorm=1.141, train_wall=20, wall=0
2024-07-18 16:41:18 | INFO | train_inner | epoch 005:   4744 / 19564 loss=4.29, nll_loss=2.885, ppl=7.39, wps=17444.2, ups=4.98, wpb=3506.3, bsz=140.2, num_updates=83000, lr=0.000109764, gnorm=1.119, train_wall=20, wall=0
2024-07-18 16:41:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:41:20 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.172 | nll_loss 2.643 | ppl 6.25 | wps 53862.6 | wpb 2872.6 | bsz 51.2 | num_updates 83000 | best_loss 12.134
2024-07-18 16:41:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:41:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_83000.pt (epoch 5 @ 83000 updates, score 4.172) (writing took 3.632430828176439 seconds)
2024-07-18 16:41:44 | INFO | train_inner | epoch 005:   4844 / 19564 loss=4.285, nll_loss=2.881, ppl=7.37, wps=13350.6, ups=3.87, wpb=3446.1, bsz=141.7, num_updates=83100, lr=0.000109698, gnorm=1.143, train_wall=20, wall=0
2024-07-18 16:42:03 | INFO | train_inner | epoch 005:   4944 / 19564 loss=4.365, nll_loss=2.97, ppl=7.84, wps=17435.6, ups=5.16, wpb=3376.7, bsz=131.9, num_updates=83200, lr=0.000109632, gnorm=1.205, train_wall=19, wall=0
2024-07-18 16:42:23 | INFO | train_inner | epoch 005:   5044 / 19564 loss=4.232, nll_loss=2.818, ppl=7.05, wps=17604, ups=5.09, wpb=3457.3, bsz=135.9, num_updates=83300, lr=0.000109566, gnorm=1.132, train_wall=19, wall=0
2024-07-18 16:42:43 | INFO | train_inner | epoch 005:   5144 / 19564 loss=4.251, nll_loss=2.842, ppl=7.17, wps=17428.9, ups=4.92, wpb=3542.6, bsz=154.6, num_updates=83400, lr=0.000109501, gnorm=1.117, train_wall=20, wall=0
2024-07-18 16:43:03 | INFO | train_inner | epoch 005:   5244 / 19564 loss=4.284, nll_loss=2.877, ppl=7.35, wps=17660.4, ups=5.11, wpb=3456.3, bsz=132.5, num_updates=83500, lr=0.000109435, gnorm=1.182, train_wall=19, wall=0
2024-07-18 16:43:22 | INFO | train_inner | epoch 005:   5344 / 19564 loss=4.304, nll_loss=2.902, ppl=7.47, wps=17799.5, ups=5.01, wpb=3549.7, bsz=132, num_updates=83600, lr=0.00010937, gnorm=1.115, train_wall=20, wall=0
2024-07-18 16:43:42 | INFO | train_inner | epoch 005:   5444 / 19564 loss=4.256, nll_loss=2.848, ppl=7.2, wps=17797.8, ups=5.04, wpb=3530.2, bsz=142.3, num_updates=83700, lr=0.000109304, gnorm=1.126, train_wall=20, wall=0
2024-07-18 16:44:02 | INFO | train_inner | epoch 005:   5544 / 19564 loss=4.336, nll_loss=2.938, ppl=7.67, wps=17765.3, ups=5.15, wpb=3452.2, bsz=138.1, num_updates=83800, lr=0.000109239, gnorm=1.189, train_wall=19, wall=0
2024-07-18 16:44:22 | INFO | train_inner | epoch 005:   5644 / 19564 loss=4.211, nll_loss=2.797, ppl=6.95, wps=17731.8, ups=5.03, wpb=3528.3, bsz=166.1, num_updates=83900, lr=0.000109174, gnorm=1.116, train_wall=20, wall=0
2024-07-18 16:44:41 | INFO | train_inner | epoch 005:   5744 / 19564 loss=4.268, nll_loss=2.862, ppl=7.27, wps=17582.3, ups=5.04, wpb=3489.1, bsz=156.7, num_updates=84000, lr=0.000109109, gnorm=1.151, train_wall=20, wall=0
2024-07-18 16:44:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:44:44 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.186 | nll_loss 2.662 | ppl 6.33 | wps 53980 | wpb 2872.6 | bsz 51.2 | num_updates 84000 | best_loss 12.134
2024-07-18 16:44:44 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:44:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_84000.pt (epoch 5 @ 84000 updates, score 4.186) (writing took 4.1636515613645315 seconds)
2024-07-18 16:45:08 | INFO | train_inner | epoch 005:   5844 / 19564 loss=4.288, nll_loss=2.884, ppl=7.38, wps=13117.6, ups=3.81, wpb=3440.8, bsz=146, num_updates=84100, lr=0.000109044, gnorm=1.147, train_wall=19, wall=0
2024-07-18 16:45:28 | INFO | train_inner | epoch 005:   5944 / 19564 loss=4.257, nll_loss=2.848, ppl=7.2, wps=17672.3, ups=4.96, wpb=3562.9, bsz=141.8, num_updates=84200, lr=0.000108979, gnorm=1.108, train_wall=20, wall=0
2024-07-18 16:45:48 | INFO | train_inner | epoch 005:   6044 / 19564 loss=4.211, nll_loss=2.796, ppl=6.94, wps=17395, ups=4.93, wpb=3530.4, bsz=147.8, num_updates=84300, lr=0.000108915, gnorm=1.1, train_wall=20, wall=0
2024-07-18 16:46:08 | INFO | train_inner | epoch 005:   6144 / 19564 loss=4.245, nll_loss=2.835, ppl=7.13, wps=17573.4, ups=5.03, wpb=3492.4, bsz=141, num_updates=84400, lr=0.00010885, gnorm=1.14, train_wall=20, wall=0
2024-07-18 16:46:28 | INFO | train_inner | epoch 005:   6244 / 19564 loss=4.335, nll_loss=2.938, ppl=7.66, wps=17553.2, ups=5.11, wpb=3435.3, bsz=138.5, num_updates=84500, lr=0.000108786, gnorm=1.17, train_wall=19, wall=0
2024-07-18 16:46:47 | INFO | train_inner | epoch 005:   6344 / 19564 loss=4.328, nll_loss=2.93, ppl=7.62, wps=17410.5, ups=5.14, wpb=3389.2, bsz=139.7, num_updates=84600, lr=0.000108721, gnorm=1.205, train_wall=19, wall=0
2024-07-18 16:47:07 | INFO | train_inner | epoch 005:   6444 / 19564 loss=4.314, nll_loss=2.914, ppl=7.54, wps=17514.7, ups=5.05, wpb=3468.7, bsz=154.8, num_updates=84700, lr=0.000108657, gnorm=1.196, train_wall=20, wall=0
2024-07-18 16:47:26 | INFO | train_inner | epoch 005:   6544 / 19564 loss=4.248, nll_loss=2.836, ppl=7.14, wps=17614.4, ups=5.1, wpb=3453.1, bsz=128.8, num_updates=84800, lr=0.000108593, gnorm=1.137, train_wall=19, wall=0
2024-07-18 16:47:47 | INFO | train_inner | epoch 005:   6644 / 19564 loss=4.26, nll_loss=2.851, ppl=7.22, wps=17101.9, ups=4.94, wpb=3459.8, bsz=144.1, num_updates=84900, lr=0.000108529, gnorm=1.156, train_wall=20, wall=0
2024-07-18 16:48:06 | INFO | train_inner | epoch 005:   6744 / 19564 loss=4.304, nll_loss=2.902, ppl=7.47, wps=17862.5, ups=5.08, wpb=3517, bsz=140.4, num_updates=85000, lr=0.000108465, gnorm=1.119, train_wall=19, wall=0
2024-07-18 16:48:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:48:09 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.167 | nll_loss 2.64 | ppl 6.24 | wps 54199.5 | wpb 2872.6 | bsz 51.2 | num_updates 85000 | best_loss 12.134
2024-07-18 16:48:09 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:48:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_85000.pt (epoch 5 @ 85000 updates, score 4.167) (writing took 5.142289143055677 seconds)
2024-07-18 16:48:34 | INFO | train_inner | epoch 005:   6844 / 19564 loss=4.326, nll_loss=2.926, ppl=7.6, wps=12429.4, ups=3.68, wpb=3380.5, bsz=128.2, num_updates=85100, lr=0.000108401, gnorm=1.214, train_wall=19, wall=0
2024-07-18 16:48:54 | INFO | train_inner | epoch 005:   6944 / 19564 loss=4.311, nll_loss=2.912, ppl=7.52, wps=17376.3, ups=5, wpb=3476.3, bsz=143.8, num_updates=85200, lr=0.000108338, gnorm=1.142, train_wall=20, wall=0
2024-07-18 16:49:13 | INFO | train_inner | epoch 005:   7044 / 19564 loss=4.309, nll_loss=2.909, ppl=7.51, wps=17754.8, ups=5.09, wpb=3491.6, bsz=148.1, num_updates=85300, lr=0.000108274, gnorm=1.148, train_wall=19, wall=0
2024-07-18 16:49:33 | INFO | train_inner | epoch 005:   7144 / 19564 loss=4.227, nll_loss=2.813, ppl=7.03, wps=17689.4, ups=5.01, wpb=3532.8, bsz=134.6, num_updates=85400, lr=0.000108211, gnorm=1.106, train_wall=20, wall=0
2024-07-18 16:49:53 | INFO | train_inner | epoch 005:   7244 / 19564 loss=4.319, nll_loss=2.919, ppl=7.56, wps=17314.4, ups=5.08, wpb=3408.5, bsz=136.2, num_updates=85500, lr=0.000108148, gnorm=1.188, train_wall=19, wall=0
2024-07-18 16:50:13 | INFO | train_inner | epoch 005:   7344 / 19564 loss=4.258, nll_loss=2.852, ppl=7.22, wps=17270.9, ups=4.98, wpb=3464.8, bsz=166.7, num_updates=85600, lr=0.000108084, gnorm=1.141, train_wall=20, wall=0
2024-07-18 16:50:33 | INFO | train_inner | epoch 005:   7444 / 19564 loss=4.245, nll_loss=2.834, ppl=7.13, wps=16933.8, ups=5.02, wpb=3374.9, bsz=143, num_updates=85700, lr=0.000108021, gnorm=1.162, train_wall=20, wall=0
2024-07-18 16:50:53 | INFO | train_inner | epoch 005:   7544 / 19564 loss=4.325, nll_loss=2.927, ppl=7.6, wps=17308.9, ups=5.07, wpb=3411.2, bsz=133.6, num_updates=85800, lr=0.000107958, gnorm=1.193, train_wall=20, wall=0
2024-07-18 16:51:13 | INFO | train_inner | epoch 005:   7644 / 19564 loss=4.285, nll_loss=2.881, ppl=7.37, wps=17429.5, ups=4.96, wpb=3513.5, bsz=145.8, num_updates=85900, lr=0.000107896, gnorm=1.148, train_wall=20, wall=0
2024-07-18 16:51:33 | INFO | train_inner | epoch 005:   7744 / 19564 loss=4.263, nll_loss=2.855, ppl=7.23, wps=17446.4, ups=5.04, wpb=3461.3, bsz=143.1, num_updates=86000, lr=0.000107833, gnorm=1.143, train_wall=20, wall=0
2024-07-18 16:51:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:51:35 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.17 | nll_loss 2.642 | ppl 6.24 | wps 53720.8 | wpb 2872.6 | bsz 51.2 | num_updates 86000 | best_loss 12.134
2024-07-18 16:51:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:51:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_86000.pt (epoch 5 @ 86000 updates, score 4.17) (writing took 4.160154283978045 seconds)
2024-07-18 16:51:59 | INFO | train_inner | epoch 005:   7844 / 19564 loss=4.327, nll_loss=2.93, ppl=7.62, wps=12885.3, ups=3.82, wpb=3372.6, bsz=142.5, num_updates=86100, lr=0.00010777, gnorm=1.241, train_wall=19, wall=0
2024-07-18 16:52:18 | INFO | train_inner | epoch 005:   7944 / 19564 loss=4.25, nll_loss=2.841, ppl=7.16, wps=17629.8, ups=5.14, wpb=3429.7, bsz=144.3, num_updates=86200, lr=0.000107708, gnorm=1.176, train_wall=19, wall=0
2024-07-18 16:52:38 | INFO | train_inner | epoch 005:   8044 / 19564 loss=4.268, nll_loss=2.863, ppl=7.28, wps=17964.1, ups=5.13, wpb=3501.5, bsz=169.8, num_updates=86300, lr=0.000107645, gnorm=1.143, train_wall=19, wall=0
2024-07-18 16:52:57 | INFO | train_inner | epoch 005:   8144 / 19564 loss=4.331, nll_loss=2.932, ppl=7.63, wps=17461.9, ups=5.14, wpb=3395.7, bsz=119.6, num_updates=86400, lr=0.000107583, gnorm=1.182, train_wall=19, wall=0
2024-07-18 16:53:17 | INFO | train_inner | epoch 005:   8244 / 19564 loss=4.273, nll_loss=2.867, ppl=7.3, wps=17804.3, ups=5.12, wpb=3477.1, bsz=134.2, num_updates=86500, lr=0.000107521, gnorm=1.153, train_wall=19, wall=0
2024-07-18 16:53:36 | INFO | train_inner | epoch 005:   8344 / 19564 loss=4.318, nll_loss=2.917, ppl=7.55, wps=17685.1, ups=5.22, wpb=3386.4, bsz=127.1, num_updates=86600, lr=0.000107459, gnorm=1.206, train_wall=19, wall=0
2024-07-18 16:53:55 | INFO | train_inner | epoch 005:   8444 / 19564 loss=4.28, nll_loss=2.875, ppl=7.34, wps=17833.6, ups=5.12, wpb=3483.6, bsz=141.4, num_updates=86700, lr=0.000107397, gnorm=1.136, train_wall=19, wall=0
2024-07-18 16:54:15 | INFO | train_inner | epoch 005:   8544 / 19564 loss=4.252, nll_loss=2.843, ppl=7.18, wps=17673.6, ups=5.09, wpb=3469.6, bsz=151.2, num_updates=86800, lr=0.000107335, gnorm=1.134, train_wall=19, wall=0
2024-07-18 16:54:35 | INFO | train_inner | epoch 005:   8644 / 19564 loss=4.277, nll_loss=2.871, ppl=7.32, wps=17849.2, ups=5.09, wpb=3509.5, bsz=146.8, num_updates=86900, lr=0.000107273, gnorm=1.151, train_wall=19, wall=0
2024-07-18 16:54:54 | INFO | train_inner | epoch 005:   8744 / 19564 loss=4.276, nll_loss=2.871, ppl=7.31, wps=17550.7, ups=5.11, wpb=3432.7, bsz=134.3, num_updates=87000, lr=0.000107211, gnorm=1.165, train_wall=19, wall=0
2024-07-18 16:54:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:54:57 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.169 | nll_loss 2.639 | ppl 6.23 | wps 53786.3 | wpb 2872.6 | bsz 51.2 | num_updates 87000 | best_loss 12.134
2024-07-18 16:54:57 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:55:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_87000.pt (epoch 5 @ 87000 updates, score 4.169) (writing took 4.3295297883450985 seconds)
2024-07-18 16:55:21 | INFO | train_inner | epoch 005:   8844 / 19564 loss=4.299, nll_loss=2.897, ppl=7.45, wps=12945.9, ups=3.76, wpb=3442.2, bsz=157.3, num_updates=87100, lr=0.00010715, gnorm=1.171, train_wall=20, wall=0
2024-07-18 16:55:40 | INFO | train_inner | epoch 005:   8944 / 19564 loss=4.29, nll_loss=2.887, ppl=7.4, wps=17505.4, ups=5.14, wpb=3404, bsz=142.3, num_updates=87200, lr=0.000107088, gnorm=1.181, train_wall=19, wall=0
2024-07-18 16:56:00 | INFO | train_inner | epoch 005:   9044 / 19564 loss=4.291, nll_loss=2.887, ppl=7.4, wps=17523, ups=5.14, wpb=3406.2, bsz=137, num_updates=87300, lr=0.000107027, gnorm=1.187, train_wall=19, wall=0
2024-07-18 16:56:19 | INFO | train_inner | epoch 005:   9144 / 19564 loss=4.283, nll_loss=2.879, ppl=7.36, wps=17543.8, ups=5.1, wpb=3440.6, bsz=147, num_updates=87400, lr=0.000106966, gnorm=1.163, train_wall=19, wall=0
2024-07-18 16:56:39 | INFO | train_inner | epoch 005:   9244 / 19564 loss=4.275, nll_loss=2.87, ppl=7.31, wps=17580.3, ups=5.03, wpb=3491.6, bsz=156.5, num_updates=87500, lr=0.000106904, gnorm=1.114, train_wall=20, wall=0
2024-07-18 16:56:59 | INFO | train_inner | epoch 005:   9344 / 19564 loss=4.275, nll_loss=2.87, ppl=7.31, wps=17288.9, ups=5.1, wpb=3388.9, bsz=142.9, num_updates=87600, lr=0.000106843, gnorm=1.19, train_wall=19, wall=0
2024-07-18 16:57:18 | INFO | train_inner | epoch 005:   9444 / 19564 loss=4.274, nll_loss=2.869, ppl=7.3, wps=17346.2, ups=5.12, wpb=3389.7, bsz=147.8, num_updates=87700, lr=0.000106783, gnorm=1.157, train_wall=19, wall=0
2024-07-18 16:57:38 | INFO | train_inner | epoch 005:   9544 / 19564 loss=4.303, nll_loss=2.901, ppl=7.47, wps=17740.6, ups=5.06, wpb=3509.4, bsz=139.2, num_updates=87800, lr=0.000106722, gnorm=1.151, train_wall=20, wall=0
2024-07-18 16:57:58 | INFO | train_inner | epoch 005:   9644 / 19564 loss=4.31, nll_loss=2.909, ppl=7.51, wps=16934.5, ups=5.08, wpb=3336.8, bsz=132.2, num_updates=87900, lr=0.000106661, gnorm=1.213, train_wall=20, wall=0
2024-07-18 16:58:17 | INFO | train_inner | epoch 005:   9744 / 19564 loss=4.341, nll_loss=2.945, ppl=7.7, wps=17390, ups=5.14, wpb=3383.2, bsz=131.4, num_updates=88000, lr=0.0001066, gnorm=1.208, train_wall=19, wall=0
2024-07-18 16:58:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 16:58:20 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.169 | nll_loss 2.636 | ppl 6.22 | wps 54477.5 | wpb 2872.6 | bsz 51.2 | num_updates 88000 | best_loss 12.134
2024-07-18 16:58:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 16:58:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_88000.pt (epoch 5 @ 88000 updates, score 4.169) (writing took 10.385470865294337 seconds)
2024-07-18 16:58:50 | INFO | train_inner | epoch 005:   9844 / 19564 loss=4.326, nll_loss=2.928, ppl=7.61, wps=10454.2, ups=3.1, wpb=3374.4, bsz=143.7, num_updates=88100, lr=0.00010654, gnorm=1.198, train_wall=19, wall=0
2024-07-18 16:59:09 | INFO | train_inner | epoch 005:   9944 / 19564 loss=4.283, nll_loss=2.879, ppl=7.35, wps=17712.5, ups=5.15, wpb=3438.5, bsz=131.1, num_updates=88200, lr=0.000106479, gnorm=1.163, train_wall=19, wall=0
2024-07-18 16:59:29 | INFO | train_inner | epoch 005:  10044 / 19564 loss=4.271, nll_loss=2.863, ppl=7.28, wps=17716.8, ups=4.99, wpb=3550, bsz=131, num_updates=88300, lr=0.000106419, gnorm=1.127, train_wall=20, wall=0
2024-07-18 16:59:49 | INFO | train_inner | epoch 005:  10144 / 19564 loss=4.278, nll_loss=2.874, ppl=7.33, wps=17466.2, ups=5.12, wpb=3412.2, bsz=143.9, num_updates=88400, lr=0.000106359, gnorm=1.168, train_wall=19, wall=0
2024-07-18 17:00:08 | INFO | train_inner | epoch 005:  10244 / 19564 loss=4.3, nll_loss=2.898, ppl=7.45, wps=17465.8, ups=5.05, wpb=3456.3, bsz=139.8, num_updates=88500, lr=0.000106299, gnorm=1.155, train_wall=20, wall=0
2024-07-18 17:00:28 | INFO | train_inner | epoch 005:  10344 / 19564 loss=4.274, nll_loss=2.869, ppl=7.31, wps=17864.2, ups=5.13, wpb=3482.7, bsz=138.5, num_updates=88600, lr=0.000106239, gnorm=1.138, train_wall=19, wall=0
2024-07-18 17:00:48 | INFO | train_inner | epoch 005:  10444 / 19564 loss=4.173, nll_loss=2.753, ppl=6.74, wps=17688.5, ups=5.01, wpb=3534.1, bsz=154.4, num_updates=88700, lr=0.000106179, gnorm=1.098, train_wall=20, wall=0
2024-07-18 17:01:08 | INFO | train_inner | epoch 005:  10544 / 19564 loss=4.3, nll_loss=2.898, ppl=7.45, wps=16776.4, ups=5.05, wpb=3322.6, bsz=138.4, num_updates=88800, lr=0.000106119, gnorm=1.205, train_wall=20, wall=0
2024-07-18 17:01:27 | INFO | train_inner | epoch 005:  10644 / 19564 loss=4.22, nll_loss=2.807, ppl=7, wps=17817.1, ups=5.12, wpb=3478.3, bsz=143.8, num_updates=88900, lr=0.000106059, gnorm=1.109, train_wall=19, wall=0
2024-07-18 17:01:46 | INFO | train_inner | epoch 005:  10744 / 19564 loss=4.345, nll_loss=2.95, ppl=7.73, wps=17632.7, ups=5.18, wpb=3403.6, bsz=125, num_updates=89000, lr=0.000106, gnorm=1.228, train_wall=19, wall=0
2024-07-18 17:01:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:01:49 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.174 | nll_loss 2.645 | ppl 6.25 | wps 54121.3 | wpb 2872.6 | bsz 51.2 | num_updates 89000 | best_loss 12.134
2024-07-18 17:01:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:01:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_89000.pt (epoch 5 @ 89000 updates, score 4.174) (writing took 5.627635071985424 seconds)
2024-07-18 17:02:14 | INFO | train_inner | epoch 005:  10844 / 19564 loss=4.282, nll_loss=2.878, ppl=7.35, wps=12317, ups=3.57, wpb=3450, bsz=141.5, num_updates=89100, lr=0.00010594, gnorm=1.163, train_wall=20, wall=0
2024-07-18 17:02:34 | INFO | train_inner | epoch 005:  10944 / 19564 loss=4.318, nll_loss=2.918, ppl=7.56, wps=17688.1, ups=5.16, wpb=3429.9, bsz=135.4, num_updates=89200, lr=0.000105881, gnorm=1.2, train_wall=19, wall=0
2024-07-18 17:02:54 | INFO | train_inner | epoch 005:  11044 / 19564 loss=4.219, nll_loss=2.807, ppl=7, wps=17415.3, ups=5.09, wpb=3420.8, bsz=155.7, num_updates=89300, lr=0.000105822, gnorm=1.172, train_wall=19, wall=0
2024-07-18 17:03:13 | INFO | train_inner | epoch 005:  11144 / 19564 loss=4.296, nll_loss=2.893, ppl=7.43, wps=17541.9, ups=5.06, wpb=3465.2, bsz=129.7, num_updates=89400, lr=0.000105762, gnorm=1.166, train_wall=20, wall=0
2024-07-18 17:03:33 | INFO | train_inner | epoch 005:  11244 / 19564 loss=4.31, nll_loss=2.909, ppl=7.51, wps=17796.9, ups=5.11, wpb=3479.9, bsz=132.8, num_updates=89500, lr=0.000105703, gnorm=1.181, train_wall=19, wall=0
2024-07-18 17:03:52 | INFO | train_inner | epoch 005:  11344 / 19564 loss=4.222, nll_loss=2.808, ppl=7, wps=17694.5, ups=5.1, wpb=3468.3, bsz=141.3, num_updates=89600, lr=0.000105644, gnorm=1.125, train_wall=19, wall=0
2024-07-18 17:04:12 | INFO | train_inner | epoch 005:  11444 / 19564 loss=4.266, nll_loss=2.86, ppl=7.26, wps=17591.3, ups=5.07, wpb=3473, bsz=139, num_updates=89700, lr=0.000105585, gnorm=1.146, train_wall=20, wall=0
2024-07-18 17:04:32 | INFO | train_inner | epoch 005:  11544 / 19564 loss=4.271, nll_loss=2.865, ppl=7.29, wps=17420.3, ups=5.14, wpb=3392, bsz=143.2, num_updates=89800, lr=0.000105527, gnorm=1.2, train_wall=19, wall=0
2024-07-18 17:04:52 | INFO | train_inner | epoch 005:  11644 / 19564 loss=4.262, nll_loss=2.856, ppl=7.24, wps=17335.5, ups=5.03, wpb=3446.8, bsz=145.4, num_updates=89900, lr=0.000105468, gnorm=1.193, train_wall=20, wall=0
2024-07-18 17:05:11 | INFO | train_inner | epoch 005:  11744 / 19564 loss=4.338, nll_loss=2.942, ppl=7.68, wps=17397.4, ups=5.2, wpb=3343.9, bsz=143, num_updates=90000, lr=0.000105409, gnorm=1.196, train_wall=19, wall=0
2024-07-18 17:05:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:05:13 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.148 | nll_loss 2.621 | ppl 6.15 | wps 54263 | wpb 2872.6 | bsz 51.2 | num_updates 90000 | best_loss 12.134
2024-07-18 17:05:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:05:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_90000.pt (epoch 5 @ 90000 updates, score 4.148) (writing took 10.418672516942024 seconds)
2024-07-18 17:05:43 | INFO | train_inner | epoch 005:  11844 / 19564 loss=4.336, nll_loss=2.941, ppl=7.68, wps=10755.4, ups=3.1, wpb=3473.7, bsz=153.9, num_updates=90100, lr=0.000105351, gnorm=1.179, train_wall=19, wall=0
2024-07-18 17:06:03 | INFO | train_inner | epoch 005:  11944 / 19564 loss=4.208, nll_loss=2.794, ppl=6.94, wps=17574.3, ups=4.99, wpb=3523.3, bsz=152.4, num_updates=90200, lr=0.000105292, gnorm=1.102, train_wall=20, wall=0
2024-07-18 17:06:23 | INFO | train_inner | epoch 005:  12044 / 19564 loss=4.249, nll_loss=2.84, ppl=7.16, wps=17499.2, ups=5.08, wpb=3441.7, bsz=141.6, num_updates=90300, lr=0.000105234, gnorm=1.148, train_wall=19, wall=0
2024-07-18 17:06:42 | INFO | train_inner | epoch 005:  12144 / 19564 loss=4.341, nll_loss=2.946, ppl=7.7, wps=17556.3, ups=5.12, wpb=3427.1, bsz=137.1, num_updates=90400, lr=0.000105176, gnorm=1.191, train_wall=19, wall=0
2024-07-18 17:07:02 | INFO | train_inner | epoch 005:  12244 / 19564 loss=4.312, nll_loss=2.911, ppl=7.52, wps=17335.6, ups=5.16, wpb=3357.7, bsz=118.6, num_updates=90500, lr=0.000105118, gnorm=1.214, train_wall=19, wall=0
2024-07-18 17:07:21 | INFO | train_inner | epoch 005:  12344 / 19564 loss=4.264, nll_loss=2.859, ppl=7.25, wps=17893.7, ups=5.09, wpb=3515.4, bsz=155.4, num_updates=90600, lr=0.00010506, gnorm=1.118, train_wall=19, wall=0
2024-07-18 17:07:41 | INFO | train_inner | epoch 005:  12444 / 19564 loss=4.314, nll_loss=2.913, ppl=7.53, wps=17229.5, ups=5.1, wpb=3380.9, bsz=129, num_updates=90700, lr=0.000105002, gnorm=1.198, train_wall=19, wall=0
2024-07-18 17:08:00 | INFO | train_inner | epoch 005:  12544 / 19564 loss=4.312, nll_loss=2.912, ppl=7.53, wps=17691.2, ups=5.16, wpb=3430, bsz=131.8, num_updates=90800, lr=0.000104944, gnorm=1.19, train_wall=19, wall=0
2024-07-18 17:08:20 | INFO | train_inner | epoch 005:  12644 / 19564 loss=4.267, nll_loss=2.861, ppl=7.26, wps=17361.9, ups=5.15, wpb=3373.6, bsz=138.4, num_updates=90900, lr=0.000104886, gnorm=1.167, train_wall=19, wall=0
2024-07-18 17:08:39 | INFO | train_inner | epoch 005:  12744 / 19564 loss=4.269, nll_loss=2.864, ppl=7.28, wps=16998.4, ups=5.12, wpb=3318.5, bsz=132.6, num_updates=91000, lr=0.000104828, gnorm=1.203, train_wall=19, wall=0
2024-07-18 17:08:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:08:42 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.147 | nll_loss 2.617 | ppl 6.13 | wps 54317.1 | wpb 2872.6 | bsz 51.2 | num_updates 91000 | best_loss 12.134
2024-07-18 17:08:42 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:08:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_91000.pt (epoch 5 @ 91000 updates, score 4.147) (writing took 11.642309625633061 seconds)
2024-07-18 17:09:13 | INFO | train_inner | epoch 005:  12844 / 19564 loss=4.303, nll_loss=2.901, ppl=7.47, wps=10079.5, ups=2.96, wpb=3406.4, bsz=133, num_updates=91100, lr=0.000104771, gnorm=1.199, train_wall=20, wall=0
2024-07-18 17:09:33 | INFO | train_inner | epoch 005:  12944 / 19564 loss=4.19, nll_loss=2.773, ppl=6.83, wps=17618, ups=4.98, wpb=3535.9, bsz=138.4, num_updates=91200, lr=0.000104713, gnorm=1.109, train_wall=20, wall=0
2024-07-18 17:09:53 | INFO | train_inner | epoch 005:  13044 / 19564 loss=4.249, nll_loss=2.841, ppl=7.16, wps=17607.1, ups=5, wpb=3519.5, bsz=153.5, num_updates=91300, lr=0.000104656, gnorm=1.15, train_wall=20, wall=0
2024-07-18 17:10:13 | INFO | train_inner | epoch 005:  13144 / 19564 loss=4.319, nll_loss=2.922, ppl=7.58, wps=17488.8, ups=5.14, wpb=3399.7, bsz=146.5, num_updates=91400, lr=0.000104599, gnorm=1.203, train_wall=19, wall=0
2024-07-18 17:10:32 | INFO | train_inner | epoch 005:  13244 / 19564 loss=4.319, nll_loss=2.921, ppl=7.57, wps=17465.7, ups=5.18, wpb=3369.8, bsz=148.5, num_updates=91500, lr=0.000104542, gnorm=1.194, train_wall=19, wall=0
2024-07-18 17:10:51 | INFO | train_inner | epoch 005:  13344 / 19564 loss=4.296, nll_loss=2.895, ppl=7.44, wps=17802, ups=5.1, wpb=3489.9, bsz=153.9, num_updates=91600, lr=0.000104485, gnorm=1.159, train_wall=19, wall=0
2024-07-18 17:11:11 | INFO | train_inner | epoch 005:  13444 / 19564 loss=4.293, nll_loss=2.891, ppl=7.42, wps=17521.5, ups=5.11, wpb=3426.5, bsz=143.7, num_updates=91700, lr=0.000104428, gnorm=1.174, train_wall=19, wall=0
2024-07-18 17:11:31 | INFO | train_inner | epoch 005:  13544 / 19564 loss=4.247, nll_loss=2.837, ppl=7.15, wps=17626.9, ups=5.12, wpb=3444.9, bsz=137.4, num_updates=91800, lr=0.000104371, gnorm=1.171, train_wall=19, wall=0
2024-07-18 17:11:50 | INFO | train_inner | epoch 005:  13644 / 19564 loss=4.276, nll_loss=2.872, ppl=7.32, wps=17849.7, ups=5.08, wpb=3513.8, bsz=145, num_updates=91900, lr=0.000104314, gnorm=1.156, train_wall=20, wall=0
2024-07-18 17:12:10 | INFO | train_inner | epoch 005:  13744 / 19564 loss=4.346, nll_loss=2.951, ppl=7.73, wps=17791.7, ups=5.09, wpb=3492.5, bsz=131.7, num_updates=92000, lr=0.000104257, gnorm=1.163, train_wall=19, wall=0
2024-07-18 17:12:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:12:12 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.148 | nll_loss 2.613 | ppl 6.12 | wps 54720.4 | wpb 2872.6 | bsz 51.2 | num_updates 92000 | best_loss 12.134
2024-07-18 17:12:12 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:12:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_92000.pt (epoch 5 @ 92000 updates, score 4.148) (writing took 5.144477243535221 seconds)
2024-07-18 17:12:37 | INFO | train_inner | epoch 005:  13844 / 19564 loss=4.272, nll_loss=2.867, ppl=7.29, wps=12652.9, ups=3.68, wpb=3437.7, bsz=136.9, num_updates=92100, lr=0.000104201, gnorm=1.154, train_wall=19, wall=0
2024-07-18 17:12:57 | INFO | train_inner | epoch 005:  13944 / 19564 loss=4.303, nll_loss=2.902, ppl=7.48, wps=17077, ups=5.02, wpb=3398.9, bsz=124.7, num_updates=92200, lr=0.000104144, gnorm=1.176, train_wall=20, wall=0
2024-07-18 17:13:16 | INFO | train_inner | epoch 005:  14044 / 19564 loss=4.267, nll_loss=2.861, ppl=7.27, wps=17540.5, ups=5.15, wpb=3404.6, bsz=139.4, num_updates=92300, lr=0.000104088, gnorm=1.142, train_wall=19, wall=0
2024-07-18 17:13:36 | INFO | train_inner | epoch 005:  14144 / 19564 loss=4.274, nll_loss=2.869, ppl=7.3, wps=17776.6, ups=5.15, wpb=3454.9, bsz=139.5, num_updates=92400, lr=0.000104031, gnorm=1.147, train_wall=19, wall=0
2024-07-18 17:13:55 | INFO | train_inner | epoch 005:  14244 / 19564 loss=4.234, nll_loss=2.825, ppl=7.08, wps=17540.8, ups=5.13, wpb=3420.8, bsz=152.9, num_updates=92500, lr=0.000103975, gnorm=1.176, train_wall=19, wall=0
2024-07-18 17:14:15 | INFO | train_inner | epoch 005:  14344 / 19564 loss=4.292, nll_loss=2.889, ppl=7.41, wps=17754.1, ups=5.12, wpb=3466.4, bsz=134.1, num_updates=92600, lr=0.000103919, gnorm=1.176, train_wall=19, wall=0
2024-07-18 17:14:34 | INFO | train_inner | epoch 005:  14444 / 19564 loss=4.269, nll_loss=2.864, ppl=7.28, wps=17829.6, ups=5.09, wpb=3501.6, bsz=147.4, num_updates=92700, lr=0.000103863, gnorm=1.137, train_wall=19, wall=0
2024-07-18 17:14:54 | INFO | train_inner | epoch 005:  14544 / 19564 loss=4.334, nll_loss=2.938, ppl=7.66, wps=17483.4, ups=5.08, wpb=3439.2, bsz=139, num_updates=92800, lr=0.000103807, gnorm=1.197, train_wall=19, wall=0
2024-07-18 17:15:14 | INFO | train_inner | epoch 005:  14644 / 19564 loss=4.294, nll_loss=2.892, ppl=7.42, wps=17531.7, ups=5.12, wpb=3424, bsz=127.8, num_updates=92900, lr=0.000103751, gnorm=1.158, train_wall=19, wall=0
2024-07-18 17:15:34 | INFO | train_inner | epoch 005:  14744 / 19564 loss=4.261, nll_loss=2.854, ppl=7.23, wps=17538.4, ups=5.03, wpb=3490.1, bsz=149.6, num_updates=93000, lr=0.000103695, gnorm=1.151, train_wall=20, wall=0
2024-07-18 17:15:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:15:36 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.142 | nll_loss 2.603 | ppl 6.08 | wps 54719.9 | wpb 2872.6 | bsz 51.2 | num_updates 93000 | best_loss 12.134
2024-07-18 17:15:36 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:15:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_93000.pt (epoch 5 @ 93000 updates, score 4.142) (writing took 6.365643261000514 seconds)
2024-07-18 17:16:02 | INFO | train_inner | epoch 005:  14844 / 19564 loss=4.333, nll_loss=2.935, ppl=7.65, wps=11893, ups=3.53, wpb=3367.1, bsz=124.6, num_updates=93100, lr=0.000103639, gnorm=1.196, train_wall=19, wall=0
2024-07-18 17:16:21 | INFO | train_inner | epoch 005:  14944 / 19564 loss=4.278, nll_loss=2.875, ppl=7.33, wps=17511.9, ups=5.14, wpb=3409.9, bsz=140.5, num_updates=93200, lr=0.000103584, gnorm=1.162, train_wall=19, wall=0
2024-07-18 17:16:41 | INFO | train_inner | epoch 005:  15044 / 19564 loss=4.267, nll_loss=2.862, ppl=7.27, wps=17435, ups=5.07, wpb=3439.5, bsz=160.1, num_updates=93300, lr=0.000103528, gnorm=1.185, train_wall=20, wall=0
2024-07-18 17:17:01 | INFO | train_inner | epoch 005:  15144 / 19564 loss=4.243, nll_loss=2.834, ppl=7.13, wps=17699.1, ups=5.1, wpb=3473, bsz=134.8, num_updates=93400, lr=0.000103473, gnorm=1.166, train_wall=19, wall=0
2024-07-18 17:17:20 | INFO | train_inner | epoch 005:  15244 / 19564 loss=4.327, nll_loss=2.93, ppl=7.62, wps=17411.7, ups=5.11, wpb=3409.7, bsz=143.9, num_updates=93500, lr=0.000103418, gnorm=1.202, train_wall=19, wall=0
2024-07-18 17:17:40 | INFO | train_inner | epoch 005:  15344 / 19564 loss=4.294, nll_loss=2.892, ppl=7.42, wps=17363.2, ups=5.15, wpb=3370.7, bsz=136.6, num_updates=93600, lr=0.000103362, gnorm=1.204, train_wall=19, wall=0
2024-07-18 17:17:59 | INFO | train_inner | epoch 005:  15444 / 19564 loss=4.274, nll_loss=2.869, ppl=7.31, wps=17588, ups=5.12, wpb=3436.7, bsz=138.9, num_updates=93700, lr=0.000103307, gnorm=1.148, train_wall=19, wall=0
2024-07-18 17:18:19 | INFO | train_inner | epoch 005:  15544 / 19564 loss=4.212, nll_loss=2.799, ppl=6.96, wps=17332.1, ups=5.01, wpb=3459.4, bsz=154.7, num_updates=93800, lr=0.000103252, gnorm=1.132, train_wall=20, wall=0
2024-07-18 17:18:39 | INFO | train_inner | epoch 005:  15644 / 19564 loss=4.281, nll_loss=2.878, ppl=7.35, wps=17431.2, ups=5.12, wpb=3406.5, bsz=148.4, num_updates=93900, lr=0.000103197, gnorm=1.185, train_wall=19, wall=0
2024-07-18 17:18:58 | INFO | train_inner | epoch 005:  15744 / 19564 loss=4.243, nll_loss=2.833, ppl=7.12, wps=17449.3, ups=5.09, wpb=3429.8, bsz=141.9, num_updates=94000, lr=0.000103142, gnorm=1.214, train_wall=19, wall=0
2024-07-18 17:18:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:19:01 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.136 | nll_loss 2.61 | ppl 6.1 | wps 54474.6 | wpb 2872.6 | bsz 51.2 | num_updates 94000 | best_loss 12.134
2024-07-18 17:19:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:19:05 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_94000.pt (epoch 5 @ 94000 updates, score 4.136) (writing took 3.9906065547838807 seconds)
2024-07-18 17:19:24 | INFO | train_inner | epoch 005:  15844 / 19564 loss=4.296, nll_loss=2.895, ppl=7.44, wps=13014.9, ups=3.85, wpb=3378.9, bsz=136.3, num_updates=94100, lr=0.000103087, gnorm=1.2, train_wall=19, wall=0
2024-07-18 17:19:44 | INFO | train_inner | epoch 005:  15944 / 19564 loss=4.227, nll_loss=2.815, ppl=7.04, wps=17910.4, ups=5.07, wpb=3531.6, bsz=147.2, num_updates=94200, lr=0.000103033, gnorm=1.105, train_wall=20, wall=0
2024-07-18 17:20:03 | INFO | train_inner | epoch 005:  16044 / 19564 loss=4.353, nll_loss=2.96, ppl=7.78, wps=17748.3, ups=5.19, wpb=3419.1, bsz=135.1, num_updates=94300, lr=0.000102978, gnorm=1.187, train_wall=19, wall=0
2024-07-18 17:20:23 | INFO | train_inner | epoch 005:  16144 / 19564 loss=4.328, nll_loss=2.932, ppl=7.63, wps=17623.3, ups=5.18, wpb=3402.7, bsz=137.8, num_updates=94400, lr=0.000102923, gnorm=1.2, train_wall=19, wall=0
2024-07-18 17:20:42 | INFO | train_inner | epoch 005:  16244 / 19564 loss=4.249, nll_loss=2.841, ppl=7.17, wps=17644.8, ups=5.11, wpb=3454.9, bsz=142.6, num_updates=94500, lr=0.000102869, gnorm=1.148, train_wall=19, wall=0
2024-07-18 17:21:02 | INFO | train_inner | epoch 005:  16344 / 19564 loss=4.242, nll_loss=2.833, ppl=7.12, wps=17717.7, ups=5.1, wpb=3471.4, bsz=147.1, num_updates=94600, lr=0.000102815, gnorm=1.142, train_wall=19, wall=0
2024-07-18 17:21:21 | INFO | train_inner | epoch 005:  16444 / 19564 loss=4.3, nll_loss=2.901, ppl=7.47, wps=17416.1, ups=5.16, wpb=3374.5, bsz=157.4, num_updates=94700, lr=0.00010276, gnorm=1.2, train_wall=19, wall=0
2024-07-18 17:21:41 | INFO | train_inner | epoch 005:  16544 / 19564 loss=4.261, nll_loss=2.856, ppl=7.24, wps=17276.5, ups=5.07, wpb=3405.7, bsz=156.9, num_updates=94800, lr=0.000102706, gnorm=1.155, train_wall=20, wall=0
2024-07-18 17:22:01 | INFO | train_inner | epoch 005:  16644 / 19564 loss=4.222, nll_loss=2.811, ppl=7.02, wps=17609.6, ups=5.07, wpb=3471.2, bsz=155, num_updates=94900, lr=0.000102652, gnorm=1.14, train_wall=19, wall=0
2024-07-18 17:22:20 | INFO | train_inner | epoch 005:  16744 / 19564 loss=4.265, nll_loss=2.86, ppl=7.26, wps=17899.4, ups=5.14, wpb=3481.2, bsz=153.8, num_updates=95000, lr=0.000102598, gnorm=1.159, train_wall=19, wall=0
2024-07-18 17:22:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:22:23 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.13 | nll_loss 2.597 | ppl 6.05 | wps 54490.7 | wpb 2872.6 | bsz 51.2 | num_updates 95000 | best_loss 12.134
2024-07-18 17:22:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:22:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_95000.pt (epoch 5 @ 95000 updates, score 4.13) (writing took 5.283775998279452 seconds)
2024-07-18 17:22:47 | INFO | train_inner | epoch 005:  16844 / 19564 loss=4.324, nll_loss=2.927, ppl=7.6, wps=12219.2, ups=3.68, wpb=3317.2, bsz=129, num_updates=95100, lr=0.000102544, gnorm=1.231, train_wall=19, wall=0
2024-07-18 17:23:07 | INFO | train_inner | epoch 005:  16944 / 19564 loss=4.304, nll_loss=2.904, ppl=7.49, wps=17460.6, ups=5.11, wpb=3415.6, bsz=132.1, num_updates=95200, lr=0.00010249, gnorm=1.178, train_wall=19, wall=0
2024-07-18 17:23:26 | INFO | train_inner | epoch 005:  17044 / 19564 loss=4.242, nll_loss=2.833, ppl=7.13, wps=17372.8, ups=5.13, wpb=3388.7, bsz=143.8, num_updates=95300, lr=0.000102436, gnorm=1.186, train_wall=19, wall=0
2024-07-18 17:23:46 | INFO | train_inner | epoch 005:  17144 / 19564 loss=4.242, nll_loss=2.833, ppl=7.13, wps=18115, ups=5.11, wpb=3543.2, bsz=152.6, num_updates=95400, lr=0.000102383, gnorm=1.125, train_wall=19, wall=0
2024-07-18 17:24:05 | INFO | train_inner | epoch 005:  17244 / 19564 loss=4.246, nll_loss=2.838, ppl=7.15, wps=17653.6, ups=5.14, wpb=3435.9, bsz=128.1, num_updates=95500, lr=0.000102329, gnorm=1.198, train_wall=19, wall=0
2024-07-18 17:24:25 | INFO | train_inner | epoch 005:  17344 / 19564 loss=4.178, nll_loss=2.76, ppl=6.77, wps=17805.5, ups=5.08, wpb=3508.1, bsz=148.6, num_updates=95600, lr=0.000102275, gnorm=1.111, train_wall=20, wall=0
2024-07-18 17:24:45 | INFO | train_inner | epoch 005:  17444 / 19564 loss=4.252, nll_loss=2.844, ppl=7.18, wps=17370.7, ups=5.06, wpb=3433.6, bsz=138.7, num_updates=95700, lr=0.000102222, gnorm=1.182, train_wall=20, wall=0
2024-07-18 17:25:04 | INFO | train_inner | epoch 005:  17544 / 19564 loss=4.285, nll_loss=2.883, ppl=7.38, wps=17444.4, ups=5.08, wpb=3435.5, bsz=145.7, num_updates=95800, lr=0.000102169, gnorm=1.157, train_wall=19, wall=0
2024-07-18 17:25:24 | INFO | train_inner | epoch 005:  17644 / 19564 loss=4.293, nll_loss=2.892, ppl=7.42, wps=17873.9, ups=5.1, wpb=3507.8, bsz=151.3, num_updates=95900, lr=0.000102115, gnorm=1.151, train_wall=19, wall=0
2024-07-18 17:25:44 | INFO | train_inner | epoch 005:  17744 / 19564 loss=4.305, nll_loss=2.905, ppl=7.49, wps=17885.2, ups=5.07, wpb=3527.9, bsz=132.6, num_updates=96000, lr=0.000102062, gnorm=1.144, train_wall=20, wall=0
2024-07-18 17:25:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:25:46 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.13 | nll_loss 2.607 | ppl 6.09 | wps 54496 | wpb 2872.6 | bsz 51.2 | num_updates 96000 | best_loss 12.134
2024-07-18 17:25:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:25:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_96000.pt (epoch 5 @ 96000 updates, score 4.13) (writing took 4.623782385140657 seconds)
2024-07-18 17:26:10 | INFO | train_inner | epoch 005:  17844 / 19564 loss=4.26, nll_loss=2.854, ppl=7.23, wps=13047.5, ups=3.76, wpb=3473.5, bsz=149, num_updates=96100, lr=0.000102009, gnorm=1.166, train_wall=19, wall=0
2024-07-18 17:26:30 | INFO | train_inner | epoch 005:  17944 / 19564 loss=4.225, nll_loss=2.813, ppl=7.03, wps=17658.3, ups=5.06, wpb=3486.6, bsz=146.8, num_updates=96200, lr=0.000101956, gnorm=1.149, train_wall=20, wall=0
2024-07-18 17:26:50 | INFO | train_inner | epoch 005:  18044 / 19564 loss=4.19, nll_loss=2.775, ppl=6.85, wps=17232.7, ups=5.05, wpb=3412.7, bsz=161.4, num_updates=96300, lr=0.000101903, gnorm=1.183, train_wall=20, wall=0
2024-07-18 17:27:10 | INFO | train_inner | epoch 005:  18144 / 19564 loss=4.231, nll_loss=2.821, ppl=7.07, wps=17315.3, ups=5.04, wpb=3433.7, bsz=157, num_updates=96400, lr=0.00010185, gnorm=1.179, train_wall=20, wall=0
2024-07-18 17:27:29 | INFO | train_inner | epoch 005:  18244 / 19564 loss=4.263, nll_loss=2.857, ppl=7.24, wps=17265.4, ups=5.11, wpb=3378.5, bsz=132.9, num_updates=96500, lr=0.000101797, gnorm=1.193, train_wall=19, wall=0
2024-07-18 17:27:49 | INFO | train_inner | epoch 005:  18344 / 19564 loss=4.261, nll_loss=2.857, ppl=7.24, wps=17376.8, ups=5.07, wpb=3424.2, bsz=157.3, num_updates=96600, lr=0.000101745, gnorm=1.188, train_wall=20, wall=0
2024-07-18 17:28:09 | INFO | train_inner | epoch 005:  18444 / 19564 loss=4.264, nll_loss=2.859, ppl=7.25, wps=17283.7, ups=5.1, wpb=3385.8, bsz=142.9, num_updates=96700, lr=0.000101692, gnorm=1.203, train_wall=19, wall=0
2024-07-18 17:28:29 | INFO | train_inner | epoch 005:  18544 / 19564 loss=4.248, nll_loss=2.84, ppl=7.16, wps=17637.1, ups=5.04, wpb=3497.7, bsz=139.3, num_updates=96800, lr=0.000101639, gnorm=1.132, train_wall=20, wall=0
2024-07-18 17:28:49 | INFO | train_inner | epoch 005:  18644 / 19564 loss=4.204, nll_loss=2.791, ppl=6.92, wps=17640.7, ups=5, wpb=3531.5, bsz=145, num_updates=96900, lr=0.000101587, gnorm=1.122, train_wall=20, wall=0
2024-07-18 17:29:08 | INFO | train_inner | epoch 005:  18744 / 19564 loss=4.304, nll_loss=2.904, ppl=7.48, wps=17427.6, ups=5.12, wpb=3406.1, bsz=136.4, num_updates=97000, lr=0.000101535, gnorm=1.183, train_wall=19, wall=0
2024-07-18 17:29:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:29:10 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.119 | nll_loss 2.591 | ppl 6.03 | wps 54639.2 | wpb 2872.6 | bsz 51.2 | num_updates 97000 | best_loss 12.134
2024-07-18 17:29:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:29:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_5_97000.pt (epoch 5 @ 97000 updates, score 4.119) (writing took 5.7880243100225925 seconds)
2024-07-18 17:29:36 | INFO | train_inner | epoch 005:  18844 / 19564 loss=4.308, nll_loss=2.909, ppl=7.51, wps=12302.7, ups=3.62, wpb=3394.6, bsz=126.5, num_updates=97100, lr=0.000101482, gnorm=1.176, train_wall=19, wall=0
2024-07-18 17:29:55 | INFO | train_inner | epoch 005:  18944 / 19564 loss=4.292, nll_loss=2.891, ppl=7.42, wps=17189.7, ups=5.07, wpb=3391.2, bsz=136.5, num_updates=97200, lr=0.00010143, gnorm=1.188, train_wall=20, wall=0
2024-07-18 17:30:15 | INFO | train_inner | epoch 005:  19044 / 19564 loss=4.234, nll_loss=2.825, ppl=7.08, wps=17735, ups=5.1, wpb=3479.1, bsz=156.1, num_updates=97300, lr=0.000101378, gnorm=1.163, train_wall=19, wall=0
2024-07-18 17:30:35 | INFO | train_inner | epoch 005:  19144 / 19564 loss=4.306, nll_loss=2.906, ppl=7.5, wps=17524.8, ups=5.13, wpb=3413.6, bsz=128.2, num_updates=97400, lr=0.000101326, gnorm=1.204, train_wall=19, wall=0
2024-07-18 17:30:54 | INFO | train_inner | epoch 005:  19244 / 19564 loss=4.249, nll_loss=2.842, ppl=7.17, wps=17219.8, ups=5.09, wpb=3381.9, bsz=152.3, num_updates=97500, lr=0.000101274, gnorm=1.222, train_wall=19, wall=0
2024-07-18 17:31:14 | INFO | train_inner | epoch 005:  19344 / 19564 loss=4.228, nll_loss=2.818, ppl=7.05, wps=17972.8, ups=5.11, wpb=3518.2, bsz=153.2, num_updates=97600, lr=0.000101222, gnorm=1.108, train_wall=19, wall=0
2024-07-18 17:31:33 | INFO | train_inner | epoch 005:  19444 / 19564 loss=4.24, nll_loss=2.832, ppl=7.12, wps=17327, ups=5.06, wpb=3421.5, bsz=138.6, num_updates=97700, lr=0.00010117, gnorm=1.189, train_wall=20, wall=0
2024-07-18 17:31:53 | INFO | train_inner | epoch 005:  19544 / 19564 loss=4.266, nll_loss=2.861, ppl=7.26, wps=17748.7, ups=5.11, wpb=3471.3, bsz=134.8, num_updates=97800, lr=0.000101118, gnorm=1.155, train_wall=19, wall=0
2024-07-18 17:31:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:31:59 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.122 | nll_loss 2.587 | ppl 6.01 | wps 54489.9 | wpb 2872.6 | bsz 51.2 | num_updates 97820 | best_loss 12.134
2024-07-18 17:31:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:32:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 5 @ 97820 updates, score 4.122) (writing took 4.047557279467583 seconds)
2024-07-18 17:32:03 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2024-07-18 17:32:03 | INFO | train | epoch 005 | loss 4.279 | nll_loss 2.874 | ppl 7.33 | wps 16818.6 | ups 4.88 | wpb 3446.5 | bsz 142.2 | num_updates 97820 | lr 0.000101108 | gnorm 1.163 | train_wall 3811 | wall 0
2024-07-18 17:32:04 | INFO | fairseq.trainer | begin training epoch 6
2024-07-18 17:32:19 | INFO | train_inner | epoch 006:     80 / 19564 loss=4.212, nll_loss=2.798, ppl=6.96, wps=13166.6, ups=3.81, wpb=3451.6, bsz=128.6, num_updates=97900, lr=0.000101067, gnorm=1.146, train_wall=19, wall=0
2024-07-18 17:32:39 | INFO | train_inner | epoch 006:    180 / 19564 loss=4.178, nll_loss=2.76, ppl=6.78, wps=17824.4, ups=5.08, wpb=3510.5, bsz=154.1, num_updates=98000, lr=0.000101015, gnorm=1.132, train_wall=20, wall=0
2024-07-18 17:32:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:32:41 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 4.128 | nll_loss 2.591 | ppl 6.03 | wps 54056.3 | wpb 2872.6 | bsz 51.2 | num_updates 98000 | best_loss 12.134
2024-07-18 17:32:41 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:32:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_98000.pt (epoch 6 @ 98000 updates, score 4.128) (writing took 5.419659415259957 seconds)
2024-07-18 17:33:06 | INFO | train_inner | epoch 006:    280 / 19564 loss=4.238, nll_loss=2.828, ppl=7.1, wps=12237.7, ups=3.64, wpb=3360, bsz=134.5, num_updates=98100, lr=0.000100964, gnorm=1.203, train_wall=19, wall=0
2024-07-18 17:33:26 | INFO | train_inner | epoch 006:    380 / 19564 loss=4.262, nll_loss=2.856, ppl=7.24, wps=17486.4, ups=5.09, wpb=3434.1, bsz=144.2, num_updates=98200, lr=0.000100912, gnorm=1.199, train_wall=19, wall=0
2024-07-18 17:33:46 | INFO | train_inner | epoch 006:    480 / 19564 loss=4.246, nll_loss=2.837, ppl=7.15, wps=17447.9, ups=5.08, wpb=3436.8, bsz=142.9, num_updates=98300, lr=0.000100861, gnorm=1.188, train_wall=20, wall=0
2024-07-18 17:34:06 | INFO | train_inner | epoch 006:    580 / 19564 loss=4.149, nll_loss=2.727, ppl=6.62, wps=17316.9, ups=4.99, wpb=3472.7, bsz=146.8, num_updates=98400, lr=0.00010081, gnorm=1.107, train_wall=20, wall=0
2024-07-18 17:34:26 | INFO | train_inner | epoch 006:    680 / 19564 loss=4.219, nll_loss=2.807, ppl=7, wps=17196.8, ups=5.05, wpb=3407.6, bsz=146.6, num_updates=98500, lr=0.000100759, gnorm=1.158, train_wall=20, wall=0
2024-07-18 17:34:45 | INFO | train_inner | epoch 006:    780 / 19564 loss=4.21, nll_loss=2.796, ppl=6.95, wps=17409.6, ups=5.09, wpb=3417.8, bsz=134.1, num_updates=98600, lr=0.000100707, gnorm=1.164, train_wall=19, wall=0
2024-07-18 17:35:05 | INFO | train_inner | epoch 006:    880 / 19564 loss=4.215, nll_loss=2.802, ppl=6.97, wps=17861.5, ups=5.1, wpb=3502.9, bsz=132.7, num_updates=98700, lr=0.000100656, gnorm=1.144, train_wall=19, wall=0
2024-07-18 17:35:25 | INFO | train_inner | epoch 006:    980 / 19564 loss=4.242, nll_loss=2.832, ppl=7.12, wps=17307.1, ups=5.07, wpb=3411.5, bsz=131.4, num_updates=98800, lr=0.000100605, gnorm=1.195, train_wall=20, wall=0
2024-07-18 17:35:44 | INFO | train_inner | epoch 006:   1080 / 19564 loss=4.243, nll_loss=2.834, ppl=7.13, wps=17830, ups=5.09, wpb=3505.5, bsz=129.7, num_updates=98900, lr=0.000100555, gnorm=1.154, train_wall=19, wall=0
2024-07-18 17:36:04 | INFO | train_inner | epoch 006:   1180 / 19564 loss=4.285, nll_loss=2.882, ppl=7.37, wps=17397.1, ups=5.08, wpb=3426.2, bsz=132.4, num_updates=99000, lr=0.000100504, gnorm=1.177, train_wall=20, wall=0
2024-07-18 17:36:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:36:06 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 4.109 | nll_loss 2.575 | ppl 5.96 | wps 54735.3 | wpb 2872.6 | bsz 51.2 | num_updates 99000 | best_loss 12.134
2024-07-18 17:36:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:36:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_99000.pt (epoch 6 @ 99000 updates, score 4.109) (writing took 4.789982800371945 seconds)
2024-07-18 17:36:31 | INFO | train_inner | epoch 006:   1280 / 19564 loss=4.213, nll_loss=2.801, ppl=6.97, wps=12808.9, ups=3.7, wpb=3461.2, bsz=139.2, num_updates=99100, lr=0.000100453, gnorm=1.179, train_wall=20, wall=0
2024-07-18 17:36:51 | INFO | train_inner | epoch 006:   1380 / 19564 loss=4.269, nll_loss=2.863, ppl=7.28, wps=17480, ups=5.11, wpb=3422.5, bsz=126.4, num_updates=99200, lr=0.000100402, gnorm=1.206, train_wall=19, wall=0
2024-07-18 17:37:10 | INFO | train_inner | epoch 006:   1480 / 19564 loss=4.232, nll_loss=2.821, ppl=7.07, wps=17547.1, ups=5.02, wpb=3492.3, bsz=147.1, num_updates=99300, lr=0.000100352, gnorm=1.144, train_wall=20, wall=0
2024-07-18 17:37:30 | INFO | train_inner | epoch 006:   1580 / 19564 loss=4.177, nll_loss=2.759, ppl=6.77, wps=17828.4, ups=5.09, wpb=3505.4, bsz=142.9, num_updates=99400, lr=0.000100301, gnorm=1.124, train_wall=19, wall=0
2024-07-18 17:37:50 | INFO | train_inner | epoch 006:   1680 / 19564 loss=4.214, nll_loss=2.802, ppl=6.97, wps=17695.9, ups=5.08, wpb=3482.3, bsz=147.4, num_updates=99500, lr=0.000100251, gnorm=1.162, train_wall=19, wall=0
2024-07-18 17:38:09 | INFO | train_inner | epoch 006:   1780 / 19564 loss=4.217, nll_loss=2.805, ppl=6.99, wps=17410.2, ups=5.1, wpb=3413.6, bsz=151.8, num_updates=99600, lr=0.000100201, gnorm=1.173, train_wall=19, wall=0
2024-07-18 17:38:29 | INFO | train_inner | epoch 006:   1880 / 19564 loss=4.267, nll_loss=2.861, ppl=7.27, wps=17586.7, ups=5.06, wpb=3472.4, bsz=143.7, num_updates=99700, lr=0.00010015, gnorm=1.163, train_wall=20, wall=0
2024-07-18 17:38:48 | INFO | train_inner | epoch 006:   1980 / 19564 loss=4.276, nll_loss=2.872, ppl=7.32, wps=17491.2, ups=5.18, wpb=3378.3, bsz=127.5, num_updates=99800, lr=0.0001001, gnorm=1.228, train_wall=19, wall=0
2024-07-18 17:39:08 | INFO | train_inner | epoch 006:   2080 / 19564 loss=4.242, nll_loss=2.833, ppl=7.13, wps=17651.4, ups=5.18, wpb=3410.1, bsz=148.7, num_updates=99900, lr=0.00010005, gnorm=1.194, train_wall=19, wall=0
2024-07-18 17:39:27 | INFO | train_inner | epoch 006:   2180 / 19564 loss=4.249, nll_loss=2.842, ppl=7.17, wps=17503.1, ups=5.19, wpb=3370.3, bsz=135.3, num_updates=100000, lr=0.0001, gnorm=1.187, train_wall=19, wall=0
2024-07-18 17:39:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-07-18 17:39:29 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 4.119 | nll_loss 2.593 | ppl 6.03 | wps 54326.1 | wpb 2872.6 | bsz 51.2 | num_updates 100000 | best_loss 12.134
2024-07-18 17:39:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-07-18 17:39:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_6_100000.pt (epoch 6 @ 100000 updates, score 4.119) (writing took 4.89105873927474 seconds)
2024-07-18 17:39:34 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2024-07-18 17:39:34 | INFO | train | epoch 006 | loss 4.23 | nll_loss 2.819 | ppl 7.06 | wps 16645 | ups 4.83 | wpb 3442.6 | bsz 139.4 | num_updates 100000 | lr 0.0001 | gnorm 1.17 | train_wall 424 | wall 0
2024-07-18 17:39:34 | INFO | fairseq_cli.train | done training in 18332.9 seconds
