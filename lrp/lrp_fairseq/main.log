cuda
100000.pt
['▁wissen', '▁sie', '▁,', '▁eines', '▁der', '▁großen', '▁vern', 'ügen', '▁beim', '▁reisen', '▁und', '▁eine', '▁der', '▁freu', 'den', '▁bei', '▁der', '▁ethn', 'ograph', 'ischen', '▁forschung', '▁ist', '▁,', '▁gemeinsam', '▁mit', '▁den', '▁menschen', '▁zu', '▁leben', '▁,', '▁die', '▁sich', '▁noch', '▁an', '▁die', '▁alten', '▁tage', '▁erinnern', '▁können', '▁.', '▁die', '▁ihre', '▁vergangenheit', '▁noch', '▁immer', '▁im', '▁wind', '▁spüren', '▁,', '▁sie', '▁auf', '▁vom', '▁regen', '▁ge', 'gl', 'ät', 'teten', '▁ste', 'inen', '▁berühren', '▁,', '▁sie', '▁in', '▁den', '▁b', 'itter', 'en', '▁blät', 'tern', '▁der', '▁pflanzen', '▁schme', 'cken', '▁.', '</s>']
Predicted sentence: 	 ['▁you', '▁know', '▁,', '▁one', '▁of', '▁the', '▁great', '▁san', 'ures', '▁in', '▁traveling', '▁,', '▁one', '▁of', '▁the', '▁great', 's', '▁of', '▁ethnic', 'n', 'ographic', '▁research', '▁is', '▁to', '▁together', '▁to', '▁live', '▁with', '▁the', '▁old', '▁still', '▁the', '▁remember', '▁from', '▁old', '▁days', '▁,', '▁and', '▁still', '▁feel', '▁their', '▁past', '▁in', '▁the', '▁wind', '▁,', '▁to', 'ing', '▁from', '▁the', '▁that', 'ishing', '▁,', '▁the', '▁,', '▁taste', '▁it', '▁in', '▁the', '▁bit', 'ter', '▁leaves', '▁of', '▁the', '▁.', '</s>']
Traceback (most recent call last):
  File "main.py", line 120, in <module>
    R = hub.relprop_decode(R)
  File "/local/home/ggabriel/ma/lrp/lrp_fairseq/wrappers/transformer_wrapper.py", line 800, in relprop_decode
    relevance_dict = self.relprop_attn(R, self.get_name(i,'encoder_attn', 'decoder'))
  File "/local/home/ggabriel/ma/lrp/lrp_fairseq/wrappers/transformer_wrapper.py", line 725, in relprop_attn
    flat_relevances = LRP.relprop(
  File "/local/home/ggabriel/ma/lrp/lrp_fairseq/wrappers/lrp.py", line 74, in relprop
    jacobians = jacobians if jacobians is not None else jacobian(output, inps, function)
  File "/local/home/ggabriel/ma/lrp/lrp_fairseq/wrappers/lrp.py", line 24, in jacobian
    flat_jac_components = torch.autograd.functional.jacobian(function, tuple(inps))#, retain_graph=True))        print(flat_jac_components[0][0].shape)
  File "/local/home/ggabriel/ma/alti/venv_alti/lib/python3.8/site-packages/torch/autograd/functional.py", line 579, in jacobian
    vj = _autograd_grad((out.reshape(-1)[j],), inputs,
  File "/local/home/ggabriel/ma/alti/venv_alti/lib/python3.8/site-packages/torch/autograd/functional.py", line 147, in _autograd_grad
    return torch.autograd.grad(new_outputs, inputs, new_grad_outputs, allow_unused=True,
  File "/local/home/ggabriel/ma/alti/venv_alti/lib/python3.8/site-packages/torch/autograd/__init__.py", line 226, in grad
    return Variable._execution_engine.run_backward(
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.91 GiB total capacity; 10.16 GiB already allocated; 3.00 MiB free; 11.12 GiB reserved in total by PyTorch)
